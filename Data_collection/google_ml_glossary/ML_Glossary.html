<!DOCTYPE html>
<!-- saved from url=(0055)https://developers.google.com/machine-learning/glossary -->
<html lang="en" dir="ltr"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="google-signin-client-id" content="721724668570-nbkv1cfusk7kk4eni4pjvepaus73b13t.apps.googleusercontent.com">
    <meta name="google-signin-scope" content="profile email https://www.googleapis.com/auth/developerprofiles https://www.googleapis.com/auth/developerprofiles.award">
    <meta property="og:site_name" content="Google Developers">
    <meta property="og:type" content="website"><meta name="theme-color" content="#ffffff">
    <meta content="IE=Edge" http-equiv="X-UA-Compatible">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    

    <link rel="manifest" href="https://developers.google.com/_pwa/developers/manifest.json" crossorigin="use-credentials">
    <link rel="preconnect" href="https://www.gstatic.com/" crossorigin="">
    <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin="">
    <link rel="preconnect" href="https://fonts.googleapis.com/" crossorigin="">
    <link rel="preconnect" href="https://apis.google.com/" crossorigin="">
    <link rel="preconnect" href="https://www.google-analytics.com/" crossorigin=""><link rel="stylesheet" href="./ML_Glossary_files/css">
      <link rel="stylesheet" href="./ML_Glossary_files/css2"><link rel="stylesheet" href="./ML_Glossary_files/app.css">
      <link rel="shortcut icon" href="https://www.gstatic.com/devrel-devsite/prod/v4fdbc33a55781dc592d32bc0c5d1eb8f6c96a05c8dafb5ba814fcab1c6bf1229/developers/images/favicon.png">
    <link rel="apple-touch-icon" href="https://www.gstatic.com/devrel-devsite/prod/v4fdbc33a55781dc592d32bc0c5d1eb8f6c96a05c8dafb5ba814fcab1c6bf1229/developers/images/touchicon-180.png"><link rel="canonical" href="https://developers.google.com/machine-learning/glossary"><link rel="search" type="application/opensearchdescription+xml" title="Google Developers" href="https://developers.google.com/s/opensearch.xml">
      <link rel="alternate" hreflang="en" href="https://developers.google.com/machine-learning/glossary"><link rel="alternate" hreflang="x-default" href="https://developers.google.com/machine-learning/glossary"><link rel="alternate" hreflang="ar" href="https://developers.google.com/machine-learning/glossary?hl=ar"><link rel="alternate" hreflang="bn" href="https://developers.google.com/machine-learning/glossary?hl=bn"><link rel="alternate" hreflang="zh-Hans" href="https://developers.google.com/machine-learning/glossary?hl=zh-cn"><link rel="alternate" hreflang="zh-Hant" href="https://developers.google.com/machine-learning/glossary?hl=zh-tw"><link rel="alternate" hreflang="fa" href="https://developers.google.com/machine-learning/glossary?hl=fa"><link rel="alternate" hreflang="fr" href="https://developers.google.com/machine-learning/glossary?hl=fr"><link rel="alternate" hreflang="de" href="https://developers.google.com/machine-learning/glossary?hl=de"><link rel="alternate" hreflang="he" href="https://developers.google.com/machine-learning/glossary?hl=he"><link rel="alternate" hreflang="hi" href="https://developers.google.com/machine-learning/glossary?hl=hi"><link rel="alternate" hreflang="id" href="https://developers.google.com/machine-learning/glossary?hl=id"><link rel="alternate" hreflang="it" href="https://developers.google.com/machine-learning/glossary?hl=it"><link rel="alternate" hreflang="ja" href="https://developers.google.com/machine-learning/glossary?hl=ja"><link rel="alternate" hreflang="ko" href="https://developers.google.com/machine-learning/glossary?hl=ko"><link rel="alternate" hreflang="pl" href="https://developers.google.com/machine-learning/glossary?hl=pl"><link rel="alternate" hreflang="pt-BR" href="https://developers.google.com/machine-learning/glossary?hl=pt-br"><link rel="alternate" hreflang="ru" href="https://developers.google.com/machine-learning/glossary?hl=ru"><link rel="alternate" hreflang="es-419" href="https://developers.google.com/machine-learning/glossary?hl=es-419"><link rel="alternate" hreflang="th" href="https://developers.google.com/machine-learning/glossary?hl=th"><link rel="alternate" hreflang="tr" href="https://developers.google.com/machine-learning/glossary?hl=tr"><link rel="alternate" hreflang="vi" href="https://developers.google.com/machine-learning/glossary?hl=vi"><title>Machine Learning Glossary &nbsp;|&nbsp; Google Developers</title>

<meta property="og:title" content="Machine Learning Glossary  |  Google Developers"><meta property="og:url" content="https://developers.google.com/machine-learning/glossary"><meta property="og:image" content="https://www.gstatic.com/devrel-devsite/prod/v4fdbc33a55781dc592d32bc0c5d1eb8f6c96a05c8dafb5ba814fcab1c6bf1229/developers/images/opengraph/white.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="675"><meta property="og:locale" content="en"><meta name="twitter:card" content="summary_large_image"><script src="./ML_Glossary_files/cb=gapi.loaded_1" nonce="" async=""></script><script src="./ML_Glossary_files/cb=gapi.loaded_0" nonce="" async=""></script><script type="text/javascript" async="" src="./ML_Glossary_files/linkid.js.download" nonce=""></script><script async="" src="./ML_Glossary_files/app_loader.js.download"></script><script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "BreadcrumbList",
    "itemListElement": [{
      "@type": "ListItem",
      "position": 1,
      "name": "Machine Learning",
      "item": "https://developers.google.com/machine-learning"
    },{
      "@type": "ListItem",
      "position": 2,
      "name": "Machine Learning Glossary",
      "item": "https://developers.google.com/machine-learning/glossary"
    }]
  }
  </script>
  <meta name="xsrf_token" content="yy60MGAkE5-KIh79UcTxfktNzU2hD4G-uqmdSf5c3Ac6MTY3NDAxNjU3ODg1NjgzOA">
  

  <meta name="session_expiry" content="0">
  

  

  


    
      <link rel="stylesheet" href="./ML_Glossary_files/extras.css"><script src="./ML_Glossary_files/devsite_app_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_app_custom_elements_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_a11y_announce_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_analytics_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_badger_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_book_nav_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_bookmark_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_code_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_content_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_expandable_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_feature_tooltip_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_feedback_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_footer_linkboxes_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_footer_promos_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_footer_utility_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_header_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_heading_link_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_language_selector_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_mathjax_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_notification_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_panel_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_progress_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_recommendations_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_recommendations_dropdown_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_recommendations_sidebar_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_search_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_sitemask_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_snackbar_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_tabs_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_thumb_rating_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_toc_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_tooltip_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_user_module.js.download" nonce=""></script><script src="./ML_Glossary_files/analytics.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_badge_awarded_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_dialog_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_spinner_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_mwc_module.js.download" nonce=""></script><script src="./ML_Glossary_files/MathJax.js.download" nonce=""></script><style type="text/css">.gb_5a:not(.gb_Ld){font:13px/27px Roboto,Arial,sans-serif;z-index:986}@-webkit-keyframes gb__a{0%{opacity:0}50%{opacity:1}}@keyframes gb__a{0%{opacity:0}50%{opacity:1}}a.gb_ca{border:none;color:#4285f4;cursor:default;font-weight:bold;outline:none;position:relative;text-align:center;text-decoration:none;text-transform:uppercase;white-space:nowrap;-webkit-user-select:none}a.gb_ca:hover:after,a.gb_ca:focus:after{background-color:rgba(0,0,0,.12);content:"";height:100%;left:0;position:absolute;top:0;width:100%}a.gb_ca:hover,a.gb_ca:focus{text-decoration:none}a.gb_ca:active{background-color:rgba(153,153,153,.4);text-decoration:none}a.gb_da{background-color:#4285f4;color:#fff}a.gb_da:active{background-color:#0043b2}.gb_ea{-webkit-box-shadow:0 1px 1px rgba(0,0,0,.16);box-shadow:0 1px 1px rgba(0,0,0,.16)}.gb_ca,.gb_da,.gb_fa,.gb_ga{display:inline-block;line-height:28px;padding:0 12px;-webkit-border-radius:2px;border-radius:2px}.gb_fa{background:#f8f8f8;border:1px solid #c6c6c6}.gb_ga{background:#f8f8f8}.gb_fa,#gb a.gb_fa.gb_fa,.gb_ga{color:#666;cursor:default;text-decoration:none}#gb a.gb_ga.gb_ga{cursor:default;text-decoration:none}.gb_ga{border:1px solid #4285f4;font-weight:bold;outline:none;background:#4285f4;background:-webkit-linear-gradient(top,#4387fd,#4683ea);background:linear-gradient(top,#4387fd,#4683ea);filter:progid:DXImageTransform.Microsoft.gradient(startColorstr=#4387fd,endColorstr=#4683ea,GradientType=0)}#gb a.gb_ga.gb_ga{color:#fff}.gb_ga:hover{-webkit-box-shadow:0 1px 0 rgba(0,0,0,.15);box-shadow:0 1px 0 rgba(0,0,0,.15)}.gb_ga:active{-webkit-box-shadow:inset 0 2px 0 rgba(0,0,0,.15);box-shadow:inset 0 2px 0 rgba(0,0,0,.15);background:#3c78dc;background:-webkit-linear-gradient(top,#3c7ae4,#3f76d3);background:linear-gradient(top,#3c7ae4,#3f76d3);filter:progid:DXImageTransform.Microsoft.gradient(startColorstr=#3c7ae4,endColorstr=#3f76d3,GradientType=0)}#gb .gb_ia{background:#fff;border:1px solid #dadce0;color:#1a73e8;display:inline-block;text-decoration:none}#gb .gb_ia:hover{background:#f8fbff;border-color:#dadce0;color:#174ea6}#gb .gb_ia:focus{background:#f4f8ff;color:#174ea6;outline:1px solid #174ea6}#gb .gb_ia:active,#gb .gb_ia:focus:active{background:#ecf3fe;color:#174ea6}#gb .gb_ia.gb_5{background:transparent;border:1px solid #5f6368;color:#8ab4f8;text-decoration:none}#gb .gb_ia.gb_5:hover{background:rgba(255,255,255,.04);color:#e8eaed}#gb .gb_ia.gb_5:focus{background:rgba(232,234,237,.12);color:#e8eaed;outline:1px solid #e8eaed}#gb .gb_ia.gb_5:active,#gb .gb_ia.gb_5:focus:active{background:rgba(232,234,237,.1);color:#e8eaed}.gb_i{display:none!important}.gb_Oa{visibility:hidden}.gb_kd{display:inline-block;vertical-align:middle}.gb_Cf .gb_h{bottom:-3px;right:-5px}.gb_Df{position:relative}.gb_e{display:inline-block;outline:none;vertical-align:middle;-webkit-border-radius:2px;border-radius:2px;-webkit-box-sizing:border-box;box-sizing:border-box;height:40px;width:40px;color:#000;cursor:pointer;text-decoration:none}#gb#gb a.gb_e{color:#000;cursor:pointer;text-decoration:none}.gb_7a{border-color:transparent;border-bottom-color:#fff;border-style:dashed dashed solid;border-width:0 8.5px 8.5px;display:none;position:absolute;left:11.5px;top:43px;z-index:1;height:0;width:0;-webkit-animation:gb__a .2s;animation:gb__a .2s}.gb_8a{border-color:transparent;border-style:dashed dashed solid;border-width:0 8.5px 8.5px;display:none;position:absolute;left:11.5px;z-index:1;height:0;width:0;-webkit-animation:gb__a .2s;animation:gb__a .2s;border-bottom-color:#ccc;border-bottom-color:rgba(0,0,0,.2);top:42px}x:-o-prefocus,div.gb_8a{border-bottom-color:#ccc}.gb_L{background:#fff;border:1px solid #ccc;border-color:rgba(0,0,0,.2);color:#000;-webkit-box-shadow:0 2px 10px rgba(0,0,0,.2);box-shadow:0 2px 10px rgba(0,0,0,.2);display:none;outline:none;overflow:hidden;position:absolute;right:8px;top:62px;-webkit-animation:gb__a .2s;animation:gb__a .2s;-webkit-border-radius:2px;border-radius:2px;-webkit-user-select:text}.gb_kd.gb_ya .gb_7a,.gb_kd.gb_ya .gb_8a,.gb_kd.gb_ya .gb_L,.gb_ya.gb_L{display:block}.gb_kd.gb_ya.gb_Ef .gb_7a,.gb_kd.gb_ya.gb_Ef .gb_8a{display:none}.gb_Ff{position:absolute;right:8px;top:62px;z-index:-1}.gb_Ua .gb_7a,.gb_Ua .gb_8a,.gb_Ua .gb_L{margin-top:-10px}.gb_kd:first-child,#gbsfw:first-child+.gb_kd{padding-left:4px}.gb_Ca.gb_Ue .gb_kd:first-child{padding-left:0}.gb_Ve{position:relative}.gb_Vc .gb_Ve,.gb_2d .gb_Ve{float:right}.gb_e{padding:8px;cursor:pointer}.gb_Ca .gb_cd:not(.gb_ca):focus img{background-color:rgba(0,0,0,.20);outline:none;-webkit-border-radius:50%;border-radius:50%}.gb_We button svg,.gb_e{-webkit-border-radius:50%;border-radius:50%}.gb_We button:focus:not(:focus-visible) svg,.gb_We button:hover svg,.gb_We button:active svg,.gb_e:focus:not(:focus-visible),.gb_e:hover,.gb_e:active,.gb_e[aria-expanded=true]{outline:none}.gb_Ec .gb_We.gb_Xe button:focus-visible svg,.gb_We button:focus-visible svg,.gb_e:focus-visible{outline:1px solid #202124}.gb_Ec .gb_We button:focus-visible svg,.gb_Ec .gb_e:focus-visible{outline:1px solid #f1f3f4}@media (forced-colors:active){.gb_Ec .gb_We.gb_Xe button:focus-visible svg,.gb_We button:focus-visible svg,.gb_Ec .gb_We button:focus-visible svg{outline:1px solid currentcolor}}.gb_Ec .gb_We.gb_Xe button:focus svg,.gb_Ec .gb_We.gb_Xe button:focus:hover svg,.gb_We button:focus svg,.gb_We button:focus:hover svg,.gb_e:focus,.gb_e:focus:hover{background-color:rgba(60,64,67,.1)}.gb_Ec .gb_We.gb_Xe button:active svg,.gb_We button:active svg,.gb_e:active{background-color:rgba(60,64,67,.12)}.gb_Ec .gb_We.gb_Xe button:hover svg,.gb_We button:hover svg,.gb_e:hover{background-color:rgba(60,64,67,.08)}.gb_wa .gb_e.gb_Xa:hover{background-color:transparent}.gb_e[aria-expanded=true],.gb_e:hover[aria-expanded=true]{background-color:rgba(95,99,104,.24)}.gb_e[aria-expanded=true] .gb_Ze,.gb_e[aria-expanded=true] .gb_0e{fill:#5f6368;opacity:1}.gb_Ec .gb_We button:hover svg,.gb_Ec .gb_e:hover{background-color:rgba(232,234,237,.08)}.gb_Ec .gb_We button:focus svg,.gb_Ec .gb_We button:focus:hover svg,.gb_Ec .gb_e:focus,.gb_Ec .gb_e:focus:hover{background-color:rgba(232,234,237,.10)}.gb_Ec .gb_We button:active svg,.gb_Ec .gb_e:active{background-color:rgba(232,234,237,.12)}.gb_Ec .gb_e[aria-expanded=true],.gb_Ec .gb_e:hover[aria-expanded=true]{background-color:rgba(255,255,255,.12)}.gb_Ec .gb_e[aria-expanded=true] .gb_Ze,.gb_Ec .gb_e[aria-expanded=true] .gb_0e{fill:#fff;opacity:1}.gb_kd{padding:4px}.gb_Ca.gb_Ue .gb_kd{padding:4px 2px}.gb_Ca.gb_Ue .gb_b.gb_kd{padding-left:6px}.gb_L{z-index:991;line-height:normal}.gb_L.gb_1e{left:8px;right:auto}@media (max-width:350px){.gb_L.gb_1e{left:0}}.gb_2e .gb_L{top:56px}.gb_J .gb_e,.gb_K .gb_J .gb_e{background-position:-64px -29px}.gb_p .gb_J .gb_e{background-position:-29px -29px;opacity:1}.gb_J .gb_e,.gb_J .gb_e:hover,.gb_J .gb_e:focus{opacity:1}.gb_Md{display:none}.gb_h{display:none}.gb_4c{font-family:Google Sans,Roboto,Helvetica,Arial,sans-serif;font-size:20px;font-weight:400;letter-spacing:0.25px;line-height:48px;margin-bottom:2px;opacity:1;overflow:hidden;padding-left:16px;position:relative;text-overflow:ellipsis;vertical-align:middle;top:2px;white-space:nowrap;-webkit-flex:1 1 auto;flex:1 1 auto}.gb_4c.gb_5c{color:#3c4043}.gb_Ca.gb_Da .gb_4c{margin-bottom:0}.gb_6c.gb_7c .gb_4c{padding-left:4px}.gb_Ca.gb_Da .gb_8c{position:relative;top:-2px}.gb_Ca{color:black;min-width:320px;position:relative;-webkit-transition:box-shadow 250ms;transition:box-shadow 250ms}.gb_Ca.gb_Nc{min-width:240px}.gb_Ca.gb_Nd .gb_Od{display:none}.gb_Ca.gb_Nd .gb_Pd{height:56px}header.gb_Ca{display:block}.gb_Ca svg{fill:currentColor}.gb_Qd{position:fixed;top:0;width:100%}.gb_Rd{-webkit-box-shadow:0px 4px 5px 0px rgba(0,0,0,.14),0px 1px 10px 0px rgba(0,0,0,.12),0px 2px 4px -1px rgba(0,0,0,.2);box-shadow:0px 4px 5px 0px rgba(0,0,0,.14),0px 1px 10px 0px rgba(0,0,0,.12),0px 2px 4px -1px rgba(0,0,0,.2)}.gb_Sd{height:64px}.gb_Pd{-webkit-box-sizing:border-box;box-sizing:border-box;position:relative;width:100%;display:-webkit-box;display:-webkit-flex;display:flex;-webkit-box-pack:space-between;-webkit-justify-content:space-between;justify-content:space-between;min-width:-webkit-min-content;min-width:min-content}.gb_Ca:not(.gb_Da) .gb_Pd{padding:8px}.gb_Ca.gb_Td .gb_Pd{-webkit-flex:1 0 auto;flex:1 0 auto}.gb_Ca .gb_Pd.gb_Ud.gb_Vd{min-width:0}.gb_Ca.gb_Da .gb_Pd{padding:4px;padding-left:8px;min-width:0}.gb_Od{height:48px;vertical-align:middle;white-space:nowrap;-webkit-box-align:center;-webkit-align-items:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:flex;-webkit-user-select:none}.gb_Xd>.gb_Od{display:table-cell;width:100%}.gb_6c{padding-right:30px;-webkit-box-sizing:border-box;box-sizing:border-box;-webkit-flex:1 0 auto;flex:1 0 auto}.gb_Ca.gb_Da .gb_6c{padding-right:14px}.gb_Zd{-webkit-flex:1 1 100%;flex:1 1 100%}.gb_Zd>:only-child{display:inline-block}.gb_0d.gb_Wc{padding-left:4px}.gb_0d.gb_1d,.gb_Ca.gb_Td .gb_0d,.gb_Ca.gb_Da:not(.gb_2d) .gb_0d{padding-left:0}.gb_Ca.gb_Da .gb_0d.gb_1d{padding-right:0}.gb_Ca.gb_Da .gb_0d.gb_1d .gb_wa{margin-left:10px}.gb_Wc{display:inline}.gb_Ca.gb_Qc .gb_0d.gb_3d,.gb_Ca.gb_2d .gb_0d.gb_3d{padding-left:2px}.gb_4c{display:inline-block}.gb_0d{-webkit-box-sizing:border-box;box-sizing:border-box;height:48px;line-height:normal;padding:0 4px;padding-left:30px;-webkit-flex:0 0 auto;flex:0 0 auto;-webkit-box-pack:flex-end;-webkit-justify-content:flex-end;justify-content:flex-end}.gb_2d{height:48px}.gb_Ca.gb_2d{min-width:initial;min-width:auto}.gb_2d .gb_0d{float:right;padding-left:32px}.gb_2d .gb_0d.gb_4d{padding-left:0}.gb_5d{font-size:14px;max-width:200px;overflow:hidden;padding:0 12px;text-overflow:ellipsis;white-space:nowrap;-webkit-user-select:text}.gb_6d{-webkit-transition:background-color .4s;transition:background-color .4s}.gb_7d{color:black}.gb_Ec{color:white}.gb_Ca a,.gb_Kc a{color:inherit}.gb_z{color:rgba(0,0,0,.87)}.gb_Ca svg,.gb_Kc svg,.gb_6c .gb_8d,.gb_Vc .gb_8d{color:#5f6368;opacity:1}.gb_Ec svg,.gb_Kc.gb_Oc svg,.gb_Ec .gb_6c .gb_8d,.gb_Ec .gb_6c .gb_Dc,.gb_Ec .gb_6c .gb_8c,.gb_Kc.gb_Oc .gb_8d{color:rgba(255,255,255,0.87)}.gb_Ec .gb_6c .gb_Cc:not(.gb_9d){opacity:0.87}.gb_5c{color:inherit;opacity:1;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased}.gb_Ec .gb_5c,.gb_7d .gb_5c{opacity:1}.gb_ae{position:relative}.gb_be{font-family:arial,sans-serif;line-height:normal;padding-right:15px}a.gb_m,span.gb_m{color:rgba(0,0,0,.87);text-decoration:none}.gb_Ec a.gb_m,.gb_Ec span.gb_m{color:white}a.gb_m:focus{outline-offset:2px}a.gb_m:hover{text-decoration:underline}.gb_n{display:inline-block;padding-left:15px}.gb_n .gb_m{display:inline-block;line-height:24px;vertical-align:middle}.gb_ce{font-family:Google Sans,Roboto,Helvetica,Arial,sans-serif;font-weight:500;font-size:14px;letter-spacing:0.25px;line-height:16px;margin-left:10px;margin-right:8px;min-width:96px;padding:9px 23px;text-align:center;vertical-align:middle;-webkit-border-radius:4px;border-radius:4px;-webkit-box-sizing:border-box;box-sizing:border-box}.gb_Ca.gb_2d .gb_ce{margin-left:8px}#gb a.gb_ga.gb_ga.gb_ce{cursor:pointer}.gb_ga.gb_ce:hover{background:#1b66c9;-webkit-box-shadow:0 1px 3px 1px rgba(66,64,67,.15),0 1px 2px 0 rgba(60,64,67,.3);box-shadow:0 1px 3px 1px rgba(66,64,67,.15),0 1px 2px 0 rgba(60,64,67,.3)}.gb_ga.gb_ce:focus,.gb_ga.gb_ce:hover:focus{background:#1c5fba;-webkit-box-shadow:0 1px 3px 1px rgba(66,64,67,.15),0 1px 2px 0 rgba(60,64,67,.3);box-shadow:0 1px 3px 1px rgba(66,64,67,.15),0 1px 2px 0 rgba(60,64,67,.3)}.gb_ga.gb_ce:active{background:#1b63c1;-webkit-box-shadow:0 1px 3px 1px rgba(66,64,67,.15),0 1px 2px 0 rgba(60,64,67,.3);box-shadow:0 1px 3px 1px rgba(66,64,67,.15),0 1px 2px 0 rgba(60,64,67,.3)}.gb_ce{background:#1a73e8;border:1px solid transparent}.gb_Ca.gb_Da .gb_ce{padding:9px 15px;min-width:80px}.gb_de{text-align:left}#gb .gb_Ec a.gb_ce:not(.gb_5),#gb.gb_Ec a.gb_ce{background:#fff;border-color:#dadce0;-webkit-box-shadow:none;box-shadow:none;color:#1a73e8}#gb a.gb_ga.gb_5.gb_ce{background:#8ab4f8;border:1px solid transparent;-webkit-box-shadow:none;box-shadow:none;color:#202124}#gb .gb_Ec a.gb_ce:hover:not(.gb_5),#gb.gb_Ec a.gb_ce:hover{background:#f8fbff;border-color:#cce0fc}#gb a.gb_ga.gb_5.gb_ce:hover{background:#93baf9;border-color:transparent;-webkit-box-shadow:0 1px 3px 1px rgba(0,0,0,.15),0 1px 2px rgba(0,0,0,.3);box-shadow:0 1px 3px 1px rgba(0,0,0,.15),0 1px 2px rgba(0,0,0,.3)}#gb .gb_Ec a.gb_ce:focus:not(.gb_5),#gb .gb_Ec a.gb_ce:focus:hover:not(.gb_5),#gb.gb_Ec a.gb_ce:focus:not(.gb_5),#gb.gb_Ec a.gb_ce:focus:hover:not(.gb_5){background:#f4f8ff;outline:1px solid #c9ddfc}#gb a.gb_ga.gb_5.gb_ce:focus,#gb a.gb_ga.gb_5.gb_ce:focus:hover{background:#a6c6fa;border-color:transparent;-webkit-box-shadow:none;box-shadow:none}#gb .gb_Ec a.gb_ce:active:not(.gb_5),#gb.gb_Ec a.gb_ce:active{background:#ecf3fe}#gb a.gb_ga.gb_5.gb_ce:active{background:#a1c3f9;-webkit-box-shadow:0 1px 2px rgba(60,64,67,.3),0 2px 6px 2px rgba(60,64,67,.15);box-shadow:0 1px 2px rgba(60,64,67,.3),0 2px 6px 2px rgba(60,64,67,.15)}.gb_wa{background-color:rgba(255,255,255,.88);border:1px solid #dadce0;-webkit-box-sizing:border-box;box-sizing:border-box;cursor:pointer;display:inline-block;max-height:48px;overflow:hidden;outline:none;padding:0;vertical-align:middle;width:134px;-webkit-border-radius:8px;border-radius:8px}.gb_wa.gb_5{background-color:transparent;border:1px solid #5f6368}.gb_xa{display:inherit}.gb_wa.gb_5 .gb_xa{background:#fff;-webkit-border-radius:4px;border-radius:4px;display:inline-block;left:8px;margin-right:5px;position:relative;padding:3px;top:-1px}.gb_wa:hover{border:1px solid #d2e3fc;background-color:rgba(248,250,255,.88)}.gb_wa.gb_5:hover{background-color:rgba(241,243,244,.04);border:1px solid #5f6368}.gb_wa:focus-visible,.gb_wa:focus{background-color:rgba(255,255,255);outline:1px solid #202124;-webkit-box-shadow:0px 1px 2px 0px rgba(60,64,67,.3),0px 1px 3px 1px rgba(60,64,67,.15);box-shadow:0px 1px 2px 0px rgba(60,64,67,.3),0px 1px 3px 1px rgba(60,64,67,.15)}.gb_wa.gb_5:focus-visible,.gb_wa.gb_5:focus{background-color:rgba(241,243,244,.12);outline:1px solid #f1f3f4;-webkit-box-shadow:0 1px 3px 1px rgba(0,0,0,.15),0 1px 2px 0 rgba(0,0,0,.3);box-shadow:0 1px 3px 1px rgba(0,0,0,.15),0 1px 2px 0 rgba(0,0,0,.3)}.gb_wa.gb_5:active,.gb_wa.gb_ya.gb_5:focus{background-color:rgba(241,243,244,.1);border:1px solid #5f6368}.gb_za{display:inline-block;padding-bottom:2px;padding-left:7px;padding-top:2px;text-align:center;vertical-align:middle;line-height:32px;width:78px}.gb_wa.gb_5 .gb_za{line-height:26px;margin-left:0;padding-bottom:0;padding-left:0;padding-top:0;width:72px}.gb_za.gb_Aa{background-color:#f1f3f4;-webkit-border-radius:4px;border-radius:4px;margin-left:8px;padding-left:0}.gb_za.gb_Aa .gb_Ba{vertical-align:middle}.gb_Ca:not(.gb_Da) .gb_wa{margin-left:10px;margin-right:4px}.gb_Ea{max-height:32px;width:78px}.gb_wa.gb_5 .gb_Ea{max-height:26px;width:72px}.gb_g{-webkit-background-size:32px 32px;background-size:32px 32px;border:0;-webkit-border-radius:50%;border-radius:50%;display:block;margin:0px;position:relative;height:32px;width:32px;z-index:0}.gb_Pa{background-color:#e8f0fe;border:1px solid rgba(32,33,36,.08);position:relative}.gb_Pa.gb_g{height:30px;width:30px}.gb_Pa.gb_g:hover,.gb_Pa.gb_g:active{-webkit-box-shadow:none;box-shadow:none}.gb_Qa{background:#fff;border:none;-webkit-border-radius:50%;border-radius:50%;bottom:2px;-webkit-box-shadow:0px 1px 2px 0px rgba(60,64,67,.30),0px 1px 3px 1px rgba(60,64,67,.15);box-shadow:0px 1px 2px 0px rgba(60,64,67,.30),0px 1px 3px 1px rgba(60,64,67,.15);height:14px;margin:2px;position:absolute;right:0;width:14px}.gb_Ra{color:#1f71e7;font:400 22px/32px Google Sans,Roboto,Helvetica,Arial,sans-serif;text-align:center;text-transform:uppercase}@media (min-resolution:1.25dppx),(-o-min-device-pixel-ratio:5/4),(-webkit-min-device-pixel-ratio:1.25),(min-device-pixel-ratio:1.25){.gb_g::before,.gb_Sa::before{display:inline-block;-webkit-transform:scale(.5);transform:scale(.5);-webkit-transform-origin:left 0;transform-origin:left 0}.gb_r .gb_Sa::before{-webkit-transform:scale(0.416666667);transform:scale(0.416666667)}}.gb_g:hover,.gb_g:focus{-webkit-box-shadow:0 1px 0 rgba(0,0,0,.15);box-shadow:0 1px 0 rgba(0,0,0,.15)}.gb_g:active{-webkit-box-shadow:inset 0 2px 0 rgba(0,0,0,.15);box-shadow:inset 0 2px 0 rgba(0,0,0,.15)}.gb_g:active::after{background:rgba(0,0,0,.1);-webkit-border-radius:50%;border-radius:50%;content:"";display:block;height:100%}.gb_Ta{cursor:pointer;line-height:40px;min-width:30px;opacity:.75;overflow:hidden;vertical-align:middle;text-overflow:ellipsis}.gb_e.gb_Ta{width:auto}.gb_Ta:hover,.gb_Ta:focus{opacity:.85}.gb_Ua .gb_Ta,.gb_Ua .gb_Va{line-height:26px}#gb#gb.gb_Ua a.gb_Ta,.gb_Ua .gb_Va{font-size:11px;height:auto}.gb_Wa{border-top:4px solid #000;border-left:4px dashed transparent;border-right:4px dashed transparent;display:inline-block;margin-left:6px;opacity:.75;vertical-align:middle}.gb_Xa:hover .gb_Wa{opacity:.85}.gb_wa>.gb_b{padding:3px 3px 3px 4px}.gb_Za.gb_Oa{color:#fff}.gb_p .gb_Ta,.gb_p .gb_Wa{opacity:1}#gb#gb.gb_p.gb_p a.gb_Ta,#gb#gb .gb_p.gb_p a.gb_Ta{color:#fff}.gb_p.gb_p .gb_Wa{border-top-color:#fff;opacity:1}.gb_K .gb_g:hover,.gb_p .gb_g:hover,.gb_K .gb_g:focus,.gb_p .gb_g:focus{-webkit-box-shadow:0 1px 0 rgba(0,0,0,.15),0 1px 2px rgba(0,0,0,.2);box-shadow:0 1px 0 rgba(0,0,0,.15),0 1px 2px rgba(0,0,0,.2)}.gb_0a .gb_b,.gb_1a .gb_b{position:absolute;right:1px}.gb_b.gb_o,.gb_2a.gb_o,.gb_Xa.gb_o{-webkit-flex:0 1 auto;flex:0 1 auto;-webkit-flex:0 1 main-size;flex:0 1 main-size}.gb_3a.gb_4a .gb_Ta{width:30px!important}.gb_d{height:40px;position:absolute;right:-5px;top:-5px;width:40px}.gb_5a .gb_d,.gb_6a .gb_d{right:0;top:0}.gb_b .gb_e{padding:4px}.gb_fe{display:none}sentinel{}</style><script id="ogb-head-script">;this.gbar_={CONFIG:[[[0,"www.gstatic.com","og.qtm.en_US.68822eSqMEc.2019.O","com.au","en","331",0,[4,2,"","","","500587755","0"],null,"RnfHY8bKHuWZp84PyOe3qAw",null,0,"og.qtm.u7mWlFl1QR4.L.W.O","AA2YrTvPl0rdmuQXhRk94MOFFvx26r1YrA","AA2YrTvz7ig2_pXD7E6HPsesgafZ3WrM_Q","",2,1,200,"AUS",null,null,"18","331",1],null,[1,0.1000000014901161,2,1],[1,0.001000000047497451,1],[1,0,0,null,"0","dunglailaptrinh@gmail.com","","ACMtNjcTqirm6BVdmHcNII-yjwZY9CeFJSpR-58ljFhCY1bpPpNwSEVrRbqzbASVTqfMXChQRawqT60bS-1O1v7tdQegsiFj_A"],[0,0,"",1,0,0,0,0,0,0,null,0,0,null,0,0,null,null,0,0,0,"","","","","","",null,0,0,0,0,0,null,null,null,"rgba(32,33,36,1)","rgba(255,255,255,1)",0,0,0,null,null,1,0,0],["%1$s (default)","Brand account",1,"%1$s (delegated)",1,null,83,"?authuser=$authuser",null,null,null,1,"https://accounts.google.com/ListAccounts?listPages=0\u0026authuser=0\u0026pid=331\u0026gpsia=1\u0026source=ogb\u0026atic=1\u0026mo=1\u0026mn=1\u0026hl=en",0,"dashboard",null,null,null,null,"Profile","",1,null,"Signed out","https://accounts.google.com/AccountChooser?source=ogb\u0026continue=$continue\u0026Email=$email\u0026ec=GAhAywI","https://accounts.google.com/RemoveLocalAccount?source=ogb","Remove","Sign in",0,1,1,0,1,1,0,null,null,null,"Session expired",null,null,null,"Visitor",null,"Default","Delegated","Sign out of all accounts",1,null,null,0,null,null,"myaccount.google.com","https",0,1,0],null,["1","gci_91f30755d6a6b787dcc2a4062e6e9824.js","googleapis.client:gapi.iframes","0","en"],null,null,null,null,["m;/_/scs/abc-static/_/js/k=gapi.gapi.en.WEPncdil2Uw.O/d=1/rs=AHpOoo-eOecLLtOXEl3I3kIuMsKXRkDMmA/m=__features__","https://apis.google.com","","","1","",null,1,"es_plusone_gc_20221206.0_p0","en",null,0],[0.009999999776482582,"com.au","331",[null,"","0",null,1,5184000,null,null,"",null,null,null,null,null,0,null,0,0,1,0,0,0,null,null,0,0,null,0,0,0,0,0],null,null,null,0,null,null,["5061451","google\\.(com|ru|ca|by|kz|com\\.mx|com\\.tr)$",1]],[1,1,null,40400,331,"AUS","en","500587755.0",8,0.009999999776482582,1,0,null,null,null,null,"3700949",null,null,null,"RnfHY8bKHuWZp84PyOe3qAw",0,0,0,null,2,5,"nn",85,0,0,1,0,0],[[null,null,null,"https://www.gstatic.com/og/_/js/k=og.qtm.en_US.68822eSqMEc.2019.O/rt=j/m=qabr,qgl,q_dnp,qcwid,qbd,qapid/exm=qaaw,qadd,qaid,qein,qhaw,qhba,qhbr,qhch,qhga,qhid,qhin,qhpr/d=1/ed=1/rs=AA2YrTvPl0rdmuQXhRk94MOFFvx26r1YrA"],[null,null,null,"https://www.gstatic.com/og/_/ss/k=og.qtm.u7mWlFl1QR4.L.W.O/m=qcwid/excm=qaaw,qadd,qaid,qein,qhaw,qhba,qhbr,qhch,qhga,qhid,qhin,qhpr/d=1/ed=1/ct=zgms/rs=AA2YrTvz7ig2_pXD7E6HPsesgafZ3WrM_Q"]],null,null,null,[[[null,null,[null,null,null,"https://ogs.google.com/u/0/widget/account?sea=1"],0,414,372,57,4,1,0,0,65,66,8000,"https://accounts.google.com/SignOutOptions?hl=en\u0026continue=https://developers.google.com/_d/profile/ogb",68,2,null,null,1,113,"Something went wrong. Refresh to try again or %1$schoose another account%2$s.",3,null,null,75,0,null,null,null,null,null,null,null,"/widget/account",["https","myaccount.google.com",0,32,83,0],0,0,1,["Critical security alert","Important recommended actions"],0]],0,[null,null,null,"https://www.gstatic.com/og/_/js/k=og.qtm.en_US.68822eSqMEc.2019.O/rt=j/m=qdsh/d=1/ed=1/rs=AA2YrTvPl0rdmuQXhRk94MOFFvx26r1YrA"],"18","331",1,0,null,"en",0,["?authuser=$authuser","https://accounts.google.com/AddSession?continue=\u0026ec=GAlAywI","https://accounts.google.com/Logout?continue=https://developers.google.com/\u0026service=ahsid\u0026ec=GAdAywI","https://accounts.google.com/ListAccounts?listPages=0\u0026authuser=0\u0026pid=331\u0026gpsia=1\u0026source=ogb\u0026atic=1\u0026mo=1\u0026mn=1\u0026hl=en",0,0,"",0,0,null,0,0],0,0,0],null,[["mousedown","touchstart","touchmove","wheel","keydown"],300000]]],};this.gbar_=this.gbar_||{};(function(_){var window=this;
try{
/*

 Copyright The Closure Library Authors.
 SPDX-License-Identifier: Apache-2.0
*/
var ja,ya,za,Aa,Ba,Ha,Ja,Ia,La,Ma,Pa,Ta,Qa,Wa,Xa;_.aa=function(a,b){if(Error.captureStackTrace)Error.captureStackTrace(this,_.aa);else{const c=Error().stack;c&&(this.stack=c)}a&&(this.message=String(a));void 0!==b&&(this.cause=b)};_.ba=function(){var a=_.m.navigator;return a&&(a=a.userAgent)?a:""};_.n=function(a){return-1!=_.ba().indexOf(a)};_.ca=function(){return _.n("Opera")};_.da=function(){return _.n("Trident")||_.n("MSIE")};_.ea=function(){return _.n("Firefox")||_.n("FxiOS")};
_.ha=function(){return _.n("Safari")&&!(_.fa()||_.n("Coast")||_.ca()||_.n("Edge")||_.n("Edg/")||_.n("OPR")||_.ea()||_.n("Silk")||_.n("Android"))};_.fa=function(){return(_.n("Chrome")||_.n("CriOS"))&&!_.n("Edge")||_.n("Silk")};_.ia=function(){return _.n("Android")&&!(_.fa()||_.ea()||_.ca()||_.n("Silk"))};ja=function(){return _.n("iPhone")&&!_.n("iPod")&&!_.n("iPad")};_.la=function(){return ja()||_.n("iPad")||_.n("iPod")};
_.ma=function(a){const b=a.length;if(0<b){const c=Array(b);for(let d=0;d<b;d++)c[d]=a[d];return c}return[]};_.na=function(){return-1!=_.ba().toLowerCase().indexOf("webkit")&&!_.n("Edge")};_.pa=function(a){return oa&&null!=a&&a instanceof Uint8Array};_.ra=function(a,b){if(_.qa)return a[_.qa]|=b;if(void 0!==a.Yb)return a.Yb|=b;Object.defineProperties(a,{Yb:{value:b,configurable:!0,writable:!0,enumerable:!1}});return b};
_.ua=function(a,b){const c=_.sa(a);(c&b)!==b&&(Object.isFrozen(a)&&(a=Array.prototype.slice.call(a)),_.ta(a,c|b));return a};_.sa=function(a){let b;_.qa?b=a[_.qa]:b=a.Yb;return null==b?0:b};_.ta=function(a,b){_.qa?a[_.qa]=b:void 0!==a.Yb?a.Yb=b:Object.defineProperties(a,{Yb:{value:b,configurable:!0,writable:!0,enumerable:!1}})};_.va=function(a){_.ra(a,1);return a};_.wa=function(a){return!!(_.sa(a)&2)};_.xa=function(a){_.ra(a,16);return a};ya=function(a,b){_.ta(b,(a|0)&-51)};
za=function(a,b){_.ta(b,(a|18)&-41)};Aa=function(a){return null!==a&&"object"===typeof a&&!Array.isArray(a)&&a.constructor===Object};Ba=function(a){var b=a.length;(b=b?a[b-1]:void 0)&&Aa(b)?b.g=1:a.push({g:1})};_.Ca=function(a,b){return null==a?b:a};_.Ea=function(a,b){Da=b;a=new a(b);Da=void 0;return a};
Ha=function(a){switch(typeof a){case "number":return isFinite(a)?a:String(a);case "object":if(a)if(Array.isArray(a)){if(0!==(_.sa(a)&128))return a=Array.prototype.slice.call(a),Ba(a),a}else{if(_.pa(a))return _.Fa(a);if(a instanceof _.Ga){const b=a.Ea;return null==b?"":"string"===typeof b?b:a.Ea=_.Fa(b)}}}return a};Ja=function(a,b,c,d){if(null!=a){if(Array.isArray(a))a=Ia(a,b,c,void 0!==d);else if(Aa(a)){const e={};for(let f in a)e[f]=Ja(a[f],b,c,d);a=e}else a=b(a,d);return a}};
Ia=function(a,b,c,d){const e=_.sa(a);d=d?!!(e&16):void 0;a=Array.prototype.slice.call(a);for(let f=0;f<a.length;f++)a[f]=Ja(a[f],b,c,d);c(e,a);return a};La=function(a){return a.we===Ka?a.toJSON():Ha(a)};Ma=function(a,b){a&128&&Ba(b)};
Pa=function(a,b,c=za){if(null!=a){if(oa&&a instanceof Uint8Array)return a.length?new _.Ga(new Uint8Array(a),_.Na):_.Oa();if(Array.isArray(a)){const d=_.sa(a);if(d&2)return a;if(b&&!(d&32)&&(d&16||0===d))return _.ta(a,d|2),a;a=Ia(a,Pa,d&4?za:c,!0);b=_.sa(a);b&4&&b&2&&Object.freeze(a);return a}return a.we===Ka?Qa(a):a}};Ta=function(a,b,c,d,e,f,g){(a=a.j&&a.j[c])?(d=_.sa(a),d&2?d=a:(f=_.Ra(a,Qa),za(d,f),Object.freeze(f),d=f),_.Sa(b,c,d,e)):_.r(b,c,Pa(d,f,g),e)};
Qa=function(a){if(_.wa(a.Da))return a;a=_.Ua(a,!0);_.ra(a.Da,2);return a};
_.Ua=function(a,b){var c=a.Da,d=_.xa([]),e=a.constructor.j;e&&d.push(e);e=a.Lb;let f;e&&(d.length=c.length,d.fill(void 0,d.length,c.length),f={},d[d.length-1]=f);0!==(_.sa(c)&128)&&Ba(d);b=b||a.mc()?za:ya;d=_.Ea(a.constructor,d);a.ud&&(d.ud=a.ud.slice());const g=!!(_.sa(c)&16);var h=e?c.length-1:c.length;for(let l=0;l<h;l++)Ta(a,d,l-a.yc,c[l],!1,g,b);if(e)for(const l in e)c=e[l],h=+l,Number.isNaN(h)?f[h]=c:Ta(a,d,h,c,!0,g,b);return d};
_.Va=function(a){if(!_.wa(a.Da))return a;const b=_.Ua(a,!1);b.A=a;return b};Wa=function(a,b){if(Array.isArray(a)){var c=_.sa(a),d=1;!b||c&2||(d|=16);(c&d)!==d&&_.ta(a,c|d)}};Xa=function(a,b){return Ha(b)};_.t=function(a,b){return null!=a?!!a:!!b};_.v=function(a,b){void 0==b&&(b="");return null!=a?a:b};_.Ya=function(a,b){void 0==b&&(b=0);return null!=a?a:b};_.Za=function(a,b,c){for(const d in a)b.call(c,a[d],d,a)};
_.ab=function(a,b){let c,d;for(let e=1;e<arguments.length;e++){d=arguments[e];for(c in d)a[c]=d[c];for(let f=0;f<$a.length;f++)c=$a[f],Object.prototype.hasOwnProperty.call(d,c)&&(a[c]=d[c])}};var eb,fb,gb;_.bb=_.bb||{};_.m=this||self;_.cb=function(a){var b=typeof a;return"object"==b&&null!=a||"function"==b};_.db="closure_uid_"+(1E9*Math.random()>>>0);eb=function(a,b,c){return a.call.apply(a.bind,arguments)};fb=function(a,b,c){if(!a)throw Error();if(2<arguments.length){var d=Array.prototype.slice.call(arguments,2);return function(){var e=Array.prototype.slice.call(arguments);Array.prototype.unshift.apply(e,d);return a.apply(b,e)}}return function(){return a.apply(b,arguments)}};
_.x=function(a,b,c){Function.prototype.bind&&-1!=Function.prototype.bind.toString().indexOf("native code")?_.x=eb:_.x=fb;return _.x.apply(null,arguments)};_.y=function(a,b){a=a.split(".");var c=_.m;a[0]in c||"undefined"==typeof c.execScript||c.execScript("var "+a[0]);for(var d;a.length&&(d=a.shift());)a.length||void 0===b?c[d]&&c[d]!==Object.prototype[d]?c=c[d]:c=c[d]={}:c[d]=b};
_.z=function(a,b){function c(){}c.prototype=b.prototype;a.Z=b.prototype;a.prototype=new c;a.prototype.constructor=a;a.xi=function(d,e,f){for(var g=Array(arguments.length-2),h=2;h<arguments.length;h++)g[h-2]=arguments[h];return b.prototype[e].apply(d,g)}};gb=function(a){return a};_.hb=function(a){var b=null,c=_.m.trustedTypes;if(!c||!c.createPolicy)return b;try{b=c.createPolicy(a,{createHTML:gb,createScript:gb,createScriptURL:gb})}catch(d){_.m.console&&_.m.console.error(d.message)}return b};_.z(_.aa,Error);_.aa.prototype.name="CustomError";_.ib=String.prototype.trim?function(a){return a.trim()}:function(a){return/^[\s\xa0]*([\s\S]*?)[\s\xa0]*$/.exec(a)[1]};_.jb=function(a,b){return Array.prototype.indexOf.call(a,b,void 0)};_.kb=function(a,b,c){Array.prototype.forEach.call(a,b,c)};_.Ra=function(a,b,c){return Array.prototype.map.call(a,b,c)};_.lb=function(a){_.lb[" "](a);return a};_.lb[" "]=function(){};var zb,Ab,Fb;_.mb=_.ca();_.A=_.da();_.nb=_.n("Edge");_.ob=_.nb||_.A;_.pb=_.n("Gecko")&&!_.na()&&!(_.n("Trident")||_.n("MSIE"))&&!_.n("Edge");_.qb=_.na();_.rb=_.n("Macintosh");_.sb=_.n("Windows");_.tb=_.n("Linux")||_.n("CrOS");_.ub=_.n("Android");_.vb=ja();_.wb=_.n("iPad");_.xb=_.n("iPod");_.yb=_.la();zb=function(){var a=_.m.document;return a?a.documentMode:void 0};
a:{var Bb="",Cb=function(){var a=_.ba();if(_.pb)return/rv:([^\);]+)(\)|;)/.exec(a);if(_.nb)return/Edge\/([\d\.]+)/.exec(a);if(_.A)return/\b(?:MSIE|rv)[: ]([^\);]+)(\)|;)/.exec(a);if(_.qb)return/WebKit\/(\S+)/.exec(a);if(_.mb)return/(?:Version)[ \/]?(\S+)/.exec(a)}();Cb&&(Bb=Cb?Cb[1]:"");if(_.A){var Db=zb();if(null!=Db&&Db>parseFloat(Bb)){Ab=String(Db);break a}}Ab=Bb}_.Eb=Ab;if(_.m.document&&_.A){var Gb=zb();Fb=Gb?Gb:parseInt(_.Eb,10)||void 0}else Fb=void 0;_.Hb=Fb;_.Ib=_.ea();_.Jb=ja()||_.n("iPod");_.Kb=_.n("iPad");_.Lb=_.ia();_.Mb=_.fa();_.Nb=_.ha()&&!_.la();var Ob;Ob={};_.Pb=null;_.Fa=function(a,b){void 0===b&&(b=0);_.Qb();b=Ob[b];const c=Array(Math.floor(a.length/3)),d=b[64]||"";let e=0,f=0;for(;e<a.length-2;e+=3){var g=a[e],h=a[e+1],l=a[e+2],p=b[g>>2];g=b[(g&3)<<4|h>>4];h=b[(h&15)<<2|l>>6];l=b[l&63];c[f++]=p+g+h+l}p=0;l=d;switch(a.length-e){case 2:p=a[e+1],l=b[(p&15)<<2]||d;case 1:a=a[e],c[f]=b[a>>2]+b[(a&3)<<4|p>>4]+l+d}return c.join("")};
_.Qb=function(){if(!_.Pb){_.Pb={};for(var a="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789".split(""),b=["+/=","+/","-_=","-_.","-_"],c=0;5>c;c++){var d=a.concat(b[c].split(""));Ob[c]=d;for(var e=0;e<d.length;e++){var f=d[e];void 0===_.Pb[f]&&(_.Pb[f]=e)}}}};var oa;oa="undefined"!==typeof Uint8Array;_.Na={};_.Rb="undefined"!==typeof TextDecoder;_.Sb="undefined"!==typeof TextEncoder;var Tb;_.Oa=function(){return Tb||(Tb=new _.Ga(null,_.Na))};_.Ga=class{constructor(a,b){if(b!==_.Na)throw Error("m");this.Ea=a;if(null!=a&&0===a.length)throw Error("n");}lc(){return null==this.Ea}};_.qa=Symbol();var Ka,Ub,Wb;Ka={};Wb=[];_.ta(Wb,23);_.Vb=Object.freeze(Wb);_.Xb=function(a){if(_.wa(a.Da))throw Error("p");};var Yb;Yb=function(a){const b=a.o+a.yc;return a.Lb||(a.Lb=a.Da[b]={})};_.C=function(a,b,c){return-1===b?null:b>=a.o?a.Lb?a.Lb[b]:void 0:c&&a.Lb&&(c=a.Lb[b],null!=c)?c:a.Da[b+a.yc]};_.r=function(a,b,c,d){_.Xb(a);return _.Zb(a,b,c,d)};_.Zb=function(a,b,c,d){a.A&&(a.A=void 0);if(b>=a.o||d)return Yb(a)[b]=c,a;a.Da[b+a.yc]=c;(c=a.Lb)&&b in c&&delete c[b];return a};_.E=function(a,b){a=_.C(a,b);return null==a?a:!!a};
_.$b=function(a,b,c,d){const e=_.C(a,c,d);{let g=!1;var f=null==e||"object"!==typeof e||(g=Array.isArray(e))||e.we!==Ka?g?new b(e):void 0:e}f!==e&&null!=f&&(_.Zb(a,c,f,d),_.ra(f.Da,_.sa(a.Da)&18));return f};_.F=function(a,b,c,d=!1){b=_.$b(a,b,c,d);if(null==b)return b;if(!_.wa(a.Da)){const e=_.Va(b);e!==b&&(b=e,_.Zb(a,c,b,d))}return b};_.G=function(a,b,c){_.Xb(a);null==c&&(c=void 0);return _.Zb(a,b,c)};
_.Sa=function(a,b,c,d){_.Xb(a);let e=null==c?_.Vb:_.va([]);if(null!=c){let f=!!c.length;for(let g=0;g<c.length;g++){const h=c[g];f=f&&!_.wa(h.Da);e[g]=h.Da}e=_.ua(e,(f?8:0)|1);a.j||(a.j={});a.j[b]=c}else a.j&&(a.j[b]=void 0);return _.Zb(a,b,e,d)};_.ac=function(a,b,c=0){a=_.C(a,b);return null==a?c:a};_.bc=function(a,b,c=0){const d=_.C(a,b);var e=null==d?d:"number"===typeof d||"NaN"===d||"Infinity"===d||"-Infinity"===d?Number(d):void 0;null!=e&&e!==d&&_.Zb(a,b,e);return _.Ca(e,c)};var Da;_.H=class{constructor(a,b,c){null==a&&(a=Da);Da=void 0;var d=this.constructor.o||0,e=0<d,f=this.constructor.j,g=!1;if(null==a){a=f?[f]:[];var h=48;var l=!0;e&&(d=0,h|=128);_.ta(a,h)}else{if(!Array.isArray(a))throw Error();if(f&&f!==a[0])throw Error();let p=h=_.ra(a,0);if(l=0!==(16&p))(g=0!==(32&p))||(p|=32);if(e)if(128&p)d=0;else{if(0<a.length){const q=a[a.length-1];if(Aa(q)&&"g"in q){d=0;p|=128;delete q.g;let u=!0;for(let B in q){u=!1;break}u&&a.pop()}}}else if(128&p)throw Error();h!==p&&_.ta(a,
p)}this.yc=(f?0:-1)-d;this.j=void 0;this.Da=a;a:{f=this.Da.length;d=f-1;if(f&&(f=this.Da[d],Aa(f))){this.Lb=f;this.o=d-this.yc;break a}void 0!==b&&-1<b?(this.o=Math.max(b,d+1-this.yc),this.Lb=void 0):this.o=Number.MAX_VALUE}if(!e&&this.Lb&&"g"in this.Lb)throw Error("u");if(c){b=l&&!g&&!0;e=this.o;let p;for(l=0;l<c.length;l++)g=c[l],g<e?(g+=this.yc,(d=a[g])?Wa(d,b):a[g]=_.Vb):(p||(p=Yb(this)),(d=p[g])?Wa(d,b):p[g]=_.Vb)}}toJSON(){const a=this.Da;return Ub?a:Ia(a,La,Ma)}Ha(){Ub=!0;try{return JSON.stringify(this.toJSON(),
Xa)}finally{Ub=!1}}mc(){return _.wa(this.Da)}};_.H.prototype.we=Ka;_.H.prototype.toString=function(){return this.Da.toString()};_.cc=Symbol();_.dc=Symbol();_.ec=Symbol();_.fc=Symbol();var gc=class extends _.H{constructor(){super()}};_.hc=class extends _.H{constructor(){super()}Vc(a){return _.r(this,3,a)}};_.ic=class extends _.H{constructor(a){super(a)}};var jc=class extends _.H{constructor(a){super(a)}};_.kc=class extends _.H{constructor(a){super(a)}Wc(a){return _.r(this,24,a)}};_.lc=class extends _.H{constructor(a){super(a)}};_.I=function(){this.Fb=this.Fb;this.Oa=this.Oa};_.I.prototype.Fb=!1;_.I.prototype.isDisposed=function(){return this.Fb};_.I.prototype.ya=function(){this.Fb||(this.Fb=!0,this.R())};_.I.prototype.R=function(){if(this.Oa)for(;this.Oa.length;)this.Oa.shift()()};var mc=class extends _.I{constructor(){var a=window;super();this.A=a;this.j=[];this.o={}}resolve(a){var b=this.A;a=a.split(".");for(var c=a.length,d=0;d<c;++d)if(b[a[d]])b=b[a[d]];else return null;return b instanceof Function?b:null}md(){for(var a=this.j.length,b=this.j,c=[],d=0;d<a;++d){var e=b[d].j(),f=this.resolve(e);if(f&&f!=this.o[e])try{b[d].md(f)}catch(g){}else c.push(b[d])}this.j=c.concat(b.slice(a))}};var oc=class extends _.I{constructor(){var a=_.nc;super();this.A=a;this.C=this.j=null;this.B=0;this.D={};this.o=!1;a=window.navigator.userAgent;0<=a.indexOf("MSIE")&&0<=a.indexOf("Trident")&&(a=/\b(?:MSIE|rv)[: ]([^\);]+)(\)|;)/.exec(a))&&a[1]&&9>parseFloat(a[1])&&(this.o=!0)}F(a,b){this.j=b;this.C=a;b.preventDefault?b.preventDefault():b.returnValue=!1}};_.pc=class extends _.H{constructor(a){super(a)}};_.qc=class extends _.H{constructor(a){super(a)}};_.rc=class{constructor(){this.data={}}Ha(a){var b=[],c;for(c in this.data)b.push(encodeURIComponent(c)+"="+encodeURIComponent(String(this.data[c])));return("atyp=i&zx="+(new Date).getTime()+"&"+b.join("&")).substr(0,a)}};var sc=class extends _.rc{constructor(a,b){super();var c=_.F(a,jc,8)||new jc;window.google&&window.google.kEI&&(this.data.ei=window.google.kEI);this.data.sei=_.v(_.C(a,10));this.data.ogf=_.v(_.C(c,3));this.data.ogrp=(window.google&&window.google.sn?!/.*hp$/.test(window.google.sn):_.t(_.E(a,7)))?"1":"";this.data.ogv=_.v(_.C(c,6))+"."+_.v(_.C(c,7));this.data.ogd=_.v(_.C(a,21));this.data.ogc=_.v(_.C(a,20));this.data.ogl=_.v(_.C(a,5));b&&(this.data.oggv=b)}};var $a="constructor hasOwnProperty isPrototypeOf propertyIsEnumerable toLocaleString toString valueOf".split(" ");_.tc=class extends sc{constructor(a,b,c,d,e){super(a,b);_.ab(this.data,{jexpid:_.v(_.C(a,9)),srcpg:"prop="+_.v(_.C(a,6)),jsr:Math.round(1/d),emsg:c.name+":"+c.message});if(e){e._sn&&(e._sn="og."+e._sn);for(const f in e)this.data[encodeURIComponent(f)]=e[f]}}};var uc;_.vc=function(){void 0===uc&&(uc=_.hb("ogb-qtm#html"));return uc};_.yc=function(a,b){this.j=a===_.wc&&b||"";this.o=_.xc};_.yc.prototype.Xb=!0;_.yc.prototype.Hb=function(){return this.j};_.xc={};_.wc={};_.Ac=class{constructor(a,b){this.j=b===_.zc?a:""}toString(){return this.j+""}};_.Ac.prototype.Xb=!0;_.Ac.prototype.Hb=function(){return this.j.toString()};_.Cc=function(a){return _.Bc(a).toString()};_.Bc=function(a){return a instanceof _.Ac&&a.constructor===_.Ac?a.j:"type_error:TrustedResourceUrl"};_.zc={};var Gc,Hc,Dc;_.Ec=class{constructor(a,b){this.j=b===Dc?a:""}toString(){return this.j.toString()}};_.Ec.prototype.Xb=!0;_.Ec.prototype.Hb=function(){return this.j.toString()};_.Fc=function(a){return a instanceof _.Ec&&a.constructor===_.Ec?a.j:"type_error:SafeUrl"};Gc=/^data:(.*);base64,[a-z0-9+\/]+=*$/i;Hc=/^(?:(?:https?|mailto|ftp):|[^:/?#]*(?:[/?#]|$))/i;
_.Jc=function(a){if(a instanceof _.Ec)return a;a="object"==typeof a&&a.Xb?a.Hb():String(a);Hc.test(a)?a=_.Ic(a):(a=String(a).replace(/(%0A|%0D)/g,""),a=a.match(Gc)?_.Ic(a):null);return a};_.Kc=function(a){if(a instanceof _.Ec)return a;a="object"==typeof a&&a.Xb?a.Hb():String(a);Hc.test(a)||(a="about:invalid#zClosurez");return _.Ic(a)};Dc={};_.Ic=function(a){return new _.Ec(a,Dc)};_.Lc=_.Ic("about:invalid#zClosurez");_.Mc={};_.Nc=class{constructor(a,b){this.j=b===_.Mc?a:"";this.Xb=!0}Hb(){return this.j}toString(){return this.j.toString()}};_.Pc=new _.Nc("",_.Mc);_.Qc=RegExp("^[-+,.\"'%_!#/ a-zA-Z0-9\\[\\]]+$");_.Rc=RegExp("\\b(url\\([ \t\n]*)('[ -&(-\\[\\]-~]*'|\"[ !#-\\[\\]-~]*\"|[!#-&*-\\[\\]-~]*)([ \t\n]*\\))","g");
_.Sc=RegExp("\\b(calc|cubic-bezier|fit-content|hsl|hsla|linear-gradient|matrix|minmax|radial-gradient|repeat|rgb|rgba|(rotate|scale|translate)(X|Y|Z|3d)?|steps|var)\\([-+*/0-9a-zA-Z.%#\\[\\], ]+\\)","g");var Tc;Tc={};_.Vc=function(a){return a instanceof _.Uc&&a.constructor===_.Uc?a.j:"type_error:SafeHtml"};_.Wc=function(a){const b=_.vc();a=b?b.createHTML(a):a;return new _.Uc(a,Tc)};_.Uc=class{constructor(a,b){this.j=b===Tc?a:"";this.Xb=!0}Hb(){return this.j.toString()}toString(){return this.j.toString()}};_.Xc=new _.Uc(_.m.trustedTypes&&_.m.trustedTypes.emptyHTML||"",Tc);_.Yc=_.Wc("<br>");var $c;_.Zc=function(a){let b=!1,c;return function(){b||(c=a(),b=!0);return c}}(function(){var a=document.createElement("div"),b=document.createElement("div");b.appendChild(document.createElement("div"));a.appendChild(b);b=a.firstChild.firstChild;a.innerHTML=_.Vc(_.Xc);return!b.parentElement});$c=/^[\w+/_-]+[=]{0,2}$/;
_.ad=function(a){a=(a||_.m).document;return a.querySelector?(a=a.querySelector('style[nonce],link[rel="stylesheet"][nonce]'))&&(a=a.nonce||a.getAttribute("nonce"))&&$c.test(a)?a:"":""};_.bd=RegExp("^\\s{3,4}at(?: (?:(.*?)\\.)?((?:new )?(?:[a-zA-Z_$][\\w$]*|<anonymous>))(?: \\[as ([a-zA-Z_$][\\w$]*)\\])?)? (?:\\(unknown source\\)|\\(native\\)|\\((?:eval at )?((?:http|https|file)://[^\\s)]+|javascript:.*)\\)|((?:http|https|file)://[^\\s)]+|javascript:.*))$");_.cd=RegExp("^(?:(.*?)\\.)?([a-zA-Z_$][\\w$]*(?:/.?<)?)?(\\(.*\\))?@(?::0|((?:http|https|file)://[^\\s)]+|javascript:.*))$");var dd,gd,fd;_.ed=function(a){let b;b=window.google&&window.google.logUrl?"":"https://www.google.com";b+="/gen_204?use_corp=on&";b+=a.Ha(2040-b.length);dd(_.Jc(b)||_.Lc)};dd=function(a){var b=new Image,c=fd;b.onerror=b.onload=b.onabort=function(){c in gd&&delete gd[c]};gd[fd++]=b;b.src=_.Fc(a)};gd=[];fd=0;_.hd=class extends _.H{constructor(a){super(a)}};_.id=a=>{var b="Ec";if(a.Ec&&a.hasOwnProperty(b))return a.Ec;b=new a;return a.Ec=b};var pd,ld,nd;_.md=function(a,b){var c=_.jd.j();if(a in c.j){if(c.j[a]!=b)throw new ld;}else{c.j[a]=b;if(b=c.o[a])for(let d=0,e=b.length;d<e;d++)b[d].j(c.j,a);delete c.o[a]}};_.od=function(a,b){if(b in a.j)return a.j[b];throw new nd;};_.jd=class{constructor(){this.j={};this.o={}}static j(){return _.id(_.jd)}};pd=class extends _.aa{constructor(){super()}};ld=class extends pd{};nd=class extends pd{};var sd=class{constructor(){var a=qd;this.C=rd;this.o=_.Ya(_.bc(a,2,.001),.001);this.D=_.t(_.E(a,1))&&Math.random()<this.o;this.F=_.Ya(_.ac(a,3,1),1);this.B=0;this.j=this.A=null}log(a,b){if(this.j){const d=new gc;_.r(d,1,a.message);_.r(d,2,a.stack);_.r(d,3,a.lineNumber);_.r(d,5,1);const e=new _.hc;_.G(e,40,d);this.j.log(98,e)}try{if(this.D&&this.B<this.F){try{var c=(this.A||_.od(_.jd.j(),"lm")).B(a,b)}catch(d){c=new _.tc(this.C,"quantum:gapiBuildLabel",a,this.o,b)}_.ed(c);this.B++}}catch(d){}}};var td=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,42,43,48,49,50,51,52,53,62,500],vd=function(a){if(!ud){ud={};for(var b=0;b<td.length;b++)ud[td[b]]=!0}return!!ud[a]},wd=function(a){a=String(a);return a.replace(".","%2E").replace(",","%2C")},xd=class extends sc{constructor(a,b,c,d,e){super(a,"quantum:gapiBuildLabel");_.ab(this.data,{oge:c,ogex:_.v(_.C(a,9)),ogp:_.v(_.C(a,6)),ogsr:Math.round(1/(vd(c)?_.Ya(_.bc(b,3,1)):_.Ya(_.bc(b,2,1E-4)))),ogus:d});if(e){"ogw"in e&&(this.data.ogw=e.ogw,
delete e.ogw);"ved"in e&&(this.data.ved=e.ved,delete e.ved);a=[];for(var f in e)0!=a.length&&a.push(","),a.push(wd(f)),a.push("."),a.push(wd(e[f]));e=a.join("");""!=e&&(this.data.ogad=e)}}},ud=null;var yd=class extends _.H{constructor(a){super(a)}};var Cd=class{constructor(){var a=zd,b=Ad,c=Bd;this.o=a;this.j=b;this.B=_.Ya(_.bc(a,2,1E-4),1E-4);this.D=_.Ya(_.bc(a,3,1),1);b=Math.random();this.A=_.t(_.E(a,1))&&b<this.B;this.C=_.t(_.E(a,1))&&b<this.D;a=0;_.t(_.E(c,1))&&(a|=1);_.t(_.E(c,2))&&(a|=2);_.t(_.E(c,3))&&(a|=4);this.F=a}log(a,b){try{if(vd(a)?this.C:this.A){var c=new xd(this.j,this.o,a,this.F,b);_.ed(c)}}catch(d){}}};var Ed;_.Dd=function(a){if(0<a.o.length){var b=void 0!==a.Ea,c=void 0!==a.j;if(b||c){b=b?a.A:a.B;c=a.o;a.o=[];try{_.kb(c,b,a)}catch(d){console.error(d)}}}};_.Fd=class{constructor(a){this.Ea=a;this.j=void 0;this.o=[]}then(a,b,c){this.o.push(new Ed(a,b,c));_.Dd(this)}resolve(a){if(void 0!==this.Ea||void 0!==this.j)throw Error("C");this.Ea=a;_.Dd(this)}A(a){a.o&&a.o.call(a.j,this.Ea)}B(a){a.A&&a.A.call(a.j,this.j)}};Ed=class{constructor(a,b,c){this.o=a;this.A=b;this.j=c}};_.J=class{constructor(){this.B=new _.Fd;this.j=new _.Fd;this.G=new _.Fd;this.D=new _.Fd;this.F=new _.Fd;this.H=new _.Fd;this.C=new _.Fd;this.A=new _.Fd;this.o=new _.Fd;this.J=new _.Fd}N(){return this.B}T(){return this.j}Fb(){return this.G}Oa(){return this.D}S(){return this.F}O(){return this.H}P(){return this.C}M(){return this.A}L(){return this.o}static j(){return _.id(_.J)}};var Kd;_.Hd=function(){return _.F(_.Gd,_.kc,1)};_.Id=function(){return _.F(_.Gd,_.lc,5)};Kd=class extends _.H{constructor(){super(Jd)}};var Jd;window.gbar_&&window.gbar_.CONFIG?Jd=window.gbar_.CONFIG[0]||{}:Jd=[];_.Gd=new Kd;var qd,rd,Ad,Bd,zd;qd=_.F(_.Gd,_.hd,3)||new _.hd;rd=_.Hd()||new _.kc;_.nc=new sd;Ad=_.Hd()||new _.kc;Bd=_.Id()||new _.lc;zd=_.F(_.Gd,yd,4)||new yd;_.Ld=new Cd;_.y("gbar_._DumpException",function(a){_.nc?_.nc.log(a):console.error(a)});_.Md=new oc;_.Ld.log(8,{m:"BackCompat"==document.compatMode?"q":"s"});_.y("gbar.A",_.Fd);_.Fd.prototype.aa=_.Fd.prototype.then;_.y("gbar.B",_.J);_.J.prototype.ba=_.J.prototype.T;_.J.prototype.bb=_.J.prototype.Fb;_.J.prototype.bd=_.J.prototype.S;_.J.prototype.bf=_.J.prototype.N;_.J.prototype.bg=_.J.prototype.Oa;_.J.prototype.bh=_.J.prototype.O;_.J.prototype.bi=_.J.prototype.P;_.J.prototype.bj=_.J.prototype.M;_.J.prototype.bk=_.J.prototype.L;_.y("gbar.a",_.J.j());var Nd=new mc;_.md("api",Nd);var Od=_.Id()||new _.lc;
window.__PVT=_.v(_.C(Od,8));_.md("eq",_.Md);
}catch(e){_._DumpException(e)}
try{
var Pd=class extends _.H{constructor(){super()}};var Qd=class extends _.I{constructor(){super();this.o=[];this.j=[]}A(a,b){this.o.push({features:a,options:b})}init(a,b,c){window.gapi={};var d=window.___jsl={};d.h=_.v(_.C(a,1));null!=_.C(a,12,!1)&&(d.dpo=_.t(_.E(a,12)));d.ms=_.v(_.C(a,2));d.m=_.v(_.C(a,3));d.l=[];_.C(b,1)&&(a=_.C(b,3))&&this.j.push(a);_.C(c,1)&&(c=_.C(c,2))&&this.j.push(c);_.y("gapi.load",(0,_.x)(this.A,this));return this}};var Rd=_.F(_.Gd,_.pc,14)||new _.pc,Sd=_.F(_.Gd,_.qc,9)||new _.qc,Td=new Pd,Ud=new Qd;Ud.init(Rd,Sd,Td);_.md("gs",Ud);
}catch(e){_._DumpException(e)}
})(this.gbar_);
// Google Inc.
</script><script id="ogb-head-script2">this.gbar_=this.gbar_||{};(function(_){var window=this;
try{
_.Vd=function(a,b,c){if(!a.o)if(c instanceof Array)for(var d of c)_.Vd(a,b,d);else{d=(0,_.x)(a.F,a,b);const e=a.B+c;a.B++;b.setAttribute("data-eqid",e);a.D[e]=d;b&&b.addEventListener?b.addEventListener(c,d,!1):b&&b.attachEvent?b.attachEvent("on"+c,d):a.A.log(Error("x`"+b))}};
}catch(e){_._DumpException(e)}
try{
_.Wd=function(){if(!_.m.addEventListener||!Object.defineProperty)return!1;var a=!1,b=Object.defineProperty({},"passive",{get:function(){a=!0}});try{_.m.addEventListener("test",()=>{},b),_.m.removeEventListener("test",()=>{},b)}catch(c){}return a}();_.Xd=_.qb?"webkitTransitionEnd":"transitionend";
}catch(e){_._DumpException(e)}
try{
var Yd=document.querySelector(".gb_J .gb_e"),Zd=document.querySelector("#gb.gb_Nc");Yd&&!Zd&&_.Vd(_.Md,Yd,"click");
}catch(e){_._DumpException(e)}
try{
var Nh;_.Mh=function(a){if(a.B)return a.B;for(const b in a.j)if(a.j[b].wb()&&a.j[b].G())return a.j[b];return null};
Nh=new class extends _.I{constructor(){var a=_.nc;super();this.J=a;this.B=null;this.o={};this.M={};this.j={};this.F=null}D(a){a&&_.Mh(this)&&a!=_.Mh(this)&&_.Mh(this).ua(!1);this.B=a}G(a){a=this.j[a]||a;return _.Mh(this)==a}A(a,b){b=b.S();if(this.o[a]&&this.o[a][b])for(let c=0;c<this.o[a][b].length;c++)try{this.o[a][b][c]()}catch(d){this.J.log(d)}}L(a){return!this.M[a.S()]}H(a){this.j[a]&&(_.Mh(this)&&_.Mh(this).S()==a||this.j[a].ua(!0))}Za(a){this.F=a;for(const b in this.j)this.j[b].wb()&&this.j[b].Za(a)}C(a){this.j[a.S()]=
a}Ac(a){return a in this.j?this.j[a]:null}};_.md("dd",Nh);
}catch(e){_._DumpException(e)}
try{
var lj=document.querySelector(".gb_b .gb_e"),mj=document.querySelector("#gb.gb_Nc");lj&&!mj&&_.Vd(_.Md,lj,"click");
}catch(e){_._DumpException(e)}
})(this.gbar_);
// Google Inc.
</script><script id="ogb-head-script3">this.gbar_=this.gbar_||{};(function(_){var window=this;
try{
_.$d=function(a,b){return 0<=_.jb(a,b)};_.ae=function(a){var b=typeof a;return"object"!=b?b:a?Array.isArray(a)?"array":b:"null"};_.be=function(a){var b=_.ae(a);return"array"==b||"object"==b&&"number"==typeof a.length};_.ce=function(a,b){var c=Array.prototype.slice.call(arguments,1);return function(){var d=c.slice();d.push.apply(d,arguments);return a.apply(this,d)}};try{(new self.OffscreenCanvas(0,0)).getContext("2d")}catch(a){}_.de=_.A||_.qb;_.ee=function(a,b){this.width=a;this.height=b};_.k=_.ee.prototype;_.k.aspectRatio=function(){return this.width/this.height};_.k.lc=function(){return!(this.width*this.height)};_.k.ceil=function(){this.width=Math.ceil(this.width);this.height=Math.ceil(this.height);return this};_.k.floor=function(){this.width=Math.floor(this.width);this.height=Math.floor(this.height);return this};_.k.round=function(){this.width=Math.round(this.width);this.height=Math.round(this.height);return this};var ge,je;_.fe=function(a,b){return(b||document).getElementsByTagName(String(a))};_.he=function(a,b){_.Za(b,function(c,d){c&&"object"==typeof c&&c.Xb&&(c=c.Hb());"style"==d?a.style.cssText=c:"class"==d?a.className=c:"for"==d?a.htmlFor=c:ge.hasOwnProperty(d)?a.setAttribute(ge[d],c):0==d.lastIndexOf("aria-",0)||0==d.lastIndexOf("data-",0)?a.setAttribute(d,c):a[d]=c})};
ge={cellpadding:"cellPadding",cellspacing:"cellSpacing",colspan:"colSpan",frameborder:"frameBorder",height:"height",maxlength:"maxLength",nonce:"nonce",role:"role",rowspan:"rowSpan",type:"type",usemap:"useMap",valign:"vAlign",width:"width"};_.ke=function(a,b){var c=b[1],d=_.ie(a,String(b[0]));c&&("string"===typeof c?d.className=c:Array.isArray(c)?d.className=c.join(" "):_.he(d,c));2<b.length&&je(a,d,b);return d};
je=function(a,b,c){function d(h){h&&b.appendChild("string"===typeof h?a.createTextNode(h):h)}for(var e=2;e<c.length;e++){var f=c[e];if(!_.be(f)||_.cb(f)&&0<f.nodeType)d(f);else{a:{if(f&&"number"==typeof f.length){if(_.cb(f)){var g="function"==typeof f.item||"string"==typeof f.item;break a}if("function"===typeof f){g="function"==typeof f.item;break a}}g=!1}_.kb(g?_.ma(f):f,d)}}};_.le=function(a){return _.ie(document,a)};
_.ie=function(a,b){b=String(b);"application/xhtml+xml"===a.contentType&&(b=b.toLowerCase());return a.createElement(b)};_.me=function(a){for(var b;b=a.firstChild;)a.removeChild(b)};_.ne=function(a){return _.cb(a)&&1==a.nodeType};_.oe=function(a){return 9==a.nodeType?a:a.ownerDocument||a.document};_.pe=function(a,b){for(var c=0;a;){if(b(a))return a;a=a.parentNode;c++}return null};
}catch(e){_._DumpException(e)}
try{
var Fe;_.Ce=function(a){return/^[\s\xa0]*$/.test(a)};_.De=function(a,b){if(void 0!==a.Ea||void 0!==a.j)throw Error("C");a.j=b;_.Dd(a)};_.Ee=class extends _.H{constructor(a){super(a)}};Fe=0;_.Ge=function(a){return Object.prototype.hasOwnProperty.call(a,_.db)&&a[_.db]||(a[_.db]=++Fe)};_.He=function(a){return _.od(_.jd.j(),a)};
}catch(e){_._DumpException(e)}
try{
_.qj=function(a,b,c){a.rel=c;-1!=c.toLowerCase().indexOf("stylesheet")?(a.href=_.Cc(b),(b=_.ad(a.ownerDocument&&a.ownerDocument.defaultView))&&a.setAttribute("nonce",b)):a.href=b instanceof _.Ac?_.Cc(b):b instanceof _.Ec?_.Fc(b):_.Fc(_.Kc(b))};
}catch(e){_._DumpException(e)}
try{
_.rj=function(a){const b=_.vc();a=b?b.createScriptURL(a):a;return new _.Ac(a,_.zc)};/*

 SPDX-License-Identifier: Apache-2.0
*/
var sj;try{new URL("s://g"),sj=!0}catch(a){sj=!1}_.tj=sj;
}catch(e){_._DumpException(e)}
try{
_.uj=function(a){var b;let c;const d=null==(c=(b=(a.ownerDocument&&a.ownerDocument.defaultView||window).document).querySelector)?void 0:c.call(b,"script[nonce]");(b=d?d.nonce||d.getAttribute("nonce")||"":"")&&a.setAttribute("nonce",b)};
}catch(e){_._DumpException(e)}
try{
var vj=function(a,b,c){_.Ld.log(46,{att:a,max:b,url:c})},xj=function(a,b,c){_.Ld.log(47,{att:a,max:b,url:c});a<b?wj(a+1,b):_.nc.log(Error("aa`"+a+"`"+b),{url:c})},wj=function(a,b){if(yj){const d=_.le("SCRIPT");d.async=!0;d.type="text/javascript";d.charset="UTF-8";var c=d;c.src=_.Bc(yj);_.uj(c);d.onload=_.ce(vj,a,b,d.src);d.onerror=_.ce(xj,a,b,d.src);_.Ld.log(45,{att:a,max:b,url:d.src});_.fe("HEAD")[0].appendChild(d)}},zj=class extends _.H{constructor(a){super(a)}},Aj=_.F(_.Gd,zj,17)||new zj,Bj,yj=
(Bj=_.F(Aj,_.ic,1))?_.rj(_.C(Bj,4)||""):null,Cj,Dj=(Cj=_.F(Aj,_.ic,2))?_.rj(_.C(Cj,4)||""):null,Ej=function(){wj(1,2);if(Dj){const a=_.le("LINK");a.setAttribute("type","text/css");_.qj(a,Dj,"stylesheet");let b=_.ad();b&&a.setAttribute("nonce",b);_.fe("HEAD")[0].appendChild(a)}};(function(){const a=_.Hd();if(_.E(a,18))Ej();else{const b=_.C(a,19)||0;window.addEventListener("load",()=>{window.setTimeout(Ej,b)})}})();
}catch(e){_._DumpException(e)}
})(this.gbar_);
// Google Inc.
</script><script async="" type="text/javascript" charset="UTF-8" src="./ML_Glossary_files/rs=AA2YrTvPl0rdmuQXhRk94MOFFvx26r1YrA" nonce=""></script><link type="text/css" rel="stylesheet" href="./ML_Glossary_files/rs=AA2YrTvz7ig2_pXD7E6HPsesgafZ3WrM_Q"><script src="./ML_Glossary_files/devsite_devsite_dropdown_list_module.js.download" nonce=""></script><script src="./ML_Glossary_files/devsite_devsite_checkbox_module.js.download" nonce=""></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover, .MJXp-munder {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > *, .MJXp-munder > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><script type="text/javascript" charset="UTF-8" nonce="" src="./ML_Glossary_files/api.js.download" gapi_processed="true"></script><style type="text/css">.MathJax_SVG_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax_SVG .MJX-monospace {font-family: monospace}
.MathJax_SVG .MJX-sans-serif {font-family: sans-serif}
#MathJax_SVG_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax_SVG {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax_SVG * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_SVG > div {display: inline-block}
.mjx-svg-href {fill: blue; stroke: blue}
.MathJax_SVG_Processing {visibility: hidden; position: absolute; top: 0; left: 0; width: 0; height: 0; overflow: hidden; display: block!important}
.MathJax_SVG_Processed {display: none!important}
.MathJax_SVG_test {font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow: hidden; height: 1px}
.MathJax_SVG_test.mjx-test-display {display: table!important}
.MathJax_SVG_test.mjx-test-inline {display: inline!important; margin-right: -1px}
.MathJax_SVG_test.mjx-test-default {display: block!important; clear: both}
.MathJax_SVG_ex_box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .MathJax_SVG_left_box {display: inline-block; width: 0; float: left}
.mjx-test-inline .MathJax_SVG_right_box {display: inline-block; width: 0; float: right}
.mjx-test-display .MathJax_SVG_right_box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MathJax_SVG .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style></head>
  <body class="" template="page" theme="white" type="article" layout="docs" data-new-gr-c-s-check-loaded="14.1093.0" data-gr-ext-installed="" style="--devsite-js-header-height:48.8px; --devsite-panel-height:0px;" ready="" signed-in=""><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_SVG_Hidden"><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br></div><svg><defs id="MathJax_SVG_glyphs"><path stroke-width="1" id="MJMAIN-41" d="M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z"></path><path stroke-width="1" id="MJMAIN-63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path stroke-width="1" id="MJMAIN-75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z"></path><path stroke-width="1" id="MJMAIN-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path stroke-width="1" id="MJMAIN-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path stroke-width="1" id="MJMAIN-79" d="M69 -66Q91 -66 104 -80T118 -116Q118 -134 109 -145T91 -160Q84 -163 97 -166Q104 -168 111 -168Q131 -168 148 -159T175 -138T197 -106T213 -75T225 -43L242 0L170 183Q150 233 125 297Q101 358 96 368T80 381Q79 382 78 382Q66 385 34 385H19V431H26L46 430Q65 430 88 429T122 428Q129 428 142 428T171 429T200 430T224 430L233 431H241V385H232Q183 385 185 366L286 112Q286 113 332 227L376 341V350Q376 365 366 373T348 383T334 385H331V431H337H344Q351 431 361 431T382 430T405 429T422 429Q477 429 503 431H508V385H497Q441 380 422 345Q420 343 378 235T289 9T227 -131Q180 -204 113 -204Q69 -204 44 -177T19 -116Q19 -89 35 -78T69 -66Z"></path><path stroke-width="1" id="MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="1" id="MJMAIN-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path><path stroke-width="1" id="MJMAIN-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path stroke-width="1" id="MJMAIN-74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path stroke-width="1" id="MJMAIN-70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z"></path><path stroke-width="1" id="MJMAIN-64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"></path><path stroke-width="1" id="MJMAIN-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path><path stroke-width="1" id="MJMAIN-6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path stroke-width="1" id="MJMAIN-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path stroke-width="1" id="MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="1" id="MJMAIN-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path stroke-width="1" id="MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path stroke-width="1" id="MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path stroke-width="1" id="MJMAIN-38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path><path stroke-width="1" id="MJMAIN-25" d="M465 605Q428 605 394 614T340 632T319 641Q332 608 332 548Q332 458 293 403T202 347Q145 347 101 402T56 548Q56 637 101 693T202 750Q241 750 272 719Q359 642 464 642Q580 642 650 732Q662 748 668 749Q670 750 673 750Q682 750 688 743T693 726Q178 -47 170 -52Q166 -56 160 -56Q147 -56 142 -45Q137 -36 142 -27Q143 -24 363 304Q469 462 525 546T581 630Q528 605 465 605ZM207 385Q235 385 263 427T292 548Q292 617 267 664T200 712Q193 712 186 709T167 698T147 668T134 615Q132 595 132 548V527Q132 436 165 403Q183 385 203 385H207ZM500 146Q500 234 544 290T647 347Q699 347 737 292T776 146T737 0T646 -56Q590 -56 545 0T500 146ZM651 -18Q679 -18 707 24T736 146Q736 215 711 262T644 309Q637 309 630 306T611 295T591 265T578 212Q577 200 577 146V124Q577 -18 647 -18H651Z"></path><path stroke-width="1" id="MJMAIN-54" d="M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z"></path><path stroke-width="1" id="MJMAIN-50" d="M130 622Q123 629 119 631T103 634T60 637H27V683H214Q237 683 276 683T331 684Q419 684 471 671T567 616Q624 563 624 489Q624 421 573 372T451 307Q429 302 328 301H234V181Q234 62 237 58Q245 47 304 46H337V0H326Q305 3 182 3Q47 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM507 488Q507 514 506 528T500 564T483 597T450 620T397 635Q385 637 307 637H286Q237 637 234 628Q231 624 231 483V342H302H339Q390 342 423 349T481 382Q507 411 507 488Z"></path><path stroke-width="1" id="MJMAIN-4E" d="M42 46Q74 48 94 56T118 69T128 86V634H124Q114 637 52 637H25V683H232L235 680Q237 679 322 554T493 303L578 178V598Q572 608 568 613T544 627T492 637H475V683H483Q498 680 600 680Q706 680 715 683H724V637H707Q634 633 622 598L621 302V6L614 0H600Q585 0 582 3T481 150T282 443T171 605V345L172 86Q183 50 257 46H274V0H265Q250 3 150 3Q48 3 33 0H25V46H42Z"></path><path stroke-width="1" id="MJMAIN-46" d="M128 619Q121 626 117 628T101 631T58 634H25V680H582V676Q584 670 596 560T610 444V440H570V444Q563 493 561 501Q555 538 543 563T516 601T477 622T431 631T374 633H334H286Q252 633 244 631T233 621Q232 619 232 490V363H284Q287 363 303 363T327 364T349 367T372 373T389 385Q407 403 410 459V480H450V200H410V221Q407 276 389 296Q381 303 371 307T348 313T327 316T303 317T284 317H232V189L233 61Q240 54 245 52T270 48T333 46H360V0H348Q324 3 182 3Q51 3 36 0H25V46H58Q100 47 109 49T128 61V619Z"></path><path stroke-width="1" id="MJMATHI-51" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path><path stroke-width="1" id="MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="1" id="MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path stroke-width="1" id="MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path stroke-width="1" id="MJMATHI-61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path><path stroke-width="1" id="MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="1" id="MJMATHI-72" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMATHI-3B3" d="M31 249Q11 249 11 258Q11 275 26 304T66 365T129 418T206 441Q233 441 239 440Q287 429 318 386T371 255Q385 195 385 170Q385 166 386 166L398 193Q418 244 443 300T486 391T508 430Q510 431 524 431H537Q543 425 543 422Q543 418 522 378T463 251T391 71Q385 55 378 6T357 -100Q341 -165 330 -190T303 -216Q286 -216 286 -188Q286 -138 340 32L346 51L347 69Q348 79 348 100Q348 257 291 317Q251 355 196 355Q148 355 108 329T51 260Q49 251 47 251Q45 249 31 249Z"></path><path stroke-width="1" id="MJAMS-45" d="M12 666Q12 675 24 683H582Q590 680 593 672V588Q593 514 591 502T575 490Q567 490 563 495T555 517Q552 556 517 590Q486 623 445 634T340 648H282Q266 636 264 620T260 492V370H277Q329 375 358 391T404 439Q420 480 420 506Q420 529 436 529Q445 529 451 521Q455 517 455 361Q455 333 455 298T456 253Q456 217 453 207T437 197Q420 196 420 217Q420 240 406 270Q377 328 284 335H260V201Q261 174 261 134Q262 73 264 61T278 38Q281 36 282 35H331Q400 35 449 50Q571 93 602 179Q605 203 622 203Q629 203 634 197T640 183Q638 181 624 95T604 3L600 -1H24Q12 5 12 16Q12 35 51 35Q92 38 97 52Q102 60 102 341T97 632Q91 645 51 648Q12 648 12 666ZM137 341Q137 131 136 89T130 37Q129 36 129 35H235Q233 41 231 48L226 61V623L231 635L235 648H129Q132 641 133 638T135 603T137 517T137 341ZM557 603V648H504Q504 646 515 639Q527 634 542 619L557 603ZM420 317V397L406 383Q394 370 380 363L366 355Q373 350 382 346Q400 333 409 328L420 317ZM582 61L586 88Q585 88 582 83Q557 61 526 46L511 37L542 35H577Q577 36 578 39T580 49T582 61Z"></path><path stroke-width="1" id="MJMAIN-2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path><path stroke-width="1" id="MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path><path stroke-width="1" id="MJMAIN-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path stroke-width="1" id="MJMAIN-78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path><path stroke-width="1" id="MJMAIN-2190" d="M944 261T944 250T929 230H165Q167 228 182 216T211 189T244 152T277 96T303 25Q308 7 308 0Q308 -11 288 -11Q281 -11 278 -11T272 -7T267 2T263 21Q245 94 195 151T73 236Q58 242 55 247Q55 254 59 257T73 264Q121 283 158 314T215 375T247 434T264 480L267 497Q269 503 270 505T275 509T288 511Q308 511 308 500Q308 493 303 475Q293 438 278 406T246 352T215 315T185 287T165 270H929Q944 261 944 250Z"></path><path stroke-width="1" id="MJMATHI-3B1" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path><path stroke-width="1" id="MJMAIN-5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path><path stroke-width="1" id="MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="1" id="MJMAIN-5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path><path stroke-width="1" id="MJSZ2-5B" d="M224 -649V1150H455V1099H275V-598H455V-649H224Z"></path><path stroke-width="1" id="MJSZ2-5D" d="M16 1099V1150H247V-649H16V-598H196V1099H16Z"></path><path stroke-width="1" id="MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path><path stroke-width="1" id="MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path><path stroke-width="1" id="MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="1" id="MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path stroke-width="1" id="MJMAIN-2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path><path stroke-width="1" id="MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMAIN-66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z"></path><path stroke-width="1" id="MJMAIN-6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path stroke-width="1" id="MJMAIN-67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z"></path><path stroke-width="1" id="MJMAIN-76" d="M338 431Q344 429 422 429Q479 429 503 431H508V385H497Q439 381 423 345Q421 341 356 172T288 -2Q283 -11 263 -11Q244 -11 239 -2Q99 359 98 364Q93 378 82 381T43 385H19V431H25L33 430Q41 430 53 430T79 430T104 429T122 428Q217 428 232 431H240V385H226Q187 384 184 370Q184 366 235 234L286 102L377 341V349Q377 363 367 372T349 383T335 385H331V431H338Z"></path><path stroke-width="1" id="MJMATHI-46" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path><path stroke-width="1" id="MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMATHI-3BE" d="M268 632Q268 704 296 704Q314 704 314 687Q314 682 311 664T308 635T309 620V616H315Q342 619 360 619Q443 619 443 586Q439 548 358 546H344Q326 546 317 549T290 566Q257 550 226 505T195 405Q195 381 201 364T211 342T218 337Q266 347 298 347Q375 347 375 314Q374 297 359 288T327 277T280 275Q234 275 208 283L195 286Q149 260 119 214T88 130Q88 116 90 108Q101 79 129 63T229 20Q238 17 243 15Q337 -21 354 -33Q383 -53 383 -94Q383 -137 351 -171T273 -205Q240 -205 202 -190T158 -167Q156 -163 156 -159Q156 -151 161 -146T176 -140Q182 -140 189 -143Q232 -168 274 -168Q286 -168 292 -165Q313 -151 313 -129Q313 -112 301 -104T232 -75Q214 -68 204 -64Q198 -62 171 -52T136 -38T107 -24T78 -8T56 12T36 37T26 66T21 103Q21 149 55 206T145 301L154 307L148 313Q141 319 136 323T124 338T111 358T103 382T99 413Q99 471 143 524T259 602L271 607Q268 618 268 632Z"></path><path stroke-width="1" id="MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path stroke-width="1" id="MJMAIN-2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path><path stroke-width="1" id="MJMAIN-37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z"></path><path stroke-width="1" id="MJMAIN-45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z"></path><path stroke-width="1" id="MJMAIN-35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path stroke-width="1" id="MJSZ2-221A" d="M1001 1150Q1017 1150 1020 1132Q1020 1127 741 244L460 -643Q453 -650 436 -650H424Q423 -647 423 -645T421 -640T419 -631T415 -617T408 -594T399 -560T385 -512T367 -448T343 -364T312 -259L203 119L138 41L111 67L212 188L264 248L472 -474L983 1140Q988 1150 1001 1150Z"></path><path stroke-width="1" id="MJMAIN-4D" d="M132 622Q125 629 121 631T105 634T62 637H29V683H135Q221 683 232 682T249 675Q250 674 354 398L458 124L562 398Q666 674 668 675Q671 681 683 682T781 683H887V637H854Q814 636 803 634T785 622V61Q791 51 802 49T854 46H887V0H876Q855 3 736 3Q605 3 596 0H585V46H618Q660 47 669 49T688 61V347Q688 424 688 461T688 546T688 613L687 632Q454 14 450 7Q446 1 430 1T410 7Q409 9 292 316L176 624V606Q175 588 175 543T175 463T175 356L176 86Q187 50 261 46H278V0H269Q254 3 154 3Q52 3 37 0H29V46H46Q78 48 98 56T122 69T132 86V622Z"></path><path stroke-width="1" id="MJMAIN-68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path stroke-width="1" id="MJMATHI-4C" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path stroke-width="1" id="MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path stroke-width="1" id="MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path stroke-width="1" id="MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path><path stroke-width="1" id="MJMAIN-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path><path stroke-width="1" id="MJMAIN-4C" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q48 680 182 680Q324 680 348 683H360V637H333Q273 637 258 635T233 622L232 342V129Q232 57 237 52Q243 47 313 47Q384 47 410 53Q470 70 498 110T536 221Q536 226 537 238T540 261T542 272T562 273H582V268Q580 265 568 137T554 5V0H25V46H58Q100 47 109 49T128 61V622Z"></path><path stroke-width="1" id="MJMAIN-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path><path stroke-width="1" id="MJMATHI-44" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path><path stroke-width="1" id="MJMAIN-2D" d="M11 179V252H277V179H11Z"></path><path stroke-width="1" id="MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path><path stroke-width="1" id="MJMAIN-39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z"></path><path stroke-width="1" id="MJMAIN-62" d="M307 -11Q234 -11 168 55L158 37Q156 34 153 28T147 17T143 10L138 1L118 0H98V298Q98 599 97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V543Q179 391 180 391L183 394Q186 397 192 401T207 411T228 421T254 431T286 439T323 442Q401 442 461 379T522 216Q522 115 458 52T307 -11ZM182 98Q182 97 187 90T196 79T206 67T218 55T233 44T250 35T271 29T295 26Q330 26 363 46T412 113Q424 148 424 212Q424 287 412 323Q385 405 300 405Q270 405 239 390T188 347L182 339V98Z"></path><path stroke-width="1" id="MJMAIN-53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path><path stroke-width="1" id="MJMAIN-71" d="M33 218Q33 308 95 374T236 441H246Q330 441 381 372L387 364Q388 364 404 403L420 442H457V156Q457 -132 458 -134Q462 -142 470 -145Q491 -148 519 -148H535V-194H527L504 -193Q480 -192 453 -192T415 -191Q312 -191 303 -194H295V-148H311Q339 -148 360 -145Q369 -141 371 -135T373 -106V-41V49Q313 -11 236 -11Q154 -11 94 53T33 218ZM376 300Q346 389 278 401Q275 401 269 401T261 402Q211 400 171 350T131 214Q131 137 165 82T253 27Q296 27 328 54T376 118V300Z"></path><path stroke-width="1" id="MJMAIN-33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path stroke-width="1" id="MJMATHI-50" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path><path stroke-width="1" id="MJMAIN-52" d="M130 622Q123 629 119 631T103 634T60 637H27V683H202H236H300Q376 683 417 677T500 648Q595 600 609 517Q610 512 610 501Q610 468 594 439T556 392T511 361T472 343L456 338Q459 335 467 332Q497 316 516 298T545 254T559 211T568 155T578 94Q588 46 602 31T640 16H645Q660 16 674 32T692 87Q692 98 696 101T712 105T728 103T732 90Q732 59 716 27T672 -16Q656 -22 630 -22Q481 -16 458 90Q456 101 456 163T449 246Q430 304 373 320L363 322L297 323H231V192L232 61Q238 51 249 49T301 46H334V0H323Q302 3 181 3Q59 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM491 499V509Q491 527 490 539T481 570T462 601T424 623T362 636Q360 636 340 636T304 637H283Q238 637 234 628Q231 624 231 492V360H289Q390 360 434 378T489 456Q491 467 491 499Z"></path><path stroke-width="1" id="MJMAIN-7A" d="M42 263Q44 270 48 345T53 423V431H393Q399 425 399 415Q399 403 398 402L381 378Q364 355 331 309T265 220L134 41L182 40H206Q254 40 283 46T331 77Q352 105 359 185L361 201Q361 202 381 202H401V196Q401 195 393 103T384 6V0H209L34 1L31 3Q28 8 28 17Q28 30 29 31T160 210T294 394H236Q169 393 152 388Q127 382 113 367Q89 344 82 264V255H42V263Z"></path><path stroke-width="1" id="MJMATHI-3BB" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path><path stroke-width="1" id="MJMATHI-4E" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path><path stroke-width="1" id="MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path><path stroke-width="1" id="MJMATHI-6D" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path><path stroke-width="1" id="MJMATHI-65" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path stroke-width="1" id="MJMATHI-3C3" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path><path stroke-width="1" id="MJSZ1-2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path><path stroke-width="1" id="MJMATHI-6A" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path><path stroke-width="1" id="MJMATHI-4B" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path><path stroke-width="1" id="MJMATHI-7A" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path><path stroke-width="1" id="MJMAIN-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path></defs></svg></div><div id="MathJax_Message" style="display: none;"></div>
    <devsite-progress id="app-progress"></devsite-progress>
  
    <section class="devsite-wrapper"><devsite-header top-row--height="48.79999923706055" bottom-row--height="72" bottom-tabs--height="0" fixed="" offset="72" bottom-row--hidden="">
  
    























<div class="devsite-header--inner nocontent">
  <div class="devsite-top-logo-row-wrapper-wrapper">
    <div class="devsite-top-logo-row-wrapper">
      <div class="devsite-top-logo-row">
        <button type="button" id="devsite-hamburger-menu" class="devsite-header-icon-button button-flat material-icons gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Navigation menu button" aria-label="Open menu">
        </button>
        <div class="devsite-product-name-wrapper">

  
    
  



  
  
  <span class="devsite-product-name">
    <ul class="devsite-breadcrumb-list">
  
  <li class="devsite-breadcrumb-item
             ">
    
    
    
      
      
        
  <a href="https://developers.google.com/machine-learning" class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Upper Header" data-value="1" track-type="globalNav" track-name="breadcrumb" track-metadata-position="1" track-metadata-eventdetail="Machine Learning">
    
          Machine Learning
        
  </a>
  
      
    
  </li>
  
</ul>
  </span>

</div>
        <div class="devsite-top-logo-row-middle">
          <div class="devsite-header-upper-tabs">
            
              
              
  <devsite-tabs class="upper-tabs" connected="">

    

  <nav class="devsite-tabs-wrapper" aria-label="Upper tabs">
      
        
          <tab>
            
    <a href="https://developers.google.com/machine-learning/foundational-courses" track-metadata-eventdetail="https://developers.google.com/machine-learning/foundational-courses" class="devsite-tabs-content gc-analytics-event " track-type="nav" track-metadata-position="nav - foundational courses" track-metadata-module="primary nav" data-category="Site-Wide Custom Events" data-label="Tab: Foundational courses" track-name="foundational courses">
    Foundational courses
  
    </a>
  
  
          </tab>
        
      
        
          <tab>
            
    <a href="https://developers.google.com/machine-learning/advanced-courses" track-metadata-eventdetail="https://developers.google.com/machine-learning/advanced-courses" class="devsite-tabs-content gc-analytics-event " track-type="nav" track-metadata-position="nav - advanced courses" track-metadata-module="primary nav" data-category="Site-Wide Custom Events" data-label="Tab: Advanced courses" track-name="advanced courses">
    Advanced courses
  
    </a>
  
  
          </tab>
        
      
        
          <tab>
            
    <a href="https://developers.google.com/machine-learning/guides" track-metadata-eventdetail="https://developers.google.com/machine-learning/guides" class="devsite-tabs-content gc-analytics-event " track-type="nav" track-metadata-position="nav - guides" track-metadata-module="primary nav" data-category="Site-Wide Custom Events" data-label="Tab: Guides" track-name="guides">
    Guides
  
    </a>
  
  
          </tab>
        
      
        
          <tab dropdown="" active="">
  
    <a href="https://developers.google.com/machine-learning/glossary" track-metadata-eventdetail="https://developers.google.com/machine-learning/glossary" class="devsite-tabs-content gc-analytics-event " track-type="nav" track-metadata-position="nav - glossary" track-metadata-module="primary nav" aria-label="Glossary, selected" data-category="Site-Wide Custom Events" data-label="Tab: Glossary" track-name="glossary">
    Glossary
  
    </a>
  
  
    <a href="https://developers.google.com/machine-learning/glossary#" role="button" aria-haspopup="true" aria-expanded="false" aria-label="Dropdown menu for Glossary" track-type="nav" track-metadata-eventdetail="https://developers.google.com/machine-learning/glossary" track-metadata-position="nav - glossary" track-metadata-module="primary nav" data-category="Site-Wide Custom Events" data-label="Tab: Glossary" track-name="glossary" class="devsite-tabs-dropdown-toggle devsite-icon devsite-icon-arrow-drop-down"></a>
  
  <div class="devsite-tabs-dropdown" aria-label="submenu" hidden="">
    
    <div class="devsite-tabs-dropdown-content">
      
        <div class="devsite-tabs-dropdown-column
                    ">
          
            <ul class="devsite-tabs-dropdown-section
                       ">
              
              
              
                <li class="devsite-nav-item">
                  <a href="https://developers.google.com/machine-learning/glossary" track-type="nav" track-metadata-eventdetail="https://developers.google.com/machine-learning/glossary" track-metadata-position="nav - glossary" track-metadata-module="tertiary nav" tooltip="">
                    
                    <div class="devsite-nav-item-title">
                      All terms
                    </div>
                    
                  </a>
                </li>
              
                <li class="devsite-nav-item">
                  <a href="https://developers.google.com/machine-learning/glossary/clustering" track-type="nav" track-metadata-eventdetail="https://developers.google.com/machine-learning/glossary/clustering" track-metadata-position="nav - glossary" track-metadata-module="tertiary nav" tooltip="">
                    
                    <div class="devsite-nav-item-title">
                      Clustering
                    </div>
                    
                  </a>
                </li>
              
                <li class="devsite-nav-item">
                  <a href="https://developers.google.com/machine-learning/glossary/df" track-type="nav" track-metadata-eventdetail="https://developers.google.com/machine-learning/glossary/df" track-metadata-position="nav - glossary" track-metadata-module="tertiary nav" tooltip="">
                    
                    <div class="devsite-nav-item-title">
                      Decision Forests
                    </div>
                    
                  </a>
                </li>
              
                <li class="devsite-nav-item">
                  <a href="https://developers.google.com/machine-learning/glossary/fairness" track-type="nav" track-metadata-eventdetail="https://developers.google.com/machine-learning/glossary/fairness" track-metadata-position="nav - glossary" track-metadata-module="tertiary nav" tooltip="">
                    
                    <div class="devsite-nav-item-title">
                      Fairness
                    </div>
                    
                  </a>
                </li>
              
                <li class="devsite-nav-item">
                  <a href="https://developers.google.com/machine-learning/glossary/fundamentals" track-type="nav" track-metadata-eventdetail="https://developers.google.com/machine-learning/glossary/fundamentals" track-metadata-position="nav - glossary" track-metadata-module="tertiary nav" tooltip="">
                    
                    <div class="devsite-nav-item-title">
                      Fundamentals
                    </div>
                    
                  </a>
                </li>
              
                <li class="devsite-nav-item">
                  <a href="https://developers.google.com/machine-learning/glossary/googlecloud" track-type="nav" track-metadata-eventdetail="https://developers.google.com/machine-learning/glossary/googlecloud" track-metadata-position="nav - glossary" track-metadata-module="tertiary nav" tooltip="">
                    
                    <div class="devsite-nav-item-title">
                      GCP
                    </div>
                    
                  </a>
                </li>
              
                <li class="devsite-nav-item">
                  <a href="https://developers.google.com/machine-learning/glossary/image" track-type="nav" track-metadata-eventdetail="https://developers.google.com/machine-learning/glossary/image" track-metadata-position="nav - glossary" track-metadata-module="tertiary nav" tooltip="">
                    
                    <div class="devsite-nav-item-title">
                      Image
                    </div>
                    
                  </a>
                </li>
              
                <li class="devsite-nav-item">
                  <a href="https://developers.google.com/machine-learning/glossary/language" track-type="nav" track-metadata-eventdetail="https://developers.google.com/machine-learning/glossary/language" track-metadata-position="nav - glossary" track-metadata-module="tertiary nav" tooltip="">
                    
                    <div class="devsite-nav-item-title">
                      Lang Eval
                    </div>
                    
                  </a>
                </li>
              
                <li class="devsite-nav-item">
                  <a href="https://developers.google.com/machine-learning/glossary/recsystems" track-type="nav" track-metadata-eventdetail="https://developers.google.com/machine-learning/glossary/recsystems" track-metadata-position="nav - glossary" track-metadata-module="tertiary nav" tooltip="">
                    
                    <div class="devsite-nav-item-title">
                      Recommendation Systems
                    </div>
                    
                  </a>
                </li>
              
                <li class="devsite-nav-item">
                  <a href="https://developers.google.com/machine-learning/glossary/rl" track-type="nav" track-metadata-eventdetail="https://developers.google.com/machine-learning/glossary/rl" track-metadata-position="nav - glossary" track-metadata-module="tertiary nav" tooltip="">
                    
                    <div class="devsite-nav-item-title">
                      Reinforcement Learning
                    </div>
                    
                  </a>
                </li>
              
                <li class="devsite-nav-item">
                  <a href="https://developers.google.com/machine-learning/glossary/sequence" track-type="nav" track-metadata-eventdetail="https://developers.google.com/machine-learning/glossary/sequence" track-metadata-position="nav - glossary" track-metadata-module="tertiary nav" tooltip="">
                    
                    <div class="devsite-nav-item-title">
                      Sequence Models
                    </div>
                    
                  </a>
                </li>
              
                <li class="devsite-nav-item">
                  <a href="https://developers.google.com/machine-learning/glossary/tensorflow" track-type="nav" track-metadata-eventdetail="https://developers.google.com/machine-learning/glossary/tensorflow" track-metadata-position="nav - glossary" track-metadata-module="tertiary nav" tooltip="">
                    
                    <div class="devsite-nav-item-title">
                      TensorFlow
                    </div>
                    
                  </a>
                </li>
              
            </ul>
          
        </div>
      
    </div>
  </div>
</tab>
        
      
    <tab overflow-tab="" hidden=""><a href="https://developers.google.com/machine-learning/glossary#" class="devsite-icon devsite-icon-arrow-drop-down">More</a><div class="devsite-tabs-overflow-menu" scrollbars="" hidden=""></div></tab></nav></devsite-tabs>

            
           </div>
          
<devsite-search aria-expanded="false" aria-haspopup="listbox" enable-signin="" enable-search="" enable-suggestions="" enable-query-completion="" project-name="Machine Learning" tenant-name="Google Developers" project-scope="/machine-learning" url-scoped="https://developers.google.com/s/results/machine-learning" role="combobox">
  <form class="devsite-search-form" action="https://developers.google.com/s/results" method="GET">
    <div class="devsite-search-container">
      <div class="devsite-searchbox">
        <input aria-activedescendant="" aria-autocomplete="list" aria-label="Search" aria-haspopup="false" aria-multiline="false" autocomplete="off" class="devsite-search-field devsite-search-query" name="q" placeholder="Search" role="searchbox" type="text" value="" aria-controls="devsite-search-popout-container-id-1">
        <div class="devsite-search-image material-icons" aria-hidden="true"></div>
      </div>
      <button type="button" search-open="" class="devsite-search-button devsite-header-icon-button button-flat material-icons" aria-label="Open search"></button>
    </div>
  <div class="devsite-popout" id="devsite-search-popout-container-id-1"><div class="devsite-popout-result devsite-suggest-results-container" devsite-hide=""></div></div></form>
  <button type="button" search-close="" class="devsite-search-button devsite-header-icon-button button-flat material-icons" aria-label="Close search"></button>
</devsite-search>

        <div class="devsite-search-background" style="opacity: 1;"></div></div>

        

        

        

        
<devsite-language-selector aria-label="Select your language preference.">
  <ul role="presentation">
    
    
    <li role="presentation">
      <a role="menuitem" lang="en" href="https://developers.google.com/machine-learning/glossary" aria-current="true">English</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="id" href="https://developers.google.com/machine-learning/glossary?hl=id">Bahasa Indonesia</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="de" href="https://developers.google.com/machine-learning/glossary?hl=de">Deutsch</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="es" href="https://developers.google.com/machine-learning/glossary?hl=es">Español</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="es-419" href="https://developers.google.com/machine-learning/glossary?hl=es-419">Español – América Latina</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="fr" href="https://developers.google.com/machine-learning/glossary?hl=fr">Français</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="it" href="https://developers.google.com/machine-learning/glossary?hl=it">Italiano</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="pl" href="https://developers.google.com/machine-learning/glossary?hl=pl">Polski</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="pt-br" href="https://developers.google.com/machine-learning/glossary?hl=pt-br">Português – Brasil</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="vi" href="https://developers.google.com/machine-learning/glossary?hl=vi">Tiếng Việt</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="tr" href="https://developers.google.com/machine-learning/glossary?hl=tr">Türkçe</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="ru" href="https://developers.google.com/machine-learning/glossary?hl=ru">Русский</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="he" href="https://developers.google.com/machine-learning/glossary?hl=he">עברית</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="ar" href="https://developers.google.com/machine-learning/glossary?hl=ar">العربيّة</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="fa" href="https://developers.google.com/machine-learning/glossary?hl=fa">فارسی</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="hi" href="https://developers.google.com/machine-learning/glossary?hl=hi">हिंदी</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="bn" href="https://developers.google.com/machine-learning/glossary?hl=bn">বাংলা</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="th" href="https://developers.google.com/machine-learning/glossary?hl=th">ภาษาไทย</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="zh-cn" href="https://developers.google.com/machine-learning/glossary?hl=zh-cn">中文 – 简体</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="zh-tw" href="https://developers.google.com/machine-learning/glossary?hl=zh-tw">中文 – 繁體</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="ja" href="https://developers.google.com/machine-learning/glossary?hl=ja">日本語</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="ko" href="https://developers.google.com/machine-learning/glossary?hl=ko">한국어</a>
    </li>
    
  </ul>
</devsite-language-selector>


        

        
          
          
          <devsite-user signed-in="" enable-profiles="" fp-auth="" id="devsite-user" sign-in-url="https://developers.google.com/_d/signin?continue=https%3A%2F%2Fdevelopers.google.com%2Fmachine-learning%2Fglossary&amp;prompt=select_account" sign-out-url="https://developers.google.com/_d/signout?continue=https%3A%2F%2Fdevelopers.google.com%2Fmachine-learning%2Fglossary" url="https://developers.google.com/_d/signin?continue=https%3A%2F%2Fdevelopers.google.com%2Fmachine-learning%2Fglossary&amp;prompt=select_account"><div class="ogb-wrapper ogb-si"><div class="devsite-devprofile-wrapper show"><devsite-feature-tooltip ack-key="AckViewSavedPagesPopoutDismiss" id="devsite-view-saved-pages" close-button-href="" close-button-text="View" dismiss-button="" managed="" ready="" current-step="0" style="--devsite-popout-offset-x:32px;"><button class="devsite-devprofile-button" aria-controls="devsite-devprofile-popout" aria-expanded="false" aria-haspopup="true" aria-label="Open Google Developer Profile" data-tooltip="Google Developer Profile"><svg width="4" height="16" viewBox="0 0 4 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M2 4C3.1 4 4 3.1 4 2C4 0.9 3.1 0 2 0C0.9 0 0 0.9 0 2C0 3.1 0.9 4 2 4ZM2 6C0.9 6 0 6.9 0 8C0 9.1 0.9 10 2 10C3.1 10 4 9.1 4 8C4 6.9 3.1 6 2 6ZM0 14C0 12.9 0.9 12 2 12C3.1 12 4 12.9 4 14C4 15.1 3.1 16 2 16C0.9 16 0 15.1 0 14Z" fill="#5F6368"></path></svg></button><span slot="popout-heading">Google Developer Profile</span><span slot="popout-contents">View your saved pages and finish your Google Developer Profile setup here.</span></devsite-feature-tooltip><div class="devsite-devprofile-popout" role="menu"></div></div><div class="gb_Ca gb_2d gb_5a gb_Da" id="gb"><div class="gb_0d gb_3a gb_Od" ng-non-bindable="" data-ogsr-up="" style="padding:0;height:auto;display:block"><div class="gb_Ve" style="display:block"><div class="gb_Wc"></div><div class="gb_b gb_kd gb_pg gb_o gb_Ef"><div class="gb_Df gb_2a gb_pg gb_o"><a class="gb_e gb_Xa gb_o devsite-top-button button" aria-label="Google Account: Tuấn Dũng Lại  
(dunglailaptrinh@gmail.com)" href="https://accounts.google.com/SignOutOptions?hl=en&amp;continue=https://developers.google.com/_d/profile/ogb" role="button" tabindex="0" id="devsite-signin-btn"><img class="gb_g gbii" src="./ML_Glossary_files/unnamed.jpg" srcset="https://lh3.googleusercontent.com/ogw/AAEL6sjX5nFi7ooEIaUtlYfJBK5ORIO-QmKkxConR1Vf=s32-c-mo 1x, https://lh3.googleusercontent.com/ogw/AAEL6sjX5nFi7ooEIaUtlYfJBK5ORIO-QmKkxConR1Vf=s64-c-mo 2x " alt="" aria-hidden="true" data-noaft=""></a><div class="gb_8a"></div><div class="gb_7a"></div></div></div></div><div style="overflow: hidden; position: absolute; top: 0px; visibility: hidden; width: 372px; z-index: 991; height: 0px; margin-top: 57px; right: 0px; margin-right: 4px;"></div></div></div></div></devsite-user>
           
        
      </div>
    </div>
  </div>



  <div class="devsite-collapsible-section
    
      devsite-header-no-lower-tabs
    " style="transform: translate3d(0px, -72px, 0px);">
    <div class="devsite-header-background">
      
        
          <div class="devsite-product-id-row">
            <div class="devsite-product-description-row">
              
                
                  
                  
                  <ul class="devsite-breadcrumb-list">
  
  <li class="devsite-breadcrumb-item
             ">
    
    
    
      
  <a href="https://developers.google.com/machine-learning/glossary" class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Lower Header" data-value="1" track-type="globalNav" track-name="breadcrumb" track-metadata-position="1" track-metadata-eventdetail="">
    
        Glossary
      
  </a>
  
    
  </li>
  
</ul>
                
              
              
            </div>
            
          </div>
          
        
      
      
    </div>
  </div>

</div>



  

  
</devsite-header>
      <div class="devsite-book-nav-bg" fixed="" hidden=""></div><devsite-book-nav scrollbars="" hidden="" fixed="" style="--devsite-js-book-nav-y-offset:-72px; top: 120.8px; max-height: 914.2px;" top-level-nav="">
        
          





















<div class="devsite-book-nav-filter
            hidden">
  <input type="text" placeholder="Filter" aria-label="Type to filter" role="searchbox">
  
  <span class="filter-clear-button hidden" data-title="Clear filter" aria-label="Clear filter" role="button" tabindex="0"></span>
</div>

<nav class="devsite-book-nav devsite-nav nocontent" aria-label="Side menu">
  <div class="devsite-mobile-header">
    <button type="button" id="devsite-close-nav" class="devsite-header-icon-button button-flat material-icons gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Close navigation" aria-label="Close navigation">
    </button>
    <div class="devsite-product-name-wrapper">

  
    
  


  
      <span class="devsite-product-name">
        
        
        <ul class="devsite-breadcrumb-list">
  
  <li class="devsite-breadcrumb-item
             ">
    
    
    
      
      
        
  <a href="https://developers.google.com/machine-learning" class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Upper Header" data-value="1" track-type="globalNav" track-name="breadcrumb" track-metadata-position="1" track-metadata-eventdetail="Machine Learning">
    
          Machine Learning
        
  </a>
  
      
    
  </li>
  
</ul>
      </span>
    

</div>
  </div>

  <div class="devsite-book-nav-wrapper">
    <div class="devsite-mobile-nav-top">
      
        <ul class="devsite-nav-list">
          
            <li class="devsite-nav-item">
              
  
  <a href="https://developers.google.com/machine-learning/foundational-courses" class="devsite-nav-title gc-analytics-event
              
              " data-category="Site-Wide Custom Events" data-label="Tab: Foundational courses" track-name="foundational courses" track-type="globalNav" track-metadata-eventdetail="globalMenu" track-metadata-position="nav">
  
    <span class="devsite-nav-text" tooltip="">
      Foundational courses
   </span>
    
  
  </a>
  

  
              
            </li>
          
            <li class="devsite-nav-item">
              
  
  <a href="https://developers.google.com/machine-learning/advanced-courses" class="devsite-nav-title gc-analytics-event
              
              " data-category="Site-Wide Custom Events" data-label="Tab: Advanced courses" track-name="advanced courses" track-type="globalNav" track-metadata-eventdetail="globalMenu" track-metadata-position="nav">
  
    <span class="devsite-nav-text" tooltip="">
      Advanced courses
   </span>
    
  
  </a>
  

  
              
            </li>
          
            <li class="devsite-nav-item">
              
  
  <a href="https://developers.google.com/machine-learning/guides" class="devsite-nav-title gc-analytics-event
              
              " data-category="Site-Wide Custom Events" data-label="Tab: Guides" track-name="guides" track-type="globalNav" track-metadata-eventdetail="globalMenu" track-metadata-position="nav">
  
    <span class="devsite-nav-text" tooltip="">
      Guides
   </span>
    
  
  </a>
  

  
              
            </li>
          
            <li class="devsite-nav-item">
              
  
  <a href="https://developers.google.com/machine-learning/glossary" class="devsite-nav-title gc-analytics-event
              
              devsite-nav-active" data-category="Site-Wide Custom Events" data-label="Tab: Glossary" track-name="glossary" track-type="globalNav" track-metadata-eventdetail="globalMenu" track-metadata-position="nav">
  
    <span class="devsite-nav-text" tooltip="">
      Glossary
   </span>
    
  
  </a>
  

  
    <ul class="devsite-nav-responsive-tabs devsite-nav-has-menu
               ">
      
<li class="devsite-nav-item">

  
  <span class="devsite-nav-title" tooltip="" data-category="Site-Wide Custom Events" data-label="Tab: Glossary" track-name="glossary">
  
    <span class="devsite-nav-text" tooltip="" menu="Glossary">
      More
   </span>
    
    <span class="devsite-nav-icon material-icons" data-icon="forward" menu="Glossary">
    </span>
    
  
  </span>
  

</li>

    </ul>
  
              
            </li>
          
          
          
        </ul>
      
    </div>
    
      <div class="devsite-mobile-nav-bottom" role="navigation">
        
        
          
    
  
    
  
    
  
    
      
      <ul class="devsite-nav-list" menu="Glossary" aria-label="Side menu" hidden="">
        
          
            
            
              
<li class="devsite-nav-item">

  
  <a href="https://developers.google.com/machine-learning/glossary" class="devsite-nav-title gc-analytics-event
              
              " data-category="Site-Wide Custom Events" data-label="Responsive Tab: All terms" track-type="navMenu" track-metadata-eventdetail="globalMenu" track-metadata-position="nav">
  
    <span class="devsite-nav-text" tooltip="">
      All terms
   </span>
    
  
  </a>
  

</li>

            
              
<li class="devsite-nav-item">

  
  <a href="https://developers.google.com/machine-learning/glossary/clustering" class="devsite-nav-title gc-analytics-event
              
              " data-category="Site-Wide Custom Events" data-label="Responsive Tab: Clustering" track-type="navMenu" track-metadata-eventdetail="globalMenu" track-metadata-position="nav">
  
    <span class="devsite-nav-text" tooltip="">
      Clustering
   </span>
    
  
  </a>
  

</li>

            
              
<li class="devsite-nav-item">

  
  <a href="https://developers.google.com/machine-learning/glossary/df" class="devsite-nav-title gc-analytics-event
              
              " data-category="Site-Wide Custom Events" data-label="Responsive Tab: Decision Forests" track-type="navMenu" track-metadata-eventdetail="globalMenu" track-metadata-position="nav">
  
    <span class="devsite-nav-text" tooltip="">
      Decision Forests
   </span>
    
  
  </a>
  

</li>

            
              
<li class="devsite-nav-item">

  
  <a href="https://developers.google.com/machine-learning/glossary/fairness" class="devsite-nav-title gc-analytics-event
              
              " data-category="Site-Wide Custom Events" data-label="Responsive Tab: Fairness" track-type="navMenu" track-metadata-eventdetail="globalMenu" track-metadata-position="nav">
  
    <span class="devsite-nav-text" tooltip="">
      Fairness
   </span>
    
  
  </a>
  

</li>

            
              
<li class="devsite-nav-item">

  
  <a href="https://developers.google.com/machine-learning/glossary/fundamentals" class="devsite-nav-title gc-analytics-event
              
              " data-category="Site-Wide Custom Events" data-label="Responsive Tab: Fundamentals" track-type="navMenu" track-metadata-eventdetail="globalMenu" track-metadata-position="nav">
  
    <span class="devsite-nav-text" tooltip="">
      Fundamentals
   </span>
    
  
  </a>
  

</li>

            
              
<li class="devsite-nav-item">

  
  <a href="https://developers.google.com/machine-learning/glossary/googlecloud" class="devsite-nav-title gc-analytics-event
              
              " data-category="Site-Wide Custom Events" data-label="Responsive Tab: GCP" track-type="navMenu" track-metadata-eventdetail="globalMenu" track-metadata-position="nav">
  
    <span class="devsite-nav-text" tooltip="">
      GCP
   </span>
    
  
  </a>
  

</li>

            
              
<li class="devsite-nav-item">

  
  <a href="https://developers.google.com/machine-learning/glossary/image" class="devsite-nav-title gc-analytics-event
              
              " data-category="Site-Wide Custom Events" data-label="Responsive Tab: Image" track-type="navMenu" track-metadata-eventdetail="globalMenu" track-metadata-position="nav">
  
    <span class="devsite-nav-text" tooltip="">
      Image
   </span>
    
  
  </a>
  

</li>

            
              
<li class="devsite-nav-item">

  
  <a href="https://developers.google.com/machine-learning/glossary/language" class="devsite-nav-title gc-analytics-event
              
              " data-category="Site-Wide Custom Events" data-label="Responsive Tab: Lang Eval" track-type="navMenu" track-metadata-eventdetail="globalMenu" track-metadata-position="nav">
  
    <span class="devsite-nav-text" tooltip="">
      Lang Eval
   </span>
    
  
  </a>
  

</li>

            
              
<li class="devsite-nav-item">

  
  <a href="https://developers.google.com/machine-learning/glossary/recsystems" class="devsite-nav-title gc-analytics-event
              
              " data-category="Site-Wide Custom Events" data-label="Responsive Tab: Recommendation Systems" track-type="navMenu" track-metadata-eventdetail="globalMenu" track-metadata-position="nav">
  
    <span class="devsite-nav-text" tooltip="">
      Recommendation Systems
   </span>
    
  
  </a>
  

</li>

            
              
<li class="devsite-nav-item">

  
  <a href="https://developers.google.com/machine-learning/glossary/rl" class="devsite-nav-title gc-analytics-event
              
              " data-category="Site-Wide Custom Events" data-label="Responsive Tab: Reinforcement Learning" track-type="navMenu" track-metadata-eventdetail="globalMenu" track-metadata-position="nav">
  
    <span class="devsite-nav-text" tooltip="">
      Reinforcement Learning
   </span>
    
  
  </a>
  

</li>

            
              
<li class="devsite-nav-item">

  
  <a href="https://developers.google.com/machine-learning/glossary/sequence" class="devsite-nav-title gc-analytics-event
              
              " data-category="Site-Wide Custom Events" data-label="Responsive Tab: Sequence Models" track-type="navMenu" track-metadata-eventdetail="globalMenu" track-metadata-position="nav">
  
    <span class="devsite-nav-text" tooltip="">
      Sequence Models
   </span>
    
  
  </a>
  

</li>

            
              
<li class="devsite-nav-item">

  
  <a href="https://developers.google.com/machine-learning/glossary/tensorflow" class="devsite-nav-title gc-analytics-event
              
              " data-category="Site-Wide Custom Events" data-label="Responsive Tab: TensorFlow" track-type="navMenu" track-metadata-eventdetail="globalMenu" track-metadata-position="nav">
  
    <span class="devsite-nav-text" tooltip="">
      TensorFlow
   </span>
    
  
  </a>
  

</li>

            
          
        
      </ul>
    
  
        
        
      </div>
    
  </div>
</nav>
        
      </devsite-book-nav><div class="devsite-book-nav-blur" hidden="" fixed="" style="--devsite-js-book-nav-scrollbar-width:0px;"></div><button class="devsite-book-nav-toggle" aria-haspopup="menu" hidden="" fixed="" aria-label="Hide side navigation" data-title="Hide side navigation" aria-expanded="true"><span class="material-icons devsite-book-nav-toggle-icon"></span></button>
      <section id="gc-wrapper" style="margin-top: 120.8px;">
        <main role="main" class="devsite-main-content" has-sidebar="">
          
          <div class="devsite-sidebar" fixed="" style="--devsite-js-sidebar-max-height:866.2px; --devsite-js-sidebar-max-width:507.2px; --devsite-js-sidebar-offset:-72px;">
            <div class="devsite-sidebar-content">
              
              <devsite-toc class="devsite-nav devsite-toc" role="navigation" aria-label="On this page" depth="2" scrollbars="" visible=""><ul class="devsite-nav-list"><li class="devsite-nav-item devsite-nav-heading devsite-toc-toggle" role="heading" aria-level="2"><span class="devsite-nav-title"><span class="devsite-nav-text">On this page</span></span></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#a" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="0" track-type="navigation" track-name="rightNav" track-metadata-position="0" track-metadata-link-destination="#a"><span class="devsite-nav-text" tooltip="">A</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#b" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="1" track-type="navigation" track-name="rightNav" track-metadata-position="1" track-metadata-link-destination="#b"><span class="devsite-nav-text" tooltip="">B</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#c" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="2" track-type="navigation" track-name="rightNav" track-metadata-position="2" track-metadata-link-destination="#c"><span class="devsite-nav-text" tooltip="">C</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#d" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="3" track-type="navigation" track-name="rightNav" track-metadata-position="3" track-metadata-link-destination="#d"><span class="devsite-nav-text" tooltip="">D</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#e" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="4" track-type="navigation" track-name="rightNav" track-metadata-position="4" track-metadata-link-destination="#e"><span class="devsite-nav-text" tooltip="">E</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#f" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="5" track-type="navigation" track-name="rightNav" track-metadata-position="5" track-metadata-link-destination="#f"><span class="devsite-nav-text" tooltip="">F</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#g" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="6" track-type="navigation" track-name="rightNav" track-metadata-position="6" track-metadata-link-destination="#g"><span class="devsite-nav-text" tooltip="">G</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#h" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="7" track-type="navigation" track-name="rightNav" track-metadata-position="7" track-metadata-link-destination="#h"><span class="devsite-nav-text" tooltip="">H</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#i" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="8" track-type="navigation" track-name="rightNav" track-metadata-position="8" track-metadata-link-destination="#i"><span class="devsite-nav-text" tooltip="">I</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#k" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="9" track-type="navigation" track-name="rightNav" track-metadata-position="9" track-metadata-link-destination="#k"><span class="devsite-nav-text" tooltip="">K</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#l" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="10" track-type="navigation" track-name="rightNav" track-metadata-position="10" track-metadata-link-destination="#l"><span class="devsite-nav-text" tooltip="">L</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#m" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="11" track-type="navigation" track-name="rightNav" track-metadata-position="11" track-metadata-link-destination="#m"><span class="devsite-nav-text" tooltip="">M</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#n" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="12" track-type="navigation" track-name="rightNav" track-metadata-position="12" track-metadata-link-destination="#n"><span class="devsite-nav-text" tooltip="">N</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#o" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="13" track-type="navigation" track-name="rightNav" track-metadata-position="13" track-metadata-link-destination="#o"><span class="devsite-nav-text" tooltip="">O</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#p" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="14" track-type="navigation" track-name="rightNav" track-metadata-position="14" track-metadata-link-destination="#p"><span class="devsite-nav-text" tooltip="">P</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#q" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="15" track-type="navigation" track-name="rightNav" track-metadata-position="15" track-metadata-link-destination="#q"><span class="devsite-nav-text" tooltip="">Q</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#r" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="16" track-type="navigation" track-name="rightNav" track-metadata-position="16" track-metadata-link-destination="#r"><span class="devsite-nav-text" tooltip="">R</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#s" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="17" track-type="navigation" track-name="rightNav" track-metadata-position="17" track-metadata-link-destination="#s"><span class="devsite-nav-text" tooltip="">S</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#t" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="18" track-type="navigation" track-name="rightNav" track-metadata-position="18" track-metadata-link-destination="#t"><span class="devsite-nav-text" tooltip="">T</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#u" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="19" track-type="navigation" track-name="rightNav" track-metadata-position="19" track-metadata-link-destination="#u"><span class="devsite-nav-text" tooltip="">U</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#v" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="20" track-type="navigation" track-name="rightNav" track-metadata-position="20" track-metadata-link-destination="#v"><span class="devsite-nav-text" tooltip="">V</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#w" class="devsite-nav-title gc-analytics-event devsite-nav-active" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="21" track-type="navigation" track-name="rightNav" track-metadata-position="21" track-metadata-link-destination="#w"><span class="devsite-nav-text" tooltip="">W</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#z" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Right nav" data-value="22" track-type="navigation" track-name="rightNav" track-metadata-position="22" track-metadata-link-destination="#z"><span class="devsite-nav-text" tooltip="">Z</span></a></li></ul></devsite-toc>
              <devsite-recommendations-sidebar class="nocontent devsite-nav recommendations-rendered"><div class="devsite-recommendations-sidebar-heading" role="heading" aria-level="2"><a href="https://developers.google.com/machine-learning/glossary#recommendations-link" class="devsite-nav-title devsite-recommendations-sidebar-heading-link" data-category="Site-Wide Custom Events" data-label="devsite-recommendation side-nav title" data-action="click" data-tooltip="See content recommendations"><svg class="devsite-recommendations-sidebar-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" aria-hidden="true"><path d="M12.5,8.5L10,3L7.5,8.5L2,11l5.5,2.5L10,19l2.5-5.5L18,11L12.5,8.5z M18,13l-1.25,2.75L14,17l2.75,1.25L18,21l1.25-2.75 L22,17l-2.75-1.25L18,13z"></path></svg><span class="devsite-nav-text devsite-nav-title">Recommended for you</span></a></div><ul class="devsite-nav-list"><li role="option" class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/crash-course/prereqs-and-prework?rec=CjdodHRwczovL2RldmVsb3BlcnMuZ29vZ2xlLmNvbS9tYWNoaW5lLWxlYXJuaW5nL2dsb3NzYXJ5EAEYDSABKAMwFjoIMzkzMDAzNzc" class="devsite-nav-title devsite-recommendations-sidebar-title" data-category="Site-Wide Custom Events" data-label="devsite-recommendation side-nav link" data-action="click"><span class="devsite-nav-text" tooltip="">Prerequisites and Prework</span></a><div class="significatio-card-meta">Updated <span class="significatio-date" date="1658177971">19 Jul 2022</span></div></li><li role="option" class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/crash-course?rec=CjdodHRwczovL2RldmVsb3BlcnMuZ29vZ2xlLmNvbS9tYWNoaW5lLWxlYXJuaW5nL2dsb3NzYXJ5EAIYDSABMB86CDM5MzAwMzc3" class="devsite-nav-title devsite-recommendations-sidebar-title" data-category="Site-Wide Custom Events" data-label="devsite-recommendation side-nav link" data-action="click"><span class="devsite-nav-text" tooltip="">Machine Learning</span></a><div class="significatio-card-meta">Updated <span class="significatio-date" date="1658177971">19 Jul 2022</span></div></li><li role="option" class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/crash-course/ml-intro?rec=CjdodHRwczovL2RldmVsb3BlcnMuZ29vZ2xlLmNvbS9tYWNoaW5lLWxlYXJuaW5nL2dsb3NzYXJ5EAMYDSABKAQwBDoIMzkzMDAzNzc" class="devsite-nav-title devsite-recommendations-sidebar-title" data-category="Site-Wide Custom Events" data-label="devsite-recommendation side-nav link" data-action="click"><span class="devsite-nav-text" tooltip="">Introduction to Machine Learning</span></a><div class="significatio-card-meta">Updated <span class="significatio-date" date="1658177971">19 Jul 2022</span></div></li></ul></devsite-recommendations-sidebar>
            </div>
          </div>
          <devsite-content>
            
              











<article class="devsite-article" has-bookmark=""><style>
      /* Styles inlined from /machine-learning/glossary/glossary.css */
/* Drop display of empty description row */
.devsite-product-description-row {
  display: none;
}

h2.glossary {
  border: none;
  padding-top: 25px;
  margin-top: 30px;
  margin-bottom: 10px;
  font-weight: bold;
}

h2.hide-from-toc {
  border-bottom: none;
  border-top: 1px solid #ebebeb;
  padding-top: 1%;
  margin-bottom: 1px;
}

a.glossary-anchor {
  display: block;
  padding-top: 40px;
}

@media screen and (min-width: 720px) {

  /* Styling for intersection/union images in IoU entry */
  /* Place images side by side if not on phone */
  #intersection-union-side-by-side img {
    display: inline-block;
    width: 45%;
    margin-right: 4.5%;
  }

  /* Styling for tables in sparse representation section */
  /* Use two-column layout if not on phone */
  #sparse-dense-tables {
    width: 80%;
    margin-left: auto;
    margin-right: auto;
    column-count: 2;
    column-width: 45%;
  }

  #sparse-dense-tables table {
    break-after: column;
  }
}

#sparse-dense-tables table caption {
  background: none;
}

#sparse-dense-tables table tr.elided-rows td {
  text-align: center;
}

.glossary-icon-container {
  float: right;
  position: relative;
  top: -34px;
}

/* Push glossary icons 40px to the left
 * to match 40px of right padding
 * applied to heading elements
 */
h2 + .glossary-icon-container {
  right: 40px;
}

/* Push sequence glossary icon to the left
 * an additional 100px, as it's a bit wider
 */
h2 + .glossary-icon-container
.glossary-icon[data-title='Sequence Models'] {
  right: 100px;
}

.glossary-icon {
  color: transparent;
  float: left;
  font-size: 5px;
  position: relative;
}

.glossary-icon::after {
  background-color: white;
  position: absolute;
  left: 0;
}

.glossary-icon[title='Fairness'], .glossary-icon[data-title='Fairness'],
.glossary-icon[title='ML Fundamentals'], .glossary-icon[data-title='ML Fundamentals'],
.glossary-icon[title='Recommendation Systems'], .glossary-icon[data-title='Recommendation Systems'],
.glossary-icon[title='Image Models'], .glossary-icon[data-title='Image Models'],
.glossary-icon[title='Clustering'], .glossary-icon[data-title='Clustering'],
.glossary-icon[title='Language Evaluation'], .glossary-icon[data-title='Language Evaluation'],
.glossary-icon[title='Sequence Models'], .glossary-icon[data-title='Sequence Models'],
.glossary-icon[title='Decision Forests'], .glossary-icon[data-title='Decision Forests']
{
  font-size: 7px;
  top: 4px;
}

.glossary-icon[title='Fairness']::after, .glossary-icon[data-title='Fairness']::after,
.glossary-icon[title='ML Fundamentals']::after, .glossary-icon[data-title='ML Fundamentals']::after,
.glossary-icon[title='Recommendation Systems']::after, .glossary-icon[data-title='Recommendation Systems']::after,
.glossary-icon[title='Image Models']::after, .glossary-icon[data-title='Image Models']::after,
.glossary-icon[title='Clustering']::after, .glossary-icon[data-title='Clustering']::after,
.glossary-icon[title='Language Evaluation'], .glossary-icon[data-title='Language Evaluation']::after,
.glossary-icon[title='Sequence Models'], .glossary-icon[data-title='Sequence Models']::after,
.glossary-icon[title='Decision Forests'], .glossary-icon[data-title='Decision Forests']::after
{
  color: initial;
  font-size: 25px;
  text-align: center;
}

.glossary-icon[title='Fairness']::after, .glossary-icon[data-title='Fairness']::after {
  content: '⚖️';
  width: 32px;
}

.glossary-icon[title='ML Fundamentals']::after, .glossary-icon[data-title='ML Fundamentals']::after {
  content: '🐣';
  width: 32px;
}

.glossary-icon[title='Image Models']::after, .glossary-icon[data-title='Image Models']::after {
  content: '🖼️';
  width: 32px;
}

.glossary-icon[title='Clustering']::after, .glossary-icon[data-title='Clustering']::after {
  content: '🍇';
  width: 32px;
}

.glossary-icon[title='Language Evaluation']::after, .glossary-icon[data-title='Language Evaluation']::after {
  content: '🔤';
  width: 32px;
}

.glossary-icon[title='Sequence Models']::after, .glossary-icon[data-title='Sequence Models']::after {
  content: '🔺→🟦→🟡';
  width: 96px;
  font-size: 1vw;
}

.glossary-icon[title='Decision Forests']::after, .glossary-icon[data-title='Decision Forests']::after {
  content: '🌳🌲🌳';
  width: 64px;
  letter-spacing: -0.45em;
  font-size: 1vw;
}

.glossary-icon[title='Recommendation Systems']::after, .glossary-icon[data-title='Recommendation Systems']::after {
  content: '👎👍';
  width: 64px;
}

.glossary-icon[title='Google Cloud']::after, .glossary-icon[data-title='Google Cloud']::after {
  background-position: center;
  background-repeat: no-repeat;
  content: "";
  width: 37px;
  background-image: url(https://www.gstatic.com/images/branding/product/1x/google_cloud_48dp.png);
  background-size: 28px 28px;
  height: 29px;
}

.glossary-icon[title='Reinforcement Learning'], .glossary-icon[data-title='Reinforcement Learning'] {
  font-size: 7px;
  top: 4px;
  right: 24px;
}

.glossary-icon[title='Reinforcement Learning']::after, .glossary-icon[data-title='Reinforcement Learning']::after {
  color: rgb(139, 0, 0);
  content: 'RL';
  font-size: 25px;
  text-align: center;
  width: 32px;
  margin-right: 16px;
}

.glossary-icon[title='TensorFlow']::after, .glossary-icon[data-title='TensorFlow']::after {
  background-position: center;
  background-repeat: no-repeat;
  content: "";
  width: 30px;
  background-image: url(https://developers.google.com/site-assets/logo-tensorflow.svg);
  background-size: 26px 26px;
  height: 28px;
}

      </style>
  
  
  

  <div class="devsite-article-meta nocontent" role="navigation">
    
    
    <ul class="devsite-breadcrumb-list" aria-label="Breadcrumb">
  
  <li class="devsite-breadcrumb-item
             ">
    
    
    
      
  <a href="https://developers.google.com/" class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="1" track-type="globalNav" track-name="breadcrumb" track-metadata-position="1" track-metadata-eventdetail="">
    
        Home
      
  </a>
  
    
  </li>
  
  <li class="devsite-breadcrumb-item
             ">
    
      
      <div class="devsite-breadcrumb-guillemet material-icons" aria-hidden="true"></div>
    
    
    
      
  <a href="https://developers.google.com/products" class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="2" track-type="globalNav" track-name="breadcrumb" track-metadata-position="2" track-metadata-eventdetail="">
    
        Products
      
  </a>
  
    
  </li>
  
  <li class="devsite-breadcrumb-item
             ">
    
      
      <div class="devsite-breadcrumb-guillemet material-icons" aria-hidden="true"></div>
    
    
    
      
  <a href="https://developers.google.com/machine-learning" class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="3" track-type="globalNav" track-name="breadcrumb" track-metadata-position="3" track-metadata-eventdetail="Machine Learning">
    
        Machine Learning
      
  </a>
  
    
  </li>
  
  <li class="devsite-breadcrumb-item
             ">
    
      
      <div class="devsite-breadcrumb-guillemet material-icons" aria-hidden="true"></div>
    
    
    
      
  <a href="https://developers.google.com/machine-learning/glossary" class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="4" track-type="globalNav" track-name="breadcrumb" track-metadata-position="4" track-metadata-eventdetail="">
    
        Glossary
      
  </a>
  
    
  </li>
  
</ul>
    
      
    <devsite-thumb-rating position="header"><div class="devsite-thumb-rating" role="form" aria-labelledby="devsite-thumb-label-header" tabindex="0"><div class="devsite-thumb-label" id="devsite-thumb-label-header">Was this helpful?</div><div class="devsite-thumbs"><button class="devsite-thumb devsite-thumb-up" data-title="Helpful" aria-label="Helpful"><svg class="devsite-thumb-icon" viewBox="0 0 24 24" aria-hidden="true"><path d="M21,7h-6.31l0.95-4.57l0.03-0.32c0-0.41-0.17-0.79-0.44-1.06L14.17,0c0,0-7.09,6.85-7.17,7H2v13h16 c0.83,0,1.54-0.5,1.84-1.22l3.02-7.05C22.95,11.5,23,11.26,23,11V9C23,7.9,22.1,7,21,7z M7,18H4V9h3V18z M21,11l-3,7H9V8l4.34-4.34 L12,9h9V11z"></path></svg></button><button class="devsite-thumb devsite-thumb-down" data-title="Not helpful" aria-label="Not helpful"><svg class="devsite-thumb-icon" viewBox="0 0 24 24" aria-hidden="true"><path d="M3,17h6.31l-0.95,4.57l-0.03,0.32c0,0.41,0.17,0.79,0.44,1.06L9.83,24c0,0,7.09-6.85,7.17-7h5V4H6 C5.17,4,4.46,4.5,4.16,5.22l-3.02,7.05C1.05,12.5,1,12.74,1,13v2C1,16.1,1.9,17,3,17z M17,6h3v9h-3V6z M3,13l3-7h9v10l-4.34,4.34 L12,15H3V13z"></path></svg></button></div></div></devsite-thumb-rating>
  
    
  </div>
  
    <devsite-feedback position="header" project-name="Machine Learning" product-id="5005867" bucket="" context="" version="t-devsite-webserver-20230110-r01-rc00.449249680248403396" data-label="Send Feedback Button" track-type="feedback" track-name="sendFeedbackLink" track-metadata-position="header" project-icon="https://www.gstatic.com/devrel-devsite/prod/v4fdbc33a55781dc592d32bc0c5d1eb8f6c96a05c8dafb5ba814fcab1c6bf1229/developers/images/touchicon-180.png" feedback-type="thumb-rating">

  <button>
  
    
    Send feedback
  
  </button>
</devsite-feedback>
  <h1 class="devsite-page-title">Machine Learning Glossary</h1><devsite-feature-tooltip ack-key="AckCollectionsBookmarkTooltipDismiss" analytics-category="Site-Wide Custom Events" analytics-action-show="Callout Profile displayed" analytics-action-close="Callout Profile dismissed" analytics-label="Create Collection Callout" class="devsite-page-bookmark-tooltip inline-block" dismiss-button="true" id="devsite-collections-dropdown" dismiss-button-text="Dismiss" close-button-text="Got it" ready="" current-step="0" style="--devsite-popout-offset-x:32px;">

        
        <devsite-bookmark class="show"><devsite-dropdown-list ellipsis="" checkboxes="" fetchingitems="true" writable="" additemtext="New Collection" ready="" style="--devsite-popout-offset-x:0px;"><span class="material-icons bookmark-icon" slot="toggle">bookmark_border</span></devsite-dropdown-list></devsite-bookmark>

        <span slot="popout-heading">
          
          Stay organized with collections
        </span>
        <span slot="popout-contents">
          
          Save and categorize content based on your preferences.
        </span>
      </devsite-feature-tooltip>
    
  
  <devsite-toc class="devsite-nav devsite-toc-embedded" depth="2" devsite-toc-embedded="" expandable="" visible=""><ul class="devsite-nav-list"><li class="devsite-nav-item devsite-nav-heading devsite-toc-toggle" role="heading" aria-level="2"><span class="devsite-nav-title"><span class="devsite-nav-text">On this page</span></span><button type="button" title="Expand/collapse contents" class="devsite-nav-show-all button-transparent material-icons"></button></li><li class="devsite-nav-item" visible=""><a href="https://developers.google.com/machine-learning/glossary#a" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="0" track-type="navigation" track-name="embeddedNav" track-metadata-position="0" track-metadata-link-destination="#a"><span class="devsite-nav-text" tooltip="">A</span></a></li><li class="devsite-nav-item" visible=""><a href="https://developers.google.com/machine-learning/glossary#b" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="1" track-type="navigation" track-name="embeddedNav" track-metadata-position="1" track-metadata-link-destination="#b"><span class="devsite-nav-text" tooltip="">B</span></a></li><li class="devsite-nav-item" visible=""><a href="https://developers.google.com/machine-learning/glossary#c" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="2" track-type="navigation" track-name="embeddedNav" track-metadata-position="2" track-metadata-link-destination="#c"><span class="devsite-nav-text" tooltip="">C</span></a></li><li class="devsite-nav-item" visible=""><a href="https://developers.google.com/machine-learning/glossary#d" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="3" track-type="navigation" track-name="embeddedNav" track-metadata-position="3" track-metadata-link-destination="#d"><span class="devsite-nav-text" tooltip="">D</span></a></li><li class="devsite-nav-item" visible=""><a href="https://developers.google.com/machine-learning/glossary#e" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="4" track-type="navigation" track-name="embeddedNav" track-metadata-position="4" track-metadata-link-destination="#e"><span class="devsite-nav-text" tooltip="">E</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#f" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="5" track-type="navigation" track-name="embeddedNav" track-metadata-position="5" track-metadata-link-destination="#f"><span class="devsite-nav-text" tooltip="">F</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#g" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="6" track-type="navigation" track-name="embeddedNav" track-metadata-position="6" track-metadata-link-destination="#g"><span class="devsite-nav-text" tooltip="">G</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#h" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="7" track-type="navigation" track-name="embeddedNav" track-metadata-position="7" track-metadata-link-destination="#h"><span class="devsite-nav-text" tooltip="">H</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#i" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="8" track-type="navigation" track-name="embeddedNav" track-metadata-position="8" track-metadata-link-destination="#i"><span class="devsite-nav-text" tooltip="">I</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#k" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="9" track-type="navigation" track-name="embeddedNav" track-metadata-position="9" track-metadata-link-destination="#k"><span class="devsite-nav-text" tooltip="">K</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#l" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="10" track-type="navigation" track-name="embeddedNav" track-metadata-position="10" track-metadata-link-destination="#l"><span class="devsite-nav-text" tooltip="">L</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#m" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="11" track-type="navigation" track-name="embeddedNav" track-metadata-position="11" track-metadata-link-destination="#m"><span class="devsite-nav-text" tooltip="">M</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#n" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="12" track-type="navigation" track-name="embeddedNav" track-metadata-position="12" track-metadata-link-destination="#n"><span class="devsite-nav-text" tooltip="">N</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#o" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="13" track-type="navigation" track-name="embeddedNav" track-metadata-position="13" track-metadata-link-destination="#o"><span class="devsite-nav-text" tooltip="">O</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#p" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="14" track-type="navigation" track-name="embeddedNav" track-metadata-position="14" track-metadata-link-destination="#p"><span class="devsite-nav-text" tooltip="">P</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#q" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="15" track-type="navigation" track-name="embeddedNav" track-metadata-position="15" track-metadata-link-destination="#q"><span class="devsite-nav-text" tooltip="">Q</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#r" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="16" track-type="navigation" track-name="embeddedNav" track-metadata-position="16" track-metadata-link-destination="#r"><span class="devsite-nav-text" tooltip="">R</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#s" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="17" track-type="navigation" track-name="embeddedNav" track-metadata-position="17" track-metadata-link-destination="#s"><span class="devsite-nav-text" tooltip="">S</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#t" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="18" track-type="navigation" track-name="embeddedNav" track-metadata-position="18" track-metadata-link-destination="#t"><span class="devsite-nav-text" tooltip="">T</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#u" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="19" track-type="navigation" track-name="embeddedNav" track-metadata-position="19" track-metadata-link-destination="#u"><span class="devsite-nav-text" tooltip="">U</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#v" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="20" track-type="navigation" track-name="embeddedNav" track-metadata-position="20" track-metadata-link-destination="#v"><span class="devsite-nav-text" tooltip="">V</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#w" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="21" track-type="navigation" track-name="embeddedNav" track-metadata-position="21" track-metadata-link-destination="#w"><span class="devsite-nav-text" tooltip="">W</span></a></li><li class="devsite-nav-item"><a href="https://developers.google.com/machine-learning/glossary#z" class="devsite-nav-title gc-analytics-event" data-category="Site-Wide Custom Events" data-action="click" data-label="Embedded nav" data-value="22" track-type="navigation" track-name="embeddedNav" track-metadata-position="22" track-metadata-link-destination="#z"><span class="devsite-nav-text" tooltip="">Z</span></a></li><li class="devsite-toc-toggle"><button type="button" class="button-flat devsite-nav-more-items material-icons" track-type="navigation" track-name="embeddedNavExpand" title="Expand/collapse contents"></button></li></ul></devsite-toc>

  
  <devsite-recommendations-dropdown class="nocontent"></devsite-recommendations-dropdown>
  

  






<div class="devsite-article-body clearfix
  ">

  
    




































<devsite-mathjax config="TeX-AMS-MML_SVG"></devsite-mathjax><p></p>




<p>This glossary defines general machine learning terms, plus
terms specific to TensorFlow.</p>

<aside class="key-point">
  <h4 id="did-you-know" data-text="Did You Know?" role="presentation"><span class="devsite-heading" role="heading" aria-level="4">Did You Know?</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: Did You Know?" data-title="Copy link to this section: Did You Know?" data-id="did-you-know"></button></h4>
  <p>You can <strong>filter the glossary</strong> by choosing a topic from
     the Glossary dropdown in the top navigation bar.
     The hatching bird icon signifies definitions aimed at ML newcomers.</p>
</aside>

<p><a class="glossary-anchor" name="a"></a>
</p><h2 class="glossary" id="a" data-text="A" role="presentation"><span class="devsite-heading" role="heading" aria-level="2">A</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: A" data-title="Copy link to this section: A" data-id="a"></button></h2><p></p>

<p><a class="glossary-anchor" name="AB_testing"></a>
</p><h2 class="hide-from-toc" id="ab-testing" data-text=" A/B testing" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> A/<wbr>B testing</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  A/B testing" data-title="Copy link to this section:  A/B testing" data-id="ab-testing"></button></h2><p></p>

<p>A statistical way of comparing two (or more) techniques—the <em>A</em>
and the <em>B</em>. Typically, the <em>A</em> is an existing technique, and the
<em>B</em> is a new technique.
A/B testing not only determines which technique performs better
but also whether the difference is statistically significant.</p>

<p>A/B testing usually compares a single <a href="https://developers.google.com/machine-learning/glossary#metric"><strong>metric</strong></a> on two techniques;
for example, how does model <a href="https://developers.google.com/machine-learning/glossary#accuracy"><strong>accuracy</strong></a> compare for two
techniques? However, A/B testing can also compare any finite number of
metrics.</p>

<p><a class="glossary-anchor" name="accuracy"></a>
</p><h2 class="hide-from-toc" id="accuracy" data-text=" accuracy" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> accuracy</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  accuracy" data-title="Copy link to this section:  accuracy" data-id="accuracy"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The number of correct classification <a href="https://developers.google.com/machine-learning/glossary#prediction"><strong>predictions</strong></a> divided
by the total number of predictions. That is:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Accuracy&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtext&gt;correct predictions&lt;/mtext&gt;&lt;mtext&gt;correct predictions + incorrect predictions&amp;#xA0;&lt;/mtext&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="56.257ex" height="5.571ex" viewBox="0 -1428.7 24221.6 2398.8" role="img" focusable="false" style="vertical-align: -2.253ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-41"></use><use href="#MJMAIN-63" x="750" y="0"></use><use href="#MJMAIN-63" x="1195" y="0"></use><use href="#MJMAIN-75" x="1639" y="0"></use><use href="#MJMAIN-72" x="2196" y="0"></use><use href="#MJMAIN-61" x="2588" y="0"></use><use href="#MJMAIN-63" x="3089" y="0"></use><use href="#MJMAIN-79" x="3533" y="0"></use><use href="#MJMAIN-3D" x="4339" y="0"></use><g transform="translate(5118,0)"><g transform="translate(397,0)"><rect stroke="none" width="18585" height="60" x="0" y="220"></rect><g transform="translate(5267,676)"><use href="#MJMAIN-63"></use><use href="#MJMAIN-6F" x="444" y="0"></use><use href="#MJMAIN-72" x="945" y="0"></use><use href="#MJMAIN-72" x="1337" y="0"></use><use href="#MJMAIN-65" x="1730" y="0"></use><use href="#MJMAIN-63" x="2174" y="0"></use><use href="#MJMAIN-74" x="2619" y="0"></use><use href="#MJMAIN-70" x="3258" y="0"></use><use href="#MJMAIN-72" x="3815" y="0"></use><use href="#MJMAIN-65" x="4207" y="0"></use><use href="#MJMAIN-64" x="4652" y="0"></use><use href="#MJMAIN-69" x="5208" y="0"></use><use href="#MJMAIN-63" x="5487" y="0"></use><use href="#MJMAIN-74" x="5931" y="0"></use><use href="#MJMAIN-69" x="6321" y="0"></use><use href="#MJMAIN-6F" x="6599" y="0"></use><use href="#MJMAIN-6E" x="7100" y="0"></use><use href="#MJMAIN-73" x="7656" y="0"></use></g><g transform="translate(60,-686)"><use href="#MJMAIN-63"></use><use href="#MJMAIN-6F" x="444" y="0"></use><use href="#MJMAIN-72" x="945" y="0"></use><use href="#MJMAIN-72" x="1337" y="0"></use><use href="#MJMAIN-65" x="1730" y="0"></use><use href="#MJMAIN-63" x="2174" y="0"></use><use href="#MJMAIN-74" x="2619" y="0"></use><use href="#MJMAIN-70" x="3258" y="0"></use><use href="#MJMAIN-72" x="3815" y="0"></use><use href="#MJMAIN-65" x="4207" y="0"></use><use href="#MJMAIN-64" x="4652" y="0"></use><use href="#MJMAIN-69" x="5208" y="0"></use><use href="#MJMAIN-63" x="5487" y="0"></use><use href="#MJMAIN-74" x="5931" y="0"></use><use href="#MJMAIN-69" x="6321" y="0"></use><use href="#MJMAIN-6F" x="6599" y="0"></use><use href="#MJMAIN-6E" x="7100" y="0"></use><use href="#MJMAIN-73" x="7656" y="0"></use><use href="#MJMAIN-2B" x="8301" y="0"></use><use href="#MJMAIN-69" x="9329" y="0"></use><use href="#MJMAIN-6E" x="9608" y="0"></use><use href="#MJMAIN-63" x="10164" y="0"></use><use href="#MJMAIN-6F" x="10609" y="0"></use><use href="#MJMAIN-72" x="11109" y="0"></use><use href="#MJMAIN-72" x="11502" y="0"></use><use href="#MJMAIN-65" x="11894" y="0"></use><use href="#MJMAIN-63" x="12339" y="0"></use><use href="#MJMAIN-74" x="12783" y="0"></use><use href="#MJMAIN-70" x="13423" y="0"></use><use href="#MJMAIN-72" x="13979" y="0"></use><use href="#MJMAIN-65" x="14372" y="0"></use><use href="#MJMAIN-64" x="14816" y="0"></use><use href="#MJMAIN-69" x="15373" y="0"></use><use href="#MJMAIN-63" x="15651" y="0"></use><use href="#MJMAIN-74" x="16096" y="0"></use><use href="#MJMAIN-69" x="16485" y="0"></use><use href="#MJMAIN-6F" x="16764" y="0"></use><use href="#MJMAIN-6E" x="17264" y="0"></use><use href="#MJMAIN-73" x="17821" y="0"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Accuracy</mtext><mo>=</mo><mfrac><mtext>correct predictions</mtext><mtext>correct predictions + incorrect predictions&nbsp;</mtext></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-1">\text{Accuracy} =
\frac{\text{correct predictions}} {\text{correct predictions + incorrect predictions }}</script>
</div>

<p>For example, a model that made 40 correct predictions and 10 incorrect
predictions would have an accuracy of:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Accuracy&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtext&gt;40&lt;/mtext&gt;&lt;mtext&gt;40 + 10&lt;/mtext&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mtext&gt;80%&lt;/mtext&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="28.347ex" height="5.335ex" viewBox="0 -1428.7 12205.1 2296.9" role="img" focusable="false" style="vertical-align: -2.016ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-41"></use><use href="#MJMAIN-63" x="750" y="0"></use><use href="#MJMAIN-63" x="1195" y="0"></use><use href="#MJMAIN-75" x="1639" y="0"></use><use href="#MJMAIN-72" x="2196" y="0"></use><use href="#MJMAIN-61" x="2588" y="0"></use><use href="#MJMAIN-63" x="3089" y="0"></use><use href="#MJMAIN-79" x="3533" y="0"></use><use href="#MJMAIN-3D" x="4339" y="0"></use><g transform="translate(5118,0)"><g transform="translate(397,0)"><rect stroke="none" width="3400" height="60" x="0" y="220"></rect><g transform="translate(1199,676)"><use href="#MJMAIN-34"></use><use href="#MJMAIN-30" x="500" y="0"></use></g><g transform="translate(60,-686)"><use href="#MJMAIN-34"></use><use href="#MJMAIN-30" x="500" y="0"></use><use href="#MJMAIN-2B" x="1251" y="0"></use><use href="#MJMAIN-31" x="2279" y="0"></use><use href="#MJMAIN-30" x="2780" y="0"></use></g></g></g><use href="#MJMAIN-3D" x="9314" y="0"></use><g transform="translate(10370,0)"><use href="#MJMAIN-38"></use><use href="#MJMAIN-30" x="500" y="0"></use><use href="#MJMAIN-25" x="1001" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Accuracy</mtext><mo>=</mo><mfrac><mtext>40</mtext><mtext>40 + 10</mtext></mfrac><mo>=</mo><mtext>80%</mtext></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-2">\text{Accuracy} =
\frac{\text{40}} {\text{40 + 10}} =
\text{80%}</script>
</div>

<p><a href="https://developers.google.com/machine-learning/glossary#binary_classification"><strong>Binary classification</strong></a> provides specific names
for the different categories of <em>correct predictions</em> and
<em>incorrect predictions</em>. So, the accuracy formula for binary classification
is as follows:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Accuracy&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mtext&gt;TP&lt;/mtext&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;TN&lt;/mtext&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mtext&gt;TP&lt;/mtext&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;TN&lt;/mtext&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;FP&lt;/mtext&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;FN&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="34.289ex" height="5.335ex" viewBox="0 -1428.7 14763.1 2296.9" role="img" focusable="false" style="vertical-align: -2.016ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-41"></use><use href="#MJMAIN-63" x="750" y="0"></use><use href="#MJMAIN-63" x="1195" y="0"></use><use href="#MJMAIN-75" x="1639" y="0"></use><use href="#MJMAIN-72" x="2196" y="0"></use><use href="#MJMAIN-61" x="2588" y="0"></use><use href="#MJMAIN-63" x="3089" y="0"></use><use href="#MJMAIN-79" x="3533" y="0"></use><use href="#MJMAIN-3D" x="4339" y="0"></use><g transform="translate(5118,0)"><g transform="translate(120,0)"><rect stroke="none" width="9404" height="60" x="0" y="220"></rect><g transform="translate(2652,676)"><use href="#MJMAIN-54"></use><use href="#MJMAIN-50" x="722" y="0"></use><use href="#MJMAIN-2B" x="1626" y="0"></use><g transform="translate(2626,0)"><use href="#MJMAIN-54"></use><use href="#MJMAIN-4E" x="722" y="0"></use></g></g><g transform="translate(60,-686)"><use href="#MJMAIN-54"></use><use href="#MJMAIN-50" x="722" y="0"></use><use href="#MJMAIN-2B" x="1626" y="0"></use><g transform="translate(2626,0)"><use href="#MJMAIN-54"></use><use href="#MJMAIN-4E" x="722" y="0"></use></g><use href="#MJMAIN-2B" x="4322" y="0"></use><g transform="translate(5322,0)"><use href="#MJMAIN-46"></use><use href="#MJMAIN-50" x="653" y="0"></use></g><use href="#MJMAIN-2B" x="6880" y="0"></use><g transform="translate(7880,0)"><use href="#MJMAIN-46"></use><use href="#MJMAIN-4E" x="653" y="0"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Accuracy</mtext><mo>=</mo><mfrac><mrow><mtext>TP</mtext><mo>+</mo><mtext>TN</mtext></mrow><mrow><mtext>TP</mtext><mo>+</mo><mtext>TN</mtext><mo>+</mo><mtext>FP</mtext><mo>+</mo><mtext>FN</mtext></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-3">\text{Accuracy} = \frac{\text{TP} + \text{TN}}
                         {\text{TP} + \text{TN} + \text{FP} + \text{FN}}</script>
</div>

<p>where:</p>

<ul>
<li>TP is the number of <a href="https://developers.google.com/machine-learning/glossary#TP"><strong>true positives</strong></a> (correct predictions).</li>
<li>TN is the number of <a href="https://developers.google.com/machine-learning/glossary#TN"><strong>true negatives</strong></a> (correct predictions).</li>
<li>FP is the number of <a href="https://developers.google.com/machine-learning/glossary#FP"><strong>false positives</strong></a> (incorrect predictions).</li>
<li>FN is the number of <a href="https://developers.google.com/machine-learning/glossary#FN"><strong>false negatives</strong></a> (incorrect predictions).</li>
</ul>

<p>Compare and contrast accuracy with
<a href="https://developers.google.com/machine-learning/glossary#precision"><strong>precision</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#recall"><strong>recall</strong></a>.</p>

<devsite-expandable is-upgraded="" id="expandable-1"><a class="exw-control" aria-controls="expandable-1" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-additional-notes." data-text=" Click the icon for additional notes. " role="presentation"><span class="devsite-heading" role="heading" aria-level="4">
Click the icon for additional notes.<wbr>
</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: 
Click the icon for additional notes.
" data-title="Copy link to this section: 
Click the icon for additional notes.
" data-id="click-the-icon-for-additional-notes."></button></h4></a>



<div class="expand-background">
<p>
Although a valuable metric for some situations, accuracy is highly
misleading for others. Notably, accuracy is usually a poor metric
for evaluating classification models that process
<a href="https://developers.google.com/machine-learning/glossary#class_imbalanced_data_set"><b>class-imbalanced datasets</b></a>.
</p>

<p>
For example, suppose snow falls only 25 days per century in a certain
subtropical city. Since days without snow (the negative class) vastly
outnumber days with snow (the positive class), the snow dataset for
this city is class-imbalanced.
Imagine a <a href="https://developers.google.com/machine-learning/glossary#binary-classification"><b>binary classification</b></a>
model that is supposed to predict either snow or no snow each day but
simply predicts "no snow" every day.
This model is highly accurate but has no predictive power.
The following table summarizes the results for a century of predictions:
</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr><th>Category</th> <th>Number</th> <th></th></tr>
  <tr><td>TP</td> <td>0</td>     </tr>
  <tr><td>TN</td> <td>36500</td> </tr>
  <tr><td>FP</td> <td>25</td>    </tr>
  <tr><td>FN</td> <td>0</td>     </tr>
</tbody></table></div>

<p>The accuracy of this model is therefore:</p>

<devsite-code data-copy-event-label=""><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="pln">accuracy </span><span class="pun">=</span><span class="pln"> </span><span class="pun">(</span><span class="pln">TP </span><span class="pun">+</span><span class="pln"> TN</span><span class="pun">)</span><span class="pln"> </span><span class="pun">/</span><span class="pln"> </span><span class="pun">(</span><span class="pln">TP </span><span class="pun">+</span><span class="pln"> TN </span><span class="pun">+</span><span class="pln"> FP </span><span class="pun">+</span><span class="pln"> FN</span><span class="pun">)</span><span class="pln"><br>accuracy </span><span class="pun">=</span><span class="pln"> </span><span class="pun">(</span><span class="lit">0</span><span class="pln"> </span><span class="pun">+</span><span class="pln"> </span><span class="lit">36500</span><span class="pun">)</span><span class="pln"> </span><span class="pun">/</span><span class="pln"> </span><span class="pun">(</span><span class="lit">0</span><span class="pln"> </span><span class="pun">+</span><span class="pln"> </span><span class="lit">36500</span><span class="pln"> </span><span class="pun">+</span><span class="pln"> </span><span class="lit">25</span><span class="pln"> </span><span class="pun">+</span><span class="pln"> </span><span class="lit">0</span><span class="pun">)</span><span class="pln"> </span><span class="pun">=</span><span class="pln"> </span><span class="lit">0.9993</span><span class="pln"> </span><span class="pun">=</span><span class="pln"> </span><span class="lit">99.93</span><span class="pun">%</span><span class="pln"><br></span></pre></devsite-code>

<p>Although 99.93% accuracy seems like very a impressive percentage, the model
actually has no predictive power.</p>

<p>
<a href="https://developers.google.com/machine-learning/glossary#precision"><b>Precision</b></a> and
<a href="https://developers.google.com/machine-learning/glossary#recall"><b>recall</b></a> are usually more useful metrics
than <b>accuracy</b> for evaluating models trained on class-imbalanced datasets.
</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="action"></a>
</p><h2 class="hide-from-toc" id="action" data-text="action" role="presentation"><span class="devsite-heading" role="heading" aria-level="2">action</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: action" data-title="Copy link to this section: action" data-id="action"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#reinforcement_learning"><strong>reinforcement learning</strong></a>,
the mechanism by which the <a href="https://developers.google.com/machine-learning/glossary#agent"><strong>agent</strong></a>
transitions between <a href="https://developers.google.com/machine-learning/glossary#state"><strong>states</strong></a> of the
<a href="https://developers.google.com/machine-learning/glossary#environment"><strong>environment</strong></a>. The agent chooses the action by using a
<a href="https://developers.google.com/machine-learning/glossary#policy"><strong>policy</strong></a>.</p>

<p><a class="glossary-anchor" name="activation_function"></a>
</p><h2 class="hide-from-toc" id="activation-function" data-text="activation function" role="presentation"><span class="devsite-heading" role="heading" aria-level="2">activation function</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: activation function" data-title="Copy link to this section: activation function" data-id="activation-function"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A function that enables <a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural networks</strong></a> to learn
<a href="https://developers.google.com/machine-learning/glossary#nonlinear"><strong>nonlinear</strong></a> (complex) relationships between features
and the label.</p>

<p>Popular activation functions include:</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#ReLU"><strong>ReLU</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#sigmoid-function"><strong>Sigmoid</strong></a></li>
</ul>

<p>The plots of activation functions are never single straight lines.
For example, the plot of the ReLU activation function consists of
two straight lines:</p>

<p>
<img src="./ML_Glossary_files/relu.svg" loading="lazy" alt="A cartesian plot of two lines. The first line has a constant
          y value of 0, running along the x-axis from -infinity,0 to 0,-0.
          The second line starts at 0,0. This line has a slope of +1, so
          it runs from 0,0 to +infinity,+infinity.">
</p>

<p>A plot of the sigmoid activation function looks as follows:</p>

<p>
<img src="./ML_Glossary_files/sigmoid.svg" loading="lazy" alt="A two-dimensional curved plot with x values spanning the domain
          -infinity to +positive, while y values span the range almost 0 to
          almost 1. When x is 0, y is 0.5. The slope of the curve is always
          positive, with the highest slope at 0,0.5 and gradually decreasing
          slopes as the absolute value of x increases.">
</p>

<devsite-expandable is-upgraded="" id="expandable-2"><a class="exw-control" aria-controls="expandable-2" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-to-see-an-example." data-text=" Click the icon to see an example. " role="presentation"><span class="devsite-heading" role="heading" aria-level="4">
Click the icon to see an example.<wbr>
</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: 
Click the icon to see an example.
" data-title="Copy link to this section: 
Click the icon to see an example.
" data-id="click-the-icon-to-see-an-example."></button></h4></a>



<div class="expand-background">

<p>In a neural network, activation functions manipulate the
<a href="https://developers.google.com/machine-learning/glossary#weighted_sum">weighted sum</a> of all the inputs to a
<a href="https://developers.google.com/machine-learning/glossary#neuron">neuron</a>. To calculate a weighted sum, the neuron adds up
the products of the relevant values and weights.  For example, suppose the
relevant input to a neuron consists of the following:</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr><td>input value</td> <td>input weight</td></tr>
  <tr><td>2</td> <td>-1.3</td></tr>
  <tr><td>-1</td> <td>0.6</td></tr>
  <tr><td>3</td> <td>0.4</td></tr>
</tbody></table></div>

The weighted sum is therefore:

<devsite-code data-copy-event-label=""><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="pln">weighted sum </span><span class="pun">=</span><span class="pln"> </span><span class="pun">(</span><span class="lit">2</span><span class="pun">)(-</span><span class="lit">1.3</span><span class="pun">)</span><span class="pln"> </span><span class="pun">+</span><span class="pln"> </span><span class="pun">(-</span><span class="lit">1</span><span class="pun">)(</span><span class="lit">0.6</span><span class="pun">)</span><span class="pln"> </span><span class="pun">+</span><span class="pln"> </span><span class="pun">(</span><span class="lit">3</span><span class="pun">)(</span><span class="lit">0.4</span><span class="pun">)</span><span class="pln"> </span><span class="pun">=</span><span class="pln"> </span><span class="pun">-</span><span class="lit">2.0</span><span class="pln"><br></span></pre></devsite-code>

Suppose the designer of this neural network chooses the
<a href="https://developers.google.com/machine-learning/glossary#sigmoid-function"><b>sigmoid function</b></a> to be the
activation function. In that case, the neuron calculates the
sigmoid of -2.0, which is approximately 0.12. Therefore, the
neuron passes 0.12 (rather than -2.0) to the next layer in the neural network.
The following figure illustrates the relevant part of the process:

<p>
<img src="./ML_Glossary_files/ActivationFunction_sigmoid.png" loading="lazy" height="400" width="668" alt="An input layer with three features passing three feature values and
          three weights to a neuron in a hidden layer. The hidden layer
          calculates the raw value (-2.0), and then passes the raw value to
          the activation function. The activation function calculates the
          sigmoid of the raw value and passes the result (0.12) to the next
          layer of the neural network.">
</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="active_learning"></a>
</p><h2 class="hide-from-toc" id="active-learning" data-text="active learning" role="presentation"><span class="devsite-heading" role="heading" aria-level="2">active learning</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: active learning" data-title="Copy link to this section: active learning" data-id="active-learning"></button></h2><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#training"><strong>training</strong></a> approach in which the
algorithm <em>chooses</em> some of the data it learns from. Active learning
is particularly valuable when <a href="https://developers.google.com/machine-learning/glossary#labeled_example"><strong>labeled examples</strong></a>
are scarce or expensive to obtain. Instead of blindly seeking a diverse
range of labeled examples, an active learning algorithm selectively seeks
the particular range of examples it needs for learning.</p>

<p><a class="glossary-anchor" name="AdaGrad"></a>
</p><h2 class="hide-from-toc" id="adagrad" data-text=" AdaGrad" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> AdaGrad</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  AdaGrad" data-title="Copy link to this section:  AdaGrad" data-id="adagrad"></button></h2><p></p>

<p>A sophisticated gradient descent algorithm that rescales the
gradients of each <a href="https://developers.google.com/machine-learning/glossary#parameter"><strong>parameter</strong></a>, effectively giving each parameter
an independent <a href="https://developers.google.com/machine-learning/glossary#learning_rate"><strong>learning rate</strong></a>. For a full explanation, see
<a href="http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf" target="T">this paper</a>.</p>

<p><a class="glossary-anchor" name="agent"></a>
</p><h2 class="hide-from-toc" id="agent" data-text=" agent" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> agent</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  agent" data-title="Copy link to this section:  agent" data-id="agent"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#reinforcement_learning"><strong>reinforcement learning</strong></a>,
the entity that uses a
<a href="https://developers.google.com/machine-learning/glossary#policy"><strong>policy</strong></a> to maximize the expected <a href="https://developers.google.com/machine-learning/glossary#return"><strong>return</strong></a> gained from
transitioning between <a href="https://developers.google.com/machine-learning/glossary#state"><strong>states</strong></a> of the
<a href="https://developers.google.com/machine-learning/glossary#environment"><strong>environment</strong></a>.</p>

<p><a class="glossary-anchor" name="agglomerative_clustering"></a>
</p><h2 class="hide-from-toc" id="agglomerative-clustering" data-text=" agglomerative clustering" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> agglomerative clustering</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  agglomerative clustering" data-title="Copy link to this section:  agglomerative clustering" data-id="agglomerative-clustering"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Clustering">#clustering</div>
</div><p></p>

<p>See <a href="https://developers.google.com/machine-learning/glossary#hierarchical_clustering"><strong>hierarchical clustering</strong></a>.</p>

<p><a class="glossary-anchor" name="anomaly-detection"></a>
</p><h2 class="hide-from-toc" id="anomaly-detection" data-text=" anomaly detection" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> anomaly detection</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  anomaly detection" data-title="Copy link to this section:  anomaly detection" data-id="anomaly-detection"></button></h2><p></p>

<p>The process of identifying <a href="https://developers.google.com/machine-learning/glossary#outliers"><strong>outliers</strong></a>. For example, if the mean
for a certain <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a> is 100 with a standard deviation of 10,
then anomaly detection should flag a value of 200 as suspicious.</p>

<p><a class="glossary-anchor" name="AR"></a>
</p><h2 class="hide-from-toc" id="ar" data-text=" AR" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> AR</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  AR" data-title="Copy link to this section:  AR" data-id="ar"></button></h2><p></p>

<p>Abbreviation for <a href="https://developers.google.com/machine-learning/glossary#augmented_reality"><strong>augmented reality</strong></a>.</p>

<p><a class="glossary-anchor" name="area_under_the_pr_curve"></a>
</p><h2 class="hide-from-toc" id="area-under-the-pr-curve" data-text=" area under the PR curve" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> area under the PR curve</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  area under the PR curve" data-title="Copy link to this section:  area under the PR curve" data-id="area-under-the-pr-curve"></button></h2><p></p>

<p>See <a href="https://developers.google.com/machine-learning/glossary#PR_AUC"><strong>PR AUC (Area under the PR Curve)</strong></a>.</p>

<p><a class="glossary-anchor" name="area_under_the_ROC_curve"></a>
</p><h2 class="hide-from-toc" id="area-under-the-roc-curve" data-text=" area under the ROC curve" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> area under the ROC curve</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  area under the ROC curve" data-title="Copy link to this section:  area under the ROC curve" data-id="area-under-the-roc-curve"></button></h2><p></p>

<p>See <a href="https://developers.google.com/machine-learning/glossary#AUC"><strong>AUC (Area under the ROC curve)</strong></a>.</p>

<p><a class="glossary-anchor" name="artificial_general_intelligence"></a>
</p><h2 class="hide-from-toc" id="artificial-general-intelligence" data-text=" artificial general intelligence" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> artificial general intelligence</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  artificial general intelligence" data-title="Copy link to this section:  artificial general intelligence" data-id="artificial-general-intelligence"></button></h2><p></p>

<p>A non-human mechanism that demonstrates a <em>broad range</em> of problem solving,
creativity, and adaptability. For example, a program demonstrating artificial
general intelligence could translate text, compose symphonies, <em>and</em> excel at
games that have not yet been invented.</p>

<p><a class="glossary-anchor" name="artificial_intelligence"></a>
</p><h2 class="hide-from-toc" id="artificial-intelligence" data-text=" artificial intelligence" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> artificial intelligence</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  artificial intelligence" data-title="Copy link to this section:  artificial intelligence" data-id="artificial-intelligence"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A non-human program or <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> that can solve sophisticated tasks.
For example, a program or model that translates text or a program or model that
identifies diseases from radiologic images both exhibit artificial intelligence.</p>

<p>Formally, <a href="https://developers.google.com/machine-learning/glossary#machine_learning"><strong>machine learning</strong></a> is a sub-field of artificial
intelligence. However, in recent years, some organizations have begun using the
terms <em>artificial intelligence</em> and <em>machine learning</em> interchangeably.</p>

<p><a class="glossary-anchor" name="attention"></a>
</p><h2 class="hide-from-toc" id="attention" data-text=" attention" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> attention</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  attention" data-title="Copy link to this section:  attention" data-id="attention"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>Any of a wide range of <a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural network</strong></a> architecture
mechanisms
that aggregate information from a set of inputs in a data-dependent manner. A
typical attention mechanism might consist of a weighted sum over a set of
inputs, where the <a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weight</strong></a> for each input is computed by another
part of the neural network.</p>

<p>Refer also to <a href="https://developers.google.com/machine-learning/glossary#self-attention"><strong>self-attention</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#multi-head-self-attention"><strong>multi-head self-attention</strong></a>, which are the
building blocks of <a href="https://developers.google.com/machine-learning/glossary#Transformer"><strong>Transformers</strong></a>.</p>

<p><a class="glossary-anchor" name="attribute"></a>
</p><h2 class="hide-from-toc" id="attribute" data-text=" attribute" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> attribute</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  attribute" data-title="Copy link to this section:  attribute" data-id="attribute"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a>.</p>

<p>In machine learning fairness, attributes often refer to
characteristics pertaining to individuals.</p>

<p><a class="glossary-anchor" name="attribute-sampling"></a>
</p><h2 class="hide-from-toc" id="attribute-sampling" data-text=" attribute sampling" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> attribute sampling</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  attribute sampling" data-title="Copy link to this section:  attribute sampling" data-id="attribute-sampling"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>A tactic for training a <a href="https://developers.google.com/machine-learning/glossary#decision-forest"><strong>decision forest</strong></a> in which each
<a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a> considers only a random subset of possible
<a href="https://developers.google.com/machine-learning/glossary#feature"><strong>features</strong></a> when learning the <a href="https://developers.google.com/machine-learning/glossary#condition"><strong>condition</strong></a>.
Generally, a different subset of features is sampled for each
<a href="https://developers.google.com/machine-learning/glossary#node-decision-tree"><strong>node</strong></a>. In contrast, when training a decision tree
without attribute sampling, all possible features are considered for each node.</p>

<p><a class="glossary-anchor" name="AUC"></a>
</p><h2 class="hide-from-toc" id="auc-area-under-the-roc-curve" data-text=" AUC (Area under the ROC curve)" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> AUC (Area under the ROC curve)</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  AUC (Area under the ROC curve)" data-title="Copy link to this section:  AUC (Area under the ROC curve)" data-id="auc-area-under-the-roc-curve"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A number between 0.0 and 1.0 representing a
<a href="https://developers.google.com/machine-learning/glossary#binary-classification"><strong>binary classification</strong></a> model's
ability to separate <a href="https://developers.google.com/machine-learning/glossary#positive_class"><strong>positive classes</strong></a> from
<a href="https://developers.google.com/machine-learning/glossary#negative_class"><strong>negative classes</strong></a>.
The closer the AUC is to 1.0, the better the model's ability to separate
classes from each other.</p>

<p>For example, the following illustration shows a classifier model
that separates positive classes (green ovals) from negative classes
(purple rectangles) perfectly. This unrealistically perfect model has
an AUC of 1.0:</p>

<p>
<img src="./ML_Glossary_files/AUCIdealClassSeparation.png" loading="lazy" alt="A number line with 8 positive examples on one side and
          9 negative examples on the other side.">
</p>

<p>Conversely, the following illustration shows the results for a classifier
model that generated random results. This model has an AUC of 0.5:</p>

<p>
<img src="./ML_Glossary_files/AUCSetupPNPNPN.png" loading="lazy" alt="A number line with 6 positive examples and 6 negative examples.
          The sequence of examples is positive, negative,
          positive, negative, positive, negative, positive, negative, positive
          negative, positive, negative.">
</p>

<p>Yes, the preceding model has an AUC of 0.5, not 0.0.</p>

<p>Most models are somewhere between the two extremes. For instance, the
following model separates positives from negatives somewhat, and therefore
has an AUC somewhere between 0.5 and 1.0:</p>

<p>
<img src="./ML_Glossary_files/AUCSetupTypical.png" loading="lazy" alt="A number line with 6 positive examples and 6 negative examples.
          The sequence of examples is negative, negative, negative, negative,
          positive, negative, positive, positive, negative, positive, positive,
          positive.">
</p>

<p>AUC ignores any value you set for
<a href="https://developers.google.com/machine-learning/glossary#classification_threshold"><strong>classification threshold</strong></a>. Instead, AUC
considers <em>all</em> possible classification thresholds.</p>

<devsite-expandable is-upgraded="" id="expandable-3"><a class="exw-control" aria-controls="expandable-3" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-to-learn-about-the-relationship-between-auc-and-roc-curves." data-text=" Click the icon to learn about the relationship between AUC and ROC curves. " role="presentation"><span class="devsite-heading" role="heading" aria-level="4">
Click the icon to learn about the relationship between AUC and ROC curves.<wbr>
</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: 
Click the icon to learn about the relationship between AUC and ROC curves.
" data-title="Copy link to this section: 
Click the icon to learn about the relationship between AUC and ROC curves.
" data-id="click-the-icon-to-learn-about-the-relationship-between-auc-and-roc-curves."></button></h4></a>



<div class="expand-background">

<p>AUC represents the <i>area</i> under an
<a href="https://developers.google.com/machine-learning/glossary#ROC"><b>ROC curve</b></a>.
For example,
the ROC curve for a model that perfectly separates positives from
negatives looks as follows:</p>

<p>
<img src="./ML_Glossary_files/AUC1_0.png" loading="lazy" alt="Cartesian plot. x-axis is false positive rate; y-axis
          is true positive rate. Graph starts at 0,0 and goes straight up
          to 0,1 and then straight to the right ending at 1,1.">
</p>

<p>AUC is the area of the gray region in the preceding illustration.
In this unusual case, the area is simply the length of the gray region
(1.0) multiplied by the width of the gray region (1.0). So, the product
of 1.0 and 1.0 yields an AUC of exactly 1.0, which is the highest possible
AUC score.</p>

<p>Conversely, the ROC curve for a classifier that can't separate classes
at all is as follows.  The area of this gray region is 0.5.</p>

<img src="./ML_Glossary_files/AUC0_5.png" loading="lazy" alt="Cartesian plot. x-axis is false positive rate; y-axis is true
          positive rate. Graph starts at 0,0 and goes diagonally to 1,1.">
<p></p>

<p>A more typical ROC curve looks approximately like the following:</p>

<img src="./ML_Glossary_files/ROCTypicalGraph.png" loading="lazy" alt="Cartesian plot. x-axis is false positive rate; y-axis is true
          positive rate. Graph starts at 0,0 and takes an irregular arc
          to 1,0.">
<p></p>

<p>
It would be painstaking to calculate the area under this curve manually,
which is why a program typically calculates most AUC values.
</p>
</div>

<hr>
</devsite-expandable>

<devsite-expandable is-upgraded="" id="expandable-4"><a class="exw-control" aria-controls="expandable-4" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-a-more-formal-definition-of-auc." data-text=" Click the icon for a more formal definition of AUC. " role="presentation"><span class="devsite-heading" role="heading" aria-level="4">
Click the icon for a more formal definition of AUC.<wbr>
</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: 
Click the icon for a more formal definition of AUC.
" data-title="Copy link to this section: 
Click the icon for a more formal definition of AUC.
" data-id="click-the-icon-for-a-more-formal-definition-of-auc."></button></h4></a>



<div class="expand-background">
<p>
AUC is the probability that a classifier will be more confident that a
randomly chosen positive example is actually positive than that a
randomly chosen negative example is positive.
</p>

</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="augmented_reality"></a>
</p><h2 class="hide-from-toc" id="augmented-reality" data-text=" augmented reality" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> augmented reality</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  augmented reality" data-title="Copy link to this section:  augmented reality" data-id="augmented-reality"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>A technology that superimposes a computer-generated image on a user's view of
the real world, thus providing a composite view.</p>

<p><a class="glossary-anchor" name="automation_bias"></a>
</p><h2 class="hide-from-toc" id="automation-bias" data-text=" automation bias " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> automation bias </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  automation bias " data-title="Copy link to this section:  automation bias " data-id="automation-bias"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>When a human decision maker favors recommendations made by an automated
decision-making system over information made without automation, even
when the automated decision-making system makes errors.</p>

<p><a class="glossary-anchor" name="average_precision"></a>
</p><h2 class="hide-from-toc" id="average-precision" data-text=" average precision " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> average precision </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  average precision " data-title="Copy link to this section:  average precision " data-id="average-precision"></button></h2><p></p>

<p>A metric for summarizing the performance of a ranked sequence of results.
Average precision is calculated by taking the average of the
<a href="https://developers.google.com/machine-learning/glossary#precision"><strong>precision</strong></a> values for each relevant result (each result in
the ranked list where the recall increases relative to the previous result).</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#area_under_the_pr_curve"><strong>Area under the PR Curve</strong></a>.</p>

<p><a class="glossary-anchor" name="axis-aligned-condition"></a>
</p><h2 class="hide-from-toc" id="axis-aligned-condition" data-text=" axis-aligned condition " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> axis-aligned condition </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  axis-aligned condition " data-title="Copy link to this section:  axis-aligned condition " data-id="axis-aligned-condition"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>In a <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a>, a <a href="https://developers.google.com/machine-learning/glossary#condition"><strong>condition</strong></a>
that involves only a single <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a>. For example, if area
is a feature, then the following is an axis-aligned condition:</p>

<devsite-code data-copy-event-label=""><div class="devsite-code-buttons-container" role="group" aria-label="Action buttons"><button type="button" class="gc-analytics-event material-icons devsite-icon-code-dark devsite-toggle-dark" data-category="Site-Wide Custom Events" data-label="Dark Code Toggle" track-type="exampleCode" track-name="darkCodeToggle" aria-label="Dark code theme" data-title="Dark code theme"></button><button type="button" class="gc-analytics-event material-icons devsite-icon-code-light devsite-toggle-light" data-category="Site-Wide Custom Events" data-label="Light Code Toggle" track-type="exampleCode" track-name="lightCodeToggle" aria-label="Light code theme" data-title="Light code theme"></button><button type="button" class="gc-analytics-event material-icons devsite-icon-copy" data-category="Site-Wide Custom Events" data-label="Click To Copy" track-type="exampleCode" track-name="clickToCopy" aria-label="Copy code sample" data-title="Copy code sample"></button></div><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="pln">area </span><span class="pun">&gt;</span><span class="pln"> </span><span class="lit">200</span><span class="pln"><br></span></pre></devsite-code>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#oblique-condition"><strong>oblique condition</strong></a>.</p>

<p><a class="glossary-anchor" name="b"></a>
</p><h2 class="glossary" id="b" data-text="B" role="presentation"><span class="devsite-heading" role="heading" aria-level="2">B</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: B" data-title="Copy link to this section: B" data-id="b"></button></h2><p></p>

<p><a class="glossary-anchor" name="backpropagation"></a>
</p><h2 class="hide-from-toc" id="backpropagation" data-text=" backpropagation" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> backpropagation</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  backpropagation" data-title="Copy link to this section:  backpropagation" data-id="backpropagation"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The algorithm that implements
<a href="https://developers.google.com/machine-learning/glossary#gradient_descent"><strong>gradient descent</strong></a> in
<a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural networks</strong></a>.</p>

<p>Training a neural network involves many <a href="https://developers.google.com/machine-learning/glossary#iteration"><strong>iterations</strong></a>
of the following two-pass cycle:</p>

<ol>
<li>During the <strong>forward pass</strong>, the system processes a <a href="https://developers.google.com/machine-learning/glossary#batch"><strong>batch</strong></a> of
<a href="https://developers.google.com/machine-learning/glossary#example"><strong>examples</strong></a> to yield prediction(s). The system compares each
prediction to each <a href="https://developers.google.com/machine-learning/glossary#label"><strong>label</strong></a> value. The difference between
the prediction and the label value is the <a href="https://developers.google.com/machine-learning/glossary#loss"><strong>loss</strong></a> for that example.
The system aggregates the losses for all the examples to compute the total
loss for the current batch.</li>
<li>During the <strong>backward pass</strong> (backpropagation), the system reduces loss by
adjusting the weights of all the <a href="https://developers.google.com/machine-learning/glossary#neuron"><strong>neurons</strong></a> in all the
<a href="https://developers.google.com/machine-learning/glossary#hidden_layer"><strong>hidden layer(s)</strong></a>.</li>
</ol>

<p>Neural networks often contain many neurons across many hidden layers.
Each of those neurons contribute to the overall loss in different ways.
Backpropagation determines whether to increase or decrease the weights
applied to particular neurons.</p>

<p>The <a href="https://developers.google.com/machine-learning/glossary#learning_rate"><strong>learning rate</strong></a> is a multiplier that controls the
degree to which each backward pass increases or decreases each weight.
A large learning rate will increase or decrease each weight more than a
small learning rate.</p>

<p>In calculus terms, backpropagation implements calculus'
<a href="https://www.khanacademy.org/math/ap-calculus-ab/ab-differentiation-2-new/ab-3-1a/v/chain-rule-introduction"><strong>chain
rule</strong></a>.
That is, backpropagation calculates the
<a href="https://developers.google.com/machine-learning/glossary#partial_derivative"><b>partial derivative</b></a> of the error with
respect to each parameter. For more details, see this
<a href="https://developers-dot-devsite-v2-prod.appspot.com/machine-learning/crash-course/backprop-scroll"><strong>tutorial in Machine Learning Crash
Course</strong></a>.</p>

<p>Years ago, ML practitioners had to write code to implement backpropagation.
Modern ML APIs like TensorFlow now implement backpropagation for you. Phew!</p>

<p><a class="glossary-anchor" name="bagging"></a>
</p><h2 class="hide-from-toc" id="bagging" data-text=" bagging " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> bagging </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  bagging " data-title="Copy link to this section:  bagging " data-id="bagging"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>A method to <a href="https://developers.google.com/machine-learning/glossary#training"><strong>train</strong></a> an <a href="https://developers.google.com/machine-learning/glossary#ensemble"><strong>ensemble</strong></a> where each
constituent <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> trains on a random subset of training
examples <a href="https://developers.google.com/machine-learning/glossary#sampling-with-replacement"><strong>sampled with replacement</strong></a>.
For example, a <a href="https://developers.google.com/machine-learning/glossary#random-forest"><strong>random forest</strong></a> is a collection of
<a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision trees</strong></a> trained with bagging.</p>

<p>The term <strong>bagging</strong> is short for <strong>b</strong>ootstrap <strong>agg</strong>regat<strong>ing</strong>.</p>

<p><a class="glossary-anchor" name="bag_of_words"></a>
</p><h2 class="hide-from-toc" id="bag-of-words" data-text=" bag of words"> bag of words</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A representation of the words in a phrase or passage,
irrespective of order. For example, bag of words represents the
following three phrases identically:</p>

<ul>
<li>the dog jumps</li>
<li>jumps the dog</li>
<li>dog jumps the</li>
</ul>

<p>Each word is mapped to an index in a <a href="https://developers.google.com/machine-learning/glossary#sparse_vector"><strong>sparse vector</strong></a>, where
the vector has an index for every word in the vocabulary.  For example,
the phrase <em>the dog jumps</em> is mapped into a feature vector with non-zero
values at the three indices corresponding to the words <em>the</em>, <em>dog</em>, and
<em>jumps</em>. The non-zero value can be any of the following:</p>

<ul>
<li>A 1 to indicate the presence of a word.</li>
<li>A count of the number of times a word appears in the bag. For example,
if the phrase were <em>the maroon dog is a dog with maroon fur</em>, then both
<em>maroon</em> and <em>dog</em> would be represented as 2, while the other words would
be represented as 1.</li>
<li>Some other value, such as the logarithm of the count of the number of
times a word appears in the bag.</li>
</ul>

<p><a class="glossary-anchor" name="baseline"></a>
</p><h2 class="hide-from-toc" id="baseline" data-text=" baseline"> baseline</h2><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> used as a reference point for comparing how well another
model (typically, a more complex one) is performing. For example, a
<a href="https://developers.google.com/machine-learning/glossary#logistic_regression"><strong>logistic regression model</strong></a> might serve as a
good baseline for a <a href="https://developers.google.com/machine-learning/glossary#deep_model"><strong>deep model</strong></a>.</p>

<p>For a particular problem, the baseline helps model developers quantify
the minimal expected performance that a new model must achieve for the new
model to be useful.</p>

<p><a class="glossary-anchor" name="batch"></a>
</p><h2 class="hide-from-toc" id="batch" data-text=" batch" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> batch</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  batch" data-title="Copy link to this section:  batch" data-id="batch"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The set of <a href="https://developers.google.com/machine-learning/glossary#example"><strong>examples</strong></a> used in one training
<a href="https://developers.google.com/machine-learning/glossary#iteration"><strong>iteration</strong></a>.
The <a href="https://developers.google.com/machine-learning/glossary#batch_size"><strong>batch size</strong></a> determines the number of examples in a
batch.</p>

<p>See <a href="https://developers.google.com/machine-learning/glossary#epoch"><strong>epoch</strong></a> for an explanation of how a batch relates to
an epoch.</p>

<p><a class="glossary-anchor" name="batch_normalization"></a>
</p><h2 class="hide-from-toc" id="batch-normalization" data-text=" batch normalization"> batch normalization</h2><p></p>

<p><a href="https://developers.google.com/machine-learning/glossary#normalization"><strong>Normalizing</strong></a> the input or output of the
<a href="https://developers.google.com/machine-learning/glossary#activation_function"><strong>activation functions</strong></a> in a
<a href="https://developers.google.com/machine-learning/glossary#hidden_layer"><strong>hidden layer</strong></a>. Batch normalization can
provide the following benefits:</p>

<ul>
<li>Make <a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural networks</strong></a> more stable by protecting
against <a href="https://developers.google.com/machine-learning/glossary#outliers"><strong>outlier</strong></a> weights.</li>
<li>Enable higher <a href="https://developers.google.com/machine-learning/glossary#learning_rate"><strong>learning rates</strong></a>, which can
speed training.</li>
<li>Reduce <a href="https://developers.google.com/machine-learning/glossary#overfitting"><strong>overfitting</strong></a>.</li>
</ul>

<p><a class="glossary-anchor" name="batch_size"></a>
</p><h2 class="hide-from-toc" id="batch-size" data-text=" batch size"> batch size</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The number of <a href="https://developers.google.com/machine-learning/glossary#example"><strong>examples</strong></a> in a <a href="https://developers.google.com/machine-learning/glossary#batch"><strong>batch</strong></a>.
For instance, if the batch size is 100, then the model processes
100 examples per <a href="https://developers.google.com/machine-learning/glossary#iteration"><strong>iteration</strong></a>.</p>

<p>The following are popular batch size strategies:</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#SGD"><strong>Stochastic Gradient Descent (SGD)</strong></a>, in which the batch size is 1.</li>
<li>full batch, in which the batch size is the number of examples in the entire
<a href="https://developers.google.com/machine-learning/glossary#training_set"><strong>training set</strong></a>.  For instance, if the training set
contains a million examples, then the batch size would be a million
examples. Full batch is usually an inefficient strategy.</li>
<li><a href="https://developers.google.com/machine-learning/glossary#mini-batch"><strong>mini-batch</strong></a> in which the batch size is usually between
10 and 1000. Mini-batch is usually the most efficient strategy.</li>
</ul>

<p><a class="glossary-anchor" name="Bayesian_neural_network"></a>
</p><h2 class="hide-from-toc" id="bayesian-neural-network" data-text=" Bayesian neural network" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> Bayesian neural network</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  Bayesian neural network" data-title="Copy link to this section:  Bayesian neural network" data-id="bayesian-neural-network"></button></h2><p></p>

<p>A probabilistic <a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural network</strong></a> that accounts for
uncertainty in <a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weights</strong></a> and outputs. A standard neural network
regression model typically <a href="https://developers.google.com/machine-learning/glossary#prediction"><strong>predicts</strong></a> a scalar value;
for example, a model predicts a house price
of 853,000. In contrast, a Bayesian neural network predicts a distribution of
values; for example, a model predicts a house price of 853,000 with a standard
deviation of 67,200. A Bayesian neural network relies on
<a href="https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/" target="T">
Bayes' Theorem</a>
to calculate uncertainties in weights and predictions. A Bayesian neural
network can be useful when it is important to quantify uncertainty, such as in
models related to pharmaceuticals. Bayesian neural networks can also help
prevent <a href="https://developers.google.com/machine-learning/glossary#overfitting"><strong>overfitting</strong></a>.</p>

<p><a class="glossary-anchor" name="Bayesian_optimization"></a>
</p><h2 class="hide-from-toc" id="bayesian-optimization" data-text=" Bayesian optimization" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> Bayesian optimization</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  Bayesian optimization" data-title="Copy link to this section:  Bayesian optimization" data-id="bayesian-optimization"></button></h2><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#probabilistic-regression-model"><strong>probabilistic regression model</strong></a>
technique for optimizing computationally expensive
<a href="https://developers.google.com/machine-learning/glossary#objective_function"><strong>objective functions</strong></a> by instead optimizing a surrogate
that quantifies the uncertainty via a Bayesian learning technique. Since
Bayesian optimization is itself very expensive, it is usually used to optimize
expensive-to-evaluate tasks that have a small number of parameters, such as
selecting <a href="https://developers.google.com/machine-learning/glossary#hyperparameter"><strong>hyperparameters</strong></a>.</p>

<p><a class="glossary-anchor" name="bellman_equation"></a>
</p><h2 class="hide-from-toc" id="bellman-equation" data-text=" Bellman equation" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> Bellman equation</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  Bellman equation" data-title="Copy link to this section:  Bellman equation" data-id="bellman-equation"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In reinforcement learning, the following identity satisfied by the optimal
<a href="https://developers.google.com/machine-learning/glossary#q-function"><strong>Q-function</strong></a>:</p>

<p><span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;&amp;#x03B3;&lt;/mi&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;&amp;#x2032;&lt;/mo&gt;&lt;/msup&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;munder&gt;&lt;mo movablelimits=&quot;true&quot; form=&quot;prefix&quot;&gt;max&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;&amp;#x2032;&lt;/mo&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;&amp;#x2032;&lt;/mo&gt;&lt;/msup&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;&amp;#x2032;&lt;/mo&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="39.48ex" height="4.151ex" viewBox="0 -868.2 16998.2 1787.4" role="img" focusable="false" style="vertical-align: -2.135ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-51" x="0" y="0"></use><use href="#MJMAIN-28" x="791" y="0"></use><use href="#MJMATHI-73" x="1181" y="0"></use><use href="#MJMAIN-2C" x="1650" y="0"></use><use href="#MJMATHI-61" x="2095" y="0"></use><use href="#MJMAIN-29" x="2625" y="0"></use><use href="#MJMAIN-3D" x="3292" y="0"></use><use href="#MJMATHI-72" x="4348" y="0"></use><use href="#MJMAIN-28" x="4800" y="0"></use><use href="#MJMATHI-73" x="5189" y="0"></use><use href="#MJMAIN-2C" x="5659" y="0"></use><use href="#MJMATHI-61" x="6104" y="0"></use><use href="#MJMAIN-29" x="6633" y="0"></use><use href="#MJMAIN-2B" x="7245" y="0"></use><use href="#MJMATHI-3B3" x="8246" y="0"></use><g transform="translate(8789,0)"><use href="#MJAMS-45" x="0" y="0"></use><g transform="translate(667,-187)"><use transform="scale(0.707)" href="#MJMATHI-73" x="0" y="0"></use><use transform="scale(0.5)" href="#MJMAIN-2032" x="663" y="408"></use><use transform="scale(0.707)" href="#MJMAIN-7C" x="764" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-73" x="1042" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2C" x="1512" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-61" x="1790" y="0"></use></g></g><g transform="translate(11364,0)"><use href="#MJMAIN-6D"></use><use href="#MJMAIN-61" x="833" y="0"></use><use href="#MJMAIN-78" x="1334" y="0"></use><g transform="translate(639,-716)"><use transform="scale(0.707)" href="#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.5)" href="#MJMAIN-2032" x="748" y="513"></use></g></g><use href="#MJMATHI-51" x="13393" y="0"></use><use href="#MJMAIN-28" x="14185" y="0"></use><g transform="translate(14574,0)"><use href="#MJMATHI-73" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2032" x="663" y="583"></use></g><use href="#MJMAIN-2C" x="15339" y="0"></use><g transform="translate(15784,0)"><use href="#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2032" x="748" y="583"></use></g><use href="#MJMAIN-29" x="16608" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>Q</mi><mo stretchy="false">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mi>r</mi><mo stretchy="false">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="double-struck">E</mi></mrow><mrow class="MJX-TeXAtom-ORD"><msup><mi>s</mi><mo>′</mo></msup><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>s</mi><mo>,</mo><mi>a</mi></mrow></msub><munder><mo movablelimits="true" form="prefix">max</mo><mrow class="MJX-TeXAtom-ORD"><msup><mi>a</mi><mo>′</mo></msup></mrow></munder><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>s</mi><mo>′</mo></msup><mo>,</mo><msup><mi>a</mi><mo>′</mo></msup><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-4">Q(s, a) = r(s, a) + \gamma \mathbb{E}_{s'|s,a} \max_{a'} Q(s', a')</script></p>

<p><a href="https://developers.google.com/machine-learning/glossary#reinforcement_learning"><strong>Reinforcement learning</strong></a> algorithms apply this
identity to create <a href="https://developers.google.com/machine-learning/glossary#q-learning"><strong>Q-learning</strong></a> via the following update rule:</p>

<p><span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2190;&lt;/mo&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;&amp;#x03B1;&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;[&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;&amp;#x03B3;&lt;/mi&gt;&lt;mstyle displaystyle=&quot;true&quot; scriptlevel=&quot;0&quot;&gt;&lt;munder&gt;&lt;mo movablelimits=&quot;true&quot; form=&quot;prefix&quot;&gt;max&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mstyle scriptlevel=&quot;1&quot;&gt;&lt;mtable rowspacing=&quot;0.1em&quot; columnspacing=&quot;0em&quot; displaystyle=&quot;false&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;&amp;#x2032;&lt;/mo&gt;&lt;/msup&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;&amp;#x2032;&lt;/mo&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mstyle&gt;&lt;mo&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="58.156ex" height="4.743ex" viewBox="0 -1224.9 25039.3 2042.1" role="img" focusable="false" style="vertical-align: -1.898ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-51" x="0" y="0"></use><use href="#MJMAIN-28" x="791" y="0"></use><use href="#MJMATHI-73" x="1181" y="0"></use><use href="#MJMAIN-2C" x="1650" y="0"></use><use href="#MJMATHI-61" x="2095" y="0"></use><use href="#MJMAIN-29" x="2625" y="0"></use><use href="#MJMAIN-2190" x="3292" y="0"></use><use href="#MJMATHI-51" x="4570" y="0"></use><use href="#MJMAIN-28" x="5362" y="0"></use><use href="#MJMATHI-73" x="5751" y="0"></use><use href="#MJMAIN-2C" x="6221" y="0"></use><use href="#MJMATHI-61" x="6666" y="0"></use><use href="#MJMAIN-29" x="7195" y="0"></use><use href="#MJMAIN-2B" x="7807" y="0"></use><use href="#MJMATHI-3B1" x="8808" y="0"></use><g transform="translate(9615,0)"><use href="#MJSZ2-5B"></use><use href="#MJMATHI-72" x="472" y="0"></use><use href="#MJMAIN-28" x="924" y="0"></use><use href="#MJMATHI-73" x="1313" y="0"></use><use href="#MJMAIN-2C" x="1783" y="0"></use><use href="#MJMATHI-61" x="2228" y="0"></use><use href="#MJMAIN-29" x="2757" y="0"></use><use href="#MJMAIN-2B" x="3369" y="0"></use><use href="#MJMATHI-3B3" x="4370" y="0"></use><g transform="translate(5080,0)"><use href="#MJMAIN-6D"></use><use href="#MJMAIN-61" x="833" y="0"></use><use href="#MJMAIN-78" x="1334" y="0"></use><g transform="translate(423,-612)"><g transform="translate(167,0)"><g transform="translate(-15,0)"><g transform="translate(0,73)"><use transform="scale(0.707)" href="#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.5)" href="#MJMAIN-31" x="748" y="-213"></use></g></g></g></g><use href="#MJMATHI-51" x="2029" y="0"></use><use href="#MJMAIN-28" x="2820" y="0"></use><g transform="translate(3210,0)"><use href="#MJMATHI-73" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2032" x="663" y="583"></use></g><use href="#MJMAIN-2C" x="3974" y="0"></use><g transform="translate(4419,0)"><use href="#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2032" x="748" y="583"></use></g><use href="#MJMAIN-29" x="5243" y="0"></use><use href="#MJMAIN-2212" x="5855" y="0"></use><use href="#MJMATHI-51" x="6856" y="0"></use><use href="#MJMAIN-28" x="7647" y="0"></use><use href="#MJMATHI-73" x="8037" y="0"></use><use href="#MJMAIN-2C" x="8506" y="0"></use><use href="#MJMATHI-61" x="8952" y="0"></use><use href="#MJMAIN-29" x="9481" y="0"></use></g><use href="#MJSZ2-5D" x="14951" y="-1"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>Q</mi><mo stretchy="false">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="false">)</mo><mo stretchy="false">←</mo><mi>Q</mi><mo stretchy="false">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>+</mo><mi>α</mi><mrow><mo>[</mo><mi>r</mi><mo stretchy="false">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mstyle displaystyle="true" scriptlevel="0"><munder><mo movablelimits="true" form="prefix">max</mo><mrow class="MJX-TeXAtom-ORD"><mstyle scriptlevel="1"><mtable rowspacing="0.1em" columnspacing="0em" displaystyle="false"><mtr><mtd><msub><mi>a</mi><mn>1</mn></msub></mtd></mtr></mtable></mstyle></mrow></munder><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>s</mi><mo>′</mo></msup><mo>,</mo><msup><mi>a</mi><mo>′</mo></msup><mo stretchy="false">)</mo><mo>−</mo><mi>Q</mi><mo stretchy="false">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="false">)</mo></mstyle><mo>]</mo></mrow></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-5">Q(s,a) \gets Q(s,a) + \alpha
  \left[r(s,a)
      + \gamma \displaystyle\max_{\substack{a_1}} Q(s’,a’)
    - Q(s,a) \right]
</script></p>

<p>Beyond reinforcement learning, the Bellman equation has applications to
dynamic programming. See the
<a href="https://wikipedia.org/wiki/Bellman_equation" target="T">
Wikipedia entry for Bellman Equation</a>.</p>

<p><a class="glossary-anchor" name="BERT"></a>
</p><h2 class="hide-from-toc" id="bert-bidirectional-encoder-representations-from-transformers" data-text=" BERT (Bidirectional Encoder Representations from Transformers)" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> BERT (Bidirectional Encoder
Representations from Transformers)</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  BERT (Bidirectional Encoder
Representations from Transformers)" data-title="Copy link to this section:  BERT (Bidirectional Encoder
Representations from Transformers)" data-id="bert-bidirectional-encoder-representations-from-transformers"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A model architecture for text <a href="https://developers.google.com/machine-learning/glossary#representation"><strong>representation</strong></a>. A trained
BERT model can act as part of a larger model for text classification or
other ML tasks.</p>

<p>BERT has the following characteristics:</p>

<ul>
<li>Uses the <a href="https://developers.google.com/machine-learning/glossary#Transformer"><strong>Transformer</strong></a> architecture, and therefore relies
on <a href="https://developers.google.com/machine-learning/glossary#self-attention"><strong>self-attention</strong></a>.</li>
<li>Uses the <a href="https://developers.google.com/machine-learning/glossary#encoder"><strong>encoder</strong></a> part of the Transformer. The encoder's job
is to produce good text representations, rather than to perform a specific
task like classification.</li>
<li>Is <a href="https://developers.google.com/machine-learning/glossary#bidirectional"><strong>bidirectional</strong></a>.</li>
<li>Uses <a href="https://developers.google.com/machine-learning/glossary#masked-language-model"><strong>masking</strong></a> for
<a href="https://developers.google.com/machine-learning/glossary#unsupervised_machine_learning"><strong>unsupervised training</strong></a>.</li>
</ul>

<p>BERT's variants include:</p>

<ul>
<li><a href="https://ai.googleblog.com/2019/12/albert-lite-bert-for-self-supervised.html">ALBERT</a>,
which is an acronym for <strong>A</strong> <strong>L</strong>ight <strong>BERT</strong>.</li>
<li><a href="https://ai.googleblog.com/2020/08/language-agnostic-bert-sentence.html">LaBSE</a>.</li>
</ul>



<p>See <a href="https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html">Open Sourcing BERT: State-of-the-Art Pre-training for Natural Language
Processing</a>
for an overview of BERT.</p>

<p><a class="glossary-anchor" name="bias_ethics"></a>
</p><h2 class="hide-from-toc" id="bias-ethicsfairness" data-text=" bias (ethics/fairness)" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> bias (ethics/<wbr>fairness)</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  bias (ethics/fairness)" data-title="Copy link to this section:  bias (ethics/fairness)" data-id="bias-ethicsfairness"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>
1. Stereotyping, prejudice or favoritism towards some things, people,
or groups over others. These biases can affect collection and
interpretation of data, the design of a system, and how users interact
with a system.  Forms of this type of bias include:
</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#automation_bias"><strong>automation bias</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#confirmation_bias"><strong>confirmation bias</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#confirmation_bias"><strong>experimenter’s bias</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#group_attribution_bias"><strong>group attribution bias</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#implicit_bias"><strong>implicit bias</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#in-group_bias"><strong>in-group bias</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#out-group_homogeneity_bias"><strong>out-group homogeneity bias</strong></a></li>
</ul>

<p>
2. Systematic error introduced by a sampling or reporting procedure.
Forms of this type of bias include:
</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#selection_bias"><strong>coverage bias</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#selection_bias"><strong>non-response bias</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#participation_bias"><strong>participation bias</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#reporting_bias"><strong>reporting bias</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#selection_bias"><strong>sampling bias</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#selection_bias"><strong>selection bias</strong></a></li>
</ul>

<p>Not to be confused with the <a href="https://developers.google.com/machine-learning/glossary#bias"><strong>bias term</strong></a> in machine learning models
or <a href="https://developers.google.com/machine-learning/glossary#prediction_bias"><strong>prediction bias</strong></a>.</p>

<p><a class="glossary-anchor" name="bias"></a>
</p><h2 class="hide-from-toc" id="bias-math-or-bias-term" data-text=" bias (math) or bias term" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> bias (math) or bias term</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  bias (math) or bias term" data-title="Copy link to this section:  bias (math) or bias term" data-id="bias-math-or-bias-term"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>An intercept or offset from an origin. Bias is a parameter in
machine learning models, which is symbolized by either of the
following:</p>

<ul>
<li><i>b</i></li>
<li><i>w<sub>0</sub></i>
</li></ul>

<p>For example, bias is the <em>b</em> in the following formula:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msup&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;&amp;#x2032;&lt;/mo&gt;&lt;/msup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo&gt;&amp;#x2026;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="33.208ex" height="2.731ex" viewBox="0 -868.2 14297.9 1175.9" role="img" focusable="false" style="vertical-align: -0.715ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2032" x="706" y="583"></use><use href="#MJMAIN-3D" x="1072" y="0"></use><use href="#MJMATHI-62" x="2128" y="0"></use><use href="#MJMAIN-2B" x="2780" y="0"></use><g transform="translate(3780,0)"><use href="#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="1013" y="-213"></use></g><g transform="translate(4951,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="809" y="-213"></use></g><use href="#MJMAIN-2B" x="6199" y="0"></use><g transform="translate(7200,0)"><use href="#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="1013" y="-213"></use></g><g transform="translate(8371,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="809" y="-213"></use></g><use href="#MJMAIN-2B" x="9619" y="0"></use><use href="#MJMAIN-2026" x="10620" y="0"></use><g transform="translate(11959,0)"><use href="#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-6E" x="1013" y="-213"></use></g><g transform="translate(13200,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-6E" x="809" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msup><mi>y</mi><mo>′</mo></msup><mo>=</mo><mi>b</mi><mo>+</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mo>…</mo><msub><mi>w</mi><mi>n</mi></msub><msub><mi>x</mi><mi>n</mi></msub></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-6">y' = b + w_1x_1 + w_2x_2 + … w_nx_n</script>
</div>

<p>In a simple two-dimensional line, bias just means "y-intercept."
For example, the bias of the line in the following illustration is 2.</p>

<p>
<img src="./ML_Glossary_files/bias.png" loading="lazy" alt="The plot of a line with a slope of 0.5 and a bias (y-intercept) of 2.">
</p>

<p>Bias exists because not all models start from the origin (0,0). For example,
suppose an amusement park costs 2 Euros to enter and an additional
0.5 Euro for every hour a customer stays. Therefore, a model mapping the
total cost has a bias of 2 because the lowest cost is 2 Euros.</p>

<p>Bias is not to be confused with <a href="https://developers.google.com/machine-learning/glossary#bias_ethics"><strong>bias in ethics and fairness</strong></a>
or <a href="https://developers.google.com/machine-learning/glossary#prediction_bias"><strong>prediction bias</strong></a>.</p>

<p><a class="glossary-anchor" name="bigram"></a>
</p><h2 class="hide-from-toc" id="bigram" data-text=" bigram" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> bigram</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  bigram" data-title="Copy link to this section:  bigram" data-id="bigram"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Sequence Models">#seq</div>
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>An <a href="https://developers.google.com/machine-learning/glossary#N-gram"><strong>N-gram</strong></a> in which N=2.</p>

<p><a class="glossary-anchor" name="bidirectional"></a>
</p><h2 class="hide-from-toc" id="bidirectional" data-text=" bidirectional" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> bidirectional</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  bidirectional" data-title="Copy link to this section:  bidirectional" data-id="bidirectional"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A term used to describe a system that evaluates the text that both <em>precedes</em>
and <em>follows</em> a target section of text. In contrast, a
<a href="https://developers.google.com/machine-learning/glossary#unidirectional"><strong>unidirectional</strong></a> system only
evaluates the text that <em>precedes</em> a target section of text.</p>

<p>For example, consider a <a href="https://developers.google.com/machine-learning/glossary#masked-language-model"><strong>masked language model</strong></a> that
must determine probabilities for the word or words representing the underline in
the following question:</p>

<blockquote>
<p>What is the _____ with you?</p>
</blockquote>

<p>A unidirectional language model would have to base its probabilities only
on the context provided by the words "What", "is", and "the". In contrast,
a bidirectional language model could also gain context from "with" and "you",
which might help the model generate better predictions.</p>

<p><a class="glossary-anchor" name="bidirectional-language-model"></a>
</p><h2 class="hide-from-toc" id="bidirectional-language-model" data-text=" bidirectional language model" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> bidirectional language model</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  bidirectional language model" data-title="Copy link to this section:  bidirectional language model" data-id="bidirectional-language-model"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#language-model"><strong>language model</strong></a> that determines the probability that a
given token is present at a given location in an excerpt of text based on
the <em>preceding</em> and <em>following</em> text.</p>

<p><a class="glossary-anchor" name="binary_classification"></a>
<a class="glossary-anchor" name="binary-classification"></a>
</p><h2 class="hide-from-toc" id="binary-classification" data-text=" binary classification" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> binary classification</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  binary classification" data-title="Copy link to this section:  binary classification" data-id="binary-classification"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A type of <a href="https://developers.google.com/machine-learning/glossary#classification_model"><strong>classification</strong></a> task that
predicts one of two mutually exclusive classes:</p>

<ul>
<li>the <a href="https://developers.google.com/machine-learning/glossary#positive_class"><strong>positive class</strong></a></li>
<li>the <a href="https://developers.google.com/machine-learning/glossary#negative_class"><strong>negative class</strong></a></li>
</ul>

<p>For example, the following two machine learning models each perform
binary classification:</p>

<ul>
<li>A model that determines whether email messages are
<em>spam</em> (the positive class) or <em>not spam</em> (the negative class).</li>
<li>A model that evaluates medical symptoms to determine whether a person
has a particular disease (the positive class) or doesn't have that
disease (the negative class).</li>
</ul>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#multi-class"><strong>multi-class classification</strong></a>.</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#logistic_regression"><strong>logistic regression</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#classification_threshold"><strong>classification threshold</strong></a>.</p>

<p><a class="glossary-anchor" name="binary-condition"></a>
</p><h2 class="hide-from-toc" id="binary-condition" data-text=" binary condition "> binary condition </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>In a <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a>, a <a href="https://developers.google.com/machine-learning/glossary#condition"><strong>condition</strong></a>
that has only two possible outcomes, typically <em>yes</em> or <em>no</em>.
For example, the following is a binary condition:</p>

<devsite-code data-copy-event-label=""><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="pln">temperature </span><span class="pun">&gt;=</span><span class="pln"> </span><span class="lit">100</span><span class="pln"><br></span></pre></devsite-code>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#non-binary-condition"><strong>non-binary condition</strong></a>.</p>

<p><a class="glossary-anchor" name="binning"></a>
</p><h2 class="hide-from-toc" id="binning" data-text=" binning"> binning</h2><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#bucketing"><strong>bucketing</strong></a>.</p>

<p><a class="glossary-anchor" name="BLEU"></a>
</p><h2 class="hide-from-toc" id="bleu-bilingual-evaluation-understudy" data-text=" BLEU (Bilingual Evaluation Understudy)"> BLEU (Bilingual Evaluation Understudy)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A score between 0.0 and 1.0, inclusive, indicating the quality of a translation
between two human languages (for example, between English and Russian). A BLEU
score of 1.0 indicates a perfect translation; a BLEU score of 0.0 indicates a
terrible translation.</p>

<p><a class="glossary-anchor" name="boosting"></a>
</p><h2 class="hide-from-toc" id="boosting" data-text=" boosting"> boosting</h2><p></p>

<p>A machine learning technique that iteratively combines a set of simple and
not very accurate classifiers (referred to as "weak" classifiers) into a
classifier with high accuracy (a "strong" classifier) by
<a href="https://developers.google.com/machine-learning/glossary#upweighting"><strong>upweighting</strong></a> the examples that the model is currently
misclassifying.</p>

<p><a class="glossary-anchor" name="bounding_box"></a>
</p><h2 class="hide-from-toc" id="bounding-box" data-text=" bounding box"> bounding box</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>In an image, the (<em>x</em>, <em>y</em>) coordinates of a rectangle around an area of
interest, such as the dog in the image below.</p>

<p>
<img src="./ML_Glossary_files/bounding_box.jpg" loading="lazy" height="300" width="280" alt="Photograph of a dog sitting on a sofa. A green bounding box
          with top-left coordinates of (275, 1271) and bottom-right
          coordinates of (2954, 2761) circumscribes the dog&#39;s body">
</p>



<p><a class="glossary-anchor" name="broadcasting"></a>
</p><h2 class="hide-from-toc" id="broadcasting" data-text=" broadcasting"> broadcasting</h2><p></p>

<p>Expanding the shape of an operand in a matrix math operation to
<a href="https://developers.google.com/machine-learning/glossary#dimensions"><strong>dimensions</strong></a> compatible for that operation. For instance,
linear algebra requires that the two operands in a matrix addition operation
must have the same dimensions. Consequently, you can't add a matrix of shape
(m, n) to a vector of length n. Broadcasting enables this operation by
virtually expanding the vector of length n to a matrix of shape (m, n) by
replicating the same values down each column.</p>

<p>For example, given the following definitions, linear algebra prohibits
A+B because A and B have different dimensions:</p>
<devsite-code data-copy-event-label=""><pre class="" translate="no" dir="ltr" is-upgraded=""><code dir="ltr"><span class="pln">A </span><span class="pun">=</span><span class="pln"> </span><span class="pun">[[</span><span class="lit">7</span><span class="pun">,</span><span class="pln"> </span><span class="lit">10</span><span class="pun">,</span><span class="pln"> </span><span class="lit">4</span><span class="pun">],</span><span class="pln"><br>&nbsp; &nbsp; &nbsp;</span><span class="pun">[</span><span class="lit">13</span><span class="pun">,</span><span class="pln"> </span><span class="lit">5</span><span class="pun">,</span><span class="pln"> </span><span class="lit">9</span><span class="pun">]]</span><span class="pln"><br>B </span><span class="pun">=</span><span class="pln"> </span><span class="pun">[</span><span class="lit">2</span><span class="pun">]</span><span class="pln"><br></span></code></pre></devsite-code>
<p>However, broadcasting enables the operation A+B by virtually expanding B to:</p>
<devsite-code data-copy-event-label=""><div class="devsite-code-buttons-container" role="group" aria-label="Action buttons"><button type="button" class="gc-analytics-event material-icons devsite-icon-code-dark devsite-toggle-dark" data-category="Site-Wide Custom Events" data-label="Dark Code Toggle" track-type="exampleCode" track-name="darkCodeToggle" aria-label="Dark code theme" data-title="Dark code theme"></button><button type="button" class="gc-analytics-event material-icons devsite-icon-code-light devsite-toggle-light" data-category="Site-Wide Custom Events" data-label="Light Code Toggle" track-type="exampleCode" track-name="lightCodeToggle" aria-label="Light code theme" data-title="Light code theme"></button><button type="button" class="gc-analytics-event material-icons devsite-icon-copy" data-category="Site-Wide Custom Events" data-label="Click To Copy" track-type="exampleCode" track-name="clickToCopy" aria-label="Copy code sample" data-title="Copy code sample"></button></div><pre class="" translate="no" dir="ltr" is-upgraded=""><code dir="ltr"><span class="pln">&nbsp;</span><span class="pun">[[</span><span class="lit">2</span><span class="pun">,</span><span class="pln"> </span><span class="lit">2</span><span class="pun">,</span><span class="pln"> </span><span class="lit">2</span><span class="pun">],</span><span class="pln"><br>&nbsp; </span><span class="pun">[</span><span class="lit">2</span><span class="pun">,</span><span class="pln"> </span><span class="lit">2</span><span class="pun">,</span><span class="pln"> </span><span class="lit">2</span><span class="pun">]]</span><span class="pln"><br></span></code></pre></devsite-code>
<p>Thus, A+B is now a valid operation:</p>
<devsite-code data-copy-event-label=""><div class="devsite-code-buttons-container" role="group" aria-label="Action buttons"><button type="button" class="gc-analytics-event material-icons devsite-icon-code-dark devsite-toggle-dark" data-category="Site-Wide Custom Events" data-label="Dark Code Toggle" track-type="exampleCode" track-name="darkCodeToggle" aria-label="Dark code theme" data-title="Dark code theme"></button><button type="button" class="gc-analytics-event material-icons devsite-icon-code-light devsite-toggle-light" data-category="Site-Wide Custom Events" data-label="Light Code Toggle" track-type="exampleCode" track-name="lightCodeToggle" aria-label="Light code theme" data-title="Light code theme"></button><button type="button" class="gc-analytics-event material-icons devsite-icon-copy" data-category="Site-Wide Custom Events" data-label="Click To Copy" track-type="exampleCode" track-name="clickToCopy" aria-label="Copy code sample" data-title="Copy code sample"></button></div><pre class="" translate="no" dir="ltr" is-upgraded=""><code dir="ltr"><span class="pun">[[</span><span class="lit">7</span><span class="pun">,</span><span class="pln"> </span><span class="lit">10</span><span class="pun">,</span><span class="pln"> </span><span class="lit">4</span><span class="pun">],</span><span class="pln"> &nbsp;</span><span class="pun">+</span><span class="pln"> &nbsp;</span><span class="pun">[[</span><span class="lit">2</span><span class="pun">,</span><span class="pln"> </span><span class="lit">2</span><span class="pun">,</span><span class="pln"> </span><span class="lit">2</span><span class="pun">],</span><span class="pln"> &nbsp;</span><span class="pun">=</span><span class="pln"> &nbsp;</span><span class="pun">[[</span><span class="pln"> </span><span class="lit">9</span><span class="pun">,</span><span class="pln"> </span><span class="lit">12</span><span class="pun">,</span><span class="pln"> </span><span class="lit">6</span><span class="pun">],</span><span class="pln"><br>&nbsp;</span><span class="pun">[</span><span class="lit">13</span><span class="pun">,</span><span class="pln"> </span><span class="lit">5</span><span class="pun">,</span><span class="pln"> </span><span class="lit">9</span><span class="pun">]]</span><span class="pln"> &nbsp; &nbsp; &nbsp;</span><span class="pun">[</span><span class="lit">2</span><span class="pun">,</span><span class="pln"> </span><span class="lit">2</span><span class="pun">,</span><span class="pln"> </span><span class="lit">2</span><span class="pun">]]</span><span class="pln"> &nbsp; &nbsp; &nbsp;</span><span class="pun">[</span><span class="lit">15</span><span class="pun">,</span><span class="pln"> </span><span class="lit">7</span><span class="pun">,</span><span class="pln"> </span><span class="lit">11</span><span class="pun">]]</span><span class="pln"><br></span></code></pre></devsite-code>
<p>See the following description of
<a href="https://docs.scipy.org/doc/numpy-1.15.0/user/basics.broadcasting.html" target="T">broadcasting in NumPy</a> for more details.</p>

<p><a class="glossary-anchor" name="bucketing"></a>
</p><h2 class="hide-from-toc" id="bucketing" data-text=" bucketing" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> bucketing</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  bucketing" data-title="Copy link to this section:  bucketing" data-id="bucketing"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Converting a single <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a> into multiple binary features
called <strong>buckets</strong> or <strong>bins</strong>,
typically based on a value range. The chopped feature is typically a
<a href="https://developers.google.com/machine-learning/glossary#continuous_feature"><strong>continuous feature</strong></a>.</p>

<p>For example, instead of representing temperature as a single
continuous floating-point feature, you could chop ranges of temperatures
into discrete buckets, such as:</p>

<ul>
<li>&lt;= 10 degrees Celsius would be the "cold" bucket.</li>
<li>11 - 24 degrees Celsius would be the "temperate" bucket.</li>
<li>&gt;= 25 degrees Celsius would be the "warm" bucket.</li>
</ul>

<p>The model will treat every value in the same bucket identically. For
example, the values <code translate="no" dir="ltr">13</code> and <code translate="no" dir="ltr">22</code> are both in the temperate bucket, so the
model treats the two values identically.</p>

<devsite-expandable is-upgraded="" id="expandable-5"><a class="exw-control" aria-controls="expandable-5" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-additional-notes._1" data-text=" Click the icon for additional notes. " role="presentation"><span class="devsite-heading" role="heading" aria-level="4">
Click the icon for additional notes.<wbr>
</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: 
Click the icon for additional notes.
" data-title="Copy link to this section: 
Click the icon for additional notes.
" data-id="click-the-icon-for-additional-notes._1"></button></h4></a>



<div class="expand-background">
<p>
If you represent temperature as a continuous feature, then the model
treats temperature as a single feature. If you represent temperature
as three buckets, then the model treats each bucket as a separate feature.
That is, a model can learn separate relationships of each bucket to the
<a href="https://developers.google.com/machine-learning/glossary#label"><b>label</b></a>. For example, a
<a href="https://developers.google.com/machine-learning/glossary#linear_regression"><b>linear regression</b></a> model can learn
separate <a href="https://developers.google.com/machine-learning/glossary#weight"><b>weights</b></a> for each bucket.

</p><p>Increasing the number of buckets makes your model more complicated by
increasing the number of relationships that your model must learn.
For example, the cold, temperate, and warm buckets are essentially
three separate features for your model to train on. If you decide to add
two more buckets--for example, freezing and hot--your model would
now have to train on five separate features.</p>

<p>How do you know how many buckets to create, or what the ranges for each
bucket should be? The answers typically require a fair amount of
experimentation.
</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="c"></a>
</p><h2 class="glossary" id="c" data-text="C" role="presentation"><span class="devsite-heading" role="heading" aria-level="2">C</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: C" data-title="Copy link to this section: C" data-id="c"></button></h2><p></p>

<p><a class="glossary-anchor" name="calibration_layer"></a>
</p><h2 class="hide-from-toc" id="calibration-layer" data-text=" calibration layer" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> calibration layer</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  calibration layer" data-title="Copy link to this section:  calibration layer" data-id="calibration-layer"></button></h2><p></p>

<p>A post-prediction adjustment, typically to account for
<a href="https://developers.google.com/machine-learning/glossary#prediction_bias"><strong>prediction bias</strong></a>. The adjusted predictions and
probabilities should match the distribution of an observed set of labels.</p>

<p><a class="glossary-anchor" name="candidate_generation"></a>
</p><h2 class="hide-from-toc" id="candidate-generation" data-text=" candidate generation"> candidate generation</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Recommendation Systems">#recsystems</div>
</div><p></p>

<p>The initial set of recommendations chosen by a
<a href="https://developers.google.com/machine-learning/glossary#recommendation_system"><strong>recommendation system</strong></a>. For example, consider a
bookstore that offers 100,000 titles. The candidate generation phase creates
a much smaller list of suitable books for a particular user, say 500. But even
500 books is way too many to recommend to a user. Subsequent, more expensive,
phases of a recommendation system (such as <a href="https://developers.google.com/machine-learning/glossary#scoring"><strong>scoring</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#re-ranking"><strong>re-ranking</strong></a>) reduce those 500 to a much smaller,
more useful set of recommendations.</p>

<p><a class="glossary-anchor" name="candidate_sampling"></a>
</p><h2 class="hide-from-toc" id="candidate-sampling" data-text=" candidate sampling"> candidate sampling</h2><p></p>

<p>A training-time optimization in which a probability is calculated for all the
<a href="https://developers.google.com/machine-learning/glossary#positive_class"><strong>positive</strong></a> labels, using, for example,
<a href="https://developers.google.com/machine-learning/glossary#softmax"><strong>softmax</strong></a>, but only for a random
sample of negative labels. For example, if we have an example labeled
<em>beagle</em> and <em>dog</em> candidate sampling computes the predicted probabilities
and corresponding loss terms for the <em>beagle</em> and <em>dog</em> class outputs
in addition to a random subset of the remaining classes
(<em>cat</em>, <em>lollipop</em>, <em>fence</em>). The idea is that the
<a href="https://developers.google.com/machine-learning/glossary#negative_class"><strong>negative classes</strong></a> can learn from less frequent
negative reinforcement as long as
<a href="https://developers.google.com/machine-learning/glossary#positive_class"><strong>positive classes</strong></a> always get proper positive
reinforcement, and this is indeed observed empirically. The motivation for
candidate sampling is a computational efficiency win from not computing
predictions for all negatives.</p>

<p><a class="glossary-anchor" name="categorical_data"></a>
</p><h2 class="hide-from-toc" id="categorical-data" data-text=" categorical data"> categorical data</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p><a href="https://developers.google.com/machine-learning/glossary#feature"><strong>Features</strong></a> having a specific set of possible values. For example,
consider a categorical feature named <code translate="no" dir="ltr">traffic-light-state</code>, which can only
have one of the following three possible values:</p>

<ul>
<li><code translate="no" dir="ltr">red</code></li>
<li><code translate="no" dir="ltr">yellow</code></li>
<li><code translate="no" dir="ltr">green</code></li>
</ul>

<p>By representing <code translate="no" dir="ltr">traffic-light-state</code> as a categorical feature,
a model can learn the
differing impacts of <code translate="no" dir="ltr">red</code>, <code translate="no" dir="ltr">green</code>, and <code translate="no" dir="ltr">yellow</code> on driver behavior.</p>

<p>Categorical features are sometimes called
<a href="https://developers.google.com/machine-learning/glossary#discrete_feature"><strong>discrete features</strong></a>.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#numerical_data"><strong>numerical data</strong></a>.</p>

<p><a class="glossary-anchor" name="causal-language-model"></a>
</p><h2 class="hide-from-toc" id="causal-language-model" data-text=" causal language model"> causal language model</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#unidirectional-language-model"><strong>unidirectional language model</strong></a>.</p>

<p>See <a href="https://developers.google.com/machine-learning/glossary#bidirectional-language-model"><strong>bidirectional language model</strong></a> to
contrast different directional approaches in language modeling.</p>

<p><a class="glossary-anchor" name="centroid"></a>
</p><h2 class="hide-from-toc" id="centroid" data-text="centroid">centroid</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Clustering">#clustering</div>
</div><p></p>

<p>The center of a cluster as determined by a <a href="https://developers.google.com/machine-learning/glossary#k-means"><strong>k-means</strong></a> or
<a href="https://developers.google.com/machine-learning/glossary#k-median"><strong>k-median</strong></a> algorithm. For instance, if k is 3,
then the k-means or k-median algorithm finds 3 centroids.</p>

<p><a class="glossary-anchor" name="centroid_based_clustering"></a>
</p><h2 class="hide-from-toc" id="centroid-based-clustering" data-text=" centroid-based clustering"> centroid-based clustering</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Clustering">#clustering</div>
</div><p></p>

<p>A category of <a href="https://developers.google.com/machine-learning/glossary#clustering"><strong>clustering</strong></a> algorithms that organizes data
into nonhierarchical clusters. <a href="https://developers.google.com/machine-learning/glossary#k-means"><strong>k-means</strong></a> is the most widely
used centroid-based clustering algorithm.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#hierarchical_clustering"><strong>hierarchical clustering</strong></a>
algorithms.</p>

<p><a class="glossary-anchor" name="checkpoint"></a>
</p><h2 class="hide-from-toc" id="checkpoint" data-text=" checkpoint"> checkpoint</h2><p></p>

<p>Data that captures the state of a model's <a href="https://developers.google.com/machine-learning/glossary#parameter"><strong>parameters</strong></a> at a
particular training iteration. Checkpoints enable exporting model
<a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weights</strong></a>, or performing <a href="https://developers.google.com/machine-learning/glossary#training"><strong>training</strong></a> across
multiple sessions. Checkpoints
also enable training to continue past errors (for example, job preemption).</p>

<p><a class="glossary-anchor" name="class"></a>
</p><h2 class="hide-from-toc" id="class" data-text=" class"> class</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A category that a <a href="https://developers.google.com/machine-learning/glossary#label"><strong>label</strong></a> can belong to.
For example:</p>

<ul>
<li>In a <a href="https://developers.google.com/machine-learning/glossary#binary_classification"><strong>binary classification</strong></a> model that detects
spam, the two classes might be <em>spam</em> and <em>not spam</em>.</li>
<li>In a <a href="https://developers.google.com/machine-learning/glossary#multi-class"><strong>multi-class classification</strong></a> model that identifies
dog breeds, the classes might be <em>poodle</em>, <em>beagle</em>, <em>pug</em>, and so
on.</li>
</ul>

<p>A <a href="https://developers.google.com/machine-learning/glossary#classification_model"><strong>classification model</strong></a> predicts a class.
In contrast, a <a href="https://developers.google.com/machine-learning/glossary#regression_model"><strong>regression model</strong></a> predicts a number
rather than a class.</p>

<p><a class="glossary-anchor" name="classification_model"></a>
</p><h2 class="hide-from-toc" id="classification-model" data-text=" classification model"> classification model</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> whose prediction is a <a href="https://developers.google.com/machine-learning/glossary#class"><strong>class</strong></a>.
For example, the following are all classification models:</p>

<ul>
<li>A model that predicts an input sentence's language (French? Spanish?
Italian?).</li>
<li>A model that predicts tree species (Maple? Oak? Baobab?).</li>
<li>A model that predicts the positive or negative class for a particular
medical condition.</li>
</ul>

<p>In contrast, <a href="https://developers.google.com/machine-learning/glossary#regression_model"><strong>regression models</strong></a> predict numbers
rather than classes.</p>

<p>Two common types of classification models are:</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#binary-classification"><strong>binary classification</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#multi-class"><strong>multi-class classification</strong></a></li>
</ul>

<p><a class="glossary-anchor" name="classification_threshold"></a>
</p><h2 class="hide-from-toc" id="classification-threshold" data-text=" classification threshold"> classification threshold</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>In a <a href="https://developers.google.com/machine-learning/glossary#binary-classification"><strong>binary classification</strong></a>, a
number between 0 and 1 that converts the raw output of a
<a href="https://developers.google.com/machine-learning/glossary#logistic_regression"><strong>logistic regression</strong></a> model
into a prediction of either the <a href="https://developers.google.com/machine-learning/glossary#positive_class"><strong>positive class</strong></a>
or the <a href="https://developers.google.com/machine-learning/glossary#negative_class"><strong>negative class</strong></a>.
Note that the classification threshold is a value that a human chooses,
not a value chosen by model training.</p>

<p>A logistic regression model outputs a raw value between 0 and 1. Then:</p>

<ul>
<li>If this raw value is <em>greater than</em> the classification threshold, then
the positive class is predicted.</li>
<li>If this raw value is <em>less than</em> the classification threshold, then
the negative class is predicted.</li>
</ul>

<p>For example, suppose the classification threshold is 0.8. If the raw value
is 0.9, then the model predicts the positive class. If the raw value is
0.7, then the model predicts the negative class.</p>

<p>The choice of classification threshold strongly influences the number of
<a href="https://developers.google.com/machine-learning/glossary#FP"><strong>false positives</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#FN"><strong>false negatives</strong></a>.</p>

<devsite-expandable is-upgraded="" id="expandable-6"><a class="exw-control" aria-controls="expandable-6" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-additional-notes._2" data-text=" Click the icon for additional notes. ">
Click the icon for additional notes.<wbr>
</h4></a>



<div class="expand-background">
<p>
As models or datasets evolve, engineers sometimes also change the
classification threshold. When the classification threshold changes,
positive class predictions can suddenly become negative classes
and vice-versa.
</p>

<p>
For example, consider a binary classification disease prediction model.
Suppose that when the system runs in the first year:</p>

<ul>
<li>The raw value for a particular patient is 0.95.</li>
<li>The classification threshold is 0.94.</li>
</ul>

<p>Therefore, the system diagnoses the positive class. (The patient gasps,
"Oh no! I'm sick!")</p>

<p>A year later, perhaps the values now look as follows:</p>

<ul>
<li>The raw value for the same patient remains at 0.95.</li>
<li>The classification threshold changes to 0.97.</li>
</ul>

<p>Therefore, the system now reclassifies that patient as the negative class.
("Happy day! I'm not sick.") Same patient. Different diagnosis.</p>

<p></p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="class_imbalanced_data_set"></a>
</p><h2 class="hide-from-toc" id="class-imbalanced-dataset" data-text=" class-imbalanced dataset"> class-imbalanced dataset</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A dataset for a classification problem in which the total number
of <a href="https://developers.google.com/machine-learning/glossary#label"><strong>labels</strong></a> of each class differs significantly.
For example, consider a binary classification dataset whose two labels
are divided as follows:</p>

<ul>
<li>1,000,000 negative labels</li>
<li>10 positive labels</li>
</ul>

<p>The ratio of negative to positive labels is 100,000 to 1, so this
is a class-imbalanced dataset.</p>

<p>In contrast, the following dataset is <em>not</em> class-imbalanced because the
ratio of negative labels to positive labels is relatively close to 1:</p>

<ul>
<li>517 negative labels</li>
<li>483 positive labels</li>
</ul>

<p>Multi-class datasets can also be class-imbalanced. For example, the following
multi-class classification dataset is also class-imbalanced because one label
has far more examples than the other two:</p>

<ul>
<li>1,000,000 labels with class "green"</li>
<li>200 labels with class "purple"</li>
<li>350 labels with class "orange"</li>
</ul>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#entropy"><strong>entropy</strong></a>, <a href="https://developers.google.com/machine-learning/glossary#majority_class"><strong>majority class</strong></a>,
and <a href="https://developers.google.com/machine-learning/glossary#minority_class"><strong>minority class</strong></a>.</p>

<p><a class="glossary-anchor" name="clipping"></a>
</p><h2 class="hide-from-toc" id="clipping" data-text=" clipping"> clipping</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A technique for handling <a href="https://developers.google.com/machine-learning/glossary#outliers"><strong>outliers</strong></a> by doing
either or both of the following:</p>

<ul>
<li>Reducing <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a> values that are greater than a maximum
threshold down to that maximum threshold.</li>
<li>Increasing feature values that are less than a minimum threshold up to that
minimum threshold.</li>
</ul>

<p>For example, suppose that &lt;0.5% of values for a particular feature fall outside
the range 40–60. In this case, you could do the following:</p>

<ul>
<li>Clip all values over 60 (the maximum threshold) to be exactly 60.</li>
<li>Clip all values under 40 (the minimum threshold) to be exactly 40.</li>
</ul>

<p>Outliers can damage models, sometimes causing <a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weights</strong></a>
to overflow during training. Some outliers can also dramatically spoil
metrics like <a href="https://developers.google.com/machine-learning/glossary#accuracy"><strong>accuracy</strong></a>. Clipping is a common technique to limit
the damage.</p>

<p><a href="https://developers.google.com/machine-learning/glossary#gradient_clipping"><strong>Gradient clipping</strong></a> forces
<a href="https://developers.google.com/machine-learning/glossary#gradient"><strong>gradient</strong></a> values within a designated range during training.</p>

<p><a class="glossary-anchor" name="Cloud_TPU"></a>
</p><h2 class="hide-from-toc" id="cloud-tpu" data-text=" Cloud TPU " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> Cloud TPU </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  Cloud TPU " data-title="Copy link to this section:  Cloud TPU " data-id="cloud-tpu"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
  <div class="glossary-icon" data-title="Google Cloud">#GoogleCloud</div>
</div><p></p>

<p>A specialized hardware accelerator designed to speed up machine
learning workloads on Google Cloud Platform.</p>

<p><a class="glossary-anchor" name="clustering"></a>
</p><h2 class="hide-from-toc" id="clustering" data-text="clustering" role="presentation"><span class="devsite-heading" role="heading" aria-level="2">clustering</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: clustering" data-title="Copy link to this section: clustering" data-id="clustering"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Clustering">#clustering</div>
</div><p></p>

<p>Grouping related <a href="https://developers.google.com/machine-learning/glossary#example"><strong>examples</strong></a>, particularly during
<a href="https://developers.google.com/machine-learning/glossary#unsupervised_machine_learning"><strong>unsupervised learning</strong></a>. Once all the
examples are grouped, a human can optionally supply meaning to each cluster.</p>

<p>Many clustering algorithms exist.  For example, the <a href="https://developers.google.com/machine-learning/glossary#k-means"><strong>k-means</strong></a>
algorithm clusters examples based on their proximity to a
<a href="https://developers.google.com/machine-learning/glossary#centroid"><strong>centroid</strong></a>, as in the following diagram:</p>

<p>
<img src="./ML_Glossary_files/Cluster.svg" loading="lazy" alt="A two-dimensional graph in which the x-axis is labeled &#39;tree width&#39;
          and the y-axis is labeled &#39;tree height&#39;.  The graph contains two
          centroids and several dozen data points. The data points are
          categorized based on their proximity. That is, the data points
          closest to one centroid are categorized as &#39;cluster 1&#39;, while those
          closest to the other centroid are categorized as &#39;cluster 2&#39;.">

</p>

<p>A human researcher could then review the clusters and, for example,
label cluster 1 as "dwarf trees" and cluster 2 as "full-size trees."</p>

<p>As another example, consider a clustering algorithm based on an
example's distance from a center point, illustrated as follows:</p>

<p>
<img src="./ML_Glossary_files/RingCluster.svg" loading="lazy" alt="Dozens of data points are arranged in concentric circles, almost
          like holes around the center of a dart board. The innermost ring
          of data points is categorized as &#39;cluster 1&#39;, the middle ring
          is categorized as &#39;cluster 2&#39;, and the outermost ring as
          &#39;cluster 3.&#39;">
</p>

<p><a class="glossary-anchor" name="co-adaptation"></a>
</p><h2 class="hide-from-toc" id="co-adaptation" data-text=" co-adaptation"> co-adaptation</h2><p></p>

<p>When <a href="https://developers.google.com/machine-learning/glossary#neuron"><strong>neurons</strong></a> predict patterns in training data by relying
almost exclusively on outputs of specific other neurons instead of relying on
the network's behavior as a whole. When the patterns that cause co-adaption
are not present in validation data, then co-adaptation causes overfitting.
<a href="https://developers.google.com/machine-learning/glossary#dropout_regularization"><strong>Dropout regularization</strong></a> reduces co-adaptation
because dropout ensures neurons cannot rely solely on specific other neurons.</p>

<p><a class="glossary-anchor" name="collaborative_filtering"></a>
</p><h2 class="hide-from-toc" id="collaborative-filtering" data-text=" collaborative filtering"> collaborative filtering</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Recommendation Systems">#recsystems</div>
</div><p></p>

<p>Making <a href="https://developers.google.com/machine-learning/glossary#prediction"><strong>predictions</strong></a> about the interests of one user
based on the interests of many other users.  Collaborative filtering
is often used in <a href="https://developers.google.com/machine-learning/glossary#recommendation_system"><strong>recommendation systems</strong></a>.</p>

<p><a class="glossary-anchor" name="condition"></a>
</p><h2 class="hide-from-toc" id="condition" data-text=" condition "> condition </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>In a <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a>, any <a href="https://developers.google.com/machine-learning/glossary#node"><strong>node</strong></a> that
evaluates an expression. For example, the following portion of a
decision tree contains two conditions:</p>

<p>
<img src="./ML_Glossary_files/condition.png" loading="lazy" height="250" width="433" alt="A decision tree consisting of two conditions: (x &gt; 0) and
          (y &gt; 0).">
</p>

<p>A condition is also called a split or a test.</p>

<p>Contrast condition with <a href="https://developers.google.com/machine-learning/glossary#leaf"><strong>leaf</strong></a>.</p>

<p>See also:</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#binary-condition"><strong>binary condition</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#non-binary-condition"><strong>non-binary condition</strong></a>.</li>
<li><a href="https://developers.google.com/machine-learning/glossary#axis-aligned-condition"><strong>axis-aligned-condition</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#oblique-condition"><strong>oblique-condition</strong></a></li>
</ul>

<p><a class="glossary-anchor" name="confirmation_bias"></a>
</p><h2 class="hide-from-toc" id="confirmation-bias" data-text=" confirmation bias "> confirmation bias </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>The tendency to search for, interpret, favor, and recall information in a
way that confirms one's preexisting beliefs or hypotheses.
Machine learning developers may inadvertently collect or label
data in ways that influence an outcome supporting their existing
beliefs.  Confirmation bias is a form of <a href="https://developers.google.com/machine-learning/glossary#implicit_bias"><strong>implicit bias</strong></a>.</p>

<p><strong>Experimenter's bias</strong> is a form of confirmation bias in which
an experimenter continues training models until a preexisting
hypothesis is confirmed.</p>

<p><a class="glossary-anchor" name="confusion_matrix"></a>
</p><h2 class="hide-from-toc" id="confusion-matrix" data-text=" confusion matrix"> confusion matrix</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>An NxN table that summarizes the number of correct and incorrect predictions
that a <a href="https://developers.google.com/machine-learning/glossary#classification_model"><strong>classification model</strong></a> made.
For example, consider the following confusion matrix for a
<a href="https://developers.google.com/machine-learning/glossary#binary_classification"><strong>binary classification</strong></a> model:</p>

<div class="devsite-table-wrapper"><table>
<thead>
<tr>
<th></th>
<th>Tumor (predicted)</th>
<th>Non-Tumor (predicted)</th>
</tr>
</thead>

<tbody>
<tr>
<td>Tumor (ground truth)</td>
<td>18 (TP)</td>
<td>1 (FN)</td>
</tr>
<tr>
<td>Non-Tumor (ground truth)</td>
<td>6 (FP)</td>
<td>452 (TN)</td>
</tr>
</tbody>
</table></div>

<p>The preceding confusion matrix shows the following:</p>

<ul>
<li>Of the 19 predictions in which <a href="https://developers.google.com/machine-learning/glossary#ground_truth"><strong>ground truth</strong></a> was Tumor,
the model correctly classified 18 and incorrectly classified 1.</li>
<li>Of the 458 predictions in which ground truth was Non-Tumor, the model
correctly classified 452 and incorrectly classified 6.</li>
</ul>

<p>The confusion matrix for a <a href="https://developers.google.com/machine-learning/glossary#multi-class"><strong>multi-class classification</strong></a>
problem can help you identify patterns of mistakes.
For example, consider the following confusion matrix for a 3-class
multi-class classification model that categorizes three different iris types
(Virginica, Versicolor, and Setosa).  When the ground truth was Virginica, the
confusion matrix shows that the model was far more likely to mistakenly
predict Versicolor than Setosa:</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr>
    <th>&nbsp;</th>
    <th>Setosa (predicted)</th>
    <th>Versicolor (predicted)</th>
    <th>Virginica (predicted)</th>
  </tr>
  <tr>
    <td>Setosa (ground truth)</td>
    <td>88</td>
    <td>12</td>
    <td>0</td>
  </tr>
  <tr>
    <td>Versicolor (ground truth)</td>
    <td>6</td>
    <td>141</td>
    <td>7</td>
  </tr>
  <tr>
    <td>Virginica (ground truth)</td>
    <td>2</td>
    <td>27</td>
    <td>109</td>
  </tr>
</tbody></table></div>

<p>As yet another example, a confusion matrix could reveal that a model trained
to recognize handwritten digits tends to mistakenly predict 9 instead of 4,
or mistakenly predict 1 instead of 7.</p>

<p>Confusion matrices contain sufficient information to calculate a
variety of performance metrics, including <a href="https://developers.google.com/machine-learning/glossary#precision"><strong>precision</strong></a>
and <a href="https://developers.google.com/machine-learning/glossary#recall"><strong>recall</strong></a>.</p>

<p><a class="glossary-anchor" name="continuous_feature"></a>
</p><h2 class="hide-from-toc" id="continuous-feature" data-text=" continuous feature" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> continuous feature</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  continuous feature" data-title="Copy link to this section:  continuous feature" data-id="continuous-feature"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A floating-point <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a> with an infinite range of possible
values, such as temperature or weight.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#discrete_feature"><strong>discrete feature</strong></a>.</p>

<p><a class="glossary-anchor" name="convenience_sampling"></a>
</p><h2 class="hide-from-toc" id="convenience-sampling" data-text=" convenience sampling" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> convenience sampling</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  convenience sampling" data-title="Copy link to this section:  convenience sampling" data-id="convenience-sampling"></button></h2><p></p>

<p>Using a dataset not gathered scientifically in order to run quick
experiments. Later on, it's essential to switch to a scientifically gathered
dataset.</p>

<p><a class="glossary-anchor" name="convergence"></a>
</p><h2 class="hide-from-toc" id="convergence" data-text=" convergence" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> convergence</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  convergence" data-title="Copy link to this section:  convergence" data-id="convergence"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A state reached when <a href="https://developers.google.com/machine-learning/glossary#loss"><strong>loss</strong></a> values change very little or
not at all with each <a href="https://developers.google.com/machine-learning/glossary#iteration"><strong>iteration</strong></a>. For example, the following
<a href="https://developers.google.com/machine-learning/glossary#loss_curve"><strong>loss curve</strong></a> suggests convergence at around 700 iterations:</p>

<p>
<img src="./ML_Glossary_files/Convergence.png" height="300" loading="lazy" alt="Cartesian plot. X-axis is loss. Y-axis is the number of training
          iterations. Loss is very high during first few iterations, but
          drops sharply. After about 100 iterations, loss is still
          descending but far more gradually. After about 700 iterations,
          loss stays flat.">
</p>

<p>A model <strong>converges</strong> when additional training will not
improve the model.</p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#deep_model"><strong>deep learning</strong></a>, loss values sometimes stay constant or
nearly so for many iterations before finally descending. During a long period
of constant loss values, you may temporarily get a false sense of convergence.</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#early_stopping"><strong>early stopping</strong></a>.</p>

<p><a class="glossary-anchor" name="convex_function"></a>
</p><h2 class="hide-from-toc" id="convex-function" data-text=" convex function"> convex function</h2><p></p>

<p>A function in which the region above the graph of the function is a
<a href="https://developers.google.com/machine-learning/glossary#convex_set"><strong>convex set</strong></a>.  The prototypical convex function is
shaped something like the letter <strong>U</strong>.  For example, the following
are all convex functions:</p>

<p>
<img src="./ML_Glossary_files/convex_functions.png" height="300" loading="lazy" alt="U-shaped curves, each with a single minimum point.">
</p>

<p>In contrast, the following function is not convex.  Notice how the
region above the graph is not a convex set:</p>

<p>
<img src="./ML_Glossary_files/nonconvex_function.svg" loading="lazy" alt="A W-shaped curve with two different local minimum points.">
</p>

<p>A <strong>strictly convex function</strong> has exactly one local minimum point, which
is also the global minimum point. The classic U-shaped functions are
strictly convex functions.  However, some convex functions
(for example, straight lines) are not U-shaped.</p>

<devsite-expandable is-upgraded="" id="expandable-7"><a class="exw-control" aria-controls="expandable-7" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-a-deeper-look-at-the-math." data-text=" Click the icon for a deeper look at the math. ">
Click the icon for a deeper look at the math.<wbr>
</h4></a>



<div class="expand-background">
<p>
A lot of the common <a href="https://developers.google.com/machine-learning/glossary#loss-function">loss functions</a>, including the
following, are convex functions:
</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#L2_loss"><b>L<sub>2</sub> loss</b></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#Log_Loss"><b>Log Loss</b></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#L1_regularization"><b>L<sub>1</sub> regularization</b></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#L2_regularization"><b>L<sub>2</sub> regularization</b></a></li>
</ul>

<p>
Many variations of <a href="https://developers.google.com/machine-learning/glossary#gradient_descent"><b>gradient descent</b></a>
are guaranteed to find a point close to the minimum of a
strictly convex function.  Similarly, many variations of
<a href="https://developers.google.com/machine-learning/glossary#SGD"><b>stochastic gradient descent</b></a> have a high probability
(though, not a guarantee) of finding a point close to the minimum of a
strictly convex function.
</p>

<p>
The sum of two convex functions (for example,
L<sub>2</sub> loss + L<sub>1</sub> regularization) is a convex function.
</p>

<p>
<a href="https://developers.google.com/machine-learning/glossary#deep_model"><b>Deep models</b></a> are never convex functions.
Remarkably, algorithms designed for
<a href="https://developers.google.com/machine-learning/glossary#convex_optimization" )<b="">convex optimization</a> tend to find
reasonably good solutions on deep networks anyway, even though
those solutions are not guaranteed to be a global minimum.
</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="convex_optimization"></a>
</p><h2 class="hide-from-toc" id="convex-optimization" data-text="convex optimization">convex optimization</h2><p></p>

<p>The process of using mathematical techniques such as
<a href="https://developers.google.com/machine-learning/glossary#gradient_descent"><strong>gradient descent</strong></a> to find
the minimum of a <a href="https://developers.google.com/machine-learning/glossary#convex_function"><strong>convex function</strong></a>.
A great deal of research in machine learning has focused on formulating various
problems as convex optimization problems and in solving those problems more
efficiently.</p>

<p>For complete details, see Boyd and Vandenberghe,
<a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf" target="T">Convex
Optimization</a>.</p>

<p><a class="glossary-anchor" name="convex_set"></a>
</p><h2 class="hide-from-toc" id="convex-set" data-text="convex set">convex set</h2><p></p>

<p>A subset of Euclidean space such that a line drawn between any two points in the
subset remains completely within the subset.  For instance, the following two
shapes are convex sets:</p>

<p>
<img src="./ML_Glossary_files/convex_set.png" loading="lazy" alt="One illustration of a rectangle. Another illustration of an oval.">
</p>

<p>In contrast, the following two shapes are not convex sets:</p>

<p>
<img src="./ML_Glossary_files/nonconvex_set.png" loading="lazy" alt="One illustration of a pie-chart with a missing slice.
          Another illustration of a wildly irregular polygon.">
</p>

<p><a class="glossary-anchor" name="convolution"></a>
</p><h2 class="hide-from-toc" id="convolution" data-text="convolution">convolution</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>In mathematics, casually speaking, a mixture of two functions. In machine
learning, a convolution mixes the <a href="https://developers.google.com/machine-learning/glossary#convolutional_filter"><strong>convolutional
filter</strong></a> and the input matrix
in order to train <a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weights</strong></a>.</p>

<p>The term "convolution" in machine learning is often a shorthand way of
referring to either <a href="https://developers.google.com/machine-learning/glossary#convolutional_operation"><strong>convolutional operation</strong></a>
or <a href="https://developers.google.com/machine-learning/glossary#convolutional_layer"><strong>convolutional layer</strong></a>.</p>

<p>Without convolutions, a machine learning algorithm would have to learn
a separate weight for every cell in a large <a href="https://developers.google.com/machine-learning/glossary#tensor"><strong>tensor</strong></a>.  For example,
a machine learning algorithm training on 2K x 2K images would be forced to
find 4M separate weights. Thanks to convolutions, a machine learning
algorithm only has to find weights for every cell in the
<a href="https://developers.google.com/machine-learning/glossary#convolutional_filter"><strong>convolutional filter</strong></a>, dramatically reducing
the memory needed to train the model.  When the convolutional filter is
applied, it is simply replicated across cells such that each is multiplied
by the filter.</p>

<p><a class="glossary-anchor" name="convolutional_filter"></a>
</p><h2 class="hide-from-toc" id="convolutional-filter" data-text="convolutional filter">convolutional filter</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>One of the two actors in a
<a href="https://developers.google.com/machine-learning/glossary#convolutional_operation"><strong>convolutional operation</strong></a>. (The other actor
is a slice of an input matrix.) A convolutional filter is a matrix having
the same <a href="https://developers.google.com/machine-learning/glossary#rank"><strong>rank</strong></a> as the input matrix, but a smaller shape.
For example, given a 28x28 input matrix, the filter could be any 2D matrix
smaller than 28x28.</p>

<p>In photographic manipulation, all the cells in a convolutional filter are
typically set to a constant pattern of ones and zeroes. In machine learning,
convolutional filters are typically seeded with random numbers and then the
network <a href="https://developers.google.com/machine-learning/glossary#training"><strong>trains</strong></a> the ideal values.</p>

<p><a class="glossary-anchor" name="convolutional_layer"></a>
</p><h2 class="hide-from-toc" id="convolutional-layer" data-text="convolutional layer">convolutional layer</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>A layer of a <a href="https://developers.google.com/machine-learning/glossary#deep_model"><strong>deep neural network</strong></a> in which a
<a href="https://developers.google.com/machine-learning/glossary#convolutional_filter"><strong>convolutional filter</strong></a> passes along an input
matrix.  For example, consider the following 3x3
<a href="https://developers.google.com/machine-learning/glossary#convolutional_filter"><strong>convolutional filter</strong></a>:</p>

<p>
<img src="./ML_Glossary_files/ConvolutionalFilter33.svg" loading="lazy" alt="A 3x3 matrix with the following values: [[0,1,0], [1,0,1], [0,1,0]]">
</p>

<p>The following animation shows a convolutional layer consisting of 9
convolutional operations involving the 5x5 input matrix. Notice that each
convolutional operation works on a different 3x3 slice of the input matrix.
The resulting 3x3 matrix (on the right) consists of the results of the 9
convolutional operations:</p>

<p>
<img src="./ML_Glossary_files/AnimatedConvolution.gif" loading="lazy" alt="An animation showing two matrices. The first matrix is the 5x5
          matrix: [[128,97,53,201,198], [35,22,25,200,195],
          [37,24,28,197,182], [33,28,92,195,179], [31,40,100,192,177]].
          The second matrix is the 3x3 matrix:
          [[181,303,618], [115,338,605], [169,351,560]].
          The second matrix is calculated by applying the convolutional
          filter [[0, 1, 0], [1, 0, 1], [0, 1, 0]] across
          different 3x3 subsets of the 5x5 matrix.">
</p>

<p><a class="glossary-anchor" name="convolutional_neural_network"></a>
</p><h2 class="hide-from-toc" id="convolutional-neural-network" data-text="convolutional neural network">convolutional neural network</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural network</strong></a> in which at least one layer is a
<a href="https://developers.google.com/machine-learning/glossary#convolutional_layer"><strong>convolutional layer</strong></a>. A typical convolutional
neural network consists of some combination of the following layers:</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#convolutional_layer"><strong>convolutional layers</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#pooling"><strong>pooling layers</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#dense_layer"><strong>dense layers</strong></a></li>
</ul>

<p>Convolutional neural networks have had great success in certain kinds
of problems, such as image recognition.</p>

<p><a class="glossary-anchor" name="convolutional_operation"></a>
</p><h2 class="hide-from-toc" id="convolutional-operation" data-text="convolutional operation">convolutional operation</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>The following two-step mathematical operation:</p>

<ol>
<li>Element-wise multiplication of the
<a href="https://developers.google.com/machine-learning/glossary#convolutional_filter"><strong>convolutional filter</strong></a> and a slice of an
input matrix. (The slice of the input matrix has the same rank and
size as the convolutional filter.)</li>
<li>Summation of all the values in the resulting product matrix.</li>
</ol>

<p>For example, consider the following 5x5 input matrix:</p>

<p>
<img src="./ML_Glossary_files/ConvolutionalLayerInputMatrix.svg" loading="lazy" alt="The 5x5 matrix: [[128,97,53,201,198], [35,22,25,200,195],
          [37,24,28,197,182], [33,28,92,195,179], [31,40,100,192,177]].">
</p>

<p>Now imagine the following 2x2 convolutional filter:</p>

<p>
<img src="./ML_Glossary_files/ConvolutionalLayerFilter.svg" loading="lazy" alt="The 2x2 matrix: [[1, 0], [0, 1]]">
</p>

<p>Each convolutional operation involves a single 2x2 slice of the
input matrix. For instance, suppose we use the 2x2 slice at the
top-left of the input matrix.  So, the convolution operation on
this slice looks as follows:</p>

<p>
<img src="./ML_Glossary_files/ConvolutionalLayerOperation.svg" loading="lazy" alt="Applying the convolutional filter [[1, 0], [0, 1]] to the top-left
          2x2 section of the input matrix, which is [[128,97], [35,22]].
          The convolutional filter leaves the 128 and 22 intact, but zeroes
          out the 97 and 35. Consequently, the convolution operation yields
          the value 150 (128+22).">
</p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#convolutional_layer"><strong>convolutional layer</strong></a> consists of a
series of convolutional operations, each acting on a different slice
of the input matrix.</p>

<p><a class="glossary-anchor" name="cost"></a>
</p><h2 class="hide-from-toc" id="cost" data-text=" cost"> cost</h2><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#loss"><strong>loss</strong></a>.</p>

<p><a class="glossary-anchor" name="co-training"></a>
</p><h2 class="hide-from-toc" id="co-training" data-text=" co-training"> co-training</h2><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#semi-supervised_learning"><strong>semi-supervised learning</strong></a> approach
particularly useful when all of the following conditions are true:</p>

<ul>
<li>The ratio of <a href="https://developers.google.com/machine-learning/glossary#unlabeled_example"><strong>unlabeled examples</strong></a> to
<a href="https://developers.google.com/machine-learning/glossary#labeled_example"><strong>labeled examples</strong></a> in the dataset is high.</li>
<li>This is a classification problem (<a href="https://developers.google.com/machine-learning/glossary#binary_classification"><strong>binary</strong></a> or
<a href="https://developers.google.com/machine-learning/glossary#multi-class"><strong>multi-class</strong></a>).</li>
<li>The <a href="https://developers.google.com/machine-learning/glossary#dataset"><strong>dataset</strong></a> contains two different sets of
predictive features that are independent of each other and complementary.</li>
</ul>

<p>Co-training essentially amplifies independent signals into a stronger signal.
For instance, consider a <a href="https://developers.google.com/machine-learning/glossary#classification_model"><strong>classification model</strong></a> that
categorizes individual used cars as either <em>Good</em> or <em>Bad</em>.  One set of
predictive features might focus on aggregate characteristics such as the year,
make, and model of the car; another set of predictive features might focus on
the previous owner's driving record and the car's maintenance history.</p>

<p>The seminal paper on co-training is <a href="https://www.cs.cmu.edu/~avrim/Papers/cotrain.pdf">Combining Labeled and Unlabeled Data with
Co-Training</a> by
Blum and Mitchell.</p>

<p><a class="glossary-anchor" name="counterfactual_fairness"></a>
</p><h2 class="hide-from-toc" id="counterfactual-fairness" data-text=" counterfactual fairness "> counterfactual fairness </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div>
A <a href="https://developers.google.com/machine-learning/glossary#fairness_metric"><strong>fairness metric</strong></a> that checks whether a classifier
produces the same result for one individual as it does for another individual
who is identical to the first, except with respect to one or more
<a href="https://developers.google.com/machine-learning/glossary#sensitive_attribute"><strong>sensitive attributes</strong></a>. Evaluating a classifier for
counterfactual fairness is one method for surfacing potential sources of
bias in a model.<p></p>

<p>See
<a href="https://papers.nips.cc/paper/2017/file/1271a7029c9df08643b631b02cf9e116-Paper.pdf" target="T">"When Worlds Collide: Integrating Different Counterfactual
Assumptions in Fairness"</a> for a more detailed discussion of counterfactual
fairness.</p>

<p><a class="glossary-anchor" name="coverage_bias"></a>
</p><h2 class="hide-from-toc" id="coverage-bias" data-text=" coverage bias "> coverage bias </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>See <a href="https://developers.google.com/machine-learning/glossary#selection_bias"><strong>selection bias</strong></a>.</p>

<p><a class="glossary-anchor" name="crash_blossom"></a>
</p><h2 class="hide-from-toc" id="crash-blossom" data-text=" crash blossom"> crash blossom</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A sentence or phrase with an ambiguous meaning.
Crash blossoms present a significant problem in <a href="https://developers.google.com/machine-learning/glossary#natural_language_understanding"><strong>natural
language understanding</strong></a>.
For example, the headline <em>Red Tape Holds Up Skyscraper</em> is a
crash blossom because an NLU model could interpret the headline literally or
figuratively.</p>

<devsite-expandable is-upgraded="" id="expandable-8"><a class="exw-control" aria-controls="expandable-8" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-additional-notes._3" data-text=" Click the icon for additional notes. ">
Click the icon for additional notes.
</h4></a>



<div class="expand-background">
<p>

Just to clarify that mysterious headline:

</p><ul>
  <li><b>Red Tape</b> could refer to either of the following:
     <ul>
        <li>An adhesive</li>
        <li>Excessive bureaucracy</li>
     </ul>
  </li>
  <li><b>Holds Up</b> could refer to either of the following:
     <ul>
        <li>Structural support</li>
        <li>Delays</li>
     </ul>
  </li>
</ul>
<p></p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="critic"></a>
</p><h2 class="hide-from-toc" id="critic" data-text=" critic"> critic</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#deep_q-network"><strong>Deep Q-Network</strong></a>.</p>

<p><a class="glossary-anchor" name="cross-entropy"></a>
</p><h2 class="hide-from-toc" id="cross-entropy" data-text=" cross-entropy"> cross-entropy</h2><p></p>

<p>A generalization of <a href="https://developers.google.com/machine-learning/glossary#Log_Loss"><strong>Log Loss</strong></a> to
<a href="https://developers.google.com/machine-learning/glossary#multi-class"><strong>multi-class classification problems</strong></a>. Cross-entropy
quantifies the difference between two probability distributions.  See also
<a href="https://developers.google.com/machine-learning/glossary#perplexity"><strong>perplexity</strong></a>.</p>

<p><a class="glossary-anchor" name="cross-validation"></a>
</p><h2 class="hide-from-toc" id="cross-validation" data-text=" cross-validation"> cross-validation</h2><p></p>

<p>A mechanism for estimating how well a <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> would generalize to
new data by testing the model against one or more non-overlapping data subsets
withheld from the <a href="https://developers.google.com/machine-learning/glossary#training_set"><strong>training set</strong></a>.</p>

<p><a class="glossary-anchor" name="d"></a>
</p><h2 class="glossary" id="d" data-text="D">D</h2><p></p>

<p><a class="glossary-anchor" name="data_analysis"></a>
</p><h2 class="hide-from-toc" id="data-analysis" data-text=" data analysis"> data analysis</h2><p></p>

<p>Obtaining an understanding of data by considering samples, measurement,
and visualization. Data analysis can be particularly useful when a
dataset is first received, before one builds the first <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a>.
It is also crucial in understanding experiments and debugging problems with
the system.</p>

<p><a class="glossary-anchor" name="data_augmentation"></a>
</p><h2 class="hide-from-toc" id="data-augmentation" data-text=" data augmentation"> data augmentation</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>Artificially boosting the range and number of
<a href="https://developers.google.com/machine-learning/glossary#training"><strong>training</strong></a> examples
by transforming existing
<a href="https://developers.google.com/machine-learning/glossary#example"><strong>examples</strong></a> to create additional examples. For example,
suppose images are one of your
<a href="https://developers.google.com/machine-learning/glossary#feature"><strong>features</strong></a>, but your dataset doesn't
contain enough image examples for the model to learn useful associations.
Ideally, you'd add enough
<a href="https://developers.google.com/machine-learning/glossary#label"><strong>labeled</strong></a> images to your dataset to
enable your model to train properly. If that's not possible, data augmentation
can rotate, stretch, and reflect each image to produce many variants of the
original picture, possibly yielding enough labeled data to enable excellent
training.</p>

<p><a class="glossary-anchor" name="DataFrame"></a>
</p><h2 class="hide-from-toc" id="dataframe" data-text=" DataFrame"> DataFrame</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A popular <a href="https://developers.google.com/machine-learning/glossary#pandas"><strong>pandas</strong></a> datatype for representing
<a href="https://developers.google.com/machine-learning/glossary#dataset"><strong>datasets</strong></a> in memory.</p>

<p>A DataFrame is analogous to a table or a spreadsheet. Each column of
a DataFrame has a name (a header), and each row is identified by a
unique number.</p>

<p>Each column in a DataFrame is structured like a 2D array, except that
each column can be assigned its own data type.</p>

<p>See also the official
<a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html"><strong>pandas.DataFrame reference page</strong></a>.</p>

<p><a class="glossary-anchor" name="data-parallelism"></a>
</p><h2 class="hide-from-toc" id="data-parallelism" data-text=" data parallelism"> data parallelism</h2><p></p>

<p>A way of scaling <a href="https://developers.google.com/machine-learning/glossary#training"><strong>training</strong></a> or <a href="https://developers.google.com/machine-learning/glossary#inference"><strong>inference</strong></a>
that replicates an entire model onto
multiple devices and then passes a subset of the input data to each device.
Data parallelism can enable training and inference on very large
<a href="https://developers.google.com/machine-learning/glossary#batch_size"><strong>batch sizes</strong></a>; however, data parallelism requires that the
model be small enough to fit on all devices.</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#model-parallelism"><strong>model parallelism</strong></a>.</p>

<p><a class="glossary-anchor" name="data_set"></a>
<a class="glossary-anchor" name="dataset"></a>
</p><h2 class="hide-from-toc" id="data-set-or-dataset" data-text=" data set or dataset"> data set or dataset</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A collection of raw data, commonly (but not exclusively) organized in one
of the following formats:</p>

<ul>
<li>a spreadsheet</li>
<li>a file in CSV (comma-separated values) format</li>
</ul>

<p><a class="glossary-anchor" name="dataset_API"></a>
</p><h2 class="hide-from-toc" id="dataset-api-tf.data" data-text=" Dataset API (tf.data)"> Dataset API (tf.<wbr>data)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>A high-level <a href="https://developers.google.com/machine-learning/glossary#TensorFlow"><strong>TensorFlow</strong></a> API for reading data and
transforming it into a form that a machine learning algorithm requires.
A <code translate="no" dir="ltr">tf.data.Dataset</code> object represents a sequence of elements, in which
each element contains one or more <a href="https://developers.google.com/machine-learning/glossary#tensor"><strong>Tensors</strong></a>. A <code translate="no" dir="ltr">tf.data.Iterator</code>
object provides access to the elements of a <code translate="no" dir="ltr">Dataset</code>.</p>

<p>For details about the Dataset API, see
<a href="https://www.tensorflow.org/guide/data" target="T">tf.data: Build TensorFlow input pipelines</a>
in the <em>TensorFlow Programmer's Guide</em>.</p>

<p><a class="glossary-anchor" name="decision_boundary"></a>
</p><h2 class="hide-from-toc" id="decision-boundary" data-text=" decision boundary" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> decision boundary</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  decision boundary" data-title="Copy link to this section:  decision boundary" data-id="decision-boundary"></button></h2><p></p>

<p>The separator between
<a href="https://developers.google.com/machine-learning/glossary#class"><strong>classes</strong></a> learned by a
<a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> in a
<a href="https://developers.google.com/machine-learning/glossary#binary_classification"><strong>binary class</strong></a> or
<a href="https://developers.google.com/machine-learning/glossary#multi-class"><strong>multi-class classification problems</strong></a>. For example,
in the following image representing a binary classification problem,
the decision boundary is the frontier between the orange class and
the blue class:</p>

<p>
<img src="./ML_Glossary_files/decision_boundary.png" loading="lazy" alt="A well-defined boundary between one class and another.">
</p>

<p><a class="glossary-anchor" name="decision-forest"></a>
</p><h2 class="hide-from-toc" id="decision-forest" data-text=" decision forest " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> decision forest </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  decision forest " data-title="Copy link to this section:  decision forest " data-id="decision-forest"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>A model created from multiple <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision trees</strong></a>.
A decision forest makes a prediction by aggregating the predictions of
its decision trees. Popular types of decision forests include
<a href="https://developers.google.com/machine-learning/glossary#random-forest"><strong>random forests</strong></a> and <a href="https://developers.google.com/machine-learning/glossary#gbt"><strong>gradient boosted trees</strong></a>.</p>

<p><a class="glossary-anchor" name="decision_threshold"></a>
</p><h2 class="hide-from-toc" id="decision-threshold" data-text=" decision threshold" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> decision threshold</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  decision threshold" data-title="Copy link to this section:  decision threshold" data-id="decision-threshold"></button></h2><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#classification_threshold"><strong>classification threshold</strong></a>.</p>

<p><a class="glossary-anchor" name="decision-tree"></a>
</p><h2 class="hide-from-toc" id="decision-tree" data-text=" decision tree" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> decision tree</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  decision tree" data-title="Copy link to this section:  decision tree" data-id="decision-tree"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>A supervised learning model composed of a set of
<a href="https://developers.google.com/machine-learning/glossary#condition"><strong>conditions</strong></a> and <a href="https://developers.google.com/machine-learning/glossary#leaf"><strong>leaves</strong></a> organized hierarchically.
For example, the following is a decision tree:</p>

<p>
<img src="./ML_Glossary_files/DecisionTree.png" loading="lazy" height="340" width="559" alt="A decision tree consisting of four conditions arranged
          hierarchically, which lead to five leaves.">
</p>



<p><a class="glossary-anchor" name="deep_model"></a>
</p><h2 class="hide-from-toc" id="deep-model" data-text=" deep model" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> deep model</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  deep model" data-title="Copy link to this section:  deep model" data-id="deep-model"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural network</strong></a> containing more than one
<a href="https://developers.google.com/machine-learning/glossary#hidden_layer"><strong>hidden layer</strong></a>.</p>

<p>A deep model is also called a <strong>deep neural network</strong>.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#wide_model"><strong>wide model</strong></a>.</p>

<p><a class="glossary-anchor" name="decoder"></a>
</p><h2 class="hide-from-toc" id="decoder" data-text=" decoder"> decoder</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>In general, any ML system that converts from a processed, dense, or
internal representation to a more raw, sparse, or external representation.</p>

<p>Decoders are often a component of a larger model, where they are frequently
paired with an <a href="https://developers.google.com/machine-learning/glossary#encoder"><strong>encoder</strong></a>.</p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#sequence-to-sequence-task"><strong>sequence-to-sequence tasks</strong></a>, a decoder
starts with the internal state generated by the encoder to predict the next
sequence.</p>

<p>Refer to <a href="https://developers.google.com/machine-learning/glossary#Transformer"><strong>Transformer</strong></a> for the definition of a decoder within
the Transformer architecture.</p>

<p><a class="glossary-anchor" name="deep_neural_network"></a>
</p><h2 class="hide-from-toc" id="deep-neural-network" data-text=" deep neural network"> deep neural network</h2><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#deep_model"><strong>deep model</strong></a>.</p>



<p><a class="glossary-anchor" name="deep_q-network"></a>
</p><h2 class="hide-from-toc" id="deep-q-network-dqn" data-text=" Deep Q-Network (DQN)"> Deep Q-Network (DQN)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#q-learning"><strong>Q-learning</strong></a>, a deep <a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural network</strong></a>
that predicts <a href="https://developers.google.com/machine-learning/glossary#q-function"><strong>Q-functions</strong></a>.</p>

<p><strong>Critic</strong> is a synonym for Deep Q-Network.</p>

<p><a class="glossary-anchor" name="demographic_parity"></a>
</p><h2 class="hide-from-toc" id="demographic-parity" data-text=" demographic parity"> demographic parity</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#fairness_metric"><strong>fairness metric</strong></a> that is satisfied if
the results of a model's classification are not dependent on a
given <a href="https://developers.google.com/machine-learning/glossary#sensitive_attribute"><strong>sensitive attribute</strong></a>.</p>

<p>For example, if both Lilliputians and Brobdingnagians apply to
Glubbdubdrib University, demographic parity is achieved if the percentage
of Lilliputians admitted is the same as the percentage of Brobdingnagians
admitted, irrespective of whether one group is on average more qualified
than the other.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#equalized_odds"><strong>equalized odds</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#equality_of_opportunity"><strong>equality of opportunity</strong></a>, which permit
classification results in aggregate to depend on sensitive attributes,
but do not permit classification results for certain specified ground-truth
labels to depend on sensitive attributes.  See
<a href="http://research.google.com/bigpicture/attacking-discrimination-in-ml/" target="T">"Attacking
discrimination with smarter machine learning"</a> for a visualization
exploring the tradeoffs when optimizing for demographic parity.</p>

<p><a class="glossary-anchor" name="denoising"></a>
</p><h2 class="hide-from-toc" id="denoising" data-text=" denoising"> denoising</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A common approach to <a href="https://developers.google.com/machine-learning/glossary#self-supervised-learning"><strong>self-supervised learning</strong></a>
in which:</p>

<ol>
<li><a href="https://developers.google.com/machine-learning/glossary#noise"><strong>Noise</strong></a> is artificially added to the dataset.</li>
<li>The <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> tries to remove the noise.</li>
</ol>

<p>Denoising enables learning from <a href="https://developers.google.com/machine-learning/glossary#unlabeled_example"><strong>unlabeled examples</strong></a>.
The original <a href="https://developers.google.com/machine-learning/glossary#dataset"><strong>dataset</strong></a> serves as the target or
<a href="https://developers.google.com/machine-learning/glossary#label"><strong>label</strong></a> and
the noisy data as the input.</p>

<p>Some <a href="https://developers.google.com/machine-learning/glossary#masked-language-model"><strong>masked language models</strong></a> use denoising
as follows:</p>

<ol>
<li>Noise is artificially added to an unlabeled sentence by masking some of
 the tokens.</li>
<li>The model tries to predict the original tokens.</li>
</ol>

<p><a class="glossary-anchor" name="dense_feature"></a>
</p><h2 class="hide-from-toc" id="dense-feature" data-text=" dense feature"> dense feature</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a> in which most or all values are nonzero, typically
a <a href="https://developers.google.com/machine-learning/glossary#tensor"><strong>Tensor</strong></a> of floating-point values.  For example, the following
10-element Tensor is dense because 9 of its values are nonzero:</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr> <td>8</td> <td>3</td> <td>7</td> <td>5</td> <td>2</td>
       <td>4</td> <td>0</td> <td>4</td> <td>9</td> <td>6</td> </tr>
</tbody></table></div>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#sparse_features"><strong>sparse feature</strong></a>.</p>

<p><a class="glossary-anchor" name="dense_layer"></a>
</p><h2 class="hide-from-toc" id="dense-layer" data-text=" dense layer"> dense layer</h2><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#fully_connected_layer"><strong>fully connected layer</strong></a>.</p>

<p><a class="glossary-anchor" name="depth"></a>
</p><h2 class="hide-from-toc" id="depth" data-text=" depth"> depth</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The sum of the following in a <a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural network</strong></a>:</p>

<ul>
<li>the number of <a href="https://developers.google.com/machine-learning/glossary#hidden_layer"><strong>hidden layers</strong></a></li>
<li>the number of <a href="https://developers.google.com/machine-learning/glossary#output_layer"><strong>output layers</strong></a>, which is typically 1</li>
<li>the number of any <a href="https://developers.google.com/machine-learning/glossary#embedding_layer"><strong>embedding layers</strong></a></li>
</ul>

<p>For example, a neural network with five hidden layers and one output layer
has a depth of 6.</p>

<p>Notice that the <a href="https://developers.google.com/machine-learning/glossary#input_layer"><strong>input layer</strong></a> does not
influence depth.</p>

<p><a class="glossary-anchor" name="depthwise_separable_cnn"></a>
</p><h2 class="hide-from-toc" id="depthwise-separable-convolutional-neural-network-sepcnn" data-text="depthwise separable convolutional neural network (sepCNN)">depthwise separable convolutional neural network (sepCNN)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#convolutional_neural_network"><strong>convolutional neural network</strong></a>
architecture based on
<a href="https://github.com/tensorflow/tpu/tree/master/models/experimental/inception">Inception</a>,
but where Inception modules are replaced with depthwise separable
convolutions.  Also known as Xception.</p>

<p>A depthwise separable convolution (also abbreviated as separable convolution)
factors a standard 3-D convolution into two separate convolution operations
that are more computationally efficient: first, a depthwise convolution,
with a depth of 1 (n ✕ n ✕ 1), and then second, a pointwise convolution,
with length and width of 1 (1 ✕ 1 ✕ n).</p>

<p>To learn more, see <a href="https://arxiv.org/pdf/1610.02357.pdf">Xception: Deep Learning with Depthwise Separable
Convolutions</a>.</p>

<p><a class="glossary-anchor" name="derived-label"></a>
</p><h2 class="hide-from-toc" id="derived-label" data-text=" derived label"> derived label</h2><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#proxy_labels"><strong>proxy label</strong></a>.</p>

<p><a class="glossary-anchor" name="device"></a>
</p><h2 class="hide-from-toc" id="device" data-text=" device"> device</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>A category of hardware that can run a TensorFlow session, including
CPUs, GPUs, and <a href="https://developers.google.com/machine-learning/glossary#TPU"><strong>TPUs</strong></a>.</p>

<p><a class="glossary-anchor" name="dimension_reduction"></a>
</p><h2 class="hide-from-toc" id="dimension-reduction" data-text=" dimension reduction"> dimension reduction</h2><p></p>

<p>Decreasing the number of dimensions used to represent a particular feature
in a feature vector, typically by
converting to an <a href="https://developers.google.com/machine-learning/glossary#embedding_vector"><strong>embedding vector</strong></a>.</p>

<p><a class="glossary-anchor" name="dimensions"></a>
</p><h2 class="hide-from-toc" id="dimensions" data-text=" dimensions "> dimensions </h2><p></p>

<p>Overloaded term having any of the following definitions:</p>

<ul>
<li><p>The number of levels of coordinates in a <a href="https://developers.google.com/machine-learning/glossary#tensor"><strong>Tensor</strong></a>. For
example:</p>

<ul>
<li>A scalar has zero dimensions; for example, <code translate="no" dir="ltr">["Hello"]</code>.</li>
<li>A vector has one dimension; for example, <code translate="no" dir="ltr">[3, 5, 7, 11]</code>.</li>
<li>A matrix has two dimensions; for example, <code translate="no" dir="ltr">[[2, 4, 18], [5, 7, 14]]</code>.</li>
</ul>

<p>You can uniquely specify a particular cell in a one-dimensional vector
with one coordinate; you need two coordinates to uniquely specify a
particular cell in a two-dimensional matrix.</p></li>
<li><p>The number of entries in a <a href="https://developers.google.com/machine-learning/glossary#feature_vector"><strong>feature vector</strong></a>.</p></li>
<li><p>The number of elements in an <a href="https://developers.google.com/machine-learning/glossary#embedding_layer"><strong>embedding layer</strong></a>.
</p></li></ul><p></p>


<p><a class="glossary-anchor" name="discrete_feature"></a>
</p><h2 class="hide-from-toc" id="discrete-feature" data-text=" discrete feature"> discrete feature</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a> with a finite set of possible values. For example,
a feature whose values may only be <em>animal</em>, <em>vegetable</em>, or <em>mineral</em> is a
discrete (or categorical) feature.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#continuous_feature"><strong>continuous feature</strong></a>.</p>

<p><a class="glossary-anchor" name="discriminative_model"></a>
</p><h2 class="hide-from-toc" id="discriminative-model" data-text=" discriminative model"> discriminative model</h2><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> that predicts <a href="https://developers.google.com/machine-learning/glossary#label"><strong>labels</strong></a> from a set of one or
more <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>features</strong></a>. More formally, discriminative models define the
conditional probability of an output given the features and
<a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weights</strong></a>; that is:</p>

<devsite-code data-copy-event-label=""><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="pln">p</span><span class="pun">(</span><span class="pln">output </span><span class="pun">|</span><span class="pln"> features</span><span class="pun">,</span><span class="pln"> weights</span><span class="pun">)</span><span class="pln"><br></span></pre></devsite-code>

<p>For example, a model that predicts whether an email is spam from features
and weights is a discriminative model.</p>

<p>The vast majority of supervised learning models, including classification
and regression models, are discriminative models.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#generative_model"><strong>generative model</strong></a>.</p>

<p><a class="glossary-anchor" name="discriminator"></a>
</p><h2 class="hide-from-toc" id="discriminator" data-text=" discriminator"> discriminator</h2><p></p>

<p>A system that determines whether <a href="https://developers.google.com/machine-learning/glossary#example"><strong>examples</strong></a> are real or fake.</p>

<p>Alternatively, the subsystem within a <a href="https://developers.google.com/machine-learning/glossary#generative_adversarial_network"><strong>generative adversarial
network</strong></a> that determines whether
the examples created by the <a href="https://developers.google.com/machine-learning/glossary#generator"><strong>generator</strong></a> are real or fake.</p>

<p><a class="glossary-anchor" name="disparate_impact"></a>
</p><h2 class="hide-from-toc" id="disparate-impact" data-text=" disparate impact"> disparate impact</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>Making decisions about people that impact different population
subgroups disproportionately. This usually refers to situations
where an algorithmic decision-making process harms or benefits
some subgroups more than others.</p>

<p>For example, suppose an algorithm that determines a Lilliputian's
eligibility for a miniature-home loan is more likely to classify
them as “ineligible” if their mailing address contains a certain
postal code. If Big-Endian Lilliputians  are more likely to have
mailing addresses with this postal code than Little-Endian Lilliputians,
then this algorithm may result in disparate impact.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#disparate_treatment"><strong>disparate treatment</strong></a>,
which focuses on disparities that result when subgroup characteristics
are explicit inputs to an algorithmic decision-making process.</p>

<p><a class="glossary-anchor" name="disparate_treatment"></a>
</p><h2 class="hide-from-toc" id="disparate-treatment" data-text=" disparate treatment"> disparate treatment</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>Factoring subjects' <a href="https://developers.google.com/machine-learning/glossary#sensitive_attribute"><strong>sensitive attributes</strong></a>
into an algorithmic decision-making process such that different subgroups
of people are treated differently.</p>

<p>For example, consider an algorithm that
determines Lilliputians’ eligibility for a miniature-home loan based on the
data they provide in their loan application.  If the algorithm uses a
Lilliputian’s affiliation as Big-Endian or Little-Endian as an input, it
is enacting disparate treatment along that dimension.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#disparate_impact"><strong>disparate impact</strong></a>, which focuses
on disparities in the societal impacts of algorithmic decisions on subgroups,
irrespective of whether those subgroups are inputs to the model.</p>
<aside class="warning"><strong>Warning:</strong><span> Because sensitive attributes are almost always correlated with
other features the data may have, explicitly removing sensitive attribute
information does not guarantee that subgroups will be treated equally.
For example, removing sensitive demographic attributes from a training
data set that still includes postal code as a feature may address disparate
treatment of subgroups, but there still might be
disparate impact upon these groups because
postal code might serve as a <a href="https://developers.google.com/machine-learning/glossary#proxy_sensitive_attributes"><strong>proxy</strong></a> for other
demographic information.</span></aside>
<p><a class="glossary-anchor" name="divisive_clustering"></a>
</p><h2 class="hide-from-toc" id="divisive-clustering" data-text=" divisive clustering"> divisive clustering</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Clustering">#clustering</div>
</div><p></p>

<p>See <a href="https://developers.google.com/machine-learning/glossary#hierarchical_clustering"><strong>hierarchical clustering</strong></a>.</p>

<p><a class="glossary-anchor" name="downsampling"></a>
</p><h2 class="hide-from-toc" id="downsampling" data-text=" downsampling"> downsampling</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>Overloaded term that can mean either of the following:</p>

<ul>
<li>Reducing the amount of information in a <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a> in
order to <a href="https://developers.google.com/machine-learning/glossary#training"><strong>train</strong></a> a model more efficiently. For example,
before training an image recognition model, downsampling high-resolution
images to a lower-resolution format.</li>
<li>Training on a disproportionately low percentage of over-represented
<a href="https://developers.google.com/machine-learning/glossary#class"><strong>class</strong></a>
examples in order to improve model training on under-represented classes.
For example, in a <a href="https://developers.google.com/machine-learning/glossary#class_imbalanced_data_set"><strong>class-imbalanced
dataset</strong></a>, models tend to learn a lot about the
<a href="https://developers.google.com/machine-learning/glossary#majority_class"><strong>majority class</strong></a> and not enough about the
<a href="https://developers.google.com/machine-learning/glossary#minority_class"><strong>minority class</strong></a>. Downsampling helps
balance the amount of training on the majority and minority classes.</li>
</ul>

<p><a class="glossary-anchor" name="DQN"></a>
</p><h2 class="hide-from-toc" id="dqn" data-text=" DQN"> DQN</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>Abbreviation for <a href="https://developers.google.com/machine-learning/glossary#deep_q-network"><strong>Deep Q-Network</strong></a>.</p>

<p><a class="glossary-anchor" name="dropout_regularization"></a>
</p><h2 class="hide-from-toc" id="dropout-regularization" data-text=" dropout regularization"> dropout regularization</h2><p></p>

<p>A form of <a href="https://developers.google.com/machine-learning/glossary#regularization"><strong>regularization</strong></a> useful in training
<a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural networks</strong></a>. Dropout regularization
removes a random selection of a fixed number of the units in a network
layer for a single gradient step. The more units dropped out, the stronger
the regularization. This is analogous to training the network to emulate
an exponentially large <a href="https://developers.google.com/machine-learning/glossary#ensemble"><strong>ensemble</strong></a> of smaller networks.
For full details, see
<a href="http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf" target="T">Dropout: A Simple Way to Prevent Neural Networks from
Overfitting</a>.</p>

<p><a class="glossary-anchor" name="dynamic"></a>
</p><h2 class="hide-from-toc" id="dynamic" data-text=" dynamic"> dynamic</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Something done frequently or continuously.
The terms <strong>dynamic</strong> and <strong>online</strong> are synonyms in machine learning.
The following are common uses of <strong>dynamic</strong> and <strong>online</strong> in machine
learning:</p>

<ul>
<li>A <a href="https://developers.google.com/machine-learning/glossary#dynamic_model"><strong>dynamic model</strong></a> (or <strong>online model</strong>) is a model
that is retrained frequently or continuously.</li>
<li><strong>Dynamic training</strong> (or <strong>online training</strong>) is the process of training
frequently or continuously.</li>
<li><strong>Dynamic inference</strong> (or <strong>online inference</strong>) is the process of
generating predictions on demand.</li>
</ul>

<p><a class="glossary-anchor" name="dynamic_model"></a>
</p><h2 class="hide-from-toc" id="dynamic-model" data-text=" dynamic model"> dynamic model</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> that is frequently (maybe even continuously)
retrained. A dynamic model is a "lifelong learner" that
constantly adapts to evolving data.  A dynamic model is also known as an
<strong>online model</strong>.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#static-model"><strong>static model</strong></a>.</p>

<p><a class="glossary-anchor" name="e"></a>
</p><h2 class="glossary" id="e" data-text="E">E</h2><p></p>

<p><a class="glossary-anchor" name="eager_execution"></a>
</p><h2 class="hide-from-toc" id="eager-execution" data-text=" eager execution"> eager execution</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>A TensorFlow programming environment in which <a href="https://developers.google.com/machine-learning/glossary#Operation"><strong>operations</strong></a>
run immediately. In contrast, operations called in
<a href="https://developers.google.com/machine-learning/glossary#graph_execution"><strong>graph execution</strong></a> don't run until they are explicitly
evaluated. Eager execution is an
<a href="https://wikipedia.org/wiki/Imperative_programming" target="T">imperative interface</a>, much
like the code in most programming languages. Eager execution programs are
generally far easier to debug than graph execution programs.</p>

<p><a class="glossary-anchor" name="early_stopping"></a>
</p><h2 class="hide-from-toc" id="early-stopping" data-text=" early stopping"> early stopping</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A method for <a href="https://developers.google.com/machine-learning/glossary#regularization"><strong>regularization</strong></a> that involves ending
<a href="https://developers.google.com/machine-learning/glossary#training"><strong>training</strong></a> <em>before</em> training loss finishes
decreasing. In early stopping, you intentionally stop training the model
when the loss on a <a href="https://developers.google.com/machine-learning/glossary#validation_set"><strong>validation dataset</strong></a> starts to
increase; that is, when
<a href="https://developers.google.com/machine-learning/glossary#generalization"><strong>generalization</strong></a> performance worsens.</p>

<devsite-expandable is-upgraded="" id="expandable-9"><a class="exw-control" aria-controls="expandable-9" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-additional-notes._4" data-text=" Click the icon for additional notes. ">
Click the icon for additional notes.
</h4></a>



<div class="expand-background">
<p>
Early stopping may seem counterintuitive. After all, telling a model to halt
training while the loss is still decreasing may seem like telling a chef to
stop cooking before the dessert has fully baked. However, training a model for
too long can lead to <a href="https://developers.google.com/machine-learning/glossary#overfitting">overfitting</a>. That is, if you
train a model too long, the model may fit the training data so closely that
the model doesn't make good predictions on new examples.
</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="earth-movers-distance"></a>
</p><h2 class="hide-from-toc" id="earth-movers-distance-emd" data-text=" earth mover&#39;s distance (EMD)"> earth mover's distance (EMD)</h2><p></p>

<p>A measure of the relative similarity between two documents. The lower the
earth mover's distance, the more similar the documents.</p>

<p><a class="glossary-anchor" name="embedding_layer"></a>
</p><h2 class="hide-from-toc" id="embedding-layer" data-text=" embedding layer"> embedding layer</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A special <a href="https://developers.google.com/machine-learning/glossary#hidden_layer"><strong>hidden layer</strong></a> that trains on a
high-dimensional <a href="https://developers.google.com/machine-learning/glossary#categorical_data"><strong>categorical</strong></a> feature to
gradually learn a lower dimension embedding vector. An
embedding layer enables a neural network to train far more
efficiently than training just on the high-dimensional categorical feature.</p>

<p>For example, Earth currently supports about 73,000 tree species. Suppose
tree species is a <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a> in your model, so your model's
input layer includes a <a href="https://developers.google.com/machine-learning/glossary#one-hot_encoding"><strong>one-hot vector</strong></a> 73,000
elements long.
For example, perhaps <code translate="no" dir="ltr">baobab</code> would be represented something like this:</p>

<p>
<img src="./ML_Glossary_files/One-HotRepresentationOfTreeSpecies.png" loading="lazy" alt="An array of 73,000 elements. The first 6,232 elements hold the value
     0. The next element holds the value 1. The final 66,767 elements hold
     the value zero.">
</p>

<p>A 73,000-element array is very long. If you don't add an embedding layer
to the model, training is going to be very time consuming due to
multiplying 72,999 zeros. Perhaps you pick the embedding layer to consist
of 12 dimensions. Consequently, the embedding layer will gradually learn
a new embedding vector for each tree species.</p>

<p>In certain situations, <a href="https://developers.google.com/machine-learning/glossary#hashing"><strong>hashing</strong></a> is a reasonable alternative
to an embedding layer.</p>

<p><a class="glossary-anchor" name="embedding_space"></a>
</p><h2 class="hide-from-toc" id="embedding-space" data-text=" embedding space"> embedding space</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>The d-dimensional vector space that features from a higher-dimensional
vector space are mapped to. Ideally, the embedding space contains a
structure that yields meaningful mathematical results; for example,
in an ideal embedding space, addition and subtraction of embeddings
can solve word analogy tasks.</p>

<p>The <a href="https://wikipedia.org/wiki/Dot_product" target="T">dot product</a>
of two embeddings is a measure of their similarity.</p>

<p><a class="glossary-anchor" name="embedding_vector"></a>
</p><h2 class="hide-from-toc" id="embedding-vector" data-text=" embedding vector"> embedding vector</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>Broadly speaking, an array of floating-point numbers taken from <strong>any</strong>
<a href="https://developers.google.com/machine-learning/glossary#hidden_layer"><strong>hidden layer</strong></a> that describe the inputs to that hidden layer.
Often, an embedding vector is the array of floating-point numbers trained in
an embedding layer. For example, suppose an embedding layer must learn an
embedding vector for each of the 73,000 tree species on Earth. Perhaps the
following array is the embedding vector for a baobab tree:</p>

<p>
<img src="./ML_Glossary_files/EmbeddingBaobab.png" loading="lazy" alt="An array of 12 elements, each holding a floating-point number
          between 0.0 and 1.0.">
</p>

<p>An embedding vector is not a bunch of random numbers. An embedding layer
determines these values through training, similar to the way a
neural network learns other weights during training. Each element of the
array is a rating along some characteristic of a tree species. Which
element represents which tree species' characteristic? That's very hard
for humans to determine.</p>

<p>The mathematically remarkable part of an embedding vector is that similar
items have similar sets of floating-point numbers. For example, similar
tree species have a more similar set of floating-point numbers than
dissimilar tree species. Redwoods and sequoias are related tree species,
so they'll have a more similar set of floating-pointing numbers than
redwoods and coconut palms. The numbers in the embedding vector will
change each time you retrain the model, even if you retrain the model
with identical input.</p>

<p><a class="glossary-anchor" name="ERM"></a>
</p><h2 class="hide-from-toc" id="empirical-risk-minimization-erm" data-text=" empirical risk minimization (ERM)"> empirical risk minimization (ERM)</h2><p></p>

<p>Choosing the function that minimizes loss on the training set. Contrast
with <a href="https://developers.google.com/machine-learning/glossary#SRM"><strong>structural risk minimization</strong></a>.</p>

<p><a class="glossary-anchor" name="encoder"></a>
</p><h2 class="hide-from-toc" id="encoder" data-text=" encoder"> encoder</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>In general, any ML system that converts from a raw, sparse, or external
representation into a more processed, denser, or more internal representation.</p>

<p>Encoders are often a component of a larger model, where they are frequently
paired with a <a href="https://developers.google.com/machine-learning/glossary#decoder"><strong>decoder</strong></a>. Some <a href="https://developers.google.com/machine-learning/glossary#Transformer"><strong>Transformers</strong></a>
pair encoders with decoders, though other Transformers use only the encoder
or only the decoder.</p>

<p>Some systems use the encoder's output as the input to a classification or
regression network.</p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#sequence-to-sequence-task"><strong>sequence-to-sequence tasks</strong></a>, an encoder
takes an input sequence and returns an internal state (a vector). Then, the
<a href="https://developers.google.com/machine-learning/glossary#decoder"><strong>decoder</strong></a> uses that internal state to predict the next sequence.</p>

<p>Refer to <a href="https://developers.google.com/machine-learning/glossary#Transformer"><strong>Transformer</strong></a> for the definition of an encoder in
the Transformer architecture.</p>

<p><a class="glossary-anchor" name="ensemble"></a>
</p><h2 class="hide-from-toc" id="ensemble" data-text=" ensemble"> ensemble</h2><p></p>

<p>A collection of <a href="https://developers.google.com/machine-learning/glossary#model"><strong>models</strong></a> trained independently whose predictions
are averaged or aggregated. In many cases, an ensemble produces better
predictions than a single model. For example, a
<a href="https://developers.google.com/machine-learning/glossary#random-forest"><strong>random forest</strong></a> is an ensemble built from multiple
<a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision trees</strong></a>. Note that not all
<a href="https://developers.google.com/machine-learning/glossary#decision-forest"><strong>decision forests</strong></a> are ensembles.</p>

<p><a class="glossary-anchor" name="entropy"></a>
</p><h2 class="hide-from-toc" id="entropy" data-text=" entropy "> entropy </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>In
<a href="https://wikipedia.org/wiki/Information_theory" target="T">
information theory</a>,
a description of how unpredictable a probability
distribution is. Alternatively, entropy is also defined as how much
information each <a href="https://developers.google.com/machine-learning/glossary#example"><strong>example</strong></a> contains. A distribution has
the highest possible entropy when all values of a random variable are
equally likely.</p>

<p>The entropy of a set with two possible values "0" and "1" (for example,
the labels in a <a href="https://developers.google.com/machine-learning/glossary#binary_classification"><strong>binary classification</strong></a> problem)
has the following formula:</p>

<p><tt>
&nbsp;&nbsp;H = -p log p - q log q = -p log p - (1-p) * log (1-p)
</tt></p>

<p>where:</p>

<ul>
<li><tt>H</tt> is the entropy.</li>
<li><tt>p</tt> is the fraction of "1" examples.</li>
<li><tt>q</tt> is the fraction of "0" examples. Note that q = (1 - p)</li>
<li><tt>log</tt> is generally log<sub>2</sub>. In this case, the entropy
unit is a bit.</li>
</ul>

<p>For example, suppose the following:</p>

<ul>
<li>100 examples contain the value "1"</li>
<li>300 examples contain the value "0"</li>
</ul>

<p>Therefore, the entropy value is:</p>

<p></p><ul><tt>
  <li>p = 0.25</li>
  <li>q = 0.75</li>
  </tt><li><tt>H = (-0.25)log<sub>2</sub>(0.25) - (0.75)log<sub>2</sub>(0.75) =
      0.81</tt> bits per example</li>
</ul><p></p>

<p>A set that is perfectly balanced (for example, 200 "0"s and 200 "1"s)
would have an entropy of 1.0 bit per example. As a set becomes more
<a href="https://developers.google.com/machine-learning/glossary#class_imbalanced_data_set"><strong>imbalanced</strong></a>, its entropy moves towards 0.0.</p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision trees</strong></a>, entropy helps formulate
<a href="https://developers.google.com/machine-learning/glossary#information-gain"><strong>information gain</strong></a> to help the
<a href="https://developers.google.com/machine-learning/glossary#splitter"><strong>splitter</strong></a> select the <a href="https://developers.google.com/machine-learning/glossary#condition"><strong>conditions</strong></a>
during the growth of a classification decision tree.</p>

<p>Compare entropy with:</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#gini-impurity"><strong>gini impurity</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#cross-entropy"><strong>cross-entropy</strong></a> loss function</li>
</ul>

<p>Entropy is often called Shannon's entropy.</p>

<p><a class="glossary-anchor" name="environment"></a>
</p><h2 class="hide-from-toc" id="environment" data-text=" environment"> environment</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In reinforcement learning, the world that contains the <a href="https://developers.google.com/machine-learning/glossary#agent"><strong>agent</strong></a>
and allows the agent to observe that world's <a href="https://developers.google.com/machine-learning/glossary#state"><strong>state</strong></a>. For example,
the represented world can be a game like chess, or a physical world like a
maze. When the agent applies an <a href="https://developers.google.com/machine-learning/glossary#action"><strong>action</strong></a> to the environment,
then the environment transitions between states.</p>

<p><a class="glossary-anchor" name="episode"></a>
</p><h2 class="hide-from-toc" id="episode" data-text=" episode"> episode</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In reinforcement learning, each of the repeated attempts by the
<a href="https://developers.google.com/machine-learning/glossary#agent"><strong>agent</strong></a> to learn an <a href="https://developers.google.com/machine-learning/glossary#environment"><strong>environment</strong></a>.</p>

<p><a class="glossary-anchor" name="epoch"></a>
</p><h2 class="hide-from-toc" id="epoch" data-text=" epoch"> epoch</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A full training pass over the entire <a href="https://developers.google.com/machine-learning/glossary#training_set"><strong>training set</strong></a>
such that each <a href="https://developers.google.com/machine-learning/glossary#example"><strong>example</strong></a> has been processed once.</p>

<p>An epoch represents <code translate="no" dir="ltr">N</code>/<a href="https://developers.google.com/machine-learning/glossary#batch_size"><strong>batch size</strong></a>
training <a href="https://developers.google.com/machine-learning/glossary#iteration"><strong>iterations</strong></a>, where <code translate="no" dir="ltr">N</code> is the
total number of examples.</p>

<p>For instance, suppose the following:</p>

<ul>
<li>The dataset consists of 1,000 examples.</li>
<li>The batch size is 50 examples.</li>
</ul>

<p>Therefore, a single epoch requires 20 iterations:</p>

<devsite-code no-copy="" data-copy-event-label=""><pre translate="no" dir="ltr" is-upgraded="">1 epoch = (N/batch size) = (1,000 / 50) = 20 iterations
</pre></devsite-code>

<p><a class="glossary-anchor" name="epsilon_greedy_policy"></a>
</p><h2 class="hide-from-toc" id="epsilon-greedy-policy" data-text=" epsilon greedy policy"> epsilon greedy policy</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In reinforcement learning, a <a href="https://developers.google.com/machine-learning/glossary#policy"><strong>policy</strong></a> that either follows a
<a href="https://developers.google.com/machine-learning/glossary#random_policy"><strong>random policy</strong></a> with epsilon probability or a
<a href="https://developers.google.com/machine-learning/glossary#greedy_policy"><strong>greedy policy</strong></a> otherwise. For example, if epsilon is
0.9, then the policy follows a random policy 90% of the time and a greedy
policy 10% of the time.</p>

<p>Over successive episodes, the algorithm reduces epsilon’s value in order
to shift from following a random policy to following a greedy policy. By
shifting the policy, the agent first randomly explores the environment and
then greedily exploits the results of random exploration.</p>

<p><a class="glossary-anchor" name="equality_of_opportunity"></a>
</p><h2 class="hide-from-toc" id="equality-of-opportunity" data-text=" equality of opportunity "> equality of opportunity </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div>
A <a href="https://developers.google.com/machine-learning/glossary#fairness_metric"><strong>fairness metric</strong></a> that checks whether, for
a preferred <a href="https://developers.google.com/machine-learning/glossary#label"><strong>label</strong></a> (one that confers an advantage or
benefit to a person) and a given <a href="https://developers.google.com/machine-learning/glossary#attribute"><strong>attribute</strong></a>, a classifier
predicts that preferred label equally well for all values of that
attribute. In other words, equality of opportunity measures whether
the people who should qualify for an opportunity are equally likely
to do so regardless of their group membership.<p></p>

<p>For example, suppose Glubbdubdrib University admits both Lilliputians
and Brobdingnagians to a rigorous mathematics program. Lilliputians’
secondary schools offer a robust curriculum of math classes, and the
vast majority of students are qualified for the university program.
Brobdingnagians’ secondary schools don’t offer math classes at all,
and as a result, far fewer of their students are qualified. Equality
of opportunity is satisfied for the preferred label of "admitted" with
respect to nationality (Lilliputian or Brobdingnagian) if qualified
students are equally likely to be admitted irrespective of whether
they're a Lilliputian or a Brobdingnagian.</p>

<p>For example, let's say 100 Lilliputians and 100 Brobdingnagians apply
to Glubbdubdrib University, and admissions decisions are made as follows:</p>

<p><b>Table 1.</b> Lilliputian applicants (90% are qualified)</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr> <th>&nbsp;</th>   <th>Qualified</th> <th>Unqualified</th> </tr>
  <tr> <th>Admitted</th> <td>45</td>        <td>3</td>           </tr>
  <tr> <th>Rejected</th> <td>45</td>        <td>7</td>           </tr>
  <tr> <th>Total</th>    <td>90</td>        <td>10</td>          </tr>
  <tr>
     <td colspan="3">
        Percentage of qualified students admitted: 45/90 = 50%<br>
        Percentage of unqualified students rejected: 7/10 = 70%<br>
        Total percentage of Lilliputian students admitted: (45+3)/100 = 48%
     </td>
  </tr>
</tbody></table></div>

<p>&nbsp;</p>

<p><b>Table 2.</b> Brobdingnagian applicants (10% are qualified):</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr> <th>&nbsp;</th>   <th>Qualified</th> <th>Unqualified</th> </tr>
  <tr> <th>Admitted</th> <td>5</td>         <td>9</td>           </tr>
  <tr> <th>Rejected</th> <td>5</td>         <td>81</td>          </tr>
  <tr> <th>Total</th>    <td>10</td>        <td>90</td>          </tr>
  <tr>
     <td colspan="3">
        Percentage of qualified students admitted: 5/10 = 50%<br>
        Percentage of unqualified students rejected: 81/90 = 90%<br>
        Total percentage of Brobdingnagian students admitted: (5+9)/100 = 14%
     </td>
  </tr>
</tbody></table></div>

<p>The preceding examples satisfy equality of opportunity for acceptance
of qualified students because qualified Lilliputians and Brobdingnagians
both have a 50% chance of being admitted.</p>
<aside class="note"><strong>Note:</strong><span> While equality of opportunity is satisfied, the following two
fairness metrics are not satisfied:
<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#demographic_parity"><strong>demographic parity</strong></a>: Lilliputians and
     Brobdingnagians are admitted to the university at different rates;
     48% of Lilliputians students are admitted, but only 14% of
     Brobdingnagian students are admitted.</li>
<li><a href="https://developers.google.com/machine-learning/glossary#equalized_odds"><strong>equalized odds</strong></a>: While qualified Lilliputian
     and Brobdingnagian students both have the same chance of being admitted,
     the additional constraint that unqualified Lilliputians and
     Brobdingnagians both have the same chance of being rejected is not
     satisfied. Unqualified Lilliputians have a 70% rejection rate, whereas
     unqualified Brobdingnagians have a 90% rejection rate.</li>
</ul></span></aside>
<p>See
<a href="https://arxiv.org/pdf/1610.02413.pdf" target="T">"Equality of
Opportunity in Supervised Learning"</a> for a more detailed discussion
of equality of opportunity. Also see
<a href="http://research.google.com/bigpicture/attacking-discrimination-in-ml/" target="T">"Attacking
discrimination with smarter machine learning"</a> for a visualization
exploring the tradeoffs when optimizing for equality of opportunity.</p>

<p><a class="glossary-anchor" name="equalized_odds"></a>
</p><h2 class="hide-from-toc" id="equalized-odds" data-text=" equalized odds"> equalized odds</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div>
A <a href="https://developers.google.com/machine-learning/glossary#fairness_metric"><strong>fairness metric</strong></a> that checks if, for any particular
label and attribute, a classifier predicts that label equally well for all
values of that attribute.<p></p>

<p>For example, suppose Glubbdubdrib University admits both Lilliputians and
Brobdingnagians to a rigorous mathematics program. Lilliputians' secondary
schools offer a robust curriculum of math classes, and the vast majority of
students are qualified for the university program. Brobdingnagians' secondary
schools don’t offer math classes at all, and as a result, far fewer of
their students are qualified.  Equalized odds is satisfied provided that no
matter whether an applicant is  a Lilliputian or a Brobdingnagian, if they
are qualified, they are equally as likely to get admitted to the program,
and if they are not qualified, they are equally as likely to get rejected.</p>

<p>Let’s say 100 Lilliputians and 100 Brobdingnagians apply to Glubbdubdrib
University, and admissions decisions are made as follows:</p>

<p><b>Table 3.</b> Lilliputian applicants (90% are qualified)</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr> <th>&nbsp;</th>   <th>Qualified</th> <th>Unqualified</th> </tr>
  <tr> <th>Admitted</th> <td>45</td>        <td>2</td>           </tr>
  <tr> <th>Rejected</th> <td>45</td>        <td>8</td>           </tr>
  <tr> <th>Total</th>    <td>90</td>        <td>10</td>          </tr>
  <tr>
     <td colspan="3">
        Percentage of qualified students admitted: 45/90 = 50%<br>
        Percentage of unqualified students rejected: 8/10 = 80%<br>
        Total percentage of Lilliputian students admitted: (45+2)/100 = 47%
     </td>
  </tr>
</tbody></table></div>

<p>&nbsp;</p>

<p><b>Table 4.</b> Brobdingnagian applicants (10% are qualified):</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr> <th>&nbsp;</th>   <th>Qualified</th> <th>Unqualified</th> </tr>
  <tr> <th>Admitted</th> <td>5</td>         <td>18</td>           </tr>
  <tr> <th>Rejected</th> <td>5</td>         <td>72</td>           </tr>
  <tr> <th>Total</th>    <td>10</td>        <td>90</td>          </tr>
  <tr>
     <td colspan="3">
        Percentage of qualified students admitted: 5/10 = 50%<br>
        Percentage of unqualified students rejected: 72/90 = 80%<br>
        Total percentage of Brobdingnagian students admitted: (5+18)/100 = 23%
     </td>
  </tr>
</tbody></table></div>

<p>Equalized odds is satisfied because qualified Lilliputian and Brobdingnagian
students both have a 50% chance of being admitted, and unqualified Lilliputian
and Brobdingnagian have an 80% chance of being rejected.</p>
<aside class="note"><strong>Note:</strong><span> While equalized odds is satisfied here,
<a href="https://developers.google.com/machine-learning/glossary#demographic_parity"><strong>demographic parity</strong></a> is <em>not satisfied</em>. Lilliputian
and Brobdingnagian students are admitted to Glubbdubdrib University at
different rates; 47% of Lilliputian students are admitted, and 23% of
Brobdingnagian students are admitted.</span></aside>
<p>Equalized odds is formally defined in
<a href="https://arxiv.org/pdf/1610.02413.pdf" target="T">"Equality of
Opportunity in Supervised Learning"</a> as follows:
"predictor Ŷ satisfies equalized odds with respect
to protected attribute A and outcome Y if Ŷ and A are independent,
conditional on Y."</p>
<aside class="note"><strong>Note:</strong><span> Contrast equalized odds with the more relaxed
<a href="https://developers.google.com/machine-learning/glossary#equality_of_opportunity"><strong>equality of opportunity</strong></a> metric.</span></aside>
<p><a class="glossary-anchor" name="Estimators"></a>
</p><h2 class="hide-from-toc" id="estimator" data-text=" Estimator"> Estimator</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>A deprecated TensorFlow API. Use <a href="https://developers.google.com/machine-learning/glossary#tf.keras">tf.keras</a> instead of Estimators.</p>

<p><a class="glossary-anchor" name="example"></a>
</p><h2 class="hide-from-toc" id="example" data-text=" example"> example</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The values of one row of <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>features</strong></a> and possibly
a <a href="https://developers.google.com/machine-learning/glossary#label"><strong>label</strong></a>. Examples in
<a href="https://developers.google.com/machine-learning/glossary#supervised_machine_learning"><strong>supervised learning</strong></a> fall into two
general categories:</p>

<ul>
<li>A <a href="https://developers.google.com/machine-learning/glossary#labeled_example"><strong>labeled example</strong></a> consists of one or more features
and a label. Labeled examples are used during training.</li>
<li>An <a href="https://developers.google.com/machine-learning/glossary#unlabeled_example"><strong>unlabeled example</strong></a> consists of one or
more features but no label. Unlabeled examples are used during inference.</li>
</ul>

<p>For instance, suppose you are training a model to determine the influence
of weather conditions on student test scores. Here are three labeled examples:</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr><th colspan="3">Features</th> <th>Label</th></tr>
  <tr><th width="25%">Temperature</th> <th width="25%">Humidity</th>
      <th width="25%">Pressure</th> <th width="25%">Test score</th></tr>
  <tr><td>15</td> <td>47</td> <td>998</td> <td>Good</td></tr>
  <tr><td>19</td> <td>34</td> <td>1020</td> <td>Excellent</td></tr>
  <tr><td>18</td> <td>92</td> <td>1012</td> <td>Poor</td></tr>
</tbody></table></div>

<p>Here are three unlabeled examples:</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr><th width="25%">Temperature</th> <th width="25%">Humidity</th>
      <th width="25%">Pressure</th> <th width="25%">&nbsp;</th></tr>
  <tr><td>12</td> <td>62</td> <td>1014</td>  <td>&nbsp;</td></tr>
  <tr><td>21</td> <td>47</td> <td>1017</td>  <td>&nbsp;</td></tr>
  <tr><td>19</td> <td>41</td> <td>1021</td>  <td>&nbsp;</td></tr>
</tbody></table></div>

<p>The row of a <a href="https://developers.google.com/machine-learning/glossary#dataset"><strong>dataset</strong></a> is typically the raw source for an example.
That is, an example typically consists of a subset of the columns in
the dataset. Furthermore, the features in an example can also include
<a href="https://developers.google.com/machine-learning/glossary#synthetic_feature"><strong>synthetic features</strong></a>, such as
<a href="https://developers.google.com/machine-learning/glossary#feature_cross"><strong>feature crosses</strong></a>.</p>

<p><a class="glossary-anchor" name="experience_replay"></a>
</p><h2 class="hide-from-toc" id="experience-replay" data-text=" experience replay"> experience replay</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In reinforcement learning, a <a href="https://developers.google.com/machine-learning/glossary#deep_q-network"><strong>DQN</strong></a> technique used to
reduce temporal correlations in training data. The <a href="https://developers.google.com/machine-learning/glossary#agent"><strong>agent</strong></a>
stores state transitions in a <a href="https://developers.google.com/machine-learning/glossary#replay_buffer"><strong>replay buffer</strong></a>, and then
samples transitions from the replay buffer to create training data.</p>

<p><a class="glossary-anchor" name="experimenters_bias"></a>
</p><h2 class="hide-from-toc" id="experimenters-bias" data-text=" experimenter&#39;s bias "> experimenter's bias </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>See <a href="https://developers.google.com/machine-learning/glossary#confirmation_bias"><strong>confirmation bias</strong></a>.</p>

<p><a class="glossary-anchor" name="exploding_gradient_problem"></a>
</p><h2 class="hide-from-toc" id="exploding-gradient-problem" data-text=" exploding gradient problem"> exploding gradient problem</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Sequence Models">#seq</div>
</div><p></p>

<p>The tendency for <a href="https://developers.google.com/machine-learning/glossary#gradient"><strong>gradients</strong></a> in
<a href="https://developers.google.com/machine-learning/glossary#deep_neural_network"><strong>deep neural networks</strong></a> (especially
<a href="https://developers.google.com/machine-learning/glossary#recurrent_neural_network"><strong>recurrent neural networks</strong></a>) to become
surprisingly steep (high). Steep gradients often cause very large updates
to the <a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weights</strong></a> of each <a href="https://developers.google.com/machine-learning/glossary#node"><strong>node</strong></a> in a
deep neural network.</p>

<p>Models suffering from the exploding gradient problem become difficult
or impossible to train. <a href="https://developers.google.com/machine-learning/glossary#gradient_clipping"><strong>Gradient clipping</strong></a>
can mitigate this problem.</p>

<p>Compare to <a href="https://developers.google.com/machine-learning/glossary#vanishing_gradient_problem"><strong>vanishing gradient problem</strong></a>.</p>

<p><a class="glossary-anchor" name="f"></a>
</p><h2 class="glossary" id="f" data-text="F">F</h2><p></p>

<p><a class="glossary-anchor" name="fairness_constraint"></a>
</p><h2 class="hide-from-toc" id="fairness-constraint" data-text=" fairness constraint"> fairness constraint</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div>
Applying a constraint to an algorithm to ensure one or more definitions
of fairness are satisfied. Examples of fairness constraints include:<p></p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#post-processing"><strong>Post-processing</strong></a> your model's output.</li>
<li>Altering the <a href="https://developers.google.com/machine-learning/glossary#loss"><strong>loss function</strong></a> to incorporate a penalty
 for violating a <a href="https://developers.google.com/machine-learning/glossary#fairness_metric"><strong>fairness metric</strong></a>.</li>
<li>Directly adding a mathematical constraint to an optimization problem.</li>
</ul>

<p><a class="glossary-anchor" name="fairness_metric"></a>
</p><h2 class="hide-from-toc" id="fairness-metric" data-text=" fairness metric"> fairness metric</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>A mathematical definition of “fairness” that is measurable.
Some commonly used fairness metrics include:</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#equalized_odds"><strong>equalized odds</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#predictive_parity"><strong>predictive parity</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#counterfactual_fairness"><strong>counterfactual fairness</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#demographic_parity"><strong>demographic parity</strong></a></li>
</ul>

<p>Many fairness metrics are mutually exclusive; see
<a href="https://developers.google.com/machine-learning/glossary#incompatibility_of_fairness_metrics"><strong>incompatibility of fairness metrics</strong></a>.</p>

<p><a class="glossary-anchor" name="FN"></a>
</p><h2 class="hide-from-toc" id="false-negative-fn" data-text=" false negative (FN)"> false negative (FN)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>An example in which the model mistakenly predicts the
<a href="https://developers.google.com/machine-learning/glossary#negative_class"><strong>negative class</strong></a>. For example, the model
predicts that a particular email message is <em>not spam</em>
(the negative class), but that email message <em>actually is spam</em>.</p>

<p><a class="glossary-anchor" name="false-negative-rate"></a>
</p><h2 class="hide-from-toc" id="false-negative-rate" data-text=" false negative rate"> false negative rate</h2><p></p>

<p>The proportion of actual positive examples for which the model mistakenly
predicted the negative class. The following formula calculates the false
negative rate:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;false negative rate&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtext&gt;false negatives&lt;/mtext&gt;&lt;mrow&gt;&lt;mtext&gt;false negatives&lt;/mtext&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;true positives&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="52.774ex" height="5.69ex" viewBox="0 -1479.6 22722 2449.8" role="img" focusable="false" style="vertical-align: -2.253ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-66"></use><use href="#MJMAIN-61" x="306" y="0"></use><use href="#MJMAIN-6C" x="807" y="0"></use><use href="#MJMAIN-73" x="1085" y="0"></use><use href="#MJMAIN-65" x="1480" y="0"></use><use href="#MJMAIN-6E" x="2174" y="0"></use><use href="#MJMAIN-65" x="2731" y="0"></use><use href="#MJMAIN-67" x="3175" y="0"></use><use href="#MJMAIN-61" x="3676" y="0"></use><use href="#MJMAIN-74" x="4176" y="0"></use><use href="#MJMAIN-69" x="4566" y="0"></use><use href="#MJMAIN-76" x="4844" y="0"></use><use href="#MJMAIN-65" x="5373" y="0"></use><use href="#MJMAIN-72" x="6067" y="0"></use><use href="#MJMAIN-61" x="6460" y="0"></use><use href="#MJMAIN-74" x="6960" y="0"></use><use href="#MJMAIN-65" x="7350" y="0"></use><use href="#MJMAIN-3D" x="8072" y="0"></use><g transform="translate(8850,0)"><g transform="translate(397,0)"><rect stroke="none" width="13353" height="60" x="0" y="220"></rect><g transform="translate(3570,676)"><use href="#MJMAIN-66"></use><use href="#MJMAIN-61" x="306" y="0"></use><use href="#MJMAIN-6C" x="807" y="0"></use><use href="#MJMAIN-73" x="1085" y="0"></use><use href="#MJMAIN-65" x="1480" y="0"></use><use href="#MJMAIN-6E" x="2174" y="0"></use><use href="#MJMAIN-65" x="2731" y="0"></use><use href="#MJMAIN-67" x="3175" y="0"></use><use href="#MJMAIN-61" x="3676" y="0"></use><use href="#MJMAIN-74" x="4176" y="0"></use><use href="#MJMAIN-69" x="4566" y="0"></use><use href="#MJMAIN-76" x="4844" y="0"></use><use href="#MJMAIN-65" x="5373" y="0"></use><use href="#MJMAIN-73" x="5817" y="0"></use></g><g transform="translate(60,-686)"><use href="#MJMAIN-66"></use><use href="#MJMAIN-61" x="306" y="0"></use><use href="#MJMAIN-6C" x="807" y="0"></use><use href="#MJMAIN-73" x="1085" y="0"></use><use href="#MJMAIN-65" x="1480" y="0"></use><use href="#MJMAIN-6E" x="2174" y="0"></use><use href="#MJMAIN-65" x="2731" y="0"></use><use href="#MJMAIN-67" x="3175" y="0"></use><use href="#MJMAIN-61" x="3676" y="0"></use><use href="#MJMAIN-74" x="4176" y="0"></use><use href="#MJMAIN-69" x="4566" y="0"></use><use href="#MJMAIN-76" x="4844" y="0"></use><use href="#MJMAIN-65" x="5373" y="0"></use><use href="#MJMAIN-73" x="5817" y="0"></use><use href="#MJMAIN-2B" x="6434" y="0"></use><g transform="translate(7434,0)"><use href="#MJMAIN-74"></use><use href="#MJMAIN-72" x="389" y="0"></use><use href="#MJMAIN-75" x="782" y="0"></use><use href="#MJMAIN-65" x="1338" y="0"></use><use href="#MJMAIN-70" x="2033" y="0"></use><use href="#MJMAIN-6F" x="2589" y="0"></use><use href="#MJMAIN-73" x="3090" y="0"></use><use href="#MJMAIN-69" x="3484" y="0"></use><use href="#MJMAIN-74" x="3763" y="0"></use><use href="#MJMAIN-69" x="4152" y="0"></use><use href="#MJMAIN-76" x="4431" y="0"></use><use href="#MJMAIN-65" x="4959" y="0"></use><use href="#MJMAIN-73" x="5404" y="0"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>false negative rate</mtext><mo>=</mo><mfrac><mtext>false negatives</mtext><mrow><mtext>false negatives</mtext><mo>+</mo><mtext>true positives</mtext></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-7">\text{false negative rate} =
\frac{\text{false negatives}}{\text{false negatives} + \text{true positives}}</script>
</div>

<p><a class="glossary-anchor" name="FP"></a>
<a class="glossary-anchor" name="false_positive"></a>
</p><h2 class="hide-from-toc" id="false-positive-fp" data-text=" false positive (FP)"> false positive (FP)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>An example in which the model mistakenly predicts the
<a href="https://developers.google.com/machine-learning/glossary#positive_class"><strong>positive class</strong></a>. For example, the model predicts
that a particular email message is <em>spam</em> (the positive class), but that
email message is <em>actually not spam</em>.</p>

<p><a class="glossary-anchor" name="FP_rate"></a>
</p><h2 class="hide-from-toc" id="false-positive-rate-fpr" data-text=" false positive rate (FPR)"> false positive rate (FPR)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The proportion of actual negative examples for which the model mistakenly
predicted the positive class. The following formula calculates the false
positive rate:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;false positive rate&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtext&gt;false positives&lt;/mtext&gt;&lt;mrow&gt;&lt;mtext&gt;false positives&lt;/mtext&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;true negatives&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="52.142ex" height="5.69ex" viewBox="0 -1479.6 22450 2449.8" role="img" focusable="false" style="vertical-align: -2.253ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-66"></use><use href="#MJMAIN-61" x="306" y="0"></use><use href="#MJMAIN-6C" x="807" y="0"></use><use href="#MJMAIN-73" x="1085" y="0"></use><use href="#MJMAIN-65" x="1480" y="0"></use><use href="#MJMAIN-70" x="2174" y="0"></use><use href="#MJMAIN-6F" x="2731" y="0"></use><use href="#MJMAIN-73" x="3231" y="0"></use><use href="#MJMAIN-69" x="3626" y="0"></use><use href="#MJMAIN-74" x="3904" y="0"></use><use href="#MJMAIN-69" x="4294" y="0"></use><use href="#MJMAIN-76" x="4572" y="0"></use><use href="#MJMAIN-65" x="5101" y="0"></use><use href="#MJMAIN-72" x="5795" y="0"></use><use href="#MJMAIN-61" x="6188" y="0"></use><use href="#MJMAIN-74" x="6688" y="0"></use><use href="#MJMAIN-65" x="7078" y="0"></use><use href="#MJMAIN-3D" x="7800" y="0"></use><g transform="translate(8578,0)"><g transform="translate(397,0)"><rect stroke="none" width="13353" height="60" x="0" y="220"></rect><g transform="translate(3706,676)"><use href="#MJMAIN-66"></use><use href="#MJMAIN-61" x="306" y="0"></use><use href="#MJMAIN-6C" x="807" y="0"></use><use href="#MJMAIN-73" x="1085" y="0"></use><use href="#MJMAIN-65" x="1480" y="0"></use><use href="#MJMAIN-70" x="2174" y="0"></use><use href="#MJMAIN-6F" x="2731" y="0"></use><use href="#MJMAIN-73" x="3231" y="0"></use><use href="#MJMAIN-69" x="3626" y="0"></use><use href="#MJMAIN-74" x="3904" y="0"></use><use href="#MJMAIN-69" x="4294" y="0"></use><use href="#MJMAIN-76" x="4572" y="0"></use><use href="#MJMAIN-65" x="5101" y="0"></use><use href="#MJMAIN-73" x="5545" y="0"></use></g><g transform="translate(60,-686)"><use href="#MJMAIN-66"></use><use href="#MJMAIN-61" x="306" y="0"></use><use href="#MJMAIN-6C" x="807" y="0"></use><use href="#MJMAIN-73" x="1085" y="0"></use><use href="#MJMAIN-65" x="1480" y="0"></use><use href="#MJMAIN-70" x="2174" y="0"></use><use href="#MJMAIN-6F" x="2731" y="0"></use><use href="#MJMAIN-73" x="3231" y="0"></use><use href="#MJMAIN-69" x="3626" y="0"></use><use href="#MJMAIN-74" x="3904" y="0"></use><use href="#MJMAIN-69" x="4294" y="0"></use><use href="#MJMAIN-76" x="4572" y="0"></use><use href="#MJMAIN-65" x="5101" y="0"></use><use href="#MJMAIN-73" x="5545" y="0"></use><use href="#MJMAIN-2B" x="6162" y="0"></use><g transform="translate(7162,0)"><use href="#MJMAIN-74"></use><use href="#MJMAIN-72" x="389" y="0"></use><use href="#MJMAIN-75" x="782" y="0"></use><use href="#MJMAIN-65" x="1338" y="0"></use><use href="#MJMAIN-6E" x="2033" y="0"></use><use href="#MJMAIN-65" x="2589" y="0"></use><use href="#MJMAIN-67" x="3034" y="0"></use><use href="#MJMAIN-61" x="3534" y="0"></use><use href="#MJMAIN-74" x="4035" y="0"></use><use href="#MJMAIN-69" x="4424" y="0"></use><use href="#MJMAIN-76" x="4703" y="0"></use><use href="#MJMAIN-65" x="5231" y="0"></use><use href="#MJMAIN-73" x="5676" y="0"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>false positive rate</mtext><mo>=</mo><mfrac><mtext>false positives</mtext><mrow><mtext>false positives</mtext><mo>+</mo><mtext>true negatives</mtext></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-8">\text{false positive rate} =
\frac{\text{false positives}}{\text{false positives} + \text{true negatives}}</script>
</div>

<p>The false positive rate is the x-axis in an <a href="https://developers.google.com/machine-learning/glossary#ROC"><strong>ROC curve</strong></a>.</p>

<p><a class="glossary-anchor" name="feature"></a>
</p><h2 class="hide-from-toc" id="feature" data-text=" feature"> feature</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>An input variable to a machine learning model. An <a href="https://developers.google.com/machine-learning/glossary#example"><strong>example</strong></a>
consists of one or more features. For instance, suppose you are training a
model to determine the influence of weather conditions on student test scores.
The following table shows three examples, each of which contains
three features and one label:</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr><th colspan="3">Features</th> <th>Label</th></tr>
  <tr><th>Temperature</th> <th>Humidity</th> <th>Pressure</th>
      <th>Test score </th></tr>
  <tr><td>15</td> <td>47</td> <td>998</td> <td>92</td></tr>
  <tr><td>19</td> <td>34</td> <td>1020</td> <td>84</td></tr>
  <tr><td>18</td> <td>92</td> <td>1012</td> <td>87</td></tr>
</tbody></table></div>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#label"><strong>label</strong></a>.</p>

<p><a class="glossary-anchor" name="feature_cross"></a>
</p><h2 class="hide-from-toc" id="feature-cross" data-text=" feature cross"> feature cross</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#synthetic_feature"><strong>synthetic feature</strong></a> formed by "crossing"
<a href="https://developers.google.com/machine-learning/glossary#categorical_data"><strong>categorical</strong></a> or <a href="https://developers.google.com/machine-learning/glossary#bucketing"><strong>bucketed</strong></a> features.</p>

<p>For example, consider a "mood forecasting" model that represents
temperature in one of the following four buckets:</p>

<ul>
<li><code translate="no" dir="ltr">freezing</code></li>
<li><code translate="no" dir="ltr">chilly</code></li>
<li><code translate="no" dir="ltr">temperate</code></li>
<li><code translate="no" dir="ltr">warm</code></li>
</ul>

<p>And represents wind speed in one of the following three buckets:</p>

<ul>
<li><code translate="no" dir="ltr">still</code></li>
<li><code translate="no" dir="ltr">light</code></li>
<li><code translate="no" dir="ltr">windy</code></li>
</ul>

<p>Without feature crosses, the linear model trains independently on each of the
preceding seven various buckets. So, the model trains on, for instance,
<code translate="no" dir="ltr">freezing</code> independently of the training on, for instance,
<code translate="no" dir="ltr">windy</code>.</p>

<p>Alternatively, you could create a feature cross of temperature and
wind speed. This synthetic feature would have the following 12 possible
values:</p>

<ul>
<li><code translate="no" dir="ltr">freezing-still</code></li>
<li><code translate="no" dir="ltr">freezing-light</code></li>
<li><code translate="no" dir="ltr">freezing-windy</code></li>
<li><code translate="no" dir="ltr">chilly-still</code></li>
<li><code translate="no" dir="ltr">chilly-light</code></li>
<li><code translate="no" dir="ltr">chilly-windy</code></li>
<li><code translate="no" dir="ltr">temperate-still</code></li>
<li><code translate="no" dir="ltr">temperate-light</code></li>
<li><code translate="no" dir="ltr">temperate-windy</code></li>
<li><code translate="no" dir="ltr">warm-still</code></li>
<li><code translate="no" dir="ltr">warm-light</code></li>
<li><code translate="no" dir="ltr">warm-windy</code></li>
</ul>

<p>Thanks to feature crosses, the model can learn mood differences
between a <code translate="no" dir="ltr">freezing-windy</code> day and a <code translate="no" dir="ltr">freezing-still</code> day.</p>

<p>If you create a synthetic feature from two features that each have a lot of
different buckets, the resulting feature cross will have a huge number
of possible combinations. For example, if one feature has 1,000 buckets and
the other feature has 2,000 buckets, the resulting feature cross has 2,000,000
buckets.</p>

<p>Formally, a cross is a
<a href="https://wikipedia.org/wiki/Cartesian_product" target="T">Cartesian product</a>.</p>

<p>Feature crosses are mostly used with linear models and are rarely used
with neural networks.</p>

<p><a class="glossary-anchor" name="feature_engineering"></a>
</p><h2 class="hide-from-toc" id="feature-engineering" data-text=" feature engineering"> feature engineering</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>A process that involves the following steps:</p>

<ol>
<li>Determining which <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>features</strong></a> might be useful
in training a model.</li>
<li>Converting raw data from the dataset into efficient versions of
those features.</li>
</ol>

<p>For example, you might determine that <code translate="no" dir="ltr">temperature</code> might be a useful
feature. Then, you might experiment with <a href="https://developers.google.com/machine-learning/glossary#bucketing"><strong>bucketing</strong></a>
to optimize what the model can learn from different <code translate="no" dir="ltr">temperature</code> ranges.</p>

<p>Feature engineering is sometimes called <strong>feature extraction</strong>.</p>

<devsite-expandable is-upgraded="" id="expandable-10"><a class="exw-control" aria-controls="expandable-10" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-additional-notes-about-tensorflow." data-text=" Click the icon for additional notes about TensorFlow. ">
Click the icon for additional notes about TensorFlow.
</h4></a>



<div class="expand-background">
<p>
In TensorFlow, feature engineering often means converting raw log file
entries to <a href="https://developers.google.com/machine-learning/glossary#tf.Example"><b>tf.Example</b></a> protocol buffers.
See also
<a href="https://github.com/tensorflow/transform" target="T">tf.Transform</a>.
</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="feature_extraction"></a>
</p><h2 class="hide-from-toc" id="feature-extraction" data-text=" feature extraction"> feature extraction</h2><p></p>

<p>Overloaded term having either of the following definitions:</p>

<ul>
<li>Retrieving intermediate feature representations calculated by an
<a href="https://developers.google.com/machine-learning/glossary#unsupervised_machine_learning"><strong>unsupervised</strong></a> or pretrained model
(for example, <a href="https://developers.google.com/machine-learning/glossary#hidden_layer"><strong>hidden layer</strong></a> values in a
<a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural network</strong></a>) for use in another model as input.</li>
<li>Synonym for <a href="https://developers.google.com/machine-learning/glossary#feature_engineering"><strong>feature engineering</strong></a>.</li>
</ul>

<p><a class="glossary-anchor" name="feature-importances"></a>
</p><h2 class="hide-from-toc" id="feature-importances" data-text=" feature importances "> feature importances </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#variable-importances"><strong>variable importances</strong></a>.</p>

<p><a class="glossary-anchor" name="feature_set"></a>
</p><h2 class="hide-from-toc" id="feature-set" data-text=" feature set"> feature set</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The group of <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>features</strong></a> your machine learning
<a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> trains on.
For example, postal code, property size, and property condition might
comprise a simple feature set for a model that predicts housing prices.</p>

<p><a class="glossary-anchor" name="feature_spec"></a>
</p><h2 class="hide-from-toc" id="feature-spec" data-text=" feature spec"> feature spec</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>Describes the information required to extract <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>features</strong></a> data
from the <a href="https://developers.google.com/machine-learning/glossary#tf.Example"><strong>tf.Example</strong></a> protocol buffer. Because the
tf.Example protocol buffer is just a container for data, you must specify
the following:</p>

<ul>
<li>the data to extract (that is, the keys for the features)</li>
<li>the data type (for example, float or int)</li>
<li>The length (fixed or variable)</li>
</ul>

<p><a class="glossary-anchor" name="feature_vector"></a>
</p><h2 class="hide-from-toc" id="feature-vector" data-text=" feature vector"> feature vector</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The array of <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a> values comprising an
<a href="https://developers.google.com/machine-learning/glossary#example"><strong>example</strong></a>. The feature vector is input during
<a href="https://developers.google.com/machine-learning/glossary#training"><strong>training</strong></a> and during <a href="https://developers.google.com/machine-learning/glossary#inference"><strong>inference</strong></a>.
For example, the feature vector for a model with two discrete features
might be:</p>

<devsite-code data-copy-event-label=""><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="pun">[</span><span class="lit">0.92</span><span class="pun">,</span><span class="pln"> </span><span class="lit">0.56</span><span class="pun">]</span><span class="pln"><br></span></pre></devsite-code>

<p>
<img src="./ML_Glossary_files/FeatureVector.png" loading="lazy" alt="Four layers: an input layer, two hidden layers, and one output layer.
          The input layer contains two nodes, one containing the value
          0.92 and the other containing the value 0.56.">
</p>

<p>Each example supplies different values for the feature vector, so the
feature vector for the next example could be something like:</p>

<devsite-code data-copy-event-label=""><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="pun">[</span><span class="lit">0.73</span><span class="pun">,</span><span class="pln"> </span><span class="lit">0.49</span><span class="pun">]</span><span class="pln"><br></span></pre></devsite-code>

<p><a href="https://developers.google.com/machine-learning/glossary#feature_engineering"><strong>Feature engineering</strong></a> determines how to represent
features in the feature vector. For example, a binary categorical feature with
five possible values might be represented with
<a href="https://developers.google.com/machine-learning/glossary#one-hot_encoding"><strong>one-hot encoding</strong></a>. In this case, the portion of the
feature vector for a particular example would consist of four zeroes and
a single 1.0 in the third position, as follows:</p>

<devsite-code no-copy="" data-copy-event-label=""><pre translate="no" dir="ltr" is-upgraded="">[0.0, 0.0, 1.0, 0.0, 0.0]
</pre></devsite-code>

<p>As another example, suppose your model consists of three features:</p>

<ul>
<li>a binary categorical feature with <em>five</em> possible values represented with
one-hot encoding; for example: <code translate="no" dir="ltr">[0.0, 1.0, 0.0, 0.0, 0.0]</code></li>
<li>another binary categorical feature with <em>three</em> possible values represented
with one-hot encoding; for example: <code translate="no" dir="ltr">[0.0, 0.0, 1.0]</code></li>
<li>a floating-point feature; for example: <code translate="no" dir="ltr">8.3</code>.</li>
</ul>

<p>In this case, the feature vector for each example would be represented
by <em>nine</em> values. Given the example values in the preceding list, the
feature vector would be:</p>

<devsite-code no-copy="" data-copy-event-label=""><pre translate="no" dir="ltr" is-upgraded="">0.0
1.0
0.0
0.0
0.0
0.0
0.0
1.0
8.3
</pre></devsite-code>

<p><a class="glossary-anchor" name="federated_learning"></a>
</p><h2 class="hide-from-toc" id="federated-learning" data-text=" federated learning"> federated learning</h2><p></p>

<p>A distributed machine learning approach that <a href="https://developers.google.com/machine-learning/glossary#training"><strong>trains</strong></a>
machine learning <a href="https://developers.google.com/machine-learning/glossary#model"><strong>models</strong></a> using decentralized
<a href="https://developers.google.com/machine-learning/glossary#example"><strong>examples</strong></a> residing on devices such as smartphones.
In federated learning, a subset of devices downloads the current model
from a central coordinating server. The devices use the examples stored
on the devices to make improvements to the model. The devices then upload
the model improvements (but not the training examples) to the coordinating
server, where they are aggregated with other updates to yield an improved
global model. After the aggregation, the model updates computed by devices
are no longer needed, and can be discarded.</p>

<p>Since the training examples are never uploaded, federated learning follows the
privacy principles of focused data collection and data minimization.</p>

<p>For more information about federated learning,
see <a href="https://federated.withgoogle.com/" target="T">this tutorial</a>.</p>

<p><a class="glossary-anchor" name="feedback_loop"></a>
</p><h2 class="hide-from-toc" id="feedback-loop" data-text=" feedback loop"> feedback loop</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>In machine learning, a situation in which a model's predictions influence the
training data for the same model or another model. For example, a model that
recommends movies will influence the movies that people see, which will then
influence subsequent movie recommendation models.</p>

<p><a class="glossary-anchor" name="feedforward_neural_network"></a>
</p><h2 class="hide-from-toc" id="feedforward-neural-network-ffn" data-text=" feedforward neural network (FFN)"> feedforward neural network (FFN)</h2><p></p>

<p>A neural network without cyclic or recursive connections. For example,
traditional <a href="https://developers.google.com/machine-learning/glossary#deep_neural_network"><strong>deep neural networks</strong></a> are
feedforward neural networks. Contrast with <a href="https://developers.google.com/machine-learning/glossary#recurrent_neural_network"><strong>recurrent neural
networks</strong></a>, which are cyclic.</p>

<p><a class="glossary-anchor" name="few-shot_learning"></a>
</p><h2 class="hide-from-toc" id="few-shot-learning" data-text=" few-shot learning"> few-shot learning</h2><p></p>

<p>A machine learning approach, often used for object classification,
designed to train effective classifiers from only a small number of
training examples.</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#one-shot_learning"><strong>one-shot learning</strong></a>.</p>

<p><a class="glossary-anchor" name="fine_tuning"></a>
</p><h2 class="hide-from-toc" id="fine-tuning" data-text="fine tuning">fine tuning</h2><p></p>

<p>Performing a secondary optimization to adjust the parameters of an already
trained <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> to fit a new problem. Fine tuning often
refers to refitting the weights of a trained
<a href="https://developers.google.com/machine-learning/glossary#unsupervised_machine_learning"><strong>unsupervised</strong></a> model to a
<a href="https://developers.google.com/machine-learning/glossary#supervised_machine_learning"><strong>supervised</strong></a> model.</p>

<p><a class="glossary-anchor" name="forget_gate"></a>
</p><h2 class="hide-from-toc" id="forget-gate" data-text="forget gate">forget gate</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Sequence Models">#seq</div>
</div><p></p>

<p>The portion of a <a href="https://developers.google.com/machine-learning/glossary#Long_Short-Term_Memory"><strong>Long Short-Term Memory</strong></a>
cell that regulates the flow of information through the cell.
Forget gates maintain context by deciding which information to discard
from the cell state.</p>

<p><a class="glossary-anchor" name="full_softmax"></a>
</p><h2 class="hide-from-toc" id="full-softmax" data-text=" full softmax"> full softmax</h2><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#softmax"><strong>softmax</strong></a>.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#candidate_sampling"><strong>candidate sampling</strong></a>.</p>

<p><a class="glossary-anchor" name="fully_connected_layer"></a>
</p><h2 class="hide-from-toc" id="fully-connected-layer" data-text=" fully connected layer"> fully connected layer</h2><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#hidden_layer"><strong>hidden layer</strong></a> in which each <a href="https://developers.google.com/machine-learning/glossary#node"><strong>node</strong></a> is
connected to <em>every</em> node in the subsequent hidden layer.</p>

<p>A fully connected layer is also known as a <a href="https://developers.google.com/machine-learning/glossary#dense_layer"><strong>dense layer</strong></a>.</p>

<p><a class="glossary-anchor" name="g"></a>
</p><h2 class="glossary" id="g" data-text="G">G</h2><p></p>



<p><a class="glossary-anchor" name="GAN"></a>
</p><h2 class="hide-from-toc" id="gan" data-text=" GAN"> GAN</h2><p></p>

<p>Abbreviation for <a href="https://developers.google.com/machine-learning/glossary#generative_adversarial_network"><strong>generative adversarial
network</strong></a>.</p>

<p><a class="glossary-anchor" name="generalization"></a>
</p><h2 class="hide-from-toc" id="generalization" data-text=" generalization"> generalization</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model's</strong></a> ability to make correct predictions on new,
previously unseen data. A model that can generalize is the opposite
of a model that is <a href="https://developers.google.com/machine-learning/glossary#overfitting"><strong>overfitting</strong></a>.</p>

<devsite-expandable is-upgraded="" id="expandable-11"><a class="exw-control" aria-controls="expandable-11" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-additional-notes._5" data-text=" Click the icon for additional notes. ">
Click the icon for additional notes.
</h4></a>



<div class="expand-background">
<p>
You train a model on the examples in the training set. Consequently, the
model learns the peculiarities of the data in the training set. Generalization
essentially asks whether your model can make good predictions on examples
that are <i>not</i> in the training set.
</p>

<p>
To encourage generalization,
<a href="https://developers.google.com/machine-learning/glossary#regularization"><b>regularization</b></a> helps a model train
less exactly to the peculiarities of the data in the training set.
</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="generalization_curve"></a>
</p><h2 class="hide-from-toc" id="generalization-curve" data-text=" generalization curve"> generalization curve</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A plot of both <a href="https://developers.google.com/machine-learning/glossary#training-loss"><strong>training loss</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#validation-loss"><strong>validation loss</strong></a> as a function of the number of
<a href="https://developers.google.com/machine-learning/glossary#iteration"><strong>iterations</strong></a>.</p>

<p>A generalization curve can help you detect possible
<a href="https://developers.google.com/machine-learning/glossary#overfitting"><strong>overfitting</strong></a>.  For example, the following
generalization curve suggests overfitting because validation loss
ultimately becomes significantly higher than training loss.</p>

<p>
<img src="./ML_Glossary_files/GeneralizationCurveSmooth.png" height="500" loading="lazy" alt="A Cartesian graph in which the y-axis is labeled &#39;loss&#39; and the x-axis
          is labeled &#39;iterations&#39;. Two plots appear. One plots shows the
          training loss and the other shows the validation loss.
          The two plots start off similarly, but the training loss eventually
          dips far lower than the validation loss.">
</p>

<p><a class="glossary-anchor" name="generalized_linear_model"></a>
</p><h2 class="hide-from-toc" id="generalized-linear-model" data-text=" generalized linear model"> generalized linear model</h2><p></p>

<p>A generalization of <a href="https://developers.google.com/machine-learning/glossary#least_squares_regression"><strong>least squares regression</strong></a>
models, which are based on
<a href="https://wikipedia.org/wiki/Gaussian_noise" target="T">Gaussian
noise</a>, to other
types of models based on other types of noise, such as
<a href="https://wikipedia.org/wiki/Shot_noise" target="T">Poisson noise</a>
or
categorical noise. Examples of generalized linear models include:</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#logistic_regression"><strong>logistic regression</strong></a></li>
<li>multi-class regression</li>
<li>least squares regression</li>
</ul>

<p>The parameters of a generalized linear model can be found through
<a href="https://developers.google.com/machine-learning/glossary#convex_optimization"><strong>convex optimization</strong></a>.</p>

<p>Generalized linear models exhibit the following properties:</p>

<ul>
<li>The average prediction of the optimal least squares regression model is
equal to the average label on the training data.</li>
<li>The average probability predicted by the optimal logistic regression
model is equal to the average label on the training data.</li>
</ul>

<p>The power of a generalized linear model is limited by its features. Unlike
a deep model, a generalized linear model cannot "learn new features."</p>

<p><a class="glossary-anchor" name="generative_adversarial_network"></a>
</p><h2 class="hide-from-toc" id="generative-adversarial-network-gan" data-text=" generative adversarial network (GAN)"> generative adversarial network (GAN)</h2><p></p>

<p>A system to create new data in which a <a href="https://developers.google.com/machine-learning/glossary#generator"><strong>generator</strong></a> creates
data and a <a href="https://developers.google.com/machine-learning/glossary#discriminator"><strong>discriminator</strong></a> determines whether that
created data is valid or invalid.</p>

<p><a class="glossary-anchor" name="generative_model"></a>
</p><h2 class="hide-from-toc" id="generative-model" data-text=" generative model"> generative model</h2><p></p>

<p>Practically speaking, a model that does either of the following:</p>

<ul>
<li>Creates (generates) new examples from the training dataset.
For example, a generative model could create poetry after training
on a dataset of poems. The <a href="https://developers.google.com/machine-learning/glossary#generator"><strong>generator</strong></a> part of a
<a href="https://developers.google.com/machine-learning/glossary#generative_adversarial_network"><strong>generative adversarial network</strong></a>
falls into this category.</li>
<li>Determines the probability that a new example comes from the
training set, or was created from the same mechanism that created
the training set.  For example, after training on
a dataset consisting of English sentences, a generative model could
determine the probability that new input is a valid English sentence.</li>
</ul>

<p>A generative model can theoretically discern the distribution of examples
or particular features in a dataset. That is:</p>

<devsite-code data-copy-event-label=""><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="pln">p</span><span class="pun">(</span><span class="pln">examples</span><span class="pun">)</span><span class="pln"><br></span></pre></devsite-code>

<p>Unsupervised learning models are generative.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#discriminative_model"><strong>discriminative models</strong></a>.</p>

<p><a class="glossary-anchor" name="generator"></a>
</p><h2 class="hide-from-toc" id="generator" data-text=" generator"> generator</h2><p></p>

<p>The subsystem within a <a href="https://developers.google.com/machine-learning/glossary#generative_adversarial_network"><strong>generative adversarial
network</strong></a>
that creates new <a href="https://developers.google.com/machine-learning/glossary#example"><strong>examples</strong></a>.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#discriminative_model"><strong>discriminative model</strong></a>.</p>

<p><a class="glossary-anchor" name="GPT"></a>
</p><h2 class="hide-from-toc" id="gpt-generative-pre-trained-transformer" data-text=" GPT (Generative Pre-trained Transformer)"> GPT (Generative Pre-trained Transformer)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A family of <a href="https://developers.google.com/machine-learning/glossary#Transformer"><strong>Transformer</strong></a>-based
<a href="https://developers.google.com/machine-learning/glossary#large-language-model"><strong>large language models</strong></a> developed by
<a href="https://openai.com/">OpenAI</a>.</p>

<p>GPT variants can apply to multiple <a href="https://developers.google.com/machine-learning/glossary#modality"><strong>modalities</strong></a>, including:</p>

<ul>
<li>image generation (for example, ImageGPT)</li>
<li>text-to-image generation (for example,
<a href="https://openai.com/blog/dall-e/">DALL-E</a>).</li>
</ul>

<p><a class="glossary-anchor" name="gini-impurity"></a>
</p><h2 class="hide-from-toc" id="gini-impurity" data-text=" gini impurity "> gini impurity </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>A metric similar to <a href="https://developers.google.com/machine-learning/glossary#entropy"><strong>entropy</strong></a>. <a href="https://developers.google.com/machine-learning/glossary#splitter"><strong>Splitters</strong></a>
use values derived from either gini impurity or entropy to compose
<a href="https://developers.google.com/machine-learning/glossary#condition"><strong>conditions</strong></a> for classification
<a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision trees</strong></a>.
<a href="https://developers.google.com/machine-learning/glossary#information-gain"><strong>Information gain</strong></a> is derived from entropy.
There is no universally accepted equivalent term for the metric derived
from gini impurity; however, this unnamed metric is just as important as
information gain.</p>

<p>Gini impurity is also called <strong>gini index</strong>, or simply <strong>gini</strong>.</p>

<devsite-expandable is-upgraded="" id="expandable-12"><a class="exw-control" aria-controls="expandable-12" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-mathematical-details-about-gini-impurity." data-text=" Click the icon for mathematical details about gini impurity. ">
Click the icon for mathematical details about gini impurity.<wbr>
</h4></a>



<div class="expand-background">
<p>Gini impurity is the probability of misclassifying a new piece of data
taken from the same distribution. The gini impurity of a set with two
possible values "0" and "1" (for example, the labels in a
<b><a href="https://developers.google.com/machine-learning/glossary#binary_classification">binary classification</a></b> problem)
is calculated from the following formula:</p>

<p>
<tt>&nbsp;&nbsp;
I = 1 - (p<sup>2</sup> + q<sup>2</sup>) = 1 - (p<sup>2</sup> + (1-p)<sup>2</sup>)
</tt>

</p><p>where:</p>

<ul>
  <li><tt>I</tt> is the gini impurity.</li>
  <li><tt>p</tt> is the fraction of "1" examples.</li>
  <li><tt>q</tt> is the fraction of "0" examples. Note that <tt>q =
  1-p</tt></li>
</ul>

<p>For example, consider the following dataset:</p>

<ul>
  <li>100 labels (0.25 of the dataset) contain the value "1"</li>
  <li>300 labels (0.75 of the dataset) contain the value "0"</li>
</ul>

<p>Therefore, the gini impurity is:</p>

<p>
<tt>
</tt></p><ul><tt>
  <li>p = 0.25</li>
  <li>q = 0.75</li>
  <li>I = 1 - (0.25<sup>2</sup> + 0.75<sup>2</sup>) = <b>0.375</b></li>
</tt></ul><tt>
</tt>
<p></p>

<p>Consequently, a random label from the same dataset would have a 37.5% chance
of being misclassified, and a 62.5% chance of being properly classified.</p>

<p>A perfectly balanced label (for example, 200 "0"s and 200 "1"s) would have a
gini impurity of 0.5. A highly
<a href="https://developers.google.com/machine-learning/glossary#class_imbalanced_data_set"><b>imbalanced</b></a> label would have a
gini impurity close to 0.0.</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="gradient"></a>
</p><h2 class="hide-from-toc" id="gradient" data-text=" gradient"> gradient</h2><p></p>

<p>The vector of <a href="https://developers.google.com/machine-learning/glossary#partial_derivative"><strong>partial derivatives</strong></a> with respect to
all of the independent variables.  In machine learning, the gradient is
the vector of partial derivatives of the model function.  The gradient points
in the direction of steepest ascent.</p>

<p><a class="glossary-anchor" name="gradient-boosting"></a>
</p><h2 class="hide-from-toc" id="gradient-boosting" data-text=" gradient boosting"> gradient boosting</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>A training algorithm where weak models are trained to iteratively
improve the quality (reduce the loss) of a strong model. For example,
a weak model could be a linear or small decision tree model.
The strong model becomes the sum of all the previously trained weak models.</p>

<p>In the simplest form of gradient boosting, at each iteration, a weak model
is trained to predict the loss gradient of the strong model. Then, the
strong model's output is updated by subtracting the predicted gradient,
similar to <a href="https://developers.google.com/machine-learning/glossary#gradient_descent"><strong>gradient descent</strong></a>.</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msub&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.81ex" height="2.376ex" viewBox="0 -766.3 2932 1023.1" role="img" focusable="false" style="vertical-align: -0.596ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-46" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-30" x="910" y="-213"></use><use href="#MJMAIN-3D" x="1375" y="0"></use><use href="#MJMAIN-30" x="2431" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>F</mi><mrow class="MJX-TeXAtom-ORD"><mn>0</mn></mrow></msub><mo>=</mo><mn>0</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-9">F_{0} = 0</script>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-10-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msub&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;&amp;#x03BE;&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="15.597ex" height="2.494ex" viewBox="0 -766.3 6715.3 1074" role="img" focusable="false" style="vertical-align: -0.715ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-46" x="0" y="0"></use><g transform="translate(643,-150)"><use transform="scale(0.707)" href="#MJMATHI-69" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2B" x="345" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="1124" y="0"></use></g><use href="#MJMAIN-3D" x="2169" y="0"></use><g transform="translate(3226,0)"><use href="#MJMATHI-46" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-69" x="910" y="-213"></use></g><use href="#MJMAIN-2212" x="4436" y="0"></use><use href="#MJMATHI-3BE" x="5437" y="0"></use><g transform="translate(5880,0)"><use href="#MJMATHI-66" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-69" x="693" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>F</mi><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>F</mi><mi>i</mi></msub><mo>−</mo><mi>ξ</mi><msub><mi>f</mi><mi>i</mi></msub></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-10">F_{i+1} = F_i - \xi f_i </script>
</div>

<p>where:</p>

<ul>
  <li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-11-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.549ex" height="2.376ex" viewBox="0 -766.3 1097.4 1023.1" role="img" focusable="false" style="vertical-align: -0.596ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-46" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-30" x="910" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>F</mi><mrow class="MJX-TeXAtom-ORD"><mn>0</mn></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-11">F_{0}</script> is the starting strong model.</li>
  <li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-12-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.395ex" height="2.494ex" viewBox="0 -766.3 1892.2 1074" role="img" focusable="false" style="vertical-align: -0.715ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-46" x="0" y="0"></use><g transform="translate(643,-150)"><use transform="scale(0.707)" href="#MJMATHI-69" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2B" x="345" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="1124" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>F</mi><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-12">F_{i+1}</script> is the next strong model.</li>
  <li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-13-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.294ex" height="2.376ex" viewBox="0 -766.3 987.8 1023.1" role="img" focusable="false" style="vertical-align: -0.596ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-46" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-69" x="910" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>F</mi><mrow class="MJX-TeXAtom-ORD"><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-13">F_{i}</script> is the current strong model.</li>
  <li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-14-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;&amp;#x03BE;&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.03ex" height="2.494ex" viewBox="0 -766.3 443.5 1074" role="img" focusable="false" style="vertical-align: -0.715ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-3BE" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ξ</mi></math></span></span><script type="math/tex" id="MathJax-Element-14">\xi</script> is a value between 0.0 and 1.0 called <a href="https://developers.google.com/machine-learning/glossary#shrinkage"><b>shrinkage</b></a>,
      which is analogous to the
      <a href="https://developers.google.com/machine-learning/glossary#learning_rate"><b>learning rate</b></a> in
      gradient descent.</li>
  <li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-15-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.939ex" height="2.494ex" viewBox="0 -766.3 834.8 1074" role="img" focusable="false" style="vertical-align: -0.715ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-66" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-69" x="693" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>f</mi><mrow class="MJX-TeXAtom-ORD"><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-15">f_{i}</script> is the weak model trained to predict the loss gradient of
      <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-16-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.294ex" height="2.376ex" viewBox="0 -766.3 987.8 1023.1" role="img" focusable="false" style="vertical-align: -0.596ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-46" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-69" x="910" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>F</mi><mrow class="MJX-TeXAtom-ORD"><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-16">F_{i}</script>.</li>
</ul>

<p>Modern variations of gradient boosting also include the second derivative
(Hessian) of the loss in their computation.</p>

<p><a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>Decision trees</strong></a> are commonly used as weak models in
gradient boosting. See
<a href="https://developers.google.com/machine-learning/glossary#gbt"><strong>gradient boosted (decision) trees</strong></a>.</p>

<p><a class="glossary-anchor" name="gbt"></a>
</p><h2 class="hide-from-toc" id="gradient-boosted-decision-trees-gbt" data-text=" gradient boosted (decision) trees (GBT) " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> gradient boosted (decision) trees (GBT) </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  gradient boosted (decision) trees (GBT) " data-title="Copy link to this section:  gradient boosted (decision) trees (GBT) " data-id="gradient-boosted-decision-trees-gbt"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>A type of <a href="https://developers.google.com/machine-learning/glossary#decision-forest"><strong>decision forest</strong></a> in which:</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#training"><strong>Training</strong></a> relies on
<a href="https://developers.google.com/machine-learning/glossary#gradient-boosting"><strong>gradient boosting</strong></a>.</li>
<li>The weak model is a <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a>.</li>
</ul>

<p><a class="glossary-anchor" name="gradient_clipping"></a>
</p><h2 class="hide-from-toc" id="gradient-clipping" data-text=" gradient clipping" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> gradient clipping</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  gradient clipping" data-title="Copy link to this section:  gradient clipping" data-id="gradient-clipping"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Sequence Models">#seq</div>
</div><p></p>

<p>A commonly used mechanism to mitigate the
<a href="https://developers.google.com/machine-learning/glossary#exploding_gradient_problem"><strong>exploding gradient problem</strong></a> by artificially
limiting (clipping) the maximum value of gradients when using
<a href="https://developers.google.com/machine-learning/glossary#gradient_descent"><strong>gradient descent</strong></a> to <a href="https://developers.google.com/machine-learning/glossary#training"><strong>train</strong></a> a model.</p>

<p><a class="glossary-anchor" name="gradient_descent"></a>
</p><h2 class="hide-from-toc" id="gradient-descent" data-text=" gradient descent" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> gradient descent</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  gradient descent" data-title="Copy link to this section:  gradient descent" data-id="gradient-descent"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A mathematical technique to minimize <a href="https://developers.google.com/machine-learning/glossary#loss"><strong>loss</strong></a>.
Gradient descent iteratively adjusts
<a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weights</strong></a> and <a href="https://developers.google.com/machine-learning/glossary#bias"><strong>biases</strong></a>,
gradually finding the best combination to minimize loss.</p>

<p>Gradient descent is older—much, much older—than machine learning.</p>

<p><a class="glossary-anchor" name="graph"></a>
</p><h2 class="hide-from-toc" id="graph" data-text=" graph" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> graph</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  graph" data-title="Copy link to this section:  graph" data-id="graph"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>In TensorFlow, a computation specification. Nodes in the graph
represent operations. Edges are directed and represent passing the result
of an operation (a <a href="https://developers.google.com/machine-learning/glossary#tensor"><strong>Tensor</strong></a>) as an
operand to another operation. Use
<a href="https://developers.google.com/machine-learning/glossary#TensorBoard"><strong>TensorBoard</strong></a> to visualize a graph.</p>

<p><a class="glossary-anchor" name="graph_execution"></a>
</p><h2 class="hide-from-toc" id="graph-execution" data-text=" graph execution" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> graph execution</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  graph execution" data-title="Copy link to this section:  graph execution" data-id="graph-execution"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>A TensorFlow programming environment in which the program first constructs
a <a href="https://developers.google.com/machine-learning/glossary#graph"><strong>graph</strong></a> and then executes all or part of that graph. Graph
execution is the default execution mode in TensorFlow 1.x.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#eager_execution"><strong>eager execution</strong></a>.</p>

<p><a class="glossary-anchor" name="greedy_policy"></a>
</p><h2 class="hide-from-toc" id="greedy-policy" data-text=" greedy policy" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> greedy policy</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  greedy policy" data-title="Copy link to this section:  greedy policy" data-id="greedy-policy"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In reinforcement learning, a <a href="https://developers.google.com/machine-learning/glossary#policy"><strong>policy</strong></a> that always chooses the
action with the highest expected <a href="https://developers.google.com/machine-learning/glossary#return"><strong>return</strong></a>.</p>

<p><a class="glossary-anchor" name="ground_truth"></a>
</p><h2 class="hide-from-toc" id="ground-truth" data-text=" ground truth" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> ground truth</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  ground truth" data-title="Copy link to this section:  ground truth" data-id="ground-truth"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Reality.</p>

<p>The thing that actually happened.</p>

<p>For example, consider a <a href="https://developers.google.com/machine-learning/glossary#binary_classification"><strong>binary classification</strong></a>
model that predicts whether a student in their first year of university
will graduate within six years. Ground truth for this model is whether or
not that student actually graduated within six years.</p>

<devsite-expandable is-upgraded="" id="expandable-13"><a class="exw-control" aria-controls="expandable-13" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-additional-notes._6" data-text=" Click the icon for additional notes. " role="presentation"><span class="devsite-heading" role="heading" aria-level="4">
Click the icon for additional notes.<wbr>
</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: 
Click the icon for additional notes.
" data-title="Copy link to this section: 
Click the icon for additional notes.
" data-id="click-the-icon-for-additional-notes._6"></button></h4></a>



<div class="expand-background">
<p>
We assess model quality against ground truth. However, ground truth
is not always completely, well, truthful.  For example, consider the
following examples of potential imperfections in ground truth:</p>

<ul>
  <li>In the graduation example, are we <i>certain</i> that the graduation
      records for each student are always correct?  Is the university's
      record-keeping flawless?</li>
  <li>Suppose the label is a floating-point value measured by instruments
      (for instance, barometers). How can we be sure that each instrument
      is calibrated identically or that each reading was taken under the same
      circumstances?</li>
  <li>If the label is a matter of human opinion, how can we be sure that
      each human <a href="https://developers.google.com/machine-learning/glossary#rater"><b>rater</b></a> is evaluating events in the
      same way?  To improve consistency, <i>expert</i> human raters sometimes
      intervene.</li>
</ul>

</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="group_attribution_bias"></a>
</p><h2 class="hide-from-toc" id="group-attribution-bias" data-text=" group attribution bias " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> group attribution bias </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  group attribution bias " data-title="Copy link to this section:  group attribution bias " data-id="group-attribution-bias"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>Assuming that what is true for an individual is also true for everyone
in that group. The effects of group attribution bias can be exacerbated
if a <a href="https://developers.google.com/machine-learning/glossary#convenience_sampling"><strong>convenience sampling</strong></a>
is used for data collection. In a non-representative sample, attributions
may be made that do not reflect reality.</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#out-group_homogeneity_bias"><strong>out-group homogeneity bias</strong></a>
and <a href="https://developers.google.com/machine-learning/glossary#in-group_bias"><strong>in-group bias</strong></a>.</p>

<p><a class="glossary-anchor" name="h"></a>
</p><h2 class="glossary" id="h" data-text="H" role="presentation"><span class="devsite-heading" role="heading" aria-level="2">H</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: H" data-title="Copy link to this section: H" data-id="h"></button></h2><p></p>

<p><a class="glossary-anchor" name="hallucination"></a>
</p><h2 class="hide-from-toc" id="hallucination" data-text=" hallucination"> hallucination</h2><p></p>

<p>The production of plausible-seeming but factually incorrect output by a
<a href="https://developers.google.com/machine-learning/glossary#generative_model"><strong>generative model</strong></a> that purports to be making an
assertion about the real world.
For example, if a dialog agent claims that Barack Obama died in 1865,
the agent is <em>hallucinating</em>.</p>

<p><a class="glossary-anchor" name="hashing"></a>
</p><h2 class="hide-from-toc" id="hashing" data-text=" hashing" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> hashing</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  hashing" data-title="Copy link to this section:  hashing" data-id="hashing"></button></h2><p></p>

<p>In machine learning, a mechanism for bucketing
<a href="https://developers.google.com/machine-learning/glossary#categorical_data"><strong>categorical data</strong></a>, particularly when the number
of categories is large, but the number of categories actually appearing
in the dataset is comparatively small.</p>

<p>For example, Earth is home to about 73,000 tree species. You could
represent each of the 73,000 tree species in 73,000 separate categorical
buckets. Alternatively, if only 200 of those tree species actually appear
in a dataset, you could use hashing to divide tree species into
perhaps 500 buckets.</p>

<p>A single bucket could contain multiple tree species. For example, hashing
could place <em>baobab</em> and <em>red maple</em>—two genetically dissimilar
species—into the same bucket. Regardless, hashing is still a good way to
map large categorical sets into the desired number of buckets. Hashing turns a
categorical feature having a large number of possible values into a much
smaller number of values by grouping values in a
deterministic way.</p>

<p><a class="glossary-anchor" name="heuristic"></a>
</p><h2 class="hide-from-toc" id="heuristic" data-text=" heuristic" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> heuristic</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  heuristic" data-title="Copy link to this section:  heuristic" data-id="heuristic"></button></h2><p></p>

<p>A simple and quickly implemented solution to a problem. For example,
"With a heuristic, we achieved 86% accuracy. When we switched to a
deep neural network, accuracy went up to 98%."</p>

<p><a class="glossary-anchor" name="hidden_layer"></a>
</p><h2 class="hide-from-toc" id="hidden-layer" data-text=" hidden layer" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> hidden layer</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  hidden layer" data-title="Copy link to this section:  hidden layer" data-id="hidden-layer"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A layer in a <a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural network</strong></a> between the
<a href="https://developers.google.com/machine-learning/glossary#input_layer"><strong>input layer</strong></a> (the features) and the
<a href="https://developers.google.com/machine-learning/glossary#output_layer"><strong>output layer</strong></a> (the prediction).
Each hidden layer consists of one or more <a href="https://developers.google.com/machine-learning/glossary#neuron"><strong>neurons</strong></a>.
For example, the following neural network contains two hidden layers,
the first with three neurons and the second with two neurons:</p>

<p>
<img src="./ML_Glossary_files/HiddenLayerBigPicture.png" loading="lazy" alt="Four layers. The first layer is an input layer containing two
          features. The second layer is a hidden layer containing three
          neurons. The third layer is a hidden layer containing two
          neurons. The fourth layer is an output layer. Each feature
          contains three edges, each of which points to a different neuron
          in the second layer. Each of the neurons in the second layer
          contains two edges, each of which points to a different neuron
          in the third layer. Each of the neurons in the third layer contain
          one edge, each pointing to the output layer.">
</p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#deep_neural_network"><strong>deep neural network</strong></a> contains more than one
hidden layer. For example, the preceding illustration is a deep neural
network because the model contains two hidden layers.</p>

<p><a class="glossary-anchor" name="hierarchical_clustering"></a>
</p><h2 class="hide-from-toc" id="hierarchical-clustering" data-text=" hierarchical clustering" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> hierarchical clustering</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  hierarchical clustering" data-title="Copy link to this section:  hierarchical clustering" data-id="hierarchical-clustering"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Clustering">#clustering</div>
</div><p></p>

<p>A category of <a href="https://developers.google.com/machine-learning/glossary#clustering"><strong>clustering</strong></a> algorithms that create a tree
of clusters. Hierarchical clustering is well-suited to hierarchical data,
such as botanical taxonomies. There are two types of hierarchical
clustering algorithms:</p>

<ul>
<li><strong>Agglomerative clustering</strong> first assigns every example to its own cluster,
and iteratively merges the closest clusters to create a hierarchical
tree.</li>
<li><strong>Divisive clustering</strong> first groups all examples into one cluster and then
iteratively divides the cluster into a hierarchical tree.</li>
</ul>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#centroid_based_clustering"><strong>centroid-based clustering</strong></a>.</p>

<p><a class="glossary-anchor" name="hinge-loss"></a>
</p><h2 class="hide-from-toc" id="hinge-loss" data-text=" hinge loss" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> hinge loss</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  hinge loss" data-title="Copy link to this section:  hinge loss" data-id="hinge-loss"></button></h2><p></p>

<p>A family of <a href="https://developers.google.com/machine-learning/glossary#loss"><strong>loss</strong></a> functions for
<a href="https://developers.google.com/machine-learning/glossary#classification_model"><strong>classification</strong></a> designed to find the
<a href="https://developers.google.com/machine-learning/glossary#decision_boundary"><strong>decision boundary</strong></a> as distant as possible
from each training example,
thus maximizing the margin between examples and the boundary.
<a href="https://developers.google.com/machine-learning/glossary#KSVMs"><strong>KSVMs</strong></a> use hinge loss (or a related function, such as
squared hinge loss). For binary classification, the hinge loss function
is defined as follows:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-17-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;loss&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mtext&gt;max&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;&amp;#x2217;&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;&amp;#x2032;&lt;/mo&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="26.079ex" height="2.731ex" viewBox="0 -868.2 11228.6 1175.9" role="img" focusable="false" style="vertical-align: -0.715ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-6C"></use><use href="#MJMAIN-6F" x="278" y="0"></use><use href="#MJMAIN-73" x="779" y="0"></use><use href="#MJMAIN-73" x="1173" y="0"></use><use href="#MJMAIN-3D" x="1845" y="0"></use><g transform="translate(2902,0)"><use href="#MJMAIN-6D"></use><use href="#MJMAIN-61" x="833" y="0"></use><use href="#MJMAIN-78" x="1334" y="0"></use></g><use href="#MJMAIN-28" x="4764" y="0"></use><use href="#MJMAIN-30" x="5154" y="0"></use><use href="#MJMAIN-2C" x="5654" y="0"></use><use href="#MJMAIN-31" x="6099" y="0"></use><use href="#MJMAIN-2212" x="6822" y="0"></use><use href="#MJMAIN-28" x="7823" y="0"></use><use href="#MJMATHI-79" x="8212" y="0"></use><use href="#MJMAIN-2217" x="8932" y="0"></use><g transform="translate(9655,0)"><use href="#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2032" x="706" y="583"></use></g><use href="#MJMAIN-29" x="10449" y="0"></use><use href="#MJMAIN-29" x="10839" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>loss</mtext><mo>=</mo><mtext>max</mtext><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>−</mo><mo stretchy="false">(</mo><mi>y</mi><mo>∗</mo><msup><mi>y</mi><mo>′</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-17">\text{loss} = \text{max}(0, 1 - (y * y'))</script>
</div>

<p>where <em>y</em> is the true label, either -1 or +1, and <em>y'</em> is the raw output
of the classifier model:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-18-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msup&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;&amp;#x2032;&lt;/mo&gt;&lt;/msup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo&gt;&amp;#x2026;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="33.208ex" height="2.731ex" viewBox="0 -868.2 14297.9 1175.9" role="img" focusable="false" style="vertical-align: -0.715ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2032" x="706" y="583"></use><use href="#MJMAIN-3D" x="1072" y="0"></use><use href="#MJMATHI-62" x="2128" y="0"></use><use href="#MJMAIN-2B" x="2780" y="0"></use><g transform="translate(3780,0)"><use href="#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="1013" y="-213"></use></g><g transform="translate(4951,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="809" y="-213"></use></g><use href="#MJMAIN-2B" x="6199" y="0"></use><g transform="translate(7200,0)"><use href="#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="1013" y="-213"></use></g><g transform="translate(8371,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="809" y="-213"></use></g><use href="#MJMAIN-2B" x="9619" y="0"></use><use href="#MJMAIN-2026" x="10620" y="0"></use><g transform="translate(11959,0)"><use href="#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-6E" x="1013" y="-213"></use></g><g transform="translate(13200,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-6E" x="809" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msup><mi>y</mi><mo>′</mo></msup><mo>=</mo><mi>b</mi><mo>+</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mo>…</mo><msub><mi>w</mi><mi>n</mi></msub><msub><mi>x</mi><mi>n</mi></msub></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-18">y' = b + w_1x_1 + w_2x_2 + … w_nx_n</script>
</div>

<p>Consequently, a plot of hinge loss vs. (y * y') looks as follows:</p>

<p>
<img src="./ML_Glossary_files/hinge-loss.svg" loading="lazy" alt="A Cartesian plot consisting of two joined line segments. The first
          line segment starts at (-3, 4) and ends at (1, 0). The second line
          segment begins at (1, 0) and continues indefinitely with a slope
          of 0.">
</p>

<p><a class="glossary-anchor" name="holdout_data"></a>
</p><h2 class="hide-from-toc" id="holdout-data" data-text=" holdout data" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> holdout data</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  holdout data" data-title="Copy link to this section:  holdout data" data-id="holdout-data"></button></h2><p></p>

<p><a href="https://developers.google.com/machine-learning/glossary#example"><strong>Examples</strong></a> intentionally not used ("held out") during training.
The <a href="https://developers.google.com/machine-learning/glossary#validation_set"><strong>validation dataset</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#test_set"><strong>test dataset</strong></a> are examples of holdout data. Holdout data
helps evaluate your model's ability to generalize to data other than the
data it was trained on. The loss on the holdout set provides a better
estimate of the loss on an unseen dataset than does the loss on the
training set.</p>

<p><a class="glossary-anchor" name="hyperparameter"></a>
</p><h2 class="hide-from-toc" id="hyperparameter" data-text=" hyperparameter"> hyperparameter</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The variables that you or a hyperparameter tuning service

adjust during successive runs of training a model. For example,
<a href="https://developers.google.com/machine-learning/glossary#learning_rate"><strong>learning rate</strong></a> is a hyperparameter. You could
set the learning rate to 0.01 before one training session. If you
determine that 0.01 is too high, you could perhaps set the learning
rate to 0.003 for the next training session.</p>

<p>In contrast, <a href="https://developers.google.com/machine-learning/glossary#parameter"><strong>parameters</strong></a> are the various
<a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weights</strong></a> and <a href="https://developers.google.com/machine-learning/glossary#bias"><strong>bias</strong></a> that the model
<em>learns</em> during training.</p>

<p><a class="glossary-anchor" name="hyperplane"></a>
</p><h2 class="hide-from-toc" id="hyperplane" data-text=" hyperplane"> hyperplane</h2><p></p>

<p>A boundary that separates a space into two subspaces.  For example, a line is a
hyperplane in two dimensions and a plane is a hyperplane in three dimensions.
More typically in machine learning, a hyperplane is the boundary separating a
high-dimensional space.  <a href="https://developers.google.com/machine-learning/glossary#KSVMs"><strong>Kernel Support Vector Machines</strong></a> use
hyperplanes to separate positive classes from negative classes, often in a very
high-dimensional space.</p>

<p><a class="glossary-anchor" name="i"></a>
</p><h2 class="glossary" id="i" data-text="I">I</h2><p></p>

<p><a class="glossary-anchor" name="iid_abbreviation"></a>
</p><h2 class="hide-from-toc" id="i.i.d." data-text=" i.i.d."> i.<wbr>i.<wbr>d.<wbr></h2><p></p>

<p>Abbreviation for <a href="https://developers.google.com/machine-learning/glossary#iid"><strong>independently and identically distributed</strong></a>.</p>

<p><a class="glossary-anchor" name="image_recognition"></a>
</p><h2 class="hide-from-toc" id="image-recognition" data-text=" image recognition"> image recognition</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>A process that classifies object(s), pattern(s), or concept(s) in an image.
Image recognition is also known as <strong>image classification</strong>.</p>

<p>For more information, see
<a href="https://developers.google.com/machine-learning/practica/image-classification" target="T" class="gc-analytics-event" data-category="launchImageClassificationPracticum" data-label="ml-glossary" data-action="click">ML Practicum: Image Classification</a>.</p>

<p><a class="glossary-anchor" name="imbalanced_data_set"></a>
</p><h2 class="hide-from-toc" id="imbalanced-dataset" data-text=" imbalanced dataset"> imbalanced dataset</h2><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#class_imbalanced_data_set"><strong>class-imbalanced dataset</strong></a>.</p>

<p><a class="glossary-anchor" name="implicit_bias"></a>
</p><h2 class="hide-from-toc" id="implicit-bias" data-text=" implicit bias "> implicit bias </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>Automatically making an association or assumption based on one’s mental
models and memories. Implicit bias can affect the following:</p>

<ul>
<li>How data is collected and classified.</li>
<li>How machine learning systems are designed and developed.</li>
</ul>

<p>For example, when building a classifier to identify wedding photos,
an engineer may use the presence of a white dress in a photo as a feature.
However, white dresses have been customary only during certain eras and
in certain cultures.</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#confirmation_bias"><strong>confirmation bias</strong></a>.</p>

<p><a class="glossary-anchor" name="incompatibility_of_fairness_metrics"></a>
<a class="glossary-anchor" name="incompatibility"></a>
</p><h2 class="hide-from-toc" id="incompatibility-of-fairness-metrics" data-text=" incompatibility of fairness metrics"> incompatibility of fairness metrics</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>The idea that some notions of fairness are mutually incompatible and
cannot be satisfied simultaneously. As a result, there is no single
universal <a href="https://developers.google.com/machine-learning/glossary#fairness_metric"><strong>metric</strong></a> for quantifying fairness
that can be applied to all ML problems.</p>

<p>While this may seem discouraging, incompatibility of fairness metrics
doesn’t imply that fairness efforts are fruitless. Instead, it suggests
that fairness must be defined contextually for a given ML problem, with
the goal of preventing harms specific to its use cases.</p>

<p>See <a href="https://arxiv.org/pdf/1609.07236.pdf" target="T">"On the
(im)possibility of fairness"</a> for a more detailed discussion of this topic.</p>

<p><a class="glossary-anchor" name="iid"></a>
</p><h2 class="hide-from-toc" id="independently-and-identically-distributed-i.i.d" data-text="independently and identically distributed (i.i.d)">independently and identically distributed (i.i.d)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Data drawn from a distribution that doesn't change, and where each value
drawn doesn't depend on values that have been drawn previously. An i.i.d.
is the <a href="https://wikipedia.org/wiki/Ideal_gas" target="T">ideal gas</a>
of machine
learning—a useful mathematical construct but almost never exactly found
in the real world. For example, the distribution of visitors to a web page
may be i.i.d. over a brief window of time; that is, the distribution doesn't
change during that brief window and one person's visit is generally
independent of another's visit. However, if you expand that window of time,
seasonal differences in the web page's visitors may appear.</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#nonstationarity"><strong>nonstationarity</strong></a>.</p>

<p><a class="glossary-anchor" name="individual_fairness"></a>
</p><h2 class="hide-from-toc" id="individual-fairness" data-text=" individual fairness"> individual fairness</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>A fairness metric that checks whether similar individuals are classified
similarly. For example, Brobdingnagian Academy might want to satisfy
individual fairness by ensuring that two students with identical grades
and standardized test scores are equally likely to gain admission.</p>

<p>Note that individual fairness relies entirely on how you define "similarity"
(in this case, grades and test scores), and you can run the risk of
introducing new fairness problems if your similarity metric misses important
information (such as the rigor of a student’s curriculum).</p>

<p>See <a href="https://arxiv.org/pdf/1104.3913.pdf" target="T">"Fairness Through
Awareness"</a> for a more detailed discussion of individual fairness.</p>

<p><a class="glossary-anchor" name="inference"></a>
</p><h2 class="hide-from-toc" id="inference" data-text=" inference"> inference</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>In machine learning, the process of making predictions by
applying a trained model to <a href="https://developers.google.com/machine-learning/glossary#unlabeled_example"><strong>unlabeled examples</strong></a>.</p>

<p>Inference has a somewhat different meaning in statistics.
See the
<a href="https://wikipedia.org/wiki/Statistical_inference" target="T">
Wikipedia article on statistical inference</a> for details.</p>

<p><a class="glossary-anchor" name="inference-path"></a>
</p><h2 class="hide-from-toc" id="inference-path" data-text=" inference path "> inference path </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>In a <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a>, during <a href="https://developers.google.com/machine-learning/glossary#inference"><strong>inference</strong></a>,
the route a particular <a href="https://developers.google.com/machine-learning/glossary#example"><strong>example</strong></a> takes from the
<a href="https://developers.google.com/machine-learning/glossary#root"><strong>root</strong></a> to other <a href="https://developers.google.com/machine-learning/glossary#condition"><strong>conditions</strong></a>, terminating with
a <a href="https://developers.google.com/machine-learning/glossary#leaf"><strong>leaf</strong></a>. For instance, in the following decision tree, the
thicker arrows show the inference path for an example with the following
feature values:</p>

<ul>
<li>x = 7</li>
<li>y = 12</li>
<li>z = -3</li>
</ul>

<p>The inference path in the following illustration travels through three
conditions before reaching the leaf (<code translate="no" dir="ltr">Zeta</code>).</p>

<p>
<img src="./ML_Glossary_files/information-gain.png" loading="lazy" width="490" height="300" alt="A decision tree consisting of four conditions and five leaves.
          The root condition is (x &gt; 0). Since the answer is Yes, the
          inference path travels from the root to the next condition (y &gt; 0).
          Since the answer is Yes, the inference path then travels to the
          next condition (z &gt; 0). Since the answer is No, the inference path
          travels to its terminal node, which is the leaf (Zeta).">
</p>

<p><b>The three thick arrows show the inference path.</b></p>

<p><a class="glossary-anchor" name="information-gain"></a>
</p><h2 class="hide-from-toc" id="information-gain" data-text=" information gain "> information gain </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#decision-forest"><strong>decision forests</strong></a>, the difference between
a node's <a href="https://developers.google.com/machine-learning/glossary#entropy"><strong>entropy</strong></a> and the weighted (by number of examples)
sum of the entropy of its children nodes. A node's entropy is the entropy
of the examples in that node.</p>

<p>For example, consider the following entropy values:</p>

<ul>
<li>entropy of parent node = 0.6</li>
<li>entropy of one child node with 16 relevant examples = 0.2</li>
<li>entropy of another child node with 24 relevant examples = 0.1</li>
</ul>

<p>So 40% of the examples are in one child node and 60% are in the
other child node. Therefore:</p>

<ul>
<li>weighted entropy sum of child nodes = (0.4 * 0.2) + (0.6 * 0.1) = 0.14</li>
</ul>

<p>So, the information gain is:</p>

<ul>
<li>information gain = entropy of parent node - weighted entropy sum of child nodes</li>
<li>information gain = 0.6 - 0.14 = 0.46</li>
</ul>

<p>Most <a href="https://developers.google.com/machine-learning/glossary#splitter"><strong>splitters</strong></a> seek to create <a href="https://developers.google.com/machine-learning/glossary#condition"><strong>conditions</strong></a>
that maximize information gain.</p>

<p><a class="glossary-anchor" name="in-group_bias"></a>
</p><h2 class="hide-from-toc" id="in-group-bias" data-text=" in-group bias "> in-group bias </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>Showing partiality to one's own group or own characteristics.
If testers or raters consist of the machine learning developer's friends,
family, or colleagues, then in-group bias may invalidate product testing
or the dataset.</p>

<p>In-group bias is a form of
<a href="https://developers.google.com/machine-learning/glossary#group_attribution_bias"><strong>group attribution bias</strong></a>.
See also <a href="https://developers.google.com/machine-learning/glossary#out-group_homogeneity_bias"><strong>out-group homogeneity bias</strong></a>.</p>

<p><a class="glossary-anchor" name="input_layer"></a>
</p><h2 class="hide-from-toc" id="input-layer" data-text=" input layer"> input layer</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The <a href="https://developers.google.com/machine-learning/glossary#layer"><strong>layer</strong></a> of a <a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural network</strong></a> that
holds the <a href="https://developers.google.com/machine-learning/glossary#feature_vector"><strong>feature vector</strong></a>. That is, the input layer
provides <a href="https://developers.google.com/machine-learning/glossary#example"><strong>examples</strong></a> for <a href="https://developers.google.com/machine-learning/glossary#training"><strong>training</strong></a> or
<a href="https://developers.google.com/machine-learning/glossary#inference"><strong>inference</strong></a>. For example, the input layer in the following
neural network consists of two features:</p>

<p>
<img src="./ML_Glossary_files/InputLayer.png" loading="lazy" alt="Four layers: an input layer, two hidden layers, and an output layer.">
</p>

<p><a class="glossary-anchor" name="in-set-condition"></a>
</p><h2 class="hide-from-toc" id="in-set-condition" data-text=" in-set condition "> in-set condition </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>In a <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a>, a <a href="https://developers.google.com/machine-learning/glossary#condition"><strong>condition</strong></a>
that tests for the presence of one item in a set of items.
For example, the following is an in-set condition:</p>
<devsite-code data-copy-event-label=""><pre class="" translate="no" dir="ltr" is-upgraded=""><code dir="ltr"><span class="pln">&nbsp; house</span><span class="pun">-</span><span class="pln">style </span><span class="kwd">in</span><span class="pln"> </span><span class="pun">[</span><span class="pln">tudor</span><span class="pun">,</span><span class="pln"> colonial</span><span class="pun">,</span><span class="pln"> cape</span><span class="pun">]</span><span class="pln"><br></span></code></pre></devsite-code>
<p>During inference, if the value of the house-style <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a>
is <code translate="no" dir="ltr">tudor</code> or <code translate="no" dir="ltr">colonial</code> or <code translate="no" dir="ltr">cape</code>, then this condition evaluates to Yes. If
the value of the house-style feature is something else (for example, <code translate="no" dir="ltr">ranch</code>),
then this condition evaluates to No.</p>

<p>In-set conditions usually lead to more efficient decision trees than
conditions that test <a href="https://developers.google.com/machine-learning/glossary#one-hot_encoding"><strong>one-hot encoded</strong></a> features.</p>

<p><a class="glossary-anchor" name="instance"></a>
</p><h2 class="hide-from-toc" id="instance" data-text=" instance"> instance</h2><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#example"><strong>example</strong></a>.</p>

<p><a class="glossary-anchor" name="interpretability"></a>
</p><h2 class="hide-from-toc" id="interpretability" data-text=" interpretability"> interpretability</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The ability to explain or to present an ML model's reasoning in understandable
terms to a human.</p>

<p>Most linear regression models, for example, are highly
interpretable. (You merely need to look at the trained weights for each
feature.)  Decision forests are also highly interpretable. Some models, however,
require sophisticated visualization to become interpretable.</p>

<p><a class="glossary-anchor" name="inter-rater_agreement"></a>
</p><h2 class="hide-from-toc" id="inter-rater-agreement" data-text=" inter-rater agreement"> inter-rater agreement</h2><p></p>

<p>A measurement of how often human raters agree when doing a task.
If raters disagree, the task instructions may need to be improved.
Also sometimes called <strong>inter-annotator agreement</strong> or
<strong>inter-rater reliability</strong>.  See also
<a href="https://wikipedia.org/wiki/Cohen%27s_kappa" target="T">Cohen's
kappa</a>,
which is one of the most popular inter-rater agreement measurements.</p>

<p><a class="glossary-anchor" name="intersection_over_union"></a>
</p><h2 class="hide-from-toc" id="intersection-over-union-iou" data-text=" intersection over union (IoU)"> intersection over union (IoU)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>The intersection of two sets divided by their union. In machine-learning
image-detection tasks, IoU is used to measure the accuracy of the model’s
predicted <a href="https://developers.google.com/machine-learning/glossary#bounding_box"><strong>bounding box</strong></a> with respect to the
<a href="https://developers.google.com/machine-learning/glossary#ground_truth"><strong>ground-truth</strong></a> bounding box. In this case, the IoU for the
two boxes is the ratio between the overlapping area and the total area, and
its value ranges from 0 (no overlap of predicted bounding box and ground-truth
bounding box) to 1 (predicted bounding box and ground-truth bounding box have
the exact same coordinates).</p>

<p>For example, in the image below:</p>

<ul>
<li>The predicted bounding box (the coordinates delimiting where the model
predicts the night table in the painting is located) is outlined in purple.</li>
<li>The ground-truth bounding box (the coordinates delimiting where the night
table in the painting is actually located) is outlined in green.</li>
</ul>

<p>
<img src="./ML_Glossary_files/iou_van_gogh_bounding_boxes.jpg" loading="lazy" alt="The Van Gogh painting &#39;Vincent&#39;s Bedroom in Arles&#39;, with two different
          bounding boxes around the night table beside the bed. The ground-truth
          bounding box (in green) perfectly circumscribes the night table. The
          predicted bounding box (in purple) is offset 50% down and to the right
          of the ground-truth bounding box; it encloses the bottom-right quarter
          of the night table, but misses the rest of the table.">
</p>

<p>Here, the intersection of the bounding boxes for prediction and ground truth
(below left) is 1, and the union of the bounding boxes for prediction and
ground truth (below right) is 7, so the IoU is <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-19-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;7&lt;/mn&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.658ex" height="3.323ex" viewBox="0 -970.1 713.9 1430.7" role="img" focusable="false" style="vertical-align: -1.07ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(120,0)"><rect stroke="none" width="473" height="60" x="0" y="220"></rect><use transform="scale(0.707)" href="#MJMAIN-31" x="84" y="574"></use><use transform="scale(0.707)" href="#MJMAIN-37" x="84" y="-544"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mn>1</mn><mn>7</mn></mfrac></math></span></span><script type="math/tex" id="MathJax-Element-19">\frac{1}{7}</script>.</p>

<div id="intersection-union-side-by-side">
<img src="./ML_Glossary_files/iou_van_gogh_intersection.jpg" loading="lazy" alt="Same image as above, but with each bounding box divided into four
          quadrants. There are seven quadrants total, as the bottom-right
          quadrant of the ground-truth bounding box and the top-left
          quadrant of the predicted bounding box overlap each other. This
          overlapping section (highlighted in green) represents the
          intersection, and has an area of 1.">

<img src="./ML_Glossary_files/iou_van_gogh_union.jpg" loading="lazy" alt="Same image as above, but with each bounding box divided into four
          quadrants. There are seven quadrants total, as the bottom-right
          quadrant of the ground-truth bounding box and the top-left
          quadrant of the predicted bounding box overlap each other.
          The entire interior enclosed by both bounding boxes
          (highlighted in green) represents the union, and has
          an area of 7.">
</div>

<p><a class="glossary-anchor" name="ioou"></a>
</p><h2 class="hide-from-toc" id="iou" data-text="IoU">IoU</h2><p></p>

<p>Abbreviation for <a href="https://developers.google.com/machine-learning/glossary#intersection_over_union"><strong>intersection over union</strong></a>.</p>

<p><a class="glossary-anchor" name="item_matrix"></a>
</p><h2 class="hide-from-toc" id="item-matrix" data-text=" item matrix"> item matrix</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Recommendation Systems">#recsystems</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#recommendation_system"><strong>recommendation systems</strong></a>, a
matrix of <a href="https://developers.google.com/machine-learning/glossary#embedding_vector"><strong>embedding vectors</strong></a> generated by
<a href="https://developers.google.com/machine-learning/glossary#matrix_factorization"><strong>matrix factorization</strong></a>
that holds latent signals about each <a href="https://developers.google.com/machine-learning/glossary#items"><strong>item</strong></a>.
Each row of the item matrix holds the value of a single latent
feature for all items.
For example, consider a movie recommendation system. Each column
in the item matrix represents a single movie. The latent signals
might represent genres, or might be harder-to-interpret
signals that involve complex interactions among genre, stars,
movie age, or other factors.</p>

<p>The item matrix has the same number of columns as the target
matrix that is being factorized. For example, given a movie
recommendation system that evaluates 10,000 movie titles, the
item matrix will have 10,000 columns.</p>

<p><a class="glossary-anchor" name="items"></a>
</p><h2 class="hide-from-toc" id="items" data-text=" items"> items</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Recommendation Systems">#recsystems</div>
</div><p></p>

<p>In a <a href="https://developers.google.com/machine-learning/glossary#recommendation_system"><strong>recommendation system</strong></a>, the entities that
a system recommends. For example, videos are the items that a video store
recommends, while books are the items that a bookstore recommends.</p>

<p><a class="glossary-anchor" name="iteration"></a>
</p><h2 class="hide-from-toc" id="iteration" data-text=" iteration"> iteration</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A single update of a <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model's</strong></a> parameters—the model's
<a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weights</strong></a> and <a href="https://developers.google.com/machine-learning/glossary#bias"><strong>biases</strong></a>—during
<a href="https://developers.google.com/machine-learning/glossary#training"><strong>training</strong></a>. The <a href="https://developers.google.com/machine-learning/glossary#batch_size"><strong>batch size</strong></a> determines
how many examples the model processes in a single iteration. For instance,
if the batch size is 20, then the model processes 20 examples before
adjusting the parameters.</p>

<p>When training a <a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural network</strong></a>, a single iteration
involves the following two passes:</p>

<ol>
<li>A forward pass to evaluate loss on a single batch.</li>
<li>A backward pass (<a href="https://developers.google.com/machine-learning/glossary#backpropagation"><strong>backpropagation</strong></a>) to adjust the
model's parameters based on the loss and the learning rate.</li>
</ol>

<p><a class="glossary-anchor" name="k"></a>
</p><h2 class="glossary" id="k" data-text="K">K</h2><p></p>

<p><a class="glossary-anchor" name="Keras"></a>
</p><h2 class="hide-from-toc" id="keras" data-text=" Keras"> Keras</h2><p></p>

<p>A popular Python machine learning API.
<a href="https://keras.io/" target="T">Keras</a>
runs on
several deep learning frameworks, including TensorFlow, where it is made
available as
<a href="https://www.tensorflow.org/api_docs/python/tf/keras" target="T">tf.keras</a>.</p>

<p><a class="glossary-anchor" name="keypoints"></a>
</p><h2 class="hide-from-toc" id="keypoints" data-text=" keypoints"> keypoints</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>The coordinates of particular features in an image. For example, for an
<a href="https://developers.google.com/machine-learning/glossary#image_recognition"><strong>image recognition</strong></a> model that distinguishes
flower species, keypoints might be the center of each petal, the stem,
the stamen, and so on.</p>

<p><a class="glossary-anchor" name="KSVMs"></a>
</p><h2 class="hide-from-toc" id="kernel-support-vector-machines-ksvms" data-text="Kernel Support Vector Machines (KSVMs)">Kernel Support Vector Machines (KSVMs)</h2><p></p>

<p>A classification algorithm that seeks to maximize the margin between
<a href="https://developers.google.com/machine-learning/glossary#positive_class"><strong>positive</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#negative_class"><strong>negative classes</strong></a> by mapping input data vectors
to a higher dimensional space.  For example, consider a classification
problem in which the input dataset
has a hundred features. To maximize the margin between
positive and negative classes, a KSVM could internally map those features into
a million-dimension space.  KSVMs uses a loss function called
<a href="https://developers.google.com/machine-learning/glossary#hinge-loss"><strong>hinge loss</strong></a>.</p>

<p><a class="glossary-anchor" name="k-means"></a>
</p><h2 class="hide-from-toc" id="k-means" data-text=" k-means"> k-means</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Clustering">#clustering</div>
</div><p></p>

<p>A popular <a href="https://developers.google.com/machine-learning/glossary#clustering"><strong>clustering</strong></a> algorithm that groups examples
in unsupervised learning. The k-means algorithm basically does the following:</p>

<ul>
<li>Iteratively determines the best k center points (known
as <a href="https://developers.google.com/machine-learning/glossary#centroid"><strong>centroids</strong></a>).</li>
<li>Assigns each example to the closest centroid.  Those examples nearest
the same centroid belong to the same group.</li>
</ul>

<p>The k-means algorithm picks centroid locations to minimize the cumulative
<em>square</em> of the distances from each example to its closest centroid.</p>

<p>For example, consider the following plot of dog height to dog width:</p>

<p>
<img src="./ML_Glossary_files/DogDimensions.svg" loading="lazy" height="350" width="384" alt="A Cartesian plot with several dozen data points.">
</p>

<p>If k=3, the k-means algorithm will determine three centroids.  Each example
is assigned to its closest centroid, yielding three groups:</p>

<p>
<img src="./ML_Glossary_files/DogDimensionsKMeans.svg" loading="lazy" height="350" width="458" alt="The same Cartesian plot as in the previous illustration, except
          with three centroids added.
          The previous data points are clustered into three distinct groups,
          with each group representing the data points closest to a particular
          centroid.">
</p>

<p>Imagine that a manufacturer wants to determine the ideal sizes for small,
medium, and large sweaters for dogs. The three centroids identify the mean
height and mean width of each dog in that cluster. So, the manufacturer
should probably base sweater sizes on those three centroids.  Note that
the centroid of a cluster is typically <em>not</em> an example in the cluster.</p>

<p>The preceding illustrations shows k-means for examples with only
two features (height and width). Note that k-means can group examples
across many features.</p>

<p><a class="glossary-anchor" name="k-median"></a>
</p><h2 class="hide-from-toc" id="k-median" data-text=" k-median" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> k-median</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  k-median" data-title="Copy link to this section:  k-median" data-id="k-median"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Clustering">#clustering</div>
</div><p></p>

<p>A clustering algorithm closely related to <a href="https://developers.google.com/machine-learning/glossary#k-means"><strong>k-means</strong></a>. The
practical difference between the two is as follows:</p>

<ul>
<li>In k-means, centroids are determined by minimizing the sum of the
<em>squares</em> of the distance between a centroid candidate and each of
its examples.</li>
<li>In k-median, centroids are determined by minimizing the sum of the
distance between a centroid candidate and each of its examples.</li>
</ul>

<p>Note that the definitions of distance are also different:</p>

<ul>
<li>k-means relies on the
<a href="https://wikipedia.org/wiki/Euclidean_distance" target="T">Euclidean distance</a> from
the centroid to an example.  (In two dimensions, the Euclidean
distance means using the Pythagorean theorem to calculate
the hypotenuse.)  For example, the k-means distance between (2,2)
and (5,-2) would be:</li>
</ul>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-20-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;Euclidean distance&lt;/mtext&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msqrt&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/msqrt&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="49.231ex" height="4.625ex" viewBox="0 -1326.8 21196.8 1991.2" role="img" focusable="false" style="vertical-align: -1.543ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-45"></use><use href="#MJMAIN-75" x="681" y="0"></use><use href="#MJMAIN-63" x="1238" y="0"></use><use href="#MJMAIN-6C" x="1682" y="0"></use><use href="#MJMAIN-69" x="1961" y="0"></use><use href="#MJMAIN-64" x="2239" y="0"></use><use href="#MJMAIN-65" x="2796" y="0"></use><use href="#MJMAIN-61" x="3240" y="0"></use><use href="#MJMAIN-6E" x="3741" y="0"></use><use href="#MJMAIN-64" x="4547" y="0"></use><use href="#MJMAIN-69" x="5104" y="0"></use><use href="#MJMAIN-73" x="5382" y="0"></use><use href="#MJMAIN-74" x="5777" y="0"></use><use href="#MJMAIN-61" x="6166" y="0"></use><use href="#MJMAIN-6E" x="6667" y="0"></use><use href="#MJMAIN-63" x="7223" y="0"></use><use href="#MJMAIN-65" x="7668" y="0"></use><use href="#MJMAIN-3D" x="8390" y="0"></use><g transform="translate(9446,0)"><use href="#MJSZ2-221A" x="0" y="42"></use><rect stroke="none" width="8915" height="60" x="1000" y="1133"></rect><g transform="translate(1000,0)"><use href="#MJMAIN-28" x="0" y="0"></use><use href="#MJMAIN-32" x="389" y="0"></use><use href="#MJMAIN-2212" x="1112" y="0"></use><use href="#MJMAIN-35" x="2112" y="0"></use><g transform="translate(2613,0)"><use href="#MJMAIN-29" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="550" y="583"></use></g><use href="#MJMAIN-2B" x="3679" y="0"></use><use href="#MJMAIN-28" x="4679" y="0"></use><use href="#MJMAIN-32" x="5069" y="0"></use><use href="#MJMAIN-2212" x="5792" y="0"></use><use href="#MJMAIN-2212" x="6792" y="0"></use><use href="#MJMAIN-32" x="7571" y="0"></use><g transform="translate(8071,0)"><use href="#MJMAIN-29" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="550" y="583"></use></g></g></g><use href="#MJMAIN-3D" x="19639" y="0"></use><use href="#MJMAIN-35" x="20696" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow class="MJX-TeXAtom-ORD"><mtext>Euclidean distance</mtext></mrow><mo>=</mo><mrow class="MJX-TeXAtom-ORD"><msqrt><mo stretchy="false">(</mo><mn>2</mn><mo>−</mo><mn>5</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>2</mn><mo>−</mo><mo>−</mo><mn>2</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup></msqrt></mrow><mo>=</mo><mn>5</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-20">
{\text{Euclidean distance}} = {\sqrt {(2-5)^2 + (2--2)^2}} = 5
</script>
</div>

<ul>
<li>k-median relies on the <a href="https://wikipedia.org/wiki/Taxicab_geometry" target="T"> Manhattan distance</a>
from the centroid to an example.  This distance is the sum of the
absolute deltas in each dimension.  For example, the k-median
distance between (2,2) and (5,-2) would be:</li>
</ul>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-21-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;Manhattan distance&lt;/mtext&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo fence=&quot;false&quot; stretchy=&quot;false&quot;&gt;&amp;#x007C;&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;mo fence=&quot;false&quot; stretchy=&quot;false&quot;&gt;&amp;#x007C;&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo fence=&quot;false&quot; stretchy=&quot;false&quot;&gt;&amp;#x007C;&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo fence=&quot;false&quot; stretchy=&quot;false&quot;&gt;&amp;#x007C;&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;7&lt;/mn&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="45.092ex" height="2.613ex" viewBox="0 -817.3 19414.4 1125" role="img" focusable="false" style="vertical-align: -0.715ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-4D"></use><use href="#MJMAIN-61" x="917" y="0"></use><use href="#MJMAIN-6E" x="1418" y="0"></use><use href="#MJMAIN-68" x="1974" y="0"></use><use href="#MJMAIN-61" x="2531" y="0"></use><use href="#MJMAIN-74" x="3031" y="0"></use><use href="#MJMAIN-74" x="3421" y="0"></use><use href="#MJMAIN-61" x="3810" y="0"></use><use href="#MJMAIN-6E" x="4311" y="0"></use><use href="#MJMAIN-64" x="5117" y="0"></use><use href="#MJMAIN-69" x="5674" y="0"></use><use href="#MJMAIN-73" x="5952" y="0"></use><use href="#MJMAIN-74" x="6347" y="0"></use><use href="#MJMAIN-61" x="6736" y="0"></use><use href="#MJMAIN-6E" x="7237" y="0"></use><use href="#MJMAIN-63" x="7793" y="0"></use><use href="#MJMAIN-65" x="8238" y="0"></use><use href="#MJMAIN-3D" x="8960" y="0"></use><use href="#MJMAIN-7C" x="10016" y="0"></use><use href="#MJMAIN-32" x="10295" y="0"></use><use href="#MJMAIN-2212" x="11017" y="0"></use><use href="#MJMAIN-35" x="12018" y="0"></use><use href="#MJMAIN-7C" x="12519" y="0"></use><use href="#MJMAIN-2B" x="13019" y="0"></use><use href="#MJMAIN-7C" x="14020" y="0"></use><use href="#MJMAIN-32" x="14298" y="0"></use><use href="#MJMAIN-2212" x="15021" y="0"></use><use href="#MJMAIN-2212" x="16022" y="0"></use><use href="#MJMAIN-32" x="16800" y="0"></use><use href="#MJMAIN-7C" x="17301" y="0"></use><use href="#MJMAIN-3D" x="17857" y="0"></use><use href="#MJMAIN-37" x="18913" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow class="MJX-TeXAtom-ORD"><mtext>Manhattan distance</mtext></mrow><mo>=</mo><mo fence="false" stretchy="false">|</mo><mn>2</mn><mo>−</mo><mn>5</mn><mo fence="false" stretchy="false">|</mo><mo>+</mo><mo fence="false" stretchy="false">|</mo><mn>2</mn><mo>−</mo><mo>−</mo><mn>2</mn><mo fence="false" stretchy="false">|</mo><mo>=</mo><mn>7</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-21">
{\text{Manhattan distance}} = \lvert 2-5 \rvert + \lvert 2--2 \rvert = 7
</script>
</div>

<p><a class="glossary-anchor" name="l"></a>
</p><h2 class="glossary" id="l" data-text="L">L</h2><p></p>

<p><a class="glossary-anchor" name="L0_regularization"></a>
</p><h2 class="hide-from-toc" id="l0-regularization" data-text=" L0 regularization"> L<sub>0</sub> regularization</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A type of <a href="https://developers.google.com/machine-learning/glossary#regularization"><strong>regularization</strong></a> that
penalizes the <em>total number</em> of nonzero <a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weights</strong></a>
in a model. For example, a model having 11 nonzero weights
would be penalized more than a similar model having 10 nonzero weights.</p>

<p>L<sub>0</sub> regularization is seldom used.</p>

<devsite-expandable is-upgraded="" id="expandable-14"><a class="exw-control" aria-controls="expandable-14" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-additional-notes._7" data-text=" Click the icon for additional notes. ">
Click the icon for additional notes.<wbr>
</h4></a>



<div class="expand-background">
<p>
<a href="https://developers.google.com/machine-learning/glossary#L1_regularization"><b>L<sub>1</sub> regularization</b></a> and
<a href="https://developers.google.com/machine-learning/glossary#L2_regularization"><b>L<sub>2</sub> regularization</b></a> are
far more heavily used than L<sub>0</sub> regularization.
That's because L<sub>1</sub> and L<sub>2</sub> regularization
are <a href="https://developers.google.com/machine-learning/glossary#convex_function"><b>convex functions</b></a>
but L<sub>0</sub> regularization is not a convex function.
</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="L1_loss"></a>
</p><h2 class="hide-from-toc" id="l1-loss" data-text=" L1 loss"> L<sub>1</sub> loss</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#loss-function"><strong>loss function</strong></a> that calculates the absolute value
of the difference between actual <a href="https://developers.google.com/machine-learning/glossary#label"><strong>label</strong></a> values and
the values that a <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> predicts. For example, here's the
calculation of L<sub>1</sub> loss for a <a href="https://developers.google.com/machine-learning/glossary#batch"><strong>batch</strong></a> of five
<a href="https://developers.google.com/machine-learning/glossary#example"><strong>examples</strong></a>:</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr><th>Actual value of example</th> <th>Model's predicted value</th>
      <th>Absolute value of delta</th></tr>
  <tr><td>7</td> <td>6</td>  <td>1</td> </tr>
  <tr><td>5</td> <td>4</td>  <td>1</td> </tr>
  <tr><td>8</td> <td>11</td> <td>3</td> </tr>
  <tr><td>4</td> <td>6</td>  <td>2</td> </tr>
  <tr><td>9</td> <td>8</td>  <td>1</td> </tr>
  <tr><th colspan="2">&nbsp;</th> <th>8 = L<sub>1</sub> loss</th> </tr>
</tbody></table></div>

<p>L<sub>1</sub> loss is less sensitive to <a href="https://developers.google.com/machine-learning/glossary#outliers"><strong>outliers</strong></a>
than <a href="https://developers.google.com/machine-learning/glossary#squared_loss"><strong>L<sub>2</sub> loss</strong></a>.</p>

<p>The <a href="https://developers.google.com/machine-learning/glossary#MAE"><strong>Mean Absolute Error</strong></a> is the average
L<sub>1</sub> loss per example.</p>

<devsite-expandable is-upgraded="" id="expandable-15"><a class="exw-control" aria-controls="expandable-15" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-to-see-the-formal-math." data-text=" Click the icon to see the formal math. ">
Click the icon to see the formal math.<wbr>
</h4></a>



<div class="expand-background">

<p>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-22-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msub&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munderover&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/munderover&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x005E;&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="21.654ex" height="6.755ex" viewBox="0 -1632.5 9323.4 2908.3" role="img" focusable="false" aria-hidden="true" style="vertical-align: -2.963ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-4C" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="963" y="-213"></use><use href="#MJMATHI-6C" x="1135" y="0"></use><use href="#MJMATHI-6F" x="1433" y="0"></use><use href="#MJMATHI-73" x="1919" y="0"></use><use href="#MJMATHI-73" x="2388" y="0"></use><use href="#MJMAIN-3D" x="3136" y="0"></use><g transform="translate(4192,0)"><use href="#MJSZ2-2211" x="0" y="0"></use><g transform="translate(147,-1090)"><use transform="scale(0.707)" href="#MJMATHI-69" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-3D" x="345" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-30" x="1124" y="0"></use></g><use transform="scale(0.707)" href="#MJMATHI-6E" x="721" y="1627"></use></g><use href="#MJMAIN-7C" x="5803" y="0"></use><g transform="translate(6082,0)"><use href="#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-69" x="693" y="-213"></use></g><use href="#MJMAIN-2212" x="7139" y="0"></use><g transform="translate(8139,0)"><use href="#MJMATHI-79" x="1" y="0"></use><use href="#MJMAIN-5E" x="60" y="-10"></use><use transform="scale(0.707)" href="#MJMATHI-69" x="792" y="-342"></use></g><use href="#MJMAIN-7C" x="9044" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>L</mi><mn>1</mn></msub><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><munderover><mo>∑</mo><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mrow class="MJX-TeXAtom-ORD"><mover><mi>y</mi><mo stretchy="false">^</mo></mover></mrow><mi>i</mi></msub><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-22"> L_1 loss = \sum_{i=0}^n | y_i - \hat{y}_i |</script>
</p>

where:

<ul>
  <li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-23-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.395ex" height="1.429ex" viewBox="0 -511.5 600.5 615.4" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.241ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-6E" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-23">n</script> is the number of examples.</li>
  <li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-24-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.155ex" height="1.903ex" viewBox="0 -511.5 497.5 819.3" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi></math></span></span><script type="math/tex" id="MathJax-Element-24">y</script> is the actual value of the label.</li>
  <li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-25-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x005E;&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.302ex" height="2.494ex" viewBox="0 -766.3 560.7 1074" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="1" y="0"></use><use href="#MJMAIN-5E" x="60" y="-10"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><mover><mi>y</mi><mo stretchy="false">^</mo></mover></mrow></math></span></span><script type="math/tex" id="MathJax-Element-25">\hat{y}</script> is the value that the model predicts for <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-26-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.155ex" height="1.903ex" viewBox="0 -511.5 497.5 819.3" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi></math></span></span><script type="math/tex" id="MathJax-Element-26">y</script>.</li>
</ul>

</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="L1_regularization"></a>
</p><h2 class="hide-from-toc" id="l1-regularization" data-text=" L1 regularization"> L<sub>1</sub> regularization</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A type of <a href="https://developers.google.com/machine-learning/glossary#regularization"><strong>regularization</strong></a> that penalizes
<a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weights</strong></a> in proportion to the sum of the absolute value of
the weights. L<sub>1</sub> regularization helps drive the weights of irrelevant
or barely relevant features to <em>exactly 0</em>. A <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a> with
a weight of 0 is effectively removed from the model.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#L2_regularization"><strong>L<sub>2</sub> regularization</strong></a>.</p>

<p><a class="glossary-anchor" name="L2_loss"></a>
</p><h2 class="hide-from-toc" id="l2-loss" data-text=" L2 loss" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> L<sub>2</sub> loss</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  L2 loss" data-title="Copy link to this section:  L2 loss" data-id="l2-loss"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#loss-function"><strong>loss function</strong></a> that calculates the square
of the difference between actual <a href="https://developers.google.com/machine-learning/glossary#label"><strong>label</strong></a> values and
the values that a <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> predicts. For example, here's the
calculation of L<sub>2</sub> loss for a <a href="https://developers.google.com/machine-learning/glossary#batch"><strong>batch</strong></a> of five
<a href="https://developers.google.com/machine-learning/glossary#example"><strong>examples</strong></a>:</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr><th>Actual value of example</th> <th>Model's predicted value</th>
      <th>Square of delta</th></tr>
  <tr><td>7</td> <td>6</td>  <td>1</td> </tr>
  <tr><td>5</td> <td>4</td>  <td>1</td> </tr>
  <tr><td>8</td> <td>11</td> <td>9</td> </tr>
  <tr><td>4</td> <td>6</td>  <td>4</td> </tr>
  <tr><td>9</td> <td>8</td>  <td>1</td> </tr>
  <tr><th colspan="2">&nbsp;</th> <th>16 = L<sub>2</sub> loss</th> </tr>
</tbody></table></div>

<p>Due to squaring, L<sub>2</sub> loss amplifies the influence of
<a href="https://developers.google.com/machine-learning/glossary#outliers"><strong>outliers</strong></a>.
That is, L<sub>2</sub> loss reacts more strongly to bad predictions than
<a href="https://developers.google.com/machine-learning/glossary#L1_loss"><strong>L<sub>1</sub> loss</strong></a>. For example, the L<sub>1</sub> loss
for the preceding batch would be 8 rather than 16.  Notice that a single
outlier accounts for 9 of the 16.</p>

<p><a href="https://developers.google.com/machine-learning/glossary#regression_model"><strong>Regression models</strong></a> typically use L<sub>2</sub> loss
as the loss function.</p>

<p>The <a href="https://developers.google.com/machine-learning/glossary#MSE"><strong>Mean Squared Error</strong></a> is the average
L<sub>2</sub> loss per example.
<strong>Squared loss</strong> is another name for L<sub>2</sub> loss.</p>

<devsite-expandable is-upgraded="" id="expandable-16"><a class="exw-control" aria-controls="expandable-16" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-to-see-the-formal-math._1" data-text=" Click the icon to see the formal math. ">
Click the icon to see the formal math.<wbr>
</h4></a>



<div class="expand-background">

<p>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-27-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msub&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munderover&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/munderover&gt;&lt;msup&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x005E;&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="23.224ex" height="6.755ex" viewBox="0 -1632.5 9999.3 2908.3" role="img" focusable="false" aria-hidden="true" style="vertical-align: -2.963ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-4C" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="963" y="-213"></use><use href="#MJMATHI-6C" x="1135" y="0"></use><use href="#MJMATHI-6F" x="1433" y="0"></use><use href="#MJMATHI-73" x="1919" y="0"></use><use href="#MJMATHI-73" x="2388" y="0"></use><use href="#MJMAIN-3D" x="3136" y="0"></use><g transform="translate(4192,0)"><use href="#MJSZ2-2211" x="0" y="0"></use><g transform="translate(147,-1090)"><use transform="scale(0.707)" href="#MJMATHI-69" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-3D" x="345" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-30" x="1124" y="0"></use></g><use transform="scale(0.707)" href="#MJMATHI-6E" x="721" y="1627"></use></g><g transform="translate(5803,0)"><use href="#MJMAIN-28" x="0" y="0"></use><g transform="translate(389,0)"><use href="#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-69" x="693" y="-213"></use></g><use href="#MJMAIN-2212" x="1446" y="0"></use><g transform="translate(2447,0)"><use href="#MJMATHI-79" x="1" y="0"></use><use href="#MJMAIN-5E" x="60" y="-10"></use><use transform="scale(0.707)" href="#MJMATHI-69" x="792" y="-342"></use></g><use href="#MJMAIN-29" x="3352" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="5291" y="675"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>L</mi><mn>2</mn></msub><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><munderover><mo>∑</mo><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><msup><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mrow class="MJX-TeXAtom-ORD"><mover><mi>y</mi><mo stretchy="false">^</mo></mover></mrow><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mn>2</mn></msup></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-27"> L_2 loss = \sum_{i=0}^n {(y_i - \hat{y}_i)}^2</script>
</p>

where:

<ul>
  <li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-28-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.395ex" height="1.429ex" viewBox="0 -511.5 600.5 615.4" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.241ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-6E" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-28">n</script> is the number of examples.</li>
  <li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-29-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.155ex" height="1.903ex" viewBox="0 -511.5 497.5 819.3" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi></math></span></span><script type="math/tex" id="MathJax-Element-29">y</script> is the actual value of the label.</li>
  <li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-30-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x005E;&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.302ex" height="2.494ex" viewBox="0 -766.3 560.7 1074" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="1" y="0"></use><use href="#MJMAIN-5E" x="60" y="-10"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><mover><mi>y</mi><mo stretchy="false">^</mo></mover></mrow></math></span></span><script type="math/tex" id="MathJax-Element-30">\hat{y}</script> is the value that the model predicts for <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-31-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.155ex" height="1.903ex" viewBox="0 -511.5 497.5 819.3" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi></math></span></span><script type="math/tex" id="MathJax-Element-31">y</script>.</li>
</ul>

</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="L2_regularization"></a>
</p><h2 class="hide-from-toc" id="l2-regularization" data-text=" L2 regularization"> L<sub>2</sub> regularization</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A type of <a href="https://developers.google.com/machine-learning/glossary#regularization"><strong>regularization</strong></a> that penalizes
<a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weights</strong></a> in proportion to the sum of the <em>squares</em> of the weights.
L<sub>2</sub> regularization helps drive <a href="https://developers.google.com/machine-learning/glossary#outliers"><strong>outlier</strong></a> weights (those
with high positive or low negative values) closer to 0 but <em>not quite to 0</em>.
Features with values very close to 0 remain in the model
but don't influence the model's prediction very much.</p>

<p>L<sub>2</sub> regularization always improves generalization in
<a href="https://developers.google.com/machine-learning/glossary#linear_model"><strong>linear models</strong></a>.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#L1_regularization"><strong>L<sub>1</sub> regularization</strong></a>.</p>

<p><a class="glossary-anchor" name="label"></a>
</p><h2 class="hide-from-toc" id="label" data-text=" label"> label</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#supervised_machine_learning"><strong>supervised machine learning</strong></a>, the
"answer" or "result" portion of an <a href="https://developers.google.com/machine-learning/glossary#example"><strong>example</strong></a>.</p>

<p>Each <a href="https://developers.google.com/machine-learning/glossary#labeled_example"><strong>labeled example</strong></a> consists of one or more
<a href="https://developers.google.com/machine-learning/glossary#feature"><strong>features</strong></a> and a label.  For instance, in a spam
detection dataset, the label would probably be either "spam" or
"not spam." In a rainfall dataset, the label might be the amount of
rain that fell during a certain period.</p>

<p><a class="glossary-anchor" name="labeled_example"></a>
</p><h2 class="hide-from-toc" id="labeled-example" data-text=" labeled example"> labeled example</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>An example that contains one or more <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>features</strong></a> and a
<a href="https://developers.google.com/machine-learning/glossary#label"><strong>label</strong></a>. For example, the following table shows three
labeled examples from a house valuation model, each with three features
and one label:</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr><th>Number of bedrooms</th> <th>Number of bathrooms</th>
      <th>House age</th> <th>House price (label)</th></tr>
  <tr><td>3</td> <td>2</td> <td>15</td> <td>$345,000</td></tr>
  <tr><td>2</td> <td>1</td> <td>72</td> <td>$179,000</td></tr>
  <tr><td>4</td> <td>2</td> <td>34</td> <td>$392,000</td></tr>
</tbody></table></div>

<p>In <a href="https://developers.google.com/machine-learning/glossary#supervised_machine_learning"><strong>supervised machine learning</strong></a>,
models train on labeled examples and make predictions on
<a href="https://developers.google.com/machine-learning/glossary#unlabeled_example"><strong>unlabeled examples</strong></a>.</p>

<p>Contrast labeled example with unlabeled examples.</p>

<p><a class="glossary-anchor" name="LaMDA"></a>
</p><h2 class="hide-from-toc" id="lamda-language-model-for-dialogue-applications" data-text=" LaMDA (Language Model for Dialogue Applications)"> LaMDA (Language Model for Dialogue Applications)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#Transformer"><strong>Transformer</strong></a>-based
<a href="https://developers.google.com/machine-learning/glossary#large-language-model"><strong>large language model</strong></a> developed by Google trained on
a large dialogue dataset that can generate realistic conversational responses.</p>

<p><a href="https://blog.google/technology/ai/lamda/">LaMDA: our breakthrough conversation
technology</a> provides an overview.</p>

<p><a class="glossary-anchor" name="lambda"></a>
</p><h2 class="hide-from-toc" id="lambda" data-text=" lambda"> lambda</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#regularization_rate"><strong>regularization rate</strong></a>.</p>

<p>Lambda is an overloaded term. Here we're focusing on the term's
definition within <a href="https://developers.google.com/machine-learning/glossary#regularization"><strong>regularization</strong></a>.</p>

<p><a class="glossary-anchor" name="landmarks"></a>
</p><h2 class="hide-from-toc" id="landmarks" data-text=" landmarks"> landmarks</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#keypoints"><strong>keypoints</strong></a>.</p>

<p><a class="glossary-anchor" name="language-model"></a>
</p><h2 class="hide-from-toc" id="language-model" data-text=" language model"> language model</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> that estimates the probability of a <a href="https://developers.google.com/machine-learning/glossary#token"><strong>token</strong></a>
or sequence of tokens occurring in a longer sequence of tokens.</p>

<devsite-expandable is-upgraded="" id="expandable-17"><a class="exw-control" aria-controls="expandable-17" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-additional-notes._8" data-text=" Click the icon for additional notes. ">
Click the icon for additional notes.
</h4></a>



<div class="expand-background">
<p>
Though counterintuitive, many models that evaluate text are not
<b>language models</b>. For example, text classification models and sentiment
analysis models are not <b>language models</b>.
</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="large-language-model"></a>
</p><h2 class="hide-from-toc" id="large-language-model" data-text=" large language model"> large language model</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>An informal term with no strict definition that usually means a
<a href="https://developers.google.com/machine-learning/glossary#language-model"><strong>language model</strong></a> that has a high number of
<a href="https://developers.google.com/machine-learning/glossary#parameter"><strong>parameters</strong></a>.
Some large language models contain over 100 billion parameters.</p>

<devsite-expandable is-upgraded="" id="expandable-18"><a class="exw-control" aria-controls="expandable-18" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-additional-notes._9" data-text=" Click the icon for additional notes. ">
Click the icon for additional notes.
</h4></a>



<div class="expand-background">
<p>
You might be wondering when a
<a href="https://developers.google.com/machine-learning/glossary#language-model"><b>language model</b></a> becomes large enough to
be termed a <b>large language model</b>.  Currently,
there is no agreed-upon defining line for the number of parameters.
</p>

<p>
Most current large language models (for example,
<a href="https://developers.google.com/machine-learning/glossary#GPT"><b>GPT</b></a>) are based on
<a href="https://developers.google.com/machine-learning/glossary#Transformer"><b>Transformer</b></a> architecture.
</p>

</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="layer"></a>
</p><h2 class="hide-from-toc" id="layer" data-text=" layer"> layer</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A set of <a href="https://developers.google.com/machine-learning/glossary#neuron"><strong>neurons</strong></a> in a
<a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural network</strong></a>. Three common types of layers
are as follows:</p>

<ul>
<li>The <a href="https://developers.google.com/machine-learning/glossary#input_layer"><strong>input layer</strong></a>, which provides values for all the
<a href="https://developers.google.com/machine-learning/glossary#feature"><strong>features</strong></a>.</li>
<li>One or more <a href="https://developers.google.com/machine-learning/glossary#hidden_layer"><strong>hidden layers</strong></a>, which find
nonlinear relationships between the features and the label.</li>
<li>The <a href="https://developers.google.com/machine-learning/glossary#output_layer"><strong>output layer</strong></a>, which provides the prediction.</li>
</ul>

<p>For example, the following illustration shows a neural network with
one input layer, two hidden layers, and one output layer:</p>

<p>
<img src="./ML_Glossary_files/Layers.png" loading="lazy" height="300" width="600" alt="A neural network with one input layer, two hidden layers, and one
          output layer. The input layer consists of two features. The first
          hidden layer consists of three neurons and the second hidden layer
          consists of two neurons. The output layer consists of a single node.">
</p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#TensorFlow"><strong>TensorFlow</strong></a>, <strong>layers</strong> are also Python functions that take
<a href="https://developers.google.com/machine-learning/glossary#tensor"><strong>Tensors</strong></a> and configuration options as input and
produce other tensors as output.</p>

<p><a class="glossary-anchor" name="layers_API"></a>
</p><h2 class="hide-from-toc" id="layers-api-tf.layers" data-text=" Layers API (tf.layers)"> Layers API (tf.<wbr>layers)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>A TensorFlow API for constructing a <a href="https://developers.google.com/machine-learning/glossary#deep_model"><strong>deep</strong></a> neural network
as a composition of layers. The Layers API enables you to build different
types of <a href="https://developers.google.com/machine-learning/glossary#layer"><strong>layers</strong></a>, such as:</p>

<ul>
<li><code translate="no" dir="ltr">tf.layers.Dense</code> for a <a href="https://developers.google.com/machine-learning/glossary#fully_connected_layer"><strong>fully-connected layer</strong></a>.</li>
<li><code translate="no" dir="ltr">tf.layers.Conv2D</code> for a convolutional layer.</li>
</ul>

<p>The Layers API follows the <a href="https://developers.google.com/machine-learning/glossary#Keras"><strong>Keras</strong></a> layers API conventions.
That is, aside from a different prefix, all functions in the Layers API
have the same names and signatures as their counterparts in the Keras
layers API.</p>

<p><a class="glossary-anchor" name="leaf"></a>
</p><h2 class="hide-from-toc" id="leaf" data-text=" leaf "> leaf </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>Any endpoint in a <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a>. Unlike a
<a href="https://developers.google.com/machine-learning/glossary#condition"><strong>condition</strong></a>, a leaf does not perform a test.
Rather, a leaf is a possible prediction. A leaf is also the terminal
<a href="https://developers.google.com/machine-learning/glossary#node"><strong>node</strong></a> of an <a href="https://developers.google.com/machine-learning/glossary#inference-path"><strong>inference path</strong></a>.</p>

<p>For example, the following decision tree contains three leaves:</p>

<p>
<img src="./ML_Glossary_files/Leaf.png" height="100" loading="lazy" alt="A decision tree with two conditions leading to three leaves.">
</p>

<p><a class="glossary-anchor" name="learning_rate"></a>
</p><h2 class="hide-from-toc" id="learning-rate" data-text=" learning rate"> learning rate</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A floating-point number that tells the <a href="https://developers.google.com/machine-learning/glossary#gradient_descent"><strong>gradient descent</strong></a>
algorithm how strongly to adjust weights and biases on each
<a href="https://developers.google.com/machine-learning/glossary#iteration"><strong>iteration</strong></a>.  For example, a learning rate of 0.3 would
adjust weights and biases three times more powerfully than a learning rate
of 0.1.</p>

<p>Learning rate is a key <a href="https://developers.google.com/machine-learning/glossary#hyperparameter"><strong>hyperparameter</strong></a>. If you set
the learning rate too low, training will take too long. If
you set the learning rate too high, gradient descent often has trouble
reaching <a href="https://developers.google.com/machine-learning/glossary#convergence"><strong>convergence</strong></a>.</p>

<devsite-expandable is-upgraded="" id="expandable-19"><a class="exw-control" aria-controls="expandable-19" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-a-more-mathematical-explanation." data-text=" Click the icon for a more mathematical explanation. ">
Click the icon for a more mathematical explanation.<wbr>
</h4></a>



<div class="expand-background">
<p>
During each iteration, the
<a href="https://developers.google.com/machine-learning/glossary#gradient_descent"><b>gradient descent</b></a>
algorithm multiplies the
learning rate by the gradient. The resulting product is called the
<b>gradient step</b>.
</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="least_squares_regression"></a>
</p><h2 class="hide-from-toc" id="least-squares-regression" data-text=" least squares regression"> least squares regression</h2><p></p>

<p>A linear regression model trained by minimizing
<a href="https://developers.google.com/machine-learning/glossary#L2_loss"><strong>L<sub>2</sub> Loss</strong></a>.</p>

<p><a class="glossary-anchor" name="linear_model"></a>
</p><h2 class="hide-from-toc" id="linear-model" data-text=" linear model"> linear model</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> that assigns one <a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weight</strong></a> per
<a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a> to make <a href="https://developers.google.com/machine-learning/glossary#prediction"><strong>predictions</strong></a>.
(Linear models also incorporate a <a href="https://developers.google.com/machine-learning/glossary#bias"><strong>bias</strong></a>.) In contrast,
the relationship of features to predictions in <a href="https://developers.google.com/machine-learning/glossary#deep_model"><strong>deep models</strong></a>
is generally <strong>nonlinear</strong>.</p>

<p>Linear models are usually easier to train and more
<a href="https://developers.google.com/machine-learning/glossary#interpretability"><strong>interpretable</strong></a> than deep models. However,
deep models can learn complex relationships <em>between</em> features.</p>

<p><a href="https://developers.google.com/machine-learning/glossary#linear_regression"><strong>Linear regression</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#logistic_regression"><strong>logistic regression</strong></a> are two types of linear models.</p>

<devsite-expandable is-upgraded="" id="expandable-20"><a class="exw-control" aria-controls="expandable-20" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-to-see-the-math." data-text=" Click the icon to see the math. ">
Click the icon to see the math.<wbr>
</h4></a>



<div class="expand-background">
<p>
A linear model follows this formula:

</p><div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-32-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msup&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;&amp;#x2032;&lt;/mo&gt;&lt;/msup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo&gt;&amp;#x2026;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="33.208ex" height="2.731ex" viewBox="0 -868.2 14297.9 1175.9" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2032" x="706" y="583"></use><use href="#MJMAIN-3D" x="1072" y="0"></use><use href="#MJMATHI-62" x="2128" y="0"></use><use href="#MJMAIN-2B" x="2780" y="0"></use><g transform="translate(3780,0)"><use href="#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="1013" y="-213"></use></g><g transform="translate(4951,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="809" y="-213"></use></g><use href="#MJMAIN-2B" x="6199" y="0"></use><g transform="translate(7200,0)"><use href="#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="1013" y="-213"></use></g><g transform="translate(8371,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="809" y="-213"></use></g><use href="#MJMAIN-2B" x="9619" y="0"></use><use href="#MJMAIN-2026" x="10620" y="0"></use><g transform="translate(11959,0)"><use href="#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-6E" x="1013" y="-213"></use></g><g transform="translate(13200,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-6E" x="809" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msup><mi>y</mi><mo>′</mo></msup><mo>=</mo><mi>b</mi><mo>+</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mo>…</mo><msub><mi>w</mi><mi>n</mi></msub><msub><mi>x</mi><mi>n</mi></msub></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-32">y' = b + w_1x_1 + w_2x_2 + … w_nx_n</script>
</div>

where:
<ul>
<li>y' is the raw prediction. (In certain kinds of linear models, this
raw prediction will be further modified.  For example, see
<a href="https://developers.google.com/machine-learning/glossary#logistic_regression"><b>logistic regression</b></a>.)</li>
<li>b is the <a href="https://developers.google.com/machine-learning/glossary#bias"><b>bias</b></a>.</li>
<li>w is a <a href="https://developers.google.com/machine-learning/glossary#weight"><b>weight</b></a>, so w<sub>1</sub> is
the weight of the first feature, w<sub>2</sub> is the weight of the
second feature, and so on.</li>
<li>x is a <a href="https://developers.google.com/machine-learning/glossary#feature"><b>feature</b></a>, so x<sub>1</sub> is the
value of the first feature, x<sub>2</sub> is the value of the second feature,
and so on.</li>
</ul>

For example, suppose a linear model for three features learns the following
bias and weights:
<ul>
<li>b = 7</li>
<li>w<sub>1</sub> = -2.5</li>
<li>w<sub>2</sub> = -1.2</li>
<li>w<sub>3</sub> = 1.4</li>
</ul>

Therefore, given three features (x<sub>1</sub>, x<sub>2</sub>,
and x<sub>3</sub>), the linear model uses the following equation
to generate each prediction:

<devsite-code no-copy="" data-copy-event-label=""><pre translate="no" dir="ltr" is-upgraded="">y' = 7 + (-2.5)(x<sub>1</sub>) + (-1.2)(x<sub>2</sub>) + (1.4)(x<sub>3</sub>)
</pre></devsite-code>

<p>Suppose a particular example contains the following values:</p>

<ul>
<li>x<sub>1</sub> = 4</li>
<li>x<sub>2</sub> = -10</li>
<li>x<sub>3</sub> = 5</li>
</ul>

Plugging those values into the formula yields a prediction for this example:

<devsite-code no-copy="" data-copy-event-label=""><pre translate="no" dir="ltr" is-upgraded="">y' = 7 + (-2.5)(4) + (-1.2)(-10) + (1.4)(5)
y' = 16
</pre></devsite-code>

<p>Linear models include not only models that use only a linear equation to
make predictions but also a broader set of models that use a linear equation
as just one component of the formula that makes predictions.
For example, logistic regression post-processes the raw
prediction (y') to produce a final prediction value between 0 and 1,
exclusively.</p>

<p></p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="linear"></a>
</p><h2 class="hide-from-toc" id="linear" data-text=" linear "> linear </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A relationship between two or more variables that can be represented solely
through addition and multiplication.</p>

<p>The plot of a linear relationship is a line.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#nonlinear"><strong>nonlinear</strong></a>.</p>

<p><a class="glossary-anchor" name="linear_regression"></a>
</p><h2 class="hide-from-toc" id="linear-regression" data-text=" linear regression"> linear regression</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A type of machine learning model in which both of the following are true:</p>

<ul>
<li>The model is a <a href="https://developers.google.com/machine-learning/glossary#linear_model"><strong>linear model</strong></a>.</li>
<li>The prediction is a floating-point value. (This is the
<a href="https://developers.google.com/machine-learning/glossary#regression_model"><strong>regression</strong></a> part of <em>linear regression</em>.)</li>
</ul>

<p>Contrast linear regression with <a href="https://developers.google.com/machine-learning/glossary#logistic_regression"><strong>logistic regression</strong></a>.
Also, contrast regression with <a href="https://developers.google.com/machine-learning/glossary#classification_model"><strong>classification</strong></a>.</p>

<p><a class="glossary-anchor" name="logistic_regression"></a>
</p><h2 class="hide-from-toc" id="logistic-regression" data-text=" logistic regression"> logistic regression</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A type of <a href="https://developers.google.com/machine-learning/glossary#regression_model"><strong>regression model</strong></a> that predicts a probability.
Logistic regression models have the following characteristics:</p>

<ul>
<li>The label is <a href="https://developers.google.com/machine-learning/glossary#categorical_data"><strong>categorical</strong></a>. The term logistic
regression usually refers to <strong>binary logistic regression</strong>, that is,
to a model that calculates probabilities for labels with two possible values.
A less common variant, <strong>multinomial logistic regression</strong>, calculates
probabilities for labels with more than two possible values.</li>
<li>The loss function during training is <a href="https://developers.google.com/machine-learning/glossary#Log_Loss"><strong>Log Loss</strong></a>.
(Multiple Log Loss units can be placed in parallel for labels
with more than two possible values.)</li>
<li>The model has a linear architecture, not a deep neural network.
However, the remainder of this definition also applies to
<a href="https://developers.google.com/machine-learning/glossary#deep_model"><strong>deep models</strong></a> that predict probabilities
for categorical labels.</li>
</ul>

<p>For example, consider a logistic regression model that calculates the
probability of an input email being either spam or not spam.
During inference, suppose the model predicts 0.72. Therefore, the
model is estimating:</p>

<ul>
<li>A 72% chance of the email being spam.</li>
<li>A 28% chance of the email not being spam.</li>
</ul>

<p>A logistic regression model uses the following two-step architecture:</p>

<ol>
<li>The model generates a raw prediction (y') by applying a linear function
of input features.</li>
<li>The model uses that raw prediction as input to a
<a href="https://developers.google.com/machine-learning/glossary#sigmoid-function"><strong>sigmoid function</strong></a>, which converts the raw
prediction to a value between 0 and 1, exclusive.</li>
</ol>

<p>Like any regression model, a logistic regression model predicts a number.
However, this number typically becomes part of a binary classification
model as follows:</p>

<ul>
<li>If the predicted number is <em>greater</em> than the
<a href="https://developers.google.com/machine-learning/glossary#classification_threshold"><strong>classification threshold</strong></a>, the
binary classification model predicts the positive class.</li>
<li>If the predicted number is <em>less</em> than the classification threshold,
the binary classification model predicts the negative class.</li>
</ul>

<p><a class="glossary-anchor" name="logits"></a>
</p><h2 class="hide-from-toc" id="logits" data-text=" logits"> logits</h2><p></p>

<p>The vector of raw (non-normalized) predictions that a classification
model generates, which is ordinarily then passed to a normalization function.
If the model is solving a <a href="https://developers.google.com/machine-learning/glossary#multi-class"><strong>multi-class classification</strong></a>
problem, logits typically become an input to the
<a href="https://developers.google.com/machine-learning/glossary#softmax"><strong>softmax</strong></a> function.
The softmax function then generates a vector of (normalized)
probabilities with one value for each possible class.</p>

<p><a href="https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits" target="T">tf.nn.sigmoid_cross_entropy_with_logits</a>.</p>

<p><a class="glossary-anchor" name="Log_Loss"></a>
</p><h2 class="hide-from-toc" id="log-loss" data-text=" Log Loss"> Log Loss</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The <a href="https://developers.google.com/machine-learning/glossary#loss-function"><strong>loss function</strong></a> used in binary
<a href="https://developers.google.com/machine-learning/glossary#logistic_regression"><strong>logistic regression</strong></a>.</p>

<devsite-expandable is-upgraded="" id="expandable-21"><a class="exw-control" aria-controls="expandable-21" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-to-see-the-math._1" data-text=" Click the icon to see the math. ">
Click the icon to see the math.<wbr>
</h4></a>



<div class="expand-background">
<p>
The following formula calculates Log Loss:
</p>

<p>
</p><div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-33-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Log Loss&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;&amp;#x2032;&lt;/mo&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;&amp;#x2032;&lt;/mo&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="49.044ex" height="5.808ex" viewBox="0 -1021.1 21116 2500.7" role="img" focusable="false" aria-hidden="true" style="vertical-align: -3.437ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-4C"></use><use href="#MJMAIN-6F" x="625" y="0"></use><use href="#MJMAIN-67" x="1126" y="0"></use><use href="#MJMAIN-4C" x="1876" y="0"></use><use href="#MJMAIN-6F" x="2502" y="0"></use><use href="#MJMAIN-73" x="3002" y="0"></use><use href="#MJMAIN-73" x="3397" y="0"></use><use href="#MJMAIN-3D" x="4069" y="0"></use><g transform="translate(5125,0)"><use href="#MJSZ2-2211" x="558" y="0"></use><g transform="translate(0,-1149)"><use transform="scale(0.707)" href="#MJMAIN-28" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-78" x="389" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2C" x="962" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-79" x="1240" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-29" x="1738" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2208" x="2127" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-44" x="2795" y="0"></use></g></g><use href="#MJMAIN-2212" x="7854" y="0"></use><use href="#MJMATHI-79" x="8632" y="0"></use><g transform="translate(9297,0)"><use href="#MJMAIN-6C"></use><use href="#MJMAIN-6F" x="278" y="0"></use><use href="#MJMAIN-67" x="779" y="0"></use></g><use href="#MJMAIN-28" x="10576" y="0"></use><g transform="translate(10966,0)"><use href="#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2032" x="706" y="583"></use></g><use href="#MJMAIN-29" x="11760" y="0"></use><use href="#MJMAIN-2212" x="12372" y="0"></use><use href="#MJMAIN-28" x="13372" y="0"></use><use href="#MJMAIN-31" x="13762" y="0"></use><use href="#MJMAIN-2212" x="14485" y="0"></use><use href="#MJMATHI-79" x="15485" y="0"></use><use href="#MJMAIN-29" x="15983" y="0"></use><g transform="translate(16539,0)"><use href="#MJMAIN-6C"></use><use href="#MJMAIN-6F" x="278" y="0"></use><use href="#MJMAIN-67" x="779" y="0"></use></g><use href="#MJMAIN-28" x="17819" y="0"></use><use href="#MJMAIN-31" x="18208" y="0"></use><use href="#MJMAIN-2212" x="18931" y="0"></use><g transform="translate(19932,0)"><use href="#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2032" x="706" y="583"></use></g><use href="#MJMAIN-29" x="20726" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Log Loss</mtext><mo>=</mo><munder><mo>∑</mo><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>D</mi></mrow></munder><mo>−</mo><mi>y</mi><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msup><mi>y</mi><mo>′</mo></msup><mo stretchy="false">)</mo><mo>−</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>y</mi><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msup><mi>y</mi><mo>′</mo></msup><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-33">\text{Log Loss} = \sum_{(x,y)\in D} -y\log(y') - (1 - y)\log(1 - y')</script>
</div>

where:

<ul>
  <li>
  <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-34-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.093ex" height="2.613ex" viewBox="0 -817.3 4345.7 1125" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-28" x="0" y="0"></use><use href="#MJMATHI-78" x="389" y="0"></use><use href="#MJMAIN-2C" x="962" y="0"></use><use href="#MJMATHI-79" x="1407" y="0"></use><use href="#MJMAIN-29" x="1904" y="0"></use><use href="#MJMAIN-2208" x="2571" y="0"></use><use href="#MJMATHI-44" x="3517" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>D</mi></math></span></span><script type="math/tex" id="MathJax-Element-34">(x,y)\in D</script> is the data set containing many labeled
  examples, which are <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-35-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.328ex" height="2.613ex" viewBox="0 -817.3 2294.2 1125" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-28" x="0" y="0"></use><use href="#MJMATHI-78" x="389" y="0"></use><use href="#MJMAIN-2C" x="962" y="0"></use><use href="#MJMATHI-79" x="1407" y="0"></use><use href="#MJMAIN-29" x="1904" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-35">(x,y)</script> pairs.
  </li>
  <li>
    <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-36-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.155ex" height="1.903ex" viewBox="0 -511.5 497.5 819.3" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi></math></span></span><script type="math/tex" id="MathJax-Element-36">y</script> is the label in a labeled example.  Since this is logistic regression,
    every value of <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-37-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.155ex" height="1.903ex" viewBox="0 -511.5 497.5 819.3" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi></math></span></span><script type="math/tex" id="MathJax-Element-37">y</script> must either be 0 or 1.
  </li>
  <li>
    <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-38-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;&amp;#x2032;&lt;/mo&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.845ex" height="2.613ex" viewBox="0 -817.3 794.5 1125" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2032" x="706" y="513"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>y</mi><mo>′</mo></msup></math></span></span><script type="math/tex" id="MathJax-Element-38">y'</script> is the predicted value (somewhere between 0 and 1, exclusive),
    given the set of features in <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-39-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.33ex" height="1.429ex" viewBox="0 -511.5 572.5 615.4" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.241ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-78" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></span></span><script type="math/tex" id="MathJax-Element-39">x</script>.
  </li>
</ul>


<p></p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="log-odds"></a>
</p><h2 class="hide-from-toc" id="log-odds" data-text=" log-odds"> log-odds</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The logarithm of the odds of some event.</p>

<devsite-expandable is-upgraded="" id="expandable-22"><a class="exw-control" aria-controls="expandable-22" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-to-see-the-math._2" data-text=" Click the icon to see the math. ">
Click the icon to see the math.<wbr>
</h4></a>



<div class="expand-background">
<p>
If the event is a binary probability, then <b>odds</b> refers to
the ratio of the probability of success (<i>p</i>) to the probability of
failure (1-<i>p</i>). For example, suppose that a given event has a 90%
probability of success and a 10% probability of failure. In this case,
odds is calculated as follows:
</p>


<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-40-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;odds&lt;/mtext&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtext&gt;p&lt;/mtext&gt;&lt;mtext&gt;(1-p)&lt;/mtext&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;.9&lt;/mn&gt;&lt;mn&gt;.1&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;9&lt;/mtext&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="23.642ex" height="5.808ex" viewBox="0 -1428.7 10179.2 2500.7" role="img" focusable="false" aria-hidden="true" style="vertical-align: -2.49ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-6F"></use><use href="#MJMAIN-64" x="500" y="0"></use><use href="#MJMAIN-64" x="1057" y="0"></use><use href="#MJMAIN-73" x="1613" y="0"></use><use href="#MJMAIN-3D" x="2285" y="0"></use><g transform="translate(3064,0)"><g transform="translate(397,0)"><rect stroke="none" width="2289" height="60" x="0" y="220"></rect><use href="#MJMAIN-70" x="866" y="676"></use><g transform="translate(60,-719)"><use href="#MJMAIN-28"></use><use href="#MJMAIN-31" x="389" y="0"></use><use href="#MJMAIN-2D" x="890" y="0"></use><use href="#MJMAIN-70" x="1223" y="0"></use><use href="#MJMAIN-29" x="1780" y="0"></use></g></g></g><use href="#MJMAIN-3D" x="6149" y="0"></use><g transform="translate(6927,0)"><g transform="translate(397,0)"><rect stroke="none" width="899" height="60" x="0" y="220"></rect><g transform="translate(60,676)"><use href="#MJMAIN-2E"></use><use href="#MJMAIN-39" x="278" y="0"></use></g><g transform="translate(60,-686)"><use href="#MJMAIN-2E"></use><use href="#MJMAIN-31" x="278" y="0"></use></g></g></g><use href="#MJMAIN-3D" x="8622" y="0"></use><use href="#MJMAIN-39" x="9678" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow class="MJX-TeXAtom-ORD"><mtext>odds</mtext></mrow><mo>=</mo><mfrac><mtext>p</mtext><mtext>(1-p)</mtext></mfrac><mo>=</mo><mfrac><mn>.9</mn><mn>.1</mn></mfrac><mo>=</mo><mrow class="MJX-TeXAtom-ORD"><mtext>9</mtext></mrow></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-40">
{\text{odds}} =
\frac{\text{p}} {\text{(1-p)}} =
\frac{.9} {.1} =
{\text{9}}
</script>
</div>


<p>The log-odds is simply the logarithm of the odds. By convention,
"logarithm" refers to
<a href="https://wikipedia.org/wiki/Natural_logarithm" target="T">natural logarithm</a>,
but logarithm could actually be any base greater than 1.
Sticking to convention, the log-odds of our example is therefore:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-41-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;log-odds&lt;/mtext&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;9&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mtext&gt;&amp;#xA0;&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;2.2&lt;/mn&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="23.219ex" height="2.613ex" viewBox="0 -817.3 9997.1 1125" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-6C"></use><use href="#MJMAIN-6F" x="278" y="0"></use><use href="#MJMAIN-67" x="779" y="0"></use><use href="#MJMAIN-2D" x="1279" y="0"></use><use href="#MJMAIN-6F" x="1613" y="0"></use><use href="#MJMAIN-64" x="2113" y="0"></use><use href="#MJMAIN-64" x="2670" y="0"></use><use href="#MJMAIN-73" x="3226" y="0"></use><use href="#MJMAIN-3D" x="3898" y="0"></use><use href="#MJMATHI-6C" x="4955" y="0"></use><use href="#MJMATHI-6E" x="5253" y="0"></use><use href="#MJMAIN-28" x="5854" y="0"></use><use href="#MJMAIN-39" x="6243" y="0"></use><use href="#MJMAIN-29" x="6744" y="0"></use><use href="#MJMAIN-3D" x="7661" y="0"></use><g transform="translate(8717,0)"><use href="#MJMAIN-32"></use><use href="#MJMAIN-2E" x="500" y="0"></use><use href="#MJMAIN-32" x="779" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow class="MJX-TeXAtom-ORD"><mtext>log-odds</mtext></mrow><mo>=</mo><mi>l</mi><mi>n</mi><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo><mtext>&nbsp;</mtext><mo>=</mo><mn>2.2</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-41">
{\text{log-odds}} =
ln(9) ~= 2.2
</script>
</div>

<p>The log-odds function is the inverse of the
<a href="https://developers.google.com/machine-learning/glossary#sigmoid-function"><b>sigmoid function</b></a>.
</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="Long_Short-Term_Memory"></a>
</p><h2 class="hide-from-toc" id="long-short-term-memory-lstm" data-text=" Long Short-Term Memory (LSTM)"> Long Short-Term Memory (LSTM)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Sequence Models">#seq</div>
</div><p></p>

<p>A type of cell in a
<a href="https://developers.google.com/machine-learning/glossary#recurrent_neural_network"><strong>recurrent neural network</strong></a> used to process
sequences of data in applications such as handwriting recognition, machine
translation, and image captioning. LSTMs address the
<a href="https://developers.google.com/machine-learning/glossary#vanishing_gradient_problem"><strong>vanishing gradient problem</strong></a> that occurs when
training RNNs due to long data sequences by maintaining history in an
internal memory state based on new input and context from previous cells
in the RNN.</p>

<p><a class="glossary-anchor" name="loss"></a>
</p><h2 class="hide-from-toc" id="loss" data-text=" loss"> loss</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>During the <a href="https://developers.google.com/machine-learning/glossary#training"><strong>training</strong></a> of a
<a href="https://developers.google.com/machine-learning/glossary#supervised_machine_learning"><strong>supervised model</strong></a>, a measure of how far a
model's <a href="https://developers.google.com/machine-learning/glossary#prediction"><strong>prediction</strong></a> is from its <a href="https://developers.google.com/machine-learning/glossary#label"><strong>label</strong></a>.</p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#loss-function"><strong>loss function</strong></a> calculates the loss.</p>

<p><a class="glossary-anchor" name="loss_curve"></a>
</p><h2 class="hide-from-toc" id="loss-curve" data-text=" loss curve"> loss curve</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A plot of <a href="https://developers.google.com/machine-learning/glossary#loss"><strong>loss</strong></a> as a function of the number of training
<a href="https://developers.google.com/machine-learning/glossary#iteration"><strong>iterations</strong></a>. The following plot shows a typical loss
curve:</p>

<p>
<img src="./ML_Glossary_files/LossCurveSmooth.png" height="300" loading="lazy" alt="A Cartesian graph of loss versus training iterations, showing a
          rapid drop in loss for the initial iterations, followed by a gradual
          drop, and then a flat slope during the final iterations.">
</p>

<p>Loss curves can help you determine when your model is
<a href="https://developers.google.com/machine-learning/glossary#convergence"><strong>converging</strong></a> or <a href="https://developers.google.com/machine-learning/glossary#overfitting"><strong>overfitting</strong></a>.</p>

<p>Loss curves can plot all of the following types of loss:</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#training-loss"><strong>training loss</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#validation-loss"><strong>validation loss</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#test-loss"><strong>test loss</strong></a></li>
</ul>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#generalization_curve"><strong>generalization curve</strong></a>.</p>

<p><a class="glossary-anchor" name="loss-function"></a>
</p><h2 class="hide-from-toc" id="loss-function" data-text=" loss function" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> loss function</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  loss function" data-title="Copy link to this section:  loss function" data-id="loss-function"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>During <a href="https://developers.google.com/machine-learning/glossary#training"><strong>training</strong></a> or testing, a
mathematical function that calculates the
loss on a <a href="https://developers.google.com/machine-learning/glossary#batch"><strong>batch</strong></a> of examples. A loss function returns a lower loss
for models that makes good predictions than for models that make
bad predictions.</p>

<p>The goal of training is typically to minimize the loss that a loss function
returns.</p>

<p>Many different kinds of loss functions exist. Pick the appropriate loss
function for the kind of model you are building. For example:</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#L2_loss"><strong>L<sub>2</sub> loss</strong></a> (or <a href="https://developers.google.com/machine-learning/glossary#MSE"><strong>Mean Squared Error</strong></a>)
is the loss function for <a href="https://developers.google.com/machine-learning/glossary#linear_regression"><strong>linear regression</strong></a>.</li>
<li><a href="https://developers.google.com/machine-learning/glossary#Log_Loss"><strong>Log Loss</strong></a> is the loss function for
<a href="https://developers.google.com/machine-learning/glossary#logistic_regression"><strong>logistic regression</strong></a>.</li>
</ul>

<p><a class="glossary-anchor" name="loss_surface"></a>
</p><h2 class="hide-from-toc" id="loss-surface" data-text=" loss surface" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> loss surface</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  loss surface" data-title="Copy link to this section:  loss surface" data-id="loss-surface"></button></h2><p></p>

<p>A graph of weight(s) vs. loss. <a href="https://developers.google.com/machine-learning/glossary#gradient_descent"><strong>Gradient descent</strong></a> aims
to find the weight(s) for which the loss surface is at a local minimum.</p>

<p><a class="glossary-anchor" name="LSTM"></a>
</p><h2 class="hide-from-toc" id="lstm" data-text=" LSTM"> LSTM</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Sequence Models">#seq</div>
</div><p></p>

<p>Abbreviation for <a href="https://developers.google.com/machine-learning/glossary#Long_Short-Term_Memory"><strong>Long Short-Term Memory</strong></a>.</p>

<p><a class="glossary-anchor" name="m"></a>
</p><h2 class="glossary" id="m" data-text="M">M</h2><p></p>

<p><a class="glossary-anchor" name="machine_learning"></a>
</p><h2 class="hide-from-toc" id="machine-learning" data-text=" machine learning"> machine learning</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A program or system that <a href="https://developers.google.com/machine-learning/glossary#training"><strong>trains</strong></a> a
<a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> from input data.  The trained model can
make useful predictions from new (never-before-seen) data drawn from
the same distribution as the one used to train the model.</p>

<p>Machine learning also refers to the field of study concerned
with these programs or systems.</p>

<p><a class="glossary-anchor" name="majority_class"></a>
</p><h2 class="hide-from-toc" id="majority-class" data-text=" majority class"> majority class</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The more common label in a
<a href="https://developers.google.com/machine-learning/glossary#class_imbalanced_data_set"><strong>class-imbalanced dataset</strong></a>. For example,
given a dataset containing 99% negative labels and 1% positive labels, the
negative labels are the majority class.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#minority_class"><strong>minority class</strong></a>.</p>

<p><a class="glossary-anchor" name="markov_decision_process"></a>
</p><h2 class="hide-from-toc" id="markov-decision-process-mdp" data-text=" Markov decision process (MDP)"> Markov decision process (MDP)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>A graph representing the decision-making model where decisions
(or <a href="https://developers.google.com/machine-learning/glossary#action"><strong>actions</strong></a>) are taken to navigate a sequence of
<a href="https://developers.google.com/machine-learning/glossary#state"><strong>states</strong></a> under the assumption that the
<a href="https://developers.google.com/machine-learning/glossary#Markov_property"><strong>Markov property</strong></a> holds. In
<a href="https://developers.google.com/machine-learning/glossary#reinforcement_learning"><strong>reinforcement learning</strong></a>, these transitions
between states return a numerical <a href="https://developers.google.com/machine-learning/glossary#reward"><strong>reward</strong></a>.</p>

<p><a class="glossary-anchor" name="Markov_property"></a>
</p><h2 class="hide-from-toc" id="markov-property" data-text=" Markov property"> Markov property</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>A property of certain <a href="https://developers.google.com/machine-learning/glossary#environment"><strong>environments</strong></a>, where state
transitions are entirely determined by information implicit in the
current <a href="https://developers.google.com/machine-learning/glossary#state"><strong>state</strong></a> and the agent’s <a href="https://developers.google.com/machine-learning/glossary#action"><strong>action</strong></a>.</p>

<p><a class="glossary-anchor" name="masked-language-model"></a>
</p><h2 class="hide-from-toc" id="masked-language-model" data-text=" masked language model"> masked language model</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#language-model"><strong>language model</strong></a> that predicts the probability of
candidate tokens to fill in blanks in a sequence. For instance, a
masked language model can calculate probabilities for candidate word(s)
to replace the underline in the following sentence:</p>

<blockquote>
<p>The ____ in the hat came back.</p>
</blockquote>

<p>The literature typically uses the string "MASK" instead of an underline.
For example:</p>

<blockquote>
<p>The "MASK" in the hat came back.</p>
</blockquote>

<p>Most modern masked language models are <a href="https://developers.google.com/machine-learning/glossary#bidirectional"><strong>bidirectional</strong></a>.</p>

<p><a class="glossary-anchor" name="matplotlib"></a>
</p><h2 class="hide-from-toc" id="matplotlib" data-text=" matplotlib"> matplotlib</h2><p></p>

<p>An open-source Python 2D plotting library.
<a href="https://matplotlib.org/" target="T">matplotlib</a> helps you visualize
different aspects of machine learning.</p>

<p><a class="glossary-anchor" name="matrix_factorization"></a>
</p><h2 class="hide-from-toc" id="matrix-factorization" data-text=" matrix factorization"> matrix factorization</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Recommendation Systems">#recsystems</div>
</div><p></p>

<p>In math, a mechanism for finding the matrices whose dot product approximates a
target matrix.</p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#recommendation_system"><strong>recommendation systems</strong></a>, the target matrix
often holds users' ratings on <a href="https://developers.google.com/machine-learning/glossary#items"><strong>items</strong></a>. For example, the target
matrix for a movie recommendation system might look something like the
following, where the positive integers are user ratings and 0
means that the user didn't rate the movie:</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr>
    <th>&nbsp;</th>
    <th>Casablanca</th>
    <th>The Philadelphia Story</th>
    <th>Black Panther</th>
    <th>Wonder Woman</th>
    <th>Pulp Fiction</th>
  </tr>

  <tr>
    <td>User 1</td>
    <td>5.0</td>
    <td>3.0</td>
    <td>0.0</td>
    <td>2.0</td>
    <td>0.0</td>
  </tr>
  <tr>
    <td>User 2</td>
    <td>4.0</td>
    <td>0.0</td>
    <td>0.0</td>
    <td>1.0</td>
    <td>5.0</td>
  </tr>
  <tr>
    <td>User 3</td>
    <td>3.0</td>
    <td>1.0</td>
    <td>4.0</td>
    <td>5.0</td>
    <td>0.0</td>
  </tr>
</tbody></table></div>

<p>The movie recommendation system aims to predict user ratings for
unrated movies.  For example, will User 1 like <em>Black Panther</em>?</p>

<p>One approach for recommendation systems is to use matrix
factorization to generate the following two matrices:</p>

<ul>
<li>A <a href="https://developers.google.com/machine-learning/glossary#user_matrix"><strong>user matrix</strong></a>, shaped as the number of users X the
number of embedding dimensions.</li>
<li>An <a href="https://developers.google.com/machine-learning/glossary#item_matrix"><strong>item matrix</strong></a>, shaped as the number of embedding
dimensions X the number of items.</li>
</ul>

<p>For example, using matrix factorization on our three users and five items
could yield the following user matrix and item matrix:</p>

<devsite-code data-copy-event-label=""><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="typ">User</span><span class="pln"> </span><span class="typ">Matrix</span><span class="pln"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="typ">Item</span><span class="pln"> </span><span class="typ">Matrix</span><span class="pln"><br><br></span><span class="lit">1.1</span><span class="pln"> &nbsp; </span><span class="lit">2.3</span><span class="pln"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="lit">0.9</span><span class="pln"> &nbsp; </span><span class="lit">0.2</span><span class="pln"> &nbsp; </span><span class="lit">1.4</span><span class="pln"> &nbsp; &nbsp;</span><span class="lit">2.0</span><span class="pln"> &nbsp; </span><span class="lit">1.2</span><span class="pln"><br></span><span class="lit">0.6</span><span class="pln"> &nbsp; </span><span class="lit">2.0</span><span class="pln"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="lit">1.7</span><span class="pln"> &nbsp; </span><span class="lit">1.2</span><span class="pln"> &nbsp; </span><span class="lit">1.2</span><span class="pln"> &nbsp; </span><span class="pun">-</span><span class="lit">0.1</span><span class="pln"> &nbsp; </span><span class="lit">2.1</span><span class="pln"><br></span><span class="lit">2.5</span><span class="pln"> &nbsp; </span><span class="lit">0.5</span><span class="pln"><br></span></pre></devsite-code>

<p>The dot product of the user matrix and item matrix yields a recommendation
matrix that contains not only the original user ratings but also predictions
for the movies that each user hasn't seen.
For example, consider User 1's rating of <em>Casablanca</em>, which was 5.0. The dot
product corresponding to that cell in the recommendation matrix should
hopefully be around 5.0, and it is:</p>

<devsite-code no-copy="" data-copy-event-label=""><pre translate="no" dir="ltr" is-upgraded="">(1.1 * 0.9) + (2.3 * 1.7) = 4.9
</pre></devsite-code>

<p>More importantly, will User 1 like <em>Black Panther</em>? Taking the dot product
corresponding to the first row and the third column yields a predicted
rating of 4.3:</p>

<devsite-code no-copy="" data-copy-event-label=""><pre translate="no" dir="ltr" is-upgraded="">(1.1 * 1.4) + (2.3 * 1.2) = 4.3
</pre></devsite-code>

<p>Matrix factorization typically yields a user matrix and item matrix that,
together, are significantly more compact than the target matrix.</p>

<p><a class="glossary-anchor" name="MAE"></a>
</p><h2 class="hide-from-toc" id="mean-absolute-error-mae" data-text=" Mean Absolute Error (MAE)"> Mean Absolute Error (MAE)</h2><p></p>

<p>The average loss per example when <a href="https://developers.google.com/machine-learning/glossary#L1_loss"><strong>L<sub>1</sub> loss</strong></a> is
used.  Calculate Mean Absolute Error as follows:</p>

<ol>
<li>Calculate the L<sub>1</sub> loss for a batch.</li>
<li>Divide the L<sub>1</sub> loss by the number of examples in the batch.</li>
</ol>

<devsite-expandable is-upgraded="" id="expandable-23"><a class="exw-control" aria-controls="expandable-23" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-to-see-the-formal-math._2" data-text=" Click the icon to see the formal math. " role="presentation"><span class="devsite-heading" role="heading" aria-level="4">
Click the icon to see the formal math.<wbr>
</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: 
Click the icon to see the formal math.
" data-title="Copy link to this section: 
Click the icon to see the formal math.
" data-id="click-the-icon-to-see-the-formal-math._2"></button></h4></a>



<div class="expand-background">

<p>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-42-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Mean Absolute Error&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mfrac&gt;&lt;munderover&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/munderover&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x005E;&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="38.884ex" height="6.755ex" viewBox="0 -1632.5 16741.6 2908.3" role="img" focusable="false" aria-hidden="true" style="vertical-align: -2.963ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-4D"></use><use href="#MJMAIN-65" x="917" y="0"></use><use href="#MJMAIN-61" x="1362" y="0"></use><use href="#MJMAIN-6E" x="1862" y="0"></use><use href="#MJMAIN-41" x="2669" y="0"></use><use href="#MJMAIN-62" x="3419" y="0"></use><use href="#MJMAIN-73" x="3976" y="0"></use><use href="#MJMAIN-6F" x="4370" y="0"></use><use href="#MJMAIN-6C" x="4871" y="0"></use><use href="#MJMAIN-75" x="5149" y="0"></use><use href="#MJMAIN-74" x="5706" y="0"></use><use href="#MJMAIN-65" x="6095" y="0"></use><use href="#MJMAIN-45" x="6790" y="0"></use><use href="#MJMAIN-72" x="7471" y="0"></use><use href="#MJMAIN-72" x="7864" y="0"></use><use href="#MJMAIN-6F" x="8256" y="0"></use><use href="#MJMAIN-72" x="8757" y="0"></use><use href="#MJMAIN-3D" x="9427" y="0"></use><g transform="translate(10205,0)"><g transform="translate(397,0)"><rect stroke="none" width="720" height="60" x="0" y="220"></rect><use href="#MJMAIN-31" x="110" y="676"></use><use href="#MJMATHI-6E" x="60" y="-686"></use></g></g><g transform="translate(11610,0)"><use href="#MJSZ2-2211" x="0" y="0"></use><g transform="translate(147,-1090)"><use transform="scale(0.707)" href="#MJMATHI-69" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-3D" x="345" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-30" x="1124" y="0"></use></g><use transform="scale(0.707)" href="#MJMATHI-6E" x="721" y="1627"></use></g><use href="#MJMAIN-7C" x="13221" y="0"></use><g transform="translate(13500,0)"><use href="#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-69" x="693" y="-213"></use></g><use href="#MJMAIN-2212" x="14557" y="0"></use><g transform="translate(15558,0)"><use href="#MJMATHI-79" x="1" y="0"></use><use href="#MJMAIN-5E" x="60" y="-10"></use><use transform="scale(0.707)" href="#MJMATHI-69" x="792" y="-342"></use></g><use href="#MJMAIN-7C" x="16463" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Mean Absolute Error</mtext><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mrow class="MJX-TeXAtom-ORD"><mover><mi>y</mi><mo stretchy="false">^</mo></mover></mrow><mi>i</mi></msub><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-42">\text{Mean Absolute Error} = \frac{1}{n}\sum_{i=0}^n | y_i - \hat{y}_i |</script>

where:

</p><ul>
  <li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-43-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.395ex" height="1.429ex" viewBox="0 -511.5 600.5 615.4" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.241ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-6E" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-43">n</script> is the number of examples.</li>
  <li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-44-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.155ex" height="1.903ex" viewBox="0 -511.5 497.5 819.3" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi></math></span></span><script type="math/tex" id="MathJax-Element-44">y</script> is the actual value of the label.</li>
  <li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-45-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x005E;&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.302ex" height="2.494ex" viewBox="0 -766.3 560.7 1074" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="1" y="0"></use><use href="#MJMAIN-5E" x="60" y="-10"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><mover><mi>y</mi><mo stretchy="false">^</mo></mover></mrow></math></span></span><script type="math/tex" id="MathJax-Element-45">\hat{y}</script> is the value that the model predicts for <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-46-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.155ex" height="1.903ex" viewBox="0 -511.5 497.5 819.3" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi></math></span></span><script type="math/tex" id="MathJax-Element-46">y</script>.</li>
</ul>

</div>

<hr>
</devsite-expandable>

<p>For example, consider the calculation of L<sub>1</sub> loss on the
following batch of five examples:</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr><th>Actual value of example</th> <th>Model's predicted value</th>
      <th>Loss (difference between actual and predicted)</th></tr>
  <tr><td>7</td> <td>6</td> <td>1</td> </tr>
  <tr><td>5</td> <td>4</td> <td>1</td> </tr>
  <tr><td>8</td> <td>11</td> <td>3</td> </tr>
  <tr><td>4</td> <td>6</td> <td>2</td> </tr>
  <tr><td>9</td> <td>8</td> <td>1</td> </tr>
  <tr><th colspan="2">&nbsp;</th>  <th>8 = L<sub>1</sub> loss</th> </tr>
</tbody></table></div>

<p>So, L<sub>1</sub> loss is 8 and the number of examples is 5.
Therefore, the Mean Absolute Error is:</p>

<devsite-code no-copy="" data-copy-event-label=""><div class="devsite-code-buttons-container" role="group" aria-label="Action buttons"><button type="button" class="gc-analytics-event material-icons devsite-icon-code-dark devsite-toggle-dark" data-category="Site-Wide Custom Events" data-label="Dark Code Toggle" track-type="exampleCode" track-name="darkCodeToggle" aria-label="Dark code theme" data-title="Dark code theme"></button><button type="button" class="gc-analytics-event material-icons devsite-icon-code-light devsite-toggle-light" data-category="Site-Wide Custom Events" data-label="Light Code Toggle" track-type="exampleCode" track-name="lightCodeToggle" aria-label="Light code theme" data-title="Light code theme"></button></div><pre translate="no" dir="ltr" is-upgraded="">Mean Absolute Error = L<sub>1</sub> loss / Number of Examples
Mean Absolute Error = 8/5 = 1.6
</pre></devsite-code>

<p>Contrast Mean Absolute Error with <a href="https://developers.google.com/machine-learning/glossary#MSE"><strong>Mean Squared Error</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#RMSE"><strong>Root Mean Squared Error</strong></a>.</p>

<p><a class="glossary-anchor" name="MSE"></a>
</p><h2 class="hide-from-toc" id="mean-squared-error-mse" data-text=" Mean Squared Error (MSE)" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> Mean Squared Error (MSE)</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  Mean Squared Error (MSE)" data-title="Copy link to this section:  Mean Squared Error (MSE)" data-id="mean-squared-error-mse"></button></h2><p></p>

<p>The average loss per example when <a href="https://developers.google.com/machine-learning/glossary#L2_loss"><strong>L<sub>2</sub> loss</strong></a> is
used. Calculate Mean Squared Error as follows:</p>

<ol>
<li>Calculate the L<sub>2</sub> loss for a batch.</li>
<li>Divide the L<sub>2</sub> loss by the number of examples in the batch.</li>
</ol>

<devsite-expandable is-upgraded="" id="expandable-24"><a class="exw-control" aria-controls="expandable-24" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-to-see-the-formal-math._3" data-text=" Click the icon to see the formal math. " role="presentation"><span class="devsite-heading" role="heading" aria-level="4">
Click the icon to see the formal math.<wbr>
</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: 
Click the icon to see the formal math.
" data-title="Copy link to this section: 
Click the icon to see the formal math.
" data-id="click-the-icon-to-see-the-formal-math._3"></button></h4></a>



<div class="expand-background">

<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-47-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Mean Squared Error&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mfrac&gt;&lt;munderover&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/munderover&gt;&lt;msup&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x005E;&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="39.675ex" height="6.755ex" viewBox="0 -1632.5 17082 2908.3" role="img" focusable="false" aria-hidden="true" style="vertical-align: -2.963ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-4D"></use><use href="#MJMAIN-65" x="917" y="0"></use><use href="#MJMAIN-61" x="1362" y="0"></use><use href="#MJMAIN-6E" x="1862" y="0"></use><use href="#MJMAIN-53" x="2669" y="0"></use><use href="#MJMAIN-71" x="3225" y="0"></use><use href="#MJMAIN-75" x="3754" y="0"></use><use href="#MJMAIN-61" x="4310" y="0"></use><use href="#MJMAIN-72" x="4811" y="0"></use><use href="#MJMAIN-65" x="5203" y="0"></use><use href="#MJMAIN-64" x="5648" y="0"></use><use href="#MJMAIN-45" x="6454" y="0"></use><use href="#MJMAIN-72" x="7136" y="0"></use><use href="#MJMAIN-72" x="7528" y="0"></use><use href="#MJMAIN-6F" x="7921" y="0"></use><use href="#MJMAIN-72" x="8421" y="0"></use><use href="#MJMAIN-3D" x="9091" y="0"></use><g transform="translate(9870,0)"><g transform="translate(397,0)"><rect stroke="none" width="720" height="60" x="0" y="220"></rect><use href="#MJMAIN-31" x="110" y="676"></use><use href="#MJMATHI-6E" x="60" y="-686"></use></g></g><g transform="translate(11275,0)"><use href="#MJSZ2-2211" x="0" y="0"></use><g transform="translate(147,-1090)"><use transform="scale(0.707)" href="#MJMATHI-69" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-3D" x="345" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-30" x="1124" y="0"></use></g><use transform="scale(0.707)" href="#MJMATHI-6E" x="721" y="1627"></use></g><g transform="translate(12886,0)"><use href="#MJMAIN-28" x="0" y="0"></use><g transform="translate(389,0)"><use href="#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-69" x="693" y="-213"></use></g><use href="#MJMAIN-2212" x="1446" y="0"></use><g transform="translate(2447,0)"><use href="#MJMATHI-79" x="1" y="0"></use><use href="#MJMAIN-5E" x="60" y="-10"></use><use transform="scale(0.707)" href="#MJMATHI-69" x="792" y="-342"></use></g><use href="#MJMAIN-29" x="3352" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="5291" y="675"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Mean Squared Error</mtext><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><msup><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mrow class="MJX-TeXAtom-ORD"><mover><mi>y</mi><mo stretchy="false">^</mo></mover></mrow><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mn>2</mn></msup></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-47">\text{Mean Squared Error} = \frac{1}{n}\sum_{i=0}^n {(y_i - \hat{y}_i)}^2</script>

where:

<ul>
  <li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-48-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.395ex" height="1.429ex" viewBox="0 -511.5 600.5 615.4" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.241ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-6E" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-48">n</script> is the number of examples.</li>
  <li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-49-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.155ex" height="1.903ex" viewBox="0 -511.5 497.5 819.3" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi></math></span></span><script type="math/tex" id="MathJax-Element-49">y</script> is the actual value of the label.</li>
  <li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-50-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mover&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x005E;&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.302ex" height="2.494ex" viewBox="0 -766.3 560.7 1074" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="1" y="0"></use><use href="#MJMAIN-5E" x="60" y="-10"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><mover><mi>y</mi><mo stretchy="false">^</mo></mover></mrow></math></span></span><script type="math/tex" id="MathJax-Element-50">\hat{y}</script> is the model's prediction for <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-51-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.155ex" height="1.903ex" viewBox="0 -511.5 497.5 819.3" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi></math></span></span><script type="math/tex" id="MathJax-Element-51">y</script>.</li>
</ul>
</div>

<hr>
</devsite-expandable>

<p>For example, consider the loss on the following batch of five examples:</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr><th>Actual value</th> <th>Model's prediction</th>
      <th>Loss</th> <th>Squared loss</th></tr>
  <tr><td>7</td> <td>6</td>  <td>1</td> <td>1</td></tr>
  <tr><td>5</td> <td>4</td>  <td>1</td> <td>1</td></tr>
  <tr><td>8</td> <td>11</td> <td>3</td> <td>9</td></tr>
  <tr><td>4</td> <td>6</td>  <td>2</td> <td>4</td></tr>
  <tr><td>9</td> <td>8</td>  <td>1</td> <td>1</td></tr>
  <tr><th colspan="3"> </th> <th>16 = L<sub>2</sub> loss</th></tr>
</tbody></table></div>

<p>Therefore, the Mean Squared Error is:</p>

<devsite-code no-copy="" data-copy-event-label=""><pre translate="no" dir="ltr" is-upgraded="">Mean Squared Error = L<sub>2</sub> loss / Number of Examples
Mean Squared Error = 16/5 = 3.2
</pre></devsite-code>

<p>Mean Squared Error is a popular training <a href="https://developers.google.com/machine-learning/glossary#optimizer"><strong>optimizer</strong></a>,
particularly for <a href="https://developers.google.com/machine-learning/glossary#linear_regression"><strong>linear regression</strong></a>.</p>

<p>Contrast Mean Squared Error with
<a href="https://developers.google.com/machine-learning/glossary#MAE"><strong>Mean Absolute Error</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#RMSE"><strong>Root Mean Squared Error</strong></a>.</p>

<p><a href="https://developers.google.com/machine-learning/glossary#TensorFlow_Playground"><strong>TensorFlow Playground</strong></a> uses Mean Squared Error
to calculate loss values.</p>

<devsite-expandable is-upgraded="" id="expandable-25"><a class="exw-control" aria-controls="expandable-25" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-to-see-more-details-about-outliers." data-text=" Click the icon to see more details about outliers. ">
Click the icon to see more details about outliers.<wbr>
</h4></a>



<div class="expand-background">

<p>
<a href="https://developers.google.com/machine-learning/glossary#outliers"><b>Outliers</b></a> strongly influence Mean Squared Error.
For example, a loss of 1 is a squared loss of 1, but a loss of 3 is a
squared loss of 9. In the preceding table, the example with a loss of 3
accounts for ~56% of the Mean Squared Error, while each of the examples
with a loss of 1 accounts for only 6% of the Mean Squared Error.
</p>

<p>Outliers do not influence Mean Absolute Error as strongly as
Mean Squared Error. For example, a loss of 3 accounts for only ~38% of the
Mean Absolute Error.</p>

<p><a href="https://developers.google.com/machine-learning/glossary#clipping"><b>Clipping</b></a> is one way to prevent extreme
outliers from damaging your model's predictive ability.</p>

</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="metric"></a>
</p><h2 class="hide-from-toc" id="metric" data-text=" metric"> metric</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>A statistic that you care about.</p>

<p>An <a href="https://developers.google.com/machine-learning/glossary#objective"><strong>objective</strong></a> is a metric that a machine learning system
tries to optimize.</p>

<p><a class="glossary-anchor" name="meta-learning"></a>
</p><h2 class="hide-from-toc" id="meta-learning" data-text=" meta-learning"> meta-learning</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A subset of machine learning that discovers or improves a learning algorithm.
A meta-learning system can also aim to train a model to quickly learn a new
task from a small amount of data or from experience gained in previous tasks.
Meta-learning algorithms generally try to achieve the following:</p>

<ul>
<li>Improve/learn hand-engineered features (such as an initializer or
an optimizer).</li>
<li>Be more data-efficient and compute-efficient.</li>
<li>Improve generalization.</li>
</ul>

<p>Meta-learning is related to <a href="https://developers.google.com/machine-learning/glossary#few-shot_learning"><strong>few-shot learning</strong></a>.</p>

<p><a class="glossary-anchor" name="metrics_API"></a>
</p><h2 class="hide-from-toc" id="metrics-api-tf.metrics" data-text=" Metrics API (tf.metrics)"> Metrics API (tf.metrics)</h2><p></p>

<p>A TensorFlow API for evaluating models. For example, <code translate="no" dir="ltr">tf.metrics.accuracy</code>
determines how often a model's predictions match labels.</p>

<p><a class="glossary-anchor" name="mini-batch"></a>
</p><h2 class="hide-from-toc" id="mini-batch" data-text=" mini-batch"> mini-batch</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A small, randomly selected subset of a <a href="https://developers.google.com/machine-learning/glossary#batch"><strong>batch</strong></a> processed in one
<a href="https://developers.google.com/machine-learning/glossary#iteration"><strong>iteration</strong></a>.
The <a href="https://developers.google.com/machine-learning/glossary#batch_size"><strong>batch size</strong></a> of a mini-batch is usually
between 10 and 1,000 examples.</p>

<p>For example, suppose the entire training set (the full batch)
consists of 1,000 examples.  Further suppose that you set the
<a href="https://developers.google.com/machine-learning/glossary#batch_size"><strong>batch size</strong></a> of each mini-batch to 20.  Therefore, each
iteration determines the loss on a random 20 of the 1,000 examples and then
adjusts the <a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weights</strong></a> and <a href="https://developers.google.com/machine-learning/glossary#bias"><strong>biases</strong></a> accordingly.</p>

<p>It is much more efficient to calculate the loss on a mini-batch than the
loss on all the examples in the full batch.</p>

<p><a class="glossary-anchor" name="mini-batch_SGD"></a>
</p><h2 class="hide-from-toc" id="mini-batch-stochastic-gradient-descent" data-text=" mini-batch stochastic gradient descent"> mini-batch stochastic gradient descent</h2><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#gradient_descent"><strong>gradient descent</strong></a> algorithm that uses
<a href="https://developers.google.com/machine-learning/glossary#mini-batch"><strong>mini-batches</strong></a>. In other words, mini-batch stochastic
gradient descent estimates the gradient based on a small subset of the
training data. Regular <a href="https://developers.google.com/machine-learning/glossary#SGD"><strong>stochastic gradient descent</strong></a> uses a
mini-batch of size 1.</p>

<p><a class="glossary-anchor" name="minimax_loss"></a>
</p><h2 class="hide-from-toc" id="minimax-loss" data-text=" minimax loss"> minimax loss</h2><p></p>

<p>A loss function for
<a href="https://developers.google.com/machine-learning/glossary#generative_adversarial_network"><strong>generative adversarial networks</strong></a>,
based on the <a href="https://developers.google.com/machine-learning/glossary#cross-entropy"><strong>cross-entropy</strong></a> between the distribution
of generated data and real data.</p>

<p>Minimax loss is used in the
<a href="https://arxiv.org/pdf/1406.2661.pdf">first paper</a> to describe
generative adversarial networks.</p>



<p><a class="glossary-anchor" name="minority_class"></a>
</p><h2 class="hide-from-toc" id="minority-class" data-text=" minority class"> minority class</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The less common label in a
<a href="https://developers.google.com/machine-learning/glossary#class_imbalanced_data_set"><strong>class-imbalanced dataset</strong></a>. For example,
given a dataset containing 99% negative labels and 1% positive labels, the
positive labels are the minority class.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#majority_class"><strong>majority class</strong></a>.</p>

<devsite-expandable is-upgraded="" id="expandable-26"><a class="exw-control" aria-controls="expandable-26" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-additional-notes._10" data-text=" Click the icon for additional notes. ">
Click the icon for additional notes.
</h4></a>



<div class="expand-background">
<p>
A training set with a million <a href="https://developers.google.com/machine-learning/glossary#example">examples</a> sounds
impressive. However, if the minority class is poorly represented,
then even a very large training set might be insufficient. Focus less
on the total number of examples in the dataset and more on the number of
examples in the minority class.
</p>

<p>
If your dataset doesn't contain enough minority class examples, consider
using <a href="https://developers.google.com/machine-learning/glossary#downsampling"><b>downsampling</b></a> (the definition
in the second bullet) to supplement the minority class.
</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="ML"></a>
</p><h2 class="hide-from-toc" id="ml" data-text=" ML"> ML</h2><p></p>

<p>Abbreviation for <a href="https://developers.google.com/machine-learning/glossary#machine_learning"><strong>machine learning</strong></a>.</p>

<p><a class="glossary-anchor" name="MNIST"></a>
</p><h2 class="hide-from-toc" id="mnist" data-text=" MNIST"> MNIST</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>A public-domain dataset compiled by LeCun, Cortes, and Burges containing
60,000 images, each image showing how a human manually wrote a particular
digit from 0–9.  Each image is stored as a 28x28 array of integers, where
each integer is a grayscale value between 0 and 255, inclusive.</p>

<p>MNIST is a canonical dataset for machine learning, often used to test new
machine learning approaches. For details, see
<a href="http://yann.lecun.com/exdb/mnist/" target="T">
The MNIST Database of Handwritten Digits</a>.</p>

<p><a class="glossary-anchor" name="modality"></a>
</p><h2 class="hide-from-toc" id="modality" data-text=" modality"> modality</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A high-level data category. For example, numbers, text, images, video, and
audio are five different modalities.</p>

<p><a class="glossary-anchor" name="model"></a>
</p><h2 class="hide-from-toc" id="model" data-text=" model"> model</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>In general, any mathematical construct that processes input data and returns
output. Phrased differently, a model is the set of parameters and structure
needed for a system to make predictions.
In <a href="https://developers.google.com/machine-learning/glossary#supervised_machine_learning"><strong>supervised machine learning</strong></a>,
a model takes an <a href="https://developers.google.com/machine-learning/glossary#example"><strong>example</strong></a> as input and infers a
<a href="https://developers.google.com/machine-learning/glossary#prediction"><strong>prediction</strong></a> as output. Within supervised machine learning,
models differ somewhat. For example:</p>

<ul>
<li>A linear regression model consists of a set of <a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weights</strong></a>
and a <a href="https://developers.google.com/machine-learning/glossary#bias"><strong>bias</strong></a>.</li>
<li>A <a href="https://developers.google.com/machine-learning/glossary#neural-network"><strong>neural network</strong></a> model consists of:
<ul>
<li>A set of <a href="https://developers.google.com/machine-learning/glossary#hidden_layer"><strong>hidden layers</strong></a>, each containing one or
more <a href="https://developers.google.com/machine-learning/glossary#neuron"><strong>neurons</strong></a>.</li>
<li>The weights and bias associated with each neuron.</li>
</ul></li>
<li>A <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a> model consists of:
<ul>
<li>The shape of the tree; that is, the pattern in which the conditions
and leaves are connected.</li>
<li>The conditions and leaves.</li>
</ul></li>
</ul>

<p>You can save, restore, or make copies of a model.</p>

<p><a href="https://developers.google.com/machine-learning/glossary#unsupervised_machine_learning"><strong>Unsupervised machine learning</strong></a> also
generates models, typically a function that can map an input example to
the most appropriate <a href="https://developers.google.com/machine-learning/glossary#clustering"><strong>cluster</strong></a>.</p>

<devsite-expandable is-upgraded="" id="expandable-27"><a class="exw-control" aria-controls="expandable-27" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-to-compare-algebraic-and-programming-functions-to-ml-models." data-text=" Click the icon to compare algebraic and programming functions to ML models. ">
Click the icon to compare algebraic and programming functions to ML models.
</h4></a>



<div class="expand-background">
<p>An algebraic function such as the following is a model:</p>

<devsite-code no-copy="" data-copy-event-label=""><pre translate="no" dir="ltr" is-upgraded="">  f(x, y) = 3x -5xy + y<sup>2</sup> + 17
</pre></devsite-code>

<p>The preceding function maps input values (<tt>x</tt> and <tt>y</tt>) to
output.</p>

<p>Similarly, a programming function like the following is also a model:</p>

<devsite-code data-copy-event-label=""><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="kwd">def</span><span class="pln"> half_of_greater</span><span class="pun">(</span><span class="pln">x</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">):</span><span class="pln"><br>&nbsp; </span><span class="kwd">if</span><span class="pln"> </span><span class="pun">(</span><span class="pln">x </span><span class="pun">&gt;</span><span class="pln"> y</span><span class="pun">):</span><span class="pln"><br>&nbsp; &nbsp; </span><span class="kwd">return</span><span class="pun">(</span><span class="pln">x </span><span class="pun">/</span><span class="pln"> </span><span class="lit">2</span><span class="pun">)</span><span class="pln"><br>&nbsp; </span><span class="kwd">else</span><span class="pln"><br>&nbsp; &nbsp; </span><span class="kwd">return</span><span class="pun">(</span><span class="pln">y </span><span class="pun">/</span><span class="pln"> </span><span class="lit">2</span><span class="pun">)</span><span class="pln"><br></span></pre></devsite-code>

<p>A caller passes arguments to the preceding Python function, and the
Python function generates output (via the <tt>return</tt> statement).</p>

<p>Although a <a href="https://developers.google.com/machine-learning/glossary#deep_neural_network"><b>deep neural network</b></a>
has a very different mathematical structure than an algebraic or programming
function, a deep neural network still takes input (an example) and returns
output (a prediction).</p>

<p>A human programmer codes a programming function manually. In contrast,
a machine learning model gradually learns the optimal parameters
during automated training.</p>

</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="model_capacity"></a>
</p><h2 class="hide-from-toc" id="model-capacity" data-text=" model capacity"> model capacity</h2><p></p>

<p>The complexity of problems that a model can learn. The more complex the
problems that a model can learn, the higher the model’s capacity. A model’s
capacity typically increases with the number of model parameters. For a
formal definition of classifier capacity, see
<a href="https://wikipedia.org/wiki/VC_dimension" target="T">VC dimension</a>.</p>

<p><a class="glossary-anchor" name="model-parallelism"></a>
</p><h2 class="hide-from-toc" id="model-parallelism" data-text=" model parallelism"> model parallelism</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A way of scaling training or inference that puts different parts of one model
on different devices. Model parallelism enables models that are too big to fit
on a single device.</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#data-parallelism"><strong>data parallelism</strong></a>.</p>

<p><a class="glossary-anchor" name="model_training"></a>
</p><h2 class="hide-from-toc" id="model-training" data-text=" model training"> model training</h2><p></p>

<p>The process of determining the best <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a>.</p>

<p><a class="glossary-anchor" name="Momentum"></a>
</p><h2 class="hide-from-toc" id="momentum" data-text=" Momentum"> Momentum</h2><p></p>

<p>A sophisticated gradient descent algorithm in which a learning step depends
not only on the derivative in the current step, but also on the derivatives
of the step(s) that immediately preceded it. Momentum involves computing an
exponentially weighted moving average of the gradients over time, analogous
to momentum in physics.  Momentum sometimes prevents learning from getting
stuck in local minima.</p>

<p><a class="glossary-anchor" name="multi-class"></a>
</p><h2 class="hide-from-toc" id="multi-class-classification" data-text=" multi-class classification"> multi-class classification</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>In supervised learning, a <a href="https://developers.google.com/machine-learning/glossary#classification_model"><strong>classification</strong></a> problem
in which the dataset contains <em>more than two</em> <a href="https://developers.google.com/machine-learning/glossary#class"><strong>classes</strong></a> of labels.
For example, the labels in the Iris dataset must be one of the following
three classes:</p>

<ul>
<li>Iris setosa</li>
<li>Iris virginica</li>
<li>Iris versicolor</li>
</ul>

<p>A model trained on the Iris dataset that predicts Iris type on new examples
is performing multi-class classification.</p>

<p>In contrast, classification problems that distinguish between exactly two
classes are <a href="https://developers.google.com/machine-learning/glossary#binary_classification"><strong>binary classification models</strong></a>.
For example, an email model that predicts either <em>spam</em> or <em>not spam</em>
is a binary classification model.</p>

<p>In clustering problems, multi-class classification refers to more than
two clusters.</p>

<p><a class="glossary-anchor" name="multi-class_logistic_regression"></a>
</p><h2 class="hide-from-toc" id="multi-class-logistic-regression" data-text=" multi-class logistic regression"> multi-class logistic regression</h2><p></p>

<p>Using <a href="https://developers.google.com/machine-learning/glossary#logistic_regression"><strong>logistic regression</strong></a> in
<a href="https://developers.google.com/machine-learning/glossary#multi-class"><strong>multi-class classification</strong></a> problems.</p>

<p><a class="glossary-anchor" name="multi-head-self-attention"></a>
</p><h2 class="hide-from-toc" id="multi-head-self-attention" data-text=" multi-head self-attention"> multi-head self-attention</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>An extension of <a href="https://developers.google.com/machine-learning/glossary#self-attention"><strong>self-attention</strong></a> that applies the
self-attention mechanism multiple times for each position in the input sequence.</p>

<p><a href="https://developers.google.com/machine-learning/glossary#Transformer"><strong>Transformers</strong></a> introduced multi-head self-attention.</p>

<p><a class="glossary-anchor" name="multimodal-model"></a>
</p><h2 class="hide-from-toc" id="multimodal-model" data-text=" multimodal model" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> multimodal model</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  multimodal model" data-title="Copy link to this section:  multimodal model" data-id="multimodal-model"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A model whose inputs and/or outputs include more than one
<a href="https://developers.google.com/machine-learning/glossary#modality"><strong>modality</strong></a>.  For example, consider a model that takes both an
image and a text caption (two modalities) as <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>features</strong></a>, and
outputs a score indicating how appropriate the text caption is for the image.
So, this model's inputs are multimodal and the output is unimodal.</p>

<p><a class="glossary-anchor" name="multinomial_classification"></a>
</p><h2 class="hide-from-toc" id="multinomial-classification" data-text=" multinomial classification" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> multinomial classification</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  multinomial classification" data-title="Copy link to this section:  multinomial classification" data-id="multinomial-classification"></button></h2><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#multi-class"><strong>multi-class classification</strong></a>.</p>

<p><a class="glossary-anchor" name="multinomial-regression"></a>
</p><h2 class="hide-from-toc" id="multinomial-regression" data-text=" multinomial regression" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> multinomial regression</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  multinomial regression" data-title="Copy link to this section:  multinomial regression" data-id="multinomial-regression"></button></h2><p></p>

<p>Synonym for
<a href="https://developers.google.com/machine-learning/glossary#multi-class_logistic_regression"><strong>multi-class logistic regression</strong></a>.</p>



<p><a class="glossary-anchor" name="n"></a>
</p><h2 class="glossary" id="n" data-text="N" role="presentation"><span class="devsite-heading" role="heading" aria-level="2">N</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: N" data-title="Copy link to this section: N" data-id="n"></button></h2><p></p>

<p><a class="glossary-anchor" name="NaN_trap"></a>
</p><h2 class="hide-from-toc" id="nan-trap" data-text=" NaN trap" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> NaN trap</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  NaN trap" data-title="Copy link to this section:  NaN trap" data-id="nan-trap"></button></h2><p></p>

<p>When one number in your model becomes a
<a href="https://wikipedia.org/wiki/NaN" target="T">NaN</a>
during training, which causes
many or all other numbers in your model to eventually become a NaN.</p>

<p>NaN is an abbreviation for <b>N</b>ot <b>a</b> <b>N</b>umber.</p>

<p><a class="glossary-anchor" name="natural_language_understanding"></a>
</p><h2 class="hide-from-toc" id="natural-language-understanding" data-text=" natural language understanding"> natural language understanding</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>Determining a user's intentions based on what the user typed or said.
For example, a search engine uses natural language understanding to
determine what the user is searching for based on what the user typed or said.</p>

<p><a class="glossary-anchor" name="negative_class"></a>
</p><h2 class="hide-from-toc" id="negative-class" data-text=" negative class"> negative class</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#binary_classification"><strong>binary classification</strong></a>, one class is
termed <em>positive</em> and the other is termed <em>negative</em>. The positive class is
the thing or event that the model is testing for and the negative class is the
other possibility. For example:</p>

<ul>
<li>The negative class in a medical test might be "not tumor."</li>
<li>The negative class in an email classifier might be "not spam."</li>
</ul>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#positive_class"><strong>positive class</strong></a>.</p>

<p><a class="glossary-anchor" name="neural_network"></a>
<a class="glossary-anchor" name="neural-network"></a>
</p><h2 class="hide-from-toc" id="neural-network" data-text=" neural network"> neural network</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> containing at least one
<a href="https://developers.google.com/machine-learning/glossary#hidden_layer"><strong>hidden layer</strong></a>.
A <a href="https://developers.google.com/machine-learning/glossary#deep_neural_network"><strong>deep neural network</strong></a> is a type of neural network
containing more than one hidden layer. For example, the following diagram
shows a deep neural network containing two hidden layers.</p>

<p>
<img src="./ML_Glossary_files/NeuralNetwork.png" loading="lazy" alt="A neural network with an input layer, two hidden layers, and an
          output layer.">
</p>

<p>Each neuron in a neural network connects to all of the nodes in the next layer.
For example, in the preceding diagram, notice that each of the three neurons
in the first hidden layer separately connect to both of the two neurons in the
second hidden layer.</p>

<p>Neural networks implemented on computers are sometimes called
<strong>artificial neural networks</strong> to differentiate them from
neural networks found in brains and other nervous systems.</p>

<p>Some neural networks can mimic extremely complex nonlinear relationships
between different features and the label.</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#convolutional_neural_network"><strong>convolutional neural network</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#recurrent_neural_network"><strong>recurrent neural network</strong></a>.</p>

<p><a class="glossary-anchor" name="neuron"></a>
</p><h2 class="hide-from-toc" id="neuron" data-text=" neuron"> neuron</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>In machine learning, a distinct unit within a <a href="https://developers.google.com/machine-learning/glossary#hidden_layer"><strong>hidden layer</strong></a>
of a <a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural network</strong></a>.  Each neuron performs the following
two-step action:</p>

<ol>
<li>Calculates the <a href="https://developers.google.com/machine-learning/glossary#weighted_sum"><strong>weighted sum</strong></a> of input values multiplied
by their corresponding weights.</li>
<li>Passes the weighted sum as input to an
<a href="https://developers.google.com/machine-learning/glossary#activation_function"><strong>activation function</strong></a>.</li>
</ol>

<p>A neuron in the first hidden layer accepts inputs from the feature values
in the <a href="https://developers.google.com/machine-learning/glossary#input_layer"><strong>input layer</strong></a>. A neuron in any hidden layer beyond
the first accepts inputs from the neurons in the preceding hidden layer.
For example, a neuron in the second hidden layer accepts inputs from the
neurons in the first hidden layer.</p>

<p>The following illustration highlights two neurons and their
inputs.</p>

<p>
<img src="./ML_Glossary_files/Neurons.png" loading="lazy" alt="A neural network with an input layer, two hidden layers, and an
          output layer. Two neurons are highlighted: one in the first
          hidden layer and one in the second hidden layer. The highlighted
          neuron in the first hidden layer receives inputs from both features
          in the input layer. The highlighted neuron in the second hidden layer
          receives inputs from each of the three neurons in the first hidden
          layer.">
</p>

<p>A neuron in a neural network mimics the behavior of neurons in brains and
other parts of nervous systems.</p>

<p><a class="glossary-anchor" name="N-gram"></a>
</p><h2 class="hide-from-toc" id="n-gram" data-text=" N-gram"> N-gram</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Sequence Models">#seq</div>
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>An ordered sequence of N words.  For example, <em>truly madly</em> is a 2-gram. Because
order is relevant, <em>madly truly</em> is a different 2-gram than <em>truly madly</em>.</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr>
    <th>N</th>
    <th>Name(s) for this kind of N-gram</th>
    <th>Examples</th>
  </tr>
  <tr>
    <td>2 </td>
    <td>bigram or 2-gram </td>
    <td><em>to go, go to, eat lunch, eat dinner</em> </td>
  </tr>
  <tr>
    <td>3 </td>
    <td>trigram or 3-gram </td>
    <td><em>ate too much, three blind mice, the bell tolls</em> </td>
  </tr>
  <tr>
    <td>4 </td>
    <td>4-gram </td>
    <td><em>walk in the park, dust in the wind, the boy ate lentils</em> </td>
  </tr>
</tbody></table></div>

<p>Many <a href="https://developers.google.com/machine-learning/glossary#natural_language_understanding"><strong>natural language understanding</strong></a>
models rely on N-grams to predict the next word that the user will type
or say. For example, suppose a user typed <em>three blind</em>.
An NLU model based on trigrams would likely predict that the
user will next type <em>mice</em>.</p>

<p>Contrast N-grams with <a href="https://developers.google.com/machine-learning/glossary#bag_of_words"><strong>bag of words</strong></a>, which are
unordered sets of words.</p>

<p><a class="glossary-anchor" name="NLU"></a>
</p><h2 class="hide-from-toc" id="nlu" data-text=" NLU"> NLU</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>Abbreviation for <a href="https://developers.google.com/machine-learning/glossary#natural_language_understanding"><strong>natural language
understanding</strong></a>.</p>

<p><a class="glossary-anchor" name="node"></a>
</p><h2 class="hide-from-toc" id="node-neural-network" data-text=" node (neural network)"> node (neural network)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#neuron"><strong>neuron</strong></a> in a <a href="https://developers.google.com/machine-learning/glossary#hidden_layer"><strong>hidden layer</strong></a>.</p>

<p><a class="glossary-anchor" name="node_graph"></a>
</p><h2 class="hide-from-toc" id="node-tensorflow-graph" data-text=" node (TensorFlow graph)"> node (TensorFlow graph)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>An operation in a TensorFlow <a href="https://developers.google.com/machine-learning/glossary#graph"><strong>graph</strong></a>.</p>

<p><a class="glossary-anchor" name="node-decision-tree"></a>
</p><h2 class="hide-from-toc" id="node-decision-tree" data-text=" node (decision tree) "> node (decision tree) </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>In a <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a>, any
<a href="https://developers.google.com/machine-learning/glossary#condition"><strong>condition</strong></a> or <a href="https://developers.google.com/machine-learning/glossary#leaf"><strong>leaf</strong></a>.</p>

<p>
<img src="./ML_Glossary_files/node.png" loading="lazy" height="300" width="605" alt="A decision tree with two conditions and three leaves.">
</p>

<p><a class="glossary-anchor" name="noise"></a>
</p><h2 class="hide-from-toc" id="noise" data-text=" noise" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> noise</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  noise" data-title="Copy link to this section:  noise" data-id="noise"></button></h2><p></p>

<p>Broadly speaking, anything that obscures the signal in a dataset. Noise
can be introduced into data in a variety of ways. For example:</p>

<ul>
<li>Human raters make mistakes in labeling.</li>
<li>Humans and instruments mis-record or omit feature values.</li>
</ul>

<p><a class="glossary-anchor" name="non-binary-condition"></a>
</p><h2 class="hide-from-toc" id="non-binary-condition" data-text=" non-binary condition " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> non-binary condition </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  non-binary condition " data-title="Copy link to this section:  non-binary condition " data-id="non-binary-condition"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#condition"><strong>condition</strong></a> containing more than two possible outcomes.
For example, the following non-binary condition contains three possible
outcomes:</p>

<p>
<img src="./ML_Glossary_files/non-binary-conditions.png" loading="lazy" width="400" height="210" alt="A condition (number_of_legs = ?) that leads to three possible
          outcomes. One outcome (number_of_legs = 8) leads to a leaf
          named spider. A second outcome (number_of_legs = 4) leads to
          a leaf named dog. A third outcome (number_of_legs = 2) leads to
          a leaf named penguin.">
</p>

<p><a class="glossary-anchor" name="nonlinear"></a>
</p><h2 class="hide-from-toc" id="nonlinear" data-text=" nonlinear " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> nonlinear </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  nonlinear " data-title="Copy link to this section:  nonlinear " data-id="nonlinear"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A relationship between two or more variables that can't be represented solely
through addition and multiplication. A <em>linear</em> relationship
can be represented as a line; a <em>nonlinear</em> relationship can't be
represented as a line. For example, consider two models that each relate
a single feature to a single label. The model on the left is linear
and the model on the right is nonlinear:</p>

<p>
<img src="./ML_Glossary_files/LinearVsNonlinear.png" loading="lazy" alt="Two plots. One plot is a line, so this is a linear relationship.
          The other plot is a curve, so this is a nonlinear relationship.">
</p>

<p><a class="glossary-anchor" name="non-response_bias"></a>
</p><h2 class="hide-from-toc" id="non-response-bias" data-text=" non-response bias "> non-response bias </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>See <a href="https://developers.google.com/machine-learning/glossary#selection_bias"><strong>selection bias</strong></a>.</p>

<p><a class="glossary-anchor" name="nonstationarity"></a>
</p><h2 class="hide-from-toc" id="nonstationarity" data-text=" nonstationarity"> nonstationarity</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A feature whose values change across one or more dimensions, usually time.
For example, consider the following examples of nonstationarity:</p>

<ul>
<li>The number of swimsuits sold at a particular store varies with the season.</li>
<li>The quantity of a particular fruit harvested in a particular region
is zero for much of the year but large for a brief period.</li>
<li>Due to climate change, annual mean temperatures are shifting.</li>
</ul>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#stationarity"><strong>stationarity</strong></a>.</p>

<p><a class="glossary-anchor" name="normalization"></a>
</p><h2 class="hide-from-toc" id="normalization" data-text=" normalization"> normalization</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Broadly speaking, the process of converting a variable's actual range
of values into a standard range of values, such as:</p>

<ul>
<li>-1 to +1</li>
<li>0 to 1</li>
<li>the normal distribution</li>
</ul>

<p>For example, suppose the actual range of values of a certain feature is
800 to 2,400.  As part of <a href="https://developers.google.com/machine-learning/glossary#feature_engineering"><strong>feature engineering</strong></a>,
you could normalize the actual values down to a standard range, such
as -1 to +1.</p>

<p>Normalization is a common task in
<a href="https://developers.google.com/machine-learning/glossary#feature_engineering"><strong>feature engineering</strong></a>. Models usually train faster
(and produce better predictions) when every numerical feature in the
<a href="https://developers.google.com/machine-learning/glossary#feature_vector"><strong>feature vector</strong></a> has roughly the same range.</p>

<p><a class="glossary-anchor" name="novelty-detection"></a>
</p><h2 class="hide-from-toc" id="novelty-detection" data-text=" novelty detection"> novelty detection</h2><p></p>

<p>The process of determining whether a new (novel) example comes from the same
distribution as the <a href="https://developers.google.com/machine-learning/glossary#training_set"><strong>training set</strong></a>. In other words, after
training on the training set, novelty detection determines whether a <em>new</em>
example (during inference or during additional training) is an
<a href="https://developers.google.com/machine-learning/glossary#outliers"><strong>outlier</strong></a>.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#outlier-detection"><strong>outlier detection</strong></a>.</p>

<p><a class="glossary-anchor" name="numerical_data"></a>
</p><h2 class="hide-from-toc" id="numerical-data" data-text=" numerical data"> numerical data</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p><a href="https://developers.google.com/machine-learning/glossary#feature"><strong>Features</strong></a> represented as integers or real-valued numbers.
For example, a house valuation model would probably represent the size
of a house (in square feet or square meters) as numerical data.  Representing
a feature as numerical data indicates that the feature's values have
a <em>mathematical</em> relationship to the label.
That is, the number of square meters in a house probably has some
mathematical relationship to the value of the house.</p>

<p>Not all integer data should be represented as numerical data. For example,
postal codes in some parts of the world are integers; however, integer postal
codes should not be represented as numerical data in models. That's because a
postal code of <code translate="no" dir="ltr">20000</code> is not twice (or half) as potent as a postal code of
10000. Furthermore, although different postal codes <em>do</em> correlate to different
real estate values, we can't assume that real estate values at postal code
20000 are twice as valuable as real estate values at postal code 10000.
Postal codes should be represented as <a href="https://developers.google.com/machine-learning/glossary#categorical_data"><strong>categorical data</strong></a>
instead.</p>

<p>Numerical features are sometimes called
<a href="https://developers.google.com/machine-learning/glossary#continuous_feature"><strong>continuous features</strong></a>.</p>

<p><a class="glossary-anchor" name="numpy"></a>
</p><h2 class="hide-from-toc" id="numpy" data-text=" NumPy"> NumPy</h2><p></p>

<p>An <a href="http://www.numpy.org/" target="T">
open-source math library</a>
that provides efficient array operations in Python.
<a href="https://developers.google.com/machine-learning/glossary#pandas"><strong>pandas</strong></a> is built on NumPy.</p>

<p><a class="glossary-anchor" name="o"></a>
</p><h2 class="glossary" id="o" data-text="O">O</h2><p></p>

<p><a class="glossary-anchor" name="objective"></a>
</p><h2 class="hide-from-toc" id="objective" data-text=" objective"> objective</h2><p></p>

<p>A metric that your algorithm is trying to optimize.</p>

<p><a class="glossary-anchor" name="objective_function"></a>
</p><h2 class="hide-from-toc" id="objective-function" data-text=" objective function"> objective function</h2><p></p>

<p>The mathematical formula or <a href="https://developers.google.com/machine-learning/glossary#metric"><strong>metric</strong></a> that a model aims to optimize.
For example, the objective function for
<a href="https://developers.google.com/machine-learning/glossary#linear_regression"><strong>linear regression</strong></a> is usually
<a href="https://developers.google.com/machine-learning/glossary#MSE"><strong>Mean Squared Loss</strong></a>. Therefore, when training a
linear regression model, training aims to minimize Mean Squared Loss.</p>

<p>In some cases, the goal is to <em>maximize</em> the objective function.
For example, if the objective function is accuracy, the goal is
to maximize accuracy.</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#loss"><strong>loss</strong></a>.</p>

<p><a class="glossary-anchor" name="oblique-condition"></a>
</p><h2 class="hide-from-toc" id="oblique-condition" data-text=" oblique condition "> oblique condition </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>In a <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a>, a
<a href="https://developers.google.com/machine-learning/glossary#condition"><strong>condition</strong></a> that involves more than one
<a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a>.  For example, if height and width are both features,
then the following is an oblique condition:</p>
<devsite-code data-copy-event-label=""><pre class="" translate="no" dir="ltr" is-upgraded=""><code dir="ltr"><span class="pln">&nbsp; height </span><span class="pun">&gt;</span><span class="pln"> width<br></span></code></pre></devsite-code>
<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#axis-aligned-condition"><strong>axis-aligned condition</strong></a>.</p>

<p><a class="glossary-anchor" name="offline"></a>
</p><h2 class="hide-from-toc" id="offline" data-text=" offline"> offline</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#static"><strong>static</strong></a>.</p>

<p><a class="glossary-anchor" name="offline_inference"></a>
</p><h2 class="hide-from-toc" id="offline-inference" data-text=" offline inference"> offline inference</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The process of a model generating a batch of <a href="https://developers.google.com/machine-learning/glossary#prediction"><strong>predictions</strong></a>
and then caching (saving) those predictions. Apps can then access the desired
prediction from the cache rather than rerunning the model.</p>

<p>For example, consider a model that generates local weather forecasts
(predictions) once every four hours. After each model run, the system
caches all the local weather forecasts. Weather apps retrieve the forecasts
from the cache.</p>

<p>Offline inference is also called <strong>static inference</strong>.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#online_inference"><strong>online inference</strong></a>.</p>

<p><a class="glossary-anchor" name="one-hot_encoding"></a>
</p><h2 class="hide-from-toc" id="one-hot-encoding" data-text=" one-hot encoding"> one-hot encoding</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Representing categorical data as a vector in which:</p>

<ul>
<li>One element is set to 1.</li>
<li>All other elements are set to 0.</li>
</ul>

<p>One-hot encoding is commonly used to represent strings or identifiers that
have a finite set of possible values.
For example, suppose a certain categorical feature named
<code translate="no" dir="ltr">Scandinavia</code> has five possible values:</p>

<ul>
<li>"Denmark"</li>
<li>"Sweden"</li>
<li>"Norway"</li>
<li>"Finland"</li>
<li>"Iceland"</li>
</ul>

<p>One-hot encoding could represent each of the five values as follows:</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr><th>country</th> <th colspan="5&quot;">Vector</th></tr>
  <tr><td>"Denmark"</td> <td>1</td> <td>0</td> <td>0</td> <td>0</td>
      <td>0</td></tr>
  <tr><td>"Sweden"</td> <td>0</td> <td>1</td> <td>0</td> <td>0</td>
      <td>0</td></tr>
  <tr><td>"Norway"</td> <td>0</td> <td>0</td> <td>1</td> <td>0</td>
      <td>0</td></tr>
  <tr><td>"Finland"</td> <td>0</td> <td>0</td> <td>0</td> <td>1</td>
      <td>0</td></tr>
  <tr><td>"Iceland"</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td>
      <td>1</td></tr>
</tbody></table></div>

<p>Thanks to one-hot encoding, a model can learn different connections
based on each of the five countries.</p>

<p>Representing a feature as <a href="https://developers.google.com/machine-learning/glossary#numerical_data"><strong>numerical data</strong></a> is an
alternative to one-hot encoding.  Unfortunately, representing the
Scandinavian countries numerically is not a good choice.  For example,
consider the following numeric representation:</p>

<ul>
<li>"Denmark" is 0</li>
<li>"Sweden" is 1</li>
<li>"Norway" is 2</li>
<li>"Finland" is 3</li>
<li>"Iceland" is 4</li>
</ul>

<p>With numeric encoding, a model would interpret the raw numbers
mathematically and would try to train on those numbers.
However, Iceland isn't actually twice as much (or half as much) of
something as Norway, so the model would come to some strange conclusions.</p>

<p><a class="glossary-anchor" name="one-shot_learning"></a>
</p><h2 class="hide-from-toc" id="one-shot-learning" data-text=" one-shot learning"> one-shot learning</h2><p></p>

<p>A machine learning approach, often used for object classification,
designed to learn effective classifiers from a single training example.</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#few-shot_learning"><strong>few-shot learning</strong></a>.</p>

<p><a class="glossary-anchor" name="one-vs.-all"></a>
</p><h2 class="hide-from-toc" id="one-vs.-all" data-text=" one-vs.-all"> one-vs.-all</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Given a classification problem with N classes, a
solution consisting of N separate
<a href="https://developers.google.com/machine-learning/glossary#binary_classification"><strong>binary classifiers</strong></a>—one binary classifier for
each possible outcome. For example, given a model that classifies examples
as animal, vegetable, or mineral, a one-vs.-all solution would provide the
following three separate binary classifiers:</p>

<ul>
<li>animal vs. not animal</li>
<li>vegetable vs. not vegetable</li>
<li>mineral vs. not mineral</li>
</ul>

<p><a class="glossary-anchor" name="online"></a>
</p><h2 class="hide-from-toc" id="online" data-text=" online"> online</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#dynamic"><strong>dynamic</strong></a>.</p>

<p><a class="glossary-anchor" name="online_inference"></a>
</p><h2 class="hide-from-toc" id="online-inference" data-text=" online inference"> online inference</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Generating <a href="https://developers.google.com/machine-learning/glossary#prediction"><strong>predictions</strong></a> on demand. For example,
suppose an app passes input to a model and issues a request for a
prediction.
A system using online inference responds to the request by running
the model (and returning the prediction to the app).</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#offline_inference"><strong>offline inference</strong></a>.</p>

<p><a class="glossary-anchor" name="Operation"></a>
</p><h2 class="hide-from-toc" id="operation-op" data-text=" operation (op)"> operation (op)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>In TensorFlow, any procedure that creates,
manipulates, or destroys a <a href="https://developers.google.com/machine-learning/glossary#tensor"><strong>Tensor</strong></a>. For
example, a matrix multiply is an operation that takes two Tensors as
input and generates one Tensor as output.</p>

<p><a class="glossary-anchor" name="out-of-bag-evaluation"></a>
</p><h2 class="hide-from-toc" id="out-of-bag-evaluation-oob-evaluation" data-text=" out-of-bag evaluation (OOB evaluation) "> out-of-bag evaluation (OOB evaluation) </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>A mechanism for evaluating the quality of a
<a href="https://developers.google.com/machine-learning/glossary#decision-forest"><strong>decision forest</strong></a> by testing each
<a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a> against the
<a href="https://developers.google.com/machine-learning/glossary#example"><strong>examples</strong></a> <em>not</em> used during
<a href="https://developers.google.com/machine-learning/glossary#training"><strong>training</strong></a> of that decision tree. For example, in the
following diagram, notice that the system trains each decision tree
on about two-thirds of the examples and then evaluates against the
remaining one-third of the examples.</p>

<p>
<img src="./ML_Glossary_files/OOBevaluation.png" loading="lazy" width="537" height="500" alt="A decision forest consisting of three decision trees.
          One decision tree trains on two-thirds of the examples
          and then uses the remaining one-third for OOB evaluation.
          A second decision tree trains on a different two-thirds
          of the examples than the previous decision tree, and then
          uses a different one-third for OOB evaluation than the
          previous decision tree.">
</p>

<p>Out-of-bag evaluation is a computationally efficient and conservative
approximation of the <a href="https://developers.google.com/machine-learning/glossary#cross-validation"><strong>cross-validation</strong></a> mechanism.
In cross-validation, one model is trained for each cross-validation round
(for example, 10 models are trained in a 10-fold cross-validation).
With OOB evaluation, a single model is trained. Because <a href="https://developers.google.com/machine-learning/glossary#bagging"><strong>bagging</strong></a>
withholds some data from each tree during training, OOB evaluation can use
that data to approximate cross-validation.</p>

<p><a class="glossary-anchor" name="optimizer"></a>
</p><h2 class="hide-from-toc" id="optimizer" data-text=" optimizer"> optimizer</h2><p></p>

<p>A specific implementation of the <a href="https://developers.google.com/machine-learning/glossary#gradient_descent"><strong>gradient descent</strong></a>
algorithm.  Popular optimizers include:</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#AdaGrad"><strong>AdaGrad</strong></a>, which stands for ADAptive GRADient descent.</li>
<li>Adam, which stands for ADAptive with Momentum.</li>
</ul>

<p><a class="glossary-anchor" name="out-group_homogeneity_bias"></a>
</p><h2 class="hide-from-toc" id="out-group-homogeneity-bias" data-text=" out-group homogeneity bias "> out-group homogeneity bias </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>The tendency to see out-group members as more alike than in-group members
when comparing attitudes, values, personality traits, and other
characteristics. <strong>In-group</strong> refers to people you interact with regularly;
<strong>out-group</strong> refers to people you do not interact with regularly. If you
create a dataset by asking people to provide attributes about
out-groups, those attributes may be less nuanced and more stereotyped
than attributes that participants list for people in their in-group.</p>

<p>For example, Lilliputians might describe the houses of other Lilliputians
in great detail, citing small differences in architectural styles, windows,
doors, and sizes.  However, the same Lilliputians might simply declare that
Brobdingnagians all live in identical houses.</p>

<p>Out-group homogeneity bias is a form of
<a href="https://developers.google.com/machine-learning/glossary#group_attribution_bias"><strong>group attribution bias</strong></a>.</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#in-group_bias"><strong>in-group bias</strong></a>.</p>

<p><a class="glossary-anchor" name="outlier-detection"></a>
</p><h2 class="hide-from-toc" id="outlier-detection" data-text=" outlier detection"> outlier detection</h2><p></p>

<p>The process of identifying <a href="https://developers.google.com/machine-learning/glossary#outliers"><strong>outliers</strong></a> in a
<a href="https://developers.google.com/machine-learning/glossary#training_set"><strong>training set</strong></a>.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#novelty-detection"><strong>novelty detection</strong></a>.</p>

<p><a class="glossary-anchor" name="outliers"></a>
</p><h2 class="hide-from-toc" id="outliers" data-text=" outliers"> outliers</h2><p></p>

<p>Values distant from most other values. In machine learning, any of the
following are outliers:</p>

<ul>
<li>Input data whose values are more than roughly 3 standard deviations
from the mean.</li>
<li><a href="https://developers.google.com/machine-learning/glossary#weight"><strong>Weights</strong></a> with high absolute values.</li>
<li>Predicted values relatively far away from the actual values.</li>
</ul>

<p>For example, suppose that <code translate="no" dir="ltr">widget-price</code> is a feature of a certain model.
Assume that the mean <code translate="no" dir="ltr">widget-price</code> is 7 Euros with a standard deviation
of 1 Euro.  Examples containing a <code translate="no" dir="ltr">widget-price</code> of 12 Euros or 2 Euros
would therefore be considered outliers because each of those prices is
five standard deviations from the mean.</p>

<p>Outliers are often caused by typos or other input mistakes. In other cases,
outliers aren't mistakes; after all, values five standard deviations away
from the mean are rare but hardly impossible.</p>

<p>Outliers often cause problems in model training. <a href="https://developers.google.com/machine-learning/glossary#clipping"><strong>Clipping</strong></a>
is one way of managing outliers.</p>

<p><a class="glossary-anchor" name="output_layer"></a>
</p><h2 class="hide-from-toc" id="output-layer" data-text=" output layer"> output layer</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The "final" layer of a neural network. The output layer contains the prediction.</p>

<p>The following illustration shows a small deep neural network with an input
layer, two hidden layers, and an output layer:</p>

<p>
<img src="./ML_Glossary_files/OutputLayer.png" loading="lazy" alt="A neural network with one input layer, two hidden layers, and one
          output layer. The input layer consists of two features. The first
          hidden layer consists of three neurons and the second hidden layer
          consists of two neurons. The output layer consists of a single node.">
</p>

<p><a class="glossary-anchor" name="overfitting"></a>
</p><h2 class="hide-from-toc" id="overfitting" data-text=" overfitting" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> overfitting</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  overfitting" data-title="Copy link to this section:  overfitting" data-id="overfitting"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Creating a <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> that matches the
<a href="https://developers.google.com/machine-learning/glossary#training_set"><strong>training data</strong></a> so closely that the model fails to
make correct predictions on new data.</p>

<p><a href="https://developers.google.com/machine-learning/glossary#regularization"><strong>Regularization</strong></a> can reduce overfitting.
Training on a large and diverse training set can also reduce overfitting.</p>

<devsite-expandable is-upgraded="" id="expandable-28"><a class="exw-control" aria-controls="expandable-28" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-additional-notes._11" data-text=" Click the icon for additional notes. " role="presentation"><span class="devsite-heading" role="heading" aria-level="4">
Click the icon for additional notes.<wbr>
</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: 
Click the icon for additional notes.
" data-title="Copy link to this section: 
Click the icon for additional notes.
" data-id="click-the-icon-for-additional-notes._11"></button></h4></a>



<div class="expand-background">
<p>
Overfitting is like strictly following advice from only your favorite
teacher. You'll probably be successful in that teacher's class, but you
might "overfit" to that teacher's ideas and be unsuccessful in other
classes. Following advice from a mixture of teachers will enable you to
adapt better to new situations.
</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="oversampling"></a>
</p><h2 class="hide-from-toc" id="oversampling" data-text=" oversampling" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> oversampling</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  oversampling" data-title="Copy link to this section:  oversampling" data-id="oversampling"></button></h2><p></p>

<p>Reusing the <a href="https://developers.google.com/machine-learning/glossary#example"><strong>examples</strong></a> of a <a href="https://developers.google.com/machine-learning/glossary#minority_class"><strong>minority class</strong></a>
in a <a href="https://developers.google.com/machine-learning/glossary#class_imbalanced_data_set"><strong>class-imbalanced dataset</strong></a> in order to
create a more balanced <a href="https://developers.google.com/machine-learning/glossary#training_set"><strong>training set</strong></a>.</p>

<p>For example, consider a <a href="https://developers.google.com/machine-learning/glossary#binary_classification"><strong>binary classification</strong></a>
problem in which the ratio of the <a href="https://developers.google.com/machine-learning/glossary#majority_class"><strong>majority class</strong></a> to the
minority class is 5,000:1. If the dataset contains a million examples, then
the dataset contains only about 200 examples of the minority class, which might
be too few examples for effective training. To overcome this deficiency, you
might oversample (reuse) those 200 examples multiple times, possibly yielding
sufficient examples for useful training.</p>

<p>You need to be careful about over <a href="https://developers.google.com/machine-learning/glossary#overfitting"><strong>overfitting</strong></a> when
oversampling.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#undersampling"><strong>undersampling</strong></a>.</p>

<p><a class="glossary-anchor" name="p"></a>
</p><h2 class="glossary" id="p" data-text="P">P</h2><p></p>

<p><a class="glossary-anchor" name="pandas"></a>
</p><h2 class="hide-from-toc" id="pandas" data-text=" pandas"> pandas</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A column-oriented data analysis API built on top of <a href="https://developers.google.com/machine-learning/glossary#numpy"><strong>numpy</strong></a>.
Many machine learning frameworks,
including TensorFlow, support pandas data structures as inputs. See the
<a href="http://pandas.pydata.org/" target="T">pandas documentation</a>
for details.</p>

<p><a class="glossary-anchor" name="parameter"></a>
</p><h2 class="hide-from-toc" id="parameter" data-text=" parameter"> parameter</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The <a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weights</strong></a> and <a href="https://developers.google.com/machine-learning/glossary#bias"><strong>biases</strong></a> that a model learns during
<a href="https://developers.google.com/machine-learning/glossary#training"><strong>training</strong></a>. For example, in a
<a href="https://developers.google.com/machine-learning/glossary#linear_regression"><strong>linear regression</strong></a> model, the parameters consist of
the bias (<em>b</em>) and all the weights (<i>w<sub>1</sub></i>, <i>w<sub>2</sub></i>,
and so on) in the following formula:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-52-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msup&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;&amp;#x2032;&lt;/mo&gt;&lt;/msup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo&gt;&amp;#x2026;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="33.208ex" height="2.731ex" viewBox="0 -868.2 14297.9 1175.9" role="img" focusable="false" style="vertical-align: -0.715ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2032" x="706" y="583"></use><use href="#MJMAIN-3D" x="1072" y="0"></use><use href="#MJMATHI-62" x="2128" y="0"></use><use href="#MJMAIN-2B" x="2780" y="0"></use><g transform="translate(3780,0)"><use href="#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="1013" y="-213"></use></g><g transform="translate(4951,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="809" y="-213"></use></g><use href="#MJMAIN-2B" x="6199" y="0"></use><g transform="translate(7200,0)"><use href="#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="1013" y="-213"></use></g><g transform="translate(8371,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="809" y="-213"></use></g><use href="#MJMAIN-2B" x="9619" y="0"></use><use href="#MJMAIN-2026" x="10620" y="0"></use><g transform="translate(11959,0)"><use href="#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-6E" x="1013" y="-213"></use></g><g transform="translate(13200,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-6E" x="809" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msup><mi>y</mi><mo>′</mo></msup><mo>=</mo><mi>b</mi><mo>+</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mo>…</mo><msub><mi>w</mi><mi>n</mi></msub><msub><mi>x</mi><mi>n</mi></msub></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-52">y' = b + w_1x_1 + w_2x_2 + … w_nx_n</script>
</div>

<p>In contrast, <a href="https://developers.google.com/machine-learning/glossary#hyperparameter"><strong>hyperparameter</strong></a> are the values that
<em>you</em> (or a hyperparameter turning service) supply to the model.
For example, <a href="https://developers.google.com/machine-learning/glossary#learning_rate"><strong>learning rate</strong></a> is a hyperparameter.</p>

<p><a class="glossary-anchor" name="Parameter_Server"></a>
</p><h2 class="hide-from-toc" id="parameter-server-ps" data-text=" Parameter Server (PS)"> Parameter Server (PS)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>A job that keeps track of a model's <a href="https://developers.google.com/machine-learning/glossary#parameter"><strong>parameters</strong></a> in a
distributed setting.</p>

<p><a class="glossary-anchor" name="parameter_update"></a>
</p><h2 class="hide-from-toc" id="parameter-update" data-text=" parameter update"> parameter update</h2><p></p>

<p>The operation of adjusting a model's <a href="https://developers.google.com/machine-learning/glossary#parameter"><strong>parameters</strong></a> during
training, typically within a single iteration of
<a href="https://developers.google.com/machine-learning/glossary#gradient_descent"><strong>gradient descent</strong></a>.</p>

<p><a class="glossary-anchor" name="partial_derivative"></a>
</p><h2 class="hide-from-toc" id="partial-derivative" data-text=" partial derivative"> partial derivative</h2><p></p>

<p>A derivative in which all but one of the variables is considered a constant.
For example, the partial derivative of <em>f(x, y)</em> with respect to <em>x</em> is the
derivative of <em>f</em> considered as a function of <em>x</em> alone (that is, keeping <em>y</em>
constant). The partial derivative of <em>f</em> with respect to <em>x</em> focuses only on
how <em>x</em> is changing and ignores all other variables in the equation.</p>

<p><a class="glossary-anchor" name="participation_bias"></a>
</p><h2 class="hide-from-toc" id="participation-bias" data-text=" participation bias"> participation bias</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>Synonym for non-response bias.  See <a href="https://developers.google.com/machine-learning/glossary#selection_bias"><strong>selection bias</strong></a>.</p>

<p><a class="glossary-anchor" name="partitioning_strategy"></a>
</p><h2 class="hide-from-toc" id="partitioning-strategy" data-text=" partitioning strategy"> partitioning strategy</h2><p></p>

<p>The algorithm by which variables are divided across
<a href="https://developers.google.com/machine-learning/glossary#Parameter_Server"><strong>parameter servers</strong></a>.</p>



<p><a class="glossary-anchor" name="perceptron"></a>
</p><h2 class="hide-from-toc" id="perceptron" data-text=" perceptron"> perceptron</h2><p></p>

<p>A system (either hardware or software) that takes in one or more input values,
runs a function on the weighted sum of the inputs, and computes a single
output value. In machine learning, the function is typically nonlinear, such as
<a href="https://developers.google.com/machine-learning/glossary#ReLU"><strong>ReLU</strong></a>, <a href="https://developers.google.com/machine-learning/glossary#sigmoid-function"><strong>sigmoid</strong></a>, or
<a href="https://wikipedia.org/wiki/Hyperbolic_functions" target="T">tanh</a>.
For example, the following perceptron relies on the sigmoid function to process
three input values:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-53-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mtext&gt;sigmoid&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="45.966ex" height="2.613ex" viewBox="0 -817.3 19790.9 1125" role="img" focusable="false" style="vertical-align: -0.715ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-66" x="0" y="0"></use><use href="#MJMAIN-28" x="550" y="0"></use><g transform="translate(940,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="809" y="-213"></use></g><use href="#MJMAIN-2C" x="1966" y="0"></use><g transform="translate(2411,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="809" y="-213"></use></g><use href="#MJMAIN-2C" x="3437" y="0"></use><g transform="translate(3883,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-33" x="809" y="-213"></use></g><use href="#MJMAIN-29" x="4909" y="0"></use><use href="#MJMAIN-3D" x="5576" y="0"></use><g transform="translate(6633,0)"><use href="#MJMAIN-73"></use><use href="#MJMAIN-69" x="394" y="0"></use><use href="#MJMAIN-67" x="673" y="0"></use><use href="#MJMAIN-6D" x="1173" y="0"></use><use href="#MJMAIN-6F" x="2007" y="0"></use><use href="#MJMAIN-69" x="2507" y="0"></use><use href="#MJMAIN-64" x="2786" y="0"></use></g><use href="#MJMAIN-28" x="9975" y="0"></use><g transform="translate(10365,0)"><use href="#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="1013" y="-213"></use></g><g transform="translate(11535,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="809" y="-213"></use></g><use href="#MJMAIN-2B" x="12784" y="0"></use><g transform="translate(13784,0)"><use href="#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="1013" y="-213"></use></g><g transform="translate(14955,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="809" y="-213"></use></g><use href="#MJMAIN-2B" x="16203" y="0"></use><g transform="translate(17204,0)"><use href="#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-33" x="1013" y="-213"></use></g><g transform="translate(18375,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-33" x="809" y="-213"></use></g><use href="#MJMAIN-29" x="19401" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><msub><mi>x</mi><mn>3</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mtext>sigmoid</mtext><mo stretchy="false">(</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><msub><mi>w</mi><mn>3</mn></msub><msub><mi>x</mi><mn>3</mn></msub><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-53">f(x_1, x_2, x_3) = \text{sigmoid}(w_1 x_1 + w_2 x_2 + w_3 x_3)</script>
</div>

<p>In the following illustration, the perceptron takes three inputs, each of which
is itself modified by a weight before entering the perceptron:</p>

<p>
<img src="./ML_Glossary_files/Perceptron.svg" height="350" width="525" loading="lazy" alt="A perceptron that takes in 3 inputs, each multiplied by separate
          weights. The perceptron outputs a single value.">
</p>

<p>Perceptrons are the <a href="https://developers.google.com/machine-learning/glossary#neuron"><strong>neurons</strong></a> in
<a href="https://developers.google.com/machine-learning/glossary#neural-network"><strong>neural networks</strong></a>.</p>

<p><a class="glossary-anchor" name="performance"></a>
</p><h2 class="hide-from-toc" id="performance" data-text=" performance"> performance</h2><p></p>

<p>Overloaded term with the following meanings:</p>

<ul>
<li>The traditional meaning within software engineering. Namely: How fast
(or efficiently) does this piece of software run?</li>
<li>The meaning within machine learning. Here, performance answers the
following question: How correct is this <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a>? That is,
how good are the model's predictions?</li>
</ul>

<p><a class="glossary-anchor" name="permutation-variable-importances"></a>
</p><h2 class="hide-from-toc" id="permutation-variable-importances" data-text=" permutation variable importances "> permutation variable importances </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>A type of <a href="https://developers.google.com/machine-learning/glossary#variable-importances"><strong>variable importance</strong></a> that evaluates
the increase in the prediction error of a model <em>after</em> permuting the
feature’s values. Permutation variable importance is a model
agnostic metric.</p>

<p><a class="glossary-anchor" name="perplexity"></a>
</p><h2 class="hide-from-toc" id="perplexity" data-text=" perplexity"> perplexity</h2><p></p>

<p>One measure of how well a <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> is accomplishing its task.
For example, suppose your task is to read the first few letters of a word
a user is typing on a smartphone keyboard, and to offer a list of possible
completion words. Perplexity, P, for this task is approximately the number
of guesses you need to offer in order for your list to contain the actual
word the user is trying to type.</p>

<p>Perplexity is related to <a href="https://developers.google.com/machine-learning/glossary#cross-entropy"><strong>cross-entropy</strong></a> as follows:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-54-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msup&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mtext&gt;cross entropy&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="17.122ex" height="2.376ex" viewBox="0 -919.2 7372.1 1023.1" role="img" focusable="false" style="vertical-align: -0.241ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-50" x="0" y="0"></use><use href="#MJMAIN-3D" x="1029" y="0"></use><g transform="translate(2085,0)"><use href="#MJMAIN-32" x="0" y="0"></use><g transform="translate(500,412)"><use transform="scale(0.707)" href="#MJMAIN-2212" x="0" y="0"></use><g transform="translate(550,0)"><use transform="scale(0.707)" href="#MJMAIN-63"></use><use transform="scale(0.707)" href="#MJMAIN-72" x="444" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-6F" x="837" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-73" x="1337" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-73" x="1732" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-65" x="2480" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-6E" x="2924" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-74" x="3481" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-72" x="3870" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-6F" x="4263" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-70" x="4763" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-79" x="5320" y="0"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>P</mi><mo>=</mo><msup><mn>2</mn><mrow class="MJX-TeXAtom-ORD"><mo>−</mo><mtext>cross entropy</mtext></mrow></msup></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-54">P= 2^{-\text{cross entropy}}</script>
</div>

<p><a class="glossary-anchor" name="pipeline"></a>
</p><h2 class="hide-from-toc" id="pipeline" data-text=" pipeline"> pipeline</h2><p></p>

<p>The infrastructure surrounding a machine learning algorithm. A pipeline
includes gathering the data, putting the data into training data files,
training one or more models, and exporting the models to production.</p>

<p><a class="glossary-anchor" name="pipelining"></a>
</p><h2 class="hide-from-toc" id="pipelining" data-text=" pipelining"> pipelining</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A form of <a href="https://developers.google.com/machine-learning/glossary#model-parallelism"><strong>model parallelism</strong></a> in which a model's
processing is divided into consecutive stages and each stage is executed
on a different device. While a stage is processing one batch, the preceding
stage can work on the next batch.</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#staged-training"><strong>staged training</strong></a>.</p>

<p><a class="glossary-anchor" name="policy"></a>
</p><h2 class="hide-from-toc" id="policy" data-text=" policy"> policy</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In reinforcement learning, an <a href="https://developers.google.com/machine-learning/glossary#agent"><strong>agent's</strong></a> probabilistic mapping
from <a href="https://developers.google.com/machine-learning/glossary#state"><strong>states</strong></a> to <a href="https://developers.google.com/machine-learning/glossary#action"><strong>actions</strong></a>.</p>

<p><a class="glossary-anchor" name="pooling"></a>
</p><h2 class="hide-from-toc" id="pooling" data-text=" pooling"> pooling</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>Reducing a matrix (or matrices) created by an earlier
<a href="https://developers.google.com/machine-learning/glossary#convolutional_layer"><strong>convolutional layer</strong></a> to a smaller matrix.
Pooling usually involves taking either the maximum or average value
across the pooled area. For example, suppose we have the
following 3x3 matrix:</p>

<p>
<img src="./ML_Glossary_files/PoolingStart.svg" loading="lazy" height="180" width="120" alt="The 3x3 matrix [[5,3,1], [8,2,5], [9,4,3]].">
</p>

<p>A pooling operation, just like a convolutional operation, divides that
matrix into slices and then slides that convolutional operation by
<a href="https://developers.google.com/machine-learning/glossary#stride"><strong>strides</strong></a>. For example, suppose the pooling operation
divides the convolutional matrix into 2x2 slices with a 1x1 stride.
As the following diagram illustrates, four pooling operations take place.
Imagine that each pooling operation picks the maximum value of the
four in that slice:</p>

<p>
<img src="./ML_Glossary_files/PoolingConvolution.svg" loading="lazy" height="500" width="500" alt="The input matrix is 3x3 with the values: [[5,3,1], [8,2,5], [9,4,3]].
          The top-left 2x2 submatrix of the input matrix is [[5,3], [8,2]], so
          the top-left pooling operation yields the value 8 (which is the
          maximum of 5, 3, 8, and 2). The top-right 2x2 submatrix of the input
          matrix is [[3,1], [2,5]], so the top-right pooling operation yields
          the value 5. The bottom-left 2x2 submatrix of the input matrix is
          [[8,2], [9,4]], so the bottom-left pooling operation yields the value
          9.  The bottom-right 2x2 submatrix of the input matrix is
          [[2,5], [4,3]], so the bottom-right pooling operation yields the value
          5.  In summary, the pooling operation yields the 2x2 matrix
          [[8,5], [9,5]].">
</p>

<p>Pooling helps enforce
<a href="https://developers.google.com/machine-learning/glossary#translational_invariance"><strong>translational invariance</strong></a> in the input matrix.</p>

<p>Pooling for vision applications is known more formally as <strong>spatial pooling</strong>.
Time-series applications usually refer to pooling as <strong>temporal pooling</strong>.
Less formally, pooling is often called <strong>subsampling</strong> or <strong>downsampling</strong>.</p>

<p><a class="glossary-anchor" name="positive_class"></a>
</p><h2 class="hide-from-toc" id="positive-class" data-text=" positive class"> positive class</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The class you are testing for.</p>

<p>For example, the positive class in a cancer model might be "tumor."
The positive class in an email classifier might be "spam."</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#negative_class"><strong>negative class</strong></a>.</p>

<devsite-expandable is-upgraded="" id="expandable-29"><a class="exw-control" aria-controls="expandable-29" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-additional-notes._12" data-text=" Click the icon for additional notes. ">
Click the icon for additional notes.
</h4></a>



<div class="expand-background">
<p>
The term <b>positive class</b> can be confusing because the "positive" outcome
of many tests is often an undesirable result. For example, the positive class in
many medical tests corresponds to tumors or diseases. In general, you want a
doctor to tell you, "Congratulations! Your test results were negative."
Regardless, the positive class is the event that the test is seeking to find.
</p>

<p>
Admittedly, you're simultaneously testing for both the positive and negative
classes.
</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="postprocessing"></a>
<a class="glossary-anchor" name="post-processing"></a>
</p><h2 class="hide-from-toc" id="post-processing" data-text=" post-processing"> post-processing</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Adjusting the output of a model <em>after</em> the model has been run.
Post-processing can be used to enforce fairness constraints without
modifying models themselves.</p>

<p>For example, one might apply post-processing to a binary classifier
by setting a classification threshold such that
<a href="https://developers.google.com/machine-learning/glossary#equality_of_opportunity"><strong>equality of opportunity</strong></a> is maintained
for some attribute by checking that the <a href="https://developers.google.com/machine-learning/glossary#TP_rate"><strong>true positive rate</strong></a>
is the same for all values of that attribute.</p>

<p><a class="glossary-anchor" name="PRAUC"></a>
<a class="glossary-anchor" name="PR_AUC"></a>
<a class="glossary-anchor" name="area_under_the_pr_curve"></a>
</p><h2 class="hide-from-toc" id="pr-auc-area-under-the-pr-curve" data-text=" PR AUC (area under the PR curve)"> PR AUC (area under the PR curve)</h2><p></p>

<p>Area under the interpolated
<a href="https://developers.google.com/machine-learning/glossary#precision-recall_curve"><strong>precision-recall curve</strong></a>, obtained by plotting
(recall, precision) points for different values of the
<a href="https://developers.google.com/machine-learning/glossary#classification_threshold"><strong>classification threshold</strong></a>. Depending on how
it's calculated, PR AUC may be equivalent to the
<a href="https://developers.google.com/machine-learning/glossary#average_precision"><strong>average precision</strong></a> of the model.</p>

<p><a class="glossary-anchor" name="precision"></a>
</p><h2 class="hide-from-toc" id="precision" data-text=" precision"> precision</h2><p></p>

<p>A metric for <a href="https://developers.google.com/machine-learning/glossary#classification_model"><strong>classification models</strong></a> that answers
the following question:</p>

<blockquote>
<p>When the model predicted the <a href="https://developers.google.com/machine-learning/glossary#positive_class"><strong>positive class</strong></a>,
what percentage of the predictions were correct?</p>
</blockquote>

<p>Here is the formula:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-55-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Precision&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtext&gt;true positives&lt;/mtext&gt;&lt;mrow&gt;&lt;mtext&gt;true positives&lt;/mtext&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;false positives&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="43.263ex" height="5.571ex" viewBox="0 -1428.7 18627 2398.8" role="img" focusable="false" style="vertical-align: -2.253ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-50"></use><use href="#MJMAIN-72" x="681" y="0"></use><use href="#MJMAIN-65" x="1074" y="0"></use><use href="#MJMAIN-63" x="1518" y="0"></use><use href="#MJMAIN-69" x="1963" y="0"></use><use href="#MJMAIN-73" x="2241" y="0"></use><use href="#MJMAIN-69" x="2636" y="0"></use><use href="#MJMAIN-6F" x="2914" y="0"></use><use href="#MJMAIN-6E" x="3415" y="0"></use><use href="#MJMAIN-3D" x="4249" y="0"></use><g transform="translate(5027,0)"><g transform="translate(397,0)"><rect stroke="none" width="13081" height="60" x="0" y="220"></rect><g transform="translate(3641,676)"><use href="#MJMAIN-74"></use><use href="#MJMAIN-72" x="389" y="0"></use><use href="#MJMAIN-75" x="782" y="0"></use><use href="#MJMAIN-65" x="1338" y="0"></use><use href="#MJMAIN-70" x="2033" y="0"></use><use href="#MJMAIN-6F" x="2589" y="0"></use><use href="#MJMAIN-73" x="3090" y="0"></use><use href="#MJMAIN-69" x="3484" y="0"></use><use href="#MJMAIN-74" x="3763" y="0"></use><use href="#MJMAIN-69" x="4152" y="0"></use><use href="#MJMAIN-76" x="4431" y="0"></use><use href="#MJMAIN-65" x="4959" y="0"></use><use href="#MJMAIN-73" x="5404" y="0"></use></g><g transform="translate(60,-686)"><use href="#MJMAIN-74"></use><use href="#MJMAIN-72" x="389" y="0"></use><use href="#MJMAIN-75" x="782" y="0"></use><use href="#MJMAIN-65" x="1338" y="0"></use><use href="#MJMAIN-70" x="2033" y="0"></use><use href="#MJMAIN-6F" x="2589" y="0"></use><use href="#MJMAIN-73" x="3090" y="0"></use><use href="#MJMAIN-69" x="3484" y="0"></use><use href="#MJMAIN-74" x="3763" y="0"></use><use href="#MJMAIN-69" x="4152" y="0"></use><use href="#MJMAIN-76" x="4431" y="0"></use><use href="#MJMAIN-65" x="4959" y="0"></use><use href="#MJMAIN-73" x="5404" y="0"></use><use href="#MJMAIN-2B" x="6020" y="0"></use><g transform="translate(7021,0)"><use href="#MJMAIN-66"></use><use href="#MJMAIN-61" x="306" y="0"></use><use href="#MJMAIN-6C" x="807" y="0"></use><use href="#MJMAIN-73" x="1085" y="0"></use><use href="#MJMAIN-65" x="1480" y="0"></use><use href="#MJMAIN-70" x="2174" y="0"></use><use href="#MJMAIN-6F" x="2731" y="0"></use><use href="#MJMAIN-73" x="3231" y="0"></use><use href="#MJMAIN-69" x="3626" y="0"></use><use href="#MJMAIN-74" x="3904" y="0"></use><use href="#MJMAIN-69" x="4294" y="0"></use><use href="#MJMAIN-76" x="4572" y="0"></use><use href="#MJMAIN-65" x="5101" y="0"></use><use href="#MJMAIN-73" x="5545" y="0"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Precision</mtext><mo>=</mo><mfrac><mtext>true positives</mtext><mrow><mtext>true positives</mtext><mo>+</mo><mtext>false positives</mtext></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-55">\text{Precision} =
\frac{\text{true positives}} {\text{true positives} + \text{false positives}}</script>
</div>

<p>where:</p>

<ul>
<li>true positive means the model <em>correctly</em> predicted the positive class.</li>
<li>false positive means the model <em>mistakenly</em> predicted the positive class.</li>
</ul>

<p>For example, suppose a model made 200 positive predictions.
Of these 200 positive predictions:</p>

<ul>
<li>150 were true positives.</li>
<li>50 were false positives.</li>
</ul>

<p>In this case:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-56-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Precision&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtext&gt;150&lt;/mtext&gt;&lt;mrow&gt;&lt;mtext&gt;150&lt;/mtext&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;50&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.75&lt;/mn&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="29.044ex" height="5.335ex" viewBox="0 -1428.7 12505.1 2296.9" role="img" focusable="false" style="vertical-align: -2.016ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-50"></use><use href="#MJMAIN-72" x="681" y="0"></use><use href="#MJMAIN-65" x="1074" y="0"></use><use href="#MJMAIN-63" x="1518" y="0"></use><use href="#MJMAIN-69" x="1963" y="0"></use><use href="#MJMAIN-73" x="2241" y="0"></use><use href="#MJMAIN-69" x="2636" y="0"></use><use href="#MJMAIN-6F" x="2914" y="0"></use><use href="#MJMAIN-6E" x="3415" y="0"></use><use href="#MJMAIN-3D" x="4249" y="0"></use><g transform="translate(5027,0)"><g transform="translate(397,0)"><rect stroke="none" width="3845" height="60" x="0" y="220"></rect><g transform="translate(1171,676)"><use href="#MJMAIN-31"></use><use href="#MJMAIN-35" x="500" y="0"></use><use href="#MJMAIN-30" x="1001" y="0"></use></g><g transform="translate(60,-686)"><use href="#MJMAIN-31"></use><use href="#MJMAIN-35" x="500" y="0"></use><use href="#MJMAIN-30" x="1001" y="0"></use><use href="#MJMAIN-2B" x="1723" y="0"></use><g transform="translate(2724,0)"><use href="#MJMAIN-35"></use><use href="#MJMAIN-30" x="500" y="0"></use></g></g></g></g><use href="#MJMAIN-3D" x="9668" y="0"></use><g transform="translate(10725,0)"><use href="#MJMAIN-30"></use><use href="#MJMAIN-2E" x="500" y="0"></use><use href="#MJMAIN-37" x="779" y="0"></use><use href="#MJMAIN-35" x="1279" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Precision</mtext><mo>=</mo><mfrac><mtext>150</mtext><mrow><mtext>150</mtext><mo>+</mo><mtext>50</mtext></mrow></mfrac><mo>=</mo><mn>0.75</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-56">\text{Precision} =
\frac{\text{150}} {\text{150} + \text{50}} = 0.75</script>
</div>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#accuracy"><strong>accuracy</strong></a> and <a href="https://developers.google.com/machine-learning/glossary#recall"><strong>recall</strong></a>.</p>

<p><a class="glossary-anchor" name="precision-recall_curve"></a>
</p><h2 class="hide-from-toc" id="precision-recall-curve" data-text=" precision-recall curve"> precision-recall curve</h2><p></p>

<p>A curve of <a href="https://developers.google.com/machine-learning/glossary#precision"><strong>precision</strong></a> vs. <a href="https://developers.google.com/machine-learning/glossary#recall"><strong>recall</strong></a> at different
<a href="https://developers.google.com/machine-learning/glossary#classification_threshold"><strong>classification thresholds</strong></a>.</p>

<p><a class="glossary-anchor" name="prediction"></a>
</p><h2 class="hide-from-toc" id="prediction" data-text=" prediction"> prediction</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A model's output. For example:</p>

<ul>
<li>The prediction of a binary classification model is either the positive
class or the negative class.</li>
<li>The prediction of a multi-class classification model is one class.</li>
<li>The prediction of a linear regression model is a number.</li>
</ul>

<p><a class="glossary-anchor" name="prediction_bias"></a>
</p><h2 class="hide-from-toc" id="prediction-bias" data-text=" prediction bias"> prediction bias</h2><p></p>

<p>A value indicating how far apart the average of
<a href="https://developers.google.com/machine-learning/glossary#prediction"><strong>predictions</strong></a> is from the average of <a href="https://developers.google.com/machine-learning/glossary#label"><strong>labels</strong></a>
in the dataset.</p>

<p>Not to be confused with the <a href="https://developers.google.com/machine-learning/glossary#bias"><strong>bias term</strong></a> in machine learning models
or with <a href="https://developers.google.com/machine-learning/glossary#bias_ethics"><strong>bias in ethics and fairness</strong></a>.</p>

<p><a class="glossary-anchor" name="predictive_parity"></a>
</p><h2 class="hide-from-toc" id="predictive-parity" data-text=" predictive parity"> predictive parity</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#fairness_metric"><strong>fairness metric</strong></a> that checks whether,
for a given classifier, the <a href="https://developers.google.com/machine-learning/glossary#precision"><strong>precision</strong></a> rates
are equivalent for subgroups under consideration.</p>

<p>For example, a model that predicts college acceptance would satisfy
predictive parity for nationality if its precision rate is the same
for Lilliputians and Brobdingnagians.</p>

<p>Predictive parity is sometime also called <em>predictive rate parity</em>.</p>

<p>See <a href="http://fairware.cs.umass.edu/papers/Verma.pdf">"Fairness Definitions
Explained"</a> (section 3.2.1)
for a more detailed discussion of predictive parity.</p>

<p><a class="glossary-anchor" name="predictive_rate_parity"></a>
</p><h2 class="hide-from-toc" id="predictive-rate-parity" data-text=" predictive rate parity"> predictive rate parity</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>Another name for <a href="https://developers.google.com/machine-learning/glossary#predictive_parity"><strong>predictive parity</strong></a>.</p>

<p><a class="glossary-anchor" name="preprocessing"></a>
</p><h2 class="hide-from-toc" id="preprocessing" data-text=" preprocessing"> preprocessing</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div>
Processing data before it's used to train a model. Preprocessing could
be as simple as removing words from an English text corpus that don't
occur in the English dictionary, or could be as complex as re-expressing
data points in a way that eliminates as many attributes that are correlated
with  <a href="https://developers.google.com/machine-learning/glossary#sensitive_attribute"><strong>sensitive attributes</strong></a> as possible.
Preprocessing can help satisfy <a href="https://developers.google.com/machine-learning/glossary#fairness_constraint"><strong>fairness constraints</strong></a>.<p></p>

<p><a class="glossary-anchor" name="pre-trained_model"></a>
</p><h2 class="hide-from-toc" id="pre-trained-model" data-text=" pre-trained model"> pre-trained model</h2><p></p>

<p>Models or model components (such as <a href="https://developers.google.com/machine-learning/glossary#embedding_vector"><strong>embedding vector</strong></a>)
that have been already been trained. Sometimes, you'll feed pre-trained
embedding vectors into a <a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural network</strong></a>. Other times,
your model will train the embedding vectors itself rather than rely on the
pre-trained embeddings.</p>

<p><a class="glossary-anchor" name="prior_belief"></a>
</p><h2 class="hide-from-toc" id="prior-belief" data-text=" prior belief" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> prior belief</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  prior belief" data-title="Copy link to this section:  prior belief" data-id="prior-belief"></button></h2><p></p>

<p>What you believe about the data before you begin training on it.
For example, <a href="https://developers.google.com/machine-learning/glossary#L2_regularization"><strong>L<sub>2</sub> regularization</strong></a> relies on
a prior belief that <a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weights</strong></a> should be small and normally
distributed around zero.</p>

<p><a class="glossary-anchor" name="probabilistic-regression-model"></a>
</p><h2 class="hide-from-toc" id="probabilistic-regression-model" data-text=" probabilistic regression model" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> probabilistic regression model</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  probabilistic regression model" data-title="Copy link to this section:  probabilistic regression model" data-id="probabilistic-regression-model"></button></h2><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#regression_model"><strong>regression model</strong></a> that uses not only the
<a href="https://developers.google.com/machine-learning/glossary#weight"><strong>weights</strong></a> for each <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a>, but also the
uncertainty of those weights. A probabilistic regression model generates
a prediction and the uncertainty of that prediction. For example, a
probabilistic regression model might yield a prediction of 325 with a
standard deviation of 12. For more information about probabilistic regression
models, see this <a href="https://www.tensorflow.org/probability/examples/Probabilistic_Layers_Regression">Colab on
tensorflow.org</a>.</p>

<p><a class="glossary-anchor" name="proxy_sensitive_attributes"></a>
</p><h2 class="hide-from-toc" id="proxy-sensitive-attributes" data-text=" proxy (sensitive attributes)" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> proxy (sensitive attributes)</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  proxy (sensitive attributes)" data-title="Copy link to this section:  proxy (sensitive attributes)" data-id="proxy-sensitive-attributes"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div>
An attribute used as a stand-in for a
<a href="https://developers.google.com/machine-learning/glossary#sensitive_attribute"><strong>sensitive attribute</strong></a>. For example, an
individual's postal code might be used as a proxy for their income,
race, or ethnicity.<p></p>

<p><a class="glossary-anchor" name="proxy_labels"></a>
</p><h2 class="hide-from-toc" id="proxy-labels" data-text=" proxy labels" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> proxy labels</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  proxy labels" data-title="Copy link to this section:  proxy labels" data-id="proxy-labels"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Data used to approximate labels not directly available in a dataset.</p>

<p>For example, suppose you must train a model to predict employee
stress level. Your dataset contains a lot of predictive features but
doesn't contain a label named <em>stress level.</em>
Undaunted, you pick "workplace accidents" as a proxy label for
stress level. After all, employees under high stress get into more
accidents than calm employees. Or do they? Maybe workplace accidents
actually rise and fall for multiple reasons.</p>

<p>As a second example, suppose you want <em>is it raining?</em> to be a Boolean label
for your dataset, but your dataset doesn't contain rain data. If
photographs are available, you might establish pictures of people
carrying umbrellas as a proxy label for <em>is it raining?</em>  Is that
a good proxy label? Possibly, but people in some cultures may be
more likely to carry umbrellas to protect against sun than the rain.</p>

<p>Proxy labels are often imperfect. When possible, choose actual labels over
proxy labels. That said, when an actual label is absent, pick the proxy
label very carefully, choosing the least horrible proxy label candidate.</p>

<p><a class="glossary-anchor" name="q"></a>
</p><h2 class="glossary" id="q" data-text="Q">Q</h2><p></p>

<p><a class="glossary-anchor" name="q-function"></a>
</p><h2 class="hide-from-toc" id="q-function" data-text=" Q-function"> Q-function</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#reinforcement_learning"><strong>reinforcement learning</strong></a>, the function that
predicts the expected <a href="https://developers.google.com/machine-learning/glossary#return"><strong>return</strong></a> from taking an
<a href="https://developers.google.com/machine-learning/glossary#action"><strong>action</strong></a> in a
<a href="https://developers.google.com/machine-learning/glossary#state"><strong>state</strong></a> and then following a given <a href="https://developers.google.com/machine-learning/glossary#policy"><strong>policy</strong></a>.</p>

<p>Q-function is also known as <strong>state-action value function</strong>.</p>

<p><a class="glossary-anchor" name="q-learning"></a>
</p><h2 class="hide-from-toc" id="q-learning" data-text=" Q-learning"> Q-learning</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#reinforcement_learning"><strong>reinforcement learning</strong></a>, an algorithm that
allows an <a href="https://developers.google.com/machine-learning/glossary#agent"><strong>agent</strong></a>
to learn the optimal <a href="https://developers.google.com/machine-learning/glossary#q-function"><strong>Q-function</strong></a> of a
<a href="https://developers.google.com/machine-learning/glossary#markov_decision_process"><strong>Markov decision process</strong></a> by applying the
<a href="https://developers.google.com/machine-learning/glossary#bellman_equation"><strong>Bellman equation</strong></a>. The Markov decision process models
an <a href="https://developers.google.com/machine-learning/glossary#environment"><strong>environment</strong></a>.</p>

<p><a class="glossary-anchor" name="quantile"></a>
</p><h2 class="hide-from-toc" id="quantile" data-text=" quantile"> quantile</h2><p></p>

<p>Each bucket in <a href="https://developers.google.com/machine-learning/glossary#quantile_bucketing"><strong>quantile bucketing</strong></a>.</p>

<p><a class="glossary-anchor" name="quantile_bucketing"></a>
</p><h2 class="hide-from-toc" id="quantile-bucketing" data-text=" quantile bucketing"> quantile bucketing</h2><p></p>

<p>Distributing a feature's values into <a href="https://developers.google.com/machine-learning/glossary#bucketing"><strong>buckets</strong></a> so that each
bucket contains the same (or almost the same) number of examples.  For example,
the following figure divides 44 points into 4 buckets, each of which
contains 11 points.  In order for each bucket in the figure to contain the
same number of points, some buckets span a different width of x-values.</p>

<p>
<img src="./ML_Glossary_files/QuantileBucketing.svg" loading="lazy" alt="44 data points divided into 4 buckets of 11 points each.
          Although each bucket contains the same number of data points,
          some buckets contain a wider range of feature values than other
          buckets.">
</p>

<p><a class="glossary-anchor" name="quantization"></a>
</p><h2 class="hide-from-toc" id="quantization" data-text=" quantization"> quantization</h2><p></p>

<p>An algorithm that implements <a href="https://developers.google.com/machine-learning/glossary#quantile_bucketing"><strong>quantile bucketing</strong></a> on
a particular <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a> in a <a href="https://developers.google.com/machine-learning/glossary#data_set"><strong>dataset</strong></a>.</p>

<p><a class="glossary-anchor" name="queue"></a>
</p><h2 class="hide-from-toc" id="queue" data-text=" queue"> queue</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>A TensorFlow <a href="https://developers.google.com/machine-learning/glossary#Operation"><strong>Operation</strong></a> that implements a queue data
structure. Typically
used in I/O.</p>

<p><a class="glossary-anchor" name="r"></a>
</p><h2 class="glossary" id="r" data-text="R">R</h2><p></p>

<p><a class="glossary-anchor" name="random-forest"></a>
</p><h2 class="hide-from-toc" id="random-forest" data-text=" random forest"> random forest</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>An <a href="https://developers.google.com/machine-learning/glossary#ensemble"><strong>ensemble</strong></a> of <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision trees</strong></a> in
which each decision tree is trained with a specific random noise,
such as <a href="https://developers.google.com/machine-learning/glossary#bagging"><strong>bagging</strong></a>.</p>

<p>Random forests are a type of <a href="https://developers.google.com/machine-learning/glossary#decision-forest"><strong>decision forest</strong></a>.</p>

<p><a class="glossary-anchor" name="random_policy"></a>
</p><h2 class="hide-from-toc" id="random-policy" data-text=" random policy"> random policy</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#reinforcement_learning"><strong>reinforcement learning</strong></a>, a
<a href="https://developers.google.com/machine-learning/glossary#policy"><strong>policy</strong></a> that chooses an
<a href="https://developers.google.com/machine-learning/glossary#action"><strong>action</strong></a> at random.</p>

<p><a class="glossary-anchor" name="ranking"></a>
</p><h2 class="hide-from-toc" id="ranking" data-text=" ranking"> ranking</h2><p></p>

<p>A type of <a href="https://developers.google.com/machine-learning/glossary#supervised_machine_learning"><strong>supervised learning</strong></a> whose
objective is to order a list of items.</p>

<p><a class="glossary-anchor" name="rank_ordinality"></a>
</p><h2 class="hide-from-toc" id="rank-ordinality" data-text=" rank (ordinality)"> rank (ordinality)</h2><p></p>

<p>The ordinal position of a class in a machine learning problem that categorizes
classes from highest to lowest. For example, a behavior ranking
system could rank a dog's rewards from highest (a steak) to
lowest (wilted kale).</p>

<p><a class="glossary-anchor" name="rank"></a>
<a class="glossary-anchor" name="rank_Tensor"></a>
</p><h2 class="hide-from-toc" id="rank-tensor" data-text=" rank (Tensor)"> rank (Tensor)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>The number of dimensions in a <a href="https://developers.google.com/machine-learning/glossary#tensor"><strong>Tensor</strong></a>. For instance,
a scalar has rank 0, a vector has rank 1, and a matrix has rank 2.</p>

<p>Not to be confused with <a href="https://developers.google.com/machine-learning/glossary#rank_ordinality"><strong>rank (ordinality)</strong></a>.</p>

<p><a class="glossary-anchor" name="rater"></a>
</p><h2 class="hide-from-toc" id="rater" data-text=" rater"> rater</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A human who provides <a href="https://developers.google.com/machine-learning/glossary#label"><strong>labels</strong></a> for <a href="https://developers.google.com/machine-learning/glossary#example"><strong>examples</strong></a>.
"Annotator" is another name for rater.</p>

<p><a class="glossary-anchor" name="recall"></a>
</p><h2 class="hide-from-toc" id="recall" data-text=" recall"> recall</h2><p></p>

<p>A metric for <a href="https://developers.google.com/machine-learning/glossary#classification_model"><strong>classification models</strong></a> that answers
the following question:</p>

<blockquote>
<p>When <a href="https://developers.google.com/machine-learning/glossary#ground_truth"><strong>ground truth</strong></a> was the
<a href="https://developers.google.com/machine-learning/glossary#positive_class"><strong>positive class</strong></a>, what percentage of predictions did
the model correctly identify as the positive class?</p>
</blockquote>

<p>Here is the formula:</p>

<p><span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-57-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Recall&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtext&gt;true positives&lt;/mtext&gt;&lt;mrow&gt;&lt;mtext&gt;true positives&lt;/mtext&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;false negatives&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="40.902ex" height="5.571ex" viewBox="0 -1428.7 17610.5 2398.8" role="img" focusable="false" style="vertical-align: -2.253ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-52"></use><use href="#MJMAIN-65" x="736" y="0"></use><use href="#MJMAIN-63" x="1181" y="0"></use><use href="#MJMAIN-61" x="1625" y="0"></use><use href="#MJMAIN-6C" x="2126" y="0"></use><use href="#MJMAIN-6C" x="2404" y="0"></use><use href="#MJMAIN-3D" x="2960" y="0"></use><g transform="translate(3739,0)"><g transform="translate(397,0)"><rect stroke="none" width="13353" height="60" x="0" y="220"></rect><g transform="translate(3777,676)"><use href="#MJMAIN-74"></use><use href="#MJMAIN-72" x="389" y="0"></use><use href="#MJMAIN-75" x="782" y="0"></use><use href="#MJMAIN-65" x="1338" y="0"></use><use href="#MJMAIN-70" x="2033" y="0"></use><use href="#MJMAIN-6F" x="2589" y="0"></use><use href="#MJMAIN-73" x="3090" y="0"></use><use href="#MJMAIN-69" x="3484" y="0"></use><use href="#MJMAIN-74" x="3763" y="0"></use><use href="#MJMAIN-69" x="4152" y="0"></use><use href="#MJMAIN-76" x="4431" y="0"></use><use href="#MJMAIN-65" x="4959" y="0"></use><use href="#MJMAIN-73" x="5404" y="0"></use></g><g transform="translate(60,-686)"><use href="#MJMAIN-74"></use><use href="#MJMAIN-72" x="389" y="0"></use><use href="#MJMAIN-75" x="782" y="0"></use><use href="#MJMAIN-65" x="1338" y="0"></use><use href="#MJMAIN-70" x="2033" y="0"></use><use href="#MJMAIN-6F" x="2589" y="0"></use><use href="#MJMAIN-73" x="3090" y="0"></use><use href="#MJMAIN-69" x="3484" y="0"></use><use href="#MJMAIN-74" x="3763" y="0"></use><use href="#MJMAIN-69" x="4152" y="0"></use><use href="#MJMAIN-76" x="4431" y="0"></use><use href="#MJMAIN-65" x="4959" y="0"></use><use href="#MJMAIN-73" x="5404" y="0"></use><use href="#MJMAIN-2B" x="6020" y="0"></use><g transform="translate(7021,0)"><use href="#MJMAIN-66"></use><use href="#MJMAIN-61" x="306" y="0"></use><use href="#MJMAIN-6C" x="807" y="0"></use><use href="#MJMAIN-73" x="1085" y="0"></use><use href="#MJMAIN-65" x="1480" y="0"></use><use href="#MJMAIN-6E" x="2174" y="0"></use><use href="#MJMAIN-65" x="2731" y="0"></use><use href="#MJMAIN-67" x="3175" y="0"></use><use href="#MJMAIN-61" x="3676" y="0"></use><use href="#MJMAIN-74" x="4176" y="0"></use><use href="#MJMAIN-69" x="4566" y="0"></use><use href="#MJMAIN-76" x="4844" y="0"></use><use href="#MJMAIN-65" x="5373" y="0"></use><use href="#MJMAIN-73" x="5817" y="0"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Recall</mtext><mo>=</mo><mfrac><mtext>true positives</mtext><mrow><mtext>true positives</mtext><mo>+</mo><mtext>false negatives</mtext></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-57">\text{Recall} =
\frac{\text{true positives}} {\text{true positives} + \text{false negatives}}
</script></p>

<p>where:</p>

<ul>
<li>true positive means the model <em>correctly</em> predicted the positive class.</li>
<li>false negative means that the model <em>mistakenly</em> predicted the
<a href="https://developers.google.com/machine-learning/glossary#negative_class"><strong>negative class</strong></a>.</li>
</ul>

<p>For instance, suppose your model made 200 predictions on examples for which
ground truth was the positive class. Of these 200 predictions:</p>

<ul>
<li>180 were true positives.</li>
<li>20 were false negatives.</li>
</ul>

<p>In this case:</p>

<p><span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-58-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Recall&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtext&gt;180&lt;/mtext&gt;&lt;mrow&gt;&lt;mtext&gt;180&lt;/mtext&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;20&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.9&lt;/mn&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="24.889ex" height="5.335ex" viewBox="0 -1428.7 10716.1 2296.9" role="img" focusable="false" style="vertical-align: -2.016ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-52"></use><use href="#MJMAIN-65" x="736" y="0"></use><use href="#MJMAIN-63" x="1181" y="0"></use><use href="#MJMAIN-61" x="1625" y="0"></use><use href="#MJMAIN-6C" x="2126" y="0"></use><use href="#MJMAIN-6C" x="2404" y="0"></use><use href="#MJMAIN-3D" x="2960" y="0"></use><g transform="translate(3739,0)"><g transform="translate(397,0)"><rect stroke="none" width="3845" height="60" x="0" y="220"></rect><g transform="translate(1171,676)"><use href="#MJMAIN-31"></use><use href="#MJMAIN-38" x="500" y="0"></use><use href="#MJMAIN-30" x="1001" y="0"></use></g><g transform="translate(60,-686)"><use href="#MJMAIN-31"></use><use href="#MJMAIN-38" x="500" y="0"></use><use href="#MJMAIN-30" x="1001" y="0"></use><use href="#MJMAIN-2B" x="1723" y="0"></use><g transform="translate(2724,0)"><use href="#MJMAIN-32"></use><use href="#MJMAIN-30" x="500" y="0"></use></g></g></g></g><use href="#MJMAIN-3D" x="8380" y="0"></use><g transform="translate(9436,0)"><use href="#MJMAIN-30"></use><use href="#MJMAIN-2E" x="500" y="0"></use><use href="#MJMAIN-39" x="779" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Recall</mtext><mo>=</mo><mfrac><mtext>180</mtext><mrow><mtext>180</mtext><mo>+</mo><mtext>20</mtext></mrow></mfrac><mo>=</mo><mn>0.9</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-58">\text{Recall} =
\frac{\text{180}} {\text{180} + \text{20}} = 0.9
</script></p>

<devsite-expandable is-upgraded="" id="expandable-30"><a class="exw-control" aria-controls="expandable-30" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-notes-about-class-imbalanced-datasets." data-text=" Click the icon for notes about class-imbalanced datasets. ">
Click the icon for notes about class-imbalanced datasets.
</h4></a>



<div class="expand-background">
<p>
Recall is particularly useful for determining the predictive power of
classification models in which the positive class is rare. For example, consider
a <a href="https://developers.google.com/machine-learning/glossary#class_imbalanced_data_set"><b>class-imbalanced dataset</b></a>
in which the positive class for a certain disease occurs in only 10 patients
out of a million. Suppose your model makes five million predictions that yield
the following outcomes:

</p><ul>
  <li>30 True Positives</li>
  <li>20 False Negatives</li>
  <li>4,999,000 True Negatives</li>
  <li>950 False Positives</li>
</ul>

<p>The recall of this model is therefore:</p>

<devsite-code no-copy="" data-copy-event-label=""><pre translate="no" dir="ltr" is-upgraded="">recall = TP / (TP + FN)
recall = 30 / (30 + 20) = 0.6 = 60%
</pre></devsite-code>

By contrast, the <a href="https://developers.google.com/machine-learning/glossary#accuracy">accuracy</a> of this model is:

<devsite-code no-copy="" data-copy-event-label=""><pre translate="no" dir="ltr" is-upgraded="">accuracy = (TP + TN) / (TP + TN + FP + FN)
accuracy = (30 + 4,999,000) / (30 + 4,999,000 + 950 + 20) = 99.98%
</pre></devsite-code>

<p>
That high value of accuracy looks impressive but is essentially meaningless.
Recall is a much more useful metric for class-imbalanced datasets than accuracy.
</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="recommendation_system"></a>
</p><h2 class="hide-from-toc" id="recommendation-system" data-text=" recommendation system"> recommendation system</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Recommendation Systems">#recsystems</div>
</div><p></p>

<p>A system that selects for each user a relatively small set of desirable
<a href="https://developers.google.com/machine-learning/glossary#items"><strong>items</strong></a> from a large corpus.
For example, a video recommendation system might recommend two videos
from a corpus of 100,000 videos, selecting <em>Casablanca</em> and
<em>The Philadelphia Story</em> for one user, and <em>Wonder Woman</em> and
<em>Black Panther</em> for another. A video recommendation system might
base its recommendations on factors such as:</p>

<ul>
<li>Movies that similar users have rated or watched.</li>
<li>Genre, directors, actors, target demographic...</li>
</ul>

<p><a class="glossary-anchor" name="Rectified-Linear-Unit"></a>
<a class="glossary-anchor" name="ReLU"></a>
</p><h2 class="hide-from-toc" id="rectified-linear-unit-relu" data-text=" Rectified Linear Unit (ReLU)"> Rectified Linear Unit (ReLU)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>An <a href="https://developers.google.com/machine-learning/glossary#activation_function"><strong>activation function</strong></a> with the following behavior:</p>

<ul>
<li>If input is negative or zero, then the output is 0.</li>
<li>If input is positive, then the output is equal to the input.</li>
</ul>

<p>For example:</p>

<ul>
<li>If the input is -3, then the output is 0.</li>
<li>If the input is +3, then the output is 3.0.</li>
</ul>

<p>Here is a plot of ReLU:</p>

<p>
<img src="./ML_Glossary_files/ReLU.png" loading="lazy" alt="A cartesian plot of two lines. The first line has a constant
          y value of 0, running along the x-axis from -infinity,0 to 0,-0.
          The second line starts at 0,0. This line has a slope of +1, so
          it runs from 0,0 to +infinity,+infinity.">
</p>

<p>ReLU is a very popular activation function. Despite its simple behavior,
ReLU still enables a neural network to learn <a href="https://developers.google.com/machine-learning/glossary#nonlinear"><strong>nonlinear</strong></a>
relationships between <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>features</strong></a> and the <a href="https://developers.google.com/machine-learning/glossary#label"><strong>label</strong></a>.</p>

<p><a class="glossary-anchor" name="recurrent_neural_network"></a>
</p><h2 class="hide-from-toc" id="recurrent-neural-network" data-text=" recurrent neural network "> recurrent neural network </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Sequence Models">#seq</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural network</strong></a> that is intentionally run multiple
times, where parts of each run feed into the next run. Specifically,
hidden layers from the previous run provide part of the
input to the same hidden layer in the next run. Recurrent neural networks
are particularly useful for evaluating sequences, so that the hidden layers
can learn from previous runs of the neural network on earlier parts of
the sequence.</p>

<p>For example, the following figure shows a recurrent neural network that
runs four times. Notice that the values learned in the hidden layers from
the first run become part of the input to the same hidden layers in
the second run. Similarly, the values learned in the hidden layer on the
second run become part of the input to the same hidden layer in the
third run. In this way, the recurrent neural network gradually trains and
predicts the meaning of the entire sequence rather than just the meaning
of individual words.</p>

<p>
<img src="./ML_Glossary_files/RNN.svg" height="500" width="545" loading="lazy" alt="An RNN that runs four times to process four input words.">
</p>

<p><a class="glossary-anchor" name="regression_model"></a>
</p><h2 class="hide-from-toc" id="regression-model" data-text=" regression model"> regression model</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Informally, a model that generates a numerical prediction. (In contrast,
a <a href="https://developers.google.com/machine-learning/glossary#classification_model"><strong>classification model</strong></a> generates a class
prediction.)  For example, the following are all regression models:</p>

<ul>
<li>A model that predicts a certain house's value, such as 423,000 Euros.</li>
<li>A model that predicts a certain tree's life expectancy, such as 23.2 years.</li>
<li>A model that predicts the amount of rain that will fall in a certain city
over the next six hours, such as 0.18 inches.</li>
</ul>

<p>Two common types of regression models are:</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#linear_regression"><strong>Linear regression</strong></a>, which finds the line that best
fits label values to features.</li>
<li><a href="https://developers.google.com/machine-learning/glossary#logistic_regression"><strong>Logistic regression</strong></a>, which generates a
probability between 0.0 and 1.0 that a system typically then maps to a class
prediction.</li>
</ul>

<p>Not every model that outputs numerical predictions is a regression model.
In some cases, a numeric prediction is really just a classification model
that happens to have numeric class names. For example, a model that predicts
a numeric postal code is a classification model, not a regression model.</p>

<p><a class="glossary-anchor" name="regularization"></a>
</p><h2 class="hide-from-toc" id="regularization" data-text=" regularization" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> regularization</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  regularization" data-title="Copy link to this section:  regularization" data-id="regularization"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Any mechanism that reduces <a href="https://developers.google.com/machine-learning/glossary#overfitting"><strong>overfitting</strong></a>.
Popular types of regularization include:</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#L1_regularization"><strong>L<sub>1</sub> regularization</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#L2_regularization"><strong>L<sub>2</sub> regularization</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#dropout_regularization"><strong>dropout regularization</strong></a></li>
<li><a href="https://developers.google.com/machine-learning/glossary#early_stopping"><strong>early stopping</strong></a> (this is not a formal
regularization method, but can effectively limit overfitting)</li>
</ul>

<p>Regularization can also be defined as the penalty on a model's complexity.</p>

<devsite-expandable is-upgraded="" id="expandable-31"><a class="exw-control" aria-controls="expandable-31" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-additional-notes._13" data-text=" Click the icon for additional notes. " role="presentation"><span class="devsite-heading" role="heading" aria-level="4">
Click the icon for additional notes.<wbr>
</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: 
Click the icon for additional notes.
" data-title="Copy link to this section: 
Click the icon for additional notes.
" data-id="click-the-icon-for-additional-notes._13"></button></h4></a>



<div class="expand-background">
<p>
Regularization is counterintuitive. Increasing regularization usually
<i>increases</i> training loss, which is confusing because, well, isn't
the goal to <i>minimize</i> training loss?
</p>

<p>
Actually, no. The goal isn't to minimize training loss. The goal is to
make excellent predictions on real-world examples.  Remarkably, even though
increasing regularization increases training loss, it usually helps models make
better predictions on real-world examples.
</p>

<p>

</p></div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="regularization_rate"></a>
</p><h2 class="hide-from-toc" id="regularization-rate" data-text=" regularization rate" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> regularization rate</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  regularization rate" data-title="Copy link to this section:  regularization rate" data-id="regularization-rate"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A number that specifies the relative importance of
<a href="https://developers.google.com/machine-learning/glossary#regularization"><strong>regularization</strong></a> during training. Raising the
regularization rate reduces <a href="https://developers.google.com/machine-learning/glossary#overfitting"><strong>overfitting</strong></a> but may
reduce the model's predictive power. Conversely, reducing or omitting
the regularization rate increases overfitting.</p>

<devsite-expandable is-upgraded="" id="expandable-32"><a class="exw-control" aria-controls="expandable-32" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-to-see-the-math._3" data-text=" Click the icon to see the math. ">
Click the icon to see the math.<wbr>
</h4></a>



<div class="expand-background">
<p>
The regularization rate is usually represented as the Greek letter lambda.
The following simplified <a href="https://developers.google.com/machine-learning/glossary#loss"><b>loss</b></a> equation shows
lambda's influence:
</p>

<p>
</p><div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-59-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;minimize(loss function +&amp;#xA0;&lt;/mtext&gt;&lt;mi&gt;&amp;#x03BB;&lt;/mi&gt;&lt;mtext&gt;(regularization))&lt;/mtext&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="43.639ex" height="2.613ex" viewBox="0 -817.3 18789 1125" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-6D"></use><use href="#MJMAIN-69" x="833" y="0"></use><use href="#MJMAIN-6E" x="1112" y="0"></use><use href="#MJMAIN-69" x="1668" y="0"></use><use href="#MJMAIN-6D" x="1947" y="0"></use><use href="#MJMAIN-69" x="2780" y="0"></use><use href="#MJMAIN-7A" x="3059" y="0"></use><use href="#MJMAIN-65" x="3503" y="0"></use><use href="#MJMAIN-28" x="3948" y="0"></use><use href="#MJMAIN-6C" x="4337" y="0"></use><use href="#MJMAIN-6F" x="4616" y="0"></use><use href="#MJMAIN-73" x="5116" y="0"></use><use href="#MJMAIN-73" x="5511" y="0"></use><use href="#MJMAIN-66" x="6155" y="0"></use><use href="#MJMAIN-75" x="6462" y="0"></use><use href="#MJMAIN-6E" x="7018" y="0"></use><use href="#MJMAIN-63" x="7575" y="0"></use><use href="#MJMAIN-74" x="8019" y="0"></use><use href="#MJMAIN-69" x="8409" y="0"></use><use href="#MJMAIN-6F" x="8687" y="0"></use><use href="#MJMAIN-6E" x="9188" y="0"></use><use href="#MJMAIN-2B" x="9994" y="0"></use><use href="#MJMATHI-3BB" x="11023" y="0"></use><g transform="translate(11606,0)"><use href="#MJMAIN-28"></use><use href="#MJMAIN-72" x="389" y="0"></use><use href="#MJMAIN-65" x="782" y="0"></use><use href="#MJMAIN-67" x="1226" y="0"></use><use href="#MJMAIN-75" x="1727" y="0"></use><use href="#MJMAIN-6C" x="2283" y="0"></use><use href="#MJMAIN-61" x="2562" y="0"></use><use href="#MJMAIN-72" x="3062" y="0"></use><use href="#MJMAIN-69" x="3455" y="0"></use><use href="#MJMAIN-7A" x="3733" y="0"></use><use href="#MJMAIN-61" x="4178" y="0"></use><use href="#MJMAIN-74" x="4678" y="0"></use><use href="#MJMAIN-69" x="5068" y="0"></use><use href="#MJMAIN-6F" x="5346" y="0"></use><use href="#MJMAIN-6E" x="5847" y="0"></use><use href="#MJMAIN-29" x="6403" y="0"></use><use href="#MJMAIN-29" x="6793" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>minimize(loss function +&nbsp;</mtext><mi>λ</mi><mtext>(regularization))</mtext></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-59">\text{minimize(loss function + }\lambda\text{(regularization))}</script>
</div>
<p></p>

where <i>regularization</i> is any regularization mechanism, including;

<ul>
 <li><a href="https://developers.google.com/machine-learning/glossary#L1_regularization"><b>L<sub>1</sub> regularization</b></a></li>
 <li><a href="https://developers.google.com/machine-learning/glossary#L2_regularization"><b>L<sub>2</sub> regularization</b></a></li>
</ul>


<p>
</p></div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="reinforcement_learning"></a>
</p><h2 class="hide-from-toc" id="reinforcement-learning-rl" data-text=" reinforcement learning (RL)"> reinforcement learning (RL)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>A family of algorithms that learn an optimal <a href="https://developers.google.com/machine-learning/glossary#policy"><strong>policy</strong></a>, whose goal
is to maximize <a href="https://developers.google.com/machine-learning/glossary#return"><strong>return</strong></a> when interacting with
an <a href="https://developers.google.com/machine-learning/glossary#environment"><strong>environment</strong></a>.
For example, the ultimate reward of most games is victory.
Reinforcement learning systems can become expert at playing complex
games by evaluating sequences of previous game moves that ultimately
led to wins and sequences that ultimately led to losses.</p>

<p><a class="glossary-anchor" name="ReLU"></a>
</p><h2 class="hide-from-toc" id="relu" data-text=" ReLU"> ReLU</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Abbreviation for <a href="https://developers.google.com/machine-learning/glossary#ReLU"><strong>Rectified Linear Unit</strong></a>.</p>

<p><a class="glossary-anchor" name="replay_buffer"></a>
</p><h2 class="hide-from-toc" id="replay-buffer" data-text=" replay buffer"> replay buffer</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#deep_q-network"><strong>DQN</strong></a>-like algorithms, the memory used by the agent
to store state transitions for use in
<a href="https://developers.google.com/machine-learning/glossary#experience_replay"><strong>experience replay</strong></a>.</p>

<p><a class="glossary-anchor" name="reporting_bias"></a>
</p><h2 class="hide-from-toc" id="reporting-bias" data-text=" reporting bias "> reporting bias </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>The fact that the frequency with which people write about actions,
outcomes, or properties is not a reflection of their real-world
frequencies or the degree to which a property is characteristic
of a class of individuals. Reporting bias can influence the composition
of data that machine learning systems learn from.</p>

<p>For example, in books, the word <em>laughed</em> is more prevalent than
<em>breathed</em>.  A machine learning model that estimates the relative frequency of
laughing and breathing from a book corpus would probably determine
that laughing is more common than breathing.</p>

<p><a class="glossary-anchor" name="representation"></a>
</p><h2 class="hide-from-toc" id="representation" data-text=" representation"> representation</h2><p></p>

<p>The process of mapping data to useful <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>features</strong></a>.</p>

<p><a class="glossary-anchor" name="re-ranking"></a>
</p><h2 class="hide-from-toc" id="re-ranking" data-text=" re-ranking"> re-ranking</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Recommendation Systems">#recsystems</div>
</div><p></p>

<p>The final stage of a <a href="https://developers.google.com/machine-learning/glossary#recommendation_system"><strong>recommendation system</strong></a>,
during which scored items may be re-graded according to some other
(typically, non-ML) algorithm. Re-ranking evaluates the list of items
generated by the <a href="https://developers.google.com/machine-learning/glossary#scoring"><strong>scoring</strong></a> phase, taking actions such as:</p>

<ul>
<li>Eliminating items that the user has already purchased.</li>
<li>Boosting the score of fresher items.</li>
</ul>

<p><a class="glossary-anchor" name="return"></a>
</p><h2 class="hide-from-toc" id="return" data-text=" return"> return</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In reinforcement learning, given a certain policy and a certain state, the
return is the sum of all <a href="https://developers.google.com/machine-learning/glossary#reward"><strong>rewards</strong></a> that the <a href="https://developers.google.com/machine-learning/glossary#agent"><strong>agent</strong></a>
expects to receive when following the <a href="https://developers.google.com/machine-learning/glossary#policy"><strong>policy</strong></a> from the
<a href="https://developers.google.com/machine-learning/glossary#state"><strong>state</strong></a> to the end of the <a href="https://developers.google.com/machine-learning/glossary#episode"><strong>episode</strong></a>. The agent
accounts for the delayed nature of expected rewards by discounting rewards
according to the state transitions required to obtain the reward.</p>

<p>Therefore, if the discount factor is <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-60-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;&amp;#x03B3;&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.262ex" height="1.903ex" viewBox="0 -511.5 543.5 819.3" role="img" focusable="false" style="vertical-align: -0.715ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-3B3" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>γ</mi></math></span></span><script type="math/tex" id="MathJax-Element-60">\gamma</script>, and <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-61-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo&gt;&amp;#x2026;&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.021ex" height="1.784ex" viewBox="0 -511.5 4314.7 768.3" role="img" focusable="false" style="vertical-align: -0.596ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-72" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-30" x="638" y="-213"></use><use href="#MJMAIN-2C" x="905" y="0"></use><use href="#MJMAIN-2026" x="1350" y="0"></use><use href="#MJMAIN-2C" x="2689" y="0"></use><g transform="translate(3134,0)"><use href="#MJMATHI-72" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-4E" x="638" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>r</mi><mn>0</mn></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>N</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-61">r_0, \ldots, r_{N}</script>
denote the rewards until the end of the episode, then the return calculation
is as follows:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-62-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Return&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;&amp;#x03B3;&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;&amp;#x03B3;&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;msub&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo&gt;&amp;#x2026;&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;&amp;#x03B3;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;msub&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="44.145ex" height="2.968ex" viewBox="0 -970.1 19006.9 1277.8" role="img" focusable="false" style="vertical-align: -0.715ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-52"></use><use href="#MJMAIN-65" x="736" y="0"></use><use href="#MJMAIN-74" x="1181" y="0"></use><use href="#MJMAIN-75" x="1570" y="0"></use><use href="#MJMAIN-72" x="2127" y="0"></use><use href="#MJMAIN-6E" x="2519" y="0"></use><use href="#MJMAIN-3D" x="3353" y="0"></use><g transform="translate(4410,0)"><use href="#MJMATHI-72" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-30" x="638" y="-213"></use></g><use href="#MJMAIN-2B" x="5537" y="0"></use><use href="#MJMATHI-3B3" x="6538" y="0"></use><g transform="translate(7081,0)"><use href="#MJMATHI-72" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="638" y="-213"></use></g><use href="#MJMAIN-2B" x="8209" y="0"></use><g transform="translate(9210,0)"><use href="#MJMATHI-3B3" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="779" y="583"></use></g><g transform="translate(10215,0)"><use href="#MJMATHI-72" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="638" y="-213"></use></g><use href="#MJMAIN-2B" x="11342" y="0"></use><use href="#MJMAIN-2026" x="12343" y="0"></use><use href="#MJMAIN-2B" x="13738" y="0"></use><g transform="translate(14739,0)"><use href="#MJMATHI-3B3" x="0" y="0"></use><g transform="translate(551,412)"><use transform="scale(0.707)" href="#MJMATHI-4E" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2212" x="888" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="1667" y="0"></use></g></g><g transform="translate(16922,0)"><use href="#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" href="#MJMATHI-4E" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2212" x="888" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="1667" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Return</mtext><mo>=</mo><msub><mi>r</mi><mn>0</mn></msub><mo>+</mo><mi>γ</mi><msub><mi>r</mi><mn>1</mn></msub><mo>+</mo><msup><mi>γ</mi><mn>2</mn></msup><msub><mi>r</mi><mn>2</mn></msub><mo>+</mo><mo>…</mo><mo>+</mo><msup><mi>γ</mi><mrow class="MJX-TeXAtom-ORD"><mi>N</mi><mo>−</mo><mn>1</mn></mrow></msup><msub><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>N</mi><mo>−</mo><mn>1</mn></mrow></msub></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-62">\text{Return} = r_0 + \gamma r_1 + \gamma^2 r_2 + \ldots + \gamma^{N-1} r_{N-1}</script>
</div>

<p><a class="glossary-anchor" name="reward"></a>
</p><h2 class="hide-from-toc" id="reward" data-text=" reward"> reward</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In reinforcement learning, the numerical result of taking an
<a href="https://developers.google.com/machine-learning/glossary#action"><strong>action</strong></a> in a <a href="https://developers.google.com/machine-learning/glossary#state"><strong>state</strong></a>, as defined by
the <a href="https://developers.google.com/machine-learning/glossary#environment"><strong>environment</strong></a>.</p>

<p><a class="glossary-anchor" name="ridge_regularization"></a>
</p><h2 class="hide-from-toc" id="ridge-regularization" data-text=" ridge regularization"> ridge regularization</h2><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#L2_regularization"><strong>L<sub>2</sub> regularization</strong></a>. The term
<strong>ridge regularization</strong> is more frequently used in pure statistics
contexts, whereas <strong>L<sub>2</sub> regularization</strong> is used more often
in machine learning.</p>

<p><a class="glossary-anchor" name="RNN"></a>
</p><h2 class="hide-from-toc" id="rnn" data-text=" RNN"> RNN</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Sequence Models">#seq</div>
</div><p></p>

<p>Abbreviation for <a href="https://developers.google.com/machine-learning/glossary#recurrent_neural_network"><strong>recurrent neural networks</strong></a>.</p>

<p><a class="glossary-anchor" name="ROC"></a>
</p><h2 class="hide-from-toc" id="roc-receiver-operating-characteristic-curve" data-text=" ROC (receiver operating characteristic) Curve"> ROC (receiver operating characteristic) Curve</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A graph of <a href="https://developers.google.com/machine-learning/glossary#TP_rate"><strong>true positive rate</strong></a> vs.
<a href="https://developers.google.com/machine-learning/glossary#FP_rate"><strong>false positive rate</strong></a> for different
<a href="https://developers.google.com/machine-learning/glossary#classification_threshold"><strong>classification thresholds</strong></a> in binary
classification.</p>

<p>The shape of an ROC curve suggests a binary classification model's ability
to separate positive classes from negative classes. Suppose, for example,
that a binary classification model perfectly separates all the negative
classes from all the positive classes:</p>

<p>
<img src="./ML_Glossary_files/ROCSetupIdealDistributionNoClassificationThreshold.png" loading="lazy" alt="A number line with 8 positive examples on the right side and
          7 negative examples on the left.">
</p>

<p>The ROC curve for the preceding model looks as follows:</p>

<p>
<img src="./ML_Glossary_files/ROCcurvePerfect.png" loading="lazy" alt="An ROC curve. The x-axis is False Positive Rate and the y-axis
          is True Positive Rate. The curve has an inverted L shape. The curve
          starts at (0.0,0.0) and goes straight up to (0.0,1.0). Then the curve
          goes from (0.0,1.0) to (1.0,1.0).">
</p>

<p>In contrast, the following illustration graphs the raw logistic regression
values for a terrible model that can't separate negative classes from
positive classes at all:</p>

<p>
<img src="./ML_Glossary_files/ROCWorstCaseDistribution.png" loading="lazy" alt="A number line with positive examples and negative classes
          completely intermixed.">
</p>

<p>The ROC curve for this model looks as follows:</p>

<p>
<img src="./ML_Glossary_files/ROCcurveWorstCase.png" loading="lazy" alt="An ROC curve, which is actually a straight line from (0.0,0.0)
          to (1.0,1.0).">
</p>

<p>Meanwhile, back in the real world, most binary classification models separate
positive and negative classes to some degree, but usually not perfectly. So,
a typical ROC curve falls somewhere between the two extremes:</p>

<p>
<img src="./ML_Glossary_files/ROCTypicalGraph.png" loading="lazy" alt="An ROC curve. The x-axis is False Positive Rate and the y-axis
          is True Positive Rate. The ROC curve approximates a shaky arc
          traversing the compass points from West to North.">
</p>

<p>The point on an ROC curve closest to (0.0,1.0) theoretically identifies the
ideal classification threshold. However, several other real-world issues
influence the selection of the ideal classification threshold. For example,
perhaps false negatives cause far more pain than false positives.</p>

<p>A numerical metric called <a href="https://developers.google.com/machine-learning/glossary#AUC"><strong>AUC</strong></a> summarizes the ROC curve into
a single floating-point value.</p>

<p><a class="glossary-anchor" name="root"></a>
</p><h2 class="hide-from-toc" id="root" data-text=" root "> root </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>The starting <a href="https://developers.google.com/machine-learning/glossary#node-decision-tree"><strong>node</strong></a> (the first
<a href="https://developers.google.com/machine-learning/glossary#condition"><strong>condition</strong></a>) in a <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a>.
By convention, diagrams put the root at the top of the decision tree.
For example:</p>

<p>
<img src="./ML_Glossary_files/root.png" loading="lazy" height="250" width="344" alt="A decision tree with two conditions and three leaves. The
          starting condition (x &gt; 2) is the root.">
</p>

<p><a class="glossary-anchor" name="root_directory"></a>
</p><h2 class="hide-from-toc" id="root-directory" data-text=" root directory"> root directory</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>The directory you specify for hosting subdirectories of the TensorFlow
checkpoint and events files of multiple models.</p>

<p><a class="glossary-anchor" name="RMSE"></a>
</p><h2 class="hide-from-toc" id="root-mean-squared-error-rmse" data-text=" Root Mean Squared Error (RMSE)"> Root Mean Squared Error (RMSE)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The square root of the <a href="https://developers.google.com/machine-learning/glossary#MSE"><strong>Mean Squared Error</strong></a>.</p>

<p><a class="glossary-anchor" name="rotational_invariance"></a>
</p><h2 class="hide-from-toc" id="rotational-invariance" data-text=" rotational invariance"> rotational invariance</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>In an image classification problem, an algorithm's ability to successfully
classify images even when the orientation of the image changes. For example,
the algorithm can still identify a tennis racket whether it is pointing up,
sideways, or down. Note that rotational invariance is not always desirable;
for example, an upside-down 9 should not be classified as a 9.</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#translational_invariance"><strong>translational invariance</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#size_invariance"><strong>size invariance</strong></a>.</p>

<p><a class="glossary-anchor" name="s"></a>
</p><h2 class="glossary" id="s" data-text="S" role="presentation"><span class="devsite-heading" role="heading" aria-level="2">S</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: S" data-title="Copy link to this section: S" data-id="s"></button></h2><p></p>

<p><a class="glossary-anchor" name="sampling_bias"></a>
</p><h2 class="hide-from-toc" id="sampling-bias" data-text=" sampling bias " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> sampling bias </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  sampling bias " data-title="Copy link to this section:  sampling bias " data-id="sampling-bias"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>See <a href="https://developers.google.com/machine-learning/glossary#selection_bias"><strong>selection bias</strong></a>.</p>

<p><a class="glossary-anchor" name="sampling-with-replacement"></a>
</p><h2 class="hide-from-toc" id="sampling-with-replacement" data-text=" sampling with replacement " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> sampling with replacement </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  sampling with replacement " data-title="Copy link to this section:  sampling with replacement " data-id="sampling-with-replacement"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>A method of picking items from a set of candidate items in which the same
item can be picked multiple times. The phrase "with replacement" means
that after each selection, the selected item is returned to the pool
of candidate items. The inverse method, <strong>sampling without replacement</strong>,
means that a candidate item can only be picked once.</p>

<p>For example, consider the following fruit set:</p>

<devsite-code data-copy-event-label=""><div class="devsite-code-buttons-container" role="group" aria-label="Action buttons"><button type="button" class="gc-analytics-event material-icons devsite-icon-code-dark devsite-toggle-dark" data-category="Site-Wide Custom Events" data-label="Dark Code Toggle" track-type="exampleCode" track-name="darkCodeToggle" aria-label="Dark code theme" data-title="Dark code theme"></button><button type="button" class="gc-analytics-event material-icons devsite-icon-code-light devsite-toggle-light" data-category="Site-Wide Custom Events" data-label="Light Code Toggle" track-type="exampleCode" track-name="lightCodeToggle" aria-label="Light code theme" data-title="Light code theme"></button><button type="button" class="gc-analytics-event material-icons devsite-icon-copy" data-category="Site-Wide Custom Events" data-label="Click To Copy" track-type="exampleCode" track-name="clickToCopy" aria-label="Copy code sample" data-title="Copy code sample"></button></div><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="pln">fruit </span><span class="pun">=</span><span class="pln"> </span><span class="pun">{</span><span class="pln">kiwi</span><span class="pun">,</span><span class="pln"> apple</span><span class="pun">,</span><span class="pln"> pear</span><span class="pun">,</span><span class="pln"> fig</span><span class="pun">,</span><span class="pln"> cherry</span><span class="pun">,</span><span class="pln"> lime</span><span class="pun">,</span><span class="pln"> mango</span><span class="pun">}</span><span class="pln"><br></span></pre></devsite-code>

<p>Suppose that the system randomly picks <code translate="no" dir="ltr">fig</code> as the first item.
If using sampling with replacement, then the system picks the
second item from the following set:</p>

<devsite-code data-copy-event-label=""><div class="devsite-code-buttons-container" role="group" aria-label="Action buttons"><button type="button" class="gc-analytics-event material-icons devsite-icon-code-dark devsite-toggle-dark" data-category="Site-Wide Custom Events" data-label="Dark Code Toggle" track-type="exampleCode" track-name="darkCodeToggle" aria-label="Dark code theme" data-title="Dark code theme"></button><button type="button" class="gc-analytics-event material-icons devsite-icon-code-light devsite-toggle-light" data-category="Site-Wide Custom Events" data-label="Light Code Toggle" track-type="exampleCode" track-name="lightCodeToggle" aria-label="Light code theme" data-title="Light code theme"></button><button type="button" class="gc-analytics-event material-icons devsite-icon-copy" data-category="Site-Wide Custom Events" data-label="Click To Copy" track-type="exampleCode" track-name="clickToCopy" aria-label="Copy code sample" data-title="Copy code sample"></button></div><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="pln">fruit </span><span class="pun">=</span><span class="pln"> </span><span class="pun">{</span><span class="pln">kiwi</span><span class="pun">,</span><span class="pln"> apple</span><span class="pun">,</span><span class="pln"> pear</span><span class="pun">,</span><span class="pln"> fig</span><span class="pun">,</span><span class="pln"> cherry</span><span class="pun">,</span><span class="pln"> lime</span><span class="pun">,</span><span class="pln"> mango</span><span class="pun">}</span><span class="pln"><br></span></pre></devsite-code>

<p>Yes, that's the same set as before, so the system could potentially
pick <code translate="no" dir="ltr">fig</code> again.</p>

<p>If using sampling without replacement, once picked, a sample can't be
picked again.  For example, if the system randomly picks <code translate="no" dir="ltr">fig</code> as the
first sample, then <code translate="no" dir="ltr">fig</code> can't be picked again. Therefore, the system
picks the second sample from the following (reduced) set:</p>

<devsite-code data-copy-event-label=""><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="pln">fruit </span><span class="pun">=</span><span class="pln"> </span><span class="pun">{</span><span class="pln">kiwi</span><span class="pun">,</span><span class="pln"> apple</span><span class="pun">,</span><span class="pln"> pear</span><span class="pun">,</span><span class="pln"> cherry</span><span class="pun">,</span><span class="pln"> lime</span><span class="pun">,</span><span class="pln"> mango</span><span class="pun">}</span><span class="pln"><br></span></pre></devsite-code>

<devsite-expandable is-upgraded="" id="expandable-33"><a class="exw-control" aria-controls="expandable-33" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-additional-notes._14" data-text=" Click the icon for additional notes. ">
Click the icon for additional notes.<wbr>
</h4></a>



<div class="expand-background">

<p>The word <i>replacement</i> in <b>sampling with replacement</b> confuses
many people.  In English, <i>replacement</i> means "substitution."
However, <b>sampling with replacement</b> actually uses the French definition
for <i>replacement</i>, which means "putting something back."

The English word <i>replacement</i> is translated as the French
word <i>remplacement</i>.
</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="SavedModel"></a>
</p><h2 class="hide-from-toc" id="savedmodel" data-text=" SavedModel"> SavedModel</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>The recommended format for saving and recovering TensorFlow models. SavedModel
is a language-neutral, recoverable serialization format, which enables
higher-level systems and tools to produce, consume, and transform TensorFlow
models.</p>

<p>See the <a href="https://www.tensorflow.org/guide/saved_model" target="T">Saving and Restoring chapter</a>
in the TensorFlow Programmer's Guide for complete details.</p>

<p><a class="glossary-anchor" name="Saver"></a>
</p><h2 class="hide-from-toc" id="saver" data-text=" Saver"> Saver</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>A <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/Saver" target="T">TensorFlow object</a>
responsible for saving model checkpoints.</p>

<p><a class="glossary-anchor" name="scalar"></a>
</p><h2 class="hide-from-toc" id="scalar" data-text=" scalar"> scalar</h2><p></p>

<p>A single number or a single string that can be represented as a
<a href="https://developers.google.com/machine-learning/glossary#tensor"><strong>tensor</strong></a> of <a href="https://developers.google.com/machine-learning/glossary#rank"><strong>rank</strong></a> 0. For example, the following
lines of code each create one scalar in TensorFlow:</p>

<devsite-code data-copy-event-label=""><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="pln">breed </span><span class="pun">=</span><span class="pln"> tf</span><span class="pun">.</span><span class="typ">Variable</span><span class="pun">(</span><span class="str">"poodle"</span><span class="pun">,</span><span class="pln"> tf</span><span class="pun">.</span><span class="kwd">string</span><span class="pun">)</span><span class="pln"><br>temperature </span><span class="pun">=</span><span class="pln"> tf</span><span class="pun">.</span><span class="typ">Variable</span><span class="pun">(</span><span class="lit">27</span><span class="pun">,</span><span class="pln"> tf</span><span class="pun">.</span><span class="pln">int16</span><span class="pun">)</span><span class="pln"><br>precision </span><span class="pun">=</span><span class="pln"> tf</span><span class="pun">.</span><span class="typ">Variable</span><span class="pun">(</span><span class="lit">0.982375101275</span><span class="pun">,</span><span class="pln"> tf</span><span class="pun">.</span><span class="pln">float64</span><span class="pun">)</span><span class="pln"><br></span></pre></devsite-code>

<p><a class="glossary-anchor" name="scaling"></a>
</p><h2 class="hide-from-toc" id="scaling" data-text=" scaling"> scaling</h2><p></p>

<p>Any mathematical transform or technique that shifts the range of a label
and/or feature value. Some forms of scaling are very useful for transformations
like <a href="https://developers.google.com/machine-learning/glossary#normalization"><strong>normalization</strong></a>.</p>

<p>Common forms of scaling useful in Machine Learning include:</p>

<ul>
<li>linear scaling, which typically uses a combination of subtraction and
division to replace the original value with a number between -1 and +1 or
between 0 and 1.</li>
<li>logarithmic scaling, which replaces the original value with its
logarithm.</li>
<li><a href="https://developers.google.com/machine-learning/glossary#Z-score-normalization"><strong>Z-score normalization</strong></a>, which replaces the
original value with a floating-point value representing the number of
standard deviations from that feature's mean.</li>
</ul>

<p><a class="glossary-anchor" name="scikit-learn"></a>
</p><h2 class="hide-from-toc" id="scikit-learn" data-text=" scikit-learn"> scikit-learn</h2><p></p>

<p>A popular open-source machine learning platform. See
<a href="http://scikit-learn.org/" target="T">scikit-learn.org</a>.</p>

<p><a class="glossary-anchor" name="scoring"></a>
</p><h2 class="hide-from-toc" id="scoring" data-text=" scoring"> scoring</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Recommendation Systems">#recsystems</div>
</div><p></p>

<p>The part of a <a href="https://developers.google.com/machine-learning/glossary#recommendation_system"><strong>recommendation system</strong></a> that
provides a value or ranking for each item produced by the
<a href="https://developers.google.com/machine-learning/glossary#candidate_generation"><strong>candidate generation</strong></a> phase.</p>

<p><a class="glossary-anchor" name="selection_bias"></a>
</p><h2 class="hide-from-toc" id="selection-bias" data-text=" selection bias "> selection bias </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>Errors in conclusions drawn from sampled data due to a selection process
that generates systematic differences between samples observed in the data
and those not observed.  The following forms of selection bias exist:</p>

<ul>
<li><strong>coverage bias</strong>: The population represented in the dataset does not
match the population that the machine learning model is making
predictions about.</li>
<li><strong>sampling bias</strong>: Data is not collected randomly from the target group.</li>
<li><strong>non-response bias</strong> (also called <strong>participation bias</strong>): Users from
certain groups opt-out of surveys at different rates than users from
other groups.</li>
</ul>

<p>For example, suppose you are creating a machine learning model that predicts
people's enjoyment of a movie.  To collect training data,
you hand out a survey to everyone in the front row of a theater
showing the movie.  Offhand, this may sound like a reasonable way
to gather a dataset; however, this form of data collection may
introduce the following forms of selection bias:</p>

<ul>
<li>coverage bias: By sampling from a population who chose to see
the movie, your model's predictions may not generalize to people
who did not already express that level of interest in the movie.</li>
<li>sampling bias: Rather than randomly sampling from the
intended population (all the people at the movie), you sampled only
the people in the front row. It is possible that the people sitting
in the front row were more interested in the movie than those in
other rows.</li>
<li>non-response bias: In general, people with strong opinions tend
to respond to optional surveys more frequently than people with mild
opinions.  Since the movie survey is optional, the responses
are more likely to form a
<a href="https://wikipedia.org/wiki/Multimodal_distribution" target="T">bimodal distribution</a>
than a normal (bell-shaped) distribution.</li>
</ul>

<p><a class="glossary-anchor" name="self-attention"></a>
</p><h2 class="hide-from-toc" id="self-attention-also-called-self-attention-layer" data-text=" self-attention (also called self-attention layer)"> self-attention (also called self-attention layer)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A neural network layer that transforms a sequence of
embeddings (for instance, <a href="https://developers.google.com/machine-learning/glossary#token"><strong>token</strong></a> embeddings)
into another sequence of embeddings.  Each embedding in the output sequence is
constructed by integrating information from the elements of the input sequence
through an <a href="https://developers.google.com/machine-learning/glossary#attention"><strong>attention</strong></a> mechanism.</p>

<p>The <strong>self</strong> part of <strong>self-attention</strong> refers to the sequence attending to
itself rather than to some other context. Self-attention is one of the main
building blocks for <a href="https://developers.google.com/machine-learning/glossary#Transformer"><strong>Transformers</strong></a> and uses dictionary lookup
terminology, such as “query”, “key”, and “value”.</p>

<p>A self-attention layer starts with a sequence of input representations, one
for each word. The input representation for a word can be a simple
embedding. For each word in an input sequence, the network
scores the relevance of the word to every element in the whole sequence of
words. The relevance scores determine how much the word's final representation
incorporates the representations of other words.</p>

<p>For example, consider the following sentence:</p>

<blockquote>
<p>The animal didn't cross the street because it was too tired.</p>
</blockquote>

<p>The following illustration (from
<a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">Transformer: A Novel Neural Network Architecture for Language
Understanding</a>)
shows a self-attention layer's attention pattern for the pronoun <strong>it</strong>, with
the darkness of each line indicating how much each word contributes to the
representation:</p>

<p>
<img src="./ML_Glossary_files/self-attention.png" loading="lazy" alt="The following sentence appears twice: &#39;The animal didn&#39;t cross the
          street because it was too tired.&#39;  Lines connect the word &#39;it&#39; in
          one sentence to five tokens (&#39;The&#39;, &#39;animal&#39;, &#39;street&#39;, &#39;it&#39;, and
          the period) in the other sentence.  The line between &#39;it&#39; and
          &#39;animal&#39; is strongest.">
</p>

<p>The self-attention layer highlights words that are relevant to "it". In this
case, the attention layer has learned to highlight words that <strong>it</strong> might
refer to, assigning the highest weight to <strong>animal</strong>.</p>

<p>For a sequence of <em>n</em> <a href="https://developers.google.com/machine-learning/glossary#token"><strong>tokens</strong></a>, self-attention transforms a sequence
of embeddings <em>n</em> separate times, once at each position in the sequence.</p>

<p>Refer also to <a href="https://developers.google.com/machine-learning/glossary#attention"><strong>attention</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#multi-head-self-attention"><strong>multi-head self-attention</strong></a>.</p>

<p><a class="glossary-anchor" name="self-supervised-learning"></a>
</p><h2 class="hide-from-toc" id="self-supervised-learning" data-text=" self-supervised learning"> self-supervised learning</h2><p></p>

<p>A family of techniques for converting an
<a href="https://developers.google.com/machine-learning/glossary#unsupervised_machine_learning"><strong>unsupervised machine learning</strong></a> problem
into a <a href="https://developers.google.com/machine-learning/glossary#supervised_machine_learning"><strong>supervised machine learning</strong></a> problem
by creating surrogate <a href="https://developers.google.com/machine-learning/glossary#label"><strong>labels</strong></a> from
<a href="https://developers.google.com/machine-learning/glossary#unlabeled_example"><strong>unlabeled examples</strong></a>.</p>

<p>Some <a href="https://developers.google.com/machine-learning/glossary#Transformer"><strong>Transformer</strong></a>-based models such as <a href="https://developers.google.com/machine-learning/glossary#BERT"><strong>BERT</strong></a> use
self-supervised learning.</p>

<p>Self-supervised training is a
<a href="https://developers.google.com/machine-learning/glossary#semi-supervised_learning"><strong>semi-supervised learning</strong></a> approach.</p>

<p><a class="glossary-anchor" name="self-training"></a>
</p><h2 class="hide-from-toc" id="self-training" data-text=" self-training" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> self-training</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  self-training" data-title="Copy link to this section:  self-training" data-id="self-training"></button></h2><p></p>

<p>A variant of <a href="https://developers.google.com/machine-learning/glossary#self-supervised-learning"><strong>self-supervised learning</strong></a> that is
particularly useful when all of the following conditions are true:</p>

<ul>
<li>The ratio of <a href="https://developers.google.com/machine-learning/glossary#unlabeled_example"><strong>unlabeled examples</strong></a> to
<a href="https://developers.google.com/machine-learning/glossary#labeled_example"><strong>labeled examples</strong></a> in the dataset is high.</li>
<li>This is a <a href="https://developers.google.com/machine-learning/glossary#classification_model"><strong>classification</strong></a> problem.</li>
</ul>

<p>Self-training works by iterating over the following two steps until the model
stops improving:</p>

<ol>
<li>Use <a href="https://developers.google.com/machine-learning/glossary#supervised_machine_learning"><strong>supervised machine learning</strong></a> to
 train a model on the labeled examples.</li>
<li>Use the model created in Step 1 to generate predictions (labels) on the
 unlabeled examples, moving those in which there is high confidence into
 the labeled examples with the predicted label.</li>
</ol>

<p>Notice that each iteration of Step 2 adds more labeled examples for Step 1 to
train on.</p>

<p><a class="glossary-anchor" name="semi-supervised_learning"></a>
</p><h2 class="hide-from-toc" id="semi-supervised-learning" data-text=" semi-supervised learning" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> semi-supervised learning</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  semi-supervised learning" data-title="Copy link to this section:  semi-supervised learning" data-id="semi-supervised-learning"></button></h2><p></p>

<p>Training a model on data where some of the training examples have labels but
others don't. One technique for semi-supervised learning is to infer labels for
the unlabeled examples, and then to train on the inferred labels to create a new
model. Semi-supervised learning can be useful if labels are expensive to obtain
but unlabeled examples are plentiful.</p>

<p><a href="https://developers.google.com/machine-learning/glossary#self-training"><strong>Self-training</strong></a> is one technique for semi-supervised
learning.</p>

<p><a class="glossary-anchor" name="sensitive_attribute"></a>
</p><h2 class="hide-from-toc" id="sensitive-attribute" data-text=" sensitive attribute" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> sensitive attribute</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  sensitive attribute" data-title="Copy link to this section:  sensitive attribute" data-id="sensitive-attribute"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div>
A human attribute that may be given special consideration for legal,
ethical, social, or personal reasons.<p></p>

<p><a class="glossary-anchor" name="sentiment_analysis"></a>
</p><h2 class="hide-from-toc" id="sentiment-analysis" data-text=" sentiment analysis" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> sentiment analysis</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  sentiment analysis" data-title="Copy link to this section:  sentiment analysis" data-id="sentiment-analysis"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>Using statistical or machine learning algorithms to determine a group's
overall attitude—positive or negative—toward a service, product,
organization, or topic. For example, using
<a href="https://developers.google.com/machine-learning/glossary#natural_language_understanding"><strong>natural language understanding</strong></a>,
an algorithm could perform sentiment analysis on the textual feedback
from a university course to determine the degree to which students
generally liked or disliked the course.</p>

<p><a class="glossary-anchor" name="sequence_model"></a>
</p><h2 class="hide-from-toc" id="sequence-model" data-text=" sequence model"> sequence model</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Sequence Models">#seq</div>
</div><p></p>

<p>A model whose inputs have a sequential dependence. For example, predicting
the next video watched from a sequence of previously watched videos.</p>

<p><a class="glossary-anchor" name="sequence-to-sequence-task"></a>
</p><h2 class="hide-from-toc" id="sequence-to-sequence-task" data-text=" sequence-to-sequence task"> sequence-to-sequence task</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A task that converts an input sequence of <a href="https://developers.google.com/machine-learning/glossary#token"><strong>tokens</strong></a> to an output
sequence of tokens. For example, two popular kinds of sequence-to-sequence
tasks are:</p>

<ul>
<li>Translators:
<ul>
<li>Sample input sequence: "I love you."</li>
<li>Sample output sequence: "Je t'aime."</li>
</ul></li>
<li>Question answering:
<ul>
<li>Sample input sequence: "Do I need my car in New York City?"</li>
<li>Sample output sequence: "No. Please keep your car at home."</li>
</ul></li>
</ul>

<p><a class="glossary-anchor" name="serving"></a>
</p><h2 class="hide-from-toc" id="serving" data-text=" serving"> serving</h2><p></p>

<p>A synonym for <a href="https://developers.google.com/machine-learning/glossary#inference"><strong>inferring</strong></a>.</p>





<p><a class="glossary-anchor" name="shape"></a>
</p><h2 class="hide-from-toc" id="shape-tensor" data-text=" shape (Tensor)"> shape (Tensor)</h2><p></p>

<p>
The number of elements in each <b><a href="https://developers.google.com/machine-learning/glossary#dimensions">dimension</a></b> of a
tensor. The shape is represented as a list of integers. For example,
the following two-dimensional tensor has a shape of [3,4]:
</p>

<devsite-code data-copy-event-label=""><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="pun">[[</span><span class="lit">5</span><span class="pun">,</span><span class="pln"> </span><span class="lit">7</span><span class="pun">,</span><span class="pln"> </span><span class="lit">6</span><span class="pun">,</span><span class="pln"> </span><span class="lit">4</span><span class="pun">],</span><span class="pln"><br>&nbsp;</span><span class="pun">[</span><span class="lit">2</span><span class="pun">,</span><span class="pln"> </span><span class="lit">9</span><span class="pun">,</span><span class="pln"> </span><span class="lit">4</span><span class="pun">,</span><span class="pln"> </span><span class="lit">8</span><span class="pun">],</span><span class="pln"><br>&nbsp;</span><span class="pun">[</span><span class="lit">3</span><span class="pun">,</span><span class="pln"> </span><span class="lit">6</span><span class="pun">,</span><span class="pln"> </span><span class="lit">5</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">]]</span><span class="pln"><br></span></pre></devsite-code>

<p>TensorFlow uses row-major (C-style) format to represent the order of
dimensions, which is why the shape in TensorFlow is [3,4] rather than
[4,3]. In other words, in a two-dimensional TensorFlow Tensor, the shape
is [<em>number of rows</em>, <em>number of columns</em>].</p>

<p><a class="glossary-anchor" name="shrinkage"></a>
</p><h2 class="hide-from-toc" id="shrinkage" data-text=" shrinkage "> shrinkage </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#hyperparameter"><strong>hyperparameter</strong></a> in
<a href="https://developers.google.com/machine-learning/glossary#gradient-boosting"><strong>gradient boosting</strong></a> that controls
<a href="https://developers.google.com/machine-learning/glossary#overfitting"><strong>overfitting</strong></a>. Shrinkage in gradient boosting
is analogous to <a href="https://developers.google.com/machine-learning/glossary#learning_rate"><strong>learning rate</strong></a> in
<a href="https://developers.google.com/machine-learning/glossary#gradient_descent"><strong>gradient descent</strong></a>. Shrinkage is a decimal
value between 0.0 and 1.0. A lower shrinkage value reduces overfitting
more than a larger shrinkage value.</p>



<p><a class="glossary-anchor" name="sigmoid-function"></a>
</p><h2 class="hide-from-toc" id="sigmoid-function" data-text=" sigmoid function"> sigmoid function</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A mathematical function that "squishes" an input value into a constrained range,
typically 0 to 1 or -1 to +1. That is, you can pass any number (two, a million,
negative billion, whatever) to a sigmoid and the output will still be in the
constrained range.
A plot of the sigmoid activation function looks as follows:</p>

<p>
<img src="./ML_Glossary_files/sigmoid.svg" loading="lazy" alt="A two-dimensional curved plot with x values spanning the domain
          -infinity to +positive, while y values span the range almost 0 to
          almost 1. When x is 0, y is 0.5. The slope of the curve is always
          positive, with the highest slope at 0,0.5 and gradually decreasing
          slopes as the absolute value of x increases.">
</p>

<p>The sigmoid function has several uses in machine learning, including:</p>

<ul>
<li>Converting the raw output of a <a href="https://developers.google.com/machine-learning/glossary#logistic_regression"><strong>logistic regression</strong></a>
or <a href="https://developers.google.com/machine-learning/glossary#multinomial-regression"><strong>multinomial regression</strong></a> to a probability.</li>
<li>Acting as an <a href="https://developers.google.com/machine-learning/glossary#activation_function"><strong>activation function</strong></a> in some
neural networks.</li>
</ul>

<devsite-expandable is-upgraded="" id="expandable-34"><a class="exw-control" aria-controls="expandable-34" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-to-see-the-math._4" data-text=" Click the icon to see the math. ">
Click the icon to see the math.<wbr>
</h4></a>



<div class="expand-background">
<p>
The sigmoid function over an input number <i>x</i> has the following formula:
</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-63-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mtext&gt;x&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.734ex" height="5.335ex" viewBox="0 -1428.7 9788.2 2296.9" role="img" focusable="false" aria-hidden="true" style="vertical-align: -2.016ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-73" x="0" y="0"></use><use href="#MJMATHI-69" x="469" y="0"></use><use href="#MJMATHI-67" x="815" y="0"></use><use href="#MJMATHI-6D" x="1295" y="0"></use><use href="#MJMATHI-6F" x="2174" y="0"></use><use href="#MJMATHI-69" x="2659" y="0"></use><use href="#MJMATHI-64" x="3005" y="0"></use><use href="#MJMAIN-28" x="3528" y="0"></use><use href="#MJMATHI-78" x="3918" y="0"></use><use href="#MJMAIN-29" x="4490" y="0"></use><use href="#MJMAIN-3D" x="5157" y="0"></use><g transform="translate(5936,0)"><g transform="translate(397,0)"><rect stroke="none" width="3334" height="60" x="0" y="220"></rect><use href="#MJMAIN-31" x="1416" y="676"></use><g transform="translate(60,-686)"><use href="#MJMAIN-31" x="0" y="0"></use><use href="#MJMAIN-2B" x="722" y="0"></use><g transform="translate(1723,0)"><use href="#MJMATHI-65" x="0" y="0"></use><g transform="translate(466,288)"><use transform="scale(0.707)" href="#MJMAIN-2212" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-78" x="778" y="0"></use></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>o</mi><mi>i</mi><mi>d</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><mo>−</mo><mtext>x</mtext></mrow></msup></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-63">
sigmoid(x) = \frac{1}{1 + e^{-\text{x}}}
</script>
</div>

<p>
In machine learning, <i>x</i> is generally a
<a href="https://developers.google.com/machine-learning/glossary#weighted_sum"><b>weighted sum</b></a>.
</p>

</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="similarity_measure"></a>
</p><h2 class="hide-from-toc" id="similarity-measure" data-text=" similarity measure"> similarity measure</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Clustering">#clustering</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#clustering"><strong>clustering</strong></a> algorithms, the metric used to determine
how alike (how similar) any two examples are.</p>

<p><a class="glossary-anchor" name="size_invariance"></a>
</p><h2 class="hide-from-toc" id="size-invariance" data-text=" size invariance"> size invariance</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>In an image classification problem, an algorithm's ability to successfully
classify images even when the size of the image changes. For example,
the algorithm can still identify a
cat whether it consumes 2M pixels or 200K pixels. Note that even the best
image classification algorithms still have practical limits on size invariance.
For example, an algorithm (or human) is unlikely to correctly classify a
cat image consuming only 20 pixels.</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#translational_invariance"><strong>translational invariance</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#rotational_invariance"><strong>rotational invariance</strong></a>.</p>

<p><a class="glossary-anchor" name="sketching"></a>
</p><h2 class="hide-from-toc" id="sketching" data-text=" sketching" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> sketching</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  sketching" data-title="Copy link to this section:  sketching" data-id="sketching"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Clustering">#clustering</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#unsupervised_machine_learning"><strong>unsupervised machine learning</strong></a>,
a category of algorithms that perform a preliminary similarity analysis
on examples. Sketching algorithms use a
<a href="https://wikipedia.org/wiki/Locality-sensitive_hashing" target="T">
locality-sensitive hash function</a>
to identify points that are likely to be similar, and then group
them into buckets.</p>

<p>Sketching decreases the computation required for similarity calculations
on large datasets. Instead of calculating similarity for every single
pair of examples in the dataset, we calculate similarity only for each
pair of points within each bucket.</p>

<p><a class="glossary-anchor" name="softmax"></a>
</p><h2 class="hide-from-toc" id="softmax" data-text=" softmax" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> softmax</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  softmax" data-title="Copy link to this section:  softmax" data-id="softmax"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A function that determines probabilities for each possible class in a
<a href="https://developers.google.com/machine-learning/glossary#multi-class"><strong>multi-class classification model</strong></a>. The probabilities add up
to exactly 1.0. For example, the following table shows how softmax distributes
various probabilities:</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr><th>Image is a...</th> <th>Probability</th></tr>
  <tr><td>dog</td>           <td>.85</td></tr>
  <tr><td>cat</td>           <td>.13</td></tr>
  <tr><td>horse</td>         <td>.02</td></tr>
</tbody></table></div>

<p>Softmax is also called <strong>full softmax</strong>.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#candidate_sampling"><strong>candidate sampling</strong></a>.</p>

<devsite-expandable is-upgraded="" id="expandable-35"><a class="exw-control" aria-controls="expandable-35" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-to-see-the-math._5" data-text=" Click the icon to see the math. " role="presentation"><span class="devsite-heading" role="heading" aria-level="4">
Click the icon to see the math.<wbr>
</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: 
Click the icon to see the math.
" data-title="Copy link to this section: 
Click the icon to see the math.
" data-id="click-the-icon-to-see-the-math._5"></button></h4></a>



<div class="expand-background">
<p>The softmax equation is as follows:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-64-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03C3;&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mtext&gt;z&lt;/mtext&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mtext&gt;z&lt;/mtext&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="15.241ex" height="6.755ex" viewBox="0 -1428.7 6561.9 2908.3" role="img" focusable="false" aria-hidden="true" style="vertical-align: -3.437ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-3C3" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-69" x="808" y="-213"></use><use href="#MJMAIN-3D" x="1193" y="0"></use><g transform="translate(1972,0)"><g transform="translate(397,0)"><rect stroke="none" width="4072" height="60" x="0" y="220"></rect><g transform="translate(1473,676)"><use href="#MJMATHI-65" x="0" y="0"></use><g transform="translate(466,362)"><use transform="scale(0.707)" href="#MJMAIN-7A" x="0" y="0"></use><use transform="scale(0.5)" href="#MJMATHI-69" x="628" y="-213"></use></g></g><g transform="translate(60,-941)"><use href="#MJSZ1-2211" x="0" y="0"></use><g transform="translate(1056,489)"><use transform="scale(0.707)" href="#MJMATHI-6A" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-3D" x="412" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-4B" x="1191" y="0"></use></g><g transform="translate(1056,-308)"><use transform="scale(0.707)" href="#MJMATHI-6A" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-3D" x="412" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="1191" y="0"></use></g><g transform="translate(2794,0)"><use href="#MJMATHI-65" x="0" y="0"></use><g transform="translate(466,316)"><use transform="scale(0.707)" href="#MJMAIN-7A" x="0" y="0"></use><use transform="scale(0.5)" href="#MJMATHI-6A" x="628" y="-213"></use></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>σ</mi><mi>i</mi></msub><mo>=</mo><mfrac><msup><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><msub><mtext>z</mtext><mi>i</mi></msub></mrow></msup><mrow><munderover><mo>∑</mo><mrow class="MJX-TeXAtom-ORD"><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mi>j</mi><mo>=</mo><mi>K</mi></mrow></munderover><mrow class="MJX-TeXAtom-ORD"><msup><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><msub><mtext>z</mtext><mi>j</mi></msub></mrow></msup></mrow></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-64">\sigma_i = \frac{e^{\text{z}_i}} {\sum_{j=1}^{j=K} {e^{\text{z}_j}}} </script>
</div>

where:

<ul>
<li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-65-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03C3;&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.127ex" height="1.784ex" viewBox="0 -511.5 915.8 768.3" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.596ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-3C3" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMATHI-69" x="808" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>σ</mi><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-65">\sigma_i</script> is the output vector. Each element of the output vector
specifies the probability of this element. The sum of all the elements
in the output vector is 1.0. The output vector contains the same number
of elements as the input vector, <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-66-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.088ex" height="1.429ex" viewBox="0 -511.5 468.5 615.4" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.241ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-7A" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>z</mi></math></span></span><script type="math/tex" id="MathJax-Element-66">z</script>.</li>
<li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-67-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.088ex" height="1.429ex" viewBox="0 -511.5 468.5 615.4" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.241ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-7A" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>z</mi></math></span></span><script type="math/tex" id="MathJax-Element-67">z</script> is the input vector. Each element of the input vector contains
a floating-point value.</li>
<li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-68-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.066ex" height="2.021ex" viewBox="0 -766.3 889.5 870.2" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.241ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-4B" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-68">K</script> is the number of elements in the input vector (and the output
vector).</li>
</ul>

<p>For example, suppose the input vector is:</p>

<devsite-code no-copy="" data-copy-event-label=""><pre translate="no" dir="ltr" is-upgraded="">[1.2, 2.5, 1.8]
</pre></devsite-code>

<p>Therefore, softmax calculates the denominator as follows:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-69-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;denominator&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mn&gt;1.2&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mn&gt;2.5&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mn&gt;1.8&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;21.552&lt;/mn&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="41.384ex" height="2.613ex" viewBox="0 -970.1 17818.2 1125" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.36ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-64"></use><use href="#MJMAIN-65" x="556" y="0"></use><use href="#MJMAIN-6E" x="1001" y="0"></use><use href="#MJMAIN-6F" x="1557" y="0"></use><use href="#MJMAIN-6D" x="2058" y="0"></use><use href="#MJMAIN-69" x="2891" y="0"></use><use href="#MJMAIN-6E" x="3170" y="0"></use><use href="#MJMAIN-61" x="3726" y="0"></use><use href="#MJMAIN-74" x="4227" y="0"></use><use href="#MJMAIN-6F" x="4616" y="0"></use><use href="#MJMAIN-72" x="5117" y="0"></use><use href="#MJMAIN-3D" x="5787" y="0"></use><g transform="translate(6843,0)"><use href="#MJMATHI-65" x="0" y="0"></use><g transform="translate(466,412)"><use transform="scale(0.707)" href="#MJMAIN-31"></use><use transform="scale(0.707)" href="#MJMAIN-2E" x="500" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="779" y="0"></use></g></g><use href="#MJMAIN-2B" x="8537" y="0"></use><g transform="translate(9537,0)"><use href="#MJMATHI-65" x="0" y="0"></use><g transform="translate(466,412)"><use transform="scale(0.707)" href="#MJMAIN-32"></use><use transform="scale(0.707)" href="#MJMAIN-2E" x="500" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-35" x="779" y="0"></use></g></g><use href="#MJMAIN-2B" x="11231" y="0"></use><g transform="translate(12231,0)"><use href="#MJMATHI-65" x="0" y="0"></use><g transform="translate(466,412)"><use transform="scale(0.707)" href="#MJMAIN-31"></use><use transform="scale(0.707)" href="#MJMAIN-2E" x="500" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-38" x="779" y="0"></use></g></g><use href="#MJMAIN-3D" x="13980" y="0"></use><g transform="translate(15037,0)"><use href="#MJMAIN-32"></use><use href="#MJMAIN-31" x="500" y="0"></use><use href="#MJMAIN-2E" x="1001" y="0"></use><use href="#MJMAIN-35" x="1279" y="0"></use><use href="#MJMAIN-35" x="1780" y="0"></use><use href="#MJMAIN-32" x="2280" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>denominator</mtext><mo>=</mo><msup><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><mn>1.2</mn></mrow></msup><mo>+</mo><msup><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><mn>2.5</mn></mrow></msup><mo>+</mo><msup><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><mn>1.8</mn></mrow></msup><mo>=</mo><mn>21.552</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-69">\text{denominator} = e^{1.2} + e^{2.5} + e^{1.8} = 21.552</script>
</div>

<p>The softmax probability of each element is therefore:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-70-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03C3;&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mn&gt;1.2&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mn&gt;21.552&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.154&lt;/mn&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="21.17ex" height="5.453ex" viewBox="0 -1581.5 9115 2347.8" role="img" focusable="false" aria-hidden="true" style="vertical-align: -1.78ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-3C3" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="808" y="-213"></use><use href="#MJMAIN-3D" x="1303" y="0"></use><g transform="translate(2081,0)"><g transform="translate(397,0)"><rect stroke="none" width="2901" height="60" x="0" y="220"></rect><g transform="translate(714,676)"><use href="#MJMATHI-65" x="0" y="0"></use><g transform="translate(466,362)"><use transform="scale(0.707)" href="#MJMAIN-31"></use><use transform="scale(0.707)" href="#MJMAIN-2E" x="500" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="779" y="0"></use></g></g><g transform="translate(60,-686)"><use href="#MJMAIN-32"></use><use href="#MJMAIN-31" x="500" y="0"></use><use href="#MJMAIN-2E" x="1001" y="0"></use><use href="#MJMAIN-35" x="1279" y="0"></use><use href="#MJMAIN-35" x="1780" y="0"></use><use href="#MJMAIN-32" x="2280" y="0"></use></g></g></g><use href="#MJMAIN-3D" x="5778" y="0"></use><g transform="translate(6834,0)"><use href="#MJMAIN-30"></use><use href="#MJMAIN-2E" x="500" y="0"></use><use href="#MJMAIN-31" x="779" y="0"></use><use href="#MJMAIN-35" x="1279" y="0"></use><use href="#MJMAIN-34" x="1780" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>σ</mi><mn>1</mn></msub><mo>=</mo><mfrac><msup><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><mn>1.2</mn></mrow></msup><mn>21.552</mn></mfrac><mo>=</mo><mn>0.154</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-70">\sigma_1 = \frac{e^{1.2}}{21.552} = 0.154 </script>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-71-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03C3;&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mn&gt;2.5&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mn&gt;21.552&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.565&lt;/mn&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="21.17ex" height="5.453ex" viewBox="0 -1581.5 9115 2347.8" role="img" focusable="false" aria-hidden="true" style="vertical-align: -1.78ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-3C3" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="808" y="-213"></use><use href="#MJMAIN-3D" x="1303" y="0"></use><g transform="translate(2081,0)"><g transform="translate(397,0)"><rect stroke="none" width="2901" height="60" x="0" y="220"></rect><g transform="translate(714,676)"><use href="#MJMATHI-65" x="0" y="0"></use><g transform="translate(466,362)"><use transform="scale(0.707)" href="#MJMAIN-32"></use><use transform="scale(0.707)" href="#MJMAIN-2E" x="500" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-35" x="779" y="0"></use></g></g><g transform="translate(60,-686)"><use href="#MJMAIN-32"></use><use href="#MJMAIN-31" x="500" y="0"></use><use href="#MJMAIN-2E" x="1001" y="0"></use><use href="#MJMAIN-35" x="1279" y="0"></use><use href="#MJMAIN-35" x="1780" y="0"></use><use href="#MJMAIN-32" x="2280" y="0"></use></g></g></g><use href="#MJMAIN-3D" x="5778" y="0"></use><g transform="translate(6834,0)"><use href="#MJMAIN-30"></use><use href="#MJMAIN-2E" x="500" y="0"></use><use href="#MJMAIN-35" x="779" y="0"></use><use href="#MJMAIN-36" x="1279" y="0"></use><use href="#MJMAIN-35" x="1780" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>σ</mi><mn>2</mn></msub><mo>=</mo><mfrac><msup><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><mn>2.5</mn></mrow></msup><mn>21.552</mn></mfrac><mo>=</mo><mn>0.565</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-71">\sigma_2 = \frac{e^{2.5}}{21.552} = 0.565 </script>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-72-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msub&gt;&lt;mi&gt;&amp;#x03C3;&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mn&gt;1.8&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mn&gt;21.552&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.281&lt;/mn&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="21.17ex" height="5.453ex" viewBox="0 -1581.5 9115 2347.8" role="img" focusable="false" aria-hidden="true" style="vertical-align: -1.78ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-3C3" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="808" y="-213"></use><use href="#MJMAIN-3D" x="1303" y="0"></use><g transform="translate(2081,0)"><g transform="translate(397,0)"><rect stroke="none" width="2901" height="60" x="0" y="220"></rect><g transform="translate(714,676)"><use href="#MJMATHI-65" x="0" y="0"></use><g transform="translate(466,362)"><use transform="scale(0.707)" href="#MJMAIN-31"></use><use transform="scale(0.707)" href="#MJMAIN-2E" x="500" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-38" x="779" y="0"></use></g></g><g transform="translate(60,-686)"><use href="#MJMAIN-32"></use><use href="#MJMAIN-31" x="500" y="0"></use><use href="#MJMAIN-2E" x="1001" y="0"></use><use href="#MJMAIN-35" x="1279" y="0"></use><use href="#MJMAIN-35" x="1780" y="0"></use><use href="#MJMAIN-32" x="2280" y="0"></use></g></g></g><use href="#MJMAIN-3D" x="5778" y="0"></use><g transform="translate(6834,0)"><use href="#MJMAIN-30"></use><use href="#MJMAIN-2E" x="500" y="0"></use><use href="#MJMAIN-32" x="779" y="0"></use><use href="#MJMAIN-38" x="1279" y="0"></use><use href="#MJMAIN-31" x="1780" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>σ</mi><mn>1</mn></msub><mo>=</mo><mfrac><msup><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><mn>1.8</mn></mrow></msup><mn>21.552</mn></mfrac><mo>=</mo><mn>0.281</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-72">\sigma_1 = \frac{e^{1.8}}{21.552} = 0.281 </script>
</div>

<p>So, the output vector is therefore:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-73-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mi&gt;&amp;#x03C3;&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mn&gt;0.154&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;0.565&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;0.281&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="23.68ex" height="2.613ex" viewBox="0 -817.3 10195.4 1125" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-3C3" x="0" y="0"></use><use href="#MJMAIN-3D" x="850" y="0"></use><use href="#MJMAIN-5B" x="1906" y="0"></use><g transform="translate(2185,0)"><use href="#MJMAIN-30"></use><use href="#MJMAIN-2E" x="500" y="0"></use><use href="#MJMAIN-31" x="779" y="0"></use><use href="#MJMAIN-35" x="1279" y="0"></use><use href="#MJMAIN-34" x="1780" y="0"></use></g><use href="#MJMAIN-2C" x="4465" y="0"></use><g transform="translate(4910,0)"><use href="#MJMAIN-30"></use><use href="#MJMAIN-2E" x="500" y="0"></use><use href="#MJMAIN-35" x="779" y="0"></use><use href="#MJMAIN-36" x="1279" y="0"></use><use href="#MJMAIN-35" x="1780" y="0"></use></g><use href="#MJMAIN-2C" x="7191" y="0"></use><g transform="translate(7636,0)"><use href="#MJMAIN-30"></use><use href="#MJMAIN-2E" x="500" y="0"></use><use href="#MJMAIN-32" x="779" y="0"></use><use href="#MJMAIN-38" x="1279" y="0"></use><use href="#MJMAIN-31" x="1780" y="0"></use></g><use href="#MJMAIN-5D" x="9916" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>σ</mi><mo>=</mo><mo stretchy="false">[</mo><mn>0.154</mn><mo>,</mo><mn>0.565</mn><mo>,</mo><mn>0.281</mn><mo stretchy="false">]</mo></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-73">\sigma = [0.154, 0.565, 0.281]</script>
</div>

<p>The sum of the three elements in <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax_SVG" id="MathJax-Element-74-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;&amp;#x03C3;&lt;/mi&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.33ex" height="1.429ex" viewBox="0 -511.5 572.5 615.4" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.241ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-3C3" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>σ</mi></math></span></span><script type="math/tex" id="MathJax-Element-74">\sigma</script> is 1.0. Phew!</p>

</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="sparse_features"></a>
</p><h2 class="hide-from-toc" id="sparse-feature" data-text=" sparse feature" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> sparse feature</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  sparse feature" data-title="Copy link to this section:  sparse feature" data-id="sparse-feature"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a> whose values are predominately zero or empty.
For example, a feature containing a single 1 value and a million 0 values is
sparse. In contrast, a <a href="https://developers.google.com/machine-learning/glossary#dense_feature"><strong>dense feature</strong></a> has values that
are predominantly not zero or empty.</p>

<p>In machine learning, a surprising number of features are sparse features.
Categorical features are usually sparse features.
For example, of the 300 possible tree species in a forest, a single example
might identify just a <em>maple tree</em>. Or, of the millions
of possible videos in a video library, a single example might identify
just "Casablanca."</p>

<p>In a model, you typically represent sparse features with
<a href="https://developers.google.com/machine-learning/glossary#one-hot_encoding"><strong>one-hot encoding</strong></a>. If the one-hot encoding is big,
you might put an <a href="https://developers.google.com/machine-learning/glossary#embedding_layer"><strong>embedding layer</strong></a> on top of the
one-hot encoding for greater efficiency.</p>

<p><a class="glossary-anchor" name="sparse_representation"></a>
</p><h2 class="hide-from-toc" id="sparse-representation" data-text=" sparse representation"> sparse representation</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Storing only the <em>position(s)</em> of nonzero elements in a sparse feature.</p>

<p>For example, suppose a categorical feature named <code translate="no" dir="ltr">species</code> identifies the 36
tree species in a particular forest. Further assume that each
<a href="https://developers.google.com/machine-learning/glossary#example"><strong>example</strong></a> identifies only a single species.</p>

<p>You could use a one-hot vector to represent the tree species in each example.
A one-hot vector would contain a single <code translate="no" dir="ltr">1</code> (to represent
the particular tree species in that example) and 35 <code translate="no" dir="ltr">0</code>s (to represent the
35 tree species <em>not</em> in that example). So, the one-hot representation
of <code translate="no" dir="ltr">maple</code> might look something like the following:</p>

<p>
<img src="./ML_Glossary_files/One-HotRepresentationOfASparseFeature.png" loading="lazy" alt="A vector in which positions 0 through 23 hold the value 0, position
          24 holds the value 1, and positions 25 through 35 hold the value 0.">
</p>

<p>Alternatively, sparse representation would simply identify the position of the
particular species. If <code translate="no" dir="ltr">maple</code> is at position 24, then the sparse representation
of <code translate="no" dir="ltr">maple</code> would simply be:</p>

<devsite-code no-copy="" data-copy-event-label=""><pre translate="no" dir="ltr" is-upgraded="">24
</pre></devsite-code>

<p>Notice that the sparse representation is much more compact than the one-hot
representation.</p>
<aside class="note"><strong>Note:</strong><span> You shouldn't pass a sparse representation as a direct feature input
to a model. Instead, you should convert the sparse representation into a
one-hot representation before training on it.</span></aside>
<devsite-expandable is-upgraded="" id="expandable-36"><a class="exw-control" aria-controls="expandable-36" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-a-slightly-more-complex-example." data-text=" Click the icon for a slightly more complex example. ">
Click the icon for a slightly more complex example.<wbr>
</h4></a>



<div class="expand-background">
<p>
Suppose each example in your model must represent the words—but not
the order of those words—in an English sentence.
English consists of about 170,000 words, so English is a categorical
feature with about 170,000 elements. Most English sentences use an
extremely tiny fraction of those 170,000 words, so the set of words in a
single example is almost certainly going to be sparse data.
</p>

<p>Consider the following sentence:</p>

<devsite-code no-copy="" data-copy-event-label=""><pre translate="no" dir="ltr" is-upgraded="">My dog is a great dog
</pre></devsite-code>

<p>
You could use a variant of one-hot vector to represent the words in this
sentence. In this variant, multiple cells in the vector can contain
a nonzero value. Furthermore, in this variant, a cell can contain an integer
other than one. Although the words "my", "is", "a", and "great" appear only
once in the sentence, the word "dog" appears twice. Using this variant of
one-hot vectors to represent the words in this sentence yields the following
170,000-element vector:
</p>

<p>
<img src="./ML_Glossary_files/One-HotRepresentationOfWordsInASentence.png" loading="lazy" alt="A vector of 170,000 integers. The number 1 is at vector position 0,
          45770, 58906, and 91520. The number 2 is at position 26,100.
          Zeroes are at the remaining 169,996 positions.">
</p>

<p>A sparse representation of the same sentence would simply be:</p>

<devsite-code data-copy-event-label=""><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="lit">0</span><span class="pun">:</span><span class="pln"> </span><span class="lit">1</span><span class="pln"><br></span><span class="lit">26100</span><span class="pun">:</span><span class="pln"> </span><span class="lit">2</span><span class="pln"><br></span><span class="lit">45770</span><span class="pun">:</span><span class="pln"> </span><span class="lit">1</span><span class="pln"><br></span><span class="lit">58906</span><span class="pun">:</span><span class="pln"> </span><span class="lit">1</span><span class="pln"><br></span><span class="lit">91520</span><span class="pun">:</span><span class="pln"> </span><span class="lit">1</span><span class="pln"><br></span></pre></devsite-code>

</div>

<hr>
</devsite-expandable>

<devsite-expandable is-upgraded="" id="expandable-37"><a class="exw-control" aria-controls="expandable-37" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-if-you-are-confused." data-text=" Click the icon if you are confused. ">
Click the icon if you are confused.<wbr>
</h4></a>



<div class="expand-background">
<p>The term "sparse representation" confuses a lot of people because sparse
representation is itself <i>not a sparse vector</i>. Rather, sparse
representation is actually a <i>dense representation of a sparse vector</i>.
The synonym <b>index representation</b> is a little clearer than
"sparse representation."
</p>

</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="sparse_vector"></a>
</p><h2 class="hide-from-toc" id="sparse-vector" data-text=" sparse vector"> sparse vector</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A vector whose values are mostly zeroes. See also <a href="https://developers.google.com/machine-learning/glossary#sparse_features"><strong>sparse
feature</strong></a> and <a href="https://developers.google.com/machine-learning/glossary#sparsity"><strong>sparsity</strong></a>.</p>

<p><a class="glossary-anchor" name="sparsity"></a>
</p><h2 class="hide-from-toc" id="sparsity" data-text=" sparsity"> sparsity</h2><p></p>

<p>The number of elements set to zero (or null) in a vector or matrix divided
by the total number of entries in that vector or matrix. For example,
consider a 100-element matrix in which 98 cells contain zero. The calculation of
sparsity is as follows:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-75-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;sparsity&lt;/mtext&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtext&gt;98&lt;/mtext&gt;&lt;mtext&gt;100&lt;/mtext&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;0.98&lt;/mtext&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.633ex" height="5.098ex" viewBox="0 -1428.7 9744.6 2195" role="img" focusable="false" style="vertical-align: -1.78ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-73"></use><use href="#MJMAIN-70" x="394" y="0"></use><use href="#MJMAIN-61" x="951" y="0"></use><use href="#MJMAIN-72" x="1451" y="0"></use><use href="#MJMAIN-73" x="1844" y="0"></use><use href="#MJMAIN-69" x="2238" y="0"></use><use href="#MJMAIN-74" x="2517" y="0"></use><use href="#MJMAIN-79" x="2906" y="0"></use><use href="#MJMAIN-3D" x="3712" y="0"></use><g transform="translate(4491,0)"><g transform="translate(397,0)"><rect stroke="none" width="1621" height="60" x="0" y="220"></rect><g transform="translate(310,676)"><use href="#MJMAIN-39"></use><use href="#MJMAIN-38" x="500" y="0"></use></g><g transform="translate(60,-686)"><use href="#MJMAIN-31"></use><use href="#MJMAIN-30" x="500" y="0"></use><use href="#MJMAIN-30" x="1001" y="0"></use></g></g></g><use href="#MJMAIN-3D" x="6908" y="0"></use><g transform="translate(7964,0)"><use href="#MJMAIN-30"></use><use href="#MJMAIN-2E" x="500" y="0"></use><use href="#MJMAIN-39" x="779" y="0"></use><use href="#MJMAIN-38" x="1279" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow class="MJX-TeXAtom-ORD"><mtext>sparsity</mtext></mrow><mo>=</mo><mfrac><mtext>98</mtext><mtext>100</mtext></mfrac><mo>=</mo><mrow class="MJX-TeXAtom-ORD"><mtext>0.98</mtext></mrow></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-75">
{\text{sparsity}} =
\frac{\text{98}} {\text{100}} =
{\text{0.98}}
</script>
</div>

<p><strong>Feature sparsity</strong> refers to the sparsity of a feature vector;
<strong>model sparsity</strong> refers to the sparsity of the model weights.</p>

<p><a class="glossary-anchor" name="spatial_pooling"></a>
</p><h2 class="hide-from-toc" id="spatial-pooling" data-text=" spatial pooling"> spatial pooling</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>See <a href="https://developers.google.com/machine-learning/glossary#pooling"><strong>pooling</strong></a>.</p>

<p><a class="glossary-anchor" name="split"></a>
</p><h2 class="hide-from-toc" id="split" data-text=" split "> split </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>In a <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a>, another name for a
<a href="https://developers.google.com/machine-learning/glossary#condition"><strong>condition</strong></a>.</p>

<p><a class="glossary-anchor" name="splitter"></a>
</p><h2 class="hide-from-toc" id="splitter" data-text=" splitter "> splitter </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>While training a <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a>, the routine
(and algorithm) responsible for finding the best
<a href="https://developers.google.com/machine-learning/glossary#condition"><strong>condition</strong></a> at each <a href="https://developers.google.com/machine-learning/glossary#node-decision-tree"><strong>node</strong></a>.</p>

<p><a class="glossary-anchor" name="squared_hinge_loss"></a>
</p><h2 class="hide-from-toc" id="squared-hinge-loss" data-text=" squared hinge loss"> squared hinge loss</h2><p></p>

<p>The square of the <a href="https://developers.google.com/machine-learning/glossary#hinge-loss"><strong>hinge loss</strong></a>.  Squared hinge loss penalizes
outliers more harshly than regular hinge loss.</p>

<p><a class="glossary-anchor" name="squared_loss"></a>
</p><h2 class="hide-from-toc" id="squared-loss" data-text=" squared loss"> squared loss</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#L2_loss"><b>L<sub>2</sub> loss</b></a>.</p>

<p><a class="glossary-anchor" name="staged-training"></a>
</p><h2 class="hide-from-toc" id="staged-training" data-text=" staged training"> staged training</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A tactic of training a model in a sequence of discrete stages. The goal can be
either to speed up the training process, or to achieve better model quality.</p>

<p>An illustration of the progressive stacking approach is shown below:</p>

<ul>
<li>Stage 1 contains 3 hidden layers, stage 2 contains 6 hidden layers, and
stage 3 contains 12 hidden layers.</li>
<li>Stage 2 begins training with the weights learned in the 3 hidden layers
of Stage 1. Stage 3 begins training with the weights learned in the 6
hidden layers of Stage 2.</li>
</ul>

<p>
<img src="./ML_Glossary_files/staged-training.png" loading="lazy" alt="Three stages, which are labeled &#39;Stage 1&#39;, &#39;Stage 2&#39;, and &#39;Stage 3&#39;.
          Each stage contains a different number of layers: Stage 1 contains
          3 layers, Stage 2 contains 6 layers, and Stage 3 contains 12 layers.
          The 3 layers from Stage 1 become the first 3 layers of Stage 2.
          Similarly, the 6 layers from Stage 2 become the first 6 layers of
          Stage 3.">
</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#pipelining"><strong>pipelining</strong></a>.</p>

<p><a class="glossary-anchor" name="state"></a>
</p><h2 class="hide-from-toc" id="state" data-text=" state"> state</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In reinforcement learning, the parameter values that describe the current
configuration of the environment, which the <a href="https://developers.google.com/machine-learning/glossary#agent"><strong>agent</strong></a> uses to
choose an <a href="https://developers.google.com/machine-learning/glossary#action"><strong>action</strong></a>.</p>

<p><a class="glossary-anchor" name="state-action_value_function"></a>
</p><h2 class="hide-from-toc" id="state-action-value-function" data-text=" state-action value function"> state-action value function</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#q-function"><strong>Q-function</strong></a>.</p>

<p><a class="glossary-anchor" name="static"></a>
<a class="glossary-anchor" name="static-model"></a>
</p><h2 class="hide-from-toc" id="static" data-text=" static"> static</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Something done once rather than continuously.
The terms <strong>static</strong> and <strong>offline</strong> are synonyms.
The following are common uses of <strong>static</strong> and <strong>offline</strong> in machine
learning:</p>

<ul>
<li><strong>static model</strong> (or <strong>offline model</strong>) is a model trained once and then
used for a while.</li>
<li><strong>static training</strong> (or <strong>offline training</strong>) is the process of training a
static model.</li>
<li><strong>static inference</strong> (or <strong>offline inference</strong>) is a
process in which a model generates a batch of predictions at a time.</li>
</ul>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#dynamic"><strong>dynamic</strong></a>.</p>

<p><a class="glossary-anchor" name="static-inference"></a>
</p><h2 class="hide-from-toc" id="static-inference" data-text=" static inference" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> static inference</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  static inference" data-title="Copy link to this section:  static inference" data-id="static-inference"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#offline_inference"><strong>offline inference</strong></a>.</p>

<p><a class="glossary-anchor" name="stationarity"></a>
</p><h2 class="hide-from-toc" id="stationarity" data-text=" stationarity" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> stationarity</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  stationarity" data-title="Copy link to this section:  stationarity" data-id="stationarity"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A feature whose values don't change across one or more dimensions, usually time.
For example, a feature whose values look about the same in 2020 and
2022 exhibits stationarity.</p>

<p>In the real world, very few features exhibit stationarity. Even features
synonymous with stability (like sea level) change over time.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#nonstationarity"><strong>nonstationarity</strong></a>.</p>

<p><a class="glossary-anchor" name="step"></a>
</p><h2 class="hide-from-toc" id="step" data-text=" step" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> step</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  step" data-title="Copy link to this section:  step" data-id="step"></button></h2><p></p>

<p>A forward pass and backward pass of one <a href="https://developers.google.com/machine-learning/glossary#batch"><strong>batch</strong></a>.</p>

<p>See <a href="https://developers.google.com/machine-learning/glossary#backpropagation"><strong>backpropagation</strong></a> for more information
on the forward pass and backward pass.</p>

<p><a class="glossary-anchor" name="step_size"></a>
</p><h2 class="hide-from-toc" id="step-size" data-text=" step size" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> step size</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  step size" data-title="Copy link to this section:  step size" data-id="step-size"></button></h2><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#learning_rate"><strong>learning rate</strong></a>.</p>

<p><a class="glossary-anchor" name="SGD"></a>
</p><h2 class="hide-from-toc" id="stochastic-gradient-descent-sgd" data-text=" stochastic gradient descent (SGD)"> stochastic gradient descent (SGD)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#gradient_descent"><strong>gradient descent</strong></a> algorithm in which the
<a href="https://developers.google.com/machine-learning/glossary#batch_size"><strong>batch size</strong></a> is one. In other words, SGD trains on
a single example chosen uniformly at
random from a <a href="https://developers.google.com/machine-learning/glossary#training_set"><strong>training set</strong></a>.</p>

<p><a class="glossary-anchor" name="stride"></a>
</p><h2 class="hide-from-toc" id="stride" data-text=" stride"> stride</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>In a convolutional operation or pooling, the delta in each dimension of the
next series of input slices. For example, the following animation
demonstrates a (1,1) stride during a convolutional operation. Therefore,
the next input slice starts one position to the right of the previous input
slice. When the operation reaches the right edge, the next slice is all
the way over to the left but one position down.</p>

<p>
<img src="./ML_Glossary_files/AnimatedConvolution.gif" loading="lazy" alt="An input 5x5 matrix and a 3x3 convolutional filter. Because the
     stride is (1,1), a convolutional filter will be applied 9 times. The first
     convolutional slice evaluates the top-left 3x3 submatrix of the input
     matrix. The second slice evaluates the top-middle 3x3
     submatrix. The third convolutional slice evaluates the top-right 3x3
     submatrix.  The fourth slice evaluates the middle-left 3x3 submatrix.
     The fifth slice evaluates the middle 3x3 submatrix. The sixth slice
     evaluates the middle-right 3x3 submatrix. The seventh slice evaluates
     the bottom-left 3x3 submatrix.  The eighth slice evaluates the
     bottom-middle 3x3 submatrix. The ninth slice evaluates the bottom-right 3x3
     submatrix.">
</p>

<p>The preceding example demonstrates a two-dimensional stride.  If the input
matrix is three-dimensional, the stride would also be three-dimensional.</p>

<p><a class="glossary-anchor" name="SRM"></a>
</p><h2 class="hide-from-toc" id="structural-risk-minimization-srm" data-text=" structural risk minimization (SRM)" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> structural risk minimization (SRM)</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  structural risk minimization (SRM)" data-title="Copy link to this section:  structural risk minimization (SRM)" data-id="structural-risk-minimization-srm"></button></h2><p></p>

<p>An algorithm that balances two goals:</p>

<ul>
<li>The desire to build the most predictive model (for example, lowest loss).</li>
<li>The desire to keep the model as simple as possible (for example, strong
regularization).</li>
</ul>

<p>For example, a function that minimizes loss+regularization on the
training set is a structural risk minimization algorithm.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#ERM"><strong>empirical risk minimization</strong></a>.</p>

<p><a class="glossary-anchor" name="subsampling"></a>
</p><h2 class="hide-from-toc" id="subsampling" data-text=" subsampling" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> subsampling</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  subsampling" data-title="Copy link to this section:  subsampling" data-id="subsampling"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>See <a href="https://developers.google.com/machine-learning/glossary#pooling"><strong>pooling</strong></a>.</p>

<p><a class="glossary-anchor" name="summary"></a>
</p><h2 class="hide-from-toc" id="summary" data-text=" summary" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> summary</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  summary" data-title="Copy link to this section:  summary" data-id="summary"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>In TensorFlow, a value or set of values calculated at a particular
<a href="https://developers.google.com/machine-learning/glossary#step"><strong>step</strong></a>, usually used for tracking model metrics during training.</p>

<p><a class="glossary-anchor" name="supervised_machine_learning"></a>
</p><h2 class="hide-from-toc" id="supervised-machine-learning" data-text=" supervised machine learning"> supervised machine learning</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Training a <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> from <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>features</strong></a> and their
corresponding <a href="https://developers.google.com/machine-learning/glossary#label"><strong>labels</strong></a>. Supervised machine learning is analogous
to learning a subject by studying a set of questions and their
corresponding answers.  After mastering the mapping between questions and
answers, a student can then provide answers to new (never-before-seen)
questions on the same topic.</p>

<p>Compare with
<a href="https://developers.google.com/machine-learning/glossary#unsupervised_machine_learning"><strong>unsupervised machine learning</strong></a>.</p>

<p><a class="glossary-anchor" name="synthetic_feature"></a>
</p><h2 class="hide-from-toc" id="synthetic-feature" data-text=" synthetic feature" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> synthetic feature</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  synthetic feature" data-title="Copy link to this section:  synthetic feature" data-id="synthetic-feature"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a> not present among the input features, but
assembled from one or more of them. Methods for creating synthetic features
include the following:</p>

<ul>
<li><a href="https://developers.google.com/machine-learning/glossary#bucketing"><strong>Bucketing</strong></a> a continuous feature into range bins.</li>
<li>Creating a <a href="https://developers.google.com/machine-learning/glossary#feature_cross"><strong>feature cross</strong></a>.</li>
<li>Multiplying (or dividing) one feature value by other feature value(s)
or by itself. For example, if <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code> are input features, then the
following are examples of synthetic features:
<ul>
  <li><tt>ab</tt></li>
  <li><tt>a<sup>2</sup></tt></li>
</ul></li>
<li>Applying a transcendental function to a feature value. For example, if <code translate="no" dir="ltr">c</code>
is an input feature, then the following are examples of synthetic features:
<ul>
  <li><tt>sin(c)</tt></li>
  <li><tt>ln(c)</tt></li>
</ul></li>
</ul>

<p>Features created by <a href="https://developers.google.com/machine-learning/glossary#normalization"><strong>normalizing</strong></a> or <a href="https://developers.google.com/machine-learning/glossary#scaling"><strong>scaling</strong></a>
alone are not considered synthetic features.</p>

<p><a class="glossary-anchor" name="t"></a>
</p><h2 class="glossary" id="t" data-text="T" role="presentation"><span class="devsite-heading" role="heading" aria-level="2">T</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: T" data-title="Copy link to this section: T" data-id="t"></button></h2><p></p>

<p><a class="glossary-anchor" name="tabular_q-learning"></a>
</p><h2 class="hide-from-toc" id="tabular-q-learning" data-text=" tabular Q-learning" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> tabular Q-learning</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  tabular Q-learning" data-title="Copy link to this section:  tabular Q-learning" data-id="tabular-q-learning"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#reinforcement_learning"><strong>reinforcement learning</strong></a>, implementing
<a href="https://developers.google.com/machine-learning/glossary#q-learning"><strong>Q-learning</strong></a> by using a table to store the
<a href="https://developers.google.com/machine-learning/glossary#q-function"><strong>Q-functions</strong></a> for every combination of
<a href="https://developers.google.com/machine-learning/glossary#state"><strong>state</strong></a> and <a href="https://developers.google.com/machine-learning/glossary#action"><strong>action</strong></a>.</p>

<p><a class="glossary-anchor" name="target"></a>
</p><h2 class="hide-from-toc" id="target" data-text=" target" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> target</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  target" data-title="Copy link to this section:  target" data-id="target"></button></h2><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#label"><strong>label</strong></a>.</p>

<p><a class="glossary-anchor" name="target_network"></a>
</p><h2 class="hide-from-toc" id="target-network" data-text=" target network" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> target network</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  target network" data-title="Copy link to this section:  target network" data-id="target-network"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#q-learning"><strong>Deep Q-learning</strong></a>, a neural network that is a stable
approximation of the main neural network, where the main neural network
implements either a <a href="https://developers.google.com/machine-learning/glossary#q-function"><strong>Q-function</strong></a> or a <a href="https://developers.google.com/machine-learning/glossary#policy"><strong>policy</strong></a>.
Then, you can train the main network on the Q-values predicted by the target
network. Therefore, you prevent the feedback loop that occurs when the main
network trains on Q-values predicted by itself. By avoiding this feedback,
training stability increases.</p>

<p><a class="glossary-anchor" name="temporal_data"></a>
</p><h2 class="hide-from-toc" id="temporal-data" data-text=" temporal data" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> temporal data</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  temporal data" data-title="Copy link to this section:  temporal data" data-id="temporal-data"></button></h2><p></p>

<p>Data recorded at different points in time. For example, winter coat sales
recorded for each day of the year would be temporal data.</p>

<p><a class="glossary-anchor" name="tensor"></a>
</p><h2 class="hide-from-toc" id="tensor" data-text=" Tensor" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> Tensor</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  Tensor" data-title="Copy link to this section:  Tensor" data-id="tensor"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>The primary data structure in TensorFlow programs. Tensors are N-dimensional
(where N could be very large) data structures, most commonly scalars, vectors,
or matrices. The elements of a Tensor can hold integer, floating-point,
or string values.</p>

<p><a class="glossary-anchor" name="TensorBoard"></a>
</p><h2 class="hide-from-toc" id="tensorboard" data-text=" TensorBoard" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> TensorBoard</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  TensorBoard" data-title="Copy link to this section:  TensorBoard" data-id="tensorboard"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>The dashboard that displays the summaries saved during the execution of one or
more TensorFlow programs.</p>

<p><a class="glossary-anchor" name="TensorFlow"></a>
</p><h2 class="hide-from-toc" id="tensorflow" data-text=" TensorFlow" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> TensorFlow</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  TensorFlow" data-title="Copy link to this section:  TensorFlow" data-id="tensorflow"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>A large-scale, distributed, machine learning platform. The term also refers to
the base API layer in the TensorFlow stack, which supports general computation
on dataflow graphs.</p>

<p>Although TensorFlow is primarily used for machine learning, you may also use
TensorFlow for non-ML tasks that require numerical computation using
dataflow graphs.</p>

<p><a class="glossary-anchor" name="TensorFlow_Playground"></a>
</p><h2 class="hide-from-toc" id="tensorflow-playground" data-text=" TensorFlow Playground" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> TensorFlow Playground</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  TensorFlow Playground" data-title="Copy link to this section:  TensorFlow Playground" data-id="tensorflow-playground"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>A program that visualizes how different
<a href="https://developers.google.com/machine-learning/glossary#hyperparameter"><strong>hyperparameters</strong></a> influence model
(primarily neural network) training.
Go to
<a href="http://playground.tensorflow.org/" target="T">
http://playground.tensorflow.org</a>
to experiment with TensorFlow Playground.</p>

<p><a class="glossary-anchor" name="TensorFlow_Serving"></a>
</p><h2 class="hide-from-toc" id="tensorflow-serving" data-text=" TensorFlow Serving" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> TensorFlow Serving</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  TensorFlow Serving" data-title="Copy link to this section:  TensorFlow Serving" data-id="tensorflow-serving"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>A platform to deploy trained models in production.</p>

<p><a class="glossary-anchor" name="TPU"></a>
</p><h2 class="hide-from-toc" id="tensor-processing-unit-tpu" data-text=" Tensor Processing Unit (TPU)" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> Tensor Processing Unit (TPU)</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  Tensor Processing Unit (TPU)" data-title="Copy link to this section:  Tensor Processing Unit (TPU)" data-id="tensor-processing-unit-tpu"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
  <div class="glossary-icon" data-title="Google Cloud">#GoogleCloud</div>
</div><p></p>

<p>An application-specific integrated circuit (ASIC) that optimizes the
performance of machine learning workloads. These ASICs are deployed as
multiple <a href="https://developers.google.com/machine-learning/glossary#TPU_chip"><strong>TPU chips</strong></a> on a <a href="https://developers.google.com/machine-learning/glossary#TPU_device"><strong>TPU device</strong></a>.</p>

<p><a class="glossary-anchor" name="tensor_rank"></a>
</p><h2 class="hide-from-toc" id="tensor-rank" data-text=" Tensor rank" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> Tensor rank</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  Tensor rank" data-title="Copy link to this section:  Tensor rank" data-id="tensor-rank"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>See <a href="https://developers.google.com/machine-learning/glossary#rank_Tensor"><strong>rank (Tensor)</strong></a>.</p>

<p><a class="glossary-anchor" name="tensor_shape"></a>
</p><h2 class="hide-from-toc" id="tensor-shape" data-text=" Tensor shape" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> Tensor shape</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  Tensor shape" data-title="Copy link to this section:  Tensor shape" data-id="tensor-shape"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>The number of elements a <a href="https://developers.google.com/machine-learning/glossary#tensor"><strong>Tensor</strong></a> contains in various dimensions.
For example, a [5, 10] Tensor has a shape of 5 in one dimension and 10
in another.</p>

<p><a class="glossary-anchor" name="tensor_size"></a>
</p><h2 class="hide-from-toc" id="tensor-size" data-text=" Tensor size" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> Tensor size</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  Tensor size" data-title="Copy link to this section:  Tensor size" data-id="tensor-size"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>The total number of scalars a <a href="https://developers.google.com/machine-learning/glossary#tensor"><strong>Tensor</strong></a> contains. For example, a
[5, 10] Tensor has a size of 50.</p>

<p><a class="glossary-anchor" name="termination_condition"></a>
</p><h2 class="hide-from-toc" id="termination-condition" data-text=" termination condition" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> termination condition</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  termination condition" data-title="Copy link to this section:  termination condition" data-id="termination-condition"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#reinforcement_learning"><strong>reinforcement learning</strong></a>, the conditions that
determine when an <a href="https://developers.google.com/machine-learning/glossary#episode"><strong>episode</strong></a> ends, such as when the agent reaches
a certain state or exceeds a threshold number of state transitions.
For example, in <a href="https://wikipedia.org/wiki/Tic-tac-toe">tic-tac-toe</a> (also
known as noughts and crosses), an episode terminates either when a player marks
three consecutive spaces or when all spaces are marked.</p>

<p><a class="glossary-anchor" name="test"></a>
</p><h2 class="hide-from-toc" id="test" data-text=" test " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> test </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  test " data-title="Copy link to this section:  test " data-id="test"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>In a <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a>, another name for a
<a href="https://developers.google.com/machine-learning/glossary#condition"><strong>condition</strong></a>.</p>

<p><a class="glossary-anchor" name="test-loss"></a>
</p><h2 class="hide-from-toc" id="test-loss" data-text=" test loss" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> test loss</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  test loss" data-title="Copy link to this section:  test loss" data-id="test-loss"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#metric"><strong>metric</strong></a> representing a model's <a href="https://developers.google.com/machine-learning/glossary#loss"><strong>loss</strong></a> against
the <a href="https://developers.google.com/machine-learning/glossary#test_set"><strong>test set</strong></a>. When building a <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a>, you
typically try to minimize test loss. That's because a low test loss is a
stronger quality signal than a low <a href="https://developers.google.com/machine-learning/glossary#training-loss"><strong>training loss</strong></a> or
low <a href="https://developers.google.com/machine-learning/glossary#validation-loss"><strong>validation loss</strong></a>.</p>

<p>A large gap between test loss and training loss or validation loss sometimes
suggests that you need to increase the
<a href="https://developers.google.com/machine-learning/glossary#regularization_rate"><strong>regularization rate</strong></a>.</p>

<p><a class="glossary-anchor" name="test_set"></a>
</p><h2 class="hide-from-toc" id="test-set" data-text=" test set" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> test set</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  test set" data-title="Copy link to this section:  test set" data-id="test-set"></button></h2><p></p>

<p>A subset of the <a href="https://developers.google.com/machine-learning/glossary#dataset"><strong>dataset</strong></a> reserved for testing
a trained <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a>.</p>

<p>Traditionally, you divide examples in the dataset into the following three
distinct subsets:</p>

<ul>
<li>a <a href="https://developers.google.com/machine-learning/glossary#training_set"><strong>training set</strong></a></li>
<li>a <a href="https://developers.google.com/machine-learning/glossary#validation_set"><strong>validation set</strong></a></li>
<li>a test set</li>
</ul>

<p>Each example in a dataset should belong to only one of the preceding subsets.
For instance, a single example should not belong to both the training set and
the test set.</p>

<p>The training set and validation set are both closely tied to training a model.
Because the test set is only indirectly associated with training,
<a href="https://developers.google.com/machine-learning/glossary#test-loss"><strong>test loss</strong></a> is a less biased, higher quality metric than
<a href="https://developers.google.com/machine-learning/glossary#training-loss"><strong>training loss</strong></a> or <a href="https://developers.google.com/machine-learning/glossary#validation-loss"><strong>validation loss</strong></a>.</p>



<p><a class="glossary-anchor" name="tf.Example"></a>
</p><h2 class="hide-from-toc" id="tf.example" data-text=" tf.Example" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> tf.<wbr>Example</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  tf.Example" data-title="Copy link to this section:  tf.Example" data-id="tf.example"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>A standard
<a href="https://developers.google.com/protocol-buffers/" target="T">
protocol buffer</a>
for describing input data for machine learning model training or inference.</p>

<p><a class="glossary-anchor" name="tf.keras"></a>
</p><h2 class="hide-from-toc" id="tf.keras" data-text=" tf.keras" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> tf.<wbr>keras</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  tf.keras" data-title="Copy link to this section:  tf.keras" data-id="tf.keras"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
</div><p></p>

<p>An implementation of <a href="https://developers.google.com/machine-learning/glossary#Keras"><strong>Keras</strong></a> integrated into
<a href="https://developers.google.com/machine-learning/glossary#TensorFlow"><strong>TensorFlow</strong></a>.</p>



<p><a class="glossary-anchor" name="threshold"></a>
</p><h2 class="hide-from-toc" id="threshold-for-decision-trees" data-text=" threshold (for decision trees) " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> threshold (for decision trees) </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  threshold (for decision trees) " data-title="Copy link to this section:  threshold (for decision trees) " data-id="threshold-for-decision-trees"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>In an <a href="https://developers.google.com/machine-learning/glossary#axis-aligned-condition"><strong>axis-aligned condition</strong></a>, the value that a
<a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a> is being compared against. For example, 75 is the
threshold value in the following condition:</p>

<devsite-code data-copy-event-label=""><div class="devsite-code-buttons-container" role="group" aria-label="Action buttons"><button type="button" class="gc-analytics-event material-icons devsite-icon-code-dark devsite-toggle-dark" data-category="Site-Wide Custom Events" data-label="Dark Code Toggle" track-type="exampleCode" track-name="darkCodeToggle" aria-label="Dark code theme" data-title="Dark code theme"></button><button type="button" class="gc-analytics-event material-icons devsite-icon-code-light devsite-toggle-light" data-category="Site-Wide Custom Events" data-label="Light Code Toggle" track-type="exampleCode" track-name="lightCodeToggle" aria-label="Light code theme" data-title="Light code theme"></button><button type="button" class="gc-analytics-event material-icons devsite-icon-copy" data-category="Site-Wide Custom Events" data-label="Click To Copy" track-type="exampleCode" track-name="clickToCopy" aria-label="Copy code sample" data-title="Copy code sample"></button></div><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="pln">grade </span><span class="pun">&gt;=</span><span class="pln"> </span><span class="lit">75</span><span class="pln"><br></span></pre></devsite-code>

<aside class="note">
This form of the term <b>threshold</b> is different than
<a href="https://developers.google.com/machine-learning/glossary#classification_threshold"><b>classification threshold</b></a>.
</aside>

<p><a class="glossary-anchor" name="time_series_analysis"></a>
</p><h2 class="hide-from-toc" id="time-series-analysis" data-text=" time series analysis" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> time series analysis</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  time series analysis" data-title="Copy link to this section:  time series analysis" data-id="time-series-analysis"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Clustering">#clustering</div>
</div><p></p>

<p>A subfield of machine learning and statistics that analyzes
<a href="https://developers.google.com/machine-learning/glossary#temporal_data"><strong>temporal data</strong></a>.  Many types of machine learning
problems require time series analysis, including classification, clustering,
forecasting, and anomaly detection. For example, you could use
time series analysis to forecast the future sales of winter coats by month
based on historical sales data.</p>

<p><a class="glossary-anchor" name="timestep"></a>
</p><h2 class="hide-from-toc" id="timestep" data-text="timestep" role="presentation"><span class="devsite-heading" role="heading" aria-level="2">timestep</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: timestep" data-title="Copy link to this section: timestep" data-id="timestep"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Sequence Models">#seq</div>
</div><p></p>

<p>One "unrolled" cell within a
<a href="https://developers.google.com/machine-learning/glossary#recurrent_neural_network"><strong>recurrent neural network</strong></a>.
For example, the following figure shows three timesteps (labeled with
the subscripts t-1, t, and t+1):</p>

<p>
<img src="./ML_Glossary_files/Simple_RNN.svg" loading="lazy" alt="Three timesteps in a recurrent neural network. The output of the
          first timestep becomes input to the second timestep. The output
          of the second timestep becomes input to the third timestep.">
</p>

<p><a class="glossary-anchor" name="token"></a>
</p><h2 class="hide-from-toc" id="token" data-text=" token" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> token</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  token" data-title="Copy link to this section:  token" data-id="token"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>In a <a href="https://developers.google.com/machine-learning/glossary#language-model"><strong>language model</strong></a>, the atomic unit that the model is
training on and making predictions on. A token is typically one of the
following:</p>

<ul>
<li>a word—for example, the phrase "dogs like cats" consists of three word
tokens: "dogs", "like", and "cats".</li>
<li>a character—for example, the phrase "bike fish" consists of nine
character tokens. (Note that the blank space counts as one of the tokens.)</li>
<li>subwords—in which a single word can be a single token or multiple tokens.
A subword consists of a root word, a prefix, or a suffix. For example,
a language model that uses subwords as tokens might view the word "dogs"
as two tokens (the root word "dog" and the plural suffix "s"). That same
language model might view the single word "taller" as two subwords (the
root word "tall" and the suffix "er").</li>
</ul>

<p>In domains outside of language models, tokens can represent other kinds of
atomic units. For example, in computer vision, a token might be a subset
of an image.</p>

<p><a class="glossary-anchor" name="tower"></a>
</p><h2 class="hide-from-toc" id="tower" data-text="tower" role="presentation"><span class="devsite-heading" role="heading" aria-level="2">tower</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: tower" data-title="Copy link to this section: tower" data-id="tower"></button></h2><p></p>

<p>A component of a <a href="https://developers.google.com/machine-learning/glossary#deep_neural_network"><strong>deep neural network</strong></a> that
is itself a deep neural network without an output layer. Typically,
each tower reads from an independent data source. Towers are independent
until their output is combined in a final layer.</p>

<p><a class="glossary-anchor" name="TPUabbrev"></a>
</p><h2 class="hide-from-toc" id="tpu" data-text=" TPU " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> TPU </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  TPU " data-title="Copy link to this section:  TPU " data-id="tpu"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
  <div class="glossary-icon" data-title="Google Cloud">#GoogleCloud</div>
</div><p></p>

<p>Abbreviation for <a href="https://developers.google.com/machine-learning/glossary#TPU"><strong>Tensor Processing Unit</strong></a>.</p>

<p><a class="glossary-anchor" name="TPU_chip"></a>
</p><h2 class="hide-from-toc" id="tpu-chip" data-text=" TPU chip " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> TPU chip </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  TPU chip " data-title="Copy link to this section:  TPU chip " data-id="tpu-chip"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
  <div class="glossary-icon" data-title="Google Cloud">#GoogleCloud</div>
</div><p></p>

<p>A programmable linear algebra accelerator with on-chip high bandwidth memory
that is optimized for machine learning workloads.
Multiple TPU chips are deployed on a <a href="https://developers.google.com/machine-learning/glossary#TPU_device"><strong>TPU device</strong></a>.</p>

<p><a class="glossary-anchor" name="TPU_device"></a>
</p><h2 class="hide-from-toc" id="tpu-device" data-text=" TPU device " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> TPU device </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  TPU device " data-title="Copy link to this section:  TPU device " data-id="tpu-device"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
  <div class="glossary-icon" data-title="Google Cloud">#GoogleCloud</div>
</div><p></p>

<p>A printed circuit board (PCB) with multiple <a href="https://developers.google.com/machine-learning/glossary#TPU_chip"><strong>TPU chips</strong></a>,
high bandwidth network interfaces, and system cooling hardware.</p>

<p><a class="glossary-anchor" name="TPU_master"></a>
</p><h2 class="hide-from-toc" id="tpu-master" data-text=" TPU master" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> TPU master</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  TPU master" data-title="Copy link to this section:  TPU master" data-id="tpu-master"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
  <div class="glossary-icon" data-title="Google Cloud">#GoogleCloud</div>
</div><p></p>

<p>The central coordination process running on a host machine that sends and
receives data, results, programs, performance, and system health information
to the <a href="https://developers.google.com/machine-learning/glossary#TPU_worker"><strong>TPU workers</strong></a>. The TPU master also manages the setup
and shutdown of <a href="https://developers.google.com/machine-learning/glossary#TPU_device"><strong>TPU devices</strong></a>.</p>

<p><a class="glossary-anchor" name="TPU_node"></a>
</p><h2 class="hide-from-toc" id="tpu-node" data-text=" TPU node " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> TPU node </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  TPU node " data-title="Copy link to this section:  TPU node " data-id="tpu-node"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
  <div class="glossary-icon" data-title="Google Cloud">#GoogleCloud</div>
</div><p></p>

<p>A TPU resource on Google Cloud Platform with a specific
<a href="https://developers.google.com/machine-learning/glossary#TPU_type"><strong>TPU type</strong></a>. The TPU node connects to your
<a href="https://cloud.google.com/vpc/docs/">VPC Network</a> from a
<a href="https://cloud.google.com/vpc/docs/vpc-peering">peer VPC network</a>.
TPU nodes are a resource defined in the
<a href="https://cloud.google.com/tpu/docs/reference/rest/v1/projects.locations.nodes">Cloud TPU API</a>.</p>

<p><a class="glossary-anchor" name="TPU_Pod"></a>
</p><h2 class="hide-from-toc" id="tpu-pod" data-text=" TPU Pod " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> TPU Pod </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  TPU Pod " data-title="Copy link to this section:  TPU Pod " data-id="tpu-pod"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
  <div class="glossary-icon" data-title="Google Cloud">#GoogleCloud</div>
</div><p></p>

<p>A specific configuration of <a href="https://developers.google.com/machine-learning/glossary#TPU_device"><strong>TPU devices</strong></a> in a Google
data center. All of the devices in a TPU pod are connected to one another
over a dedicated high-speed network. A TPU Pod is the largest configuration of
<a href="https://developers.google.com/machine-learning/glossary#TPU_device"><strong>TPU devices</strong></a> available for a specific TPU version.</p>

<p><a class="glossary-anchor" name="TPU_resource"></a>
</p><h2 class="hide-from-toc" id="tpu-resource" data-text=" TPU resource" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> TPU resource</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  TPU resource" data-title="Copy link to this section:  TPU resource" data-id="tpu-resource"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
  <div class="glossary-icon" data-title="Google Cloud">#GoogleCloud</div>
</div><p></p>

<p>A TPU entity on Google Cloud Platform that you create, manage, or consume. For
example, <a href="https://developers.google.com/machine-learning/glossary#TPU_node"><strong>TPU nodes</strong></a> and <a href="https://developers.google.com/machine-learning/glossary#TPU_type"><strong>TPU types</strong></a> are
TPU resources.</p>

<p><a class="glossary-anchor" name="TPU_slice"></a>
</p><h2 class="hide-from-toc" id="tpu-slice" data-text=" TPU slice" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> TPU slice</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  TPU slice" data-title="Copy link to this section:  TPU slice" data-id="tpu-slice"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
  <div class="glossary-icon" data-title="Google Cloud">#GoogleCloud</div>
</div><p></p>

<p>A TPU slice is a fractional portion of the <a href="https://developers.google.com/machine-learning/glossary#TPU_device"><strong>TPU devices</strong></a> in
a <a href="https://developers.google.com/machine-learning/glossary#TPU_Pod"><strong>TPU Pod</strong></a>. All of the devices in a TPU slice are connected
to one another over a dedicated high-speed network.</p>

<p><a class="glossary-anchor" name="TPU_type"></a>
</p><h2 class="hide-from-toc" id="tpu-type" data-text=" TPU type " role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> TPU type </span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  TPU type " data-title="Copy link to this section:  TPU type " data-id="tpu-type"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
  <div class="glossary-icon" data-title="Google Cloud">#GoogleCloud</div>
</div><p></p>

<p>A configuration of one or more <a href="https://developers.google.com/machine-learning/glossary#TPU_device"><strong>TPU devices</strong></a> with a specific
TPU hardware version. You select a TPU type when you create
a <a href="https://developers.google.com/machine-learning/glossary#TPU_node"><strong>TPU node</strong></a> on Google Cloud Platform. For example, a <code translate="no" dir="ltr">v2-8</code>
TPU type is a single TPU v2 device with 8 cores. A <code translate="no" dir="ltr">v3-2048</code> TPU type has 256
networked TPU v3 devices and a total of 2048 cores. TPU types are a resource
defined in the
<a href="https://cloud.google.com/tpu/docs/reference/rest/v1/projects.locations.acceleratorTypes">Cloud TPU API</a>.</p>

<p><a class="glossary-anchor" name="TPU_worker"></a>
</p><h2 class="hide-from-toc" id="tpu-worker" data-text=" TPU worker" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> TPU worker</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  TPU worker" data-title="Copy link to this section:  TPU worker" data-id="tpu-worker"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="TensorFlow">#TensorFlow</div>
  <div class="glossary-icon" data-title="Google Cloud">#GoogleCloud</div>
</div><p></p>

<p>A process that runs on a host machine and executes machine learning programs
on <a href="https://developers.google.com/machine-learning/glossary#TPU_device"><strong>TPU devices</strong></a>.</p>

<p><a class="glossary-anchor" name="training"></a>
</p><h2 class="hide-from-toc" id="training" data-text=" training" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> training</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  training" data-title="Copy link to this section:  training" data-id="training"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The process of determining the ideal <a href="https://developers.google.com/machine-learning/glossary#parameter"><strong>parameters</strong></a> (weights and
biases) comprising a <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a>. During training, a system reads in
<a href="https://developers.google.com/machine-learning/glossary#example"><strong>examples</strong></a> and gradually adjusts parameters. Training uses each
example anywhere from a few times to billions of times.</p>

<p><a class="glossary-anchor" name="training-loss"></a>
</p><h2 class="hide-from-toc" id="training-loss" data-text=" training loss" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> training loss</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  training loss" data-title="Copy link to this section:  training loss" data-id="training-loss"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#metric"><strong>metric</strong></a> representing a model's <a href="https://developers.google.com/machine-learning/glossary#loss"><strong>loss</strong></a> during a
particular training iteration. For example, suppose the loss function
is <a href="https://developers.google.com/machine-learning/glossary#MSE"><strong>Mean Squared Error</strong></a>. Perhaps the training loss (the Mean
Squared Error) for the 10th iteration is 2.2, and the training loss for
the 100th iteration is 1.9.</p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#loss_curve"><strong>loss curve</strong></a> plots training loss vs. the number of
iterations. A loss curve provides the following hints about training:</p>

<ul>
<li>A downward slope implies that the model is improving.</li>
<li>An upward slope implies that the model is getting worse.</li>
<li>A flat slope implies that the model has reached
<a href="https://developers.google.com/machine-learning/glossary#convergence"><strong>convergence</strong></a>.</li>
</ul>

<p>For example, the following somewhat idealized <a href="https://developers.google.com/machine-learning/glossary#loss_curve"><strong>loss curve</strong></a>
shows:</p>

<ul>
<li>A steep downward slope during the initial iterations, which implies
rapid model improvement.</li>
<li>A gradually flattening (but still downward) slope until close to the end
of training, which implies continued model improvement at a somewhat
slower pace then during the initial iterations.</li>
<li>A flat slope towards the end of training, which suggests convergence.</li>
</ul>

<p>
<img src="./ML_Glossary_files/TrainingLoss.png" loading="lazy" alt="The plot of training loss vs. iterations. This loss curve starts
     with a steep downward slope. The slope gradually flattens until the
     slope becomes zero.">
</p>

<p>Although training loss is important, see also
<a href="https://developers.google.com/machine-learning/glossary#generalization"><strong>generalization</strong></a>.</p>

<p><a class="glossary-anchor" name="training-serving-skew"></a>
</p><h2 class="hide-from-toc" id="training-serving-skew" data-text=" training-serving skew" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> training-serving skew</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  training-serving skew" data-title="Copy link to this section:  training-serving skew" data-id="training-serving-skew"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The difference between a model's performance during
<a href="https://developers.google.com/machine-learning/glossary#training"><strong>training</strong></a> and that same model's performance during
<a href="https://developers.google.com/machine-learning/glossary#serving"><strong>serving</strong></a>.</p>

<p><a class="glossary-anchor" name="training_set"></a>
</p><h2 class="hide-from-toc" id="training-set" data-text=" training set" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> training set</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  training set" data-title="Copy link to this section:  training set" data-id="training-set"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The subset of the <a href="https://developers.google.com/machine-learning/glossary#dataset"><strong>dataset</strong></a> used to train a <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a>.</p>

<p>Traditionally, examples in the dataset are divided into the following three
distinct subsets:</p>

<ul>
<li>a training set</li>
<li>a <a href="https://developers.google.com/machine-learning/glossary#validation_set"><strong>validation set</strong></a></li>
<li>a <a href="https://developers.google.com/machine-learning/glossary#test_set"><strong>test set</strong></a></li>
</ul>

<p>Ideally, each example in the dataset should belong to only one of the
preceding subsets. For example, a single example should not belong to
both the training set and the validation set.</p>

<p><a class="glossary-anchor" name="trajectory"></a>
</p><h2 class="hide-from-toc" id="trajectory" data-text=" trajectory" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> trajectory</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  trajectory" data-title="Copy link to this section:  trajectory" data-id="trajectory"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Reinforcement Learning">#rl</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#reinforcement_learning"><strong>reinforcement learning</strong></a>, a sequence of
<a href="https://wikipedia.org/wiki/Tuple" target="T">tuples</a> that represent
a sequence of <a href="https://developers.google.com/machine-learning/glossary#state"><strong>state</strong></a> transitions of the <a href="https://developers.google.com/machine-learning/glossary#agent"><strong>agent</strong></a>,
where each tuple corresponds to the state, <a href="https://developers.google.com/machine-learning/glossary#action"><strong>action</strong></a>,
<a href="https://developers.google.com/machine-learning/glossary#reward"><strong>reward</strong></a>, and next state for a given state transition.</p>

<p><a class="glossary-anchor" name="transfer_learning"></a>
</p><h2 class="hide-from-toc" id="transfer-learning" data-text=" transfer learning" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> transfer learning</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  transfer learning" data-title="Copy link to this section:  transfer learning" data-id="transfer-learning"></button></h2><p></p>

<p>Transferring information from one machine learning task to another.
For example, in multi-task learning, a single model solves multiple tasks,
such as a <a href="https://developers.google.com/machine-learning/glossary#deep_model"><strong>deep model</strong></a> that has different output nodes for
different tasks.  Transfer learning might involve transferring knowledge
from the solution of a simpler task to a more complex one, or involve
transferring knowledge from a task where there is more data to one where
there is less data.</p>

<p>Most machine learning systems solve a <em>single</em> task. Transfer learning is a
baby step towards artificial intelligence in which a single program can solve
<em>multiple</em> tasks.</p>

<p><a class="glossary-anchor" name="Transformer"></a>
<a class="glossary-anchor" name="transformer"></a>
</p><h2 class="hide-from-toc" id="transformer" data-text=" Transformer"> Transformer</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural network</strong></a> architecture developed at Google that
relies on <a href="https://developers.google.com/machine-learning/glossary#self-attention"><strong>self-attention</strong></a> mechanisms to transform a
sequence of input embeddings into a sequence of output
embeddings without relying on <a href="https://developers.google.com/machine-learning/glossary#convolution"><strong>convolutions</strong></a> or
<a href="https://developers.google.com/machine-learning/glossary#recurrent_neural_network"><strong>recurrent neural networks</strong></a>. A Transformer can be
viewed as a stack of self-attention layers.</p>

<p>A Transformer can include any of the following:</p>

<ul>
<li>an <a href="https://developers.google.com/machine-learning/glossary#encoder"><strong>encoder</strong></a></li>
<li>a <a href="https://developers.google.com/machine-learning/glossary#decoder"><strong>decoder</strong></a></li>
<li>both an encoder and decoder</li>
</ul>

<p>An <strong>encoder</strong> transforms a sequence of embeddings into a new sequence of the
same length. An encoder includes N identical layers, each of which contains two
sub-layers. These two sub-layers are applied at each position of the input
embedding sequence, transforming each element of the sequence into a new
embedding. The first encoder sub-layer aggregates information from across the
input sequence. The second encoder sub-layer transforms the aggregated
information into an output embedding.</p>

<p>A <strong>decoder</strong> transforms a sequence of input embeddings into a sequence of
output embeddings, possibly with a different length. A decoder also includes
N identical layers with three sub-layers, two of which are similar to the
encoder sub-layers. The third decoder sub-layer takes the output of the
encoder and applies the <a href="https://developers.google.com/machine-learning/glossary#self-attention"><strong>self-attention</strong></a> mechanism to
gather information from it.</p>

<p>The blog post <a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">Transformer: A Novel Neural Network Architecture for Language
Understanding</a>
provides a good introduction to Transformers.</p>

<p><a class="glossary-anchor" name="translational_invariance"></a>
</p><h2 class="hide-from-toc" id="translational-invariance" data-text=" translational invariance"> translational invariance</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Image Models">#image</div>
</div><p></p>

<p>In an image classification problem, an algorithm's ability to successfully
classify images even when the position of objects within the image changes.
For example, the algorithm can still identify a dog, whether it is in the
center of the frame or at the left end of the frame.</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#size_invariance"><strong>size invariance</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#rotational_invariance"><strong>rotational invariance</strong></a>.</p>

<p><a class="glossary-anchor" name="trigram"></a>
</p><h2 class="hide-from-toc" id="trigram" data-text=" trigram"> trigram</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Sequence Models">#seq</div>
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>An <a href="https://developers.google.com/machine-learning/glossary#N-gram"><strong>N-gram</strong></a> in which N=3.</p>

<p><a class="glossary-anchor" name="TN"></a>
</p><h2 class="hide-from-toc" id="true-negative-tn" data-text=" true negative (TN)"> true negative (TN)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>An example in which the model <em>correctly</em> predicts the
<a href="https://developers.google.com/machine-learning/glossary#negative_class"><strong>negative class</strong></a>. For example, the model infers that
a particular email message is <em>not spam</em>, and that email message really is
<em>not spam</em>.</p>

<p><a class="glossary-anchor" name="TP"></a>
</p><h2 class="hide-from-toc" id="true-positive-tp" data-text=" true positive (TP)"> true positive (TP)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>An example in which the model <em>correctly</em> predicts the
<a href="https://developers.google.com/machine-learning/glossary#positive_class"><strong>positive class</strong></a>. For example, the model infers that
a particular email message is spam, and that email message really is spam.</p>

<p><a class="glossary-anchor" name="TP_rate"></a>
</p><h2 class="hide-from-toc" id="true-positive-rate-tpr" data-text=" true positive rate (TPR)"> true positive rate (TPR)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Synonym for <a href="https://developers.google.com/machine-learning/glossary#recall"><strong>recall</strong></a>. That is:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-76-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;true positive rate&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtext&gt;true positives&lt;/mtext&gt;&lt;mrow&gt;&lt;mtext&gt;true positives&lt;/mtext&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;false negatives&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="51.813ex" height="5.571ex" viewBox="0 -1428.7 22308.5 2398.8" role="img" focusable="false" style="vertical-align: -2.253ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMAIN-74"></use><use href="#MJMAIN-72" x="389" y="0"></use><use href="#MJMAIN-75" x="782" y="0"></use><use href="#MJMAIN-65" x="1338" y="0"></use><use href="#MJMAIN-70" x="2033" y="0"></use><use href="#MJMAIN-6F" x="2589" y="0"></use><use href="#MJMAIN-73" x="3090" y="0"></use><use href="#MJMAIN-69" x="3484" y="0"></use><use href="#MJMAIN-74" x="3763" y="0"></use><use href="#MJMAIN-69" x="4152" y="0"></use><use href="#MJMAIN-76" x="4431" y="0"></use><use href="#MJMAIN-65" x="4959" y="0"></use><use href="#MJMAIN-72" x="5654" y="0"></use><use href="#MJMAIN-61" x="6046" y="0"></use><use href="#MJMAIN-74" x="6547" y="0"></use><use href="#MJMAIN-65" x="6936" y="0"></use><use href="#MJMAIN-3D" x="7658" y="0"></use><g transform="translate(8437,0)"><g transform="translate(397,0)"><rect stroke="none" width="13353" height="60" x="0" y="220"></rect><g transform="translate(3777,676)"><use href="#MJMAIN-74"></use><use href="#MJMAIN-72" x="389" y="0"></use><use href="#MJMAIN-75" x="782" y="0"></use><use href="#MJMAIN-65" x="1338" y="0"></use><use href="#MJMAIN-70" x="2033" y="0"></use><use href="#MJMAIN-6F" x="2589" y="0"></use><use href="#MJMAIN-73" x="3090" y="0"></use><use href="#MJMAIN-69" x="3484" y="0"></use><use href="#MJMAIN-74" x="3763" y="0"></use><use href="#MJMAIN-69" x="4152" y="0"></use><use href="#MJMAIN-76" x="4431" y="0"></use><use href="#MJMAIN-65" x="4959" y="0"></use><use href="#MJMAIN-73" x="5404" y="0"></use></g><g transform="translate(60,-686)"><use href="#MJMAIN-74"></use><use href="#MJMAIN-72" x="389" y="0"></use><use href="#MJMAIN-75" x="782" y="0"></use><use href="#MJMAIN-65" x="1338" y="0"></use><use href="#MJMAIN-70" x="2033" y="0"></use><use href="#MJMAIN-6F" x="2589" y="0"></use><use href="#MJMAIN-73" x="3090" y="0"></use><use href="#MJMAIN-69" x="3484" y="0"></use><use href="#MJMAIN-74" x="3763" y="0"></use><use href="#MJMAIN-69" x="4152" y="0"></use><use href="#MJMAIN-76" x="4431" y="0"></use><use href="#MJMAIN-65" x="4959" y="0"></use><use href="#MJMAIN-73" x="5404" y="0"></use><use href="#MJMAIN-2B" x="6020" y="0"></use><g transform="translate(7021,0)"><use href="#MJMAIN-66"></use><use href="#MJMAIN-61" x="306" y="0"></use><use href="#MJMAIN-6C" x="807" y="0"></use><use href="#MJMAIN-73" x="1085" y="0"></use><use href="#MJMAIN-65" x="1480" y="0"></use><use href="#MJMAIN-6E" x="2174" y="0"></use><use href="#MJMAIN-65" x="2731" y="0"></use><use href="#MJMAIN-67" x="3175" y="0"></use><use href="#MJMAIN-61" x="3676" y="0"></use><use href="#MJMAIN-74" x="4176" y="0"></use><use href="#MJMAIN-69" x="4566" y="0"></use><use href="#MJMAIN-76" x="4844" y="0"></use><use href="#MJMAIN-65" x="5373" y="0"></use><use href="#MJMAIN-73" x="5817" y="0"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>true positive rate</mtext><mo>=</mo><mfrac><mtext>true positives</mtext><mrow><mtext>true positives</mtext><mo>+</mo><mtext>false negatives</mtext></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-76">\text{true positive rate} = \frac{\text{true positives}} {\text{true positives} + \text{false negatives}}</script>
</div>

<p>True positive rate is the y-axis in an <a href="https://developers.google.com/machine-learning/glossary#ROC"><strong>ROC curve</strong></a>.</p>

<p><a class="glossary-anchor" name="u"></a>
</p><h2 class="glossary" id="u" data-text="U">U</h2><p></p>

<p><a class="glossary-anchor" name="unawareness"></a>
</p><h2 class="hide-from-toc" id="unawareness-to-a-sensitive-attribute" data-text=" unawareness (to a sensitive attribute)"> unawareness (to a sensitive attribute)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Fairness">#fairness</div>
</div><p></p>

<p>A situation in which <a href="https://developers.google.com/machine-learning/glossary#sensitive_attribute"><strong>sensitive attributes</strong></a> are
present, but not included in the training data. Because sensitive attributes
are often correlated with other attributes of one’s data, a model trained
with unawareness about a sensitive attribute could still have
<a href="https://developers.google.com/machine-learning/glossary#disparate_impact"><strong>disparate impact</strong></a> with respect to that attribute,
or violate other <a href="https://developers.google.com/machine-learning/glossary#fairness_constraint"><strong>fairness constraints</strong></a>.</p>

<p><a class="glossary-anchor" name="underfitting"></a>
</p><h2 class="hide-from-toc" id="underfitting" data-text=" underfitting"> underfitting</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Producing a <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> with poor predictive ability because the model
hasn't fully captured the complexity of the training data. Many problems
can cause underfitting, including:</p>

<ul>
<li>Training on the wrong set of <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>features</strong></a>.</li>
<li>Training for too few <a href="https://developers.google.com/machine-learning/glossary#epoch"><strong>epochs</strong></a> or at too low
a <a href="https://developers.google.com/machine-learning/glossary#learning_rate"><strong>learning rate</strong></a>.</li>
<li>Training with too high a <a href="https://developers.google.com/machine-learning/glossary#regularization_rate"><strong>regularization rate</strong></a>.</li>
<li>Providing too few <a href="https://developers.google.com/machine-learning/glossary#hidden_layer"><strong>hidden layers</strong></a> in a
deep neural network.</li>
</ul>

<p><a class="glossary-anchor" name="undersampling"></a>
</p><h2 class="hide-from-toc" id="undersampling" data-text=" undersampling"> undersampling</h2><p></p>

<p>Removing <a href="https://developers.google.com/machine-learning/glossary#example"><strong>examples</strong></a> from the
<a href="https://developers.google.com/machine-learning/glossary#majority_class"><strong>majority class</strong></a> in a
<a href="https://developers.google.com/machine-learning/glossary#class_imbalanced_data_set"><strong>class-imbalanced dataset</strong></a> in order to
create a more balanced <a href="https://developers.google.com/machine-learning/glossary#training_set"><strong>training set</strong></a>.</p>

<p>For example, consider a dataset in which the ratio of the majority class to
the <a href="https://developers.google.com/machine-learning/glossary#minority_class"><strong>minority class</strong></a> is 20:1. To overcome this class
imbalance, you could create a training set consisting of <em>all</em> of the minority
class examples but only a <em>tenth</em> of the majority class examples, which would
create a training-set class ratio of 2:1. Thanks to undersampling, this more
balanced training set might produce a better model. Alternatively, this
more balanced training set might contain insufficient examples to train an
effective model.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#oversampling"><strong>oversampling</strong></a>.</p>

<p><a class="glossary-anchor" name="unidirectional"></a>
</p><h2 class="hide-from-toc" id="unidirectional" data-text=" unidirectional"> unidirectional</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A system that only evaluates the text that <em>precedes</em> a target section of text.
In contrast, a bidirectional system evaluates both the
text that <em>precedes</em> and <em>follows</em> a target section of text.
See <a href="https://developers.google.com/machine-learning/glossary#bidirectional"><strong>bidirectional</strong></a> for more details.</p>

<p><a class="glossary-anchor" name="unidirectional-language-model"></a>
</p><h2 class="hide-from-toc" id="unidirectional-language-model" data-text=" unidirectional language model"> unidirectional language model</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#language-model"><strong>language model</strong></a> that bases its probabilities only on the
<a href="https://developers.google.com/machine-learning/glossary#token"><strong>tokens</strong></a> appearing <em>before</em>, not <em>after</em>, the target token(s).
Contrast with <a href="https://developers.google.com/machine-learning/glossary#bidirectional-language-model"><strong>bidirectional language model</strong></a>.</p>

<p><a class="glossary-anchor" name="unlabeled_example"></a>
</p><h2 class="hide-from-toc" id="unlabeled-example" data-text=" unlabeled example" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> unlabeled example</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  unlabeled example" data-title="Copy link to this section:  unlabeled example" data-id="unlabeled-example"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>An example that contains <a href="https://developers.google.com/machine-learning/glossary#feature"><strong>features</strong></a> but no <a href="https://developers.google.com/machine-learning/glossary#label"><strong>label</strong></a>.
For example, the following table shows three unlabeled examples from a house
valuation model, each with three features but no house value:</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr><th>Number of bedrooms</th> <th>Number of bathrooms</th>
      <th>House age</th> </tr>
  <tr><td>3</td> <td>2</td> <td>15</td> </tr>
  <tr><td>2</td> <td>1</td> <td>72</td> </tr>
  <tr><td>4</td> <td>2</td> <td>34</td> </tr>
</tbody></table></div>

<p>In <a href="https://developers.google.com/machine-learning/glossary#supervised_machine_learning"><strong>supervised machine learning</strong></a>,
models train on labeled examples and make predictions on
<a href="https://developers.google.com/machine-learning/glossary#unlabeled_example"><strong>unlabeled examples</strong></a>.</p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#semi-supervised_learning"><strong>semi-supervised</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#unsupervised_machine_learning"><strong>unsupervised</strong></a> learning,
unlabeled examples are used during training.</p>

<p>Contrast unlabeled example with <a href="https://developers.google.com/machine-learning/glossary#labeled_example"><strong>labeled example</strong></a>.</p>

<p><a class="glossary-anchor" name="unsupervised_machine_learning"></a>
</p><h2 class="hide-from-toc" id="unsupervised-machine-learning" data-text=" unsupervised machine learning"> unsupervised machine learning</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Clustering">#clustering</div>
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>Training a <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a> to find patterns in a dataset, typically an
unlabeled dataset.</p>

<p>The most common use of unsupervised machine learning is to
<a href="https://developers.google.com/machine-learning/glossary#clustering"><strong>cluster</strong></a> data
into groups of similar examples. For example, an unsupervised machine
learning algorithm can cluster songs based on various properties
of the music. The resulting clusters can become an input to other machine
learning algorithms (for example, to a music recommendation service).
Clustering can help when useful labels are scarce or absent.
For example, in domains such as anti-abuse and fraud, clusters can help
humans better understand the data.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#supervised_machine_learning"><strong>supervised machine learning</strong></a>.</p>

<devsite-expandable is-upgraded="" id="expandable-38"><a class="exw-control" aria-controls="expandable-38" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-for-additional-notes._15" data-text=" Click the icon for additional notes. ">
Click the icon for additional notes.<wbr>
</h4></a>



<div class="expand-background">
<p>
Another example of unsupervised machine learning is
<a href="https://wikipedia.org/wiki/Principal_component_analysis" target="T">principal component analysis (PCA)</a>.
For example, applying PCA on a
dataset containing the contents of millions of shopping carts might reveal
that shopping carts containing lemons frequently also contain antacids.
</p>
</div>

<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="uplift-modeling"></a>
</p><h2 class="hide-from-toc" id="uplift-modeling" data-text=" uplift modeling"> uplift modeling</h2><p></p>

<p>A modeling technique, commonly used in marketing, that models the
"causal effect" (also known as the "incremental impact") of a
"treatment" on an "individual."  Here are two examples:</p>

<ul>
<li>Doctors might use uplift modeling to predict the mortality decrease
(causal effect) of a medical procedure (treatment) depending on the
age and medical history of a patient (individual).</li>
<li>Marketers might use uplift modeling to predict the increase in
probability of a purchase (causal effect) due to an advertisement
(treatment) on a person (individual).</li>
</ul>

<p>Uplift modeling differs from <a href="https://developers.google.com/machine-learning/glossary#classification_model"><strong>classification</strong></a> or
<a href="https://developers.google.com/machine-learning/glossary#regression_model"><strong>regression</strong></a> in that some labels (for example, half
of the labels in binary treatments) are always missing in uplift modeling.
For example, a patient can either receive or not receive a treatment;
therefore, we can only observe whether the patient is going to heal or
not heal in only one of these two situations (but never both).
The main advantage of an uplift model is that it can generate predictions
for the unobserved situation (the counterfactual) and use it to compute
the causal effect.</p>

<p><a class="glossary-anchor" name="upweighting"></a>
</p><h2 class="hide-from-toc" id="upweighting" data-text=" upweighting"> upweighting</h2><p></p>

<p>Applying a weight to the <a href="https://developers.google.com/machine-learning/glossary#downsampling"><strong>downsampled</strong></a> class equal
to the factor by which you downsampled.</p>

<p><a class="glossary-anchor" name="user_matrix"></a>
</p><h2 class="hide-from-toc" id="user-matrix" data-text=" user matrix"> user matrix</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Recommendation Systems">#recsystems</div>
</div><p></p>

<p>In <a href="https://developers.google.com/machine-learning/glossary#recommendation_system"><strong>recommendation systems</strong></a>, an
<a href="https://developers.google.com/machine-learning/glossary#embedding_vector"><strong>embedding vector</strong></a> generated by
<a href="https://developers.google.com/machine-learning/glossary#matrix_factorization"><strong>matrix factorization</strong></a>
that holds latent signals about user preferences.
Each row of the user matrix holds information about the relative
strength of various latent signals for a single user.
For example, consider a movie recommendation system.  In this system,
the latent signals in the user matrix might represent each user's interest
in particular genres, or might be harder-to-interpret signals that involve
complex interactions across multiple factors.</p>

<p>The user matrix has a column for each latent feature and a row for each user.
That is, the user matrix has the same number of rows as the target
matrix that is being factorized. For example, given a movie
recommendation system for 1,000,000 users, the
user matrix will have 1,000,000 rows.</p>

<p><a class="glossary-anchor" name="v"></a>
</p><h2 class="glossary" id="v" data-text="V">V</h2><p></p>

<p><a class="glossary-anchor" name="validation"></a>
</p><h2 class="hide-from-toc" id="validation" data-text=" validation"> validation</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The initial evaluation of a model's quality.
Validation checks the quality of a model's predictions against the
<a href="https://developers.google.com/machine-learning/glossary#validation_set"><strong>validation set</strong></a>.</p>

<p>Because the validation set differs from the <a href="https://developers.google.com/machine-learning/glossary#training_set"><strong>training set</strong></a>,
validation helps guard against <a href="https://developers.google.com/machine-learning/glossary#overfitting"><strong>overfitting</strong></a>.</p>

<p>You might think of evaluating the model against the validation set as the
first round of testing and evaluating the model against the
<a href="https://developers.google.com/machine-learning/glossary#test_set"><strong>test set</strong></a> as the second round of testing.</p>

<p><a class="glossary-anchor" name="validation-loss"></a>
</p><h2 class="hide-from-toc" id="validation-loss" data-text=" validation loss"> validation loss</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#metric"><strong>metric</strong></a> representing a model's <a href="https://developers.google.com/machine-learning/glossary#loss"><strong>loss</strong></a> on
the <a href="https://developers.google.com/machine-learning/glossary#validation_set"><strong>validation set</strong></a> during a particular
<a href="https://developers.google.com/machine-learning/glossary#iteration"><strong>iteration</strong></a> of training.</p>

<p>See also <a href="https://developers.google.com/machine-learning/glossary#generalization_curve"><strong>generalization curve</strong></a>.</p>

<p><a class="glossary-anchor" name="validation_set"></a>
</p><h2 class="hide-from-toc" id="validation-set" data-text=" validation set"> validation set</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The subset of the <a href="https://developers.google.com/machine-learning/glossary#dataset"><strong>dataset</strong></a> that performs initial
evaluation against a trained <a href="https://developers.google.com/machine-learning/glossary#model"><strong>model</strong></a>. Typically, you evaluate
the trained model against the <a href="https://developers.google.com/machine-learning/glossary#validation_set"><strong>validation set</strong></a> several
times before evaluating the model against the <a href="https://developers.google.com/machine-learning/glossary#test_set"><strong>test set</strong></a>.</p>

<p>Traditionally, you divide the examples in the dataset into the following three
distinct subsets:</p>

<ul>
<li>a <a href="https://developers.google.com/machine-learning/glossary#training_set"><strong>training set</strong></a></li>
<li>a validation set</li>
<li>a <a href="https://developers.google.com/machine-learning/glossary#test_set"><strong>test set</strong></a></li>
</ul>

<p>Ideally, each example in the dataset should belong to only one of the
preceding subsets. For example, a single example should not belong to
both the training set and the validation set.</p>

<p><a class="glossary-anchor" name="vanishing_gradient_problem"></a>
</p><h2 class="hide-from-toc" id="vanishing-gradient-problem" data-text="vanishing gradient problem">vanishing gradient problem</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Sequence Models">#seq</div>
</div><p></p>

<p>The tendency for the gradients of early <a href="https://developers.google.com/machine-learning/glossary#hidden_layer"><strong>hidden layers</strong></a>
of some <a href="https://developers.google.com/machine-learning/glossary#deep_neural_network"><strong>deep neural networks</strong></a> to become
surprisingly flat (low). Increasingly lower gradients result in increasingly
smaller changes to the weights on nodes in a deep neural network, leading to
little or no learning. Models suffering from the vanishing gradient problem
become difficult or impossible to train.
<a href="https://developers.google.com/machine-learning/glossary#Long_Short-Term_Memory"><strong>Long Short-Term Memory</strong></a> cells address this issue.</p>

<p>Compare to <a href="https://developers.google.com/machine-learning/glossary#exploding_gradient_problem"><strong>exploding gradient problem</strong></a>.</p>

<p><a class="glossary-anchor" name="variable-importances"></a>
</p><h2 class="hide-from-toc" id="variable-importances" data-text=" variable importances "> variable importances </h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>A set of scores that indicates the relative importance of each
<a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a> to the model.</p>

<p>For example, consider a <a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a> that
estimates house prices. Suppose this decision tree uses three
features: size, age, and style. If a set of variable importances
for the three features are calculated to be
{size=5.8, age=2.5, style=4.7}, then size is more important to the
decision tree than age or style.</p>

<p>Different variable importance metrics exist, which can inform
ML experts about different aspects of models.</p>



<p><a class="glossary-anchor" name="w"></a>
</p><h2 class="glossary" id="w" data-text="W" role="presentation"><span class="devsite-heading" role="heading" aria-level="2">W</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section: W" data-title="Copy link to this section: W" data-id="w"></button></h2><p></p>

<p><a class="glossary-anchor" name="Wasserstein_loss"></a>
</p><h2 class="hide-from-toc" id="wasserstein-loss" data-text="Wasserstein loss">Wasserstein loss</h2><p></p>

<p>One of the loss functions commonly used in
<a href="https://developers.google.com/machine-learning/glossary#generative_adversarial_network"><strong>generative adversarial networks</strong></a>,
based on the <a href="https://developers.google.com/machine-learning/glossary#earth-movers-distance"><strong>earth mover's distance</strong></a> between
the distribution of generated data and real data.</p>



<p><a class="glossary-anchor" name="weight"></a>
</p><h2 class="hide-from-toc" id="weight" data-text=" weight"> weight</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A value that a model multiplies by another value.
<a href="https://developers.google.com/machine-learning/glossary#training"><strong>Training</strong></a> is the process of determining a model's ideal weights;
<a href="https://developers.google.com/machine-learning/glossary#inference"><strong>inference</strong></a> is the process of using those learned weights to
make predictions.</p>

<devsite-expandable is-upgraded="" id="expandable-39"><a class="exw-control" aria-controls="expandable-39" aria-expanded="false" tabindex="0" role="button"><h4 class="showalways" id="click-the-icon-to-see-an-example-of-weights-in-a-linear-model." data-text=" Click the icon to see an example of weights in a linear model. ">
Click the icon to see an example of weights in a linear model.<wbr>
</h4></a>



<div class="expand-background">
<p>
Imagine a <a href="https://developers.google.com/machine-learning/glossary#linear_model"><b>linear model</b></a> with two features.
Suppose that training determines the following weights (and
<a href="https://developers.google.com/machine-learning/glossary#bias">bias</a>):
</p>

<ul>
  <li>The bias, b, has a value of 2.2</li>
  <li>The weight, w<sub>1</sub> associated with one feature is 1.5.</li>
  <li>The weight, w<sub>2</sub> associated with the other feature is 0.4.</li>
</ul>

<p>Now imagine an <a href="https://developers.google.com/machine-learning/glossary#example">example</a> with the following feature
values:</p>

<ul>
  <li>The value of one feature, x<sub>1</sub>, is 6.</li>
  <li>The value of the other feature, x<sub>2</sub>, is 10.</li>
</ul>

<p>This linear model uses the following formula to generate a prediction,
y':</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-77-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msup&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;&amp;#x2032;&lt;/mo&gt;&lt;/msup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="21.827ex" height="2.731ex" viewBox="0 -868.2 9397.5 1175.9" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2032" x="706" y="583"></use><use href="#MJMAIN-3D" x="1072" y="0"></use><use href="#MJMATHI-62" x="2128" y="0"></use><use href="#MJMAIN-2B" x="2780" y="0"></use><g transform="translate(3780,0)"><use href="#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="1013" y="-213"></use></g><g transform="translate(4951,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-31" x="809" y="-213"></use></g><use href="#MJMAIN-2B" x="6199" y="0"></use><g transform="translate(7200,0)"><use href="#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="1013" y="-213"></use></g><g transform="translate(8371,0)"><use href="#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-32" x="809" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msup><mi>y</mi><mo>′</mo></msup><mo>=</mo><mi>b</mi><mo>+</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-77">y' = b + w_1x_1 + w_2x_2</script>
</div>

<p>Therefore, the prediction is:</p>

<div>
<span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-78-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msup&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;&amp;#x2032;&lt;/mo&gt;&lt;/msup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;2.2&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1.5&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;6&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;0.4&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;15.2&lt;/mn&gt;&lt;/math&gt;" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="37.497ex" height="2.731ex" viewBox="0 -868.2 16144.5 1175.9" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.715ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use href="#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" href="#MJMAIN-2032" x="706" y="583"></use><use href="#MJMAIN-3D" x="1072" y="0"></use><g transform="translate(2128,0)"><use href="#MJMAIN-32"></use><use href="#MJMAIN-2E" x="500" y="0"></use><use href="#MJMAIN-32" x="779" y="0"></use></g><use href="#MJMAIN-2B" x="3630" y="0"></use><use href="#MJMAIN-28" x="4630" y="0"></use><g transform="translate(5020,0)"><use href="#MJMAIN-31"></use><use href="#MJMAIN-2E" x="500" y="0"></use><use href="#MJMAIN-35" x="779" y="0"></use></g><use href="#MJMAIN-29" x="6299" y="0"></use><use href="#MJMAIN-28" x="6689" y="0"></use><use href="#MJMAIN-36" x="7078" y="0"></use><use href="#MJMAIN-29" x="7579" y="0"></use><use href="#MJMAIN-2B" x="8191" y="0"></use><use href="#MJMAIN-28" x="9191" y="0"></use><g transform="translate(9581,0)"><use href="#MJMAIN-30"></use><use href="#MJMAIN-2E" x="500" y="0"></use><use href="#MJMAIN-34" x="779" y="0"></use></g><use href="#MJMAIN-29" x="10860" y="0"></use><use href="#MJMAIN-28" x="11250" y="0"></use><g transform="translate(11639,0)"><use href="#MJMAIN-31"></use><use href="#MJMAIN-30" x="500" y="0"></use></g><use href="#MJMAIN-29" x="12640" y="0"></use><use href="#MJMAIN-3D" x="13308" y="0"></use><g transform="translate(14364,0)"><use href="#MJMAIN-31"></use><use href="#MJMAIN-35" x="500" y="0"></use><use href="#MJMAIN-2E" x="1001" y="0"></use><use href="#MJMAIN-32" x="1279" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msup><mi>y</mi><mo>′</mo></msup><mo>=</mo><mn>2.2</mn><mo>+</mo><mo stretchy="false">(</mo><mn>1.5</mn><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>0.4</mn><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mn>10</mn><mo stretchy="false">)</mo><mo>=</mo><mn>15.2</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-78">y' = 2.2 + (1.5)(6) + (0.4)(10) = 15.2</script>
</div>

<p>If a weight is 0, then the corresponding feature does not contribute to
the model. For example, if w<sub>1</sub> is 0, then the value of x<sub>1</sub>
is irrelevant.</p>

</div>
<hr>
</devsite-expandable>

<p><a class="glossary-anchor" name="WALS"></a>
</p><h2 class="hide-from-toc" id="weighted-alternating-least-squares-wals" data-text="Weighted Alternating Least Squares (WALS)">Weighted Alternating Least Squares (WALS)</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Recommendation Systems">#recsystems</div>
</div><p></p>

<p>An algorithm for minimizing the objective function during
<a href="https://developers.google.com/machine-learning/glossary#matrix_factorization"><strong>matrix factorization</strong></a> in
<a href="https://developers.google.com/machine-learning/glossary#recommendation_system"><strong>recommendation systems</strong></a>, which allows a
downweighting of the missing examples. WALS minimizes the weighted
squared error between the original matrix and the reconstruction by
alternating between fixing the row factorization and column factorization.
Each of these optimizations can be solved by least squares
<a href="https://developers.google.com/machine-learning/glossary#convex_optimization"><strong>convex optimization</strong></a>. For details, see the
<a href="https://developers.google.com/machine-learning/recommendation/collaborative/matrix" target="T" class="gc-analytics-event" data-category="launchRecommendationCourse" data-label="ml-glossary" data-action="click">Recommendation Systems course</a>.</p>

<p><a class="glossary-anchor" name="weighted_sum"></a>
</p><h2 class="hide-from-toc" id="weighted-sum" data-text=" weighted sum"> weighted sum</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>The sum of all the relevant input values multiplied by their corresponding
weights.  For example, suppose the relevant inputs consist of the following:</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr><td>input value</td> <td>input weight</td></tr>
  <tr><td>2</td> <td>-1.3</td></tr>
  <tr><td>-1</td> <td>0.6</td></tr>
  <tr><td>3</td> <td>0.4</td></tr>
</tbody></table></div>

<p>The weighted sum is therefore:</p>

<devsite-code data-copy-event-label=""><div class="devsite-code-buttons-container" role="group" aria-label="Action buttons"><button type="button" class="gc-analytics-event material-icons devsite-icon-code-dark devsite-toggle-dark" data-category="Site-Wide Custom Events" data-label="Dark Code Toggle" track-type="exampleCode" track-name="darkCodeToggle" aria-label="Dark code theme" data-title="Dark code theme"></button><button type="button" class="gc-analytics-event material-icons devsite-icon-code-light devsite-toggle-light" data-category="Site-Wide Custom Events" data-label="Light Code Toggle" track-type="exampleCode" track-name="lightCodeToggle" aria-label="Light code theme" data-title="Light code theme"></button><button type="button" class="gc-analytics-event material-icons devsite-icon-copy" data-category="Site-Wide Custom Events" data-label="Click To Copy" track-type="exampleCode" track-name="clickToCopy" aria-label="Copy code sample" data-title="Copy code sample"></button></div><pre class="" translate="no" dir="ltr" is-upgraded=""><span class="pln">weighted sum </span><span class="pun">=</span><span class="pln"> </span><span class="pun">(</span><span class="lit">2</span><span class="pun">)(-</span><span class="lit">1.3</span><span class="pun">)</span><span class="pln"> </span><span class="pun">+</span><span class="pln"> </span><span class="pun">(-</span><span class="lit">1</span><span class="pun">)(</span><span class="lit">0.6</span><span class="pun">)</span><span class="pln"> </span><span class="pun">+</span><span class="pln"> </span><span class="pun">(</span><span class="lit">3</span><span class="pun">)(</span><span class="lit">0.4</span><span class="pun">)</span><span class="pln"> </span><span class="pun">=</span><span class="pln"> </span><span class="pun">-</span><span class="lit">2.0</span><span class="pln"><br></span></pre></devsite-code>

<p>A weighted sum is the input argument to an
<a href="https://developers.google.com/machine-learning/glossary#activation_function"><strong>activation function</strong></a>.</p>

<p><a class="glossary-anchor" name="wide_model"></a>
</p><h2 class="hide-from-toc" id="wide-model" data-text=" wide model"> wide model</h2><p></p>

<p>A linear model that typically has many
<a href="https://developers.google.com/machine-learning/glossary#sparse_features"><strong>sparse input features</strong></a>. We refer to it as "wide" since
such a model is a special type of <a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural network</strong></a> with a
large number of inputs that connect directly to the output node. Wide models
are often easier to debug and inspect than <a href="https://developers.google.com/machine-learning/glossary#deep_model"><strong>deep models</strong></a>.
Although wide models
cannot express nonlinearities through <a href="https://developers.google.com/machine-learning/glossary#hidden_layer"><strong>hidden layers</strong></a>,
wide models can use transformations such as
<a href="https://developers.google.com/machine-learning/glossary#feature_cross"><strong>feature crossing</strong></a> and
<a href="https://developers.google.com/machine-learning/glossary#bucketing"><strong>bucketization</strong></a> to model nonlinearities in different ways.</p>

<p>Contrast with <a href="https://developers.google.com/machine-learning/glossary#deep_model"><strong>deep model</strong></a>.</p>

<p><a class="glossary-anchor" name="width"></a>
</p><h2 class="hide-from-toc" id="width" data-text=" width" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> width</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  width" data-title="Copy link to this section:  width" data-id="width"></button></h2><p></p>

<p>The number of <a href="https://developers.google.com/machine-learning/glossary#neuron"><strong>neurons</strong></a> in a particular <a href="https://developers.google.com/machine-learning/glossary#layer"><strong>layer</strong></a>
of a <a href="https://developers.google.com/machine-learning/glossary#neural_network"><strong>neural network</strong></a>.</p>

<p><a class="glossary-anchor" name="wisdom-of-the-crowd"></a>
</p><h2 class="hide-from-toc" id="wisdom-of-the-crowd" data-text=" wisdom of the crowd" role="presentation"><span class="devsite-heading" role="heading" aria-level="2"> wisdom of the crowd</span><button type="button" class="devsite-heading-link button-flat material-icons" aria-label="Copy link to this section:  wisdom of the crowd" data-title="Copy link to this section:  wisdom of the crowd" data-id="wisdom-of-the-crowd"></button></h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Decision Forests">#df</div>
</div><p></p>

<p>The idea that averaging the opinions or estimates of a large group
of people ("the crowd") often produces surprisingly good results.
For example, consider a game in which people guess the number of
jelly beans packed into a large jar. Although most individual
guesses will be inaccurate, the average of all the guesses has been
empirically shown to be surprisingly close to the actual number of
jelly beans in the jar.</p>

<p><a href="https://developers.google.com/machine-learning/glossary#ensemble"><strong>Ensembles</strong></a> are a software analog of wisdom of the crowd.
Even if individual models make wildly inaccurate predictions,
averaging the predictions of many models often generates surprisingly
good predictions. For example, although an individual
<a href="https://developers.google.com/machine-learning/glossary#decision-tree"><strong>decision tree</strong></a> might make poor predictions, a
<a href="https://developers.google.com/machine-learning/glossary#decision-forest"><strong>decision forest</strong></a> often makes very good predictions.</p>

<p><a class="glossary-anchor" name="word-embedding"></a>
</p><h2 class="hide-from-toc" id="word-embedding" data-text=" word embedding"> word embedding</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="Language Evaluation">#language</div>
</div><p></p>

<p><a href="https://developers.google.com/machine-learning/glossary#representation"><strong>Representing</strong></a> each word in a word set within an
<a href="https://developers.google.com/machine-learning/glossary#embedding_vector"><strong>embedding vector</strong></a>; that is, representing each word as
a vector of floating-point values between 0.0 and 1.0.  Words with similar
meanings have more-similar representations than words with different meanings.
For example, <em>carrots</em>, <em>celery</em>, and <em>cucumbers</em> would all have relatively
similar representations, which would be very different from the representations
of <em>airplane</em>, <em>sunglasses</em>, and <em>toothpaste</em>.</p>

<p><a class="glossary-anchor" name="z"></a>
</p><h2 class="glossary" id="z" data-text="Z">Z</h2><p></p>

<p><a class="glossary-anchor" name="Z-score-normalization"></a>
</p><h2 class="hide-from-toc" id="z-score-normalization" data-text=" Z-score normalization"> Z-score normalization</h2>
<div class="glossary-icon-container">
  <div class="glossary-icon" data-title="ML Fundamentals">#fundamentals</div>
</div><p></p>

<p>A <a href="https://developers.google.com/machine-learning/glossary#scaling"><strong>scaling</strong></a> technique that replaces a raw
<a href="https://developers.google.com/machine-learning/glossary#feature"><strong>feature</strong></a> value with a floating-point value representing
the number of standard deviations from that feature's mean.
For example, consider a feature whose mean is 800 and whose standard
deviation is 100. The following table shows how Z-score normalization
would map the raw value to its Z-score:</p>

<div class="devsite-table-wrapper"><table>
  <tbody><tr> <th>Raw value</th> <th>Z-score</th> </tr>
  <tr> <td>800</td>       <td>0</td>       </tr>
  <tr> <td>950</td>       <td>+1.5</td>    </tr>
  <tr> <td>575</td>       <td>-2.25</td>   </tr>
</tbody></table></div>

<p>The machine learning model then trains on the Z-scores
for that feature instead of on the raw values.</p>
  

  
</div>

  

  
    
      <devsite-recommendations display="in-page" hidden="" yield="">
      </devsite-recommendations>
    
    
      
    <devsite-thumb-rating position="footer"><div class="devsite-thumb-rating" role="form" aria-labelledby="devsite-thumb-label-footer" tabindex="0"><div class="devsite-thumb-label" id="devsite-thumb-label-footer">Was this helpful?</div><div class="devsite-thumbs"><button class="devsite-thumb devsite-thumb-up" data-title="Helpful" aria-label="Helpful"><svg class="devsite-thumb-icon" viewBox="0 0 24 24" aria-hidden="true"><path d="M21,7h-6.31l0.95-4.57l0.03-0.32c0-0.41-0.17-0.79-0.44-1.06L14.17,0c0,0-7.09,6.85-7.17,7H2v13h16 c0.83,0,1.54-0.5,1.84-1.22l3.02-7.05C22.95,11.5,23,11.26,23,11V9C23,7.9,22.1,7,21,7z M7,18H4V9h3V18z M21,11l-3,7H9V8l4.34-4.34 L12,9h9V11z"></path></svg></button><button class="devsite-thumb devsite-thumb-down" data-title="Not helpful" aria-label="Not helpful"><svg class="devsite-thumb-icon" viewBox="0 0 24 24" aria-hidden="true"><path d="M3,17h6.31l-0.95,4.57l-0.03,0.32c0,0.41,0.17,0.79,0.44,1.06L9.83,24c0,0,7.09-6.85,7.17-7h5V4H6 C5.17,4,4.46,4.5,4.16,5.22l-3.02,7.05C1.05,12.5,1,12.74,1,13v2C1,16.1,1.9,17,3,17z M17,6h3v9h-3V6z M3,13l3-7h9v10l-4.34,4.34 L12,15H3V13z"></path></svg></button></div></div></devsite-thumb-rating>
  
       
         <devsite-feedback position="footer" project-name="Machine Learning" product-id="5005867" bucket="" context="" version="t-devsite-webserver-20230110-r01-rc00.449249680248403396" data-label="Send Feedback Button" track-type="feedback" track-name="sendFeedbackLink" track-metadata-position="footer" project-icon="https://www.gstatic.com/devrel-devsite/prod/v4fdbc33a55781dc592d32bc0c5d1eb8f6c96a05c8dafb5ba814fcab1c6bf1229/developers/images/touchicon-180.png" feedback-type="thumb-rating">

  <button>
  
    
    Send feedback
  
  </button>
</devsite-feedback>
       
    
    
      <devsite-recommendations id="recommendations-link" yield=""><div class="significatio-overview"><h2 class="significatio-heading no-link">Recommended for you</h2><div class="info-container"><button type="button" class="button-flat info-button significatio-info-container" id="significatio-info-button" aria-label="About recommendations" data-title="About recommendations"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="significatio-icon-info"><path d="M11 7h2v2h-2zm0 4h2v6h-2zm1-9C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 18c-4.41 0-8-3.59-8-8s3.59-8 8-8 8 3.59 8 8-3.59 8-8 8z"></path></svg></button></div><div class="significatio-buttons"></div></div><div class="significatio-body"><div class="significatio-recommendations"><div class="significatio-card" show=""><h3 class="significatio-card-heading no-link"><a href="https://developers.google.com/machine-learning/crash-course/prereqs-and-prework?rec=CjdodHRwczovL2RldmVsb3BlcnMuZ29vZ2xlLmNvbS9tYWNoaW5lLWxlYXJuaW5nL2dsb3NzYXJ5EAEYDSABKAMwFjoIMzkzMDAzNzc" data-category="Site-Wide Custom Events" data-label="devsite-recommendation card link" data-action="click" track-type="recommendations" track-name="cardClick" track-metadata-eventdetail="https://developers.google.com/machine-learning/crash-course/prereqs-and-prework">Prerequisites and Prework</a></h3><p class="significatio-card-description">Please read through the following Prework and Prerequisites sections before beginning Machine Learning Crash Course, to
ensure you are prepared to complete all the modules. Before beginning Machine Learning Crash Course, do the following: Programming</p><div class="significatio-card-meta">Updated <span class="significatio-date" date="1658177971">19 Jul 2022</span></div></div><div class="significatio-card" show=""><h3 class="significatio-card-heading no-link"><a href="https://developers.google.com/machine-learning/crash-course?rec=CjdodHRwczovL2RldmVsb3BlcnMuZ29vZ2xlLmNvbS9tYWNoaW5lLWxlYXJuaW5nL2dsb3NzYXJ5EAIYDSABMB86CDM5MzAwMzc3" data-category="Site-Wide Custom Events" data-label="devsite-recommendation card link" data-action="click" track-type="recommendations" track-name="cardClick" track-metadata-eventdetail="https://developers.google.com/machine-learning/crash-course">Machine Learning</a></h3><p class="significatio-card-description">Send feedback Stay organized with collections Save and categorize content based on your preferences. Google's fast-paced, practical introduction to machine learning, featuring a series of lessons with video lectures, real-world case studies, and</p><div class="significatio-card-meta">Updated <span class="significatio-date" date="1658177971">19 Jul 2022</span></div></div><div class="significatio-card" show=""><h3 class="significatio-card-heading no-link"><a href="https://developers.google.com/machine-learning/crash-course/ml-intro?rec=CjdodHRwczovL2RldmVsb3BlcnMuZ29vZ2xlLmNvbS9tYWNoaW5lLWxlYXJuaW5nL2dsb3NzYXJ5EAMYDSABKAQwBDoIMzkzMDAzNzc" data-category="Site-Wide Custom Events" data-label="devsite-recommendation card link" data-action="click" track-type="recommendations" track-name="cardClick" track-metadata-eventdetail="https://developers.google.com/machine-learning/crash-course/ml-intro">Introduction to Machine Learning</a></h3><p class="significatio-card-description">This module introduces Machine Learning (ML).</p><div class="significatio-card-meta">Updated <span class="significatio-date" date="1658177971">19 Jul 2022</span></div></div></div><div class="significatio-loading"><devsite-spinner size="64" style="height: 64px; width: 64px;"></devsite-spinner></div></div></devsite-recommendations>
    
  

  
  
</article>


<devsite-content-footer class="nocontent">
  <p>Except as otherwise noted, the content of this page is licensed under the <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 License</a>, and code samples are licensed under the <a href="https://www.apache.org/licenses/LICENSE-2.0">Apache 2.0 License</a>. For details, see the <a href="https://developers.google.com/site-policies">Google Developers Site Policies</a>. Java is a registered trademark of Oracle and/or its affiliates.</p>
  <p>Last updated 2022-11-07 UTC.</p>
</devsite-content-footer>


<devsite-notification>
</devsite-notification>


  
<div class="devsite-content-data">
  <template class="devsite-thumb-rating-down-categories"></template>
  <template class="devsite-thumb-rating-up-categories"></template>
  
    
    
    <template class="devsite-thumb-rating-feedback"></template>
  
</div>
            
          </devsite-content>
        </main>
        <devsite-footer-promos class="devsite-footer">
          
            
          
        </devsite-footer-promos>
        <devsite-footer-linkboxes class="devsite-footer">
          
            
<nav class="devsite-footer-linkboxes nocontent" aria-label="Footer links">
  
  <ul class="devsite-footer-linkboxes-list">
    
    <li class="devsite-footer-linkbox ">
    <h3 class="devsite-footer-linkbox-heading no-link">Connect</h3>
      <ul class="devsite-footer-linkbox-list">
        
        <li class="devsite-footer-linkbox-item">
          
          <a href="https://googledevelopers.blogspot.com/" class="devsite-footer-linkbox-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Link (index 1)">
            
          
            Blog
          
          </a>
          
          
        </li>
        
        <li class="devsite-footer-linkbox-item">
          
          <a href="https://www.facebook.com/Google-Developers-967415219957038" class="devsite-footer-linkbox-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Link (index 2)">
            
          
            Facebook
          
          </a>
          
          
        </li>
        
        <li class="devsite-footer-linkbox-item">
          
          <a href="https://medium.com/google-developers" class="devsite-footer-linkbox-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Link (index 3)">
            
          
            Medium
          
          </a>
          
          
        </li>
        
        <li class="devsite-footer-linkbox-item">
          
          <a href="https://twitter.com/googledevs" class="devsite-footer-linkbox-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Link (index 4)">
            
          
            Twitter
          
          </a>
          
          
        </li>
        
        <li class="devsite-footer-linkbox-item">
          
          <a href="https://www.youtube.com/user/GoogleDevelopers" class="devsite-footer-linkbox-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Link (index 5)">
            
              
              
            
          
            YouTube
          
          </a>
          
          
        </li>
        
      </ul>
    </li>
    
    <li class="devsite-footer-linkbox ">
    <h3 class="devsite-footer-linkbox-heading no-link">Programs</h3>
      <ul class="devsite-footer-linkbox-list">
        
        <li class="devsite-footer-linkbox-item">
          
          <a href="https://www.womentechmakers.com/" class="devsite-footer-linkbox-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Link (index 1)">
            
          
            Women Techmakers
          
          </a>
          
          
        </li>
        
        <li class="devsite-footer-linkbox-item">
          
          <a href="https://developers.google.com/community/gdg" class="devsite-footer-linkbox-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Link (index 2)">
            
          
            Google Developer Groups
          
          </a>
          
          
        </li>
        
        <li class="devsite-footer-linkbox-item">
          
          <a href="https://developers.google.com/community/experts" class="devsite-footer-linkbox-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Link (index 3)">
            
          
            Google Developers Experts
          
          </a>
          
          
        </li>
        
        <li class="devsite-footer-linkbox-item">
          
          <a href="https://developers.google.com/community/accelerators" class="devsite-footer-linkbox-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Link (index 4)">
            
          
            Accelerators
          
          </a>
          
          
        </li>
        
        <li class="devsite-footer-linkbox-item">
          
          <a href="https://developers.google.com/community/gdsc" class="devsite-footer-linkbox-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Link (index 5)">
            
              
              
            
          
            Google Developer Student Clubs
          
          </a>
          
          
        </li>
        
      </ul>
    </li>
    
    <li class="devsite-footer-linkbox ">
    <h3 class="devsite-footer-linkbox-heading no-link">Developer consoles</h3>
      <ul class="devsite-footer-linkbox-list">
        
        <li class="devsite-footer-linkbox-item">
          
          <a href="https://console.developers.google.com/" class="devsite-footer-linkbox-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Link (index 1)">
            
          
            Google API Console
          
          </a>
          
          
        </li>
        
        <li class="devsite-footer-linkbox-item">
          
          <a href="https://console.cloud.google.com/" class="devsite-footer-linkbox-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Link (index 2)">
            
          
            Google Cloud Platform Console
          
          </a>
          
          
        </li>
        
        <li class="devsite-footer-linkbox-item">
          
          <a href="https://play.google.com/apps/publish" class="devsite-footer-linkbox-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Link (index 3)">
            
          
            Google Play Console
          
          </a>
          
          
        </li>
        
        <li class="devsite-footer-linkbox-item">
          
          <a href="https://console.firebase.google.com/" class="devsite-footer-linkbox-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Link (index 4)">
            
          
            Firebase Console
          
          </a>
          
          
        </li>
        
        <li class="devsite-footer-linkbox-item">
          
          <a href="https://console.actions.google.com/" class="devsite-footer-linkbox-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Link (index 5)">
            
          
            Actions on Google Console
          
          </a>
          
          
        </li>
        
        <li class="devsite-footer-linkbox-item">
          
          <a href="https://cast.google.com/publish" class="devsite-footer-linkbox-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Link (index 6)">
            
          
            Cast SDK Developer Console
          
          </a>
          
          
        </li>
        
        <li class="devsite-footer-linkbox-item">
          
          <a href="https://chrome.google.com/webstore/developer/dashboard" class="devsite-footer-linkbox-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Link (index 7)">
            
              
              
            
          
            Chrome Web Store Dashboard
          
          </a>
          
          
        </li>
        
      </ul>
    </li>
    
  </ul>
  
</nav>
          
        </devsite-footer-linkboxes>
        <devsite-footer-utility class="devsite-footer">
          
            

<div class="devsite-footer-utility nocontent">
  
  
  <nav class="devsite-footer-sites" aria-label="Other Google Developers websites">
    <a href="https://developers.google.com/" class="devsite-footer-sites-logo-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Google Developers Link">
      <picture>
        <source srcset="https://www.gstatic.com/devrel-devsite/prod/v4fdbc33a55781dc592d32bc0c5d1eb8f6c96a05c8dafb5ba814fcab1c6bf1229/developers/images/lockup-developers-dark-theme.svg" media="(prefers-color-scheme: none)" class="devsite-dark-theme" loading="lazy" alt="Google Developers">
        <img class="devsite-footer-sites-logo" src="./ML_Glossary_files/lockup-developers.svg" loading="lazy" alt="Google Developers">
      </picture>
    </a>
    <ul class="devsite-footer-sites-list">
      
      <li class="devsite-footer-sites-item">
        <a href="https://developer.android.com/" class="devsite-footer-sites-link
                  gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Android Link">
          Android
        </a>
      </li>
      
      <li class="devsite-footer-sites-item">
        <a href="https://developer.chrome.com/home" class="devsite-footer-sites-link
                  gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Chrome Link">
          Chrome
        </a>
      </li>
      
      <li class="devsite-footer-sites-item">
        <a href="https://firebase.google.com/" class="devsite-footer-sites-link
                  gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Firebase Link">
          Firebase
        </a>
      </li>
      
      <li class="devsite-footer-sites-item">
        <a href="https://cloud.google.com/" class="devsite-footer-sites-link
                  gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer Google Cloud Platform Link">
          Google Cloud Platform
        </a>
      </li>
      
      <li class="devsite-footer-sites-item">
        <a href="https://developers.google.com/products" class="devsite-footer-sites-link
                  gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Footer All products Link">
          All products
        </a>
      </li>
      
    </ul>
  </nav>
  

  
  <nav class="devsite-footer-utility-links" aria-label="Utility links">
    
    <ul class="devsite-footer-utility-list">
      
      <li class="devsite-footer-utility-item
                 ">
        
        
        <a class="devsite-footer-utility-link gc-analytics-event" href="https://developers.google.com/terms/site-terms" data-category="Site-Wide Custom Events" data-label="Footer Terms link">
          Terms
        </a>
        
      </li>
      
      <li class="devsite-footer-utility-item
                 ">
        
        
        <a class="devsite-footer-utility-link gc-analytics-event" href="https://policies.google.com/privacy" data-category="Site-Wide Custom Events" data-label="Footer Privacy link">
          Privacy
        </a>
        
      </li>
      
      <li class="devsite-footer-utility-item
                 devsite-footer-utility-button">
        
        <span class="devsite-footer-utility-description">Sign up for the Google Developers newsletter</span>
        
        
        <a class="devsite-footer-utility-link gc-analytics-event" href="https://services.google.com/fb/forms/googledevelopersnewsletter/?utm_medium=referral&amp;utm_source=google-products&amp;utm_team=googledevs&amp;utm_campaign=201611-newsletter-launch" data-category="Site-Wide Custom Events" data-label="Footer Subscribe link">
          Subscribe
        </a>
        
      </li>
      
    </ul>
    
    
<devsite-language-selector aria-label="Select your language preference.">
  <ul role="presentation">
    
    
    <li role="presentation">
      <a role="menuitem" lang="en" href="https://developers.google.com/machine-learning/glossary" aria-current="true">English</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="id" href="https://developers.google.com/machine-learning/glossary?hl=id">Bahasa Indonesia</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="de" href="https://developers.google.com/machine-learning/glossary?hl=de">Deutsch</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="es" href="https://developers.google.com/machine-learning/glossary?hl=es">Español</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="es-419" href="https://developers.google.com/machine-learning/glossary?hl=es-419">Español – América Latina</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="fr" href="https://developers.google.com/machine-learning/glossary?hl=fr">Français</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="it" href="https://developers.google.com/machine-learning/glossary?hl=it">Italiano</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="pl" href="https://developers.google.com/machine-learning/glossary?hl=pl">Polski</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="pt-br" href="https://developers.google.com/machine-learning/glossary?hl=pt-br">Português – Brasil</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="vi" href="https://developers.google.com/machine-learning/glossary?hl=vi">Tiếng Việt</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="tr" href="https://developers.google.com/machine-learning/glossary?hl=tr">Türkçe</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="ru" href="https://developers.google.com/machine-learning/glossary?hl=ru">Русский</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="he" href="https://developers.google.com/machine-learning/glossary?hl=he">עברית</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="ar" href="https://developers.google.com/machine-learning/glossary?hl=ar">العربيّة</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="fa" href="https://developers.google.com/machine-learning/glossary?hl=fa">فارسی</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="hi" href="https://developers.google.com/machine-learning/glossary?hl=hi">हिंदी</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="bn" href="https://developers.google.com/machine-learning/glossary?hl=bn">বাংলা</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="th" href="https://developers.google.com/machine-learning/glossary?hl=th">ภาษาไทย</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="zh-cn" href="https://developers.google.com/machine-learning/glossary?hl=zh-cn">中文 – 简体</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="zh-tw" href="https://developers.google.com/machine-learning/glossary?hl=zh-tw">中文 – 繁體</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="ja" href="https://developers.google.com/machine-learning/glossary?hl=ja">日本語</a>
    </li>
    
    <li role="presentation">
      <a role="menuitem" lang="ko" href="https://developers.google.com/machine-learning/glossary?hl=ko">한국어</a>
    </li>
    
  </ul>
</devsite-language-selector>

  </nav>
</div>
          
        </devsite-footer-utility>
        <devsite-panel style="height: auto;"></devsite-panel>
      </section></section>
    <devsite-sitemask></devsite-sitemask>
    <devsite-snackbar style="bottom: 0px;">
</devsite-snackbar>
    <devsite-tooltip></devsite-tooltip>
    <devsite-heading-link></devsite-heading-link>
    <devsite-analytics analytics-iframe="">
      
        <script type="application/json" analytics="">[{&#34;dimensions&#34;: {&#34;dimension3&#34;: false, &#34;dimension6&#34;: &#34;en&#34;, &#34;dimension5&#34;: &#34;en&#34;, &#34;dimension11&#34;: false, &#34;dimension4&#34;: &#34;Machine Learning&#34;, &#34;dimension1&#34;: &#34;Signed In&#34;}, &#34;gaid&#34;: &#34;UA-24532603-1&#34;, &#34;metrics&#34;: {&#34;ratings_value&#34;: &#34;metric1&#34;, &#34;ratings_count&#34;: &#34;metric2&#34;}}, {&#34;dimensions&#34;: {&#34;dimension3&#34;: false, &#34;dimension6&#34;: &#34;en&#34;, &#34;dimension5&#34;: &#34;en&#34;, &#34;dimension11&#34;: false, &#34;dimension4&#34;: &#34;Machine Learning&#34;, &#34;dimension1&#34;: &#34;Signed In&#34;}, &#34;gaid&#34;: &#34;UA-105980039-1&#34;, &#34;metrics&#34;: {&#34;ratings_value&#34;: &#34;metric1&#34;, &#34;ratings_count&#34;: &#34;metric2&#34;}}]</script>
<script type="application/json" gtm="">{&#34;parameters&#34;: {&#34;internalUser&#34;: &#34;False&#34;, &#34;language&#34;: {&#34;machineTranslated&#34;: &#34;False&#34;, &#34;requested&#34;: &#34;en&#34;, &#34;served&#34;: &#34;en&#34;}, &#34;pageType&#34;: &#34;article&#34;, &#34;projectName&#34;: &#34;Machine Learning&#34;, &#34;signedIn&#34;: &#34;True&#34;, &#34;tenant&#34;: &#34;developers&#34;, &#34;recommendations&#34;: {&#34;sourcePage&#34;: &#34;&#34;, &#34;sourceType&#34;: 0, &#34;sourceRank&#34;: 0, &#34;sourceIdenticalDescriptions&#34;: 0, &#34;sourceTitleWords&#34;: 0, &#34;sourceDescriptionWords&#34;: 0, &#34;experiment&#34;: &#34;&#34;}, &#34;experiment&#34;: {&#34;ids&#34;: &#34;&#34;}}, &#34;tags&#34;: []}</script>
      
    <iframe src="./ML_Glossary_files/analytics-iframe.html"></iframe></devsite-analytics>
    
      <devsite-badger></devsite-badger>
    
    
    <script nonce="">
  
  (function(d,e,v,s,i,t,E){d['GoogleDevelopersObject']=i;
    t=e.createElement(v);t.async=1;t.src=s;E=e.getElementsByTagName(v)[0];
    E.parentNode.insertBefore(t,E);})(window, document, 'script',
    'https://www.gstatic.com/devrel-devsite/prod/v4fdbc33a55781dc592d32bc0c5d1eb8f6c96a05c8dafb5ba814fcab1c6bf1229/developers/js/app_loader.js', '[1,"en",null,"/js/devsite_app_module.js","https://www.gstatic.com/devrel-devsite/prod/v4fdbc33a55781dc592d32bc0c5d1eb8f6c96a05c8dafb5ba814fcab1c6bf1229","https://www.gstatic.com/devrel-devsite/prod/v4fdbc33a55781dc592d32bc0c5d1eb8f6c96a05c8dafb5ba814fcab1c6bf1229/developers","https://developers-dot-devsite-v2-prod.appspot.com",1,null,["/_pwa/developers/manifest.json","https://www.gstatic.com/devrel-devsite/prod/v4fdbc33a55781dc592d32bc0c5d1eb8f6c96a05c8dafb5ba814fcab1c6bf1229/images/video-placeholder.svg","https://www.gstatic.com/devrel-devsite/prod/v4fdbc33a55781dc592d32bc0c5d1eb8f6c96a05c8dafb5ba814fcab1c6bf1229/developers/images/favicon.png","https://fonts.googleapis.com/css?family=Google+Sans:400,500|Roboto:400,400italic,500,500italic,700,700italic|Roboto+Mono:400,500,700&display=swap"],1,null,[1,6,8,12,14,17,21,25,40,50,52,63,70,75,76,80,87,91,92,93,97,98,100,101,102,103,104,105,107,108,109,110,111,112,113,115,116,117,118,120,122,124,125,126,127,129,130,131,132,133,134,135,136,138,140,141,144,147,148,149,150,151,152,154,155,156,157,158,159,161,163,164,165,168,169,170,172,173,179,180,182,183,186,190,191,193,196],"AIzaSyAP-jjEJBzmIyKR4F-3XITp8yM9T1gEEI8","AIzaSyB6xiKGDR5O3Ak2okS4rLkauxGUG7XP0hg","developers.google.com","AIzaSyAQk0fBONSGUqCNznf6Krs82Ap1-NV6J4o","AIzaSyCCxcqdrZ_7QMeLCRY20bh_SXdAYqy70KY",null,null,null,["SignIn__enable_auto_signin_oauth","Experiments__enable_experiments","Badges__enable_delete_badges","Profiles__require_profile_eligibility_for_signin","BookNav__enable_collapsible_book_nav","Cloud__enable_cloudx_experiment_ids","Cloud__enable_cloud_shell_fte_user_flow","Search__enable_page_map","Search__enable_suggestions_from_borg","Search__enable_devsite_serp","Experiments__reqs_query_experiments","Profiles__enable_page_saving","MiscFeatureFlags__enable_footprints_record_views","Badges__enable_drag_and_drop_badges","BookNav__enable_book_nav_filtering","Profiles__enable_profile_collections","Search__enable_acl_suggestions","Profiles__enable_developer_profiles_interests","Significatio__enable_by_tenant","Profiles__enable_public_developer_profiles","MiscFeatureFlags__emergency_css","Cloud__enable_cloud_dlp_service","Significatio__enable_experiment_id_caching","Profiles__enable_developer_profiles_dashboard_recommendations","Cloud__enable_cloud_facet_chat","Cloud__enable_cloud_shell","Profiles__enable_developer_profiles_callout","Profiles__enable_profile_notifications_ui","MiscFeatureFlags__enable_tls_version_for_gaia_calls"]]')
  
</script>
    <devsite-a11y-announce aria-live="assertive" aria-atomic="true"></devsite-a11y-announce>
  
</body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>