{"url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/374","repository_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark","labels_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/374/labels{/name}","comments_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/374/comments","events_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/374/events","html_url":"https://github.com/clovaai/deep-text-recognition-benchmark/issues/374","id":1500168441,"node_id":"I_kwDOCq7kDM5ZasD5","number":374,"title":"Poor predictions when deploying a custom model on Arabic","user":{"login":"MohieEldinMuhammad","id":89604782,"node_id":"MDQ6VXNlcjg5NjA0Nzgy","avatar_url":"https://avatars.githubusercontent.com/u/89604782?v=4","gravatar_id":"","url":"https://api.github.com/users/MohieEldinMuhammad","html_url":"https://github.com/MohieEldinMuhammad","followers_url":"https://api.github.com/users/MohieEldinMuhammad/followers","following_url":"https://api.github.com/users/MohieEldinMuhammad/following{/other_user}","gists_url":"https://api.github.com/users/MohieEldinMuhammad/gists{/gist_id}","starred_url":"https://api.github.com/users/MohieEldinMuhammad/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MohieEldinMuhammad/subscriptions","organizations_url":"https://api.github.com/users/MohieEldinMuhammad/orgs","repos_url":"https://api.github.com/users/MohieEldinMuhammad/repos","events_url":"https://api.github.com/users/MohieEldinMuhammad/events{/privacy}","received_events_url":"https://api.github.com/users/MohieEldinMuhammad/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":10,"created_at":"2022-12-16T13:00:04Z","updated_at":"2023-01-01T07:09:40Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Following this link instructions https://github.com/JaidedAI/EasyOCR/blob/master/custom_model.md.\r\nI have trained a custom model on my own dataset.\r\n\r\n**Here is the .yml file I used:**\r\n```\r\nnetwork_params:\r\n  hidden_size: 512\r\n  input_channel: 1\r\n  output_channel: 512\r\n  hidden_size: 512\r\n  \r\nimgH: 64\r\nimgW: 600\r\n\r\nlang_list:\r\n         - 'en'\r\ncharacter_list: \"0123456789!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~ abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ٠١٢٣٤٥٦٧٨٩«»؟،؛ءآأؤإئااًبةتثجحخدذرزسشصضطظعغفقكلمنهوىيٱٹپچڈڑژکڭگںھۀہۂۃۆۇۈۋیېےۓە\"\r\nnumber: '1234567890١٢٣٤٥٦٧٨٩٠'\r\n```\r\n**The .py file:**\r\n```\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.init as init\r\nimport torchvision\r\nfrom torchvision import models\r\nfrom collections import namedtuple\r\nfrom packaging import version\r\n\r\n\r\ndef init_weights(modules):\r\n    for m in modules:\r\n        if isinstance(m, nn.Conv2d):\r\n            init.xavier_uniform_(m.weight.data)\r\n            if m.bias is not None:\r\n                m.bias.data.zero_()\r\n        elif isinstance(m, nn.BatchNorm2d):\r\n            m.weight.data.fill_(1)\r\n            m.bias.data.zero_()\r\n        elif isinstance(m, nn.Linear):\r\n            m.weight.data.normal_(0, 0.01)\r\n            m.bias.data.zero_()\r\n\r\nclass vgg16_bn(torch.nn.Module):\r\n    def __init__(self, pretrained=True, freeze=True):\r\n        super(vgg16_bn, self).__init__()\r\n        if version.parse(torchvision.__version__) >= version.parse('0.13'):\r\n            vgg_pretrained_features = models.vgg16_bn(\r\n                weights=models.VGG16_BN_Weights.DEFAULT if pretrained else None\r\n            ).features\r\n        else: #torchvision.__version__ < 0.13\r\n            models.vgg.model_urls['vgg16_bn'] = models.vgg.model_urls['vgg16_bn'].replace('https://', 'http://')\r\n            vgg_pretrained_features = models.vgg16_bn(pretrained=pretrained).features\r\n\r\n        self.slice1 = torch.nn.Sequential()\r\n        self.slice2 = torch.nn.Sequential()\r\n        self.slice3 = torch.nn.Sequential()\r\n        self.slice4 = torch.nn.Sequential()\r\n        self.slice5 = torch.nn.Sequential()\r\n        for x in range(12):         # conv2_2\r\n            self.slice1.add_module(str(x), vgg_pretrained_features[x])\r\n        for x in range(12, 19):         # conv3_3\r\n            self.slice2.add_module(str(x), vgg_pretrained_features[x])\r\n        for x in range(19, 29):         # conv4_3\r\n            self.slice3.add_module(str(x), vgg_pretrained_features[x])\r\n        for x in range(29, 39):         # conv5_3\r\n            self.slice4.add_module(str(x), vgg_pretrained_features[x])\r\n\r\n        # fc6, fc7 without atrous conv\r\n        self.slice5 = torch.nn.Sequential(\r\n                nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\r\n                nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6),\r\n                nn.Conv2d(1024, 1024, kernel_size=1)\r\n        )\r\n\r\n        if not pretrained:\r\n            init_weights(self.slice1.modules())\r\n            init_weights(self.slice2.modules())\r\n            init_weights(self.slice3.modules())\r\n            init_weights(self.slice4.modules())\r\n\r\n        init_weights(self.slice5.modules())        # no pretrained model for fc6 and fc7\r\n\r\n        if freeze:\r\n            for param in self.slice1.parameters():      # only first conv\r\n                param.requires_grad= False\r\n\r\n    def forward(self, X):\r\n        h = self.slice1(X)\r\n        h_relu2_2 = h\r\n        h = self.slice2(h)\r\n        h_relu3_2 = h\r\n        h = self.slice3(h)\r\n        h_relu4_3 = h\r\n        h = self.slice4(h)\r\n        h_relu5_3 = h\r\n        h = self.slice5(h)\r\n        h_fc7 = h\r\n        vgg_outputs = namedtuple(\"VggOutputs\", ['fc7', 'relu5_3', 'relu4_3', 'relu3_2', 'relu2_2'])\r\n        out = vgg_outputs(h_fc7, h_relu5_3, h_relu4_3, h_relu3_2, h_relu2_2)\r\n        return out\r\n\r\nclass BidirectionalLSTM(nn.Module):\r\n\r\n    def __init__(self, input_size, hidden_size, output_size):\r\n        super(BidirectionalLSTM, self).__init__()\r\n        self.rnn = nn.LSTM(input_size, hidden_size, bidirectional=True, batch_first=True)\r\n        self.linear = nn.Linear(hidden_size * 2, output_size)\r\n\r\n    def forward(self, input):\r\n        \"\"\"\r\n        input : visual feature [batch_size x T x input_size]\r\n        output : contextual feature [batch_size x T x output_size]\r\n        \"\"\"\r\n        try: # multi gpu needs this\r\n            self.rnn.flatten_parameters()\r\n        except: # quantization doesn't work with this \r\n            pass\r\n        recurrent, _ = self.rnn(input)  # batch_size x T x input_size -> batch_size x T x (2*hidden_size)\r\n        output = self.linear(recurrent)  # batch_size x T x output_size\r\n        return output\r\n\r\nclass VGG_FeatureExtractor(nn.Module):\r\n\r\n    def __init__(self, input_channel, output_channel=512):\r\n        super(VGG_FeatureExtractor, self).__init__()\r\n        self.output_channel = [int(output_channel / 8), int(output_channel / 4),\r\n                               int(output_channel / 2), output_channel]\r\n        self.ConvNet = nn.Sequential(\r\n            nn.Conv2d(input_channel, self.output_channel[0], 3, 1, 1), nn.ReLU(True),\r\n            nn.MaxPool2d(2, 2),\r\n            nn.Conv2d(self.output_channel[0], self.output_channel[1], 3, 1, 1), nn.ReLU(True),\r\n            nn.MaxPool2d(2, 2),\r\n            nn.Conv2d(self.output_channel[1], self.output_channel[2], 3, 1, 1), nn.ReLU(True),\r\n            nn.Conv2d(self.output_channel[2], self.output_channel[2], 3, 1, 1), nn.ReLU(True),\r\n            nn.MaxPool2d((2, 1), (2, 1)),\r\n            nn.Conv2d(self.output_channel[2], self.output_channel[3], 3, 1, 1, bias=False),\r\n            nn.BatchNorm2d(self.output_channel[3]), nn.ReLU(True),\r\n            nn.Conv2d(self.output_channel[3], self.output_channel[3], 3, 1, 1, bias=False),\r\n            nn.BatchNorm2d(self.output_channel[3]), nn.ReLU(True),\r\n            nn.MaxPool2d((2, 1), (2, 1)),\r\n            nn.Conv2d(self.output_channel[3], self.output_channel[3], 2, 1, 0), nn.ReLU(True))\r\n\r\n    def forward(self, input):\r\n        return self.ConvNet(input)\r\n\r\nclass ResNet_FeatureExtractor(nn.Module):\r\n    \"\"\" FeatureExtractor of FAN (http://openaccess.thecvf.com/content_ICCV_2017/papers/Cheng_Focusing_Attention_Towards_ICCV_2017_paper.pdf) \"\"\"\r\n\r\n    def __init__(self, input_channel, output_channel=512):\r\n        super(ResNet_FeatureExtractor, self).__init__()\r\n        self.ConvNet = ResNet(input_channel, output_channel, BasicBlock, [1, 2, 5, 3])\r\n\r\n    def forward(self, input):\r\n        return self.ConvNet(input)\r\n\r\nclass BasicBlock(nn.Module):\r\n    expansion = 1\r\n\r\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\r\n        super(BasicBlock, self).__init__()\r\n        self.conv1 = self._conv3x3(inplanes, planes)\r\n        self.bn1 = nn.BatchNorm2d(planes)\r\n        self.conv2 = self._conv3x3(planes, planes)\r\n        self.bn2 = nn.BatchNorm2d(planes)\r\n        self.relu = nn.ReLU(inplace=True)\r\n        self.downsample = downsample\r\n        self.stride = stride\r\n\r\n    def _conv3x3(self, in_planes, out_planes, stride=1):\r\n        \"3x3 convolution with padding\"\r\n        return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\r\n                         padding=1, bias=False)\r\n\r\n    def forward(self, x):\r\n        residual = x\r\n\r\n        out = self.conv1(x)\r\n        out = self.bn1(out)\r\n        out = self.relu(out)\r\n\r\n        out = self.conv2(out)\r\n        out = self.bn2(out)\r\n\r\n        if self.downsample is not None:\r\n            residual = self.downsample(x)\r\n        out += residual\r\n        out = self.relu(out)\r\n\r\n        return out\r\n\r\nclass ResNet(nn.Module):\r\n\r\n    def __init__(self, input_channel, output_channel, block, layers):\r\n        super(ResNet, self).__init__()\r\n\r\n        self.output_channel_block = [int(output_channel / 4), int(output_channel / 2), output_channel, output_channel]\r\n\r\n        self.inplanes = int(output_channel / 8)\r\n        self.conv0_1 = nn.Conv2d(input_channel, int(output_channel / 16),\r\n                                 kernel_size=3, stride=1, padding=1, bias=False)\r\n        self.bn0_1 = nn.BatchNorm2d(int(output_channel / 16))\r\n        self.conv0_2 = nn.Conv2d(int(output_channel / 16), self.inplanes,\r\n                                 kernel_size=3, stride=1, padding=1, bias=False)\r\n        self.bn0_2 = nn.BatchNorm2d(self.inplanes)\r\n        self.relu = nn.ReLU(inplace=True)\r\n\r\n        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\r\n        self.layer1 = self._make_layer(block, self.output_channel_block[0], layers[0])\r\n        self.conv1 = nn.Conv2d(self.output_channel_block[0], self.output_channel_block[\r\n                               0], kernel_size=3, stride=1, padding=1, bias=False)\r\n        self.bn1 = nn.BatchNorm2d(self.output_channel_block[0])\r\n\r\n        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\r\n        self.layer2 = self._make_layer(block, self.output_channel_block[1], layers[1], stride=1)\r\n        self.conv2 = nn.Conv2d(self.output_channel_block[1], self.output_channel_block[\r\n                               1], kernel_size=3, stride=1, padding=1, bias=False)\r\n        self.bn2 = nn.BatchNorm2d(self.output_channel_block[1])\r\n\r\n        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1))\r\n        self.layer3 = self._make_layer(block, self.output_channel_block[2], layers[2], stride=1)\r\n        self.conv3 = nn.Conv2d(self.output_channel_block[2], self.output_channel_block[\r\n                               2], kernel_size=3, stride=1, padding=1, bias=False)\r\n        self.bn3 = nn.BatchNorm2d(self.output_channel_block[2])\r\n\r\n        self.layer4 = self._make_layer(block, self.output_channel_block[3], layers[3], stride=1)\r\n        self.conv4_1 = nn.Conv2d(self.output_channel_block[3], self.output_channel_block[\r\n                                 3], kernel_size=2, stride=(2, 1), padding=(0, 1), bias=False)\r\n        self.bn4_1 = nn.BatchNorm2d(self.output_channel_block[3])\r\n        self.conv4_2 = nn.Conv2d(self.output_channel_block[3], self.output_channel_block[\r\n                                 3], kernel_size=2, stride=1, padding=0, bias=False)\r\n        self.bn4_2 = nn.BatchNorm2d(self.output_channel_block[3])\r\n\r\n    def _make_layer(self, block, planes, blocks, stride=1):\r\n        downsample = None\r\n        if stride != 1 or self.inplanes != planes * block.expansion:\r\n            downsample = nn.Sequential(\r\n                nn.Conv2d(self.inplanes, planes * block.expansion,\r\n                          kernel_size=1, stride=stride, bias=False),\r\n                nn.BatchNorm2d(planes * block.expansion),\r\n            )\r\n\r\n        layers = []\r\n        layers.append(block(self.inplanes, planes, stride, downsample))\r\n        self.inplanes = planes * block.expansion\r\n        for i in range(1, blocks):\r\n            layers.append(block(self.inplanes, planes))\r\n\r\n        return nn.Sequential(*layers)\r\n\r\n    def forward(self, x):\r\n        x = self.conv0_1(x)\r\n        x = self.bn0_1(x)\r\n        x = self.relu(x)\r\n        x = self.conv0_2(x)\r\n        x = self.bn0_2(x)\r\n        x = self.relu(x)\r\n\r\n        x = self.maxpool1(x)\r\n        x = self.layer1(x)\r\n        x = self.conv1(x)\r\n        x = self.bn1(x)\r\n        x = self.relu(x)\r\n\r\n        x = self.maxpool2(x)\r\n        x = self.layer2(x)\r\n        x = self.conv2(x)\r\n        x = self.bn2(x)\r\n        x = self.relu(x)\r\n\r\n        x = self.maxpool3(x)\r\n        x = self.layer3(x)\r\n        x = self.conv3(x)\r\n        x = self.bn3(x)\r\n        x = self.relu(x)\r\n\r\n        x = self.layer4(x)\r\n        x = self.conv4_1(x)\r\n        x = self.bn4_1(x)\r\n        x = self.relu(x)\r\n        x = self.conv4_2(x)\r\n        x = self.bn4_2(x)\r\n        x = self.relu(x)\r\n\r\n        return x\r\n\r\n\r\nclass Model(nn.Module):\r\n\r\n    def __init__(self, input_channel, output_channel, hidden_size, num_class):\r\n        super(Model, self).__init__()\r\n        \"\"\" FeatureExtraction \"\"\"\r\n        self.FeatureExtraction = ResNet_FeatureExtractor(input_channel, output_channel)\r\n        self.FeatureExtraction_output = output_channel  # int(imgH/16-1) * 512\r\n        self.AdaptiveAvgPool = nn.AdaptiveAvgPool2d((None, 1))  # Transform final (imgH/16-1) -> 1\r\n\r\n        \"\"\" Sequence modeling\"\"\"\r\n        self.SequenceModeling = nn.Sequential(\r\n            BidirectionalLSTM(self.FeatureExtraction_output, hidden_size, hidden_size),\r\n            BidirectionalLSTM(hidden_size, hidden_size, hidden_size))\r\n        self.SequenceModeling_output = hidden_size\r\n\r\n        \"\"\" Prediction \"\"\"\r\n        self.Prediction = nn.Linear(self.SequenceModeling_output, num_class)\r\n\r\n\r\n    def forward(self, input, text):\r\n        \"\"\" Feature extraction stage \"\"\"\r\n        visual_feature = self.FeatureExtraction(input)\r\n        visual_feature = self.AdaptiveAvgPool(visual_feature.permute(0, 3, 1, 2))  # [b, c, h, w] -> [b, w, c, h]\r\n        visual_feature = visual_feature.squeeze(3)\r\n\r\n        \"\"\" Sequence modeling stage \"\"\"\r\n        contextual_feature = self.SequenceModeling(visual_feature)\r\n\r\n        \"\"\" Prediction stage \"\"\"\r\n        prediction = self.Prediction(contextual_feature.contiguous())\r\n\r\n        return prediction\r\n\r\n```\r\n**Then i predict like this:**  \r\n```\r\nar_reader = easyocr.Reader(['en'], recog_network='arabic')\r\nar_reader.readtext(image_path,paragraph=True)\r\n```","closed_by":null,"reactions":{"url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/374/reactions","total_count":3,"+1":3,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/374/timeline","performed_via_github_app":null,"state_reason":null}