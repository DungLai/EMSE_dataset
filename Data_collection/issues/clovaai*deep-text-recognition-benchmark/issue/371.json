{"url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/371","repository_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark","labels_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/371/labels{/name}","comments_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/371/comments","events_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/371/events","html_url":"https://github.com/clovaai/deep-text-recognition-benchmark/issues/371","id":1453596862,"node_id":"I_kwDOCq7kDM5WpCC-","number":371,"title":" How to know that my data set is well done?","user":{"login":"e-click","id":105033880,"node_id":"U_kgDOBkKwmA","avatar_url":"https://avatars.githubusercontent.com/u/105033880?v=4","gravatar_id":"","url":"https://api.github.com/users/e-click","html_url":"https://github.com/e-click","followers_url":"https://api.github.com/users/e-click/followers","following_url":"https://api.github.com/users/e-click/following{/other_user}","gists_url":"https://api.github.com/users/e-click/gists{/gist_id}","starred_url":"https://api.github.com/users/e-click/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/e-click/subscriptions","organizations_url":"https://api.github.com/users/e-click/orgs","repos_url":"https://api.github.com/users/e-click/repos","events_url":"https://api.github.com/users/e-click/events{/privacy}","received_events_url":"https://api.github.com/users/e-click/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2022-11-17T16:03:42Z","updated_at":"2022-11-21T02:49:53Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I am trying to train a model to use it with EasyOCR in an ANPR project, as a first test I used a dataset that is provided in the EasyOCR repository, this is an example of the images used.\r\n![0](https://user-images.githubusercontent.com/105033880/202492671-b50e2d78-31c6-4065-ada5-e8c14fff3aa6.jpg)\r\nThe dataset contains approximately 1000 similar images in different sizes, after a training of 10,000 iterations I got poor results but since it was a training test I didn't give it more importance.\r\n\r\nAfter that I tried to train my own model following the same steps I used to train the previous model, create my .txt file with the labels and run the script to create the mdb dataset, but after training I don't get any result, it stays on the same prediction and it never gets better.\r\nExample of images:\r\n![Screenshot 2022-11-17 095720](https://user-images.githubusercontent.com/105033880/202495183-430791b4-3c0f-43cb-bd5a-12e5f8b579c8.png)\r\n\r\n\r\nAnother thing I noticed is that after the training script runs the dataset filter, I only had about 100 samples left out of 500 that the dataset has.\r\n\r\nThe training seems as if it was stuck since it never achieved a correct prediction, unlike with the first dataset, the training after 2000 iterations already gave good results.\r\n\r\nThese are my logs and results of failure training.\r\n\r\nexp_name: None-VGG-BiLSTM-CTC-Seed1111\r\ntrain_data: data\r\nvalid_data: data/val\r\nmanualSeed: 1111\r\nworkers: 0\r\nbatch_size: 192\r\nnum_iter: 10000\r\nvalInterval: 100\r\nsaved_model: \r\nFT: False\r\nadam: False\r\nlr: 1\r\nbeta1: 0.9\r\nrho: 0.95\r\neps: 1e-08\r\ngrad_clip: 5\r\nbaiduCTC: False\r\nselect_data: ['train']\r\nbatch_ratio: ['1']\r\ntotal_data_usage_ratio: 1.0\r\nbatch_max_length: 25\r\nimgH: 32\r\nimgW: 100\r\nrgb: False\r\ncharacter: 0123456789-abcdefghijklmnopqrstuvwxyz\r\nsensitive: False\r\nPAD: False\r\ndata_filtering_off: False\r\nTransformation: None\r\nFeatureExtraction: VGG\r\nSequenceModeling: BiLSTM\r\nPrediction: CTC\r\nnum_fiducial: 20\r\ninput_channel: 1\r\noutput_channel: 512\r\nhidden_size: 256\r\nnum_gpu: 0\r\nnum_class: 38\r\n---------------------------------------\r\n\r\ndataset_root: data\r\nopt.select_data: ['train']\r\nopt.batch_ratio: ['1']\r\n--------------------------------------------------------------------------------\r\ndataset_root:    data\t dataset: train\r\nsub-directory:\t/train\t num samples: 102\r\nnum total samples of train: 102 x 1.0 (total_data_usage_ratio) = 102\r\nnum samples of train per batch: 192 x 1.0 (batch_ratio) = 192\r\n--------------------------------------------------------------------------------\r\nTotal_batch_size: 192 = 192\r\n--------------------------------------------------------------------------------\r\ndataset_root:    data/val\t dataset: /\r\nsub-directory:\t/.\t num samples: 1\r\n--------------------------------------------------------------------------------\r\n\r\n\r\n[8400/10000] Train loss: 0.00001, Valid loss: 9.07022, Elapsed_time: 46794.15422\r\nCurrent_accuracy : 0.000, Current_norm_ED  : 0.14\r\nBest_accuracy    : 0.000, Best_norm_ED     : 0.14\r\n--------------------------------------------------------------------------------\r\nGround Truth              | Prediction                | Confidence Score & T/F\r\n--------------------------------------------------------------------------------\r\n4nt5526                   | 2103j6                    | 0.0474\tFalse\r\n--------------------------------------------------------------------------------\r\n[8500/10000] Train loss: 0.00001, Valid loss: 9.07421, Elapsed_time: 47353.40529\r\nCurrent_accuracy : 0.000, Current_norm_ED  : 0.14\r\nBest_accuracy    : 0.000, Best_norm_ED     : 0.14\r\n--------------------------------------------------------------------------------\r\nGround Truth              | Prediction                | Confidence Score & T/F\r\n--------------------------------------------------------------------------------\r\n4nt5526                   | 2103j6                    | 0.0477\tFalse\r\n--------------------------------------------------------------------------------\r\n[8600/10000] Train loss: 0.00001, Valid loss: 9.07817, Elapsed_time: 47907.41048\r\nCurrent_accuracy : 0.000, Current_norm_ED  : 0.14\r\nBest_accuracy    : 0.000, Best_norm_ED     : 0.14\r\n--------------------------------------------------------------------------------\r\nGround Truth              | Prediction                | Confidence Score & T/F\r\n--------------------------------------------------------------------------------\r\n4nt5526                   | 2103j6                    | 0.0479\tFalse\r\n--------------------------------------------------------------------------------\r\n[8700/10000] Train loss: 0.00001, Valid loss: 9.08219, Elapsed_time: 49519.87970\r\nCurrent_accuracy : 0.000, Current_norm_ED  : 0.14\r\nBest_accuracy    : 0.000, Best_norm_ED     : 0.14\r\n--------------------------------------------------------------------------------\r\nGround Truth              | Prediction                | Confidence Score & T/F\r\n--------------------------------------------------------------------------------\r\n4nt5526                   | 2103j6                    | 0.0481\tFalse\r\n--------------------------------------------------------------------------------\r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/371/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/371/timeline","performed_via_github_app":null,"state_reason":null}