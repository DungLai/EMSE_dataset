{"url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/155","repository_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark","labels_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/155/labels{/name}","comments_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/155/comments","events_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/155/events","html_url":"https://github.com/clovaai/deep-text-recognition-benchmark/issues/155","id":595910396,"node_id":"MDU6SXNzdWU1OTU5MTAzOTY=","number":155,"title":"Demo and paper timing vs repo demo.py timing","user":{"login":"ghandic","id":23500353,"node_id":"MDQ6VXNlcjIzNTAwMzUz","avatar_url":"https://avatars.githubusercontent.com/u/23500353?v=4","gravatar_id":"","url":"https://api.github.com/users/ghandic","html_url":"https://github.com/ghandic","followers_url":"https://api.github.com/users/ghandic/followers","following_url":"https://api.github.com/users/ghandic/following{/other_user}","gists_url":"https://api.github.com/users/ghandic/gists{/gist_id}","starred_url":"https://api.github.com/users/ghandic/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ghandic/subscriptions","organizations_url":"https://api.github.com/users/ghandic/orgs","repos_url":"https://api.github.com/users/ghandic/repos","events_url":"https://api.github.com/users/ghandic/events{/privacy}","received_events_url":"https://api.github.com/users/ghandic/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2020-04-07T14:27:13Z","updated_at":"2020-06-17T12:20:12Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"On your web demo which uses CRAFT (with extra training) and this (again extra training) you are able to apply OCR in < 2 seconds, the test document had around 100 words, at around 10ms/image that makes up 1 second. CRAFT must be taking around 0.8 seconds and then layout analysis around 0.2 seconds\r\n\r\nHow have you achieved these speeds? When I run on AWS p2.xlarge (NVIDIA Tesla K80) inside a docker environment running Cuda running the same 100 cropped regions takes me 3.23 seconds using the demo code. Changing to CTC only gets it down to 3.19 seconds (which doesn't seem right)\r\n\r\nI added the timing into the demo.py here:\r\n```python\r\nst = time.time()\r\npreds = model(image, text_for_pred)\r\nprint((time.time()-st)/batch_size)\r\n```\r\nSimilarly added timing to attn model\r\n\r\nThis gives me `0.0363` which is around 36ms per image (TPS-ResNet-BiLSTM-CTC)\r\nThis gives me `0.03675` which is around 37ms per image (TPS-ResNet-BiLSTM-Attn)\r\n\r\nCould you show how to get the reproducible timings per image as per the paper?","closed_by":null,"reactions":{"url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/155/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/155/timeline","performed_via_github_app":null,"state_reason":null}