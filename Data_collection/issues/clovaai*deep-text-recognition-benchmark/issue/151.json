{"url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/151","repository_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark","labels_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/151/labels{/name}","comments_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/151/comments","events_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/151/events","html_url":"https://github.com/clovaai/deep-text-recognition-benchmark/issues/151","id":579640455,"node_id":"MDU6SXNzdWU1Nzk2NDA0NTU=","number":151,"title":"Training speed on multi gpu","user":{"login":"khanhnt","id":5887348,"node_id":"MDQ6VXNlcjU4ODczNDg=","avatar_url":"https://avatars.githubusercontent.com/u/5887348?v=4","gravatar_id":"","url":"https://api.github.com/users/khanhnt","html_url":"https://github.com/khanhnt","followers_url":"https://api.github.com/users/khanhnt/followers","following_url":"https://api.github.com/users/khanhnt/following{/other_user}","gists_url":"https://api.github.com/users/khanhnt/gists{/gist_id}","starred_url":"https://api.github.com/users/khanhnt/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/khanhnt/subscriptions","organizations_url":"https://api.github.com/users/khanhnt/orgs","repos_url":"https://api.github.com/users/khanhnt/repos","events_url":"https://api.github.com/users/khanhnt/events{/privacy}","received_events_url":"https://api.github.com/users/khanhnt/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2020-03-12T01:46:43Z","updated_at":"2020-10-07T16:39:07Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi @ku21fan and all,\r\n\r\nI have tried to fine-tune the model on 3 GPUs, but it seem the training speed is slow. With 16 epochs, the Elapsed_time is 35945.77589, that mean each epochs cost about 2250 seconds. Is it normal ? Besides, In order to train the model, I have to reduce the batch-size to 60. \r\nHere is the training options:\r\n```\r\n{experiment_name}: {TPS-ResNet-BiLSTM-Attn-Seed1111}\r\n{train_data}: {result/train_06032020/train/}\r\n{valid_data}: {result/train_06032020/valid/}\r\n{manualSeed}: {1111}\r\n{workers}: {12}\r\n{batch_size}: {180}\r\n{num_iter}: {300000}\r\n{valInterval}: {2000}\r\n{saved_model}: {model/TPS-ResNet-BiLSTM-Attn-case-sensitive_0.pth}\r\n{FT}: {True}\r\n{adam}: {False}\r\n{lr}: {1}\r\n{beta1}: {0.9}\r\n{rho}: {0.95}\r\n{eps}: {1e-08}\r\n{grad_clip}: {5}\r\n{select_data}: {['/']}\r\n{batch_ratio}: {['1']}\r\n{total_data_usage_ratio}: {1.0}\r\n{batch_max_length}: {25}\r\n{imgH}: {32}\r\n{imgW}: {100}\r\n{rgb}: {False}\r\n{character}: {0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~áàảãạăắằẳẵặâấầẩẫậđéèẻẽẹêếềểễệíìỉĩịóòỏõọôốồổỗộơớờởỡợúùủũụưứừửữựỷỹỳýỵÁÀẢÃẠĂẮẰẲẴẶÂẤẦẨẪẬĐÉÈẺẼẸÊẾỀỂỄỆÍÌỈĨỊÓÒỎÕỌÔỐỒỔỖỘƠỚỜỐỖỘÚÙỦŨỤƯỨỪỬỮỰÝỲỶỸỴ}\r\n{sensitive}: {True}\r\n{PAD}: {False}\r\n{data_filtering_off}: {False}\r\n{Transformation}: {TPS}\r\n{FeatureExtraction}: {ResNet}\r\n{SequenceModeling}: {BiLSTM}\r\n{Prediction}: {Attn}\r\n{num_fiducial}: {20}\r\n{input_channel}: {1}\r\n{output_channel}: {512}\r\n{hidden_size}: {256}\r\n{num_gpu}: {3}\r\n{num_class}: {230}\r\n```\r\nThe training run on Intel(R) Xeon(R) CPU E5-2620 v3 @ 2.40GHz with 3 Tesla K80 :\r\n```\r\n| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           Off  | 00000000:85:00.0 Off |                    0 |\r\n| N/A   73C    P0   113W / 149W |   2783MiB / 11441MiB |     94%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla K80           Off  | 00000000:86:00.0 Off |                    0 |\r\n| N/A   53C    P0   121W / 149W |   2155MiB / 11441MiB |     88%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla K80           Off  | 00000000:89:00.0 Off |                    0 |\r\n| N/A   62C    P0   113W / 149W |   2145MiB / 11441MiB |     86%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n```\r\n\r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/151/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/clovaai/deep-text-recognition-benchmark/issues/151/timeline","performed_via_github_app":null,"state_reason":null}