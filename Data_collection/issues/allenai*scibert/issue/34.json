{"url":"https://api.github.com/repos/allenai/scibert/issues/34","repository_url":"https://api.github.com/repos/allenai/scibert","labels_url":"https://api.github.com/repos/allenai/scibert/issues/34/labels{/name}","comments_url":"https://api.github.com/repos/allenai/scibert/issues/34/comments","events_url":"https://api.github.com/repos/allenai/scibert/issues/34/events","html_url":"https://github.com/allenai/scibert/issues/34","id":432891283,"node_id":"MDU6SXNzdWU0MzI4OTEyODM=","number":34,"title":"How to get Sentence embedding using pre-trained SciBERT weights? ","user":{"login":"Santosh-Gupta","id":5524261,"node_id":"MDQ6VXNlcjU1MjQyNjE=","avatar_url":"https://avatars.githubusercontent.com/u/5524261?v=4","gravatar_id":"","url":"https://api.github.com/users/Santosh-Gupta","html_url":"https://github.com/Santosh-Gupta","followers_url":"https://api.github.com/users/Santosh-Gupta/followers","following_url":"https://api.github.com/users/Santosh-Gupta/following{/other_user}","gists_url":"https://api.github.com/users/Santosh-Gupta/gists{/gist_id}","starred_url":"https://api.github.com/users/Santosh-Gupta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Santosh-Gupta/subscriptions","organizations_url":"https://api.github.com/users/Santosh-Gupta/orgs","repos_url":"https://api.github.com/users/Santosh-Gupta/repos","events_url":"https://api.github.com/users/Santosh-Gupta/events{/privacy}","received_events_url":"https://api.github.com/users/Santosh-Gupta/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2019-04-13T19:44:04Z","updated_at":"2021-02-16T09:38:03Z","closed_at":"2019-04-20T01:40:50Z","author_association":"NONE","active_lock_reason":null,"body":"The instructions to use SciBERT say this\r\n\r\n> SciBERT models include all necessary files to be plugged in your own model and are in same format as BERT. If you are using Tensorflow, refer to Google's BERT repo and if you use PyTorch, refer to Hugging Face's repo where detailed instructions on using BERT models are provided.\r\n\r\nHowever, to use BERT, the instructions include loading BERT from tf.hub. But I don't see SciBert on tfhub, so I am unable to figure out how to get a sentence embedding for SciBert. \r\n\r\nThis is my attempt in Python. So far I cloned the repository and loaded the weights, but I don't know how to get the sentence/paragraph vector. \r\n\r\nThis is my code so far\r\n\r\n```\r\nimport sys\r\nimport tensorflow as tf\r\n\r\n!test -d SciBert_repo || git clone https://github.com/allenai/scibert SciBert_repo \r\nif not 'SciBert_repo ' in sys.path:\r\n  sys.path += ['SciBert_repo ']\r\n\r\nimport extract_features\r\n\r\nwith tf.Session(graph=graph) as session:\r\n \r\n   saver.restore(session, 'SciBert_repo.ckpt' )\r\n```\r\n\r\nI know this is based on the original BERT code. For regular BERT they have you use tf.hub, but I'm guessing the setup is pretty similar. This is my code for regular BERT\r\n\r\n```\r\npip install bert-tensorflow\r\n\r\nimport tensorflow as tf\r\nimport tensorflow_hub as hub\r\n\r\nimport bert\r\nfrom bert import run_classifier\r\nfrom bert import optimization\r\nfrom bert import tokenization\r\n\r\nimport pandas as pd\r\n\r\nfrom tensorflow import keras\r\nimport os\r\nimport re\r\n\r\nfrom tensorflow.keras import backend as K\r\n\r\nfrom bert.tokenization import FullTokenizer\r\n\r\nbert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\r\n\r\nsess = tf.Session()\r\n\r\nbert_module = hub.Module(\r\n  bert_path,\r\n  trainable=True)\r\n\r\n#Basically this is a function to convert text into a format BERT understands\r\ndef bertInputsFromText(text):\r\n.\r\n.\r\n.\r\n\r\nbert_inputs = bertInputsFromText(\"This is a test sentence\")\r\n\r\nsentence_embedding= bert_module(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\r\n        \"pooled_output\"\r\n```\r\n\r\nSo I'm guessing my question boils down to, what to use as an equivalent to `bert_module `","closed_by":{"login":"Santosh-Gupta","id":5524261,"node_id":"MDQ6VXNlcjU1MjQyNjE=","avatar_url":"https://avatars.githubusercontent.com/u/5524261?v=4","gravatar_id":"","url":"https://api.github.com/users/Santosh-Gupta","html_url":"https://github.com/Santosh-Gupta","followers_url":"https://api.github.com/users/Santosh-Gupta/followers","following_url":"https://api.github.com/users/Santosh-Gupta/following{/other_user}","gists_url":"https://api.github.com/users/Santosh-Gupta/gists{/gist_id}","starred_url":"https://api.github.com/users/Santosh-Gupta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Santosh-Gupta/subscriptions","organizations_url":"https://api.github.com/users/Santosh-Gupta/orgs","repos_url":"https://api.github.com/users/Santosh-Gupta/repos","events_url":"https://api.github.com/users/Santosh-Gupta/events{/privacy}","received_events_url":"https://api.github.com/users/Santosh-Gupta/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/allenai/scibert/issues/34/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/allenai/scibert/issues/34/timeline","performed_via_github_app":null,"state_reason":"completed"}