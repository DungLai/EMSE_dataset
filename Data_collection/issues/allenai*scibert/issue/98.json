{"url":"https://api.github.com/repos/allenai/scibert/issues/98","repository_url":"https://api.github.com/repos/allenai/scibert","labels_url":"https://api.github.com/repos/allenai/scibert/issues/98/labels{/name}","comments_url":"https://api.github.com/repos/allenai/scibert/issues/98/comments","events_url":"https://api.github.com/repos/allenai/scibert/issues/98/events","html_url":"https://github.com/allenai/scibert/issues/98","id":665344366,"node_id":"MDU6SXNzdWU2NjUzNDQzNjY=","number":98,"title":"How can I use sciBERT for Token Classification?","user":{"login":"Sachit1137","id":55988870,"node_id":"MDQ6VXNlcjU1OTg4ODcw","avatar_url":"https://avatars.githubusercontent.com/u/55988870?v=4","gravatar_id":"","url":"https://api.github.com/users/Sachit1137","html_url":"https://github.com/Sachit1137","followers_url":"https://api.github.com/users/Sachit1137/followers","following_url":"https://api.github.com/users/Sachit1137/following{/other_user}","gists_url":"https://api.github.com/users/Sachit1137/gists{/gist_id}","starred_url":"https://api.github.com/users/Sachit1137/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Sachit1137/subscriptions","organizations_url":"https://api.github.com/users/Sachit1137/orgs","repos_url":"https://api.github.com/users/Sachit1137/repos","events_url":"https://api.github.com/users/Sachit1137/events{/privacy}","received_events_url":"https://api.github.com/users/Sachit1137/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2020-07-24T18:34:00Z","updated_at":"2022-05-26T08:00:45Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I tried with the code below:\r\n```\r\nfrom transformers import AutoTokenizer, AutoModel,AutoModelForTokenClassification\r\nimport torch\r\n\r\n#I am getting the label list from labels.txt file present in the Pytorch Huggingface model(scibert-scivocab-uncased)\r\ndef read_label_list():\r\n    f = open('labels.txt','r')\r\n    label_list = []\r\n    for line in f:\r\n        label_list.append(line)\r\n    return label_list\r\n\r\ntokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\r\nmodel = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')\r\n\r\nsequence = 'Effectiveness of current drug treatments for hospitalized patients with SARS-CoV-2 infection (COVID-19 patients) in routine clinical practice|Risk factors or modifiers of pharmacological effect such as demographic characteristics, comorbidity or underlying pathology, concomitant medication.'\r\n\r\nlabel_list = read_label_list()\r\ntokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\r\ninputs = tokenizer.encode(sequence, return_tensors=\"pt\")\r\noutputs = model(inputs)[0]\r\npredictions = torch.argmax(outputs, dim = 2)\r\n\r\nfor token, prediction in zip(tokens,predictions[0].numpy()):\r\n    print((token, label_list[prediction]))\r\n```\r\n\r\n\r\nI am getting the following output which is not making sense:\r\n('[CLS]', '##.49\\n')\r\n('effectiveness', '##.49\\n')\r\n('of', '##.49\\n')\r\n('current', '##.49\\n')\r\n('drug', '##.49\\n')\r\n('treatments', '##.49\\n')\r\n('for', '##.49\\n')\r\n('hospitalized', '##.49\\n')\r\n('patients', '##.49\\n')\r\n('with', '##.49\\n')\r\n('sar', '##.49\\n')\r\n('##s', '##.49\\n')\r\n('-', '##.49\\n')\r\n('cov', '##.49\\n')\r\n('-', '##.49\\n')\r\n('2', '##.49\\n')\r\n('infection', '##.49\\n')\r\n('(', '##.49\\n')\r\n('cov', '##.49\\n')\r\n('##id', '##.49\\n')\r\n('-', '##.49\\n')\r\n('19', '##.49\\n')\r\n('patients', '##.49\\n')\r\n(')', '##.49\\n')\r\n('in', '##.49\\n')\r\n('routine', '##.49\\n')\r\n('clinical', '##.49\\n')\r\n('practice', '##.49\\n')\r\n('|', '##.49\\n')\r\n('risk', '##.49\\n')\r\n('factors', '##.49\\n')\r\n('or', '##.49\\n')\r\n('modi', '##.49\\n')\r\n('##fi', '##.49\\n')\r\n('##ers', '##.49\\n')\r\n('of', '##.49\\n')\r\n('pharmacological', '##.49\\n')\r\n('effect', '##.49\\n')\r\n('such', '##.49\\n')\r\n('as', '##.49\\n')\r\n('demographic', '##.49\\n')\r\n('characteristics', '##.49\\n')\r\n(',', '##.49\\n')\r\n('comorbidity', '##.49\\n')\r\n('or', '##.49\\n')\r\n('underlying', '##.49\\n')\r\n('pathology', '##.49\\n')\r\n(',', '##.49\\n')\r\n('concomitant', '##.49\\n')\r\n('medication', '##.49\\n')\r\n('.', '##1-4\\n')\r\n('[SEP]', '##.49\\n')","closed_by":null,"reactions":{"url":"https://api.github.com/repos/allenai/scibert/issues/98/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/allenai/scibert/issues/98/timeline","performed_via_github_app":null,"state_reason":null}