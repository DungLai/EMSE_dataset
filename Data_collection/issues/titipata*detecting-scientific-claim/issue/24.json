{"url":"https://api.github.com/repos/titipata/detecting-scientific-claim/issues/24","repository_url":"https://api.github.com/repos/titipata/detecting-scientific-claim","labels_url":"https://api.github.com/repos/titipata/detecting-scientific-claim/issues/24/labels{/name}","comments_url":"https://api.github.com/repos/titipata/detecting-scientific-claim/issues/24/comments","events_url":"https://api.github.com/repos/titipata/detecting-scientific-claim/issues/24/events","html_url":"https://github.com/titipata/detecting-scientific-claim/issues/24","id":617091910,"node_id":"MDU6SXNzdWU2MTcwOTE5MTA=","number":24,"title":"'DiscourseCrfClassifier' object has no attribute 'classifier_feedforward'","user":{"login":"pivettamarcos","id":24397077,"node_id":"MDQ6VXNlcjI0Mzk3MDc3","avatar_url":"https://avatars.githubusercontent.com/u/24397077?v=4","gravatar_id":"","url":"https://api.github.com/users/pivettamarcos","html_url":"https://github.com/pivettamarcos","followers_url":"https://api.github.com/users/pivettamarcos/followers","following_url":"https://api.github.com/users/pivettamarcos/following{/other_user}","gists_url":"https://api.github.com/users/pivettamarcos/gists{/gist_id}","starred_url":"https://api.github.com/users/pivettamarcos/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pivettamarcos/subscriptions","organizations_url":"https://api.github.com/users/pivettamarcos/orgs","repos_url":"https://api.github.com/users/pivettamarcos/repos","events_url":"https://api.github.com/users/pivettamarcos/events{/privacy}","received_events_url":"https://api.github.com/users/pivettamarcos/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-05-13T02:30:15Z","updated_at":"2020-05-13T02:30:15Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"So I tried running your transfer_learning_crf.py script and it throws back this error:\r\n\r\n```\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-2-fd6f08fec54e> in <module>\r\n     47     num_classes, constraints, include_start_end_transitions = 2, None, False\r\n     48     model.classifier_feedforward._linear_layers = ModuleList([torch.nn.Linear(2 * EMBEDDING_DIM, EMBEDDING_DIM), \r\n---> 49                                                               torch.nn.Linear(EMBEDDING_DIM, num_classes)])\r\n     50     model.crf = ConditionalRandomField(num_classes, constraints, \r\n     51                                        include_start_end_transitions=include_start_end_transitions)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py in __getattr__(self, name)\r\n    592                 return modules[name]\r\n    593         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\r\n--> 594             type(self).__name__, name))\r\n    595 \r\n    596     def __setattr__(self, name, value):\r\n\r\nAttributeError: 'DiscourseCrfClassifier' object has no attribute 'classifier_feedforward'\r\n```\r\n\r\n\r\nIn fact, DiscourseCrfClassifier doesn't have that attribute, as it was removed in an earlier commit. \r\n\r\nI tried commenting the line that tries to use the attribute, but it then gives em a different error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-1-331d1897d4d1> in <module>\r\n    102         cuda_device=-1\r\n    103     )\r\n--> 104     trainer.train()\r\n    105 \r\n    106     # unfreeze most layers and continue training\r\n\r\n~/anaconda3/lib/python3.7/site-packages/allennlp/training/trainer.py in train(self)\r\n    476         for epoch in range(epoch_counter, self._num_epochs):\r\n    477             epoch_start_time = time.time()\r\n--> 478             train_metrics = self._train_epoch(epoch)\r\n    479 \r\n    480             # get peak of memory usage\r\n\r\n~/anaconda3/lib/python3.7/site-packages/allennlp/training/trainer.py in _train_epoch(self, epoch)\r\n    318             self.optimizer.zero_grad()\r\n    319 \r\n--> 320             loss = self.batch_loss(batch_group, for_training=True)\r\n    321 \r\n    322             if torch.isnan(loss):\r\n\r\n~/anaconda3/lib/python3.7/site-packages/allennlp/training/trainer.py in batch_loss(self, batch_group, for_training)\r\n    259             batch = batch_group[0]\r\n    260             batch = nn_util.move_to_device(batch, self._cuda_devices[0])\r\n--> 261             output_dict = self.model(**batch)\r\n    262 \r\n    263         try:\r\n\r\n~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    548             result = self._slow_forward(*input, **kwargs)\r\n    549         else:\r\n--> 550             result = self.forward(*input, **kwargs)\r\n    551         for hook in self._forward_hooks.values():\r\n    552             hook_result = hook(self, input, result)\r\n\r\n/media/sf_COVID19KTool/COVID19KTool/discourse/models/discourse_crf_model.py in forward(self, sentences, labels)\r\n     77 \r\n     78         # CRF prediction\r\n---> 79         logits = self.label_projection_layer(encoded_sentences) # size: (n_batch, n_sents, n_classes)\r\n     80         best_paths = self.crf.viterbi_tags(logits, sentence_masks)\r\n     81         predicted_labels = [x for x, y in best_paths]\r\n\r\n~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    548             result = self._slow_forward(*input, **kwargs)\r\n    549         else:\r\n--> 550             result = self.forward(*input, **kwargs)\r\n    551         for hook in self._forward_hooks.values():\r\n    552             hook_result = hook(self, input, result)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/allennlp/modules/time_distributed.py in forward(self, pass_through, *inputs, **kwargs)\r\n     49             reshaped_kwargs[key] = value\r\n     50 \r\n---> 51         reshaped_outputs = self._module(*reshaped_inputs, **reshaped_kwargs)\r\n     52 \r\n     53         if some_input is None:\r\n\r\n~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    548             result = self._slow_forward(*input, **kwargs)\r\n    549         else:\r\n--> 550             result = self.forward(*input, **kwargs)\r\n    551         for hook in self._forward_hooks.values():\r\n    552             hook_result = hook(self, input, result)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py in forward(self, input)\r\n     85 \r\n     86     def forward(self, input):\r\n---> 87         return F.linear(input, self.weight, self.bias)\r\n     88 \r\n     89     def extra_repr(self):\r\n\r\n~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py in linear(input, weight, bias)\r\n   1608     if input.dim() == 2 and bias is not None:\r\n   1609         # fused op is marginally faster\r\n-> 1610         ret = torch.addmm(bias, input, weight.t())\r\n   1611     else:\r\n   1612         output = input.matmul(weight.t())\r\n\r\nRuntimeError: size mismatch, m1: [640 x 600], m2: [400 x 2] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:41\r\n\r\n```\r\n\r\nAm I doing something wrong? And could you update the transfer learning script to fit this change?\r\n\r\nThanks.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/titipata/detecting-scientific-claim/issues/24/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/titipata/detecting-scientific-claim/issues/24/timeline","performed_via_github_app":null,"state_reason":null}