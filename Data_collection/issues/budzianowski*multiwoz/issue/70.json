{"url":"https://api.github.com/repos/budzianowski/multiwoz/issues/70","repository_url":"https://api.github.com/repos/budzianowski/multiwoz","labels_url":"https://api.github.com/repos/budzianowski/multiwoz/issues/70/labels{/name}","comments_url":"https://api.github.com/repos/budzianowski/multiwoz/issues/70/comments","events_url":"https://api.github.com/repos/budzianowski/multiwoz/issues/70/events","html_url":"https://github.com/budzianowski/multiwoz/issues/70","id":833643193,"node_id":"MDU6SXNzdWU4MzM2NDMxOTM=","number":70,"title":"Tokenization and BLEU score ","user":{"login":"Tomiinek","id":13215584,"node_id":"MDQ6VXNlcjEzMjE1NTg0","avatar_url":"https://avatars.githubusercontent.com/u/13215584?v=4","gravatar_id":"","url":"https://api.github.com/users/Tomiinek","html_url":"https://github.com/Tomiinek","followers_url":"https://api.github.com/users/Tomiinek/followers","following_url":"https://api.github.com/users/Tomiinek/following{/other_user}","gists_url":"https://api.github.com/users/Tomiinek/gists{/gist_id}","starred_url":"https://api.github.com/users/Tomiinek/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Tomiinek/subscriptions","organizations_url":"https://api.github.com/users/Tomiinek/orgs","repos_url":"https://api.github.com/users/Tomiinek/repos","events_url":"https://api.github.com/users/Tomiinek/events{/privacy}","received_events_url":"https://api.github.com/users/Tomiinek/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-03-17T10:51:33Z","updated_at":"2021-06-17T16:57:58Z","closed_at":"2021-06-17T16:57:58Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Hello, I have a hard time evaluating my model. \r\n\r\nFirst, the score for DAMD in the end-to-end modeling table should be 16.6 (as described in their paper) and not 18.6.\r\n\r\nSecond, I found out that the way I tokenize my responses highly affects the resulting BLEU score. I checked the systems from the end-to-end modeling table that have an open implementation and I am afraid that the numbers are not comparable:\r\n\r\n- DAMD (16.6) -- the tokens they use seem to be the same as the tokens that are predicted by their model (they do not use subwords).\r\n- LABES-S2S (18.3) -- The score seems to me too high concerning their rather low inform and success rates. However, there is no code or predictions.\r\n- LAVA (12.0) -- I cannot find out why their score is too low. The outputs they provide are good, and they probably use the tokens corresponding to the words predicted by their model including the <unk> tokens in ground truth responses.\r\n- UBAR (17.0) -- I do not understand the code. It is adapted from DAMD, but they use subwords, so I am not sure about it. Besides that, their reported inform rate is higher than the theoretical upper bound which I hope is somewhere around 92.2.\r\n- SimpleTOD (15.01) -- They decode responses using the HF GPT2 tokenizer and split them by whitespaces to get the tokens for computing the BLEU score. However, they do not care about interpunction or other stuff, so it is underestimated compared to the DAMD.\r\n- MinTL (17.89) -- They decode responses using the HF BERT tokenizer, prepend all `.` `,` `!` `?` `:` `'s` with spaces, split them by whitespaces, and use the tokens for the BLEU score.\r\n- SOLOIST (16.56), SUMBT+LaRL (17.9) -- no code :disappointed:\r\n- Others - More papers are evaluating MultiWOZ and comparing to these numbers. Some of them use the NLTK tokenizer and it probably results in overestimated scores compared to the DAMD or MinTL. \r\n\r\nI evaluated my data using different tokenization approaches and there are results:\r\n- NLTK tokenization with special care of the delexicalized spans - 17.9\r\n- NLTK tokenization without special care of the delexicalized spans - 24.5\r\n- whitespace splitting - 14.0\r\n- whitespace splitting with prepending `.` `,` `!` `?` `:` `'s` - 16.9\r\n\r\nI think this shows that the evaluation script in this repository should be modified so that it first normalizes the input strings (for example using tokenization and immediate detokenization with the Moses tokenizer), somehow resolves the delexicalized spans (removes spaces etc., removes `[` and `]`) and does the tokenization on its own. I would really appreciate a standalone script that would be able to output the score from the delexicalized responses with corresponding dialogue and turn ids (provided in a file in a predefined format).  \r\nOr at least a guide to the preferred tokenization would be highly appreciated (for future generations).\r\n\r\nSimilarly, it would be also very nice to have a **standalone** script for computing inform and success rates that would accept just a file with delexicalized responses (taking into accunt that domain names do not have to be present in the spans) and corresponding dialogue states in `.json`\r\n\r\n\r\n","closed_by":{"login":"Tomiinek","id":13215584,"node_id":"MDQ6VXNlcjEzMjE1NTg0","avatar_url":"https://avatars.githubusercontent.com/u/13215584?v=4","gravatar_id":"","url":"https://api.github.com/users/Tomiinek","html_url":"https://github.com/Tomiinek","followers_url":"https://api.github.com/users/Tomiinek/followers","following_url":"https://api.github.com/users/Tomiinek/following{/other_user}","gists_url":"https://api.github.com/users/Tomiinek/gists{/gist_id}","starred_url":"https://api.github.com/users/Tomiinek/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Tomiinek/subscriptions","organizations_url":"https://api.github.com/users/Tomiinek/orgs","repos_url":"https://api.github.com/users/Tomiinek/repos","events_url":"https://api.github.com/users/Tomiinek/events{/privacy}","received_events_url":"https://api.github.com/users/Tomiinek/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/budzianowski/multiwoz/issues/70/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/budzianowski/multiwoz/issues/70/timeline","performed_via_github_app":null,"state_reason":"completed"}