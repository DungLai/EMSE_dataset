{"url":"https://api.github.com/repos/TimoBolkart/TF_FLAME/issues/28","repository_url":"https://api.github.com/repos/TimoBolkart/TF_FLAME","labels_url":"https://api.github.com/repos/TimoBolkart/TF_FLAME/issues/28/labels{/name}","comments_url":"https://api.github.com/repos/TimoBolkart/TF_FLAME/issues/28/comments","events_url":"https://api.github.com/repos/TimoBolkart/TF_FLAME/issues/28/events","html_url":"https://github.com/TimoBolkart/TF_FLAME/issues/28","id":700480589,"node_id":"MDU6SXNzdWU3MDA0ODA1ODk=","number":28,"title":"how to load obj file, mtl file and texture png?","user":{"login":"Adorablepet","id":29625016,"node_id":"MDQ6VXNlcjI5NjI1MDE2","avatar_url":"https://avatars.githubusercontent.com/u/29625016?v=4","gravatar_id":"","url":"https://api.github.com/users/Adorablepet","html_url":"https://github.com/Adorablepet","followers_url":"https://api.github.com/users/Adorablepet/followers","following_url":"https://api.github.com/users/Adorablepet/following{/other_user}","gists_url":"https://api.github.com/users/Adorablepet/gists{/gist_id}","starred_url":"https://api.github.com/users/Adorablepet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Adorablepet/subscriptions","organizations_url":"https://api.github.com/users/Adorablepet/orgs","repos_url":"https://api.github.com/users/Adorablepet/repos","events_url":"https://api.github.com/users/Adorablepet/events{/privacy}","received_events_url":"https://api.github.com/users/Adorablepet/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-09-13T03:48:56Z","updated_at":"2020-09-16T18:51:41Z","closed_at":"2020-09-16T18:51:41Z","author_association":"NONE","active_lock_reason":null,"body":"I generated ` imgHQ00088.obj` `imgHQ00088.mtl` `imgHQ00088.png` with the following command.Then use this three file to add texture information to the obj output by `voca`. Under `voca/animation_output/meshes_textured` directory have generated new obj, mtl and png.  For example, 00000.obj, 00000.mtl, 00000.png...\r\nI have a problem now, how do I generate a video with texture from these files?\r\n``` bash\r\npython fit_2D_landmarks.py --model_fname './models/female_model.pkl' --flame_lmk_path './data/flame_static_embedding.pkl' --texture_mapping './data/texture_data_512.npy' --target_img_path './data/imgHQ00088.jpeg' --target_lmk_path './data/imgHQ00088_lmks.npy' --out_path './results'\r\npython build_texture_from_image.py --source_img './data/imgHQ00088.jpeg' --target_mesh './results/imgHQ00088.obj' --target_scale './results/imgHQ00088_scale.npy' --texture_mapping './data/texture_data_512.npy' --out_path './results'\r\npython fit_3D_landmarks.py\r\npython fit_3D_mesh.py\r\n```\r\nthis is my code\r\n``` bash\r\nimport os\r\nimport glob\r\nimport argparse\r\nfrom subprocess import call\r\nfrom psbody.mesh import Mesh\r\nfrom psbody.mesh.meshviewer import MeshViewer\r\n\r\nparser = argparse.ArgumentParser(description='Sequence visualization')\r\nparser.add_argument('--sequence_path', default='./animation_output', help='Path to motion sequence')\r\nparser.add_argument('--audio_fname', default='./audio/test_sentence.wav', help='Path of speech sequence')\r\nparser.add_argument('--out_path', default='./animation_visualization', help='Output path')\r\n\r\nargs = parser.parse_args()\r\nsequence_path = args.sequence_path\r\naudio_fname = args.audio_fname\r\nout_path = args.out_path\r\n\r\nif not os.path.exists(args.out_path): os.makedirs(args.out_path)\r\nimg_path = os.path.join(out_path, 'img')\r\nif not os.path.exists(img_path): os.makedirs(img_path)\r\n\r\nmv = MeshViewer()\r\nsequence_fnames = sorted(glob.glob(os.path.join(sequence_path, '*.obj')))\r\nif len(sequence_fnames) == 0:\r\n    print('No meshes found')\r\n\r\n# Render images\r\nfor frame_idx, mesh_fname in enumerate(sequence_fnames):\r\n    frame_mesh = Mesh(filename=mesh_fname)\r\n    temp = mesh_fname.split('/')\r\n    frame_mesh.set_texture_image(temp[-1][:-4] + '.png')    \r\n    mv.set_dynamic_meshes([frame_mesh], blocking=True)\r\n    img_fname = os.path.join(img_path, '%05d.png' % frame_idx)\r\n    mv.save_snapshot(img_fname)\r\n\r\n# Encode images to video\r\ncmd_audio = []\r\nif os.path.exists(audio_fname):\r\n    cmd_audio += ['-i', audio_fname]\r\n    print cmd_audio\r\n\r\nif os.path.exists(args.out_path):\r\nprint(args.out_path)\r\n\r\nout_video_fname = os.path.join(out_path, 'video2.mp4')\r\nprint(out_video_fname)\r\ncmd = ['ffmpeg', '-framerate', '60', '-pattern_type', 'glob', '-i', os.path.join(img_path, '*.png')] + cmd_audio + [out_video_fname]\r\ncall(cmd)\r\n```","closed_by":{"login":"TimoBolkart","id":26549953,"node_id":"MDQ6VXNlcjI2NTQ5OTUz","avatar_url":"https://avatars.githubusercontent.com/u/26549953?v=4","gravatar_id":"","url":"https://api.github.com/users/TimoBolkart","html_url":"https://github.com/TimoBolkart","followers_url":"https://api.github.com/users/TimoBolkart/followers","following_url":"https://api.github.com/users/TimoBolkart/following{/other_user}","gists_url":"https://api.github.com/users/TimoBolkart/gists{/gist_id}","starred_url":"https://api.github.com/users/TimoBolkart/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/TimoBolkart/subscriptions","organizations_url":"https://api.github.com/users/TimoBolkart/orgs","repos_url":"https://api.github.com/users/TimoBolkart/repos","events_url":"https://api.github.com/users/TimoBolkart/events{/privacy}","received_events_url":"https://api.github.com/users/TimoBolkart/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/TimoBolkart/TF_FLAME/issues/28/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/TimoBolkart/TF_FLAME/issues/28/timeline","performed_via_github_app":null,"state_reason":"completed"}