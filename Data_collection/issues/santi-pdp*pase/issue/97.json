{"url":"https://api.github.com/repos/santi-pdp/pase/issues/97","repository_url":"https://api.github.com/repos/santi-pdp/pase","labels_url":"https://api.github.com/repos/santi-pdp/pase/issues/97/labels{/name}","comments_url":"https://api.github.com/repos/santi-pdp/pase/issues/97/comments","events_url":"https://api.github.com/repos/santi-pdp/pase/issues/97/events","html_url":"https://github.com/santi-pdp/pase/issues/97","id":599457064,"node_id":"MDU6SXNzdWU1OTk0NTcwNjQ=","number":97,"title":"Question about distortion file","user":{"login":"RE-N-Y","id":19684973,"node_id":"MDQ6VXNlcjE5Njg0OTcz","avatar_url":"https://avatars.githubusercontent.com/u/19684973?v=4","gravatar_id":"","url":"https://api.github.com/users/RE-N-Y","html_url":"https://github.com/RE-N-Y","followers_url":"https://api.github.com/users/RE-N-Y/followers","following_url":"https://api.github.com/users/RE-N-Y/following{/other_user}","gists_url":"https://api.github.com/users/RE-N-Y/gists{/gist_id}","starred_url":"https://api.github.com/users/RE-N-Y/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RE-N-Y/subscriptions","organizations_url":"https://api.github.com/users/RE-N-Y/orgs","repos_url":"https://api.github.com/users/RE-N-Y/repos","events_url":"https://api.github.com/users/RE-N-Y/events{/privacy}","received_events_url":"https://api.github.com/users/RE-N-Y/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-04-14T10:17:22Z","updated_at":"2020-05-04T02:07:17Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"HI,\r\n\r\nI'm trying to fine-tune PASE+ model on my own dataset, but it seems that I'm getting this error for the training script. I was able to correctly produce the stats file and .scp files with the provided python script.\r\n\r\nHere's my output from my train.py.\r\n\r\n`[!] Using CPU\r\nSeeds initialized to 2\r\n{'regr': [{'num_outputs': 1, 'dropout': 0, 'dropout_time': 0.0, 'hidden_layers': 1, 'name': 'cchunk', 'type': 'decoder', 'hidden_size': 64, 'fmaps': [512, 256, 128], 'strides': [4, 4, 10], 'kwidths': [30, 30, 30], 'loss': <pase.losses.ContextualizedLoss object at 0x2b3d9d6a49d0>}, {'num_outputs': 3075, 'dropout': 0, 'hidden_size': 256, 'hidden_layers': 1, 'name': 'lps', 'context': 1, 'r': 7, 'loss': <pase.losses.ContextualizedLoss object at 0x2b3d9d58bc10>, 'skip': False}, {'num_outputs': 3075, 'dropout': 0, 'hidden_size': 256, 'hidden_layers': 1, 'name': 'lps_long', 'context': 1, 'r': 7, 'transform': {'win': 512}, 'loss': <pase.losses.ContextualizedLoss object at 0x2b3d9d6a4a50>, 'skip': False}, {'num_outputs': 120, 'dropout': 0, 'hidden_size': 256, 'hidden_layers': 1, 'name': 'fbank', 'context': 1, 'r': 7, 'loss': <pase.losses.ContextualizedLoss object at 0x2b3d9d6a4a90>, 'skip': False}, {'num_outputs': 120, 'dropout': 0, 'hidden_size': 256, 'hidden_layers': 1, 'name': 'fbank_long', 'context': 1, 'r': 7, 'transform': {'win': 1024, 'n_fft': 1024}, 'loss': <pase.losses.ContextualizedLoss object at 0x2b3d9d6a4ad0>, 'skip': False}, {'num_outputs': 120, 'dropout': 0, 'hidden_size': 256, 'hidden_layers': 1, 'name': 'gtn', 'context': 1, 'r': 7, 'loss': <pase.losses.ContextualizedLoss object at 0x2b3d9d6a4b10>, 'skip': False}, {'num_outputs': 120, 'dropout': 0, 'hidden_size': 256, 'hidden_layers': 1, 'name': 'gtn_long', 'context': 1, 'r': 7, 'loss': <pase.losses.ContextualizedLoss object at 0x2b3d9d6a4b50>, 'transform': {'win': 2048}, 'skip': False}, {'num_outputs': 39, 'dropout': 0, 'hidden_size': 256, 'hidden_layers': 1, 'name': 'mfcc', 'context': 1, 'r': 7, 'loss': <pase.losses.ContextualizedLoss object at 0x2b3d9d6a4b90>, 'skip': False}, {'num_outputs': 60, 'dropout': 0, 'hidden_size': 256, 'hidden_layers': 1, 'name': 'mfcc_long', 'context': 1, 'r': 7, 'transform': {'win': 2048, 'order': 20}, 'loss': <pase.losses.ContextualizedLoss object at 0x2b3d9d6a4bd0>, 'skip': False}, {'num_outputs': 12, 'dropout': 0, 'hidden_size': 256, 'hidden_layers': 1, 'name': 'prosody', 'context': 1, 'r': 7, 'loss': <pase.losses.ContextualizedLoss object at 0x2b3d9d6a4c10>, 'skip': False}], 'cls': [{'num_outputs': 1, 'dropout': 0, 'hidden_size': 256, 'hidden_layers': 1, 'name': 'mi', 'loss': <pase.losses.ContextualizedLoss object at 0x2b3d9d6a4cd0>, 'skip': False, 'keys': ['chunk', 'chunk_ctxt', 'chunk_rand']}, {'num_outputs': 1, 'dropout': 0, 'hidden_size': 256, 'hidden_layers': 1, 'name': 'cmi', 'augment': True, 'loss': <pase.losses.ContextualizedLoss object at 0x2b3d9d6a4d90>, 'skip': False, 'keys': ['chunk', 'chunk_ctxt', 'chunk_rand']}]}\r\nCompose(\r\n    ToTensor()\r\n    MIChunkWav(32000)\r\n    LPS(n_fft=2048, hop=160, win=400, device=cpu)\r\n    LPS(n_fft=2048, hop=160, win=512, device=cpu)\r\n    FBanks(n_fft=512, n_filters=40, hop=160, win=400\r\n    FBanks(n_fft=1024, n_filters=40, hop=160, win=1024\r\n    Gammatone(f_min=500, n_channels=40, hop=160, win=400)\r\n    Gammatone(f_min=500, n_channels=40, hop=160, win=2048)\r\n    MFCC(order=13, sr=16000)\r\n    MFCC(order=20, sr=16000)\r\n    Prosody(hop=160, win=320, f0_min=60, f0_max=300, sr=16000)\r\n    ZNorm(data/PARK_stats.pkl)\r\n)\r\nPreparing dset for <MY DATASET FOLDER>\r\nFound 0 *.npy ir_files in data/omologo_revs_bin\r\n`\r\nIt seems that the issue is that there is no file called omologo_revs_bin inside data? If so, is it possible to get it?\r\n\r\nThank you in advance!","closed_by":null,"reactions":{"url":"https://api.github.com/repos/santi-pdp/pase/issues/97/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/santi-pdp/pase/issues/97/timeline","performed_via_github_app":null,"state_reason":null}