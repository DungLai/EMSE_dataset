{"url":"https://api.github.com/repos/jgraving/DeepPoseKit/issues/35","repository_url":"https://api.github.com/repos/jgraving/DeepPoseKit","labels_url":"https://api.github.com/repos/jgraving/DeepPoseKit/issues/35/labels{/name}","comments_url":"https://api.github.com/repos/jgraving/DeepPoseKit/issues/35/comments","events_url":"https://api.github.com/repos/jgraving/DeepPoseKit/issues/35/events","html_url":"https://github.com/jgraving/DeepPoseKit/issues/35","id":535966644,"node_id":"MDU6SXNzdWU1MzU5NjY2NDQ=","number":35,"title":"Shape mismatch error when training with `DLCDataGenerator`","user":{"login":"monajalal","id":1892917,"node_id":"MDQ6VXNlcjE4OTI5MTc=","avatar_url":"https://avatars.githubusercontent.com/u/1892917?v=4","gravatar_id":"","url":"https://api.github.com/users/monajalal","html_url":"https://github.com/monajalal","followers_url":"https://api.github.com/users/monajalal/followers","following_url":"https://api.github.com/users/monajalal/following{/other_user}","gists_url":"https://api.github.com/users/monajalal/gists{/gist_id}","starred_url":"https://api.github.com/users/monajalal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/monajalal/subscriptions","organizations_url":"https://api.github.com/users/monajalal/orgs","repos_url":"https://api.github.com/users/monajalal/repos","events_url":"https://api.github.com/users/monajalal/events{/privacy}","received_events_url":"https://api.github.com/users/monajalal/received_events","type":"User","site_admin":false},"labels":[{"id":1348126481,"node_id":"MDU6TGFiZWwxMzQ4MTI2NDgx","url":"https://api.github.com/repos/jgraving/DeepPoseKit/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2019-12-10T20:11:42Z","updated_at":"2019-12-11T10:31:13Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi Jake, your DLC train notebook crashes when I use my own moth dataset. Here is my saved Jupyter notebook which also has the complete error log: https://colab.research.google.com/drive/1yr5YybbAtnSCdkOC4Gbw9GKhrIGATEGS?authuser=1\r\n\r\nCould you please guide how to fix this error?\r\n\r\n```\r\n(/scratch3/3d_pose/DeepPoseKitEnv) [jalal@goku examples]$ pwd\r\n/scratch3/3d_pose/animalpose/dpk/DeepPoseKit/examples\r\n\r\n\r\n(/scratch3/3d_pose/DeepPoseKitEnv) [jalal@goku examples]$ python dlc_train.py \r\n1.15.0\r\n{'Task': 'moth-filtered', 'scorer': 'Mona', 'date': 'Dec6', 'project_path': '/projectnb/ivcgroup/jalal/moth-filtered-Mona-2019-12-06', 'video_sets': {'/projectnb/ivcgroup/jalal/moth-filtered-Mona-2019-12-06/videos/moth.avi': {'crop': '0, 800, 0, 600'}}, 'bodyparts': ['head', 'rightWingTip', 'leftWingTip', 'abdomenTip'], 'start': 0, 'stop': 1, 'numframes2pick': 100, 'skeleton': [['bodypart1', 'bodypart2'], ['objectA', 'bodypart3']], 'skeleton_color': 'black', 'pcutoff': 0.1, 'dotsize': 12, 'alphavalue': 0.7, 'colormap': 'jet', 'TrainingFraction': [0.95], 'iteration': 0, 'resnet': None, 'snapshotindex': -1, 'batch_size': 8, 'cropping': False, 'x1': 0, 'x2': 640, 'y1': 277, 'y2': 624, 'corner2move2': [50, 50], 'move2corner': True, 'default_net_type': 'resnet_50', 'default_augmenter': 'default'}\r\nWARNING:tensorflow:From /scratch3/3d_pose/DeepPoseKitEnv/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\n2019-12-10 15:04:24.550212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2019-12-10 15:04:24.595099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:05:00.0\r\n2019-12-10 15:04:24.596212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:06:00.0\r\n2019-12-10 15:04:24.596536: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-12-10 15:04:24.597751: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-12-10 15:04:24.598866: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2019-12-10 15:04:24.599135: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2019-12-10 15:04:24.600569: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-12-10 15:04:24.601678: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-12-10 15:04:24.604910: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-12-10 15:04:24.610145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\r\n2019-12-10 15:04:24.610503: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-12-10 15:04:24.616205: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3597855000 Hz\r\n2019-12-10 15:04:24.616695: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559cf7c5d7b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2019-12-10 15:04:24.616720: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2019-12-10 15:04:24.855663: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559cf7cf0e30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2019-12-10 15:04:24.855736: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\r\n2019-12-10 15:04:24.855764: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1\r\n2019-12-10 15:04:24.864118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:05:00.0\r\n2019-12-10 15:04:24.866477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:06:00.0\r\n2019-12-10 15:04:24.866581: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-12-10 15:04:24.866635: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-12-10 15:04:24.866683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2019-12-10 15:04:24.866730: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2019-12-10 15:04:24.866777: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-12-10 15:04:24.866825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-12-10 15:04:24.866872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-12-10 15:04:24.875663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\r\n2019-12-10 15:04:24.875759: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-12-10 15:04:24.883670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-12-10 15:04:24.883718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \r\n2019-12-10 15:04:24.883749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \r\n2019-12-10 15:04:24.883773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \r\n2019-12-10 15:04:24.889842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9972 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)\r\n2019-12-10 15:04:24.892445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10479 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:06:00.0, compute capability: 6.1)\r\nWARNING:tensorflow:From /scratch3/3d_pose/DeepPoseKitEnv/lib/python3.6/site-packages/deepposekit/models/backend/utils.py:35: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\n2019-12-10 15:04:44.034373: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-12-10 15:04:45.322586: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-12-10 15:04:48.539242: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n500/500 [==============================] - 13s 26ms/sample\r\n37.74724634267033\r\n/scratch3/3d_pose/DeepPoseKitEnv/lib/python3.6/site-packages/deepposekit/models/engine.py:145: UserWarning: \r\nAutomatically compiling with default settings: model.compile('adam', 'mse')\r\nCall model.compile() manually to use non-default settings.\r\n\r\n  \"\"\"\\nAutomatically compiling with default settings: model.compile('adam', 'mse')\\n\"\"\"\r\nEpoch 1/100\r\nTraceback (most recent call last):\r\n  File \"dlc_train.py\", line 204, in <module>\r\n    steps_per_epoch=200,\r\n  File \"/scratch3/3d_pose/DeepPoseKitEnv/lib/python3.6/site-packages/deepposekit/models/engine.py\", line 174, in fit\r\n    **kwargs\r\n  File \"/scratch3/3d_pose/DeepPoseKitEnv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 1296, in fit_generator\r\n    steps_name='steps_per_epoch')\r\n  File \"/scratch3/3d_pose/DeepPoseKitEnv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py\", line 265, in model_iteration\r\n    batch_outs = batch_function(*batch_data)\r\n  File \"/scratch3/3d_pose/DeepPoseKitEnv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 991, in train_on_batch\r\n    extract_tensors_from_dataset=True)\r\n  File \"/scratch3/3d_pose/DeepPoseKitEnv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 2537, in _standardize_user_data\r\n    y, self._feed_loss_fns, feed_output_shapes)\r\n  File \"/scratch3/3d_pose/DeepPoseKitEnv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py\", line 741, in check_loss_and_target_compatibility\r\n    ' while using as loss `' + loss_name + '`. '\r\nValueError: A target array with shape (5, 75, 100, 10) was passed for an output of shape (None, 74, 100, 10) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output.\r\nterminate called without an active exception\r\nAborted\r\n(/scratch3/3d_pose/DeepPoseKitEnv) [jalal@goku examples]$ \r\n```\r\n\r\nHere is a list of all packages I have installed:\r\n```\r\n(/scratch3/3d_pose/DeepPoseKitEnv) [jalal@goku examples]$ pip list\r\nPackage                Version            \r\n---------------------- -------------------\r\nabsl-py                0.8.1              \r\nastor                  0.8.0              \r\nattrs                  19.3.0             \r\nbackcall               0.1.0              \r\nbleach                 3.1.0              \r\ncertifi                2019.11.28         \r\nchardet                3.0.4              \r\nClick                  7.0                \r\ncycler                 0.10.0             \r\ndecorator              4.4.1              \r\ndeeplabcut             2.1.4              \r\ndeepposekit            0.3.4              \r\ndefusedxml             0.6.0              \r\neasydict               1.9                \r\nentrypoints            0.3                \r\ngast                   0.2.2              \r\ngoogle-pasta           0.1.8              \r\ngrpcio                 1.25.0             \r\nh5py                   2.10.0             \r\nidna                   2.8                \r\nimageio                2.6.1              \r\nimageio-ffmpeg         0.3.0              \r\nimgaug                 0.3.0              \r\nimportlib-metadata     1.2.0              \r\nintel-openmp           2020.0.133         \r\nipykernel              5.1.3              \r\nipython                7.10.1             \r\nipython-genutils       0.2.0              \r\nipywidgets             7.5.1              \r\njedi                   0.15.1             \r\nJinja2                 2.10.3             \r\njoblib                 0.14.0             \r\njsonschema             3.2.0              \r\njupyter                1.0.0              \r\njupyter-client         5.3.4              \r\njupyter-console        6.0.0              \r\njupyter-core           4.6.1              \r\nKeras-Applications     1.0.8              \r\nKeras-Preprocessing    1.1.0              \r\nkiwisolver             1.1.0              \r\nMarkdown               3.1.1              \r\nMarkupSafe             1.1.1              \r\nmatplotlib             3.0.3              \r\nmistune                0.8.4              \r\nmock                   3.0.5              \r\nmore-itertools         8.0.2              \r\nmoviepy                1.0.1              \r\nmsgpack                0.6.2              \r\nmsgpack-numpy          0.4.4.3            \r\nnbconvert              5.6.1              \r\nnbformat               4.4.0              \r\nnetworkx               2.4                \r\nnotebook               6.0.2              \r\nnumexpr                2.7.0              \r\nnumpy                  1.17.4             \r\nopencv-python          3.4.5.20           \r\nopencv-python-headless 4.1.2.30           \r\nopt-einsum             3.1.0              \r\npandas                 0.25.3             \r\npandocfilters          1.4.2              \r\nparso                  0.5.1              \r\npatsy                  0.5.1              \r\npexpect                4.7.0              \r\npickleshare            0.7.5              \r\nPillow                 6.2.1              \r\npip                    19.3.1             \r\nproglog                0.1.9              \r\nprometheus-client      0.7.1              \r\nprompt-toolkit         3.0.2              \r\nprotobuf               3.11.1             \r\npsutil                 5.6.7              \r\nptyprocess             0.6.0              \r\nPygments               2.5.2              \r\npyparsing              2.4.5              \r\nPypubsub               4.0.3              \r\npyrsistent             0.15.6             \r\npython-dateutil        2.8.1              \r\npytz                   2019.3             \r\nPyWavelets             1.1.1              \r\nPyYAML                 5.2                \r\npyzmq                  18.1.1             \r\nqtconsole              4.6.0              \r\nrequests               2.22.0             \r\nruamel.yaml            0.16.5             \r\nruamel.yaml.clib       0.2.0              \r\nscikit-image           0.16.2             \r\nscikit-learn           0.22               \r\nscipy                  1.3.3              \r\nSend2Trash             1.5.0              \r\nsetuptools             42.0.2.post20191203\r\nShapely                1.6.4.post2        \r\nsix                    1.13.0             \r\nstatsmodels            0.10.1             \r\ntables                 3.4.3              \r\ntabulate               0.8.6              \r\ntensorboard            1.15.0             \r\ntensorflow-estimator   1.15.1             \r\ntensorflow-gpu         1.15.0             \r\ntensorpack             0.9.8              \r\ntermcolor              1.1.0              \r\nterminado              0.8.3              \r\ntestpath               0.4.4              \r\ntornado                6.0.3              \r\ntqdm                   4.40.1             \r\ntraitlets              4.3.3              \r\nurllib3                1.25.7             \r\nwcwidth                0.1.7              \r\nwebencodings           0.5.1              \r\nWerkzeug               0.16.0             \r\nwheel                  0.33.6             \r\nwidgetsnbextension     3.5.1              \r\nwrapt                  1.11.2             \r\nwxPython               4.0.3              \r\nzipp                   0.6.0              \r\n\r\n```\r\n\r\n\r\nHere's the Python code:\r\n```\r\n(/scratch3/3d_pose/DeepPoseKitEnv) [jalal@goku examples]$ cat dlc_train.py \r\nimport sys\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport glob\r\n\r\nfrom deepposekit.io import TrainingGenerator, DLCDataGenerator\r\nfrom deepposekit.augment import FlipAxis\r\nimport imgaug.augmenters as iaa\r\nimport imgaug as ia\r\n\r\nfrom deepposekit.models import (StackedDenseNet,\r\n                                DeepLabCut,\r\n                                StackedHourglass,\r\n                                LEAP)\r\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\r\n\r\nfrom deepposekit.callbacks import Logger, ModelCheckpoint\r\nfrom deepposekit.models import load_model\r\n\r\nimport time\r\nfrom os.path import expanduser\r\n\r\ntry:\r\n    import google.colab\r\n    IN_COLAB = True\r\nexcept:\r\n    IN_COLAB = False\r\n\r\ndata_generator = DLCDataGenerator(\r\n    project_path='/scratch3/3d_pose/animalpose/experiments/moth-filtered-Mona-2019-12-06_95p_DONE/'\r\n)\r\n\r\nprint(data_generator.dlcconfig)\r\n\r\ndata_generator.graph = np.array([-1, 0, 0, 0])\r\n\r\ndata_generator.swap_index = np.array([-1, 2, 1, -1])\r\n\r\n\r\nimage, keypoints = data_generator[0]\r\n\r\nplt.figure(figsize=(5,5))\r\nimage = image[0] if image.shape[-1] is 3 else image[0, ..., 0]\r\ncmap = None if image.shape[-1] is 3 else 'gray'\r\nplt.imshow(image, cmap=cmap, interpolation='none')\r\nfor idx, jdx in enumerate(data_generator.graph):\r\n    if jdx > -1:\r\n        plt.plot(\r\n            [keypoints[0, idx, 0], keypoints[0, jdx, 0]],\r\n            [keypoints[0, idx, 1], keypoints[0, jdx, 1]],\r\n            'r-'\r\n        )\r\n\r\nplt.scatter(keypoints[0, :, 0], keypoints[0, :, 1], c=np.arange(data_generator.keypoints_shape[0]), s=50, cmap=plt.cm.hsv, zorder=3)\r\nplt.xlim(0, data_generator.image_shape[1])\r\nplt.ylim(0, data_generator.image_shape[0])\r\n\r\nplt.show()\r\n\r\n\r\naugmenter = []\r\n\r\naugmenter.append(FlipAxis(data_generator, axis=0))  # flip image up-down\r\naugmenter.append(FlipAxis(data_generator, axis=1))  # flip image left-right \r\n\r\nsometimes = []\r\nsometimes.append(iaa.Affine(scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\r\n                            translate_percent={'x': (-0.5, 0.5), 'y': (-0.5, 0.5)},\r\n                            shear=(-8, 8),\r\n                            order=ia.ALL,\r\n                            cval=ia.ALL)\r\n                 )\r\nsometimes.append(iaa.Affine(scale=(0.5, 1.5),\r\n                            order=ia.ALL,\r\n                            cval=ia.ALL)\r\n                 )\r\naugmenter.append(iaa.Sometimes(0.5, sometimes))\r\naugmenter.append(iaa.Sometimes(0.5, iaa.Affine(rotate=(-180, 180),\r\n                            order=ia.ALL,\r\n                            cval=ia.ALL))\r\n                 )\r\naugmenter = iaa.Sequential(augmenter)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nimage, keypoints = data_generator[0]\r\nimage, keypoints = augmenter(images=image, keypoints=keypoints)\r\nplt.figure(figsize=(5,5))\r\nimage = image[0] if image.shape[-1] is 3 else image[0, ..., 0]\r\ncmap = None if image.shape[-1] is 3 else 'gray'\r\nplt.imshow(image, cmap=cmap, interpolation='none')\r\nfor idx, jdx in enumerate(data_generator.graph):\r\n    if jdx > -1:\r\n        plt.plot(\r\n            [keypoints[0, idx, 0], keypoints[0, jdx, 0]],\r\n            [keypoints[0, idx, 1], keypoints[0, jdx, 1]],\r\n            'r-'\r\n        )\r\n\r\nplt.scatter(keypoints[0, :, 0], keypoints[0, :, 1], c=np.arange(data_generator.keypoints_shape[0]), s=50, cmap=plt.cm.hsv, zorder=3)\r\nplt.xlim(0, data_generator.image_shape[1])\r\nplt.ylim(0, data_generator.image_shape[0])\r\n\r\nplt.show()\r\n\r\n\r\ntrain_generator = TrainingGenerator(generator=data_generator,\r\n                                    downsample_factor=3,\r\n                                    augmenter=augmenter,\r\n                                    sigma=5,\r\n                                    validation_split=0.1,\r\n                                    use_graph=True,\r\n                                    random_seed=1,\r\n                                    graph_scale=1)\r\ntrain_generator.get_config()\r\n\r\n\r\nn_keypoints = data_generator.keypoints_shape[0]\r\nbatch = train_generator(batch_size=1, validation=False)[0]\r\ninputs = batch[0]\r\noutputs = batch[1]\r\n\r\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10,10))\r\nax1.set_title('image')\r\nax1.imshow(inputs[0,...,0], cmap='gray', vmin=0, vmax=255)\r\n\r\nax2.set_title('posture graph')\r\nax2.imshow(outputs[0,...,n_keypoints:-1].max(-1))\r\n\r\nax3.set_title('keypoints confidence')\r\nax3.imshow(outputs[0,...,:n_keypoints].max(-1))\r\n\r\nax4.set_title('posture graph and keypoints confidence')\r\nax4.imshow(outputs[0,...,-1], vmin=0)\r\nplt.show()\r\n\r\ntrain_generator.on_epoch_end()\r\n\r\n\r\nfrom deepposekit.models import DeepLabCut, StackedDenseNet, LEAP\r\n\r\n#model = StackedDenseNet(train_generator, n_stacks=1, growth_rate=32, pretrained=True)\r\n#model = DeepLabCut(train_generator, backbone=\"resnet50\")\r\n#model = DeepLabCut(train_generator, backbone=\"mobilenetv2\", alpha=1.0) # Increase alpha to improve accuracy\r\nmodel = DeepLabCut(train_generator, backbone=\"densenet121\")\r\n#model = LEAP(train_generator)\r\nmodel.get_config()\r\n\r\n\r\ndata_size = (500,) + data_generator.image_shape\r\nx = np.random.randint(0, 255, data_size, dtype=\"uint8\")\r\ny = model.predict(x[:100], batch_size=50) # make sure the model is in GPU memory\r\nt0 = time.time()\r\ny = model.predict(x, batch_size=50, verbose=1)\r\nt1 = time.time()\r\nprint(x.shape[0] / (t1 - t0))\r\n\r\n\r\nlogger = Logger(validation_batch_size=10\r\n    # filepath saves the logger data to a .h5 file\r\n    # filepath=HOME + \"/deeplabcut_log_dlcdensenet.h5\", validation_batch_size=10\r\n)\r\n\r\n\r\n\r\nreduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, verbose=1, patience=20)\r\n\r\n\r\nmodel_checkpoint = ModelCheckpoint(\r\n    \"../../deeplabcut_best_model_dlcdensenet_moth.h5\",\r\n    monitor=\"val_loss\",\r\n    # monitor=\"loss\" # use if validation_split=0\r\n    verbose=1,\r\n    save_best_only=True,\r\n    optimizer=True, # Set this to True if you wish to resume training from a saved model\r\n)\r\n\r\nearly_stop = EarlyStopping(\r\n    monitor=\"val_loss\",\r\n    # monitor=\"loss\" # use if validation_split=0\r\n    min_delta=0.001,\r\n    patience=100,\r\n    verbose=1\r\n)\r\n\r\n\r\n\r\ncallbacks = [early_stop, reduce_lr, model_checkpoint, logger]\r\n\r\n\r\nmodel.fit(\r\n    batch_size=5,\r\n    validation_batch_size=10,\r\n    callbacks=callbacks,\r\n    #epochs=1000, # Increase the number of epochs to train the model longer\r\n    epochs=100,\r\n    n_workers=8,\r\n    steps_per_epoch=200,\r\n)\r\n\r\n\r\nmodel = load_model(\r\n    \"../../deeplabcut_best_model_dlcdensenet_moth.h5\",\r\n    augmenter=augmenter,\r\n    generator=data_generator,\r\n)\r\n\r\n\r\nmodel.fit(\r\n    batch_size=5,\r\n    validation_batch_size=10,\r\n    callbacks=callbacks,\r\n    #epochs=1000, # Increase the number of epochs to train the model longer\r\n    epochs=100,\r\n    n_workers=8,\r\n    steps_per_epoch=200,\r\n\r\n```","closed_by":null,"reactions":{"url":"https://api.github.com/repos/jgraving/DeepPoseKit/issues/35/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/jgraving/DeepPoseKit/issues/35/timeline","performed_via_github_app":null,"state_reason":null}