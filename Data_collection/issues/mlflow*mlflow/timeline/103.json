[{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/404586447","html_url":"https://github.com/mlflow/mlflow/issues/103#issuecomment-404586447","issue_url":"https://api.github.com/repos/mlflow/mlflow/issues/103","id":404586447,"node_id":"MDEyOklzc3VlQ29tbWVudDQwNDU4NjQ0Nw==","user":{"login":"tomasatdatabricks","id":33237569,"node_id":"MDQ6VXNlcjMzMjM3NTY5","avatar_url":"https://avatars.githubusercontent.com/u/33237569?v=4","gravatar_id":"","url":"https://api.github.com/users/tomasatdatabricks","html_url":"https://github.com/tomasatdatabricks","followers_url":"https://api.github.com/users/tomasatdatabricks/followers","following_url":"https://api.github.com/users/tomasatdatabricks/following{/other_user}","gists_url":"https://api.github.com/users/tomasatdatabricks/gists{/gist_id}","starred_url":"https://api.github.com/users/tomasatdatabricks/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tomasatdatabricks/subscriptions","organizations_url":"https://api.github.com/users/tomasatdatabricks/orgs","repos_url":"https://api.github.com/users/tomasatdatabricks/repos","events_url":"https://api.github.com/users/tomasatdatabricks/events{/privacy}","received_events_url":"https://api.github.com/users/tomasatdatabricks/received_events","type":"User","site_admin":false},"created_at":"2018-07-12T17:20:55Z","updated_at":"2018-07-12T17:20:55Z","author_association":"CONTRIBUTOR","body":"Hi, which part of MLflow do you want to use with spark ml? We have just added a module for spark ml model export. You can install MLflow from github master branch and you should be able to use it or wait for the next release.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/404586447/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"tomasatdatabricks","id":33237569,"node_id":"MDQ6VXNlcjMzMjM3NTY5","avatar_url":"https://avatars.githubusercontent.com/u/33237569?v=4","gravatar_id":"","url":"https://api.github.com/users/tomasatdatabricks","html_url":"https://github.com/tomasatdatabricks","followers_url":"https://api.github.com/users/tomasatdatabricks/followers","following_url":"https://api.github.com/users/tomasatdatabricks/following{/other_user}","gists_url":"https://api.github.com/users/tomasatdatabricks/gists{/gist_id}","starred_url":"https://api.github.com/users/tomasatdatabricks/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tomasatdatabricks/subscriptions","organizations_url":"https://api.github.com/users/tomasatdatabricks/orgs","repos_url":"https://api.github.com/users/tomasatdatabricks/repos","events_url":"https://api.github.com/users/tomasatdatabricks/events{/privacy}","received_events_url":"https://api.github.com/users/tomasatdatabricks/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/408721555","html_url":"https://github.com/mlflow/mlflow/issues/103#issuecomment-408721555","issue_url":"https://api.github.com/repos/mlflow/mlflow/issues/103","id":408721555,"node_id":"MDEyOklzc3VlQ29tbWVudDQwODcyMTU1NQ==","user":{"login":"skeisoo","id":8802018,"node_id":"MDQ6VXNlcjg4MDIwMTg=","avatar_url":"https://avatars.githubusercontent.com/u/8802018?v=4","gravatar_id":"","url":"https://api.github.com/users/skeisoo","html_url":"https://github.com/skeisoo","followers_url":"https://api.github.com/users/skeisoo/followers","following_url":"https://api.github.com/users/skeisoo/following{/other_user}","gists_url":"https://api.github.com/users/skeisoo/gists{/gist_id}","starred_url":"https://api.github.com/users/skeisoo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/skeisoo/subscriptions","organizations_url":"https://api.github.com/users/skeisoo/orgs","repos_url":"https://api.github.com/users/skeisoo/repos","events_url":"https://api.github.com/users/skeisoo/events{/privacy}","received_events_url":"https://api.github.com/users/skeisoo/received_events","type":"User","site_admin":false},"created_at":"2018-07-30T01:21:06Z","updated_at":"2018-07-30T01:21:06Z","author_association":"NONE","body":"That's amazing！It's a really great help！Thank you！","reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/408721555/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"skeisoo","id":8802018,"node_id":"MDQ6VXNlcjg4MDIwMTg=","avatar_url":"https://avatars.githubusercontent.com/u/8802018?v=4","gravatar_id":"","url":"https://api.github.com/users/skeisoo","html_url":"https://github.com/skeisoo","followers_url":"https://api.github.com/users/skeisoo/followers","following_url":"https://api.github.com/users/skeisoo/following{/other_user}","gists_url":"https://api.github.com/users/skeisoo/gists{/gist_id}","starred_url":"https://api.github.com/users/skeisoo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/skeisoo/subscriptions","organizations_url":"https://api.github.com/users/skeisoo/orgs","repos_url":"https://api.github.com/users/skeisoo/repos","events_url":"https://api.github.com/users/skeisoo/events{/privacy}","received_events_url":"https://api.github.com/users/skeisoo/received_events","type":"User","site_admin":false}},{"id":1759123696,"node_id":"MDExOkNsb3NlZEV2ZW50MTc1OTEyMzY5Ng==","url":"https://api.github.com/repos/mlflow/mlflow/issues/events/1759123696","actor":{"login":"skeisoo","id":8802018,"node_id":"MDQ6VXNlcjg4MDIwMTg=","avatar_url":"https://avatars.githubusercontent.com/u/8802018?v=4","gravatar_id":"","url":"https://api.github.com/users/skeisoo","html_url":"https://github.com/skeisoo","followers_url":"https://api.github.com/users/skeisoo/followers","following_url":"https://api.github.com/users/skeisoo/following{/other_user}","gists_url":"https://api.github.com/users/skeisoo/gists{/gist_id}","starred_url":"https://api.github.com/users/skeisoo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/skeisoo/subscriptions","organizations_url":"https://api.github.com/users/skeisoo/orgs","repos_url":"https://api.github.com/users/skeisoo/repos","events_url":"https://api.github.com/users/skeisoo/events{/privacy}","received_events_url":"https://api.github.com/users/skeisoo/received_events","type":"User","site_admin":false},"event":"closed","commit_id":null,"commit_url":null,"created_at":"2018-07-30T01:21:07Z","state_reason":null,"performed_via_github_app":null},{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/559745348","html_url":"https://github.com/mlflow/mlflow/issues/103#issuecomment-559745348","issue_url":"https://api.github.com/repos/mlflow/mlflow/issues/103","id":559745348,"node_id":"MDEyOklzc3VlQ29tbWVudDU1OTc0NTM0OA==","user":{"login":"y-tee","id":26523874,"node_id":"MDQ6VXNlcjI2NTIzODc0","avatar_url":"https://avatars.githubusercontent.com/u/26523874?v=4","gravatar_id":"","url":"https://api.github.com/users/y-tee","html_url":"https://github.com/y-tee","followers_url":"https://api.github.com/users/y-tee/followers","following_url":"https://api.github.com/users/y-tee/following{/other_user}","gists_url":"https://api.github.com/users/y-tee/gists{/gist_id}","starred_url":"https://api.github.com/users/y-tee/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/y-tee/subscriptions","organizations_url":"https://api.github.com/users/y-tee/orgs","repos_url":"https://api.github.com/users/y-tee/repos","events_url":"https://api.github.com/users/y-tee/events{/privacy}","received_events_url":"https://api.github.com/users/y-tee/received_events","type":"User","site_admin":false},"created_at":"2019-11-29T10:37:27Z","updated_at":"2019-11-29T10:37:27Z","author_association":"NONE","body":"Hi Is it possible to serve saved spark ml models with mlflow api?\r\nI am seeing error as such when trying to serve the saved model. Any idea how to fix it?\r\n```\r\n19/11/29 18:10:58 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job\r\n[2019-11-29 18:10:58 +0800] [28178] [ERROR] Exception in worker process\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/site-packages/gunicorn/arbiter.py\", line 583, in spawn_worker\r\n    worker.init_process()\r\n  File \"/usr/local/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 129, in init_process\r\n    self.load_wsgi()\r\n  File \"/usr/local/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 138, in load_wsgi\r\n    self.wsgi = self.app.wsgi()\r\n  File \"/usr/local/lib/python3.6/site-packages/gunicorn/app/base.py\", line 67, in wsgi\r\n    self.callable = self.load()\r\n  File \"/usr/local/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py\", line 52, in load\r\n    return self.load_wsgiapp()\r\n  File \"/usr/local/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py\", line 41, in load_wsgiapp\r\n    return util.import_app(self.app_uri)\r\n  File \"/usr/local/lib/python3.6/site-packages/gunicorn/util.py\", line 350, in import_app\r\n    __import__(module)\r\n  File \"/home/davidooi/.local/lib/python3.6/site-packages/mlflow/pyfunc/scoring_server/wsgi.py\", line 6, in <module>\r\n    app = scoring_server.init(load_model(os.environ[scoring_server._SERVER_MODEL_PATH]))\r\n  File \"/home/davidooi/.local/lib/python3.6/site-packages/mlflow/pyfunc/__init__.py\", line 290, in load_model\r\n    return importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n  File \"/home/davidooi/.local/lib/python3.6/site-packages/mlflow/spark.py\", line 436, in _load_pyfunc\r\n    return _PyFuncModelWrapper(spark, _load_model(model_uri=path))\r\n  File \"/home/davidooi/.local/lib/python3.6/site-packages/mlflow/spark.py\", line 378, in _load_model\r\n    return PipelineModel.load(model_path)\r\n  File \"/opt/apps/ecm/service/spark/2.4.3-1.2.0/package/spark-2.4.3-1.2.0-bin-hadoop2.8/python/pyspark/ml/util.py\", line 362, in load\r\n    return cls.read().load(path)\r\n  File \"/opt/apps/ecm/service/spark/2.4.3-1.2.0/package/spark-2.4.3-1.2.0-bin-hadoop2.8/python/pyspark/ml/pipeline.py\", line 240, in load\r\n    metadata = DefaultParamsReader.loadMetadata(path, self.sc)\r\n  File \"/opt/apps/ecm/service/spark/2.4.3-1.2.0/package/spark-2.4.3-1.2.0-bin-hadoop2.8/python/pyspark/ml/util.py\", line 558, in loadMetadata\r\n    metadataStr = sc.textFile(metadataPath, 1).first()\r\n  File \"/opt/apps/ecm/service/spark/2.4.3-1.2.0/package/spark-2.4.3-1.2.0-bin-hadoop2.8/python/pyspark/rdd.py\", line 1378, in first\r\n    rs = self.take(1)\r\n  File \"/opt/apps/ecm/service/spark/2.4.3-1.2.0/package/spark-2.4.3-1.2.0-bin-hadoop2.8/python/pyspark/rdd.py\", line 1360, in take\r\n    res = self.context.runJob(self, takeUpToNumLeft, p)\r\n  File \"/opt/apps/ecm/service/spark/2.4.3-1.2.0/package/spark-2.4.3-1.2.0-bin-hadoop2.8/python/pyspark/context.py\", line 1069, in runJob\r\n    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\r\n  File \"/home/davidooi/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1257, in __call__\r\n    answer, self.gateway_client, self.target_id, self.name)\r\n  File \"/opt/apps/ecm/service/spark/2.4.3-1.2.0/package/spark-2.4.3-1.2.0-bin-hadoop2.8/python/pyspark/sql/utils.py\", line 63, in deco\r\n    return f(*a, **kw)\r\n  File \"/home/davidooi/.local/lib/python3.6/site-packages/py4j/protocol.py\", line 328, in get_return_value\r\n    format(target_id, \".\", name), value)\r\npy4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\r\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\r\n  File \"/opt/apps/ecm/service/spark/2.4.3-1.2.0/package/spark-2.4.3-1.2.0-bin-hadoop2.8/python/lib/pyspark.zip/pyspark/worker.py\", line 267, in main\r\n    (\"%d.%d\" % sys.version_info[:2], version))\r\nException: Python in worker has different version 3.7 than that in driver 3.6, PySpark cannot run with different minor versions.Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\r\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\r\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:153)\r\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:153)\r\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\r\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1893)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1881)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1880)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1880)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2114)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2063)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2052)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:153)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\r\n  File \"/opt/apps/ecm/service/spark/2.4.3-1.2.0/package/spark-2.4.3-1.2.0-bin-hadoop2.8/python/lib/pyspark.zip/pyspark/worker.py\", line 267, in main\r\n    (\"%d.%d\" % sys.version_info[:2], version))\r\nException: Python in worker has different version 3.7 than that in driver 3.6, PySpark cannot run with different minor versions.Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\r\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\r\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:153)\r\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:153)\r\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\r\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n\r\n[2019-11-29 18:10:58 +0800] [28178] [INFO] Worker exiting (pid: 28178)\r\n[2019-11-29 18:10:58 +0800] [28169] [INFO] Shutting down: Master\r\n[2019-11-29 18:10:58 +0800] [28169] [INFO] Reason: Worker failed to boot.\r\nTraceback (most recent call last):\r\n  File \"/home/davidooi/.conda/envs/mlflow/bin/mlflow\", line 10, in <module>\r\n    sys.exit(cli())\r\n  File \"/home/davidooi/.local/lib/python3.7/site-packages/click/core.py\", line 764, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/home/davidooi/.local/lib/python3.7/site-packages/click/core.py\", line 717, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/home/davidooi/.local/lib/python3.7/site-packages/click/core.py\", line 1137, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"/home/davidooi/.local/lib/python3.7/site-packages/click/core.py\", line 1137, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"/home/davidooi/.local/lib/python3.7/site-packages/click/core.py\", line 956, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/home/davidooi/.local/lib/python3.7/site-packages/click/core.py\", line 555, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"/home/davidooi/.conda/envs/mlflow/lib/python3.7/site-packages/mlflow/models/cli.py\", line 56, in serve\r\n    host=host)\r\n  File \"/home/davidooi/.conda/envs/mlflow/lib/python3.7/site-packages/mlflow/pyfunc/backend.py\", line 84, in serve\r\n    command_env=command_env)\r\n  File \"/home/davidooi/.conda/envs/mlflow/lib/python3.7/site-packages/mlflow/pyfunc/backend.py\", line 164, in _execute_in_conda_env\r\n    command, rc\r\nException: Command 'source /opt/anaconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-9ebeece9d3ad59af4a788f4ffa82db1db63f7d99 1>&2 && gunicorn --timeout=60 -b 127.0.0.1:5002 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app' returned non zero return code. Return code = 3\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/559745348/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"y-tee","id":26523874,"node_id":"MDQ6VXNlcjI2NTIzODc0","avatar_url":"https://avatars.githubusercontent.com/u/26523874?v=4","gravatar_id":"","url":"https://api.github.com/users/y-tee","html_url":"https://github.com/y-tee","followers_url":"https://api.github.com/users/y-tee/followers","following_url":"https://api.github.com/users/y-tee/following{/other_user}","gists_url":"https://api.github.com/users/y-tee/gists{/gist_id}","starred_url":"https://api.github.com/users/y-tee/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/y-tee/subscriptions","organizations_url":"https://api.github.com/users/y-tee/orgs","repos_url":"https://api.github.com/users/y-tee/repos","events_url":"https://api.github.com/users/y-tee/events{/privacy}","received_events_url":"https://api.github.com/users/y-tee/received_events","type":"User","site_admin":false}},{"id":3009850462,"node_id":"MDE1OlJlZmVyZW5jZWRFdmVudDMwMDk4NTA0NjI=","url":"https://api.github.com/repos/mlflow/mlflow/issues/events/3009850462","actor":{"login":"jdlesage","id":658597,"node_id":"MDQ6VXNlcjY1ODU5Nw==","avatar_url":"https://avatars.githubusercontent.com/u/658597?v=4","gravatar_id":"","url":"https://api.github.com/users/jdlesage","html_url":"https://github.com/jdlesage","followers_url":"https://api.github.com/users/jdlesage/followers","following_url":"https://api.github.com/users/jdlesage/following{/other_user}","gists_url":"https://api.github.com/users/jdlesage/gists{/gist_id}","starred_url":"https://api.github.com/users/jdlesage/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jdlesage/subscriptions","organizations_url":"https://api.github.com/users/jdlesage/orgs","repos_url":"https://api.github.com/users/jdlesage/repos","events_url":"https://api.github.com/users/jdlesage/events{/privacy}","received_events_url":"https://api.github.com/users/jdlesage/received_events","type":"User","site_admin":false},"event":"referenced","commit_id":"ea8fc4ccdd78c34237e681613133e13de30593b7","commit_url":"https://api.github.com/repos/jdlesage/mlflow/commits/ea8fc4ccdd78c34237e681613133e13de30593b7","created_at":"2020-02-05T12:46:41Z","performed_via_github_app":null},{"id":6740881121,"node_id":"REFE_lADOCB5Jx84UFYfPzwAAAAGRya7h","url":"https://api.github.com/repos/mlflow/mlflow/issues/events/6740881121","actor":{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https://avatars.githubusercontent.com/u/39497902?v=4","gravatar_id":"","url":"https://api.github.com/users/dbczumar","html_url":"https://github.com/dbczumar","followers_url":"https://api.github.com/users/dbczumar/followers","following_url":"https://api.github.com/users/dbczumar/following{/other_user}","gists_url":"https://api.github.com/users/dbczumar/gists{/gist_id}","starred_url":"https://api.github.com/users/dbczumar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbczumar/subscriptions","organizations_url":"https://api.github.com/users/dbczumar/orgs","repos_url":"https://api.github.com/users/dbczumar/repos","events_url":"https://api.github.com/users/dbczumar/events{/privacy}","received_events_url":"https://api.github.com/users/dbczumar/received_events","type":"User","site_admin":false},"event":"referenced","commit_id":"73ab453d5e42bdec22723db3525d106c374f4b40","commit_url":"https://api.github.com/repos/dbczumar/mlflow/commits/73ab453d5e42bdec22723db3525d106c374f4b40","created_at":"2022-06-04T03:08:38Z","performed_via_github_app":null}]