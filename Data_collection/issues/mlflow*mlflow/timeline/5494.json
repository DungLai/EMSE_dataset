[{"id":6246510897,"node_id":"LE_lADOCB5Jx85FwP63zwAAAAF0UjEx","url":"https://api.github.com/repos/mlflow/mlflow/issues/events/6246510897","actor":{"login":"karinapatel","id":33239035,"node_id":"MDQ6VXNlcjMzMjM5MDM1","avatar_url":"https://avatars.githubusercontent.com/u/33239035?v=4","gravatar_id":"","url":"https://api.github.com/users/karinapatel","html_url":"https://github.com/karinapatel","followers_url":"https://api.github.com/users/karinapatel/followers","following_url":"https://api.github.com/users/karinapatel/following{/other_user}","gists_url":"https://api.github.com/users/karinapatel/gists{/gist_id}","starred_url":"https://api.github.com/users/karinapatel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/karinapatel/subscriptions","organizations_url":"https://api.github.com/users/karinapatel/orgs","repos_url":"https://api.github.com/users/karinapatel/repos","events_url":"https://api.github.com/users/karinapatel/events{/privacy}","received_events_url":"https://api.github.com/users/karinapatel/received_events","type":"User","site_admin":false},"event":"labeled","commit_id":null,"commit_url":null,"created_at":"2022-03-15T21:15:14Z","label":{"name":"bug","color":"d73a4a"},"performed_via_github_app":null},{"id":6246512018,"node_id":"LE_lADOCB5Jx85FwP63zwAAAAF0UjWS","url":"https://api.github.com/repos/mlflow/mlflow/issues/events/6246512018","actor":{"login":"github-actions[bot]","id":41898282,"node_id":"MDM6Qm90NDE4OTgyODI=","avatar_url":"https://avatars.githubusercontent.com/in/15368?v=4","gravatar_id":"","url":"https://api.github.com/users/github-actions%5Bbot%5D","html_url":"https://github.com/apps/github-actions","followers_url":"https://api.github.com/users/github-actions%5Bbot%5D/followers","following_url":"https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}","gists_url":"https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}","starred_url":"https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/github-actions%5Bbot%5D/subscriptions","organizations_url":"https://api.github.com/users/github-actions%5Bbot%5D/orgs","repos_url":"https://api.github.com/users/github-actions%5Bbot%5D/repos","events_url":"https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}","received_events_url":"https://api.github.com/users/github-actions%5Bbot%5D/received_events","type":"Bot","site_admin":false},"event":"labeled","commit_id":null,"commit_url":null,"created_at":"2022-03-15T21:15:26Z","label":{"name":"area/docs","color":"48eabc"},"performed_via_github_app":null},{"id":6246512023,"node_id":"LE_lADOCB5Jx85FwP63zwAAAAF0UjWX","url":"https://api.github.com/repos/mlflow/mlflow/issues/events/6246512023","actor":{"login":"github-actions[bot]","id":41898282,"node_id":"MDM6Qm90NDE4OTgyODI=","avatar_url":"https://avatars.githubusercontent.com/in/15368?v=4","gravatar_id":"","url":"https://api.github.com/users/github-actions%5Bbot%5D","html_url":"https://github.com/apps/github-actions","followers_url":"https://api.github.com/users/github-actions%5Bbot%5D/followers","following_url":"https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}","gists_url":"https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}","starred_url":"https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/github-actions%5Bbot%5D/subscriptions","organizations_url":"https://api.github.com/users/github-actions%5Bbot%5D/orgs","repos_url":"https://api.github.com/users/github-actions%5Bbot%5D/repos","events_url":"https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}","received_events_url":"https://api.github.com/users/github-actions%5Bbot%5D/received_events","type":"Bot","site_admin":false},"event":"labeled","commit_id":null,"commit_url":null,"created_at":"2022-03-15T21:15:26Z","label":{"name":"area/models","color":"48eabc"},"performed_via_github_app":null},{"id":6246512026,"node_id":"LE_lADOCB5Jx85FwP63zwAAAAF0UjWa","url":"https://api.github.com/repos/mlflow/mlflow/issues/events/6246512026","actor":{"login":"github-actions[bot]","id":41898282,"node_id":"MDM6Qm90NDE4OTgyODI=","avatar_url":"https://avatars.githubusercontent.com/in/15368?v=4","gravatar_id":"","url":"https://api.github.com/users/github-actions%5Bbot%5D","html_url":"https://github.com/apps/github-actions","followers_url":"https://api.github.com/users/github-actions%5Bbot%5D/followers","following_url":"https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}","gists_url":"https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}","starred_url":"https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/github-actions%5Bbot%5D/subscriptions","organizations_url":"https://api.github.com/users/github-actions%5Bbot%5D/orgs","repos_url":"https://api.github.com/users/github-actions%5Bbot%5D/repos","events_url":"https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}","received_events_url":"https://api.github.com/users/github-actions%5Bbot%5D/received_events","type":"Bot","site_admin":false},"event":"labeled","commit_id":null,"commit_url":null,"created_at":"2022-03-15T21:15:26Z","label":{"name":"area/scoring","color":"48eabc"},"performed_via_github_app":null},{"id":6246512028,"node_id":"LE_lADOCB5Jx85FwP63zwAAAAF0UjWc","url":"https://api.github.com/repos/mlflow/mlflow/issues/events/6246512028","actor":{"login":"github-actions[bot]","id":41898282,"node_id":"MDM6Qm90NDE4OTgyODI=","avatar_url":"https://avatars.githubusercontent.com/in/15368?v=4","gravatar_id":"","url":"https://api.github.com/users/github-actions%5Bbot%5D","html_url":"https://github.com/apps/github-actions","followers_url":"https://api.github.com/users/github-actions%5Bbot%5D/followers","following_url":"https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}","gists_url":"https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}","starred_url":"https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/github-actions%5Bbot%5D/subscriptions","organizations_url":"https://api.github.com/users/github-actions%5Bbot%5D/orgs","repos_url":"https://api.github.com/users/github-actions%5Bbot%5D/repos","events_url":"https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}","received_events_url":"https://api.github.com/users/github-actions%5Bbot%5D/received_events","type":"Bot","site_admin":false},"event":"labeled","commit_id":null,"commit_url":null,"created_at":"2022-03-15T21:15:26Z","label":{"name":"integrations/databricks","color":"ffbce5"},"performed_via_github_app":null},{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/1068714861","html_url":"https://github.com/mlflow/mlflow/issues/5494#issuecomment-1068714861","issue_url":"https://api.github.com/repos/mlflow/mlflow/issues/5494","id":1068714861,"node_id":"IC_kwDOCB5Jx84_s0tt","user":{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https://avatars.githubusercontent.com/u/39497902?v=4","gravatar_id":"","url":"https://api.github.com/users/dbczumar","html_url":"https://github.com/dbczumar","followers_url":"https://api.github.com/users/dbczumar/followers","following_url":"https://api.github.com/users/dbczumar/following{/other_user}","gists_url":"https://api.github.com/users/dbczumar/gists{/gist_id}","starred_url":"https://api.github.com/users/dbczumar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbczumar/subscriptions","organizations_url":"https://api.github.com/users/dbczumar/orgs","repos_url":"https://api.github.com/users/dbczumar/repos","events_url":"https://api.github.com/users/dbczumar/events{/privacy}","received_events_url":"https://api.github.com/users/dbczumar/received_events","type":"User","site_admin":false},"created_at":"2022-03-16T04:17:43Z","updated_at":"2022-03-16T04:17:43Z","author_association":"COLLABORATOR","body":"@WeichenXu123 Can you comment here?","reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/1068714861/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https://avatars.githubusercontent.com/u/39497902?v=4","gravatar_id":"","url":"https://api.github.com/users/dbczumar","html_url":"https://github.com/dbczumar","followers_url":"https://api.github.com/users/dbczumar/followers","following_url":"https://api.github.com/users/dbczumar/following{/other_user}","gists_url":"https://api.github.com/users/dbczumar/gists{/gist_id}","starred_url":"https://api.github.com/users/dbczumar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbczumar/subscriptions","organizations_url":"https://api.github.com/users/dbczumar/orgs","repos_url":"https://api.github.com/users/dbczumar/repos","events_url":"https://api.github.com/users/dbczumar/events{/privacy}","received_events_url":"https://api.github.com/users/dbczumar/received_events","type":"User","site_admin":false}},{"id":6247904970,"node_id":"MEE_lADOCB5Jx85FwP63zwAAAAF0Z3bK","url":"https://api.github.com/repos/mlflow/mlflow/issues/events/6247904970","actor":{"login":"WeichenXu123","id":19235986,"node_id":"MDQ6VXNlcjE5MjM1OTg2","avatar_url":"https://avatars.githubusercontent.com/u/19235986?v=4","gravatar_id":"","url":"https://api.github.com/users/WeichenXu123","html_url":"https://github.com/WeichenXu123","followers_url":"https://api.github.com/users/WeichenXu123/followers","following_url":"https://api.github.com/users/WeichenXu123/following{/other_user}","gists_url":"https://api.github.com/users/WeichenXu123/gists{/gist_id}","starred_url":"https://api.github.com/users/WeichenXu123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/WeichenXu123/subscriptions","organizations_url":"https://api.github.com/users/WeichenXu123/orgs","repos_url":"https://api.github.com/users/WeichenXu123/repos","events_url":"https://api.github.com/users/WeichenXu123/events{/privacy}","received_events_url":"https://api.github.com/users/WeichenXu123/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2022-03-16T04:17:43Z","performed_via_github_app":null},{"id":6247904975,"node_id":"SE_lADOCB5Jx85FwP63zwAAAAF0Z3bP","url":"https://api.github.com/repos/mlflow/mlflow/issues/events/6247904975","actor":{"login":"WeichenXu123","id":19235986,"node_id":"MDQ6VXNlcjE5MjM1OTg2","avatar_url":"https://avatars.githubusercontent.com/u/19235986?v=4","gravatar_id":"","url":"https://api.github.com/users/WeichenXu123","html_url":"https://github.com/WeichenXu123","followers_url":"https://api.github.com/users/WeichenXu123/followers","following_url":"https://api.github.com/users/WeichenXu123/following{/other_user}","gists_url":"https://api.github.com/users/WeichenXu123/gists{/gist_id}","starred_url":"https://api.github.com/users/WeichenXu123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/WeichenXu123/subscriptions","organizations_url":"https://api.github.com/users/WeichenXu123/orgs","repos_url":"https://api.github.com/users/WeichenXu123/repos","events_url":"https://api.github.com/users/WeichenXu123/events{/privacy}","received_events_url":"https://api.github.com/users/WeichenXu123/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2022-03-16T04:17:43Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/1077621614","html_url":"https://github.com/mlflow/mlflow/issues/5494#issuecomment-1077621614","issue_url":"https://api.github.com/repos/mlflow/mlflow/issues/5494","id":1077621614,"node_id":"IC_kwDOCB5Jx85AOzNu","user":{"login":"WeichenXu123","id":19235986,"node_id":"MDQ6VXNlcjE5MjM1OTg2","avatar_url":"https://avatars.githubusercontent.com/u/19235986?v=4","gravatar_id":"","url":"https://api.github.com/users/WeichenXu123","html_url":"https://github.com/WeichenXu123","followers_url":"https://api.github.com/users/WeichenXu123/followers","following_url":"https://api.github.com/users/WeichenXu123/following{/other_user}","gists_url":"https://api.github.com/users/WeichenXu123/gists{/gist_id}","starred_url":"https://api.github.com/users/WeichenXu123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/WeichenXu123/subscriptions","organizations_url":"https://api.github.com/users/WeichenXu123/orgs","repos_url":"https://api.github.com/users/WeichenXu123/repos","events_url":"https://api.github.com/users/WeichenXu123/events{/privacy}","received_events_url":"https://api.github.com/users/WeichenXu123/received_events","type":"User","site_admin":false},"created_at":"2022-03-24T13:21:21Z","updated_at":"2022-03-24T13:29:59Z","author_association":"COLLABORATOR","body":"I am checking... ","reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/1077621614/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"WeichenXu123","id":19235986,"node_id":"MDQ6VXNlcjE5MjM1OTg2","avatar_url":"https://avatars.githubusercontent.com/u/19235986?v=4","gravatar_id":"","url":"https://api.github.com/users/WeichenXu123","html_url":"https://github.com/WeichenXu123","followers_url":"https://api.github.com/users/WeichenXu123/followers","following_url":"https://api.github.com/users/WeichenXu123/following{/other_user}","gists_url":"https://api.github.com/users/WeichenXu123/gists{/gist_id}","starred_url":"https://api.github.com/users/WeichenXu123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/WeichenXu123/subscriptions","organizations_url":"https://api.github.com/users/WeichenXu123/orgs","repos_url":"https://api.github.com/users/WeichenXu123/repos","events_url":"https://api.github.com/users/WeichenXu123/events{/privacy}","received_events_url":"https://api.github.com/users/WeichenXu123/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/1077639120","html_url":"https://github.com/mlflow/mlflow/issues/5494#issuecomment-1077639120","issue_url":"https://api.github.com/repos/mlflow/mlflow/issues/5494","id":1077639120,"node_id":"IC_kwDOCB5Jx85AO3fQ","user":{"login":"WeichenXu123","id":19235986,"node_id":"MDQ6VXNlcjE5MjM1OTg2","avatar_url":"https://avatars.githubusercontent.com/u/19235986?v=4","gravatar_id":"","url":"https://api.github.com/users/WeichenXu123","html_url":"https://github.com/WeichenXu123","followers_url":"https://api.github.com/users/WeichenXu123/followers","following_url":"https://api.github.com/users/WeichenXu123/following{/other_user}","gists_url":"https://api.github.com/users/WeichenXu123/gists{/gist_id}","starred_url":"https://api.github.com/users/WeichenXu123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/WeichenXu123/subscriptions","organizations_url":"https://api.github.com/users/WeichenXu123/orgs","repos_url":"https://api.github.com/users/WeichenXu123/repos","events_url":"https://api.github.com/users/WeichenXu123/events{/privacy}","received_events_url":"https://api.github.com/users/WeichenXu123/received_events","type":"User","site_admin":false},"created_at":"2022-03-24T13:39:04Z","updated_at":"2022-03-27T12:03:22Z","author_association":"COLLABORATOR","body":"I think current mlflow tensorflow serving code cannot support your case:\r\nhttps://github.com/mlflow/mlflow/blob/82d402173880991f0139b5f0268e4d28c7672645/mlflow/tensorflow/__init__.py#L515\r\n\r\nIf the input column is an array type, here it will feed a pandas series instance contains multiple numpy array objects,\r\nbut the `tensorflow.constant` requires an 2D numpy array (last dim = 4) in your case, so it fails.\r\n\r\nCurrent mlflow tensorflow serving code looks naive , it seems only works fine with scalar type column column as input ?","reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/1077639120/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"WeichenXu123","id":19235986,"node_id":"MDQ6VXNlcjE5MjM1OTg2","avatar_url":"https://avatars.githubusercontent.com/u/19235986?v=4","gravatar_id":"","url":"https://api.github.com/users/WeichenXu123","html_url":"https://github.com/WeichenXu123","followers_url":"https://api.github.com/users/WeichenXu123/followers","following_url":"https://api.github.com/users/WeichenXu123/following{/other_user}","gists_url":"https://api.github.com/users/WeichenXu123/gists{/gist_id}","starred_url":"https://api.github.com/users/WeichenXu123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/WeichenXu123/subscriptions","organizations_url":"https://api.github.com/users/WeichenXu123/orgs","repos_url":"https://api.github.com/users/WeichenXu123/repos","events_url":"https://api.github.com/users/WeichenXu123/events{/privacy}","received_events_url":"https://api.github.com/users/WeichenXu123/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/1080661633","html_url":"https://github.com/mlflow/mlflow/issues/5494#issuecomment-1080661633","issue_url":"https://api.github.com/repos/mlflow/mlflow/issues/5494","id":1080661633,"node_id":"IC_kwDOCB5Jx85AaZaB","user":{"login":"WeichenXu123","id":19235986,"node_id":"MDQ6VXNlcjE5MjM1OTg2","avatar_url":"https://avatars.githubusercontent.com/u/19235986?v=4","gravatar_id":"","url":"https://api.github.com/users/WeichenXu123","html_url":"https://github.com/WeichenXu123","followers_url":"https://api.github.com/users/WeichenXu123/followers","following_url":"https://api.github.com/users/WeichenXu123/following{/other_user}","gists_url":"https://api.github.com/users/WeichenXu123/gists{/gist_id}","starred_url":"https://api.github.com/users/WeichenXu123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/WeichenXu123/subscriptions","organizations_url":"https://api.github.com/users/WeichenXu123/orgs","repos_url":"https://api.github.com/users/WeichenXu123/repos","events_url":"https://api.github.com/users/WeichenXu123/events{/privacy}","received_events_url":"https://api.github.com/users/WeichenXu123/received_events","type":"User","site_admin":false},"created_at":"2022-03-28T13:37:04Z","updated_at":"2022-03-28T13:37:04Z","author_association":"COLLABORATOR","body":"@karinapatel \r\nI create a draft fix branch:\r\nYou can use this branch:\r\n```\r\n%pip install git+https://github.com/WeichenXu123/mlflow.git@tf-model-support-array\r\n```\r\nas a workaround.\r\n\r\nNote there's another issue: tensorflow autolog does not log signature. So the \"feed_dict\" key \"DATA\" mismatch with the UDF feed key name \"0\" (when no signature provided the key is generated like '0', '1', ...)\r\n\r\nSo your code  you need change another place:\r\n```\r\nclass FlatServingInputReceiver(object):\r\n    \"\"\"\r\n    Define a class to use when creating input receiver function\r\n    The input received function will be sent to the tfInputGraph to create a TFTransformer object\r\n    \"\"\"\r\n    def __init__(self, feature):\r\n        self.features = feature\r\n        self.receiver_tensors = {'0': feature}   # change 'DATA' to be '0'\r\n```","reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/1080661633/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"WeichenXu123","id":19235986,"node_id":"MDQ6VXNlcjE5MjM1OTg2","avatar_url":"https://avatars.githubusercontent.com/u/19235986?v=4","gravatar_id":"","url":"https://api.github.com/users/WeichenXu123","html_url":"https://github.com/WeichenXu123","followers_url":"https://api.github.com/users/WeichenXu123/followers","following_url":"https://api.github.com/users/WeichenXu123/following{/other_user}","gists_url":"https://api.github.com/users/WeichenXu123/gists{/gist_id}","starred_url":"https://api.github.com/users/WeichenXu123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/WeichenXu123/subscriptions","organizations_url":"https://api.github.com/users/WeichenXu123/orgs","repos_url":"https://api.github.com/users/WeichenXu123/repos","events_url":"https://api.github.com/users/WeichenXu123/events{/privacy}","received_events_url":"https://api.github.com/users/WeichenXu123/received_events","type":"User","site_admin":false}},{"id":6318608791,"node_id":"MEE_lADOCB5Jx85FwP63zwAAAAF4nlGX","url":"https://api.github.com/repos/mlflow/mlflow/issues/events/6318608791","actor":{"login":"karinapatel","id":33239035,"node_id":"MDQ6VXNlcjMzMjM5MDM1","avatar_url":"https://avatars.githubusercontent.com/u/33239035?v=4","gravatar_id":"","url":"https://api.github.com/users/karinapatel","html_url":"https://github.com/karinapatel","followers_url":"https://api.github.com/users/karinapatel/followers","following_url":"https://api.github.com/users/karinapatel/following{/other_user}","gists_url":"https://api.github.com/users/karinapatel/gists{/gist_id}","starred_url":"https://api.github.com/users/karinapatel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/karinapatel/subscriptions","organizations_url":"https://api.github.com/users/karinapatel/orgs","repos_url":"https://api.github.com/users/karinapatel/repos","events_url":"https://api.github.com/users/karinapatel/events{/privacy}","received_events_url":"https://api.github.com/users/karinapatel/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2022-03-28T13:37:05Z","performed_via_github_app":null},{"id":6318608801,"node_id":"SE_lADOCB5Jx85FwP63zwAAAAF4nlGh","url":"https://api.github.com/repos/mlflow/mlflow/issues/events/6318608801","actor":{"login":"karinapatel","id":33239035,"node_id":"MDQ6VXNlcjMzMjM5MDM1","avatar_url":"https://avatars.githubusercontent.com/u/33239035?v=4","gravatar_id":"","url":"https://api.github.com/users/karinapatel","html_url":"https://github.com/karinapatel","followers_url":"https://api.github.com/users/karinapatel/followers","following_url":"https://api.github.com/users/karinapatel/following{/other_user}","gists_url":"https://api.github.com/users/karinapatel/gists{/gist_id}","starred_url":"https://api.github.com/users/karinapatel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/karinapatel/subscriptions","organizations_url":"https://api.github.com/users/karinapatel/orgs","repos_url":"https://api.github.com/users/karinapatel/repos","events_url":"https://api.github.com/users/karinapatel/events{/privacy}","received_events_url":"https://api.github.com/users/karinapatel/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2022-03-28T13:37:05Z","performed_via_github_app":null},{"id":6332065211,"node_id":"CE_lADOCB5Jx85FwP63zwAAAAF5a6W7","url":"https://api.github.com/repos/mlflow/mlflow/issues/events/6332065211","actor":{"login":"WeichenXu123","id":19235986,"node_id":"MDQ6VXNlcjE5MjM1OTg2","avatar_url":"https://avatars.githubusercontent.com/u/19235986?v=4","gravatar_id":"","url":"https://api.github.com/users/WeichenXu123","html_url":"https://github.com/WeichenXu123","followers_url":"https://api.github.com/users/WeichenXu123/followers","following_url":"https://api.github.com/users/WeichenXu123/following{/other_user}","gists_url":"https://api.github.com/users/WeichenXu123/gists{/gist_id}","starred_url":"https://api.github.com/users/WeichenXu123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/WeichenXu123/subscriptions","organizations_url":"https://api.github.com/users/WeichenXu123/orgs","repos_url":"https://api.github.com/users/WeichenXu123/repos","events_url":"https://api.github.com/users/WeichenXu123/events{/privacy}","received_events_url":"https://api.github.com/users/WeichenXu123/received_events","type":"User","site_admin":false},"event":"closed","commit_id":null,"commit_url":null,"created_at":"2022-03-30T05:55:41Z","state_reason":null,"performed_via_github_app":null},{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/1090504344","html_url":"https://github.com/mlflow/mlflow/issues/5494#issuecomment-1090504344","issue_url":"https://api.github.com/repos/mlflow/mlflow/issues/5494","id":1090504344,"node_id":"IC_kwDOCB5Jx85A_8aY","user":{"login":"karinapatel","id":33239035,"node_id":"MDQ6VXNlcjMzMjM5MDM1","avatar_url":"https://avatars.githubusercontent.com/u/33239035?v=4","gravatar_id":"","url":"https://api.github.com/users/karinapatel","html_url":"https://github.com/karinapatel","followers_url":"https://api.github.com/users/karinapatel/followers","following_url":"https://api.github.com/users/karinapatel/following{/other_user}","gists_url":"https://api.github.com/users/karinapatel/gists{/gist_id}","starred_url":"https://api.github.com/users/karinapatel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/karinapatel/subscriptions","organizations_url":"https://api.github.com/users/karinapatel/orgs","repos_url":"https://api.github.com/users/karinapatel/repos","events_url":"https://api.github.com/users/karinapatel/events{/privacy}","received_events_url":"https://api.github.com/users/karinapatel/received_events","type":"User","site_admin":false},"created_at":"2022-04-06T17:09:06Z","updated_at":"2022-04-06T17:09:06Z","author_association":"NONE","body":"Hi @WeichenXu123 \r\nThanks for your help -- I have tested this code and have confirmed it resolves the numpy to tensor conversion. I encountered a follow up bug using this mlflow fix branch + TF 2 code (no longer using estimators as they are not supported by TF). I have created a simple example using TF keras that is almost identical to the example in TF documentation but have encountered a bug when creating the spark udf for inference. Could you help me resolve this? I am using the mlflow master code now that the numpy to tensor conversion has been merged there. I am attaching the code below but let me know since it is a follow up to this bug request, but am happy to create a separate request if that is preferred. Thanks!","reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/1090504344/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"karinapatel","id":33239035,"node_id":"MDQ6VXNlcjMzMjM5MDM1","avatar_url":"https://avatars.githubusercontent.com/u/33239035?v=4","gravatar_id":"","url":"https://api.github.com/users/karinapatel","html_url":"https://github.com/karinapatel","followers_url":"https://api.github.com/users/karinapatel/followers","following_url":"https://api.github.com/users/karinapatel/following{/other_user}","gists_url":"https://api.github.com/users/karinapatel/gists{/gist_id}","starred_url":"https://api.github.com/users/karinapatel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/karinapatel/subscriptions","organizations_url":"https://api.github.com/users/karinapatel/orgs","repos_url":"https://api.github.com/users/karinapatel/repos","events_url":"https://api.github.com/users/karinapatel/events{/privacy}","received_events_url":"https://api.github.com/users/karinapatel/received_events","type":"User","site_admin":false}},{"id":6381855259,"node_id":"MEE_lADOCB5Jx85FwP63zwAAAAF8Y2Ib","url":"https://api.github.com/repos/mlflow/mlflow/issues/events/6381855259","actor":{"login":"WeichenXu123","id":19235986,"node_id":"MDQ6VXNlcjE5MjM1OTg2","avatar_url":"https://avatars.githubusercontent.com/u/19235986?v=4","gravatar_id":"","url":"https://api.github.com/users/WeichenXu123","html_url":"https://github.com/WeichenXu123","followers_url":"https://api.github.com/users/WeichenXu123/followers","following_url":"https://api.github.com/users/WeichenXu123/following{/other_user}","gists_url":"https://api.github.com/users/WeichenXu123/gists{/gist_id}","starred_url":"https://api.github.com/users/WeichenXu123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/WeichenXu123/subscriptions","organizations_url":"https://api.github.com/users/WeichenXu123/orgs","repos_url":"https://api.github.com/users/WeichenXu123/repos","events_url":"https://api.github.com/users/WeichenXu123/events{/privacy}","received_events_url":"https://api.github.com/users/WeichenXu123/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2022-04-06T17:09:06Z","performed_via_github_app":null},{"id":6381855267,"node_id":"SE_lADOCB5Jx85FwP63zwAAAAF8Y2Ij","url":"https://api.github.com/repos/mlflow/mlflow/issues/events/6381855267","actor":{"login":"WeichenXu123","id":19235986,"node_id":"MDQ6VXNlcjE5MjM1OTg2","avatar_url":"https://avatars.githubusercontent.com/u/19235986?v=4","gravatar_id":"","url":"https://api.github.com/users/WeichenXu123","html_url":"https://github.com/WeichenXu123","followers_url":"https://api.github.com/users/WeichenXu123/followers","following_url":"https://api.github.com/users/WeichenXu123/following{/other_user}","gists_url":"https://api.github.com/users/WeichenXu123/gists{/gist_id}","starred_url":"https://api.github.com/users/WeichenXu123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/WeichenXu123/subscriptions","organizations_url":"https://api.github.com/users/WeichenXu123/orgs","repos_url":"https://api.github.com/users/WeichenXu123/repos","events_url":"https://api.github.com/users/WeichenXu123/events{/privacy}","received_events_url":"https://api.github.com/users/WeichenXu123/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2022-04-06T17:09:07Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/1090509182","html_url":"https://github.com/mlflow/mlflow/issues/5494#issuecomment-1090509182","issue_url":"https://api.github.com/repos/mlflow/mlflow/issues/5494","id":1090509182,"node_id":"IC_kwDOCB5Jx85A_9l-","user":{"login":"karinapatel","id":33239035,"node_id":"MDQ6VXNlcjMzMjM5MDM1","avatar_url":"https://avatars.githubusercontent.com/u/33239035?v=4","gravatar_id":"","url":"https://api.github.com/users/karinapatel","html_url":"https://github.com/karinapatel","followers_url":"https://api.github.com/users/karinapatel/followers","following_url":"https://api.github.com/users/karinapatel/following{/other_user}","gists_url":"https://api.github.com/users/karinapatel/gists{/gist_id}","starred_url":"https://api.github.com/users/karinapatel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/karinapatel/subscriptions","organizations_url":"https://api.github.com/users/karinapatel/orgs","repos_url":"https://api.github.com/users/karinapatel/repos","events_url":"https://api.github.com/users/karinapatel/events{/privacy}","received_events_url":"https://api.github.com/users/karinapatel/received_events","type":"User","site_admin":false},"created_at":"2022-04-06T17:13:11Z","updated_at":"2022-04-06T17:17:36Z","author_association":"NONE","body":"```\r\n%pip install git+https://github.com/mlflow/mlflow.git@master\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\r\nfrom tensorflow.keras import Model\r\nfrom pyspark.sql import functions as F\r\nfrom pyspark.sql.types import *\r\nimport fnmatch\r\nimport os\r\nimport mlflow\r\nmlflow.tensorflow.autolog()\r\n\r\ndef load_data():\r\n  mnist = tf.keras.datasets.mnist\r\n\r\n  (x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n  \r\n  x_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\n  # Add a channels dimension\r\n  x_train = x_train[..., tf.newaxis].astype(\"float32\")\r\n  x_test = x_test[..., tf.newaxis].astype(\"float32\")\r\n  train_ds = create_spark_df(x_train,y_train)\r\n  test_ds = create_spark_df(x_test,y_test)\r\n\r\n  return train_ds, test_ds\r\n\r\ndef create_spark_df(x, y):\r\n\r\n  data = {\"DATA\": list(np.reshape(np.squeeze(x),(-1,28*28))), \"label\": list(y)}\r\n  df = pd.DataFrame(data, columns=['DATA', 'label'])\r\n  df_spark = spark.createDataFrame(df)\r\n  df_spark = df_spark.withColumn('label', F.col('label').cast(FloatType()))\r\n  return df_spark\r\n\r\ndef write_data(training_data):\r\n  train_location = '/dbfs/ml/train_tf_data/'\r\n  test_location ='/dbfs/ml/test_tf_data/'\r\n  # split training_data into train and test\r\n  train, test = training_data.randomSplit([.9, .1], seed = 123)\r\n\r\n  # write training\r\n  train.repartition(1).write.format(\"tfrecords\").option(\"recordType\", \"Example\").mode(\"overwrite\").save('file:' + train_location)\r\n  # write testing\r\n  test.repartition(1).write.format(\"tfrecords\").option(\"recordType\", \"Example\").mode(\"overwrite\").save('file:' + test_location)\r\n\r\ndef _decode(serialized_example):\r\n    \"\"\"\r\n    Parses the CONCAT_MESSAGE_REPR from the given `serialized_example`.\r\n    :param serialized_example: Raw TFRecordDataset data\r\n    :param fixed_num_message: size of CONCAT_MESSAGE_REPR to be used when parsing the data\r\n    :return CONCAT_MESSAGE_REPR: Parsed data column\r\n    \"\"\"\r\n    # calculate the length of CONCAT_MESSAGE_REPR from fixed_num_message param\r\n    # define a parser\r\n    features = tf.io.parse_single_example(serialized_example,\r\n                                    features={'DATA': tf.io.FixedLenFeature([28*28], tf.float32),\r\n                                             'label': tf.io.FixedLenFeature(1, tf.float32)})\r\n\r\n    # convert the data to correct type\r\n    DATA = tf.cast(features['DATA'], tf.float32)\r\n    labels = tf.cast(features['label'], tf.float32)\r\n\r\n    return DATA, labels\r\n  \r\ndef _train_input_fn(batch_size, shuffle_count=256, repeat_count=30):\r\n    \"\"\"\r\n    Input function used to read the TFRecord from a temp location, decode (parse the serialized example), and finally output a batch of data for training\r\n    :param batch size: int\r\n    :param shuffle_count: int, number of times to shuffle data\r\n    :return dataset: batch of data for training of size equivalent to batch_size\r\n    \"\"\"            \r\n    #location of all partitions of train subset data\r\n    train_location = '/dbfs/ml/train_tf_data/'\r\n    train_files = [os.path.join(train_location, item) for item in fnmatch.filter(os.listdir(train_location), 'part*')]\r\n    raw_train_dataset = tf.data.TFRecordDataset(train_files)\r\n\r\n    #parse the serialized raw_train_dataset as CONCAT_MESSAGE_REPR column\r\n    dataset = raw_train_dataset.map(_decode)\r\n    assert batch_size is not None, \"batch_size must not be None\"\r\n\r\n    #shuffle the data and return a batch of data for training corresponding to the given batch_size\r\n    dataset = dataset.shuffle(shuffle_count).batch(batch_size)\r\n    return dataset\r\n\r\n  \r\ndef _eval_input_fn():\r\n    \"\"\"\r\n    Input function used to read the TFRecord from a temp location, decode (parse the serialized example), and finally output the data for evaluation\r\n    :return dataset: data for model evaluation\r\n    \"\"\"\r\n    test_location ='/dbfs/ml/test_tf_data/'\r\n    #location of all partitions of eval subset data    \r\n    test_files = [os.path.join(test_location, item) for item in fnmatch.filter(os.listdir(test_location), 'part*')]\r\n    raw_test_dataset = tf.data.TFRecordDataset(test_files)\r\n    #parse the serialized raw_train_dataset as CONCAT_MESSAGE_REPR column\r\n    dataset = raw_test_dataset.map(_decode)\r\n    return dataset\r\n  \r\nclass MyModel(Model):\r\n  def __init__(self):\r\n    super(MyModel, self).__init__()\r\n    self.conv1 = Conv2D(32, 3, activation='relu')\r\n    self.flatten = Flatten()\r\n    self.d1 = Dense(128, activation='relu')\r\n    self.d2 = Dense(10)\r\n    \r\n  def _hardcoded_embedding(self, message_repr):\r\n    \"\"\"\r\n    Helper function to format each recipient's history as distributions of non opened message send time, opened message send time, open time, and delay.\r\n    Concatenate these distributions (each 24 HOD).\r\n\r\n    :param message_repr: Tensor of shape [None, num_message, message_repr_size]\r\n    :return: Tensor of shape [None, 72]; hardcoded embedding of 3 concatenated distributions\r\n    \"\"\"\r\n    message_repr = tf.reshape(message_repr, shape=[-1, 28, 28])\r\n    hardcoded_emb = tf.expand_dims(message_repr, -1)\r\n\r\n    return hardcoded_emb\r\n  \r\n  def call(self, x):\r\n    x = self._hardcoded_embedding(x)\r\n    x = self.conv1(x)\r\n    x = self.flatten(x)\r\n    x = self.d1(x)\r\n    return self.d2(x)\r\n\r\n  \r\n@tf.function\r\ndef train_step(images, labels):\r\n  with tf.GradientTape() as tape:\r\n    # training=True is only needed if there are layers with different\r\n    # behavior during training versus inference (e.g. Dropout).\r\n    predictions = model(images, training=True)\r\n    loss = loss_object(labels, predictions)\r\n  gradients = tape.gradient(loss, model.trainable_variables)\r\n  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n\r\n  train_loss(loss)\r\n  train_accuracy(labels, predictions)\r\n  \r\n\r\n@tf.function\r\ndef test_step(images, labels):\r\n  # training=False is only needed if there are layers with different\r\n  # behavior during training versus inference (e.g. Dropout).\r\n  predictions = model(images, training=False)\r\n  t_loss = loss_object(labels, predictions)\r\n\r\n  test_loss(t_loss)\r\n  test_accuracy(labels, predictions)\r\n\r\n```\r\n\r\n\r\nUsing the above code, I then run the following lines to train and save the model:\r\n\r\n```\r\ntrain_ds, test_ds = load_data()\r\nwrite_data(train_ds)\r\n\r\n# Create an instance of the model\r\nmodel = MyModel()\r\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n\r\noptimizer = tf.keras.optimizers.Adam()\r\ntrain_loss = tf.keras.metrics.Mean(name='train_loss')\r\ntrain_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\r\n\r\ntest_loss = tf.keras.metrics.Mean(name='test_loss')\r\ntest_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\r\n\r\nmlflow.end_run()\r\nEPOCHS = 5\r\nwith mlflow.start_run():\r\n  for epoch in range(EPOCHS):\r\n    # Reset the metrics at the start of the next epoch\r\n    train_loss.reset_states()\r\n    train_accuracy.reset_states()\r\n    test_loss.reset_states()\r\n    test_accuracy.reset_states()\r\n\r\n    for images, labels in _train_input_fn(32):\r\n      train_step(images, labels)\r\n\r\n    for test_images, test_labels in _eval_input_fn():\r\n      test_step(test_images, test_labels)\r\n\r\n    print(\r\n      f'Epoch {epoch + 1}, '\r\n      f'Loss: {train_loss.result()}, '\r\n      f'Accuracy: {train_accuracy.result() * 100}, '\r\n      f'Test Loss: {test_loss.result()}, '\r\n      f'Test Accuracy: {test_accuracy.result() * 100}'\r\n    )\r\n    \r\ntf.saved_model.save(model, \"/tmp/test_simple_model/saved_model/\")\r\nmlflow_model_info = mlflow.tensorflow.log_model(tf_saved_model_dir=\"/tmp/test_simple_model/saved_model/\", tf_meta_graph_tags=['serve'],tf_signature_def_key=tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY, artifact_path='test_simple_model')\r\n\r\nmlflow_model_info.model_uri\r\nloaded_model =  mlflow.pyfunc.spark_udf(spark, model_uri=mlflow_model_info.model_uri, result_type='double')\r\n\r\ntest_training_data1 = train_ds.withColumn('scores', loaded_model('DATA'))\r\n\r\ndisplay(test_training_data1)\r\n\r\n```\r\n\r\nI encounter the following bug when calling display(test_training_data1: \r\n\r\n```\r\nPythonException: 'TypeError: signature_wrapper(input_1) missing required arguments: input_1'. Full traceback below:\r\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 55.0 failed 4 times, most recent failure: Lost task 0.3 in stage 55.0 (TID 2289, 10.139.64.14, executor 0): org.apache.spark.api.python.PythonException: 'TypeError: signature_wrapper(input_1) missing required arguments: input_1'. Full traceback below:\r\nTraceback (most recent call last):\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1700, in _call_with_flat_signature\r\n    args.append(kwargs.pop(compat.as_str(keyword)))\r\nKeyError: 'input_1'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/databricks/spark/python/pyspark/worker.py\", line 654, in main\r\n    process()\r\n  File \"/databricks/spark/python/pyspark/worker.py\", line 646, in process\r\n    serializer.dump_stream(out_iter, outfile)\r\n  File \"/databricks/spark/python/pyspark/sql/pandas/serializers.py\", line 281, in dump_stream\r\n    timely_flush_timeout_ms=self.timely_flush_timeout_ms)\r\n  File \"/databricks/spark/python/pyspark/sql/pandas/serializers.py\", line 97, in dump_stream\r\n    for batch in iterator:\r\n  File \"/databricks/spark/python/pyspark/sql/pandas/serializers.py\", line 271, in init_stream_yield_batches\r\n    for series in iterator:\r\n  File \"/databricks/spark/python/pyspark/worker.py\", line 376, in func\r\n    for result_batch, result_type in result_iter:\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\", line 1254, in udf\r\n    yield _predict_row_batch(batch_predict_fn, row_batch_args)\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\", line 1090, in _predict_row_batch\r\n    result = predict_fn(pdf)\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\", line 1239, in batch_predict_fn\r\n    return loaded_model.predict(pdf)\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\", line 627, in predict\r\n    return self._model_impl.predict(data)\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/mlflow/tensorflow/__init__.py\", line 523, in predict\r\n    raw_preds = self.infer(**feed_dict)\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1655, in __call__\r\n    return self._call_impl(args, kwargs)\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1673, in _call_impl\r\n    return self._call_with_flat_signature(args, kwargs, cancellation_manager)\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1706, in _call_with_flat_signature\r\n    sorted(set(self._arg_keywords) - set(specified_keywords)))))\r\nTypeError: signature_wrapper(input_1) missing required arguments: input_1\r\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:598)\r\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:99)\r\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:49)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:551)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:733)\r\n\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:80)\r\n\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:187)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:655)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:658)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2339)\r\n\tat org.apache.spark.sql.execution.collect.Collector.runSparkJobs(Collector.scala:298)\r\n\tat org.apache.spark.sql.execution.collect.Collector.collect(Collector.scala:308)\r\n\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:82)\r\n\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:88)\r\n\tat org.apache.spark.sql.execution.ResultCacheManager.getOrComputeResult(ResultCacheManager.scala:508)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollectResult(limit.scala:58)\r\n\tat org.apache.spark.sql.Dataset.collectResult(Dataset.scala:2994)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$collectResult$1(Dataset.scala:2985)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3709)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:249)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:199)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3707)\r\n\tat org.apache.spark.sql.Dataset.collectResult(Dataset.scala:2984)\r\n\tat com.databricks.backend.daemon.driver.OutputAggregator$.withOutputAggregation0(OutputAggregator.scala:194)\r\n\tat com.databricks.backend.daemon.driver.OutputAggregator$.withOutputAggregation(OutputAggregator.scala:57)\r\n\tat com.databricks.backend.daemon.driver.PythonDriverLocal.generateTableResult(PythonDriverLocal.scala:1158)\r\n\tat com.databricks.backend.daemon.driver.PythonDriverLocal.$anonfun$getResultBufferInternal$1(PythonDriverLocal.scala:1070)\r\n\tat com.databricks.backend.daemon.driver.PythonDriverLocal.withInterpLock(PythonDriverLocal.scala:857)\r\n\tat com.databricks.backend.daemon.driver.PythonDriverLocal.getResultBufferInternal(PythonDriverLocal.scala:939)\r\n\tat com.databricks.backend.daemon.driver.DriverLocal.getResultBuffer(DriverLocal.scala:538)\r\n\tat com.databricks.backend.daemon.driver.PythonDriverLocal.outputSuccess(PythonDriverLocal.scala:899)\r\n\tat com.databricks.backend.daemon.driver.PythonDriverLocal.$anonfun$repl$8(PythonDriverLocal.scala:384)\r\n\tat com.databricks.backend.daemon.driver.PythonDriverLocal.withInterpLock(PythonDriverLocal.scala:857)\r\n\tat com.databricks.backend.daemon.driver.PythonDriverLocal.repl(PythonDriverLocal.scala:371)\r\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$10(DriverLocal.scala:431)\r\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:239)\r\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\r\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:234)\r\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:231)\r\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:48)\r\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:276)\r\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:269)\r\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:48)\r\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:408)\r\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:653)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:645)\r\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:486)\r\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:598)\r\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\r\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:337)\r\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:219)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.api.python.PythonException: 'TypeError: signature_wrapper(input_1) missing required arguments: input_1'. Full traceback below:\r\nTraceback (most recent call last):\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1700, in _call_with_flat_signature\r\n    args.append(kwargs.pop(compat.as_str(keyword)))\r\nKeyError: 'input_1'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/databricks/spark/python/pyspark/worker.py\", line 654, in main\r\n    process()\r\n  File \"/databricks/spark/python/pyspark/worker.py\", line 646, in process\r\n    serializer.dump_stream(out_iter, outfile)\r\n  File \"/databricks/spark/python/pyspark/sql/pandas/serializers.py\", line 281, in dump_stream\r\n    timely_flush_timeout_ms=self.timely_flush_timeout_ms)\r\n  File \"/databricks/spark/python/pyspark/sql/pandas/serializers.py\", line 97, in dump_stream\r\n    for batch in iterator:\r\n  File \"/databricks/spark/python/pyspark/sql/pandas/serializers.py\", line 271, in init_stream_yield_batches\r\n    for series in iterator:\r\n  File \"/databricks/spark/python/pyspark/worker.py\", line 376, in func\r\n    for result_batch, result_type in result_iter:\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\", line 1254, in udf\r\n    yield _predict_row_batch(batch_predict_fn, row_batch_args)\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\", line 1090, in _predict_row_batch\r\n    result = predict_fn(pdf)\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\", line 1239, in batch_predict_fn\r\n    return loaded_model.predict(pdf)\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\", line 627, in predict\r\n    return self._model_impl.predict(data)\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/mlflow/tensorflow/__init__.py\", line 523, in predict\r\n    raw_preds = self.infer(**feed_dict)\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1655, in __call__\r\n    return self._call_impl(args, kwargs)\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1673, in _call_impl\r\n    return self._call_with_flat_signature(args, kwargs, cancellation_manager)\r\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-465e0470-fb14-454a-bacd-cba9a445ec67/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1706, in _call_with_flat_signature\r\n    sorted(set(self._arg_keywords) - set(specified_keywords)))))\r\nTypeError: signature_wrapper(input_1) missing required arguments: input_1\r\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:598)\r\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:99)\r\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:49)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:551)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:733)\r\n\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:80)\r\n\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:187)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$9(Executor.scala:655)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:658)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n\r\n```\r\n\r\nI am using the MyModel implementation as opposed to manually defining each layer after feeding an Input layer because I have some transformations of the input data to make before feeding it as an input to the keras call function. I have adopted a majority of this from [here](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit). Based on my debugging, it looks like this input_1 is a required input of the model but I am unsure how to specify that input_1 == DATA in the pyspark udf. \r\n\r\nAny guidance is much appreciated, thanks!","reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/comments/1090509182/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"karinapatel","id":33239035,"node_id":"MDQ6VXNlcjMzMjM5MDM1","avatar_url":"https://avatars.githubusercontent.com/u/33239035?v=4","gravatar_id":"","url":"https://api.github.com/users/karinapatel","html_url":"https://github.com/karinapatel","followers_url":"https://api.github.com/users/karinapatel/followers","following_url":"https://api.github.com/users/karinapatel/following{/other_user}","gists_url":"https://api.github.com/users/karinapatel/gists{/gist_id}","starred_url":"https://api.github.com/users/karinapatel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/karinapatel/subscriptions","organizations_url":"https://api.github.com/users/karinapatel/orgs","repos_url":"https://api.github.com/users/karinapatel/repos","events_url":"https://api.github.com/users/karinapatel/events{/privacy}","received_events_url":"https://api.github.com/users/karinapatel/received_events","type":"User","site_admin":false}}]