{"url":"https://api.github.com/repos/mlflow/mlflow/issues/5494","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/5494/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/5494/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/5494/events","html_url":"https://github.com/mlflow/mlflow/issues/5494","id":1170276023,"node_id":"I_kwDOCB5Jx85FwP63","number":5494,"title":"[BUG] Unsupported conversion in PySpark UDF prediction from NumPy array(numpy.ndarray) to a Tensor with TF Custom Estimator ","user":{"login":"karinapatel","id":33239035,"node_id":"MDQ6VXNlcjMzMjM5MDM1","avatar_url":"https://avatars.githubusercontent.com/u/33239035?v=4","gravatar_id":"","url":"https://api.github.com/users/karinapatel","html_url":"https://github.com/karinapatel","followers_url":"https://api.github.com/users/karinapatel/followers","following_url":"https://api.github.com/users/karinapatel/following{/other_user}","gists_url":"https://api.github.com/users/karinapatel/gists{/gist_id}","starred_url":"https://api.github.com/users/karinapatel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/karinapatel/subscriptions","organizations_url":"https://api.github.com/users/karinapatel/orgs","repos_url":"https://api.github.com/users/karinapatel/repos","events_url":"https://api.github.com/users/karinapatel/events{/privacy}","received_events_url":"https://api.github.com/users/karinapatel/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":978584226,"node_id":"MDU6TGFiZWw5Nzg1ODQyMjY=","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/docs","name":"area/docs","color":"48eabc","default":false,"description":"Documentation issues"},{"id":2022848043,"node_id":"MDU6TGFiZWwyMDIyODQ4MDQz","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/models","name":"area/models","color":"48eabc","default":false,"description":"MLmodel format, model serialization/deserialization, flavors"},{"id":2022848902,"node_id":"MDU6TGFiZWwyMDIyODQ4OTAy","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/scoring","name":"area/scoring","color":"48eabc","default":false,"description":"MLflow Model server, model deployment tools, Spark UDFs"},{"id":2114036915,"node_id":"MDU6TGFiZWwyMTE0MDM2OTE1","url":"https://api.github.com/repos/mlflow/mlflow/labels/integrations/databricks","name":"integrations/databricks","color":"ffbce5","default":false,"description":"Databricks integrations"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2022-03-15T21:15:14Z","updated_at":"2022-04-06T17:17:36Z","closed_at":"2022-03-30T05:55:40Z","author_association":"NONE","active_lock_reason":null,"body":"Thank you for submitting an issue. Please refer to our [issue policy](https://www.github.com/mlflow/mlflow/blob/master/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https://stackoverflow.com/questions/tagged/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [X] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Catalina Version 10.15.5, Ubuntu 18.04.5 LTS\r\n- **MLflow installed from (source or binary)**: Source\r\n- **MLflow version (run ``mlflow --version``)**: 1.23.1\r\n- **Python version**: 3.7.5\r\n- **npm version, if running the dev UI**: N/A\r\n- **Exact command to reproduce**: see below\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\nUsing a TF simple custom estimator with the tensorflow iris data in combination with MLFlow introduces a bug when trying to perform inference via mlflow.pyfunc.spark_udf.\r\n\r\nThe input to this model is a float array of length 4 -- this is where the conversion issue stems from as numpy.ndarray is unsupported:\r\n\r\n`PythonException: An exception was thrown from a UDF: 'ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).'. Full traceback below:`\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\n\r\nimport mlflow\r\nimport argparse\r\nimport sys\r\nfrom mlflow import pyfunc\r\nimport pandas as pd\r\nimport shutil\r\nimport tempfile\r\nimport tensorflow as tf\r\nimport mlflow.tensorflow\r\ntf.compat.v1.disable_eager_execution()\r\nimport pyspark.sql.functions as F\r\nfrom pyspark.sql.functions import row_number,lit\r\nfrom pyspark.sql.window import Window\r\nfrom pyspark.sql.types import *\r\nimport numpy as np\r\n\r\nfrom mlflow.models.signature import ModelSignature, infer_signature\r\nfrom mlflow.types.schema import *\r\n\r\nfrom pyspark.sql import functions as F\r\nfrom pyspark.sql.functions import struct,col, pandas_udf, PandasUDFType, struct\r\nimport pickle        \r\nfrom tensorflow.python.util import lazy_loader\r\nimport tensorflow as tf\r\nfrom tensorflow.estimator import Estimator\r\nfrom tensorflow.python import pywrap_tensorflow\r\nimport fnmatch\r\nfrom pyspark.sql.types import *\r\nfrom importlib import import_module\r\nfrom pyspark import StorageLevel\r\nimport json\r\nimport logging\r\nimport os\r\n\r\nfrom pyspark.sql import SparkSession\r\n\r\n\r\n\r\ndef generate_data(URL, COL_NAMES):\r\n  \"\"\"\r\n  Generate iris data as a spark dataframe formatted with all inputs in a single array as follows: \r\n  [\"RECIPIENT_ID\",\"DATA\"] where DATA = ['SepalLength', 'SepalWidth',\r\n                    'PetalLength', 'PetalWidth'] values\r\n              \r\n  \"\"\"\r\n  csv_train = pd.read_csv(URL, names=COL_NAMES, header=0)\r\n\r\n  w = Window().orderBy(lit('A'))\r\n  spark_train =spark.createDataFrame(csv_train)\r\n  spark_train = spark_train.withColumn('SepalLength', F.col('SepalLength').cast(FloatType())).withColumn('SepalWidth', F.col('SepalWidth').cast(FloatType())).withColumn('PetalLength', F.col('PetalLength').cast(FloatType())).withColumn('PetalWidth', F.col('PetalWidth').cast(FloatType())).withColumn('Species', F.col('Species').cast(IntegerType()))\r\n  spark_train = spark_train.withColumn('DATA', (F.array('SepalLength','SepalWidth','PetalLength','PetalWidth'))).withColumn(\"RECIPIENT_ID\", (row_number().over(w)).cast(StringType())).select('RECIPIENT_ID','DATA', 'Species')\r\n  \r\n  return spark_train\r\n\r\n\"\"\"\r\nSend time optimization using meta-learning. Currently implemented using Tensorflow and the built-in Estimator class.\r\nThe higest level class here is Trainer and the highest level method is Trainer.fit.\r\n\"\"\"\r\n\r\n# length of each individual message represented in a recipient's CONCAT_MESSAGE_REPR\r\n\r\nclass Trainer:\r\n    \"\"\"\r\n    High level class which performs the training and writes the result to storage.\r\n\r\n    :param loss_fn: str, loss function name\r\n    :param train_ratio: float, percentage of recipients in training group\r\n    :param learning_rate: float\r\n    :param batch_size: int\r\n    :param training_steps: int\r\n    \"\"\"\r\n    def __init__(self, \r\n                 train_ratio=0.9,\r\n                 learning_rate=0.0002,\r\n                 batch_size=250,\r\n                 training_steps=5000):\r\n\r\n        \r\n        self.params = {                       \r\n                       'train_ratio': train_ratio,\r\n                       'learning_rate': learning_rate,\r\n                       'batch_size': batch_size,\r\n                       'training_steps': training_steps,\r\n                       'train_location': '/dbfs/ml/iris_data/train_tf_data/',\r\n                       'test_location': '/dbfs/ml/iris_data/test_tf_data/',\r\n                       'model_dir': model_dir,\r\n                        # Two hidden layers of 10 nodes each.\r\n                        'hidden_units': [10, 10],\r\n                        # The model must choose between 3 classes.\r\n                        'n_classes': 3,\r\n                        }\r\n\r\n    def fit(self, training_data):\r\n        \"\"\"\r\n        Train model using training_data and save results to storage.\r\n        Converts the Spark DF to a tfrecords format to allow batch data to be\r\n        read into the estimator during training\r\n\r\n        :param training_data: pyspark dataframe with columns [RECIPIENT_ID, DATA]\r\n            RECIPIENT_ID: string\r\n            DATA: array\r\n        \"\"\"\r\n        # subset training_data and write out to tmp location \r\n        training_data.repartition(1).write.format(\"tfrecords\").option(\"recordType\", \"Example\").mode(\"overwrite\").save('file:' + self.params['train_location'])\r\n\r\n        # using Tensorflow's built in Estimator\r\n        est = Estimator(model_fn=estimator_model_fn, model_dir=self.params['model_dir'], params=self.params)\r\n\r\n\r\n        my_estimator = est.train(lambda: self._train_input_fn(self.params['batch_size']),\r\n                                  hooks=None,\r\n                                  max_steps=self.params['training_steps'],\r\n                                  saving_listeners=None)\r\n        \r\n        return my_estimator\r\n      \r\n    def _decode(self, serialized_example):\r\n        \"\"\"\r\n        Parses the DATA from the given `serialized_example`.\r\n        :param serialized_example: Raw TFRecordDataset data\r\n        :param fixed_num_message: size of DATA to be used when parsing the data\r\n        :return DATA: Parsed data column\r\n        \"\"\"\r\n        # define a parser\r\n        features = tf.io.parse_single_example(serialized_example,\r\n                                        features={'DATA': tf.io.FixedLenFeature([4], tf.float32),\r\n                                                 'Species': tf.io.FixedLenFeature((), tf.int64, default_value=0)})\r\n\r\n        # convert the data to correct type\r\n        DATA = tf.cast(features['DATA'], tf.float32)\r\n        Species =  tf.cast(features['Species'], tf.int64)\r\n        return DATA, Species\r\n      \r\n    # input_fn for training\r\n    def _train_input_fn(self, batch_size, shuffle_count=100, repeat_count=30):\r\n        \"\"\"\r\n        Input function used to read the TFRecord from a temp location, decode (parse the serialized example), and finally output a batch of data for training\r\n        :param batch size: int\r\n        :param shuffle_count: int, number of times to shuffle data\r\n        :return dataset: batch of data for training of size equivalent to batch_size\r\n        \"\"\"            \r\n        #location of all partitions of train subset data\r\n        train_files = [os.path.join(self.params['train_location'], item) for item in fnmatch.filter(os.listdir( self.params['train_location']), 'part*')]\r\n        raw_train_dataset = tf.data.TFRecordDataset(train_files)\r\n\r\n        #parse the serialized raw_train_dataset as CONCAT_MESSAGE_REPR column\r\n        dataset = raw_train_dataset.map(self._decode)\r\n        assert batch_size is not None, \"batch_size must not be None\"\r\n\r\n        #shuffle the data and return a batch of data for training corresponding to the given batch_size\r\n        dataset = dataset.shuffle(shuffle_count).repeat().batch(batch_size)\r\n        return dataset\r\n      \r\n      \r\n\r\n    # input_fn for evaluation and predictions\r\n    def _eval_input_fn(self):\r\n        \"\"\"\r\n        Input function used to read the TFRecord from a temp location, decode (parse the serialized example), and finally output the data for evaluation\r\n        :return dataset: data for model evaluation\r\n        \"\"\"        \r\n        #location of all partitions of eval subset data    \r\n        test_files = [os.path.join(self.params['train_location'], item) for item in fnmatch.filter(os.listdir( self.params['train_location']), 'part*')]\r\n        raw_test_dataset = tf.data.TFRecordDataset(test_files)\r\n        #parse the serialized raw_train_dataset as CONCAT_MESSAGE_REPR column\r\n        dataset = raw_test_dataset.map(self._decode)\r\n        return dataset\r\n\r\n    def _flat_serving_input_receiver_fn(self):\r\n        \"\"\"\r\n        Function to pass in the correct feature tensor to the tfInputGraph\r\n        Feature corresponds to DATA array data\r\n        :param fixed_num_message: size of DATA to be used when parsing the data\r\n        :return FlatServingInputReceiver: class to help create the TFTransformer object for saving model\r\n        \"\"\"\r\n\r\n        feature_tensor = tf.compat.v1.placeholder(tf.float32, [None, 4])\r\n        return FlatServingInputReceiver(feature_tensor)\r\n        \r\n\r\ndef estimator_model_fn(features, labels, mode, params):\r\n    \"\"\"\r\n    modelFn for Estimator. \r\n    Interface is designed by Databricks devs and cannot be changed.\r\n\r\n    :param features: Dict of DataFrame input column name to tensor (each tensor corresponding to\r\n                    batch of data from the input column)\r\n    :param labels: Tensor, batch of labels\r\n    :param mode: Specifies if the estimator is being run for training, evaluation or prediction.\r\n    :param params: Dict of hyperparameters. Will receive what is passed to\r\n                the Estimator in params parameter. This allows for configuring Estimators for\r\n                hyperparameter tuning.\r\n    :return: tf.estimator.EstimatorSpec describing our model.  \r\n    \"\"\"\r\n\r\n    serving_key = 'predict'\r\n  \r\n  \r\n    data = tf.reshape(features, shape=[-1, 4])\r\n    \r\n    layer1 = tf.keras.layers.Dense(3, activation='linear', input_shape=(-1, 4))\r\n    layer2 = tf.keras.layers.BatchNormalization()\r\n    layer3 = tf.keras.layers.Activation('sigmoid')\r\n    \r\n    scores = layer3(layer2(layer1(data), training=True if mode == tf.estimator.ModeKeys.TRAIN else False))\r\n    \r\n    print(\"scores:\",scores)\r\n    print(\"score shape:\", scores.shape)\r\n    \r\n    logits = scores\r\n    \r\n    print(\"logits\",logits)\r\n    print(\"labels:\", labels)\r\n    # for PREDICT mode, run model on all messages and export scores\r\n    predicted_classes = tf.argmax(logits, axis=1)\r\n    print(\"predicted_classes:\", predicted_classes)\r\n\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        predictions = {\r\n            'class_ids': predicted_classes[:, tf.newaxis],\r\n            'probabilities': tf.identity(logits, name='scores_tensor'),\r\n            'logits': logits,\r\n        }\r\n        export_outputs = {serving_key: tf.estimator.export.PredictOutput(predictions)}\r\n\r\n        return tf.estimator.EstimatorSpec(mode, predictions=predictions, export_outputs=export_outputs)\r\n      \r\n\r\n    predictions = {\r\n        'class_ids': predicted_classes[:, tf.newaxis],\r\n        'probabilities': tf.identity(logits, name='scores_tensor'),\r\n        'logits': logits,\r\n    }\r\n    export_outputs = {serving_key: tf.estimator.export.PredictOutput(predictions)}\r\n\r\n # Compute loss.\r\n    loss_def = tf.keras.losses.SparseCategoricalCrossentropy() \r\n    loss = loss_def(labels, logits)\r\n    # Compute evaluation metrics.\r\n    accuracy =tf.compat.v1.metrics.accuracy(labels=labels,\r\n                                   predictions=predicted_classes,\r\n                                   name='acc_op')\r\n    metrics = {'accuracy': accuracy}\r\n    tf.summary.scalar('accuracy', accuracy[1])\r\n\r\n    if mode == tf.estimator.ModeKeys.EVAL:\r\n        return tf.estimator.EstimatorSpec(\r\n            mode, loss=loss, eval_metric_ops=metrics)\r\n\r\n    # Create training op.\r\n    assert mode == tf.estimator.ModeKeys.TRAIN\r\n\r\n    optimizer = tf.compat.v1.train.AdagradOptimizer(learning_rate=0.1)\r\n    train_op = optimizer.minimize(loss, global_step=tf.compat.v1.train.get_global_step())\r\n    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op,export_outputs=export_outputs)\r\n\r\n  # define the receiver Class which can be fed to export a saved model\r\nclass FlatServingInputReceiver(object):\r\n    \"\"\"\r\n    Define a class to use when creating input receiver function\r\n    The input received function will be sent to the tfInputGraph to create a TFTransformer object\r\n    \"\"\"\r\n    def __init__(self, feature):\r\n        self.features = feature\r\n        self.receiver_tensors = {'DATA': feature}\r\n\r\n\r\ndef _flat_serving_input_receiver_fn():\r\n    \"\"\"\r\n    Function to pass in the correct feature tensor to the tfInputGraph\r\n    Feature corresponds to CONCAT_MESSAGE_REPR array data\r\n    :param fixed_num_message: size of CONCAT_MESSAGE_REPR to be used when parsing the data\r\n    :return FlatServingInputReceiver: class to help create the TFTransformer object for saving model\r\n    \"\"\"\r\n    # calculate the length of CONCAT_MESSAGE_REPR from fixed_num_message param\r\n    feature_length = 4\r\n    feature_tensor = tf.compat.v1.placeholder(tf.float32, [None, feature_length])\r\n    return FlatServingInputReceiver(feature_tensor)\r\n\r\n```\r\n\r\n```\r\n# code to run the training and scoring\r\nmlflow.autolog()\r\ntrain_ratio=0.9\r\nlearning_rate=0.0002\r\nbatch_size=100\r\ntraining_steps=1000\r\n\r\nTRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\r\nTEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\r\n\r\nCSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\r\n                    'PetalLength', 'PetalWidth', 'Species']\r\n\r\nspark_train = generate_data(TRAIN_URL, CSV_COLUMN_NAMES)\r\n\r\nwith mlflow.start_run(run_name=\"test_meta\") as run:\r\n    run_id = run.info.run_id\r\n    print(run_id)\r\n\r\n    model_dir = \"/tmp/estimator/2\"\r\n\r\n    trainer = Trainer(\"test\",\r\n                        learning_rate=learning_rate,\r\n                        batch_size=batch_size,\r\n                        training_steps=1000)\r\n\r\n    model_est = trainer.fit(spark_train)\r\n\r\n    model_results = {}\r\n\r\n    output_dir = model_dir+'/saved_model'\r\n    saved_model_dir = model_est.export_saved_model(output_dir, _flat_serving_input_receiver_fn, ).decode(\"utf-8\")\r\n    print(saved_model_dir)\r\n\r\n    #print(mlflow.get_artifact_uri(\"model\"))\r\n\r\n    loaded_model = mlflow.pyfunc.spark_udf(spark, model_uri = f'runs:/{run_id}/model', result_type='double')\r\n    print(\"loaded_model:  \")\r\n    print(loaded_model)\r\n\r\n    spark_train1 = spark_train.withColumn('predictions', loaded_model('DATA'))\r\n\r\n    spark_train1.show()\r\n\r\n```\r\n\r\n\r\n### Other info / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nError log:\r\n\r\n```\r\n\r\nPythonException: An exception was thrown from a UDF: 'ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).'. Full traceback below:\r\n---------------------------------------------------------------------------\r\nPythonException                           Traceback (most recent call last)\r\n<[command-2793002156562455]()> in <module>\r\n     40     spark_train1 = spark_train.withColumn('predictions', loaded_model('DATA'))\r\n     41 \r\n---> 42     spark_train1.show()\r\n\r\n/databricks/spark/python/pyspark/sql/dataframe.py in show(self, n, truncate, vertical)\r\n    439         \"\"\"\r\n    440         if isinstance(truncate, bool) and truncate:\r\n--> 441             print(self._jdf.showString(n, 20, vertical))\r\n    442         else:\r\n    443             print(self._jdf.showString(n, int(truncate), vertical))\r\n\r\n/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py in __call__(self, *args)\r\n   1303         answer = self.gateway_client.send_command(command)\r\n   1304         return_value = get_return_value(\r\n-> 1305             answer, self.gateway_client, self.target_id, self.name)\r\n   1306 \r\n   1307         for temp_arg in temp_args:\r\n\r\n/databricks/spark/python/pyspark/sql/utils.py in deco(*a, **kw)\r\n    131                 # Hide where the exception came from that shows a non-Pythonic\r\n    132                 # JVM exception message.\r\n--> 133                 raise_from(converted)\r\n    134             else:\r\n    135                 raise\r\n\r\n/databricks/spark/python/pyspark/sql/utils.py in raise_from(e)\r\n\r\nPythonException: An exception was thrown from a UDF: 'ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).'. Full traceback below:\r\nTraceback (most recent call last):\r\n  File \"/databricks/spark/python/pyspark/worker.py\", line 654, in main\r\n    process()\r\n  File \"/databricks/spark/python/pyspark/worker.py\", line 646, in process\r\n    serializer.dump_stream(out_iter, outfile)\r\n  File \"/databricks/spark/python/pyspark/sql/pandas/serializers.py\", line 281, in dump_stream\r\n    timely_flush_timeout_ms=self.timely_flush_timeout_ms)\r\n  File \"/databricks/spark/python/pyspark/sql/pandas/serializers.py\", line 97, in dump_stream\r\n    for batch in iterator:\r\n  File \"/databricks/spark/python/pyspark/sql/pandas/serializers.py\", line 271, in init_stream_yield_batches\r\n    for series in iterator:\r\n  File \"/databricks/spark/python/pyspark/worker.py\", line 467, in mapper\r\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\r\n  File \"/databricks/spark/python/pyspark/worker.py\", line 467, in <genexpr>\r\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\r\n  File \"/databricks/spark/python/pyspark/worker.py\", line 111, in <lambda>\r\n    verify_result_type(f(*a)), len(a[0])), arrow_return_type)\r\n  File \"/databricks/spark/python/pyspark/util.py\", line 109, in wrapper\r\n    return f(*args, **kwargs)\r\n  File \"/databricks/python/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\", line 856, in predict\r\n    result = model.predict(pdf)\r\n  File \"/databricks/python/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\", line 605, in predict\r\n    return self._model_impl.predict(data)\r\n  File \"/databricks/python/lib/python3.7/site-packages/mlflow/tensorflow/__init__.py\", line 493, in predict\r\n    feed_dict[df_col_name] = tensorflow.constant(val)\r\n  File \"/databricks/python/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 264, in constant\r\n    allow_broadcast=True)\r\n  File \"/databricks/python/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\r\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n  File \"/databricks/python/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_eager_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/databricks/python/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 98, in convert_to_eager_tensor\r\n    return ops.EagerTensor(value, ctx.device_name, dtype)\r\nValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).\r\n\r\n```\r\n\r\nCan this NumPy array be supported? Is this issue partially stemming from Custom Estimators or solely due to the incompatibility of array input?\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [X] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [X] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [X] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [X] `integrations/databricks`: Databricks integrations\r\n","closed_by":{"login":"WeichenXu123","id":19235986,"node_id":"MDQ6VXNlcjE5MjM1OTg2","avatar_url":"https://avatars.githubusercontent.com/u/19235986?v=4","gravatar_id":"","url":"https://api.github.com/users/WeichenXu123","html_url":"https://github.com/WeichenXu123","followers_url":"https://api.github.com/users/WeichenXu123/followers","following_url":"https://api.github.com/users/WeichenXu123/following{/other_user}","gists_url":"https://api.github.com/users/WeichenXu123/gists{/gist_id}","starred_url":"https://api.github.com/users/WeichenXu123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/WeichenXu123/subscriptions","organizations_url":"https://api.github.com/users/WeichenXu123/orgs","repos_url":"https://api.github.com/users/WeichenXu123/repos","events_url":"https://api.github.com/users/WeichenXu123/events{/privacy}","received_events_url":"https://api.github.com/users/WeichenXu123/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/5494/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/5494/timeline","performed_via_github_app":null,"state_reason":"completed"}