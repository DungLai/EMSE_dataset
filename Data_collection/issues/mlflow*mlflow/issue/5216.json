{"url":"https://api.github.com/repos/mlflow/mlflow/issues/5216","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/5216/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/5216/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/5216/events","html_url":"https://github.com/mlflow/mlflow/issues/5216","id":1093104391,"node_id":"I_kwDOCB5Jx85BJ3MH","number":5216,"title":"[FR] Support spark `transformers` tracking with mlflow","user":{"login":"serena-ruan","id":82044803,"node_id":"MDQ6VXNlcjgyMDQ0ODAz","avatar_url":"https://avatars.githubusercontent.com/u/82044803?v=4","gravatar_id":"","url":"https://api.github.com/users/serena-ruan","html_url":"https://github.com/serena-ruan","followers_url":"https://api.github.com/users/serena-ruan/followers","following_url":"https://api.github.com/users/serena-ruan/following{/other_user}","gists_url":"https://api.github.com/users/serena-ruan/gists{/gist_id}","starred_url":"https://api.github.com/users/serena-ruan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/serena-ruan/subscriptions","organizations_url":"https://api.github.com/users/serena-ruan/orgs","repos_url":"https://api.github.com/users/serena-ruan/repos","events_url":"https://api.github.com/users/serena-ruan/events{/privacy}","received_events_url":"https://api.github.com/users/serena-ruan/received_events","type":"User","site_admin":false},"labels":[{"id":955449434,"node_id":"MDU6TGFiZWw5NTU0NDk0MzQ=","url":"https://api.github.com/repos/mlflow/mlflow/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":2022848043,"node_id":"MDU6TGFiZWwyMDIyODQ4MDQz","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/models","name":"area/models","color":"48eabc","default":false,"description":"MLmodel format, model serialization/deserialization, flavors"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2022-01-04T08:05:14Z","updated_at":"2022-03-09T11:18:27Z","closed_at":"2022-03-09T11:18:27Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https://www.github.com/mlflow/mlflow/blob/master/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nCurrently, MLFlow's spark flavor only support saving/logging classes that are `Models`, and it means even those popular `Transformers` like `Bucketizer` can't call save/log/predict. Could you support `Transformers` since both of them belong to `Pipeline` and it makes more sense if we can just call the same behavior for models and transformers.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nSave, log and inference with spark transformers.\r\n- Why is this use case valuable to support for MLflow users in general?\r\nMLFlow spark already support `models`, and transformers are just like models that can be put into pipelines.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nIt makes models and transformers behaviors consistent, and users can keep track of them using mlflow following the same pattern.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nMlflow spark currently has a strict check that only classes of type `pyspark.ml.model` can be passed to the following save_model function, so for transformers we must wrap it as pipeline model in order to save it, which makes the process more complicated. So if you could add transformers into the `_validate_model` function then it can directly be saved by mlflow.spark.save_model.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nWe want to support all pyspark ml Transformers with the ability to save, log and load with mlflow.spark. For example, VectorAssembler class is a typical type of Transformer that merges multiple columns into a vector column. And Transformers can be a stage of PipelineModel. So the suggested change is as follows:\r\n\r\nFor file mlflow/spark.py we change the _validate_model to support Transformer:\r\n\r\n```\r\ndef _validate_model(spark_model):\r\n    from pyspark.ml.util import MLReadable, MLWritable\r\n    from pyspark.ml import Model as PySparkModel\r\n    from pyspark.ml import Transformer as PySparkTransformer\r\n\r\n    if (\r\n        (\r\n            not isinstance(spark_model, PySparkModel)\r\n            and not isinstance(spark_model, PySparkTransformer)\r\n        )\r\n        or not isinstance(spark_model, MLReadable)\r\n        or not isinstance(spark_model, MLWritable)\r\n    ):\r\n        raise MlflowException(\r\n            \"Cannot serialize this model. MLflow can only save descendants of pyspark.Model\"\r\n            \"that implement MLWritable and MLReadable.\",\r\n            INVALID_PARAMETER_VALUE,\r\n        )\r\n```\r\n\r\nAs we can see in save_model function:\r\n`if not isinstance(spark_model, PipelineModel):\r\n        spark_model = PipelineModel([spark_model])`\r\nAnd Transformers can also be put here so save_model will just work. log_model is the same.\r\nFor load_model it will finally load the PipelineModel back so the Transformers make no difference. We could still load PipelineModel back and call `transform` API on it.\r\n\r\nThe only difference would be that Transformers may not support `predict` function as that requires a column named `prediction`. Transformers are not designed as predictors so it's reasonable, and people can always specify the output column name as `prediction` if they insist on using this feature.","closed_by":{"login":"harupy","id":17039389,"node_id":"MDQ6VXNlcjE3MDM5Mzg5","avatar_url":"https://avatars.githubusercontent.com/u/17039389?v=4","gravatar_id":"","url":"https://api.github.com/users/harupy","html_url":"https://github.com/harupy","followers_url":"https://api.github.com/users/harupy/followers","following_url":"https://api.github.com/users/harupy/following{/other_user}","gists_url":"https://api.github.com/users/harupy/gists{/gist_id}","starred_url":"https://api.github.com/users/harupy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harupy/subscriptions","organizations_url":"https://api.github.com/users/harupy/orgs","repos_url":"https://api.github.com/users/harupy/repos","events_url":"https://api.github.com/users/harupy/events{/privacy}","received_events_url":"https://api.github.com/users/harupy/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/5216/reactions","total_count":2,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":1},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/5216/timeline","performed_via_github_app":null,"state_reason":"completed"}