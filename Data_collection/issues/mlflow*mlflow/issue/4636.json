{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4636","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/4636/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/4636/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/4636/events","html_url":"https://github.com/mlflow/mlflow/issues/4636","id":958145843,"node_id":"MDU6SXNzdWU5NTgxNDU4NDM=","number":4636,"title":"ML Flow - Pytorch lightning Multi GPU Pickling error","user":{"login":"vjkravi","id":2879344,"node_id":"MDQ6VXNlcjI4NzkzNDQ=","avatar_url":"https://avatars.githubusercontent.com/u/2879344?v=4","gravatar_id":"","url":"https://api.github.com/users/vjkravi","html_url":"https://github.com/vjkravi","followers_url":"https://api.github.com/users/vjkravi/followers","following_url":"https://api.github.com/users/vjkravi/following{/other_user}","gists_url":"https://api.github.com/users/vjkravi/gists{/gist_id}","starred_url":"https://api.github.com/users/vjkravi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vjkravi/subscriptions","organizations_url":"https://api.github.com/users/vjkravi/orgs","repos_url":"https://api.github.com/users/vjkravi/repos","events_url":"https://api.github.com/users/vjkravi/events{/privacy}","received_events_url":"https://api.github.com/users/vjkravi/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2021-08-02T13:27:02Z","updated_at":"2021-10-19T23:48:25Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"System Information:\r\n'pytorch-lightning==1.3.8\r\n'mlflow==1.19.0'\r\n\r\nDescription:\r\nI am using mlflow autologger with pytorch_lightning. The auto logging feature works fine with it is run on a single GPU. But it fails when I try it on multiple GPUs. From the stack trace I understand that it is trying to add the MLflow callback to the list of callbacks and then it fails when it is trying to spawn a new process\r\n\r\nError:\r\n\r\nAttributeError: Can't pickle local object '_create_patch_fit.<locals>.getPLCallback.<locals>.__MLflowPLCallback'\r\ndatabricks/python/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py in safe_patch_function(*args, **kwargs)\r\n    490                         patch_function.call(call_original, *args, **kwargs)\r\n    491                     else:\r\n--> 492                         patch_function(call_original, *args, **kwargs)\r\n    493 \r\n    494                     session.state = \"succeeded\"\r\n\r\n/databricks/python/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py in patch_with_managed_run(original, *args, **kwargs)\r\n    240 \r\n    241             try:\r\n--> 242                 result = patch_function(original, *args, **kwargs)\r\n    243             except (Exception, KeyboardInterrupt):\r\n    244                 # In addition to standard Python exceptions, handle keyboard interrupts to ensure\r\n\r\n/databricks/python/lib/python3.8/site-packages/mlflow/pytorch/_pytorch_autolog.py in fit(original, self, *args, **kwargs)\r\n    314         Patching trainer.fit method to add autolog class into callback\r\n    315         \"\"\"\r\n--> 316         return _run_and_log_function(self, original, args, kwargs)\r\n    317 \r\n    318     return fit\r\n\r\n/databricks/python/lib/python3.8/site-packages/mlflow/pytorch/_pytorch_autolog.py in _run_and_log_function(self, original, args, kwargs)\r\n    306         if not any(isinstance(callbacks, __MLflowPLCallback) for callbacks in self.callbacks):\r\n    307             self.callbacks += [__MLflowPLCallback()]\r\n--> 308         result = original(self, *args, **kwargs)\r\n    309 \r\n    310         return result\r\n\r\n/databricks/python/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py in call_original(*og_args, **og_kwargs)\r\n    446                                 disable_warnings=False, reroute_warnings=False,\r\n    447                             ):\r\n--> 448                                 original_result = original(*og_args, **og_kwargs)\r\n    449 \r\n    450                             try_log_autologging_event(\r\n\r\n/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py in fit(self, model, train_dataloader, val_dataloaders, datamodule)\r\n    458         )\r\n    459 \r\n--> 460         self._run(model)\r\n    461 \r\n    462         assert self.state.stopped\r\n\r\n/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py in _run(self, model)\r\n    756 \r\n    757         # dispatch `start_training` or `start_evaluating` or `start_predicting`\r\n--> 758         self.dispatch()\r\n    759 \r\n    760         # plugin will finalized fitting (e.g. ddp_spawn will load trained model)\r\n\r\n/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py in dispatch(self)\r\n    797             self.accelerator.start_predicting(self)\r\n    798         else:\r\n--> 799             self.accelerator.start_training(self)\r\n    800 \r\n    801     def run_stage(self):\r\n\r\n/databricks/python/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py in start_training(self, trainer)\r\n     94 \r\n     95     def start_training(self, trainer: 'pl.Trainer') -> None:\r\n---> 96         self.training_type_plugin.start_training(trainer)\r\n     97 \r\n     98     def start_evaluating(self, trainer: 'pl.Trainer') -> None:\r\n\r\n/databricks/python/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp_spawn.py in start_training(self, trainer)\r\n    120 \r\n    121     def start_training(self, trainer):\r\n--> 122         mp.spawn(self.new_process, **self.mp_spawn_kwargs)\r\n    123         # reset optimizers, since main process is never used for training and thus does not have a valid optim state\r\n    124         trainer.optimizers = []\r\n\r\n/databricks/python/lib/python3.8/site-packages/torch/multiprocessing/spawn.py in spawn(fn, args, nprocs, join, daemon, start_method)\r\n    197                ' torch.multiprocessing.start_process(...)' % start_method)\r\n    198         warnings.warn(msg)\r\n--> 199     return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\r\n\r\n/databricks/python/lib/python3.8/site-packages/torch/multiprocessing/spawn.py in start_processes(fn, args, nprocs, join, daemon, start_method)\r\n    146             daemon=daemon,\r\n    147         )\r\n--> 148         process.start()\r\n    149         error_queues.append(error_queue)\r\n    150         processes.append(process)\r\n\r\n/databricks/python/lib/python3.8/multiprocessing/process.py in start(self)\r\n    119                'daemonic processes are not allowed to have children'\r\n    120         _cleanup()\r\n--> 121         self._popen = self._Popen(self)\r\n    122         self._sentinel = self._popen.sentinel\r\n    123         # Avoid a refcycle if the target function holds an indirect\r\n\r\n/databricks/python/lib/python3.8/multiprocessing/context.py in _Popen(process_obj)\r\n    282         def _Popen(process_obj):\r\n    283             from .popen_spawn_posix import Popen\r\n--> 284             return Popen(process_obj)\r\n    285 \r\n    286     class ForkServerProcess(process.BaseProcess):\r\n\r\n/databricks/python/lib/python3.8/multiprocessing/popen_spawn_posix.py in __init__(self, process_obj)\r\n     30     def __init__(self, process_obj):\r\n     31         self._fds = []\r\n---> 32         super().__init__(process_obj)\r\n     33 \r\n     34     def duplicate_for_child(self, fd):\r\n\r\n/databricks/python/lib/python3.8/multiprocessing/popen_fork.py in __init__(self, process_obj)\r\n     17         self.returncode = None\r\n     18         self.finalizer = None\r\n---> 19         self._launch(process_obj)\r\n     20 \r\n     21     def duplicate_for_child(self, fd):\r\n\r\n/databricks/python/lib/python3.8/multiprocessing/popen_spawn_posix.py in _launch(self, process_obj)\r\n     45         try:\r\n     46             reduction.dump(prep_data, fp)\r\n---> 47             reduction.dump(process_obj, fp)\r\n     48         finally:\r\n     49             set_spawning_popen(None)\r\n\r\n/databricks/python/lib/python3.8/multiprocessing/reduction.py in dump(obj, file, protocol)\r\n     58 def dump(obj, file, protocol=None):\r\n     59     '''Replacement for pickle.dump() using ForkingPickler.'''\r\n---> 60     ForkingPickler(file, protocol).dump(obj)\r\n     61 \r\n     62 #\r\n\r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4636/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/4636/timeline","performed_via_github_app":null,"state_reason":null}