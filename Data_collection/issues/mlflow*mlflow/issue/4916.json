{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4916","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/4916/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/4916/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/4916/events","html_url":"https://github.com/mlflow/mlflow/issues/4916","id":1032118445,"node_id":"I_kwDOCB5Jx849hOCt","number":4916,"title":"[FR] Interoperability of spark model.","user":{"login":"bipin2295","id":37153155,"node_id":"MDQ6VXNlcjM3MTUzMTU1","avatar_url":"https://avatars.githubusercontent.com/u/37153155?v=4","gravatar_id":"","url":"https://api.github.com/users/bipin2295","html_url":"https://github.com/bipin2295","followers_url":"https://api.github.com/users/bipin2295/followers","following_url":"https://api.github.com/users/bipin2295/following{/other_user}","gists_url":"https://api.github.com/users/bipin2295/gists{/gist_id}","starred_url":"https://api.github.com/users/bipin2295/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bipin2295/subscriptions","organizations_url":"https://api.github.com/users/bipin2295/orgs","repos_url":"https://api.github.com/users/bipin2295/repos","events_url":"https://api.github.com/users/bipin2295/events{/privacy}","received_events_url":"https://api.github.com/users/bipin2295/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-10-21T06:42:48Z","updated_at":"2021-10-21T06:42:48Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Thank you for submitting an issue. Please refer to our [issue policy](https://www.github.com/mlflow/mlflow/blob/master/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https://stackoverflow.com/questions/tagged/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n-  No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04\r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.20.2\r\n- **Python version**: Python 3.9.1\r\n- **npm version, if running the dev UI**: NA\r\n- **Exact command to reproduce**: NA\r\n\r\n### Describe the problem\r\nI'm using a spark training method to train the model and store the model as pyspark flavour inside a container environment. However, for prediction, I'm using another container with python base image and trying to do prediction using pyfunc flavour. However, this tells me to install pyspark in the prediction cluster. Is there any way I could make the pyspark model interoperable  across various flavour without actually using pyspark in my prediction/model-serving container?\r\n\r\n### Code to reproduce issue\r\nTraining code:\r\n----------------------\r\n```\r\nfrom pyspark.ml.classification import LogisticRegression\r\nfrom pyspark.ml.feature import VectorAssembler, StandardScaler\r\nfrom pyspark.ml import Pipeline\r\nfrom pyspark.sql import SparkSession\r\nfrom sklearn.datasets import load_iris\r\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\r\n\r\nimport mlflow\r\n\r\nmlflow.set_registry_uri(\"mysql+pymysql://root:root@127.0.0.1:3306/mlflow_tracking_database\")\r\nmlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\r\nmr_uri = mlflow.get_registry_uri()\r\nprint(\"Current registry uri: {}\".format(mr_uri))\r\ntracking_uri = mlflow.get_tracking_uri()\r\nprint(\"Current tracking uri: {}\".format(tracking_uri))\r\n\r\n\r\nexpr_name = \"Sample_spark_aws_exp\"  # create a new experiment (do not replace)\r\nmlflow.set_experiment(expr_name)\r\nexpr = mlflow.get_experiment_by_name(expr_name)\r\nexpr_id = expr.experiment_id\r\nexpr_id, expr\r\n\r\nprint(\"===================Starting Spark session====================\")\r\nspark = SparkSession.builder \\\r\n.appName('ML Flow test') \\\r\n.config(\"spark.hadoop.fs.s3a.endpoint\", \"s3.us-east-1.amazonaws.com\") \\\r\n.config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\r\n.config(\"spark.hadoop.fs.s3a.access.key\", \"AKIA4A2VACX6BAG7W35Q\") \\\r\n.config(\"spark.hadoop.fs.s3a.secret.key\", \"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\") \\\r\n.getOrCreate()\r\n\r\nprint(\"=====================Loading Data===========================\")\r\ndf = load_iris(as_frame=True).frame.rename(columns={\"target\": \"label\"})\r\ndf = spark.createDataFrame(df)\r\ntrain, test = df.randomSplit([0.8, 0.2],)\r\nprint(\"=====================Data load completed======================\")\r\n\r\n\r\nassembler = VectorAssembler(inputCols=df.columns[:-1], outputCol=\"features\")\r\nscaler = StandardScaler(inputCol=assembler.getOutputCol(), outputCol=\"scaledFeatures\")\r\nlor = LogisticRegression(maxIter=5, featuresCol=scaler.getOutputCol())\r\n\r\n\r\ntags = {\"Dataset\": \"IRIS data\",\r\n        \"Platform\": \"Sample Examples\",\r\n        \"Framework\": \"Pyspark\"}\r\n\r\nprint(\"=====================Starting Mlflow run===================\")\r\npipeline = Pipeline(stages=[assembler, scaler, lor])\r\nwith mlflow.start_run(experiment_id=expr_id):\r\n    print(\"Current artifact uri: {}\".format(mlflow.get_artifact_uri()))\r\n    print(\"Training in progress...\")\r\n    pipeline_model = pipeline.fit(train)\r\n    print(\"======================Training Completed!================\")\r\n\r\n    print(\"======================Logging Model======================\")\r\n    mlflow.spark.log_model(pipeline_model,\"spark_model_dir\")\r\n    \r\n    columns = [\"label\",\"features\", \"prediction\",\"rawPrediction\", \"probability\"]\r\n    predictions = pipeline_model.transform(test)\r\n\r\n    predictions.select(columns).show(10, False)\r\n    \r\n    evaluator = MulticlassClassificationEvaluator()\r\n    \r\n    f1_score = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\r\n    accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\r\n    truePositiveRateByLabel = evaluator.evaluate(predictions, {evaluator.metricName: \"truePositiveRateByLabel\"})\r\n    hammingLoss = evaluator.evaluate(predictions, {evaluator.metricName: \"hammingLoss\"})\r\n    recallByLabel = evaluator.evaluate(predictions, {evaluator.metricName: \"recallByLabel\"})\r\n    \r\n    metrics = { \r\n    'F1 score': f1_score,\r\n    'Accuracy': accuracy,\r\n    'truePositiveRateByLabel': truePositiveRateByLabel,\r\n    'hammingLoss': hammingLoss,\r\n    'recallByLabel': recallByLabel,\r\n    }\r\n    \r\n    print(\"================================Evaluation Metrics: =====================================\")\r\n    print(metrics)\r\n    \r\n    mlflow.log_metrics(metrics)\r\n    mlflow.set_tags(tags)\r\n    \r\n    with open(\"test_file.txt\", \"w\") as f:\r\n        f.write(\"test Atrifacts \\n\")\r\n\r\n    mlflow.log_artifact(\"test_file.txt\")\r\n```\r\n----------------------\r\n**Model serving code:**\r\n---------------------\r\n```\r\nfrom flask import Flask, request, redirect, url_for, flash, jsonify\r\nimport numpy as np\r\nimport pandas as pd\r\nimport json\r\nimport mlflow\r\n\r\napp = Flask(__name__)\r\nmlflow.set_registry_uri(\"mysql+pymysql://root:root@mysql-server:3306/mlflow_tracking_database\")\r\nmlflow.set_tracking_uri(\"http://mlflow-server2:5000\")\r\nmr_uri = mlflow.get_registry_uri()\r\n\r\nprint(\"Current registry uri: {}\".format(mr_uri))\r\ntracking_uri = mlflow.get_tracking_uri()\r\nprint(\"Current tracking uri: {}\".format(tracking_uri))\r\n\r\n#logged_model = \"models:/IRIS_data_model_spark/4\"\r\n#loaded_model = mlflow.pyfunc.load_model(logged_model)\r\n\r\n\r\n@app.route('/predict', methods=['POST'])\r\ndef makecalc():\r\n    logged_model = \"models:/IRIS_data_model_spark/4\"\r\n    loaded_model = mlflow.pyfunc.load_model(logged_model)\r\n    data = request.get_json()\r\n    df = pd.DataFrame(data=data[\"data\"],columns=data[\"columns\"])\r\n    return jsonify(loaded_model.predict(df))\r\n#    return data\r\n\r\nif __name__ == '__main__':\r\n    app.run(debug=True, host='0.0.0.0',port=4321)\r\n```\r\n\r\n### Other info / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4916/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/4916/timeline","performed_via_github_app":null,"state_reason":null}