{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4142","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/4142/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/4142/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/4142/events","html_url":"https://github.com/mlflow/mlflow/issues/4142","id":816695480,"node_id":"MDU6SXNzdWU4MTY2OTU0ODA=","number":4142,"title":"[FR] Sending Numpy Array to Scoring Server instead of Pandas DataFrame","user":{"login":"krausmaximilian","id":66029828,"node_id":"MDQ6VXNlcjY2MDI5ODI4","avatar_url":"https://avatars.githubusercontent.com/u/66029828?v=4","gravatar_id":"","url":"https://api.github.com/users/krausmaximilian","html_url":"https://github.com/krausmaximilian","followers_url":"https://api.github.com/users/krausmaximilian/followers","following_url":"https://api.github.com/users/krausmaximilian/following{/other_user}","gists_url":"https://api.github.com/users/krausmaximilian/gists{/gist_id}","starred_url":"https://api.github.com/users/krausmaximilian/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/krausmaximilian/subscriptions","organizations_url":"https://api.github.com/users/krausmaximilian/orgs","repos_url":"https://api.github.com/users/krausmaximilian/repos","events_url":"https://api.github.com/users/krausmaximilian/events{/privacy}","received_events_url":"https://api.github.com/users/krausmaximilian/received_events","type":"User","site_admin":false},"labels":[{"id":955449434,"node_id":"MDU6TGFiZWw5NTU0NDk0MzQ=","url":"https://api.github.com/repos/mlflow/mlflow/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":978584226,"node_id":"MDU6TGFiZWw5Nzg1ODQyMjY=","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/docs","name":"area/docs","color":"48eabc","default":false,"description":"Documentation issues"},{"id":1988875934,"node_id":"MDU6TGFiZWwxOTg4ODc1OTM0","url":"https://api.github.com/repos/mlflow/mlflow/labels/needs%20author%20feedback","name":"needs author feedback","color":"fef2c0","default":false,"description":"Issue is waiting for the author to respond"},{"id":2022848043,"node_id":"MDU6TGFiZWwyMDIyODQ4MDQz","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/models","name":"area/models","color":"48eabc","default":false,"description":"MLmodel format, model serialization/deserialization, flavors"},{"id":2022848902,"node_id":"MDU6TGFiZWwyMDIyODQ4OTAy","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/scoring","name":"area/scoring","color":"48eabc","default":false,"description":"MLflow Model server, model deployment tools, Spark UDFs"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-02-25T18:42:21Z","updated_at":"2021-04-23T12:46:22Z","closed_at":"2021-04-23T12:46:21Z","author_association":"NONE","active_lock_reason":null,"body":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nCurrently, when sending a post request to the scoring server, the input of the json is automatically converted to a Pandas Dataframe. However, for higher dimensional data this is a problem since pandas only accepts 2d data. I propose to accept higher dimensional data by adding another content type \"json_numpy\" and converting the json into a numpy array. There are only small changes in pytorch.\\__init__.py (_PytorchWrapper) and scoring\\_server.\\__init\\__.py necessary (Instance checking, conversion, that's it I guess). I implemented that already for a project of mine and it's working well. It is also backwards compatible.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n  - Sending higher dimensional data to scoring server (right now only 2d possible)\r\n- Why is this use case valuable to support for MLflow users in general?\r\n  - A lot of tasks require higher dimension data (image segmentation, etc.) \r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [x] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [x] `area/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nChanges in scoring_server.\\__init__.py:\r\n```python\r\ndef parse_numpy_json_to_numpy(json_input):\r\n    \"\"\"\r\n        :param json_input: A JSON-formatted string representation of a numpy array.\r\n    \"\"\"\r\n    try:\r\n        json_input_list = json.loads(json_input,  object_pairs_hook=OrderedDict)\r\n        return np.array(json_input_list[\"data\"])\r\n    except Exception:\r\n        _handle_serving_error(\r\n            error_message=(\r\n                \"Failed to parse input as a Numpy.\"\r\n            ),\r\n            error_code=MALFORMED_REQUEST,\r\n        )\r\n\r\ndef init(model: PyFuncModel):\r\n\r\n    \"\"\"\r\n    Initialize the server. Loads pyfunc model from the path.\r\n    \"\"\"\r\n    app = flask.Flask(__name__)\r\n    input_schema = model.metadata.get_input_schema()\r\n\r\n    @app.route(\"/ping\", methods=[\"GET\"])\r\n    def ping():  # pylint: disable=unused-variable\r\n        \"\"\"\r\n        Determine if the container is working and healthy.\r\n        We declare it healthy if we can load the model successfully.\r\n        \"\"\"\r\n        health = model is not None\r\n        status = 200 if health else 404\r\n        return flask.Response(response=\"\\n\", status=status, mimetype=\"application/json\")\r\n\r\n    @app.route(\"/invocations\", methods=[\"POST\"])\r\n    @catch_mlflow_exception\r\n    def transformation():  # pylint: disable=unused-variable\r\n        \"\"\"\r\n        Do an inference on a single batch of data. In this sample server,\r\n        we take data as CSV or json, convert it to a Pandas DataFrame or Numpy,\r\n        generate predictions and convert them back to json.\r\n        \"\"\"\r\n        # Convert from CSV to pandas\r\n        if flask.request.content_type == CONTENT_TYPE_CSV:\r\n            data = flask.request.data.decode(\"utf-8\")\r\n            csv_input = StringIO(data)\r\n            data = parse_csv_input(csv_input=csv_input)\r\n        elif flask.request.content_type in [CONTENT_TYPE_JSON, CONTENT_TYPE_JSON_SPLIT_ORIENTED]:\r\n            data = parse_json_input(\r\n                json_input=flask.request.data.decode(\"utf-8\"), orient=\"split\", schema=input_schema\r\n            )\r\n        elif flask.request.content_type == CONTENT_TYPE_JSON_RECORDS_ORIENTED:\r\n            data = parse_json_input(\r\n                json_input=flask.request.data.decode(\"utf-8\"), orient=\"records\", schema=input_schema\r\n            )\r\n        elif flask.request.content_type == CONTENT_TYPE_JSON_SPLIT_NUMPY:\r\n            data = parse_split_oriented_json_input_to_numpy(flask.request.data.decode(\"utf-8\"))\r\n        elif flask.request.content_type == CONTENT_TYPE_NUMPY:\r\n            data = parse_numpy_json_to_numpy(flask.request.data.decode(\"utf-8\"))\r\n        else:\r\n            return flask.Response(\r\n                response=(\r\n                    \"This predictor only supports the following content types,\"\r\n                    \" {supported_content_types}. Got '{received_content_type}'.\".format(\r\n                        supported_content_types=CONTENT_TYPES,\r\n                        received_content_type=flask.request.content_type,\r\n                    )\r\n                ),\r\n                status=415,\r\n                mimetype=\"text/plain\",\r\n            )\r\n\r\n        # Do the prediction\r\n        # pylint: disable=broad-except\r\n        try:\r\n            raw_predictions = model.predict(data)\r\n        except MlflowException as e:\r\n            _handle_serving_error(\r\n                error_message=e.message, error_code=BAD_REQUEST, include_traceback=False\r\n            )\r\n        except Exception:\r\n            _handle_serving_error(\r\n                error_message=(\r\n                    \"Encountered an unexpected error while evaluating the model. Verify\"\r\n                    \" that the serialized input Dataframe is compatible with the model for\"\r\n                    \" inference.\"\r\n                ),\r\n                error_code=BAD_REQUEST,\r\n            )\r\n        result = StringIO()\r\n        predictions_to_json(raw_predictions, result)\r\n        return flask.Response(response=result.getvalue(), status=200, mimetype=\"application/json\")\r\n\r\n    return app\r\n```\r\n\r\n\r\nChanges in pytorch.\\__init__.py:\r\n\r\n```python\r\nclass _PyTorchWrapper(object):\r\n    \"\"\"\r\n    Wrapper class that creates a predict function such that\r\n    predict(data: pd.DataFrame) -> model's output as pd.DataFrame (pandas DataFrame)\r\n    \"\"\"\r\n\r\n    def __init__(self, pytorch_model):\r\n        self.pytorch_model = pytorch_model\r\n\r\n    def predict(self, data, device=\"cpu\"):\r\n        import torch\r\n\r\n        if not isinstance(data, pd.DataFrame) and not isinstance(data, np.ndarray):\r\n            raise TypeError(\"Input data should be pandas.DataFrame\")\r\n        self.pytorch_model.to(device)\r\n        self.pytorch_model.eval()\r\n        with torch.no_grad():\r\n            if isinstance(data, np.ndarray):\r\n                input_tensor = torch.from_numpy(data.astype(np.float32)).to(device)\r\n            else:\r\n                input_tensor = torch.from_numpy(data.values.astype(np.float32)).to(device)\r\n            preds = self.pytorch_model(input_tensor)\r\n            if not isinstance(preds, torch.Tensor):\r\n                raise TypeError(\r\n                    \"Expected PyTorch model to output a single output tensor, \"\r\n                    \"but got output of type '{}'\".format(type(preds))\r\n                )\r\n            if isinstance(data, np.ndarray):\r\n                predicted = preds.numpy()\r\n            else:\r\n                predicted = pd.DataFrame(preds.numpy())\r\n                predicted.index = data.index\r\n            return predicted\r\n```\r\n","closed_by":{"login":"krausmaximilian","id":66029828,"node_id":"MDQ6VXNlcjY2MDI5ODI4","avatar_url":"https://avatars.githubusercontent.com/u/66029828?v=4","gravatar_id":"","url":"https://api.github.com/users/krausmaximilian","html_url":"https://github.com/krausmaximilian","followers_url":"https://api.github.com/users/krausmaximilian/followers","following_url":"https://api.github.com/users/krausmaximilian/following{/other_user}","gists_url":"https://api.github.com/users/krausmaximilian/gists{/gist_id}","starred_url":"https://api.github.com/users/krausmaximilian/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/krausmaximilian/subscriptions","organizations_url":"https://api.github.com/users/krausmaximilian/orgs","repos_url":"https://api.github.com/users/krausmaximilian/repos","events_url":"https://api.github.com/users/krausmaximilian/events{/privacy}","received_events_url":"https://api.github.com/users/krausmaximilian/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4142/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/4142/timeline","performed_via_github_app":null,"state_reason":"completed"}