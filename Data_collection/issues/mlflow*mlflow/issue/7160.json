{"url":"https://api.github.com/repos/mlflow/mlflow/issues/7160","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/7160/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/7160/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/7160/events","html_url":"https://github.com/mlflow/mlflow/issues/7160","id":1422946917,"node_id":"I_kwDOCB5Jx85U0HJl","number":7160,"title":"[FR] add serverless inference endpoint support for sagemaker deployment","user":{"login":"QAM","id":3173971,"node_id":"MDQ6VXNlcjMxNzM5NzE=","avatar_url":"https://avatars.githubusercontent.com/u/3173971?v=4","gravatar_id":"","url":"https://api.github.com/users/QAM","html_url":"https://github.com/QAM","followers_url":"https://api.github.com/users/QAM/followers","following_url":"https://api.github.com/users/QAM/following{/other_user}","gists_url":"https://api.github.com/users/QAM/gists{/gist_id}","starred_url":"https://api.github.com/users/QAM/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/QAM/subscriptions","organizations_url":"https://api.github.com/users/QAM/orgs","repos_url":"https://api.github.com/users/QAM/repos","events_url":"https://api.github.com/users/QAM/events{/privacy}","received_events_url":"https://api.github.com/users/QAM/received_events","type":"User","site_admin":false},"labels":[{"id":955449434,"node_id":"MDU6TGFiZWw5NTU0NDk0MzQ=","url":"https://api.github.com/repos/mlflow/mlflow/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":2022860064,"node_id":"MDU6TGFiZWwyMDIyODYwMDY0","url":"https://api.github.com/repos/mlflow/mlflow/labels/integrations/sagemaker","name":"integrations/sagemaker","color":"ffbce5","default":false,"description":"Sagemaker integrations"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2022-10-25T19:13:33Z","updated_at":"2022-11-02T00:32:43Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"### Willingness to contribute\n\nYes. I can contribute this feature independently.\n\n### Proposal Summary\n\nNow, we can use the command and deploy model on sagemaker inference.\r\n```\r\nmlflow sagemaker deploy -m <model> -a liang-test-model --execution-role-arn <execution role>\r\n```\r\n\r\nDo we have any plan for supporting serverless deployment.\r\n\r\nReference [link](https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints-create.html)\r\nAnd ref code.\r\n```\r\nresponse = client.create_endpoint_config(\r\n   EndpointConfigName=\"<your-endpoint-configuration>\",\r\n   KmsKeyId=\"arn:aws:kms:us-east-1:123456789012:key/143ef68f-76fd-45e3-abba-ed28fc8d3d5e\",\r\n   ProductionVariants=[\r\n        {\r\n            \"ModelName\": \"<your-model-name>\",\r\n            \"VariantName\": \"AllTraffic\",\r\n            \"ServerlessConfig\": {\r\n                \"MemorySizeInMB\": 2048,\r\n                \"MaxConcurrency\": 20\r\n            }\r\n        } \r\n    ]\r\n)\r\n```\n\n### Motivation\n\n> #### What is the use case for this feature?\r\nWe can have near-real-time scenario for inference.\r\nDue to the cost, we would like to use serverless endpoint on sagemaker.\r\n\r\n> #### Why is this use case valuable to support for MLflow users in general?\r\nSave cost. Support near-real-time inference.\r\n\r\n> #### Why is this use case valuable to support for your project(s) or organization?\r\nSave cost. Support near-real-time inference.\r\n\r\n> #### Why is it currently difficult to achieve this use case?\r\nBased on current mlflow code, we need to do two operations.\r\n1. use \"mlflow sagemaker deploy\" command.\r\n2. use boto3 sagemaker api \"create_endpoint_config\" and change the endpoint type from real-time to serverless.\r\n\n\n### Details\n\n_No response_\n\n### What component(s) does this bug affect?\n\n- [ ] `area/artifacts`: Artifact stores and artifact logging\n- [ ] `area/build`: Build and test infrastructure for MLflow\n- [ ] `area/docs`: MLflow documentation pages\n- [ ] `area/examples`: Example code\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\n- [ ] `area/pipelines`: Pipelines, Pipeline APIs, Pipeline configs, Pipeline Templates\n- [ ] `area/projects`: MLproject format, project running backends\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\n- [ ] `area/server-infra`: MLflow Tracking server backend\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\n\n### What interface(s) does this bug affect?\n\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\n- [ ] `area/windows`: Windows support\n\n### What language(s) does this bug affect?\n\n- [ ] `language/r`: R APIs and clients\n- [ ] `language/java`: Java APIs and clients\n- [ ] `language/new`: Proposals for new client languages\n\n### What integration(s) does this bug affect?\n\n- [ ] `integrations/azure`: Azure and Azure ML integrations\n- [x] `integrations/sagemaker`: SageMaker integrations\n- [ ] `integrations/databricks`: Databricks integrations","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/7160/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/7160/timeline","performed_via_github_app":null,"state_reason":null}