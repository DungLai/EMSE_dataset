{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4812","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/4812/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/4812/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/4812/events","html_url":"https://github.com/mlflow/mlflow/issues/4812","id":997783072,"node_id":"I_kwDOCB5Jx847ePYg","number":4812,"title":"Multi-class classification metrics are used for autologging of binary data","user":{"login":"jwthomas04","id":7529170,"node_id":"MDQ6VXNlcjc1MjkxNzA=","avatar_url":"https://avatars.githubusercontent.com/u/7529170?v=4","gravatar_id":"","url":"https://api.github.com/users/jwthomas04","html_url":"https://github.com/jwthomas04","followers_url":"https://api.github.com/users/jwthomas04/followers","following_url":"https://api.github.com/users/jwthomas04/following{/other_user}","gists_url":"https://api.github.com/users/jwthomas04/gists{/gist_id}","starred_url":"https://api.github.com/users/jwthomas04/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jwthomas04/subscriptions","organizations_url":"https://api.github.com/users/jwthomas04/orgs","repos_url":"https://api.github.com/users/jwthomas04/repos","events_url":"https://api.github.com/users/jwthomas04/events{/privacy}","received_events_url":"https://api.github.com/users/jwthomas04/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":2022849295,"node_id":"MDU6TGFiZWwyMDIyODQ5Mjk1","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/tracking","name":"area/tracking","color":"48eabc","default":false,"description":"Tracking service, tracking client APIs, autologging"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-16T05:15:03Z","updated_at":"2021-09-16T05:15:21Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Thank you for submitting an issue. Please refer to our [issue policy](https://www.github.com/mlflow/mlflow/blob/master/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https://stackoverflow.com/questions/tagged/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [X] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**:\r\n- **Python version**:\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.\r\n\r\nThe expected behavior is that `mlflow.sklearn.eval_and_log_metrics` returns binary evaluation metrics for binary data when using default `pos_label` of 1.  This would be consistent with sklearn.metrics and align with the normal expectation when using binary data.  The actual behavior is that multi-class evaluation metrics are returned.  This is due to using `method='weighted'` instead of `method='binary'` in mlflow.utils._get_classifier_metrics, even when performing binary classification.  \r\n\r\nThis leads to misleading output, especially for imbalanced data.  If the positive class is a small fraction of the total, a naive predictor that classifies to the negative class will have precision, recall and F1 score near 1.\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nimport mlflow\r\nimport numpy as np\r\nimport pandas as pd\r\nimport sklearn\r\n\r\nmodel = sklearn.linear_model.LogisticRegression()\r\nX = pd.DataFrame({'x': [0] * 100})\r\ny = [0] * 99 + [1]\r\n\r\n# Model can't predict the single 1 so binary classifiers are all 0.\r\n# This is reasonable as this classifier can't detect the positive class at all.\r\nmodel.fit(X, y)\r\nprint(sklearn.metrics.precision_score(y, model.predict(X)))\r\n# 0.0\r\nprint(sklearn.metrics.recall_score(y, model.predict(X)))\r\n# 0.0\r\nprint(sklearn.metrics.f1_score(y, model.predict(X)))\r\n# 0.0\r\n\r\n# But mlflow  precision, recall, and F1 score are all near 1.\r\nmlflow.sklearn.eval_and_log_metrics(model, X, y, prefix='train_')\r\n# {'train_precision_score': 0.9801000000000001,\r\n# 'train_recall_score': 0.99,\r\n# 'train_f1_score': 0.9850251256281406,\r\n# 'train_accuracy_score': 0.99,\r\n# 'train_log_loss': 0.04641982852065066,\r\n# 'train_roc_auc_score': 1.0}\r\n```\r\n### Other info / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [ X]`area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4812/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/4812/timeline","performed_via_github_app":null,"state_reason":null}