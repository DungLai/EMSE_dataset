{"url":"https://api.github.com/repos/mlflow/mlflow/issues/1993","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/1993/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/1993/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/1993/events","html_url":"https://github.com/mlflow/mlflow/issues/1993","id":512458362,"node_id":"MDU6SXNzdWU1MTI0NTgzNjI=","number":1993,"title":"[BUG] GPU Support on Sagemaker","user":{"login":"jerrygb","id":1516634,"node_id":"MDQ6VXNlcjE1MTY2MzQ=","avatar_url":"https://avatars.githubusercontent.com/u/1516634?v=4","gravatar_id":"","url":"https://api.github.com/users/jerrygb","html_url":"https://github.com/jerrygb","followers_url":"https://api.github.com/users/jerrygb/followers","following_url":"https://api.github.com/users/jerrygb/following{/other_user}","gists_url":"https://api.github.com/users/jerrygb/gists{/gist_id}","starred_url":"https://api.github.com/users/jerrygb/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jerrygb/subscriptions","organizations_url":"https://api.github.com/users/jerrygb/orgs","repos_url":"https://api.github.com/users/jerrygb/repos","events_url":"https://api.github.com/users/jerrygb/events{/privacy}","received_events_url":"https://api.github.com/users/jerrygb/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2019-10-25T11:17:57Z","updated_at":"2020-04-09T09:52:02Z","closed_at":"2019-10-27T11:32:33Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"### System information\r\n- I have a Keras model with the following layers. I have different behaviours across mlflow on notebook vs mlflow cli\r\n\r\n```\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #\r\n=================================================================\r\ncu_dnnlstm_1 (CuDNNLSTM)     (None, 7, 256)           \r\n_________________________________________________________________\r\ncu_dnnlstm_2 (CuDNNLSTM)     (None, 256)              \r\n_________________________________________________________________\r\nrepeat_vector_1 (RepeatVecto (None, 7, 256)            0\r\n_________________________________________________________________\r\ntime_distributed_1 (TimeDist (None, 7, 17)            \r\n=================================================================\r\n```\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Amazon Linux\r\n- **MLflow installed from (source or binary)**: Tried both\r\n- **MLflow version (run ``mlflow --version``)**: 1.3.0\r\n- **Python version**: 3.6.5\r\n\r\n### Describe the problem\r\n\r\nI have a Keras model (using tf backend) that I am trying to train and deploy. Layers are mentioned above.\r\n\r\n#### Training\r\n\r\nWhen I try to train the model from the notebook directly, under the _conda_tensorflow_p36_ kernel on sagemaker it works as expected. It is able to train properly and run through the epochs. However, with the **mlflow** cli under the MLproject-specific _conda_ environment, it gives me the following exception saying it is unable to allocate the tensor.\r\n\r\n```\r\nWARNING:tensorflow:From /home/ec2-user/anaconda3/envs/mlflow-7da3e8bfa473f83a7a318b2c18ffb21bcea3c3fd/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\r\n\r\nWARNING:tensorflow:From /home/ec2-user/anaconda3/envs/mlflow-7da3e8bfa473f83a7a318b2c18ffb21bcea3c3fd/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholderinstead.\r\n\r\nWARNING:tensorflow:From /home/ec2-user/anaconda3/envs/mlflow-7da3e8bfa473f83a7a318b2c18ffb21bcea3c3fd/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\r\n\r\nWARNING:tensorflow:From /home/ec2-user/anaconda3/envs/mlflow-7da3e8bfa473f83a7a318b2c18ffb21bcea3c3fd/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\r\n\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #\r\n=================================================================\r\ncu_dnnlstm_1 (CuDNNLSTM)     (None, 7, 256)            281600\r\n_________________________________________________________________\r\ncu_dnnlstm_2 (CuDNNLSTM)     (None, 256)               526336\r\n_________________________________________________________________\r\nrepeat_vector_1 (RepeatVecto (None, 7, 256)            0\r\n_________________________________________________________________\r\ntime_distributed_1 (TimeDist (None, 7, 17)             4369\r\n=================================================================\r\nTotal params: 812,305\r\nTrainable params: 812,305\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nWARNING:tensorflow:From /home/ec2-user/anaconda3/envs/mlflow-7da3e8bfa473f83a7a318b2c18ffb21bcea3c3fd/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\r\n\r\nWARNING:tensorflow:From /home/ec2-user/anaconda3/envs/mlflow-7da3e8bfa473f83a7a318b2c18ffb21bcea3c3fd/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\r\n\r\nTrain on 78986 samples, validate on 19986 samples\r\nEpoch 1/50\r\n2019-10-25 10:59:23.704015: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\r\n2019-10-25 10:59:23.752666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-10-25 10:59:23.753197: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564fe59a7100 executing computations on platform CUDA. Devices:\r\n2019-10-25 10:59:23.753225: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\r\n2019-10-25 10:59:23.772660: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300060000 Hz\r\n2019-10-25 10:59:23.772916: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564fe5a17750 executing computations on platform Host. Devices:\r\n2019-10-25 10:59:23.772941: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-10-25 10:59:23.773141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-10-25 10:59:23.773475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:00:1e.0\r\n2019-10-25 10:59:23.773693: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-10-25 10:59:23.774786: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2019-10-25 10:59:23.775819: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n2019-10-25 10:59:23.776071: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n2019-10-25 10:59:23.777596: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-10-25 10:59:23.778671: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-10-25 10:59:23.781792: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2019-10-25 10:59:23.781925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-10-25 10:59:23.782485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-10-25 10:59:23.782914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\n2019-10-25 10:59:23.782995: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-10-25 10:59:23.784325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-10-25 10:59:23.784350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0\r\n2019-10-25 10:59:23.784367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N\r\n2019-10-25 10:59:23.784567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-10-25 10:59:23.785115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-10-25 10:59:23.785580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 133 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\r\n2019-10-25 10:59:24.599541: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2019-10-25 10:59:24.750318: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2019-10-25 10:59:35.383680: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memorytrying to allocate 116.02MiB (rounded to 121655296).  Current allocation summary follows.\r\n2019-10-25 10:59:35.383723: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256):   Total Chunks: 29, Chunks in use: 29. 7.2KiB allocated for chunks. 7.2KiB in use in bin. 384B client-requested in use in bin.\r\n2019-10-25 10:59:35.383735: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512):   Total Chunks: 0, Chunks inuse: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2019-10-25 10:59:35.383744: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024):  Total Chunks: 1, Chunks inuse: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin\r\n...\r\n2019-10-25 10:59:35.383875: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152):       Total Chunks: 4, Chunks in use: 4. 8.01MiB allocated for chunks. 8.01MiB in use in bin. 8.01MiB client-requested in use in bin.\r\n2019-10-25 10:59:35.383883: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2019-10-25 10:59:35.383892: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608):       Total Chunks: 1, Chunks in use: 1. 14.00MiB allocated for chunks. 14.00MiB in use in bin. 14.00MiB client-requested in use in bin.\r\n2019-10-25 10:59:35.383900: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n...\r\n2019-10-25 10:59:35.383934: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456):     Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2019-10-25 10:59:35.383943: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 116.02MiB was 64.00MiB, Chunk State:\r\n2019-10-25 10:59:35.383957: I tensorflow/core/common_runtime/bfc_allocator.cc:786]   Size: 93.08MiB | Requested Size: 256.0KiB | in_use: 0 | bin_num: 18, prev:   Size: 2.00MiB | Requested Size: 2.00MiB | in_use: 1 | bin_num: -1\r\n2019-10-25 10:59:35.383969: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 140181504\r\n2019-10-25 10:59:35.383977: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203b60000 next 1 of size 1280\r\n2019-10-25 10:59:35.383985: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203b60500 next 2 of size 256\r\n2019-10-25 10:59:35.383991: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203b60600 next 3 of size 17408\r\n2019-10-25 10:59:35.383998: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203b64a00 next 4 of size 8192\r\n2019-10-25 10:59:35.384005: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203b66a00 next 5 of size 1048576\r\n2019-10-25 10:59:35.384012: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203c66a00 next 6 of size 69632\r\n2019-10-25 10:59:35.384018: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203c77a00 next 7 of size 256\r\n2019-10-25 10:59:35.384024: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203c77b00 next 8 of size 256\r\n2019-10-25 10:59:35.384030: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203c77c00 next 9 of size 1048576\r\n2019-10-25 10:59:35.384037: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203d77c00 next 10 of size 256\r\n2019-10-25 10:59:35.384042: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203d77d00 next 11 of size 256\r\n2019-10-25 10:59:35.384049: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203d77e00 next 12 of size 8192\r\n2019-10-25 10:59:35.384054: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203d79e00 next 13 of size 1048576\r\n2019-10-25 10:59:35.384061: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203e79e00 next 14 of size 256\r\n...\r\n2019-10-25 10:59:35.384103: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203e7a500 next 21 of size 1048576\r\n2019-10-25 10:59:35.384110: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203f7a500 next 22 of size 17408\r\n2019-10-25 10:59:35.384117: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203f7e900 next 23 of size 8192\r\n2019-10-25 10:59:35.384123: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1203f80900 next 24 of size 1048576\r\n2019-10-25 10:59:35.384130: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1204080900 next 25 of size 1048576\r\n2019-10-25 10:59:35.384135: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1204180900 next 26 of size 69632\r\n2019-10-25 10:59:35.384142: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1204191900 next 27 of size 256\r\n2019-10-25 10:59:35.384147: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1204191a00 next 28 of size 8192\r\n2019-10-25 10:59:35.384154: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1204193a00 next 29 of size 17408\r\n2019-10-25 10:59:35.384162: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1204197e00 next 30 of size 8192\r\n2019-10-25 10:59:35.384176: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1204199e00 next 31 of size 256\r\n...\r\n2019-10-25 10:59:35.384242: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x12044ad300 next 41 of size 256\r\n2019-10-25 10:59:35.384277: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x12044ad900 next 47 of size 974848\r\n2019-10-25 10:59:35.384284: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x120459b900 next 48 of size 8192\r\n2019-10-25 10:59:35.384290: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x120459d900 next 49 of size 974848\r\n2019-10-25 10:59:35.384296: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x120468b900 next 52 of size 256\r\n2019-10-25 10:59:35.384301: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x120468ba00 next 50 of size 1048576\r\n2019-10-25 10:59:35.384307: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x120478ba00 next 51 of size 256\r\n2019-10-25 10:59:35.384314: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x120478bb00 next 53 of size 69632\r\n2019-10-25 10:59:35.384321: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x120479cb00 next 54 of size 256\r\n2019-10-25 10:59:35.384326: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x120479cc00 next 74 of size 1904640\r\n2019-10-25 10:59:35.384332: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x120496dc00 next 79 of size 17408\r\n2019-10-25 10:59:35.384338: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1204972000 next 80 of size 8192\r\n2019-10-25 10:59:35.384343: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1204974000 next 81 of size 8192\r\n2019-10-25 10:59:35.384350: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1204976000 next 63 of size 1133568\r\n2019-10-25 10:59:35.384355: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x1204a8ac00 next 64 of size 262144\r\n2019-10-25 10:59:35.384362: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1204acac00 next 76 of size 256\r\n2019-10-25 10:59:35.384367: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1204acad00 next 78 of size 256\r\n2019-10-25 10:59:35.384373: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x1204acae00 next 66 of size 269824\r\n2019-10-25 10:59:35.384379: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1204b0cc00 next 67 of size 2097152\r\n2019-10-25 10:59:35.384384: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1204d0cc00 next 72 of size 974848\r\n2019-10-25 10:59:35.384391: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1204dfac00 next 75 of size 1048576\r\n2019-10-25 10:59:35.384396: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1204efac00 next 77 of size 1048576\r\n2019-10-25 10:59:35.384402: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1204ffac00 next 82 of size 2105344\r\n2019-10-25 10:59:35.384408: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x12051fcc00 next 65 of size 14680064\r\n2019-10-25 10:59:35.384414: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x1205ffcc00 next 59 of size 2097152\r\n2019-10-25 10:59:35.384420: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x12061fcc00 next 68 of size 2097152\r\n2019-10-25 10:59:35.384426: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x12063fcc00 next 18446744073709551615 of size 97596416\r\n2019-10-25 10:59:35.384432: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size:\r\n2019-10-25 10:59:35.384439: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 29 Chunks of size 256 totalling 7.2KiB\r\n2019-10-25 10:59:35.384456: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1280 totalling 1.2KiB\r\n2019-10-25 10:59:35.384465: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 9 Chunks of size 8192 totalling 72.0KiB\r\n2019-10-25 10:59:35.384475: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 17408 totalling 68.0KiB\r\n...\r\n2019-10-25 10:59:35.384560: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 2105344 totalling 2.01MiB\r\n2019-10-25 10:59:35.384568: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 14680064 totalling 14.00MiB\r\n2019-10-25 10:59:35.384574: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 37.36MiB\r\n2019-10-25 10:59:35.384587: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 140181504 memory_limit_: 140181504 available bytes: 0 curr_region_allocation_bytes_: 280363008\r\n2019-10-25 10:59:35.384602: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats:\r\nLimit:                   140181504\r\nInUse:                    39173632\r\nMaxInUse:                 39173632\r\nNumAllocs:                      92\r\nMaxAllocSize:             14680064\r\n\r\n2019-10-25 10:59:35.384625: W tensorflow/core/common_runtime/bfc_allocator.cc:319] *******************************_____________________________________________________________________\r\n2019-10-25 10:59:35.384664: E tensorflow/stream_executor/dnn.cc:588] OOM when allocating tensor with shape[121655296] and type uint8 on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n2019-10-25 10:59:35.384699: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at cudnn_rnn_ops.cc:1336 : Internal: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size]: [1, 17, 256, 1, 7, 2048]\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 346, in <module>\r\n    run()\r\n  File \"/home/ec2-user/anaconda3/envs/mlflow-7da3e8bfa473f83a7a318b2c18ffb21bcea3c3fd/lib/python3.6/site-packages/click/core.py\", line 764, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/home/ec2-user/anaconda3/envs/mlflow-7da3e8bfa473f83a7a318b2c18ffb21bcea3c3fd/lib/python3.6/site-packages/click/core.py\", line 717, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/home/ec2-user/anaconda3/envs/mlflow-7da3e8bfa473f83a7a318b2c18ffb21bcea3c3fd/lib/python3.6/site-packages/click/core.py\", line 956, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/home/ec2-user/anaconda3/envs/mlflow-7da3e8bfa473f83a7a318b2c18ffb21bcea3c3fd/lib/python3.6/site-packages/click/core.py\", line 555, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"main.py\", line 280, in run\r\n    (X_validation, y_validation), patience)\r\n  File \"/home/ec2-user/SageMaker/models/network_architecture.py\", line 501, in train_model\r\n    shuffle=shuffle, verbose=2, callbacks=[early_stopping, checkpoint])\r\n  File \"/home/ec2-user/anaconda3/envs/mlflow-7da3e8bfa473f83a7a318b2c18ffb21bcea3c3fd/lib/python3.6/site-packages/mlflow/keras.py\", line 393, in fit\r\n    return original(self, *args, **kwargs)\r\n  File \"/home/ec2-user/anaconda3/envs/mlflow-7da3e8bfa473f83a7a318b2c18ffb21bcea3c3fd/lib/python3.6/site-packages/keras/engine/training.py\", line 1039, in fit\r\n    validation_steps=validation_steps)\r\n  File \"/home/ec2-user/anaconda3/envs/mlflow-7da3e8bfa473f83a7a318b2c18ffb21bcea3c3fd/lib/python3.6/site-packages/keras/engine/training_arrays.py\", line 199, in fit_loop\r\n    outs = f(ins_batch)\r\n  File \"/home/ec2-user/anaconda3/envs/mlflow-7da3e8bfa473f83a7a318b2c18ffb21bcea3c3fd/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2715, in __call__\r\n    return self._call(inputs)\r\n  File \"/home/ec2-user/anaconda3/envs/mlflow-7da3e8bfa473f83a7a318b2c18ffb21bcea3c3fd/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2675, in _call\r\n    fetched = self._callable_fn(*array_vals)\r\n  File \"/home/ec2-user/anaconda3/envs/mlflow-7da3e8bfa473f83a7a318b2c18ffb21bcea3c3fd/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1458, in __call__\r\n    run_metadata_ptr)\r\ntensorflow.python.framework.errors_impl.InternalError: 2 root error(s) found.\r\n  (0) Internal: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 ,[num_layers, input_size, num_units, dir_count, max_seq_length, batch_size]: [1, 17, 256, 1, 7, 2048]\r\n         [[{{node cu_dnnlstm_1/CudnnRNN}}]]\r\n         [[loss/mul/_69]]\r\n  (1) Internal: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 ,[num_layers, input_size, num_units, dir_count, max_seq_length, batch_size]: [1, 17, 256, 1, 7, 2048]\r\n         [[{{node cu_dnnlstm_1/CudnnRNN}}]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n2019/10/25 10:59:35 ERROR mlflow.cli: === Run (ID '74ca171f5f5c49748ccb97fced60ad0c') failed ===\r\n```\r\n\r\n#### Inference over Sagemaker Endpoint\r\n\r\nWhen I try to deploy the model onto sagemaker I receive the same issue, with GPU memory leak logged several times. \r\n\r\n```\r\n2019-10-25 09:49:40.267686: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 138.0K (141312 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n...\r\n...\r\n2019-10-25 09:49:44.991419: F tensorflow/stream_executor/cuda/cuda_driver.cc:175] Check failed: err == cudaSuccess || err == cudaErrorInvalidValue Unexpected CUDA error: out of memory\r\n...\r\n2019-10-25 09:49:51.501824: E tensorflow/core/common_runtime/executor.cc:641] Executor failed to create kernel. Resource exhausted: OOM when allocating tensor of shape [256,1024] and type float\r\n...\r\n2019-10-25 09:49:51.506818: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats:\r\nLimit: 13617207706\r\nInUse: 2048\r\nMaxInUse: 2048\r\nNumAllocs: 4\r\nMaxAllocSize: 1280\r\n...\r\n[2019-10-25 09:49:51 +0000] [751] [ERROR] Exception in worker process\r\nTraceback (most recent call last):\r\nFile \"/miniconda/envs/custom_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1356, in _do_call\r\nreturn fn(*args)\r\nFile \"/miniconda/envs/custom_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1341, in _run_fn\r\noptions, feed_dict, fetch_list, target_list, run_metadata)\r\nFile \"/miniconda/envs/custom_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1429, in _call_tf_sessionrun\r\nrun_metadata)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor of shape [256,1024] and type float\r\n```\r\n\r\nAdditionally, I can see the _gunicorn_ booting sequence for a certain number of workers over and over again.\r\n\r\nWhat I do not quite understand is how the training works fine within the notebook conda environment and not on the custom mlflow conda environment. \r\n\r\nI have the following for `conda.yaml` for the MLproject,\r\n\r\n```\r\nname: my-model\r\nchannels:\r\n  - defaults\r\ndependencies:\r\n  - python=3.6\r\n  - pip:\r\n      - https://tensorflow-aws.s3-us-west-2.amazonaws.com/1.14/AmazonLinux/gpu/final/tensorflow-1.14.0-cp36-cp36m-linux_x86_64.whl\r\n      - keras==2.2.4\r\n      - mlflow\r\n      - boto3\r\n      - scikit-learn==0.20.3\r\n      - matplotlib==2.2.2\r\n      - progressbar\r\n      - h5py\r\n      - seaborn\r\n      - pydot\r\n```\r\n","closed_by":{"login":"jerrygb","id":1516634,"node_id":"MDQ6VXNlcjE1MTY2MzQ=","avatar_url":"https://avatars.githubusercontent.com/u/1516634?v=4","gravatar_id":"","url":"https://api.github.com/users/jerrygb","html_url":"https://github.com/jerrygb","followers_url":"https://api.github.com/users/jerrygb/followers","following_url":"https://api.github.com/users/jerrygb/following{/other_user}","gists_url":"https://api.github.com/users/jerrygb/gists{/gist_id}","starred_url":"https://api.github.com/users/jerrygb/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jerrygb/subscriptions","organizations_url":"https://api.github.com/users/jerrygb/orgs","repos_url":"https://api.github.com/users/jerrygb/repos","events_url":"https://api.github.com/users/jerrygb/events{/privacy}","received_events_url":"https://api.github.com/users/jerrygb/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/1993/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/1993/timeline","performed_via_github_app":null,"state_reason":"completed"}