{"url":"https://api.github.com/repos/mlflow/mlflow/issues/7304","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/7304/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/7304/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/7304/events","html_url":"https://github.com/mlflow/mlflow/issues/7304","id":1443687830,"node_id":"I_kwDOCB5Jx85WDO2W","number":7304,"title":"[BUG] mlflow.spark.load_model fails with NotADirectoryError ","user":{"login":"pravingadakh","id":13175315,"node_id":"MDQ6VXNlcjEzMTc1MzE1","avatar_url":"https://avatars.githubusercontent.com/u/13175315?v=4","gravatar_id":"","url":"https://api.github.com/users/pravingadakh","html_url":"https://github.com/pravingadakh","followers_url":"https://api.github.com/users/pravingadakh/followers","following_url":"https://api.github.com/users/pravingadakh/following{/other_user}","gists_url":"https://api.github.com/users/pravingadakh/gists{/gist_id}","starred_url":"https://api.github.com/users/pravingadakh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pravingadakh/subscriptions","organizations_url":"https://api.github.com/users/pravingadakh/orgs","repos_url":"https://api.github.com/users/pravingadakh/repos","events_url":"https://api.github.com/users/pravingadakh/events{/privacy}","received_events_url":"https://api.github.com/users/pravingadakh/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":{"login":"harupy","id":17039389,"node_id":"MDQ6VXNlcjE3MDM5Mzg5","avatar_url":"https://avatars.githubusercontent.com/u/17039389?v=4","gravatar_id":"","url":"https://api.github.com/users/harupy","html_url":"https://github.com/harupy","followers_url":"https://api.github.com/users/harupy/followers","following_url":"https://api.github.com/users/harupy/following{/other_user}","gists_url":"https://api.github.com/users/harupy/gists{/gist_id}","starred_url":"https://api.github.com/users/harupy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harupy/subscriptions","organizations_url":"https://api.github.com/users/harupy/orgs","repos_url":"https://api.github.com/users/harupy/repos","events_url":"https://api.github.com/users/harupy/events{/privacy}","received_events_url":"https://api.github.com/users/harupy/received_events","type":"User","site_admin":false},"assignees":[{"login":"harupy","id":17039389,"node_id":"MDQ6VXNlcjE3MDM5Mzg5","avatar_url":"https://avatars.githubusercontent.com/u/17039389?v=4","gravatar_id":"","url":"https://api.github.com/users/harupy","html_url":"https://github.com/harupy","followers_url":"https://api.github.com/users/harupy/followers","following_url":"https://api.github.com/users/harupy/following{/other_user}","gists_url":"https://api.github.com/users/harupy/gists{/gist_id}","starred_url":"https://api.github.com/users/harupy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harupy/subscriptions","organizations_url":"https://api.github.com/users/harupy/orgs","repos_url":"https://api.github.com/users/harupy/repos","events_url":"https://api.github.com/users/harupy/events{/privacy}","received_events_url":"https://api.github.com/users/harupy/received_events","type":"User","site_admin":false}],"milestone":null,"comments":12,"created_at":"2022-11-10T11:01:44Z","updated_at":"2022-11-22T16:57:07Z","closed_at":"2022-11-22T16:57:06Z","author_association":"NONE","active_lock_reason":null,"body":"### Issues Policy acknowledgement\r\n\r\n- [X] I have read and agree to submit bug reports in accordance with the [issues policy](https://www.github.com/mlflow/mlflow/blob/master/ISSUE_POLICY.md)\r\n\r\n### Willingness to contribute\r\n\r\nNo. I cannot contribute a bug fix at this time.\r\n\r\n### MLflow version\r\n\r\n- Client: 1.24.0\r\n- Tracking server: 1.24.0\r\n\r\n\r\n### System information\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Python version**:\r\n- **yarn version, if running the dev UI**:\r\n- pyspark: 2.4.8\r\n- python: 3.7.0\r\n\r\n### Describe the problem\r\n\r\nI am trying to log a simple pyspark pipeline model and load it. The load_model API is failing with NotADirectoryError.\r\n\r\n### Tracking information\r\n\r\n_No response_\r\n\r\n### Code to reproduce issue\r\n\r\n```python\r\nfrom pyspark.ml import Pipeline\r\nfrom pyspark.ml.classification import LogisticRegression\r\nfrom pyspark.ml.feature import HashingTF, Tokenizer\r\ntraining = spark.createDataFrame([\r\n    (0, \"a b c d e spark\", 1.0),\r\n    (1, \"b d\", 0.0),\r\n    (2, \"spark f g h\", 1.0),\r\n    (3, \"hadoop mapreduce\", 0.0) ], [\"id\", \"text\", \"label\"])\r\ntokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\r\nhashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\r\nlr = LogisticRegression(maxIter=10, regParam=0.001)\r\npipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\r\nmodel = pipeline.fit(training)\r\n\r\nimport mlflow\r\nimport mlflow.spark\r\nimport logging\r\nlogging.getLogger(\"mlflow\").setLevel(logging.DEBUG)\r\n\r\nmlflow.set_experiment(\"pyspark_mlflow\")\r\nmlflow.spark.log_model(model, \"spark-model\")\r\n```\r\n\r\n```\r\nmodel = mlflow.spark.load_model(\"runs:/<run_id>/spark-model\")\r\n```\r\n\r\n### Stack trace\r\n\r\nfollowing warning I see while logging the model, however the model gets logged \r\n```\r\n2022/11/10 10:47:10 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpjdiqg1b4, flavor: spark), fall back to return ['pyspark==2.4.8']. Set logging level to DEBUG to see the full traceback.\r\n2022/11/10 10:47:10 DEBUG mlflow.utils.environment: \r\nTraceback (most recent call last):\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/utils/environment.py\", line 195, in infer_pip_requirements\r\n    return _infer_requirements(model_uri, flavor)\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/utils/requirements_utils.py\", line 332, in _infer_requirements\r\n    modules = _capture_imported_modules(model_uri, flavor)\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/utils/requirements_utils.py\", line 264, in _capture_imported_modules\r\n    json.dumps(sys.path),\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/utils/requirements_utils.py\", line 205, in _run_command\r\n    raise MlflowException(msg)\r\nmlflow.exceptions.MlflowException: Encountered an unexpected error while running ['/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/bin/python', '/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/utils/_capture_modules.py', '--model-path', '/tmp/tmpjdiqg1b4', '--flavor', 'spark', '--output-file', '/tmp/tmpgk7ffuhu/imported_modules.txt', '--sys-path', '[\"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/tmp\", \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/git/ext/gitdb\", \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/spark-8bfe0ab9-f148-48e7-b80f-ce0f99873adf/userFiles-9d4c6fa2-5a2f-4d72-ab25-c2a5b074bb44\", \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/pyspark.zip\", \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/py4j-0.10.7-src.zip\", \"/usr/lib/spark/python/lib/pyspark.zip\", \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip\", \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/file\", \"/usr/hdp/current/spark/python/lib/pyspark.zip\", \"/usr/hdp/current/spark/python/lib/py4j-0.10.7-src.zip\", \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python37.zip\", \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7\", \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/lib-dynload\", \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages\", \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/IPython/extensions\", \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/gitdb/ext/smmap\"]']\r\nexit status: 1\r\nstdout: \r\nstderr: Traceback (most recent call last):\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/utils/_capture_modules.py\", line 134, in <module>\r\n    main()\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/utils/_capture_modules.py\", line 109, in main\r\n    mlflow.pyfunc.load_model(model_path)\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\", line 710, in load_model\r\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/utils/_capture_modules.py\", line 106, in _load_pyfunc_patch\r\n    return original(*args, **kwargs)\r\n<img width=\"358\" alt=\"Screenshot 2022-11-10 at 4 37 54 PM\" src=\"https://user-images.githubusercontent.com/13175315/201075669-fce1322a-dd6f-4a15-9248-81d2f36f6463.png\">\r\n\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/spark.py\", line 709, in _load_pyfunc\r\n    .master(\"local[1]\")\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/pyspark.zip/pyspark/sql/session.py\", line 173, in getOrCreate\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/pyspark.zip/pyspark/context.py\", line 367, in getOrCreate\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/pyspark.zip/pyspark/context.py\", line 136, in __init__\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/pyspark.zip/pyspark/context.py\", line 198, in _do_init\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/pyspark.zip/pyspark/context.py\", line 306, in _initialize_context\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1525, in __call__\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\r\npy4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\r\n: org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:\r\norg.apache.spark.SparkContext.getOrCreate(SparkContext.scala)\r\norg.apache.livy.rsc.driver.SparkEntries.sc(SparkEntries.java:51)\r\norg.apache.livy.rsc.driver.SparkEntries.sparkSession(SparkEntries.java:72)\r\norg.apache.livy.repl.AbstractSparkInterpreter.postStart(AbstractSparkInterpreter.scala:69)\r\norg.apache.livy.repl.SparkInterpreter$$anonfun$start$1.apply$mcV$sp(SparkInterpreter.scala:95)\r\norg.apache.livy.repl.SparkInterpreter$$anonfun$start$1.apply(SparkInterpreter.scala:70)\r\norg.apache.livy.repl.SparkInterpreter$$anonfun$start$1.apply(SparkInterpreter.scala:70)\r\norg.apache.livy.repl.AbstractSparkInterpreter.restoreContextClassLoader(AbstractSparkInterpreter.scala:340)\r\norg.apache.livy.repl.SparkInterpreter.start(SparkInterpreter.scala:70)\r\norg.apache.livy.repl.Session$$anonfun$1.apply(Session.scala:128)\r\norg.apache.livy.repl.Session$$anonfun$1.apply(Session.scala:122)\r\nscala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\r\nscala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\r\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\njava.lang.Thread.run(Thread.java:748)\r\n\tat org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2498)\r\n\tat org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2494)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2494)\r\n\tat org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2583)\r\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:86)\r\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:238)\r\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\r\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n```\r\n\r\nWhile loading the I'm seeing following error \r\n\r\n```\r\nAn error was encountered:\r\n[Errno 20] Not a directory: '/tmp/tmpr4x31fth/sparkml/metadata'\r\nTraceback (most recent call last):\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/spark.py\", line 682, in load_model\r\n    return _load_model(model_uri=model_uri, dfs_tmpdir_base=dfs_tmpdir)\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/spark.py\", line 633, in _load_model\r\n    model_uri = _HadoopFileSystem.maybe_copy_from_uri(model_uri, dfs_tmpdir)\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/spark.py\", line 371, in maybe_copy_from_uri\r\n    return cls.maybe_copy_from_local_file(_download_artifact_from_uri(src_uri), dst_path)\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/tracking/artifact_utils.py\", line 96, in _download_artifact_from_uri\r\n    artifact_path=artifact_path, dst_path=output_path\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/store/artifact/artifact_repo.py\", line 243, in download_artifacts\r\n    src_artifact_dir_path=artifact_path, dst_local_dir_path=dst_path\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/store/artifact/artifact_repo.py\", line 210, in async_download_artifact_dir\r\n    dst_local_dir_path=dst_local_dir_path,\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/store/artifact/artifact_repo.py\", line 215, in async_download_artifact_dir\r\n    dst_local_dir_path=dst_local_dir_path,\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/store/artifact/artifact_repo.py\", line 155, in async_download_artifact\r\n    src_artifact_path=src_artifact_path, dst_local_dir_path=dst_local_dir_path\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/site-packages/mlflow/store/artifact/artifact_repo.py\", line 107, in _create_download_destination\r\n    os.makedirs(local_dir_path, exist_ok=True)\r\n  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1668075950962_0002/container_e01_1668075950962_0002_01_000001/mllibs/lib/python3.7/os.py\", line 221, in makedirs\r\n    mkdir(name, mode)\r\nNotADirectoryError: [Errno 20] Not a directory: '/tmp/tmpr4x31fth/sparkml/metadata'\r\n```\r\n\r\n### Other info / logs\r\n\r\n_No response_\r\n\r\n### What component(s) does this bug affect?\r\n\r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/recipes`: Recipes, Recipe APIs, Recipe configs, Recipe Templates\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n### What interface(s) does this bug affect?\r\n\r\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\n### What language(s) does this bug affect?\r\n\r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\n### What integration(s) does this bug affect?\r\n\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations","closed_by":{"login":"pravingadakh","id":13175315,"node_id":"MDQ6VXNlcjEzMTc1MzE1","avatar_url":"https://avatars.githubusercontent.com/u/13175315?v=4","gravatar_id":"","url":"https://api.github.com/users/pravingadakh","html_url":"https://github.com/pravingadakh","followers_url":"https://api.github.com/users/pravingadakh/followers","following_url":"https://api.github.com/users/pravingadakh/following{/other_user}","gists_url":"https://api.github.com/users/pravingadakh/gists{/gist_id}","starred_url":"https://api.github.com/users/pravingadakh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pravingadakh/subscriptions","organizations_url":"https://api.github.com/users/pravingadakh/orgs","repos_url":"https://api.github.com/users/pravingadakh/repos","events_url":"https://api.github.com/users/pravingadakh/events{/privacy}","received_events_url":"https://api.github.com/users/pravingadakh/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/7304/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/7304/timeline","performed_via_github_app":null,"state_reason":"completed"}