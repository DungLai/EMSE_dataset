{"url":"https://api.github.com/repos/mlflow/mlflow/issues/5528","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/5528/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/5528/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/5528/events","html_url":"https://github.com/mlflow/mlflow/issues/5528","id":1180286640,"node_id":"I_kwDOCB5Jx85GWb6w","number":5528,"title":"[BUG] mlflow.start_run(...) causes XLA crash with TensorFlow 2.8.0 on a TPU v2-8","user":{"login":"froody","id":241317,"node_id":"MDQ6VXNlcjI0MTMxNw==","avatar_url":"https://avatars.githubusercontent.com/u/241317?v=4","gravatar_id":"","url":"https://api.github.com/users/froody","html_url":"https://github.com/froody","followers_url":"https://api.github.com/users/froody/followers","following_url":"https://api.github.com/users/froody/following{/other_user}","gists_url":"https://api.github.com/users/froody/gists{/gist_id}","starred_url":"https://api.github.com/users/froody/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/froody/subscriptions","organizations_url":"https://api.github.com/users/froody/orgs","repos_url":"https://api.github.com/users/froody/repos","events_url":"https://api.github.com/users/froody/events{/privacy}","received_events_url":"https://api.github.com/users/froody/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-03-25T03:06:00Z","updated_at":"2022-03-25T03:06:00Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Thank you for submitting an issue. Please refer to our [issue policy](https://www.github.com/mlflow/mlflow/blob/master/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https://stackoverflow.com/questions/tagged/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [X] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04\r\n- **MLflow installed from (source or binary)**: installed via `pip install`\r\n- **MLflow version (run ``mlflow --version``)**: 1.24.0\r\n- **Python version**: 3.8.10\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n`python testcase.py # See below`\r\n\r\n### Describe the problem\r\nXLA fails with:\r\n```\r\n2022-03-25 02:53:54.890552: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at xla_compile_on_demand_op.cc:183 : INTERNAL: Core halted unexpectedly: No error message available as no compiler metadata was provided.\r\n```\r\n\r\n### Code to reproduce issue\r\n```\r\n# testcase.py\r\nimport mlflow\r\nimport tensorflow as tf\r\n\r\ndef init_tf_gpus():\r\n    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\r\n    tf.config.experimental_connect_to_cluster(resolver)\r\n    # This is the TPU initialization code that has to be at the beginning.\r\n    tf.tpu.experimental.initialize_tpu_system(resolver)\r\n    print(\"All devices: \", tf.config.list_logical_devices('TPU'))\r\n\r\n    tf.config.optimizer.set_jit(True)\r\n\r\n    return tf.distribute.TPUStrategy(resolver)\r\n\r\ndef main():\r\n    strategy = init_tf_gpus()\r\n    with mlflow.start_run(run_name=\"test\"): # disable this line to make it work\r\n        with strategy.scope():\r\n            seq = tf.keras.Sequential([tf.keras.layers.Dense(512)])\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\n\r\n### Other info / logs\r\n\r\nMust be run on a GCP TPU instance, I was using a \"v2-8\" instance running \"tpu-vm-tf-2.8.0 \"\r\n\r\n```\r\n2022-03-25 03:01:14.053145: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:116] Libtpu path is: libtpu.so\r\n2022-03-25 03:01:15.555809: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2022-03-25 03:01:29.331594: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x429e9c0 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\r\n2022-03-25 03:01:29.331633: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): TPU, 2a886c8\r\n2022-03-25 03:01:29.331640: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (1): TPU, 2a886c8\r\n2022-03-25 03:01:29.331646: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (2): TPU, 2a886c8\r\n2022-03-25 03:01:29.331656: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (3): TPU, 2a886c8\r\n2022-03-25 03:01:29.331664: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (4): TPU, 2a886c8\r\n2022-03-25 03:01:29.331671: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (5): TPU, 2a886c8\r\n2022-03-25 03:01:29.331681: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (6): TPU, 2a886c8\r\n2022-03-25 03:01:29.331694: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (7): TPU, 2a886c8\r\nAll devices:  [LogicalDevice(name='/device:TPU:0', device_type='TPU'), LogicalDevice(name='/device:TPU:1', device_type='TPU'), LogicalDevice(name='/device:TPU:2', device_type='TPU'), LogicalDevice(name='/device:TPU:3', device_type='TPU'), LogicalDevice(name='/device:TPU:4', device_type='TPU'), LogicalDevice(name='/device:TPU:5', device_type='TPU'), LogicalDevice(name='/device:TPU:6', device_type='TPU'), LogicalDevice(name='/device:TPU:7', device_type='TPU')]\r\n2022-03-25 03:01:56.679371: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\r\n2022-03-25 03:01:56.701447: I tensorflow/compiler/jit/xla_compilation_cache.cc:399] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\r\n2022-03-25 03:01:56.703897: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at xla_compile_on_demand_op.cc:183 : INTERNAL: Core halted unexpectedly: No error message available as no compiler metadata was provided.\r\nTraceback (most recent call last):\r\n  File \"testcase.py\", line 23, in <module>\r\n    main()\r\n  File \"testcase.py\", line 19, in main\r\n    seq = tf.keras.Sequential([tf.keras.layers.Dense(512)])\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/tracking/base.py\", line 629, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\", line 102, in convert_to_eager_tensor\r\n    return ops.EagerTensor(value, ctx.device_name, dtype)\r\ntensorflow.python.framework.errors_impl.InternalError: Core halted unexpectedly: No error message available as no compiler metadata was provided.\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/5528/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/5528/timeline","performed_via_github_app":null,"state_reason":null}