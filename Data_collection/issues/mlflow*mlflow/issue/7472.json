{"url":"https://api.github.com/repos/mlflow/mlflow/issues/7472","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/7472/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/7472/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/7472/events","html_url":"https://github.com/mlflow/mlflow/issues/7472","id":1482116772,"node_id":"I_kwDOCB5Jx85YV06k","number":7472,"title":"[FR] Allow custom evaluation metrics to leverage `self.y_probs`","user":{"login":"gphillips-ema","id":56265525,"node_id":"MDQ6VXNlcjU2MjY1NTI1","avatar_url":"https://avatars.githubusercontent.com/u/56265525?v=4","gravatar_id":"","url":"https://api.github.com/users/gphillips-ema","html_url":"https://github.com/gphillips-ema","followers_url":"https://api.github.com/users/gphillips-ema/followers","following_url":"https://api.github.com/users/gphillips-ema/following{/other_user}","gists_url":"https://api.github.com/users/gphillips-ema/gists{/gist_id}","starred_url":"https://api.github.com/users/gphillips-ema/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gphillips-ema/subscriptions","organizations_url":"https://api.github.com/users/gphillips-ema/orgs","repos_url":"https://api.github.com/users/gphillips-ema/repos","events_url":"https://api.github.com/users/gphillips-ema/events{/privacy}","received_events_url":"https://api.github.com/users/gphillips-ema/received_events","type":"User","site_admin":false},"labels":[{"id":955449434,"node_id":"MDU6TGFiZWw5NTU0NDk0MzQ=","url":"https://api.github.com/repos/mlflow/mlflow/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":2022848043,"node_id":"MDU6TGFiZWwyMDIyODQ4MDQz","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/models","name":"area/models","color":"48eabc","default":false,"description":"MLmodel format, model serialization/deserialization, flavors"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2022-12-07T14:57:12Z","updated_at":"2022-12-16T00:28:06Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"### Willingness to contribute\n\nYes. I can contribute this feature independently.\n\n### Proposal Summary\n\nCurrently custom evaluation metrics are limited in that they can only access the model predictions and not the predicted probabilities. This limits possibilities for monitoring metrics that leverage probability (e.g. top k accuracy). \r\n\r\nI propose that in a similar fashion to how `mlflow.models.evaluation.default_evaluator.DefaultEvaluator._compute_builtin_metrics` passes `self.y_probs` to the builtin evaluation metrics, `mlflow.models.evaluation.default_evaluator.DefaultEvaluator._evaluate_custom_metrics_and_log_produced_artifacts` should also be able to pass the probabilities along to custom evaluators (if they are present).\n\n### Motivation\n\n> #### What is the use case for this feature?\r\nEnable custom evaluation metrics such as top_k accuracy and other custom metrics that leverage probabilities\r\n> #### Why is this use case valuable to support for MLflow users in general?\r\nIncluding probabilities for custom metrics would enable users to develop more advanced metrics in general.\r\n> #### Why is this use case valuable to support for your project(s) or organization?\r\nMy organization utilized top_k accuracy for monitoring model performance on a nested category structures. Monitoring top_k accuracy at both the terminal and parent levels.\r\n> #### Why is it currently difficult to achieve this use case?\r\nModel probabilities are not available to custom evaluation metrics.\n\n### Details\n\n_No response_\n\n### What component(s) does this bug affect?\n\n- [ ] `area/artifacts`: Artifact stores and artifact logging\n- [ ] `area/build`: Build and test infrastructure for MLflow\n- [ ] `area/docs`: MLflow documentation pages\n- [ ] `area/examples`: Example code\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\n- [X] `area/models`: MLmodel format, model serialization/deserialization, flavors\n- [ ] `area/recipes`: Recipes, Recipe APIs, Recipe configs, Recipe Templates\n- [ ] `area/projects`: MLproject format, project running backends\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\n- [ ] `area/server-infra`: MLflow Tracking server backend\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\n\n### What interface(s) does this bug affect?\n\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\n- [ ] `area/windows`: Windows support\n\n### What language(s) does this bug affect?\n\n- [ ] `language/r`: R APIs and clients\n- [ ] `language/java`: Java APIs and clients\n- [ ] `language/new`: Proposals for new client languages\n\n### What integration(s) does this bug affect?\n\n- [ ] `integrations/azure`: Azure and Azure ML integrations\n- [ ] `integrations/sagemaker`: SageMaker integrations\n- [ ] `integrations/databricks`: Databricks integrations","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/7472/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/7472/timeline","performed_via_github_app":null,"state_reason":null}