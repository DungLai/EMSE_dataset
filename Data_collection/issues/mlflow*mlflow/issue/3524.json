{"url":"https://api.github.com/repos/mlflow/mlflow/issues/3524","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/3524/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/3524/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/3524/events","html_url":"https://github.com/mlflow/mlflow/issues/3524","id":720915310,"node_id":"MDU6SXNzdWU3MjA5MTUzMTA=","number":3524,"title":"[FR] When going back to experiment view from comparison views, keep previously compared runs selected","user":{"login":"jeisinge","id":8866793,"node_id":"MDQ6VXNlcjg4NjY3OTM=","avatar_url":"https://avatars.githubusercontent.com/u/8866793?v=4","gravatar_id":"","url":"https://api.github.com/users/jeisinge","html_url":"https://github.com/jeisinge","followers_url":"https://api.github.com/users/jeisinge/followers","following_url":"https://api.github.com/users/jeisinge/following{/other_user}","gists_url":"https://api.github.com/users/jeisinge/gists{/gist_id}","starred_url":"https://api.github.com/users/jeisinge/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jeisinge/subscriptions","organizations_url":"https://api.github.com/users/jeisinge/orgs","repos_url":"https://api.github.com/users/jeisinge/repos","events_url":"https://api.github.com/users/jeisinge/events{/privacy}","received_events_url":"https://api.github.com/users/jeisinge/received_events","type":"User","site_admin":false},"labels":[{"id":955449434,"node_id":"MDU6TGFiZWw5NTU0NDk0MzQ=","url":"https://api.github.com/repos/mlflow/mlflow/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":1470945519,"node_id":"MDU6TGFiZWwxNDcwOTQ1NTE5","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/uiux","name":"area/uiux","color":"ede978","default":false,"description":"Front-end, user experience, plotting, JavaScript, JavaScript dev server"},{"id":2114036915,"node_id":"MDU6TGFiZWwyMTE0MDM2OTE1","url":"https://api.github.com/repos/mlflow/mlflow/labels/integrations/databricks","name":"integrations/databricks","color":"ffbce5","default":false,"description":"Databricks integrations"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-10-13T22:18:16Z","updated_at":"2020-10-13T22:18:33Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"# Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ X ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nWhen clicking back to the experiment from any of the comparison views (tabular or graph), the Runs are all unselected.  Instead, it would be great if the previously selected runs from the comparison views were pre-selected.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nWhen we are comparing our runs via the graph view, we often think about another run we want to compare.\r\n\r\n- Why is this use case valuable to support for MLflow users in general?\r\nThis makes adding runs to an existing comparison plot easier.\r\n\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nSaves time.\r\n\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nToday, our workflow is not ideal:\r\n1. First, open up the comparison view.\r\n2. Open up the experiment in a new tab.\r\n3. Find the run.\r\n4. Click on it.\r\n5. From the URL, copy the MLFlow experiment ID.\r\n6. Go back to the comparison view.\r\n7. Manually edit the URL to add the new experiment.\r\n8. Hit enter.\r\n9. Reload the page.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ X ] `area/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ X ] `integrations/databricks`: Databricks integrations","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/3524/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/3524/timeline","performed_via_github_app":null,"state_reason":null}