{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4696","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/4696/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/4696/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/4696/events","html_url":"https://github.com/mlflow/mlflow/issues/4696","id":969368300,"node_id":"MDU6SXNzdWU5NjkzNjgzMDA=","number":4696,"title":"mlflow.pytorch.autolog does not work with Multi GPU [BUG]","user":{"login":"vjkravi","id":2879344,"node_id":"MDQ6VXNlcjI4NzkzNDQ=","avatar_url":"https://avatars.githubusercontent.com/u/2879344?v=4","gravatar_id":"","url":"https://api.github.com/users/vjkravi","html_url":"https://github.com/vjkravi","followers_url":"https://api.github.com/users/vjkravi/followers","following_url":"https://api.github.com/users/vjkravi/following{/other_user}","gists_url":"https://api.github.com/users/vjkravi/gists{/gist_id}","starred_url":"https://api.github.com/users/vjkravi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vjkravi/subscriptions","organizations_url":"https://api.github.com/users/vjkravi/orgs","repos_url":"https://api.github.com/users/vjkravi/repos","events_url":"https://api.github.com/users/vjkravi/events{/privacy}","received_events_url":"https://api.github.com/users/vjkravi/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":2022849295,"node_id":"MDU6TGFiZWwyMDIyODQ5Mjk1","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/tracking","name":"area/tracking","color":"48eabc","default":false,"description":"Tracking service, tracking client APIs, autologging"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-08-12T18:49:32Z","updated_at":"2021-08-13T16:39:32Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Thank you for submitting an issue. Please refer to our [issue policy](https://www.github.com/mlflow/mlflow/blob/master/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https://stackoverflow.com/questions/tagged/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04 \r\n- **MLflow installed from (source or binary)**: pip\r\n- **MLflow version (run ``mlflow --version``)**: 1.19.0\r\n- **Python version**: 3.8\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: Run the code snippet in a multi gpu node\r\n\r\n### Describe the problem\r\nWhen mlflow.pytorch.autolog() is used in multi gpu (ddp_spawn) context, it fails with the following error - AttributeError: Can't pickle local object '_create_patch_fit.<locals>.getPLCallback.<locals>.__MLflowPLCallback'\r\n\r\n### Code to reproduce issue\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nSample Code:\r\n```python\r\nimport mlflow\r\nimport os\r\nimport torch\r\nimport torch.nn as nn\r\nimport pytorch_lightning as pl\r\nfrom torch.nn import functional as F\r\nfrom torch.utils.data import DataLoader, random_split\r\nfrom torchvision import transforms\r\nfrom torchvision.datasets import MNIST\r\nfrom pytorch_lightning.metrics.functional import accuracy\r\nimport mlflow.pytorch\r\nfrom torchvision.datasets import MNIST\r\nfrom torchvision import datasets, transforms\r\nimport os\r\n\r\nclass LightningMNISTClassifier(pl.LightningModule):\r\n\r\n  def __init__(self):\r\n    super(LightningMNISTClassifier, self).__init__()\r\n\r\n    # mnist images are (1, 28, 28) (channels, width, height) \r\n    self.layer_1 = torch.nn.Linear(28 * 28, 128)\r\n    self.layer_2 = torch.nn.Linear(128, 256)\r\n    self.layer_3 = torch.nn.Linear(256, 10)\r\n\r\n  def forward(self, x):\r\n      batch_size, channels, width, height = x.size()\r\n\r\n      # (b, 1, 28, 28) -> (b, 1*28*28)\r\n      x = x.view(batch_size, -1)\r\n\r\n      # layer 1 (b, 1*28*28) -> (b, 128)\r\n      x = self.layer_1(x)\r\n      x = torch.relu(x)\r\n\r\n      # layer 2 (b, 128) -> (b, 256)\r\n      x = self.layer_2(x)\r\n      x = torch.relu(x)\r\n\r\n      # layer 3 (b, 256) -> (b, 10)\r\n      x = self.layer_3(x)\r\n\r\n      # probability distribution over labels\r\n      x = torch.log_softmax(x, dim=1)\r\n\r\n      return x\r\n\r\n  def cross_entropy_loss(self, logits, labels):\r\n    return F.nll_loss(logits, labels)\r\n\r\n  def training_step(self, train_batch, batch_idx):\r\n      x, y = train_batch\r\n      logits = self.forward(x)\r\n      loss = self.cross_entropy_loss(logits, y)\r\n\r\n      logs = {'train_loss': loss}\r\n      return {'loss': loss, 'log': logs}\r\n\r\n  def validation_step(self, val_batch, batch_idx):\r\n      x, y = val_batch\r\n      logits = self.forward(x)\r\n      loss = self.cross_entropy_loss(logits, y)\r\n      return {'val_loss': loss}\r\n\r\n  def validation_epoch_end(self, outputs):\r\n      # called at the end of the validation epoch\r\n      # outputs is an array with what you returned in validation_step for each batch\r\n      # outputs = [{'loss': batch_0_loss}, {'loss': batch_1_loss}, ..., {'loss': batch_n_loss}] \r\n      avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\r\n      tensorboard_logs = {'val_loss': avg_loss}\r\n      return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\r\n\r\n  def prepare_data(self):\r\n    # transforms for images\r\n    transform=transforms.Compose([transforms.ToTensor(), \r\n                                  transforms.Normalize((0.1307,), (0.3081,))])\r\n      \r\n    # prepare transforms standard to MNIST\r\n    mnist_train = MNIST(train=True, download=True, transform=transform)\r\n    mnist_test = MNIST(train=False, download=True, transform=transform)\r\n    \r\n    self.mnist_train, self.mnist_val = random_split(mnist_train, [55000, 5000])\r\n\r\n  def train_dataloader(self):\r\n    return DataLoader(self.mnist_train, batch_size=64)\r\n\r\n  def val_dataloader(self):\r\n    return DataLoader(self.mnist_val, batch_size=64)\r\n\r\n  def test_dataloader(self):\r\n    return DataLoader(self,mnist_test, batch_size=64)\r\n\r\n  def configure_optimizers(self):\r\n    optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\r\n    return optimizer\r\n\r\n## Auto log all MLflow entities\r\nmlflow.pytorch.autolog()\r\nfrom mlflow.tracking import MlflowClient\r\n\r\nwith mlflow.start_run(run_name='mlflow_debug_run') as run:\r\n    from pytorch_lightning.loggers import MLFlowLogger\r\n    experiment_id = run.info.experiment_id\r\n    # get the experiment name\r\n    exp_name = mlflow.get_experiment(experiment_id).name\r\n    # get the mlflow tracking uri\r\n    mlflow_uri = mlflow.get_tracking_uri()\r\n\r\n    mlf_logger = MLFlowLogger(experiment_name=exp_name, tracking_uri=mlflow_uri)\r\n    # link the mlflowlogger run ID to the azureml run ID\r\n    mlf_logger._run_id = run.info.run_id\r\n    model = LightningMNISTClassifier()\r\n    trainer = pl.Trainer(gpus=2, max_epochs=10,accelerator = 'ddp_spawn', logger=mlf_logger)\r\n    trainer.fit(model)\r\n    \r\n```\r\n\r\n### Other info / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n<details>\r\n<summary>Full Traceback: </summary>\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<command-1606990188855480> in <module>\r\n     16     model = LightningMNISTClassifier()\r\n     17     trainer = pl.Trainer(gpus=2, max_epochs=10,accelerator = 'ddp_spawn', logger=mlf_logger)\r\n---> 18     trainer.fit(model)\r\n     19 \r\n\r\n/databricks/python/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py in safe_patch_function(*args, **kwargs)\r\n    490                         patch_function.call(call_original, *args, **kwargs)\r\n    491                     else:\r\n--> 492                         patch_function(call_original, *args, **kwargs)\r\n    493 \r\n    494                     session.state = \"succeeded\"\r\n\r\n/databricks/python/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py in patch_with_managed_run(original, *args, **kwargs)\r\n    240 \r\n    241             try:\r\n--> 242                 result = patch_function(original, *args, **kwargs)\r\n    243             except (Exception, KeyboardInterrupt):\r\n    244                 # In addition to standard Python exceptions, handle keyboard interrupts to ensure\r\n\r\n/databricks/python/lib/python3.8/site-packages/mlflow/pytorch/_pytorch_autolog.py in fit(original, self, *args, **kwargs)\r\n    314         Patching trainer.fit method to add autolog class into callback\r\n    315         \"\"\"\r\n--> 316         return _run_and_log_function(self, original, args, kwargs)\r\n    317 \r\n    318     return fit\r\n\r\n/databricks/python/lib/python3.8/site-packages/mlflow/pytorch/_pytorch_autolog.py in _run_and_log_function(self, original, args, kwargs)\r\n    306         if not any(isinstance(callbacks, __MLflowPLCallback) for callbacks in self.callbacks):\r\n    307             self.callbacks += [__MLflowPLCallback()]\r\n--> 308         result = original(self, *args, **kwargs)\r\n    309 \r\n    310         return result\r\n\r\n/databricks/python/lib/python3.8/site-packages/mlflow/utils/autologging_utils/safety.py in call_original(*og_args, **og_kwargs)\r\n    446                                 disable_warnings=False, reroute_warnings=False,\r\n    447                             ):\r\n--> 448                                 original_result = original(*og_args, **og_kwargs)\r\n    449 \r\n    450                             try_log_autologging_event(\r\n\r\n/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py in fit(self, model, train_dataloader, val_dataloaders, datamodule)\r\n    458         )\r\n    459 \r\n--> 460         self._run(model)\r\n    461 \r\n    462         assert self.state.stopped\r\n\r\n/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py in _run(self, model)\r\n    756 \r\n    757         # dispatch `start_training` or `start_evaluating` or `start_predicting`\r\n--> 758         self.dispatch()\r\n    759 \r\n    760         # plugin will finalized fitting (e.g. ddp_spawn will load trained model)\r\n\r\n/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py in dispatch(self)\r\n    797             self.accelerator.start_predicting(self)\r\n    798         else:\r\n--> 799             self.accelerator.start_training(self)\r\n    800 \r\n    801     def run_stage(self):\r\n\r\n/databricks/python/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py in start_training(self, trainer)\r\n     94 \r\n     95     def start_training(self, trainer: 'pl.Trainer') -> None:\r\n---> 96         self.training_type_plugin.start_training(trainer)\r\n     97 \r\n     98     def start_evaluating(self, trainer: 'pl.Trainer') -> None:\r\n\r\n/databricks/python/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp_spawn.py in start_training(self, trainer)\r\n    120 \r\n    121     def start_training(self, trainer):\r\n--> 122         mp.spawn(self.new_process, **self.mp_spawn_kwargs)\r\n    123         # reset optimizers, since main process is never used for training and thus does not have a valid optim state\r\n    124         trainer.optimizers = []\r\n\r\n/databricks/python/lib/python3.8/site-packages/torch/multiprocessing/spawn.py in spawn(fn, args, nprocs, join, daemon, start_method)\r\n    197                ' torch.multiprocessing.start_process(...)' % start_method)\r\n    198         warnings.warn(msg)\r\n--> 199     return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\r\n\r\n/databricks/python/lib/python3.8/site-packages/torch/multiprocessing/spawn.py in start_processes(fn, args, nprocs, join, daemon, start_method)\r\n    146             daemon=daemon,\r\n    147         )\r\n--> 148         process.start()\r\n    149         error_queues.append(error_queue)\r\n    150         processes.append(process)\r\n\r\n/databricks/python/lib/python3.8/multiprocessing/process.py in start(self)\r\n    119                'daemonic processes are not allowed to have children'\r\n    120         _cleanup()\r\n--> 121         self._popen = self._Popen(self)\r\n    122         self._sentinel = self._popen.sentinel\r\n    123         # Avoid a refcycle if the target function holds an indirect\r\n\r\n/databricks/python/lib/python3.8/multiprocessing/context.py in _Popen(process_obj)\r\n    282         def _Popen(process_obj):\r\n    283             from .popen_spawn_posix import Popen\r\n--> 284             return Popen(process_obj)\r\n    285 \r\n    286     class ForkServerProcess(process.BaseProcess):\r\n\r\n/databricks/python/lib/python3.8/multiprocessing/popen_spawn_posix.py in __init__(self, process_obj)\r\n     30     def __init__(self, process_obj):\r\n     31         self._fds = []\r\n---> 32         super().__init__(process_obj)\r\n     33 \r\n     34     def duplicate_for_child(self, fd):\r\n\r\n/databricks/python/lib/python3.8/multiprocessing/popen_fork.py in __init__(self, process_obj)\r\n     17         self.returncode = None\r\n     18         self.finalizer = None\r\n---> 19         self._launch(process_obj)\r\n     20 \r\n     21     def duplicate_for_child(self, fd):\r\n\r\n/databricks/python/lib/python3.8/multiprocessing/popen_spawn_posix.py in _launch(self, process_obj)\r\n     45         try:\r\n     46             reduction.dump(prep_data, fp)\r\n---> 47             reduction.dump(process_obj, fp)\r\n     48         finally:\r\n     49             set_spawning_popen(None)\r\n\r\n/databricks/python/lib/python3.8/multiprocessing/reduction.py in dump(obj, file, protocol)\r\n     58 def dump(obj, file, protocol=None):\r\n     59     '''Replacement for pickle.dump() using ForkingPickler.'''\r\n---> 60     ForkingPickler(file, protocol).dump(obj)\r\n     61 \r\n     62 #\r\n\r\nAttributeError: Can't pickle local object '_create_patch_fit.<locals>.getPLCallback.<locals>.__MLflowPLCallback'\r\n```\r\n</details>\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [x] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [x] `integrations/databricks`: Databricks integrations\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4696/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/4696/timeline","performed_via_github_app":null,"state_reason":null}