{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4235","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/4235/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/4235/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/4235/events","html_url":"https://github.com/mlflow/mlflow/issues/4235","id":854831722,"node_id":"MDU6SXNzdWU4NTQ4MzE3MjI=","number":4235,"title":"[BUG] mlflow.autolog() for PyTorch Lightning logs `_step` metrics for epochs instead of steps","user":{"login":"danieltremblay","id":3637251,"node_id":"MDQ6VXNlcjM2MzcyNTE=","avatar_url":"https://avatars.githubusercontent.com/u/3637251?v=4","gravatar_id":"","url":"https://api.github.com/users/danieltremblay","html_url":"https://github.com/danieltremblay","followers_url":"https://api.github.com/users/danieltremblay/followers","following_url":"https://api.github.com/users/danieltremblay/following{/other_user}","gists_url":"https://api.github.com/users/danieltremblay/gists{/gist_id}","starred_url":"https://api.github.com/users/danieltremblay/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danieltremblay/subscriptions","organizations_url":"https://api.github.com/users/danieltremblay/orgs","repos_url":"https://api.github.com/users/danieltremblay/repos","events_url":"https://api.github.com/users/danieltremblay/events{/privacy}","received_events_url":"https://api.github.com/users/danieltremblay/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":2022845866,"node_id":"MDU6TGFiZWwyMDIyODQ1ODY2","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/artifacts","name":"area/artifacts","color":"48eabc","default":false,"description":"Artifact stores and artifact logging"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-04-09T20:24:38Z","updated_at":"2022-03-21T03:20:22Z","closed_at":"2022-03-21T03:20:22Z","author_association":"NONE","active_lock_reason":null,"body":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: Reproducible with example from [official docs](https://www.mlflow.org/docs/latest/python_api/mlflow.pytorch.html)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Docker image: `nvidia/cuda:10.2-base-ubuntu16.04`\r\n- **MLflow installed from (source or binary)**: Python package\r\n- **MLflow version (run ``mlflow --version``)**: 1.15.0\r\n- **Python version**: 3.8.8\r\n- **npm version, if running the dev UI**: No\r\n- **Exact command to reproduce**: See code snippet\r\n\r\n### Describe the problem\r\nExpected behavior:\r\nIf I'm using `mlflow.autolog()` with a `pl.LightningModule` and use `self.log(\"train_loss\", loss, on_epoch=True, on_step=True, logger=True)` inside its `training_step` function, MLflow should log `train_loss_step` metric for every logged **step** and `train_loss_epoch` for every logged **epoch**\r\n\r\nActual behavior:\r\n`train_loss_step` and `train_loss_epoch` are recorded for every logged **epoch** only.\r\n\r\nAfter running code in below sample, `train_loss_epoch`  contains 1 entry per epoch:\r\n```\r\n1617996945494 1.3506861925125122 0\r\n1617996966448 1.201533317565918 1\r\n1617996986735 1.1901590824127197 2\r\n1617997007487 1.190608024597168 3\r\n1617997028088 1.1838353872299194 4\r\n1617997048012 1.1807078123092651 5\r\n1617997068702 1.18239426612854 6\r\n1617997089547 1.1766492128372192 7\r\n1617997110542 1.175412654876709 8\r\n1617997130747 1.1763886213302612 9\r\n1617997150977 1.1739486455917358 10\r\n1617997171487 1.1722205877304077 11\r\n1617997191321 1.170091152191162 12\r\n1617997211502 1.1701279878616333 13\r\n1617997232425 1.1694077253341675 14\r\n1617997252996 1.1664137840270996 15\r\n1617997273641 1.1662592887878418 16\r\n1617997294056 1.1691796779632568 17\r\n1617997314113 1.164090871810913 18\r\n1617997335002 1.1653193235397339 19\r\n```\r\n`train_loss_step` also contains 1 entry per **epoch**\r\n```\r\n1617996945494 1.0488566160202026 0\r\n1617996966448 1.0117261409759521 1\r\n1617996986735 0.9437647461891174 2\r\n1617997007487 1.1345815658569336 3\r\n1617997028088 0.9712427854537964 4\r\n1617997048012 0.9615302681922913 5\r\n1617997068702 0.9383407235145569 6\r\n1617997089547 0.9366243481636047 7\r\n1617997110542 0.9363885521888733 8\r\n1617997130747 0.9403294324874878 9\r\n1617997150977 0.9360908269882202 10\r\n1617997171487 1.0088082551956177 11\r\n1617997191321 0.9398048520088196 12\r\n1617997211502 0.9855148792266846 13\r\n1617997232425 0.9356205463409424 14\r\n1617997252996 0.9355267286300659 15\r\n1617997273641 0.937127947807312 16\r\n1617997294056 0.9390522837638855 17\r\n1617997314113 0.9355039000511169 18\r\n1617997335002 0.9383139610290527 19\r\n```\r\n\r\n\r\n### Code to reproduce issue\r\nSmall modifications to [code snippet in documentation](https://www.mlflow.org/docs/latest/python_api/mlflow.pytorch.html)\r\n\r\n```\r\nimport os\r\n\r\nimport pytorch_lightning as pl\r\nimport torch\r\nfrom torch.nn import functional as F\r\nfrom torch.utils.data import DataLoader\r\nfrom torchvision import transforms\r\nfrom torchvision.datasets import MNIST\r\n\r\nimport mlflow.pytorch\r\n\r\n\r\nclass MNISTModel(pl.LightningModule):\r\n    def __init__(self):\r\n        super(MNISTModel, self).__init__()\r\n        self.l1 = torch.nn.Linear(28 * 28, 10)\r\n\r\n    def forward(self, x):\r\n        return torch.relu(self.l1(x.view(x.size(0), -1)))\r\n\r\n    def training_step(self, batch, batch_nb):\r\n        x, y = batch\r\n        loss = F.cross_entropy(self(x), y)\r\n\r\n        # Use the current of PyTorch logger\r\n        self.log(\"train_loss\", loss, on_epoch=True, on_step=True, logger=True)\r\n        return loss\r\n\r\n    def configure_optimizers(self):\r\n        return torch.optim.Adam(self.parameters(), lr=0.02)\r\n\r\n\r\ndef print_auto_logged_info(r):\r\n    print(\"metrics: {}\".format(r.data.metrics))\r\n\r\n\r\ndef main() -> None:\r\n    mlflow.set_experiment(\"Autolog issue\")\r\n\r\n    # Initialize our model\r\n    mnist_model = MNISTModel()\r\n\r\n    # Initialize DataLoader from MNIST Dataset\r\n    train_ds = MNIST(os.getcwd(), train=True,\r\n                     download=True, transform=transforms.ToTensor())\r\n    train_loader = DataLoader(train_ds, batch_size=32)\r\n\r\n    # Initialize a trainer\r\n    trainer = pl.Trainer(max_epochs=20, progress_bar_refresh_rate=20)\r\n\r\n    # Auto log all MLflow entities\r\n    mlflow.pytorch.autolog()\r\n\r\n    # Train the model\r\n    with mlflow.start_run() as run:\r\n        trainer.fit(mnist_model, train_loader)\r\n\r\n        # fetch the auto logged parameters and metrics\r\n        print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\n\r\n### Other info / logs\r\nPyTorch Lightning adds the `_step` and `_epoch` suffixes to the logged metrics, so on our side we used this info and slightly adjusted [__MLflowPLCallback](https://github.com/mlflow/mlflow/blob/86a03e9488f7cf2c7c0e46531fd2168923c79ec2/mlflow/pytorch/_pytorch_autolog.py#L83) by adding the following hook:\r\n```\r\n        def on_train_batch_end(\r\n            self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx\r\n        ):\r\n           # ADD CODE TO FILTER ON `_step` SUFFIX\r\n\r\n           # Then we log filtered metrics on pl_module.global_step instead of  pl_module.current_epoch\r\n           metrics_logger.record_metrics(step_metrics, pl_module.global_step)\r\n```\r\nWe also adjusted `__MLflowPLCallback._log_epoch_metrics()` to filter out metrics with the `_step` suffix.\r\n\r\nAre there any plans to make classes such as [__MLflowPLCallback](https://github.com/mlflow/mlflow/blob/86a03e9488f7cf2c7c0e46531fd2168923c79ec2/mlflow/pytorch/_pytorch_autolog.py#L83) accessible so that we can subclass them to add/modify such functionality?\r\n\r\nThanks!\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations\r\n","closed_by":{"login":"harupy","id":17039389,"node_id":"MDQ6VXNlcjE3MDM5Mzg5","avatar_url":"https://avatars.githubusercontent.com/u/17039389?v=4","gravatar_id":"","url":"https://api.github.com/users/harupy","html_url":"https://github.com/harupy","followers_url":"https://api.github.com/users/harupy/followers","following_url":"https://api.github.com/users/harupy/following{/other_user}","gists_url":"https://api.github.com/users/harupy/gists{/gist_id}","starred_url":"https://api.github.com/users/harupy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harupy/subscriptions","organizations_url":"https://api.github.com/users/harupy/orgs","repos_url":"https://api.github.com/users/harupy/repos","events_url":"https://api.github.com/users/harupy/events{/privacy}","received_events_url":"https://api.github.com/users/harupy/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4235/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/4235/timeline","performed_via_github_app":null,"state_reason":"completed"}