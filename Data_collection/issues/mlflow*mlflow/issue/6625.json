{"url":"https://api.github.com/repos/mlflow/mlflow/issues/6625","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/6625/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/6625/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/6625/events","html_url":"https://github.com/mlflow/mlflow/issues/6625","id":1353767988,"node_id":"I_kwDOCB5Jx85QsNw0","number":6625,"title":"[BUG] Error loading Pyspark model from databricks connect","user":{"login":"CarlaFernandez","id":9136877,"node_id":"MDQ6VXNlcjkxMzY4Nzc=","avatar_url":"https://avatars.githubusercontent.com/u/9136877?v=4","gravatar_id":"","url":"https://api.github.com/users/CarlaFernandez","html_url":"https://github.com/CarlaFernandez","followers_url":"https://api.github.com/users/CarlaFernandez/followers","following_url":"https://api.github.com/users/CarlaFernandez/following{/other_user}","gists_url":"https://api.github.com/users/CarlaFernandez/gists{/gist_id}","starred_url":"https://api.github.com/users/CarlaFernandez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CarlaFernandez/subscriptions","organizations_url":"https://api.github.com/users/CarlaFernandez/orgs","repos_url":"https://api.github.com/users/CarlaFernandez/repos","events_url":"https://api.github.com/users/CarlaFernandez/events{/privacy}","received_events_url":"https://api.github.com/users/CarlaFernandez/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":968461607,"node_id":"MDU6TGFiZWw5Njg0NjE2MDc=","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/windows","name":"area/windows","color":"ede978","default":false,"description":"Issue is unique to windows."},{"id":2022848043,"node_id":"MDU6TGFiZWwyMDIyODQ4MDQz","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/models","name":"area/models","color":"48eabc","default":false,"description":"MLmodel format, model serialization/deserialization, flavors"},{"id":2114036915,"node_id":"MDU6TGFiZWwyMTE0MDM2OTE1","url":"https://api.github.com/repos/mlflow/mlflow/labels/integrations/databricks","name":"integrations/databricks","color":"ffbce5","default":false,"description":"Databricks integrations"},{"id":2237251966,"node_id":"MDU6TGFiZWwyMjM3MjUxOTY2","url":"https://api.github.com/repos/mlflow/mlflow/labels/language/new","name":"language/new","color":"349cd8","default":false,"description":"Proposals for new client languages"}],"state":"open","locked":false,"assignee":{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https://avatars.githubusercontent.com/u/39497902?v=4","gravatar_id":"","url":"https://api.github.com/users/dbczumar","html_url":"https://github.com/dbczumar","followers_url":"https://api.github.com/users/dbczumar/followers","following_url":"https://api.github.com/users/dbczumar/following{/other_user}","gists_url":"https://api.github.com/users/dbczumar/gists{/gist_id}","starred_url":"https://api.github.com/users/dbczumar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbczumar/subscriptions","organizations_url":"https://api.github.com/users/dbczumar/orgs","repos_url":"https://api.github.com/users/dbczumar/repos","events_url":"https://api.github.com/users/dbczumar/events{/privacy}","received_events_url":"https://api.github.com/users/dbczumar/received_events","type":"User","site_admin":false},"assignees":[{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https://avatars.githubusercontent.com/u/39497902?v=4","gravatar_id":"","url":"https://api.github.com/users/dbczumar","html_url":"https://github.com/dbczumar","followers_url":"https://api.github.com/users/dbczumar/followers","following_url":"https://api.github.com/users/dbczumar/following{/other_user}","gists_url":"https://api.github.com/users/dbczumar/gists{/gist_id}","starred_url":"https://api.github.com/users/dbczumar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbczumar/subscriptions","organizations_url":"https://api.github.com/users/dbczumar/orgs","repos_url":"https://api.github.com/users/dbczumar/repos","events_url":"https://api.github.com/users/dbczumar/events{/privacy}","received_events_url":"https://api.github.com/users/dbczumar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":8,"created_at":"2022-08-29T06:22:59Z","updated_at":"2022-09-16T00:18:27Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"### Willingness to contribute\r\n\r\nNo. I cannot contribute a bug fix at this time.\r\n\r\n### MLflow version\r\n\r\n1.26.1\r\n\r\n### System information\r\n\r\n- Windows 10 Pro, Version 21H2, OS compilation 19044.1889, Windows Feature Experience Pack 120.2212.4180.0\r\n- Python 3.8\r\n- Databricks cluster  runtime: 9.1 LTS ML (includes Apache Spark 3.1.2, Scala 2.12)\r\n- Databricks Connect version 9.1.16\r\n- Pyspark version: 3.1\r\n\r\n\r\n### Describe the problem\r\n\r\nI'm using Databricks Connect version 9.1.16 to connect to a databricks external cluster and download a Pyspark ML pipeline that's been trained and saved using mlflow.\r\n\r\nThe `code to reproduce` works when executed from a Databricks notebook (and provided the real model uri), but fail when executed from my local machine via databricks connect. And I get the same error on any model I want to load.\r\n\r\n\r\n### Tracking information\r\n\r\n_No response_\r\n\r\n### Code to reproduce issue\r\nExecute the following lines from a local machine using databricks-connect to connect to an external cluster:\r\n```python\r\nimport mlflow\r\nmlflow.set_tracking_uri(\"databricks\")\r\nmodel = mlflow.spark.load_model(model_uri=\"models:/model_name/model_version\")\r\n```\r\n\r\n### Stack trace\r\n\r\n```python\r\n2022/08/26 11:54:18 INFO mlflow.spark: 'models:/model_name/model_version' resolved as 'dbfs://databricks/databricks/mlflow-registry/model_id/models/model'\r\n2022/08/26 11:54:25 INFO mlflow.spark: URI 'dbfs://databricks/databricks/mlflow-registry/model_id/models/model/sparkml' does not point to the current DFS.\r\n2022/08/26 11:54:25 INFO mlflow.spark: File 'dbfs://databricks/databricks/mlflow-registry/model_id/models/model/sparkml' not found on DFS. Will attempt to upload the file.\r\n2022/08/26 11:55:06 INFO mlflow.spark: Copied SparkML model to /tmp/mlflow/model_id\r\n---------------------------------------------------------------------------\r\nPy4JJavaError                             Traceback (most recent call last)\r\nc:\\Users\\carlafernandez\\Documents\\my_notebook.ipynb Celda 5 in <cell line: 2>()\r\n      1 mlflow.set_tracking_uri(\"databricks\")\r\n----> 2 model_h = mlflow.spark.load_model(model_uri=\"models:/model_name/model_version\")\r\n\r\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\mlflow\\spark.py:711, in load_model(model_uri, dfs_tmpdir)\r\n    708 local_model_path = _download_artifact_from_uri(model_uri)\r\n    709 _add_code_from_conf_to_system_path(local_model_path, flavor_conf)\r\n--> 711 return _load_model(model_uri=model_uri, dfs_tmpdir_base=dfs_tmpdir)\r\n\r\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\mlflow\\spark.py:660, in _load_model(model_uri, dfs_tmpdir_base)\r\n    658     return _load_model_databricks(model_uri, dfs_tmpdir)\r\n    659 model_uri = _HadoopFileSystem.maybe_copy_from_uri(model_uri, dfs_tmpdir)\r\n--> 660 return PipelineModel.load(model_uri)\r\n\r\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\pyspark\\ml\\util.py:463, in MLReadable.load(cls, path)\r\n    460 @classmethod\r\n    461 def load(cls, path):\r\n    462     \"\"\"Reads an ML instance from the input path, a shortcut of `read().load(path)`.\"\"\"\r\n--> 463     return cls.read().load(path)\r\n\r\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\pyspark\\ml\\pipeline.py:258, in PipelineModelReader.load(self, path)\r\n    256 metadata = DefaultParamsReader.loadMetadata(path, self.sc)\r\n    257 if 'language' not in metadata['paramMap'] or metadata['paramMap']['language'] != 'Python':\r\n--> 258     return JavaMLReader(self.cls).load(path)\r\n    259 else:\r\n    260     uid, stages = PipelineSharedReadWrite.load(metadata, self.sc, path)\r\n\r\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\pyspark\\ml\\util.py:413, in JavaMLReader.load(self, path)\r\n    411 if not isinstance(path, str):\r\n    412     raise TypeError(\"path should be a string, got type %s\" % type(path))\r\n--> 413 java_obj = self._jread.load(path)\r\n    414 if not hasattr(self._clazz, \"_from_java\"):\r\n    415     raise NotImplementedError(\"This Java ML type cannot be loaded into Python currently: %r\"\r\n    416                               % self._clazz)\r\n\r\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\py4j\\java_gateway.py:1304, in JavaMember.__call__(self, *args)\r\n   1298 command = proto.CALL_COMMAND_NAME +\\\r\n   1299     self.command_header +\\\r\n   1300     args_command +\\\r\n   1301     proto.END_COMMAND_PART\r\n   1303 answer = self.gateway_client.send_command(command)\r\n-> 1304 return_value = get_return_value(\r\n   1305     answer, self.gateway_client, self.target_id, self.name)\r\n   1307 for temp_arg in temp_args:\r\n   1308     temp_arg._detach()\r\n\r\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\pyspark\\sql\\utils.py:117, in capture_sql_exception.<locals>.deco(*a, **kw)\r\n    115 def deco(*a, **kw):\r\n    116     try:\r\n--> 117         return f(*a, **kw)\r\n    118     except py4j.protocol.Py4JJavaError as e:\r\n    119         converted = convert_exception(e.java_exception)\r\n\r\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\py4j\\protocol.py:326, in get_return_value(answer, gateway_client, target_id, name)\r\n    324 value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)\r\n    325 if answer[1] == REFERENCE_TYPE:\r\n--> 326     raise Py4JJavaError(\r\n    327         \"An error occurred while calling {0}{1}{2}.\\n\".\r\n    328         format(target_id, \".\", name), value)\r\n    329 else:\r\n    330     raise Py4JError(\r\n    331         \"An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n\".\r\n    332         format(target_id, \".\", name, value))\r\n\r\nPy4JJavaError: An error occurred while calling o645.load.\r\n: java.io.StreamCorruptedException: invalid type code: 00\r\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1698)\r\n    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)\r\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)\r\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\r\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\r\n    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)\r\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)\r\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\r\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\r\n    at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)\r\n    at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)\r\n    at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:488)\r\n    at sun.reflect.GeneratedMethodAccessor311.invoke(Unknown Source)\r\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n    at java.lang.reflect.Method.invoke(Method.java:498)\r\n    at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)\r\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)\r\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\r\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\r\n    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)\r\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)\r\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\r\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\r\n    at java.io.ObjectInputStream.readArray(ObjectInputStream.java:2093)\r\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1655)\r\n    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)\r\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)\r\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\r\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\r\n    at java.io.ObjectInputStream.readArray(ObjectInputStream.java:2093)\r\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1655)\r\n    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)\r\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)\r\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\r\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\r\n    at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)\r\n    at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)\r\n    at org.apache.spark.sql.util.ProtoSerializer.$anonfun$deserializeObject$1(ProtoSerializer.scala:6631)\r\n    at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\r\n    at org.apache.spark.sql.util.ProtoSerializer.deserializeObject(ProtoSerializer.scala:6616)\r\n    at com.databricks.service.SparkServiceRPCHandler.execute0(SparkServiceRPCHandler.scala:728)\r\n    at com.databricks.service.SparkServiceRPCHandler.$anonfun$executeRPC0$1(SparkServiceRPCHandler.scala:477)\r\n    at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\r\n    at com.databricks.service.SparkServiceRPCHandler.executeRPC0(SparkServiceRPCHandler.scala:372)\r\n    at com.databricks.service.SparkServiceRPCHandler$$anon$2.call(SparkServiceRPCHandler.scala:323)\r\n    at com.databricks.service.SparkServiceRPCHandler$$anon$2.call(SparkServiceRPCHandler.scala:309)\r\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n    at com.databricks.service.SparkServiceRPCHandler.$anonfun$executeRPC$1(SparkServiceRPCHandler.scala:359)\r\n    at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\r\n    at com.databricks.service.SparkServiceRPCHandler.executeRPC(SparkServiceRPCHandler.scala:336)\r\n    at com.databricks.service.SparkServiceRPCServlet.doPost(SparkServiceRPCServer.scala:167)\r\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\r\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\r\n    at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\r\n    at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:550)\r\n    at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\r\n    at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\r\n    at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\r\n    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\r\n    at org.eclipse.jetty.server.Server.handle(Server.java:516)\r\n    at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\r\n    at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\r\n    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)\r\n    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\r\n    at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\r\n    at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\r\n    at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\r\n    at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\r\n    at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\r\n    at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\r\n    at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\r\n    at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\r\n    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\r\n    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\r\n    at java.lang.Thread.run(Thread.java:748)\r\n```\r\n\r\n### Other info / logs\r\n\r\n_No response_\r\n\r\n### What component(s) does this bug affect?\r\n\r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [X] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/pipelines`: Pipelines, Pipeline APIs, Pipeline configs, Pipeline Templates\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n### What interface(s) does this bug affect?\r\n\r\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [X] `area/windows`: Windows support\r\n\r\n### What language(s) does this bug affect?\r\n\r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [X] `language/new`: Proposals for new client languages\r\n\r\n### What integration(s) does this bug affect?\r\n\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [X] `integrations/databricks`: Databricks integrations","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/6625/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/6625/timeline","performed_via_github_app":null,"state_reason":null}