{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4655","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/4655/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/4655/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/4655/events","html_url":"https://github.com/mlflow/mlflow/issues/4655","id":960311422,"node_id":"MDU6SXNzdWU5NjAzMTE0MjI=","number":4655,"title":"[BUG] Issue with mlflow.tensorflow.load_model not returning model object causing inference to fail.","user":{"login":"jchacks","id":15104741,"node_id":"MDQ6VXNlcjE1MTA0NzQx","avatar_url":"https://avatars.githubusercontent.com/u/15104741?v=4","gravatar_id":"","url":"https://api.github.com/users/jchacks","html_url":"https://github.com/jchacks","followers_url":"https://api.github.com/users/jchacks/followers","following_url":"https://api.github.com/users/jchacks/following{/other_user}","gists_url":"https://api.github.com/users/jchacks/gists{/gist_id}","starred_url":"https://api.github.com/users/jchacks/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jchacks/subscriptions","organizations_url":"https://api.github.com/users/jchacks/orgs","repos_url":"https://api.github.com/users/jchacks/repos","events_url":"https://api.github.com/users/jchacks/events{/privacy}","received_events_url":"https://api.github.com/users/jchacks/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":2022848043,"node_id":"MDU6TGFiZWwyMDIyODQ4MDQz","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/models","name":"area/models","color":"48eabc","default":false,"description":"MLmodel format, model serialization/deserialization, flavors"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-08-04T11:42:47Z","updated_at":"2022-03-24T11:47:54Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"### Willingness to contribute\r\n- [x] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code**: Yes\r\n- **OS Platform and Distribution**: Linux Ubuntu 18.04\r\n- **MLflow installed from**: binary\r\n- **MLflow version**: 1.12.1\r\n- **Python version**: 3.8.5\r\n- **Tensorflow version**: 2.3.0\r\n\r\n### Describe the problem\r\nI cannot load tensorflow models from the `mlfow.tensorflow.load_model` call.\r\n\r\n**Expected behaviour**:\r\nLoad model and input data.\r\n**Actual behaviour**:\r\nModel variables are stored on the `loaded` model object and the `mlfow.tensorflow.load_model` call returns a concrete function which garbage collects the `loaded` model, causing the concrete function to fail with `Error while reading resource variable iris_model/dense_1/kernel_98 from Container: localhost.`\r\n\r\nThis behaviour is discussed in https://github.com/tensorflow/tensorflow/issues/34253, on the tensorflow github.\r\n\r\nSection in your codebase that causes the bug: \r\nhttps://github.com/mlflow/mlflow/blob/b1c7ef3a7c60ad4df45041871c3fda40b68a47c6/mlflow/tensorflow.py#L468-L477\r\n\r\nA solution to this would be to return the `loaded` object from the `mlfow.tensorflow.load_model` call but this would change your API.\r\n\r\nThis solution below where a function binds the `loaded` variable from its outer scope could also work... feels very hacky though.\r\n```python\r\ndef _load_tensorflow_saved_model(\r\n    tf_saved_model_dir, tf_meta_graph_tags, tf_signature_def_key, tf_sess=None\r\n):\r\n    ...\r\n        loaded = tensorflow.saved_model.load(  # pylint: disable=no-value-for-parameter\r\n            tags=tf_meta_graph_tags, export_dir=tf_saved_model_dir\r\n        )\r\n        loaded_sig = loaded.signatures\r\n    if tf_signature_def_key not in loaded_sig:\r\n        raise MlflowException(\r\n            \"Could not find signature def key %s. Available keys are: %s\"\r\n            % (tf_signature_def_key, list(loaded_sig.keys()))\r\n        )\r\n\r\n    def call(*args, **kwargs):\r\n        return loaded.signatures[tf_signature_def_key](*args, **kwargs)\r\n\r\n    return call\r\n```\r\n\r\n\r\n### Code to reproduce issue\r\n\r\nWhole training and prediction code to reproduce:\r\nhttps://gist.github.com/jchacks/6ae685460c82e4b46ad9be2a90db2b47\r\n\r\n```python\r\n# Save a model using the tf api\r\ntf.saved_model.save(\r\n    model,\r\n    \"../model/iris_model\",\r\n    signatures=model.predict\r\n)\r\n\r\nx = 'some dataset'\r\n\r\n# This works as it keeps the `loaded` variable\r\nloaded = tf.saved_model.load(\"../model/iris_model\")\r\nloaded.predict(x)\r\n\r\nmodel = mlflow.tensorflow.load_model(\r\n    model_uri=f\"models:/{model_name}/{model_version}\"\r\n)\r\n# This should work as it returns the concrete function \r\n# but the loaded model in your API is being garbage \r\n# collected and deletes the model variables\r\nmodel(x)\r\n\r\n```\r\n\r\n### Other info / logs\r\nFull traceback of TF failure.\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"predict.py\", line 17, in <module>\r\n    model(x=x)\r\n  File \"/root/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1655, in __call__\r\n    return self._call_impl(args, kwargs)\r\n  File \"/root/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1673, in _call_impl\r\n    return self._call_with_flat_signature(args, kwargs, cancellation_manager)\r\n  File \"/root/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1722, in _call_with_flat_signature\r\n    return self._call_flat(args, self.captured_inputs, cancellation_manager)\r\n  File \"/root/opt/conda/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py\", line 105, in _call_flat\r\n    return super(_WrapperFunction, self)._call_flat(args, captured_inputs,\r\n  File \"/root/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1923, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"/root/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 545, in call\r\n    outputs = execute.execute(\r\n  File \"/root/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError:  Error while reading resource variable iris_model/dense_1/kernel_98 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/iris_model/dense_1/kernel_98/N10tensorflow3VarE does not exist.\r\n         [[{{node StatefulPartitionedCall/iris_model/dense_1/MatMul/ReadVariableOp}}]] [Op:__inference_signature_wrapper_88]\r\n\r\nFunction call stack:\r\nsignature_wrapper\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4655/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/4655/timeline","performed_via_github_app":null,"state_reason":null}