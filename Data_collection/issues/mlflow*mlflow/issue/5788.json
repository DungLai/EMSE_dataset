{"url":"https://api.github.com/repos/mlflow/mlflow/issues/5788","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/5788/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/5788/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/5788/events","html_url":"https://github.com/mlflow/mlflow/issues/5788","id":1217219925,"node_id":"I_kwDOCB5Jx85IjU1V","number":5788,"title":"[FR] Create serverless inference deployment on sagemaker","user":{"login":"ikergon98","id":63065119,"node_id":"MDQ6VXNlcjYzMDY1MTE5","avatar_url":"https://avatars.githubusercontent.com/u/63065119?v=4","gravatar_id":"","url":"https://api.github.com/users/ikergon98","html_url":"https://github.com/ikergon98","followers_url":"https://api.github.com/users/ikergon98/followers","following_url":"https://api.github.com/users/ikergon98/following{/other_user}","gists_url":"https://api.github.com/users/ikergon98/gists{/gist_id}","starred_url":"https://api.github.com/users/ikergon98/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ikergon98/subscriptions","organizations_url":"https://api.github.com/users/ikergon98/orgs","repos_url":"https://api.github.com/users/ikergon98/repos","events_url":"https://api.github.com/users/ikergon98/events{/privacy}","received_events_url":"https://api.github.com/users/ikergon98/received_events","type":"User","site_admin":false},"labels":[{"id":955449434,"node_id":"MDU6TGFiZWw5NTU0NDk0MzQ=","url":"https://api.github.com/repos/mlflow/mlflow/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":2022860064,"node_id":"MDU6TGFiZWwyMDIyODYwMDY0","url":"https://api.github.com/repos/mlflow/mlflow/labels/integrations/sagemaker","name":"integrations/sagemaker","color":"ffbce5","default":false,"description":"Sagemaker integrations"},{"id":2042304474,"node_id":"MDU6TGFiZWwyMDQyMzA0NDc0","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/build","name":"area/build","color":"48eabc","default":false,"description":"Build and test infrastructure for MLflow"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2022-04-27T11:28:59Z","updated_at":"2022-04-29T08:43:44Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Thank you for submitting a feature request. **Before proceeding, please review MLflow's [Issue Policy for feature requests](https://www.github.com/mlflow/mlflow/blob/master/ISSUE_POLICY.md#feature-requests) and the [MLflow Contributing Guide](https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.rst)**.\r\n\r\n**Please fill in this feature request template to ensure a timely and thorough response.**\r\n\r\n## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nAdd the possibility of selecting the new feature of AWS SageMaker, Serverless inference, while deploying a model on SageMaker. \r\n\r\n## Motivation\r\n\r\nJust a few days ago, SageMaker released a new inference option. This featured is supposed to automatically manage computer resources depending the traffic received. I would like to add this feature to my new projects, and test if it worth it. That's why i think it would be good to make it easy to deploy that kind of endpoint via MLflow.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents\r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [x] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguages\r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [x] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nAn idea could be add a new parameter on mlflow.sagemaker.deploy, that trigger a serverless endpoint configuration.\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/5788/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/5788/timeline","performed_via_github_app":null,"state_reason":null}