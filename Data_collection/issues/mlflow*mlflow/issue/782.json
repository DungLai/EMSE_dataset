{"url":"https://api.github.com/repos/mlflow/mlflow/issues/782","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/782/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/782/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/782/events","html_url":"https://github.com/mlflow/mlflow/issues/782","id":394618953,"node_id":"MDU6SXNzdWUzOTQ2MTg5NTM=","number":782,"title":"Spark dataframes with columns containing vectors cannot be scored with MLflow PySpark model UDFs","user":{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https://avatars.githubusercontent.com/u/39497902?v=4","gravatar_id":"","url":"https://api.github.com/users/dbczumar","html_url":"https://github.com/dbczumar","followers_url":"https://api.github.com/users/dbczumar/followers","following_url":"https://api.github.com/users/dbczumar/following{/other_user}","gists_url":"https://api.github.com/users/dbczumar/gists{/gist_id}","starred_url":"https://api.github.com/users/dbczumar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbczumar/subscriptions","organizations_url":"https://api.github.com/users/dbczumar/orgs","repos_url":"https://api.github.com/users/dbczumar/repos","events_url":"https://api.github.com/users/dbczumar/events{/privacy}","received_events_url":"https://api.github.com/users/dbczumar/received_events","type":"User","site_admin":false},"labels":[{"id":1554650079,"node_id":"MDU6TGFiZWwxNTU0NjUwMDc5","url":"https://api.github.com/repos/mlflow/mlflow/labels/stale","name":"stale","color":"828282","default":false,"description":""}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2018-12-28T11:45:35Z","updated_at":"2019-11-19T01:32:42Z","closed_at":"2019-11-12T23:50:11Z","author_association":"COLLABORATOR","active_lock_reason":null,"body":"### Describe the problem\r\nMLflow models can be represented as Spark UDFs for inference. However, the UDF representation of a PySpark model is unable to evaluate Spark DataFrames whose columns contain vectors. For example, consider the following DataFrame definition:\r\n\r\n```\r\nnested_df = spark.createDataFrame([\r\n  (\"This is a test\".split(\" \"), )\r\n], [\"0\"])\r\n```\r\n\r\nThe DataFrame `nested_df` contains a single row and column. The row contains a *vector* of strings. When `nested_df` is evaluated by a Spark UDF representation of an PySpark model, this *vector* is converted to a numpy array and embedded within a Pandas DataFrame. When the UDF invokes the PySpark model, it attempts to convert the Pandas DataFrame to a Spark DataFrame; however, this process fails because Spark cannot handle the embedded numpy array.\r\n\r\n### Source code / logs\r\n\r\nCode to reproduce the issue:\r\n\r\n```\r\nimport mlflow.spark\r\n\r\nfrom pyspark.ml import Pipeline\r\nfrom pyspark.ml.classification import LogisticRegression\r\n\r\nfrom pyspark.ml.feature import Word2Vec\r\nimport pyspark\r\n\r\nword_df = spark.createDataFrame([\r\n  (\"This is a test\".split(\" \"), )\r\n], [\"0\"])\r\nw2v = Word2Vec(inputCol=\"0\", outputCol=\"prediction\", minCount=0)\r\n\r\npipeline = Pipeline(stages=[w2v])\r\nmodel = pipeline.fit(word_df)\r\n\r\nmlflow.set_experiment(\"repro-exp\")\r\nwith mlflow.start_run():\r\n  mlflow.spark.log_model(model, \"spark-model\")\r\n  run_id = mlflow.active_run().info.run_uuid\r\n\r\nimport mlflow.pyfunc\r\nfrom pyspark.sql.types import DoubleType, StringType, ArrayType\r\nw2v_udf = mlflow.pyfunc.spark_udf(spark, \"spark-model\", run_id)\r\npreds = word_df.withColumn(\"prediction\", w2v_udf(\"0\"))\r\n\r\npreds.collect()\r\n```\r\n\r\nStack trace:\r\n\r\n```\r\n  File \"/databricks/spark/python/pyspark/sql/types.py\", line 1068, in _infer_type\r\n    return _infer_schema(obj)\r\n  File \"/databricks/spark/python/pyspark/sql/types.py\", line 1094, in _infer_schema\r\n    raise TypeError(\"Can not infer schema for type: %s\" % type(row))\r\nTypeError: Can not infer schema for type: <class 'numpy.ndarray'>\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/databricks/spark/python/pyspark/worker.py\", line 262, in main\r\n    process()\r\n  File \"/databricks/spark/python/pyspark/worker.py\", line 257, in process\r\n    serializer.dump_stream(func(split_index, iterator), outfile)\r\n  File \"/databricks/spark/python/pyspark/serializers.py\", line 261, in dump_stream\r\n    for series in iterator:\r\n  File \"<string>\", line 1, in <lambda>\r\n  File \"/databricks/spark/python/pyspark/worker.py\", line 95, in <lambda>\r\n    return lambda *a: (verify_result_length(*a), arrow_return_type)\r\n  File \"/databricks/spark/python/pyspark/worker.py\", line 86, in verify_result_length\r\n    result = f(*a)\r\n  File \"/databricks/spark/python/pyspark/util.py\", line 55, in wrapper\r\n    return f(*args, **kwargs)\r\n  File \"/databricks/python/lib/python3.5/site-packages/mlflow/pyfunc/__init__.py\", line 275, in predict\r\n    result = model.predict(pdf)\r\n  File \"/databricks/python/lib/python3.5/site-packages/mlflow/spark.py\", line 339, in predict\r\n    spark_df = self.spark.createDataFrame(pandas_df)\r\n  File \"/databricks/spark/python/pyspark/sql/session.py\", line 729, in createDataFrame\r\n    rdd, schema = self._createFromLocal(map(prepare, data), schema)\r\n  File \"/databricks/spark/python/pyspark/sql/session.py\", line 429, in _createFromLocal\r\n    data, schema = self._wrap_data_schema(data, schema)\r\n  File \"/databricks/spark/python/pyspark/sql/session.py\", line 408, in _wrap_data_schema\r\n    struct = self._inferSchemaFromList(data, names=schema)\r\n  File \"/databricks/spark/python/pyspark/sql/session.py\", line 344, in _inferSchemaFromList\r\n    schema = reduce(_merge_type, (_infer_schema(row, names) for row in data))\r\n  File \"/databricks/spark/python/pyspark/sql/session.py\", line 344, in <genexpr>\r\n    schema = reduce(_merge_type, (_infer_schema(row, names) for row in data))\r\n  File \"/databricks/spark/python/pyspark/sql/types.py\", line 1096, in _infer_schema\r\n    fields = [StructField(k, _infer_type(v), True) for k, v in items]\r\n  File \"/databricks/spark/python/pyspark/sql/types.py\", line 1096, in <listcomp>\r\n    fields = [StructField(k, _infer_type(v), True) for k, v in items]\r\n  File \"/databricks/spark/python/pyspark/sql/types.py\", line 1070, in _infer_type\r\n    raise TypeError(\"not supported type: %s\" % type(obj))\r\nTypeError: not supported type: <class 'numpy.ndarray'>\r\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:317)\r\n\tat org.apache.spark.sql.execution.python.ArrowPythonRunner$$anon$1.read(ArrowPythonRunner.scala:174)\r\n\tat org.apache.spark.sql.execution.python.ArrowPythonRunner$$anon$1.read(ArrowPythonRunner.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:271)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat org.apache.spark.sql.execution.python.ArrowEvalPythonExec$$anon$2.<init>(ArrowEvalPythonExec.scala:95)\r\n\tat org.apache.spark.sql.execution.python.ArrowEvalPythonExec.evaluate(ArrowEvalPythonExec.scala:93)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:131)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:93)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:812)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:812)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:42)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:336)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:300)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:42)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:336)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:300)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:112)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:384)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n```","closed_by":{"login":"stale[bot]","id":26384082,"node_id":"MDM6Qm90MjYzODQwODI=","avatar_url":"https://avatars.githubusercontent.com/in/1724?v=4","gravatar_id":"","url":"https://api.github.com/users/stale%5Bbot%5D","html_url":"https://github.com/apps/stale","followers_url":"https://api.github.com/users/stale%5Bbot%5D/followers","following_url":"https://api.github.com/users/stale%5Bbot%5D/following{/other_user}","gists_url":"https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}","starred_url":"https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stale%5Bbot%5D/subscriptions","organizations_url":"https://api.github.com/users/stale%5Bbot%5D/orgs","repos_url":"https://api.github.com/users/stale%5Bbot%5D/repos","events_url":"https://api.github.com/users/stale%5Bbot%5D/events{/privacy}","received_events_url":"https://api.github.com/users/stale%5Bbot%5D/received_events","type":"Bot","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/782/reactions","total_count":4,"+1":4,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/782/timeline","performed_via_github_app":null,"state_reason":"completed"}