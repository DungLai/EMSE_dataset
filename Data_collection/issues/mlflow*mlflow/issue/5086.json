{"url":"https://api.github.com/repos/mlflow/mlflow/issues/5086","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/5086/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/5086/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/5086/events","html_url":"https://github.com/mlflow/mlflow/issues/5086","id":1058137841,"node_id":"I_kwDOCB5Jx84_Eebx","number":5086,"title":"[BUG] Cannot use HDFS as artifact root","user":{"login":"joyatcloudfall","id":87688951,"node_id":"MDQ6VXNlcjg3Njg4OTUx","avatar_url":"https://avatars.githubusercontent.com/u/87688951?v=4","gravatar_id":"","url":"https://api.github.com/users/joyatcloudfall","html_url":"https://github.com/joyatcloudfall","followers_url":"https://api.github.com/users/joyatcloudfall/followers","following_url":"https://api.github.com/users/joyatcloudfall/following{/other_user}","gists_url":"https://api.github.com/users/joyatcloudfall/gists{/gist_id}","starred_url":"https://api.github.com/users/joyatcloudfall/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/joyatcloudfall/subscriptions","organizations_url":"https://api.github.com/users/joyatcloudfall/orgs","repos_url":"https://api.github.com/users/joyatcloudfall/repos","events_url":"https://api.github.com/users/joyatcloudfall/events{/privacy}","received_events_url":"https://api.github.com/users/joyatcloudfall/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-11-19T04:56:26Z","updated_at":"2022-12-19T09:44:33Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Thank you for submitting an issue. Please refer to our [issue policy](https://www.github.com/mlflow/mlflow/blob/master/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https://stackoverflow.com/questions/tagged/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Centos7\r\n- **MLflow installed from (source or binary)**: conda install -c conda-forge \r\n- **MLflow version (run ``mlflow --version``)**: version 1.21.0\r\n- **Python version**:  Python 3.7.11\r\n- **npm version, if running the dev UI**: No\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nI was trying to use a remote HDFS to store my models, as a backend-artifact-root. Unfortunately, I got this error that said cannot find Hadoop. I did not install Hadoop on my local machine since the data engineer insist that there is no way that I can only figure it out by installing a Hadoop locally and a Hadoop installed on the server should be enough. I spent a few days still cannot save my models to HDFS, so I hope anyone here could help me. Thanks a lot!\r\n \r\nHere's my process:\r\n1. First I start a mlflow server on the remote AWS EC2 like that\r\n```\r\nmlflow server \\\r\n         --backend-store-uri mysql+pymysql://root:pwd@localhost/mlflow_tracking_database \\\r\n         --default-artifact-root hdfs://localhost:14000/webhdfs/v1/models_artifacts?op=LISTSTATUS \\\r\n         --host 0.0.0.0\r\n```\r\n\r\n2. Then I run the example sklearn_logistic_regression on my local machine as shown below.\r\n### Code to reproduce issue\r\n```\r\nimport numpy as np\r\nfrom sklearn.linear_model import LogisticRegression\r\n\r\nimport mlflow\r\nimport mlflow.sklearn\r\n\r\nif __name__ == \"__main__\":\r\n    mlflow.set_tracking_uri(\"http://ec2host:5000\")\r\n    mlflow.set_experiment(\"test-experiment\")\r\n    X = np.array([-2, -1, 0, 1, 2, 1]).reshape(-1, 1)\r\n    y = np.array([0, 0, 1, 1, 1, 0])\r\n    lr = LogisticRegression()\r\n    lr.fit(X, y)\r\n    score = lr.score(X, y)\r\n    print(\"Score: %s\" % score)\r\n    mlflow.log_metric(\"score\", score)\r\n    mlflow.sklearn.log_model(lr, \"model\")\r\n    print(\"Model saved in run %s\" % mlflow.active_run().info.run_uuid)\r\n```\r\n\r\n### Other info / logs\r\n```\r\nScore: 0.6666666666666666\r\n/root/anaconda3/envs/ueba_env/lib/python3.7/site-packages/mlflow/store/artifact/hdfs_artifact_repo.py:183: FutureWarning: pyarrow.hdfs.connect is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\r\n  extra_conf=extra_conf,\r\nTraceback (most recent call last):\r\n  File \"/CF-AI/mlflow-demo-master/sklearn_logistic_regression/train.py\", line 17, in <module>\r\n    mlflow.sklearn.log_model(lr, \"model\")\r\n  File \"/root/anaconda3/envs/ueba_env/lib/python3.7/site-packages/mlflow/sklearn/__init__.py\", line 380, in log_model\r\n    extra_pip_requirements=extra_pip_requirements,\r\n  File \"/root/anaconda3/envs/ueba_env/lib/python3.7/site-packages/mlflow/models/model.py\", line 188, in log\r\n    mlflow.tracking.fluent.log_artifacts(local_path, artifact_path)\r\n  File \"/root/anaconda3/envs/ueba_env/lib/python3.7/site-packages/mlflow/tracking/fluent.py\", line 584, in log_artifacts\r\n    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)\r\n  File \"/root/anaconda3/envs/ueba_env/lib/python3.7/site-packages/mlflow/tracking/client.py\", line 985, in log_artifacts\r\n    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)\r\n  File \"/root/anaconda3/envs/ueba_env/lib/python3.7/site-packages/mlflow/tracking/_tracking_service/client.py\", line 341, in log_artifacts\r\n    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)\r\n  File \"/root/anaconda3/envs/ueba_env/lib/python3.7/site-packages/mlflow/store/artifact/hdfs_artifact_repo.py\", line 48, in log_artifacts\r\n    with hdfs_system(scheme=self.scheme, host=self.host, port=self.port) as hdfs:\r\n  File \"/root/anaconda3/envs/ueba_env/lib/python3.7/contextlib.py\", line 112, in __enter__\r\n    return next(self.gen)\r\n  File \"/root/anaconda3/envs/ueba_env/lib/python3.7/site-packages/mlflow/store/artifact/hdfs_artifact_repo.py\", line 183, in hdfs_system\r\n    extra_conf=extra_conf,\r\n  File \"/root/anaconda3/envs/ueba_env/lib/python3.7/site-packages/pyarrow/hdfs.py\", line 229, in connect\r\n    extra_conf=extra_conf\r\n  File \"/root/anaconda3/envs/ueba_env/lib/python3.7/site-packages/pyarrow/hdfs.py\", line 239, in _connect\r\n    extra_conf=extra_conf)\r\n  File \"/root/anaconda3/envs/ueba_env/lib/python3.7/site-packages/pyarrow/hdfs.py\", line 47, in __init__\r\n    _maybe_set_hadoop_classpath()\r\n  File \"/root/anaconda3/envs/ueba_env/lib/python3.7/site-packages/pyarrow/hdfs.py\", line 147, in _maybe_set_hadoop_classpath\r\n    classpath = _hadoop_classpath_glob('hadoop')\r\n  File \"/root/anaconda3/envs/ueba_env/lib/python3.7/site-packages/pyarrow/hdfs.py\", line 172, in _hadoop_classpath_glob\r\n    return subprocess.check_output(hadoop_classpath_args)\r\n  File \"/root/anaconda3/envs/ueba_env/lib/python3.7/subprocess.py\", line 411, in check_output\r\n    **kwargs).stdout\r\n  File \"/root/anaconda3/envs/ueba_env/lib/python3.7/subprocess.py\", line 488, in run\r\n    with Popen(*popenargs, **kwargs) as process:\r\n  File \"/root/anaconda3/envs/ueba_env/lib/python3.7/subprocess.py\", line 800, in __init__\r\n    restore_signals, start_new_session)\r\n  File \"/root/anaconda3/envs/ueba_env/lib/python3.7/subprocess.py\", line 1551, in _execute_child\r\n    raise child_exception_type(errno_num, err_msg, err_filename)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'hadoop': 'hadoop'\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/5086/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/5086/timeline","performed_via_github_app":null,"state_reason":null}