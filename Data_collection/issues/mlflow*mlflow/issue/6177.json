{"url":"https://api.github.com/repos/mlflow/mlflow/issues/6177","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/6177/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/6177/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/6177/events","html_url":"https://github.com/mlflow/mlflow/issues/6177","id":1291548068,"node_id":"I_kwDOCB5Jx85M-3Wk","number":6177,"title":"[BUG] INVALID_PARAMETER_VALUE for parameter 'params'","user":{"login":"ameasure","id":571959,"node_id":"MDQ6VXNlcjU3MTk1OQ==","avatar_url":"https://avatars.githubusercontent.com/u/571959?v=4","gravatar_id":"","url":"https://api.github.com/users/ameasure","html_url":"https://github.com/ameasure","followers_url":"https://api.github.com/users/ameasure/followers","following_url":"https://api.github.com/users/ameasure/following{/other_user}","gists_url":"https://api.github.com/users/ameasure/gists{/gist_id}","starred_url":"https://api.github.com/users/ameasure/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ameasure/subscriptions","organizations_url":"https://api.github.com/users/ameasure/orgs","repos_url":"https://api.github.com/users/ameasure/repos","events_url":"https://api.github.com/users/ameasure/events{/privacy}","received_events_url":"https://api.github.com/users/ameasure/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":2022849295,"node_id":"MDU6TGFiZWwyMDIyODQ5Mjk1","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/tracking","name":"area/tracking","color":"48eabc","default":false,"description":"Tracking service, tracking client APIs, autologging"},{"id":2022852620,"node_id":"MDU6TGFiZWwyMDIyODUyNjIw","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/sqlalchemy","name":"area/sqlalchemy","color":"ede978","default":false,"description":"Use of SQL alchemy in tracking service or model registry"},{"id":2237250735,"node_id":"MDU6TGFiZWwyMjM3MjUwNzM1","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/server-infra","name":"area/server-infra","color":"48eabc","default":false,"description":"MLflow Tracking server backend"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2022-07-01T15:25:17Z","updated_at":"2022-07-06T15:03:13Z","closed_at":"2022-07-05T20:40:06Z","author_association":"NONE","active_lock_reason":null,"body":"### Willingness to contribute\n\nYes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\n\n### MLflow version\n\n1.27.0\n\n### System information\n\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Debian 10\r\n- **Python version**: 3.9.13\r\n- **yarn version, if running the dev UI**: N/A\r\n\n\n### Describe the problem\n\nI receive a `RestException: INVAILD_PARAMETER_VALUE` error when using the mlflow tracking server with an sqlite backend, but not when using the default file-storage tracker.\n\n### Tracking information\n\nMLflow version: 1.27.0\r\nTracking URI: http://localhost:5000\r\nArtifact URI: ./mlruns/1/db6e636a9fb644cc9102a5621d2a7425/artifacts\n\n### Code to reproduce issue\n\nInitiate mlflow tracking sever from command line with:\r\n```\r\nmlflow server \\\r\n    --backend-store-uri sqlite:///mlflow.db \\\r\n    --default-artifact-root ./mlruns \\\r\n    --host 0.0.0.0\r\n```\r\nRun the transformers trainer with:\r\n```python\r\nimport os\r\nfrom transformers import (\r\n    AutoTokenizer,\r\n    AutoModelForTokenClassification,\r\n    TrainingArguments,\r\n    Trainer,\r\n    DataCollatorForTokenClassification\r\n)\r\nos.environ['MLFLOW_TRACKING_URI'] = 'http://localhost:5000'\r\nos.environ['MLFLOW_EXPERIMENT_NAME'] = 'NER'\r\n\r\nmodel_name = \"distilbert-base-uncased\"\r\ntokenizer = AutoTokenizer.from_pretrained(model_name)\r\nmodel = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=9)\r\n# save the model label config so it plays nicely with downstream tasks like pipeline()\r\n\r\ndata_collator = DataCollatorForTokenClassification(tokenizer, padding=True)\r\n\r\ndataset = [{'text': 'A dog and a cat'} for i in range(100)]\r\n\r\ntraining_args = TrainingArguments(\r\n    output_dir=\"./results\",\r\n    evaluation_strategy=\"epoch\",\r\n    learning_rate=2e-5,\r\n    per_device_train_batch_size=16,\r\n    per_device_eval_batch_size=16,\r\n    num_train_epochs=3,\r\n    weight_decay=0.01,\r\n)\r\n\r\ntrainer = Trainer(\r\n    model=model,\r\n    args=training_args,\r\n    train_dataset=dataset,\r\n    eval_dataset=dataset,\r\n    tokenizer=tokenizer,\r\n    data_collator=data_collator\r\n)\r\n\r\ntrainer.train()\r\n```\n\n### Other info / logs\n\n```python-traceback\r\nSome weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight']\r\n- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\nSome weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\r\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n/venv/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\r\n  warnings.warn(\r\n***** Running training *****\r\n  Num examples = 100\r\n  Num Epochs = 3\r\n  Instantaneous batch size per device = 16\r\n  Total train batch size (w. parallel, distributed & accumulation) = 16\r\n  Gradient Accumulation steps = 1\r\n  Total optimization steps = 21\r\n---------------------------------------------------------------------------\r\nRestException                             Traceback (most recent call last)\r\nFile /workspace/model/bug_report.py:40, in <module>\r\n     21 training_args = TrainingArguments(\r\n     22     output_dir=\"./results\",\r\n     23     evaluation_strategy=\"epoch\",\r\n   (...)\r\n     28     weight_decay=0.01,\r\n     29 )\r\n     31 trainer = Trainer(\r\n     32     model=model,\r\n     33     args=training_args,\r\n   (...)\r\n     37     data_collator=data_collator\r\n     38 )\r\n---> 40 trainer.train()\r\n\r\nFile /venv/lib/python3.9/site-packages/transformers/trainer.py:1409, in Trainer.train(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\r\n   1404     self.model_wrapped = self.model\r\n   1406 inner_training_loop = find_executable_batch_size(\r\n   1407     self._inner_training_loop, self._train_batch_size, args.auto_find_batch_size\r\n   1408 )\r\n-> 1409 return inner_training_loop(\r\n   1410     args=args,\r\n   1411     resume_from_checkpoint=resume_from_checkpoint,\r\n   1412     trial=trial,\r\n   1413     ignore_keys_for_eval=ignore_keys_for_eval,\r\n   1414 )\r\n\r\nFile /venv/lib/python3.9/site-packages/transformers/trainer.py:1580, in Trainer._inner_training_loop(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\r\n   1577 self._globalstep_last_logged = self.state.global_step\r\n   1578 model.zero_grad()\r\n-> 1580 self.control = self.callback_handler.on_train_begin(args, self.state, self.control)\r\n   1582 # Skip the first epochs_trained epochs to get the random state of the dataloader at the right point.\r\n   1583 if not args.ignore_data_skip:\r\n\r\nFile /venv/lib/python3.9/site-packages/transformers/trainer_callback.py:347, in CallbackHandler.on_train_begin(self, args, state, control)\r\n    345 def on_train_begin(self, args: TrainingArguments, state: TrainerState, control: TrainerControl):\r\n    346     control.should_training_stop = False\r\n--> 347     return self.call_event(\"on_train_begin\", args, state, control)\r\n\r\nFile /venv/lib/python3.9/site-packages/transformers/trainer_callback.py:388, in CallbackHandler.call_event(self, event, args, state, control, **kwargs)\r\n    386 def call_event(self, event, args, state, control, **kwargs):\r\n    387     for callback in self.callbacks:\r\n--> 388         result = getattr(callback, event)(\r\n    389             args,\r\n    390             state,\r\n    391             control,\r\n    392             model=self.model,\r\n    393             tokenizer=self.tokenizer,\r\n    394             optimizer=self.optimizer,\r\n    395             lr_scheduler=self.lr_scheduler,\r\n    396             train_dataloader=self.train_dataloader,\r\n    397             eval_dataloader=self.eval_dataloader,\r\n    398             **kwargs,\r\n    399         )\r\n    400         # A Callback can skip the return of `control` if it doesn't change it.\r\n    401         if result is not None:\r\n\r\nFile /venv/lib/python3.9/site-packages/transformers/integrations.py:856, in MLflowCallback.on_train_begin(self, args, state, control, model, **kwargs)\r\n    854 def on_train_begin(self, args, state, control, model=None, **kwargs):\r\n    855     if not self._initialized:\r\n--> 856         self.setup(args, state, model)\r\n\r\nFile /venv/lib/python3.9/site-packages/transformers/integrations.py:847, in MLflowCallback.setup(self, args, state, model)\r\n    845 combined_dict_items = list(combined_dict.items())\r\n    846 for i in range(0, len(combined_dict_items), self._MAX_PARAMS_TAGS_PER_BATCH):\r\n--> 847     self._ml_flow.log_params(dict(combined_dict_items[i : i + self._MAX_PARAMS_TAGS_PER_BATCH]))\r\n    848 mlflow_tags = os.getenv(\"MLFLOW_TAGS\", None)\r\n    849 if mlflow_tags:\r\n\r\nFile /venv/lib/python3.9/site-packages/mlflow/tracking/fluent.py:675, in log_params(params)\r\n    673 run_id = _get_or_start_run().info.run_id\r\n    674 params_arr = [Param(key, str(value)) for key, value in params.items()]\r\n--> 675 MlflowClient().log_batch(run_id=run_id, metrics=[], params=params_arr, tags=[])\r\n\r\nFile /venv/lib/python3.9/site-packages/mlflow/tracking/client.py:918, in MlflowClient.log_batch(self, run_id, metrics, params, tags)\r\n    861 def log_batch(\r\n    862     self,\r\n    863     run_id: str,\r\n   (...)\r\n    866     tags: Sequence[RunTag] = (),\r\n    867 ) -> None:\r\n    868     \"\"\"\r\n    869     Log multiple metrics, params, and/or tags.\r\n    870 \r\n   (...)\r\n    916         status: FINISHED\r\n    917     \"\"\"\r\n--> 918     self._tracking_client.log_batch(run_id, metrics, params, tags)\r\n\r\nFile /venv/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:315, in TrackingServiceClient.log_batch(self, run_id, metrics, params, tags)\r\n    312     metrics_batch = metrics[:metrics_batch_size]\r\n    313     metrics = metrics[metrics_batch_size:]\r\n--> 315     self.store.log_batch(\r\n    316         run_id=run_id, metrics=metrics_batch, params=params_batch, tags=tags_batch\r\n    317     )\r\n    319 for metrics_batch in chunk_list(metrics, chunk_size=MAX_METRICS_PER_BATCH):\r\n    320     self.store.log_batch(run_id=run_id, metrics=metrics_batch, params=[], tags=[])\r\n\r\nFile /venv/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:309, in RestStore.log_batch(self, run_id, metrics, params, tags)\r\n    305 tag_protos = [tag.to_proto() for tag in tags]\r\n    306 req_body = message_to_json(\r\n    307     LogBatch(metrics=metric_protos, params=param_protos, tags=tag_protos, run_id=run_id)\r\n    308 )\r\n--> 309 self._call_endpoint(LogBatch, req_body)\r\n\r\nFile /venv/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:56, in RestStore._call_endpoint(self, api, json_body)\r\n     54 endpoint, method = _METHOD_TO_INFO[api]\r\n     55 response_proto = api.Response()\r\n---> 56 return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n\r\nFile /venv/lib/python3.9/site-packages/mlflow/utils/rest_utils.py:256, in call_endpoint(host_creds, endpoint, method, json_body, response_proto)\r\n    252 else:\r\n    253     response = http_request(\r\n    254         host_creds=host_creds, endpoint=endpoint, method=method, json=json_body\r\n    255     )\r\n--> 256 response = verify_rest_response(response, endpoint)\r\n    257 js_dict = json.loads(response.text)\r\n    258 parse_dict(js_dict=js_dict, message=response_proto)\r\n\r\nFile /venv/lib/python3.9/site-packages/mlflow/utils/rest_utils.py:185, in verify_rest_response(response, endpoint)\r\n    183 if response.status_code != 200:\r\n    184     if _can_parse_as_json_object(response.text):\r\n--> 185         raise RestException(json.loads(response.text))\r\n    186     else:\r\n    187         base_msg = \"API request to endpoint %s failed with error code %s != 200\" % (\r\n    188             endpoint,\r\n    189             response.status_code,\r\n    190         )\r\n\r\nRestException: INVALID_PARAMETER_VALUE: Invalid value [{'key': 'save_strategy', 'value': 'steps'}, {'key': 'save_steps', 'value': '500'}, {'key': 'save_total_limit', 'value': 'None'}, {'key': 'save_on_each_node', 'value': 'False'}, {'key': 'no_cuda', 'value': 'False'}, {'key': 'seed', 'value': '42'}, {'key': 'data_seed', 'value': 'None'}, {'key': 'jit_mode_eval', 'value': 'False'}, {'key': 'use_ipex', 'value': 'False'}, {'key': 'bf16', 'value': 'False'}, {'key': 'fp16', 'value': 'False'}, {'key': 'fp16_opt_level', 'value': 'O1'}, {'key': 'half_precision_backend', 'value': 'auto'}, {'key': 'bf16_full_eval', 'value': 'False'}, {'key': 'fp16_full_eval', 'value': 'False'}, {'key': 'tf32', 'value': 'None'}, {'key': 'local_rank', 'value': '-1'}, {'key': 'xpu_backend', 'value': 'None'}, {'key': 'tpu_num_cores', 'value': 'None'}, {'key': 'tpu_metrics_debug', 'value': 'False'}, {'key': 'debug', 'value': '[]'}, {'key': 'dataloader_drop_last', 'value': 'False'}, {'key': 'eval_steps', 'value': 'None'}, {'key': 'dataloader_num_workers', 'value': '0'}, {'key': 'past_index', 'value': '-1'}, {'key': 'run_name', 'value': './results'}, {'key': 'disable_tqdm', 'value': 'False'}, {'key': 'remove_unused_columns', 'value': 'True'}, {'key': 'label_names', 'value': 'None'}, {'key': 'load_best_model_at_end', 'value': 'False'}, {'key': 'metric_for_best_model', 'value': 'None'}, {'key': 'greater_is_better', 'value': 'None'}, {'key': 'ignore_data_skip', 'value': 'False'}, {'key': 'sharded_ddp', 'value': '[]'}, {'key': 'fsdp', 'value': '[]'}, {'key': 'fsdp_min_num_params', 'value': '0'}, {'key': 'deepspeed', 'value': 'None'}, {'key': 'label_smoothing_factor', 'value': '0.0'}, {'key': 'optim', 'value': 'adamw_hf'}, {'key': 'adafactor', 'value': 'False'}, {'key': 'group_by_length', 'value': 'False'}, {'key': 'length_column_name', 'value': 'length'}, {'key': 'report_to', 'value': \"['mlflow']\"}, {'key': 'ddp_find_unused_parameters', 'value': 'None'}, {'key': 'ddp_bucket_cap_mb', 'value': 'None'}, {'key': 'dataloader_pin_memory', 'value': 'True'}, {'key': 'skip_memory_metrics', 'value': 'True'}, {'key': 'use_legacy_prediction_loop', 'value': 'False'}, {'key': 'push_to_hub', 'value': 'False'}, {'key': 'resume_from_checkpoint', 'value': 'None'}, {'key': 'hub_model_id', 'value': 'None'}, {'key': 'hub_strategy', 'value': 'every_save'}, {'key': 'hub_token', 'value': '<HUB_TOKEN>'}, {'key': 'hub_private_repo', 'value': 'False'}, {'key': 'gradient_checkpointing', 'value': 'False'}, {'key': 'include_inputs_for_metrics', 'value': 'False'}, {'key': 'fp16_backend', 'value': 'auto'}, {'key': 'push_to_hub_model_id', 'value': 'None'}, {'key': 'push_to_hub_organization', 'value': 'None'}, {'key': 'push_to_hub_token', 'value': '<PUSH_TO_HUB_TOKEN>'}, {'key': '_n_gpu', 'value': '0'}, {'key': 'mp_parameters', 'value': ''}, {'key': 'auto_find_batch_size', 'value': 'False'}, {'key': 'full_determinism', 'value': 'False'}, {'key': 'torchdynamo', 'value': 'None'}, {'key': 'ray_scope', 'value': 'last'}] for parameter 'params' supplied. Hint: Value was of type 'list'. See the API docs for more information about request parameters.\r\n```\n\n### What component(s) does this bug affect?\n\n- [ ] `area/artifacts`: Artifact stores and artifact logging\n- [ ] `area/build`: Build and test infrastructure for MLflow\n- [ ] `area/docs`: MLflow documentation pages\n- [ ] `area/examples`: Example code\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\n- [ ] `area/pipelines`: Pipelines, Pipeline APIs, Pipeline configs, Pipeline Templates\n- [ ] `area/projects`: MLproject format, project running backends\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\n- [X] `area/server-infra`: MLflow Tracking server backend\n- [X] `area/tracking`: Tracking Service, tracking client APIs, autologging\n\n### What interface(s) does this bug affect?\n\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\n- [X] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\n- [ ] `area/windows`: Windows support\n\n### What language(s) does this bug affect?\n\n- [ ] `language/r`: R APIs and clients\n- [ ] `language/java`: Java APIs and clients\n- [ ] `language/new`: Proposals for new client languages\n\n### What integration(s) does this bug affect?\n\n- [ ] `integrations/azure`: Azure and Azure ML integrations\n- [ ] `integrations/sagemaker`: SageMaker integrations\n- [ ] `integrations/databricks`: Databricks integrations","closed_by":{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https://avatars.githubusercontent.com/u/39497902?v=4","gravatar_id":"","url":"https://api.github.com/users/dbczumar","html_url":"https://github.com/dbczumar","followers_url":"https://api.github.com/users/dbczumar/followers","following_url":"https://api.github.com/users/dbczumar/following{/other_user}","gists_url":"https://api.github.com/users/dbczumar/gists{/gist_id}","starred_url":"https://api.github.com/users/dbczumar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbczumar/subscriptions","organizations_url":"https://api.github.com/users/dbczumar/orgs","repos_url":"https://api.github.com/users/dbczumar/repos","events_url":"https://api.github.com/users/dbczumar/events{/privacy}","received_events_url":"https://api.github.com/users/dbczumar/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/6177/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/6177/timeline","performed_via_github_app":null,"state_reason":"completed"}