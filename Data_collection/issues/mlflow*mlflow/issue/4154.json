{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4154","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/4154/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/4154/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/4154/events","html_url":"https://github.com/mlflow/mlflow/issues/4154","id":819404390,"node_id":"MDU6SXNzdWU4MTk0MDQzOTA=","number":4154,"title":"[FR] Allow argument for 'local_dst_path' when loading Pyfunc Models","user":{"login":"ameya-parab","id":75458630,"node_id":"MDQ6VXNlcjc1NDU4NjMw","avatar_url":"https://avatars.githubusercontent.com/u/75458630?v=4","gravatar_id":"","url":"https://api.github.com/users/ameya-parab","html_url":"https://github.com/ameya-parab","followers_url":"https://api.github.com/users/ameya-parab/followers","following_url":"https://api.github.com/users/ameya-parab/following{/other_user}","gists_url":"https://api.github.com/users/ameya-parab/gists{/gist_id}","starred_url":"https://api.github.com/users/ameya-parab/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ameya-parab/subscriptions","organizations_url":"https://api.github.com/users/ameya-parab/orgs","repos_url":"https://api.github.com/users/ameya-parab/repos","events_url":"https://api.github.com/users/ameya-parab/events{/privacy}","received_events_url":"https://api.github.com/users/ameya-parab/received_events","type":"User","site_admin":false},"labels":[{"id":955449434,"node_id":"MDU6TGFiZWw5NTU0NDk0MzQ=","url":"https://api.github.com/repos/mlflow/mlflow/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":955449436,"node_id":"MDU6TGFiZWw5NTU0NDk0MzY=","url":"https://api.github.com/repos/mlflow/mlflow/labels/good%20first%20issue","name":"good first issue","color":"7057ff","default":true,"description":"Good for newcomers"},{"id":2022845866,"node_id":"MDU6TGFiZWwyMDIyODQ1ODY2","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/artifacts","name":"area/artifacts","color":"48eabc","default":false,"description":"Artifact stores and artifact logging"},{"id":2022848043,"node_id":"MDU6TGFiZWwyMDIyODQ4MDQz","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/models","name":"area/models","color":"48eabc","default":false,"description":"MLmodel format, model serialization/deserialization, flavors"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":14,"created_at":"2021-03-01T23:28:36Z","updated_at":"2022-06-10T12:35:57Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nCurrently, the 'mlflow.pyfunc.load_model(MODEL_URI)' just accepts the remote model URI (S3 in our case) when trying to load a Python flavored MLFlow model and its artifacts. As part of this call, the load_model method, downloads the artifacts registered when logging the MLFLow model to a temporary directory in the local filesystem for serving. I would like to open a feature request, to allow specifying a local path when calling the load_model function, this would enable the users to download the artifacts and the model to a specific location for further analysis.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\n      - Enables downloading the remote model and its artifacts to a specified location which caters to reduced model loading \r\n         times as the model is directly loaded from a local file path and can be reused by other programs, if required.\r\n- Why is this use case valuable to support for MLflow users in general?\r\n      - The feature will reduce the overall model serving time for large models as the artifacts and the model itself would be \r\n         available at a local filesystem path for multiple programs to use.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n      - This will help us to tackle the long loading times when iniializing the model serving framework as our production \r\n         deployment consists of ensemble of models rather than a single model.\r\n- Why is it currently difficult to achieve this use case?\r\n      - We have a workaround in place to shutil the models and their artifacts from the temporary directories to a different \r\n         location everytime it is initialized by a program, this is not optimized and can be error prone.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [x] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\n```python\r\nimport mlflow\r\n\r\nLOGGED_MODEL_S3_URI : \"s3://buckeet/path/to/the/model/artifacts\"\r\n\r\n# Current API Call\r\nmodel = mlflow.pyfunc.load_model(LOGGED_MODEL_S3_URI)\r\n\r\n# Proposed API Call\r\nmodel = mlflow.pyfunc.load_model(\r\n                    LOGGED_MODEL_S3_URI, \r\n                    local_dst_path=os.path.join(os.path.expanduser(\"~\"), \"model\")\r\n               )\r\n```\r\n\r\n## Proposed solution\r\n\r\nChanges in pyfunc.__init__.py\r\n\r\n```python\r\n\r\n# Current load_model implementation\r\n\r\ndef load_model(model_uri: str, suppress_warnings: bool = True) -> PyFuncModel:\r\n    \"\"\"\r\n    Load a model stored in Python function format.\r\n\r\n    :param model_uri: The location, in URI format, of the MLflow model. For example:\r\n\r\n                      - ``/Users/me/path/to/local/model``\r\n                      - ``relative/path/to/local/model``\r\n                      - ``s3://my_bucket/path/to/model``\r\n                      - ``runs:/<mlflow_run_id>/run-relative/path/to/model``\r\n                      - ``models:/<model_name>/<model_version>``\r\n                      - ``models:/<model_name>/<stage>``\r\n\r\n                      For more information about supported URI schemes, see\r\n                      `Referencing Artifacts <https://www.mlflow.org/docs/latest/concepts.html#\r\n                      artifact-locations>`_.\r\n    :param suppress_warnings: If ``True``, non-fatal warning messages associated with the model\r\n                              loading process will be suppressed. If ``False``, these warning\r\n                              messages will be emitted.\r\n    \"\"\"\r\n    local_path = _download_artifact_from_uri(artifact_uri=model_uri)\r\n    model_meta = Model.load(os.path.join(local_path, MLMODEL_FILE_NAME))\r\n\r\n    conf = model_meta.flavors.get(FLAVOR_NAME)\r\n    if conf is None:\r\n        raise MlflowException(\r\n            'Model does not have the \"{flavor_name}\" flavor'.format(flavor_name=FLAVOR_NAME),\r\n            RESOURCE_DOES_NOT_EXIST,\r\n        )\r\n    model_py_version = conf.get(PY_VERSION)\r\n    if not suppress_warnings:\r\n        _warn_potentially_incompatible_py_version_if_necessary(model_py_version=model_py_version)\r\n    if CODE in conf and conf[CODE]:\r\n        code_path = os.path.join(local_path, conf[CODE])\r\n        mlflow.pyfunc.utils._add_code_to_system_path(code_path=code_path)\r\n    data_path = os.path.join(local_path, conf[DATA]) if (DATA in conf) else local_path\r\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n    return PyFuncModel(model_meta=model_meta, model_impl=model_impl)\r\n\r\n\r\n# Proposed load_model implementation\r\n\r\ndef load_model(model_uri: str, local_dst_path: str = None, suppress_warnings: bool = True) -> PyFuncModel:\r\n    \"\"\"\r\n    Load a model stored in Python function format.\r\n\r\n    :param model_uri: The location, in URI format, of the MLflow model. For example:\r\n\r\n                      - ``/Users/me/path/to/local/model``\r\n                      - ``relative/path/to/local/model``\r\n                      - ``s3://my_bucket/path/to/model``\r\n                      - ``runs:/<mlflow_run_id>/run-relative/path/to/model``\r\n                      - ``models:/<model_name>/<model_version>``\r\n                      - ``models:/<model_name>/<stage>``\r\n\r\n                      For more information about supported URI schemes, see\r\n                      `Referencing Artifacts <https://www.mlflow.org/docs/latest/concepts.html#\r\n                      artifact-locations>`_.\r\n    :param local_dst_path: The local file system path to download model and its artifacts. \r\n                              Defaults to `None`.\r\n    :param suppress_warnings: If ``True``, non-fatal warning messages associated with the model\r\n                              loading process will be suppressed. If ``False``, these warning\r\n                              messages will be emitted.\r\n    \"\"\"\r\n    local_path = _download_artifact_from_uri(artifact_uri=model_uri, output_path=local_dst_path)\r\n    model_meta = Model.load(os.path.join(local_path, MLMODEL_FILE_NAME))\r\n\r\n    conf = model_meta.flavors.get(FLAVOR_NAME)\r\n    if conf is None:\r\n        raise MlflowException(\r\n            'Model does not have the \"{flavor_name}\" flavor'.format(flavor_name=FLAVOR_NAME),\r\n            RESOURCE_DOES_NOT_EXIST,\r\n        )\r\n    model_py_version = conf.get(PY_VERSION)\r\n    if not suppress_warnings:\r\n        _warn_potentially_incompatible_py_version_if_necessary(model_py_version=model_py_version)\r\n    if CODE in conf and conf[CODE]:\r\n        code_path = os.path.join(local_path, conf[CODE])\r\n        mlflow.pyfunc.utils._add_code_to_system_path(code_path=code_path)\r\n    data_path = os.path.join(local_path, conf[DATA]) if (DATA in conf) else local_path\r\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n    return PyFuncModel(model_meta=model_meta, model_impl=model_impl)\r\n```","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4154/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/4154/timeline","performed_via_github_app":null,"state_reason":null}