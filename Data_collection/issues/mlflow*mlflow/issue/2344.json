{"url":"https://api.github.com/repos/mlflow/mlflow/issues/2344","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/2344/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/2344/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/2344/events","html_url":"https://github.com/mlflow/mlflow/issues/2344","id":554538409,"node_id":"MDU6SXNzdWU1NTQ1Mzg0MDk=","number":2344,"title":"[FR] Improve MLflow CI times & reduce test flakiness","user":{"login":"smurching","id":2358483,"node_id":"MDQ6VXNlcjIzNTg0ODM=","avatar_url":"https://avatars.githubusercontent.com/u/2358483?v=4","gravatar_id":"","url":"https://api.github.com/users/smurching","html_url":"https://github.com/smurching","followers_url":"https://api.github.com/users/smurching/followers","following_url":"https://api.github.com/users/smurching/following{/other_user}","gists_url":"https://api.github.com/users/smurching/gists{/gist_id}","starred_url":"https://api.github.com/users/smurching/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/smurching/subscriptions","organizations_url":"https://api.github.com/users/smurching/orgs","repos_url":"https://api.github.com/users/smurching/repos","events_url":"https://api.github.com/users/smurching/events{/privacy}","received_events_url":"https://api.github.com/users/smurching/received_events","type":"User","site_admin":false},"labels":[{"id":955449434,"node_id":"MDU6TGFiZWw5NTU0NDk0MzQ=","url":"https://api.github.com/repos/mlflow/mlflow/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":2022866026,"node_id":"MDU6TGFiZWwyMDIyODY2MDI2","url":"https://api.github.com/repos/mlflow/mlflow/labels/priority/backlog","name":"priority/backlog","color":"534cb5","default":false,"description":"We believe it is useful, but donâ€™t see it being prioritized in the next few months."},{"id":2042304474,"node_id":"MDU6TGFiZWwyMDQyMzA0NDc0","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/build","name":"area/build","color":"48eabc","default":false,"description":"Build and test infrastructure for MLflow"}],"state":"closed","locked":false,"assignee":{"login":"harupy","id":17039389,"node_id":"MDQ6VXNlcjE3MDM5Mzg5","avatar_url":"https://avatars.githubusercontent.com/u/17039389?v=4","gravatar_id":"","url":"https://api.github.com/users/harupy","html_url":"https://github.com/harupy","followers_url":"https://api.github.com/users/harupy/followers","following_url":"https://api.github.com/users/harupy/following{/other_user}","gists_url":"https://api.github.com/users/harupy/gists{/gist_id}","starred_url":"https://api.github.com/users/harupy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harupy/subscriptions","organizations_url":"https://api.github.com/users/harupy/orgs","repos_url":"https://api.github.com/users/harupy/repos","events_url":"https://api.github.com/users/harupy/events{/privacy}","received_events_url":"https://api.github.com/users/harupy/received_events","type":"User","site_admin":false},"assignees":[{"login":"harupy","id":17039389,"node_id":"MDQ6VXNlcjE3MDM5Mzg5","avatar_url":"https://avatars.githubusercontent.com/u/17039389?v=4","gravatar_id":"","url":"https://api.github.com/users/harupy","html_url":"https://github.com/harupy","followers_url":"https://api.github.com/users/harupy/followers","following_url":"https://api.github.com/users/harupy/following{/other_user}","gists_url":"https://api.github.com/users/harupy/gists{/gist_id}","starred_url":"https://api.github.com/users/harupy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harupy/subscriptions","organizations_url":"https://api.github.com/users/harupy/orgs","repos_url":"https://api.github.com/users/harupy/repos","events_url":"https://api.github.com/users/harupy/events{/privacy}","received_events_url":"https://api.github.com/users/harupy/received_events","type":"User","site_admin":false}],"milestone":null,"comments":3,"created_at":"2020-01-24T04:30:05Z","updated_at":"2020-07-20T05:52:06Z","closed_at":"2020-07-20T05:51:56Z","author_association":"COLLABORATOR","active_lock_reason":null,"body":"## Overview\r\nThis probably resonates with many of you - as we've added new functionality to MLflow, CI times have grown, and unfortunately [test flakiness](https://testing.googleblog.com/2016/05/flaky-tests-at-google-and-how-we.html) has increased (largely within the Python build). Moreover, the MLflow master build has broken increasingly frequently as the set of test dependencies has grown. We should consider ways to improve this & make the MLflow development loop faster & more stable for everyone. Your thoughts & ideas are welcome here!\r\n\r\n## Goals\r\nTo start the discussion, I'd propose that we define a couple of key metrics & aim to improve on them (welcome to other ideas here):\r\n1. **Pass rate of CI builds on the `master` branch**: when PRs are merged into MLflow, we trigger a run of all tests against the master branch. The pass rate of these builds relates closely to test flakiness, in that we only merge PRs that pass all tests, so a master-build failure indicates that a test passed on a PR and then failed when merged into master (is flaky).\r\n2. **Average open-source PR build time**: we should aim to reduce this without compromising on test coverage\r\n3. **Number of master build breakages** : this differs from 1 & refers specifically to the master build being deterministically broken (e.g. most often this occurs due to changes or breakages in test dependencies).\r\n\r\n## Potential Solutions\r\n\r\n### Pass rate of CI builds on the `master` branch\r\nA first step would be to measure this - we can get a rough idea of build pass rate via [Travis CI insights](https://travis-ci.org/mlflow?tab=insights), but cannot view pass rates per build. A more involved alternative would be to export test results to a third-party aggregator & view summary stats there. On Travis CI, we might achieve this through use of [Build Artifacts](https://docs.travis-ci.com/user/uploading-artifacts/) (i.e. export the results of master builds as artifacts in a format like jUnit XML). Other CI tools (e.g. [Circle CI](https://circleci.com/docs/2.0/collect-test-data/)) allow for the same flow, but simplified (& provides native visualization of test failures/pass rates etc).\r\n\r\nOnce we can measure & identify tests that are failing in master, we can take action to fix them, and temporarily mitigate the impact of their flakiness via tools like https://github.com/box/flaky (for Python tests at least).\r\n\r\n### Average open-source PR build time\r\nHistorically, we've attempted to improve build times by grouping tests into stages & that run serially (failures of any tests in earlier stages prevents execution of later stages), e.g. gated execution of large integration tests on smaller unit tests passing. \r\n\r\nMost MLflow PRs involve well-scoped changes that affect only a limited set of functionality (this is a good thing), but we nonetheless run every unit/integration test on each push. We would therefore likely see significant reductions from the use of selective test execution like that provided by [testmon](https://testmon.org/) for Python, i.e. only running tests corresponding to changed code. We can still run the full set of tests on merges to master as a failsafe, but other large projects (e.g. [conda](https://github.com/tarpas/pytest-testmon/network/dependents?dependents_after=NjQwNjg1OTk4OQ&package_id=UGFja2FnZS01MjUwMzA3Ng%3D%3D))  seem to successfully depend on testmon.\r\n\r\n### Number of master build breakages\r\nEntirely preventing breakages caused by changes in third-party dependencies is difficult unless we remove said dependencies. However, selective test execution as discussed above could reduce this (by simply not executing broken tests). Similarly, we could pull per-framework modules out of MLflow (e.g. pull the `mlflow.tensorflow` module into its own package & test/maintain it independently of MLflow core). \r\n\r\n\r\n## Proposal\r\nTackle low-hanging fruit first & migrate to Circle CI in order to address longer-term issues/challenges of visibility into test pass rates, etc. Circle CI also seems to have a [cleaner config format](https://circleci.com/docs/2.0/sample-config/#sample-configuration-with-sequential-workflow) (i.e. no \"default\" build stage), other nice features like support for [custom docker images](https://circleci.com/docs/2.0/custom-images/), & is [used by other OSS projects](https://circleci.com/open-source/) like React, PyTorch, etc\r\n\r\n#### Short Term\r\n* (~2 person-days) Investigate selective test execution via testmon to speed CI times\r\n* (~1 person-day / ongoing) Use https://github.com/box/flaky & proactively label flaky tests to reduce their impact on build success/failure until they're fixed\r\n* (~4 days) Investigate ways to cache MLflow test environment for faster & more robust env setup, e.g:\r\n  * Build a docker image containing MLflow test dependencies & configure CircleCI to update this image (push to DockerHub) on merges. Should make sure we consider if & how this complicates the process of updating or adding new test dependencies in the process. Will also need to figure out how to make this work with builds that run against non-master branches (do they all run against the same test docker image?).\r\n  * Use [Circle CI's build caching](https://circleci.com/docs/2.0/caching/) to cache the conda installation directory\r\n#### Medium-term\r\n* (~2 person-days) Start migrating to Circle CI, by first enabling it alongside Travis CI & only merging PRs when Travis passes. Requires refactoring Travis build logic to run on Circle CI\r\n\r\n#### Longer-term:\r\n* (~1 person day) Switch over to Circle CI, once we have confidence in its stability & speed.\r\n* (~3+ person days) Fix all flaky tests (once we switch to Circle CI, it should be easier to identify which tests are in fact flaky)\r\n\r\n## Alternatives\r\n\r\n### Use other CI systems/tools\r\nWould love to hear suggestions/recommendations on other CI systems or tools that'd help achieve our goals.\r\n\r\n### Continue using Travis CI\r\nOne alternative would be to stick with Travis CI - in this world, the proposal above might change to become:\r\n\r\n#### Short Term\r\n* (~2 person-days) Investigate selective test execution via testmon to speed CI times\r\n* (~1 person-day / ongoing) Use https://github.com/box/flaky & proactively label flaky tests to reduce their impact on build success/failure until they're fixed\r\n* (~4 days) Investigate ways to cache MLflow test environment for faster & more robust env setup, e.g:\r\n  * Build a docker image containing MLflow test dependencies & configure Travis to update this image (push to DockerHub) on merges. Should make sure we consider if & how this complicates the process of updating or adding new test dependencies in the process. Will also need to figure out how to make this work with builds that run against non-master branches (do they all run against the same test docker image?).\r\n  * Use [Travis CI's build caching](https://docs.travis-ci.com/user/caching/) to cache the conda installation directory\r\n\r\n#### Medium Term\r\n* (~1 person-days) Use Travis build artifacts to upload test reports to S3\r\n* (? person-days) Configure a third-party service to consume test reports & provide summary statistics on test pass rates\r\n\r\n#### Longer Term\r\n* (~3+ person days) Fix all flaky tests\r\n\r\n\r\n","closed_by":{"login":"smurching","id":2358483,"node_id":"MDQ6VXNlcjIzNTg0ODM=","avatar_url":"https://avatars.githubusercontent.com/u/2358483?v=4","gravatar_id":"","url":"https://api.github.com/users/smurching","html_url":"https://github.com/smurching","followers_url":"https://api.github.com/users/smurching/followers","following_url":"https://api.github.com/users/smurching/following{/other_user}","gists_url":"https://api.github.com/users/smurching/gists{/gist_id}","starred_url":"https://api.github.com/users/smurching/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/smurching/subscriptions","organizations_url":"https://api.github.com/users/smurching/orgs","repos_url":"https://api.github.com/users/smurching/repos","events_url":"https://api.github.com/users/smurching/events{/privacy}","received_events_url":"https://api.github.com/users/smurching/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/2344/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/2344/timeline","performed_via_github_app":null,"state_reason":"completed"}