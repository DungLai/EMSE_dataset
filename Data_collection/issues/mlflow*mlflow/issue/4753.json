{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4753","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/4753/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/4753/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/4753/events","html_url":"https://github.com/mlflow/mlflow/issues/4753","id":981923524,"node_id":"MDU6SXNzdWU5ODE5MjM1MjQ=","number":4753,"title":"[FR] Autoscaling MLFlow Registry Docker Instance in Kubernetes","user":{"login":"rajatonit","id":12436987,"node_id":"MDQ6VXNlcjEyNDM2OTg3","avatar_url":"https://avatars.githubusercontent.com/u/12436987?v=4","gravatar_id":"","url":"https://api.github.com/users/rajatonit","html_url":"https://github.com/rajatonit","followers_url":"https://api.github.com/users/rajatonit/followers","following_url":"https://api.github.com/users/rajatonit/following{/other_user}","gists_url":"https://api.github.com/users/rajatonit/gists{/gist_id}","starred_url":"https://api.github.com/users/rajatonit/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rajatonit/subscriptions","organizations_url":"https://api.github.com/users/rajatonit/orgs","repos_url":"https://api.github.com/users/rajatonit/repos","events_url":"https://api.github.com/users/rajatonit/events{/privacy}","received_events_url":"https://api.github.com/users/rajatonit/received_events","type":"User","site_admin":false},"labels":[{"id":955449434,"node_id":"MDU6TGFiZWw5NTU0NDk0MzQ=","url":"https://api.github.com/repos/mlflow/mlflow/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":2022847714,"node_id":"MDU6TGFiZWwyMDIyODQ3NzE0","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/model-registry","name":"area/model-registry","color":"48eabc","default":false,"description":"Model registry, model registry APIs, and the fluent client calls for model registry"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-08-28T20:39:57Z","updated_at":"2021-09-07T19:11:38Z","closed_at":"2021-09-07T19:11:38Z","author_association":"NONE","active_lock_reason":null,"body":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [x] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\nI am not sure if this is the right place to ask this, close if it isn't. \r\nBeing able to autoscale an MLFlow Registry docker containerized image in Kubernetes, so that if multiple users are using MLFlow or MLFlow is in high demand, it can autoscale out and send traffic to other instances. *Not sure if this is already thought of*\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\nTo allow ML flow to run in parallel with multiple VM's or machines/pods\r\n- Why is this use case valuable to support for MLflow users in general?\r\nIf users have demanding MLFlow ML projects or have many users, they may want multiple instances that work in unison and run ML tasks\r\n- Why is this use case valuable to support for your project(s) or organization?\r\nI have a data science team of 23 people who want to use MLFlow. And they might use it at all at once and at different times of day. My VM is restricted to 128gb of ram and 16 cpu units. So if 23 of them exceed it, then MLFlow would refuse to run any further items, and I would like to autoscale out to another VM and have a load balancer or queue to adjust what VM runs what ML task\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nI am not sure if it's possible. I wanted to reach out and ask. To me, scaling might be a difficult problem as if an ML task is running on a cluster, and half way through the task uses fewer resources (cpu, memory, etc), the VM might terminate based on the thresholds that were set on the scale in policy\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [x] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations\r\n\r\n","closed_by":{"login":"rajatonit","id":12436987,"node_id":"MDQ6VXNlcjEyNDM2OTg3","avatar_url":"https://avatars.githubusercontent.com/u/12436987?v=4","gravatar_id":"","url":"https://api.github.com/users/rajatonit","html_url":"https://github.com/rajatonit","followers_url":"https://api.github.com/users/rajatonit/followers","following_url":"https://api.github.com/users/rajatonit/following{/other_user}","gists_url":"https://api.github.com/users/rajatonit/gists{/gist_id}","starred_url":"https://api.github.com/users/rajatonit/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rajatonit/subscriptions","organizations_url":"https://api.github.com/users/rajatonit/orgs","repos_url":"https://api.github.com/users/rajatonit/repos","events_url":"https://api.github.com/users/rajatonit/events{/privacy}","received_events_url":"https://api.github.com/users/rajatonit/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4753/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/4753/timeline","performed_via_github_app":null,"state_reason":"completed"}