{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4025","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/4025/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/4025/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/4025/events","html_url":"https://github.com/mlflow/mlflow/issues/4025","id":794895720,"node_id":"MDU6SXNzdWU3OTQ4OTU3MjA=","number":4025,"title":"[BUG] mlflow.pyfunc.log_model doesn't work correctly when artifact storage is HDFS and artifact size is greater than 2gb","user":{"login":"skrasovsky","id":4233055,"node_id":"MDQ6VXNlcjQyMzMwNTU=","avatar_url":"https://avatars.githubusercontent.com/u/4233055?v=4","gravatar_id":"","url":"https://api.github.com/users/skrasovsky","html_url":"https://github.com/skrasovsky","followers_url":"https://api.github.com/users/skrasovsky/followers","following_url":"https://api.github.com/users/skrasovsky/following{/other_user}","gists_url":"https://api.github.com/users/skrasovsky/gists{/gist_id}","starred_url":"https://api.github.com/users/skrasovsky/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/skrasovsky/subscriptions","organizations_url":"https://api.github.com/users/skrasovsky/orgs","repos_url":"https://api.github.com/users/skrasovsky/repos","events_url":"https://api.github.com/users/skrasovsky/events{/privacy}","received_events_url":"https://api.github.com/users/skrasovsky/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":2022845866,"node_id":"MDU6TGFiZWwyMDIyODQ1ODY2","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/artifacts","name":"area/artifacts","color":"48eabc","default":false,"description":"Artifact stores and artifact logging"},{"id":2022847714,"node_id":"MDU6TGFiZWwyMDIyODQ3NzE0","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/model-registry","name":"area/model-registry","color":"48eabc","default":false,"description":"Model registry, model registry APIs, and the fluent client calls for model registry"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-27T08:45:21Z","updated_at":"2021-01-27T09:20:42Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04.7 LTS\r\n- **MLflow installed from (source or binary)**:\r\n- **MLflow version (run ``mlflow --version``)**: 1.10.0\r\n- **Python version**: 3.6\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI use HDFS as a storage for MLflow artifacts. When the size of an artifact is greater than to 2gb, the **mlflow.pyfunc.log_model** throws an exception _\"HDFS Write failed\"_  (full stacktrace see in the section below). \r\nExpected behavior: the artifact is uploaded to HDFS.\r\n\r\nThe issue itself comes from pyarrow library, see https://issues.apache.org/jira/browse/ARROW-11391 .\r\nAnswer from pyarrow community:\r\n```\r\nIt appears that writes over 2GB are implemented incorrectly.\r\nhttps://github.com/apache/arrow/blob/master/cpp/src/arrow/io/hdfs.cc#L277\r\n\r\nthe tSize type in libhdfs is an int32_t. So that static cast is truncating data\r\n\r\nI would recommend breaking the work into smaller pieces as a workaround\r\n```\r\n\r\n### Code to reproduce issue\r\nHow to create a file with specific size:\r\n```\r\ntruncate -s 3G 3g.txt\r\n```\r\nCode to reproduce issue on MLflow side:\r\n```\r\nimport os\r\nimport sys\r\n\r\nimport mlflow\r\nfrom mlflow.pyfunc import PythonModel\r\n\r\nhost = \"<hadoop_master_namenode>\"\r\nport = \"8020\"\r\nmflow_artifact_location = \"/<artifact_location_on_hdfs>\"\r\n\r\nhdfs_artifact_root = \"hdfs://{host}:{port}{path}\".format(\r\n    host=host,\r\n    port=port,\r\n    path=mflow_artifact_location\r\n)\r\n\r\nos.environ[\"JAVA_HOME\"] = \"/opt/adoptopenjdk/jdk-8-default/\"\r\nos.environ[\"ARTIFACT_ROOT_ENV_VAR\"] = hdfs_artifact_root\r\nos.environ[\"MLFLOW_KERBEROS_USER\"] = '<username>'\r\nos.environ['MLFLOW_TRACKING_URI'] = \"http://<host>:5000/\"\r\nos.environ['ARROW_LIBHDFS_DIR'] = \"/<path_to_libhdfs>\"\r\n\r\ndef get_and_create_experiment(experiment_name, artifact_location):\r\n    exp = mlflow.get_experiment_by_name(experiment_name)\r\n    if exp is None:\r\n         mlflow.create_experiment(name=experiment_name, artifact_location=artifact_location)\r\n         exp = mlflow.get_experiment_by_name(experiment_name)\r\n    return exp\r\n\r\nclass CustomModel(PythonModel):\r\n\r\n    def load_context(self, context):\r\n        print(\"=== load_context ===\")\r\n\r\n    def predict(self, context, model_input):\r\n        print(\"=== predict ===\")\r\n        return None\r\n    \r\nartifacts = {\r\n    \"data\": \"3g.txt\"\r\n}\r\n\r\nexperiment_name = \"custom_model_001\"\r\nexperiment = get_and_create_experiment(experiment_name, hdfs_artifact_root)\r\nwith mlflow.start_run(experiment_id=experiment.experiment_id):\r\n    result = mlflow.pyfunc.log_model(\r\n        artifact_path=\"custom_model\",\r\n        python_model=CustomModel(),\r\n        artifacts=artifacts)\r\n```\r\nCode to reproduce the issue on pyarrow side:\r\n```\r\nimport os\r\nimport pyarrow as pa\r\n\r\nos.environ[\"JAVA_HOME\"] = \"/opt/adoptopenjdk/jdk-8-default/\"\r\nos.environ['ARROW_LIBHDFS_DIR'] = \"/<path_to_libhdfs>\"\r\n\r\nconnected = pa.hdfs.connect(host=\"<host>\",port=8020)\r\n\r\ndestination = \"hdfs://<host>:8020/user/tmp/3g.txt\"\r\nsource = \"3g.txt\"\r\n\r\nwith connected.open(destination, \"wb\") as output_stream:\r\n    output_stream.write(open(source, \"rb\").read())\r\n\r\nconnected.close()\r\n```\r\n### Other info / logs\r\n```\r\nsite-packages/mlflow/store/artifact/hdfs_artifact_repo.py in log_artifacts(self, local_dir, artifact_path)\r\n     66                     destination = posixpath.join(hdfs_subdir_path, each_file)\r\n     67                     with hdfs.open(destination, 'wb') as output_stream:\r\n---> 68                         output_stream.write(open(source, \"rb\").read())\r\n     69 \r\n     70     def list_artifacts(self, path=None):\r\n\r\nsite-packages/pyarrow/io.pxi in pyarrow.lib.NativeFile.write()\r\nsite-packages/pyarrow/error.pxi in pyarrow.lib.check_status()\r\n\r\nOSError: HDFS Write failed, errno: 22 (Invalid argument)\r\n```\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [x] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [x] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [x] `language/python`\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4025/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/4025/timeline","performed_via_github_app":null,"state_reason":null}