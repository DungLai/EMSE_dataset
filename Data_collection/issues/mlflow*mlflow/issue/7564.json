{"url":"https://api.github.com/repos/mlflow/mlflow/issues/7564","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/7564/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/7564/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/7564/events","html_url":"https://github.com/mlflow/mlflow/issues/7564","id":1504439589,"node_id":"I_kwDOCB5Jx85Zq-0l","number":7564,"title":"[BUG] Mlflow returns error 504 after uploading large files (800MB +). Error with mlflow.log_artifact()","user":{"login":"Neethugkp","id":47391194,"node_id":"MDQ6VXNlcjQ3MzkxMTk0","avatar_url":"https://avatars.githubusercontent.com/u/47391194?v=4","gravatar_id":"","url":"https://api.github.com/users/Neethugkp","html_url":"https://github.com/Neethugkp","followers_url":"https://api.github.com/users/Neethugkp/followers","following_url":"https://api.github.com/users/Neethugkp/following{/other_user}","gists_url":"https://api.github.com/users/Neethugkp/gists{/gist_id}","starred_url":"https://api.github.com/users/Neethugkp/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Neethugkp/subscriptions","organizations_url":"https://api.github.com/users/Neethugkp/orgs","repos_url":"https://api.github.com/users/Neethugkp/repos","events_url":"https://api.github.com/users/Neethugkp/events{/privacy}","received_events_url":"https://api.github.com/users/Neethugkp/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":2022845866,"node_id":"MDU6TGFiZWwyMDIyODQ1ODY2","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/artifacts","name":"area/artifacts","color":"48eabc","default":false,"description":"Artifact stores and artifact logging"},{"id":2022849295,"node_id":"MDU6TGFiZWwyMDIyODQ5Mjk1","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/tracking","name":"area/tracking","color":"48eabc","default":false,"description":"Tracking service, tracking client APIs, autologging"},{"id":2042304474,"node_id":"MDU6TGFiZWwyMDQyMzA0NDc0","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/build","name":"area/build","color":"48eabc","default":false,"description":"Build and test infrastructure for MLflow"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":8,"created_at":"2022-12-20T11:52:18Z","updated_at":"2023-01-02T17:54:48Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"### Issues Policy acknowledgement\r\n\r\n- [X] I have read and agree to submit bug reports in accordance with the [issues policy](https://www.github.com/mlflow/mlflow/blob/master/ISSUE_POLICY.md)\r\n\r\n### Willingness to contribute\r\n\r\nYes. I can contribute a fix for this bug independently.\r\n\r\n### MLflow version\r\n\r\n- Client: 2.0.1\r\n- Tracking server: 2.0.1\r\n\r\n\r\n### System information\r\n\r\nOS : Red Hat Enterprise Linux release 8.6 (Ootpa)\r\nPython : 3.10.8\r\n\r\n\r\n\r\n### Describe the problem\r\n\r\n\r\n**After uploading 800 + MB files it throws 504 error at client**\r\n\r\n\r\n> mlflow.log_atifacts() throws error at client if the file size is over 800MB . It succesfully uploads the file with the status finish.But at client end it throws an error 504 as below.\r\n\r\n```\r\n(mlflow_env) [userid@server-dl-login4:~/mlflow-testing] $ python run.py\r\nMLflow version: 2.0.1\r\n2022/12/19 18:03:09 INFO mlflow.tracking.fluent: Experiment with name 'mlflow_2_testing' does not exist. Creating a new experiment.\r\nTracking URI: https://mlflow-new-deploy.internal.org.cloud/\r\nexperiment_id 16\r\nActive run_id: d18f0bd33976488d8fa34bc283c8e2a2\r\nwrite output\r\nTraceback (most recent call last):\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/requests/adapters.py\", line 489, in send\r\n    resp = conn.urlopen(\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 878, in urlopen\r\n    return self.urlopen(\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 878, in urlopen\r\n    return self.urlopen(\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 878, in urlopen\r\n    return self.urlopen(\r\n  [Previous line repeated 2 more times]\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 868, in urlopen\r\n    retries = retries.increment(method, url, response=response, _pool=self)\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/urllib3/util/retry.py\", line 592, in increment\r\n    raise MaxRetryError(_pool, url, error or ResponseError(cause))\r\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='https://mlflow-new-deploy.internal.org.cloud', port=443): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/16/d18f0bd33976488d8fa34bc283c8e2a2/artifacts/1.8gbfile (Caused by ResponseError('too many 504 error responses')) During handling of the above exception, another exception occurred: Traceback (most recent call last):\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/utils/rest_utils.py\", line 166, in http_request\r\n    return _get_http_response_with_retries(\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/utils/rest_utils.py\", line 97, in _get_http_response_with_retries\r\n    return session.request(method, url, **kwargs)\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/requests/sessions.py\", line 587, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/requests/sessions.py\", line 701, in send\r\n    r = adapter.send(request, **kwargs)\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/requests/adapters.py\", line 556, in send\r\n    raise RetryError(e, request=request)\r\nrequests.exceptions.RetryError: HTTPSConnectionPool(host='mlflow-new-deploy-https://mlflow-new-deploy.internal.org.cloud/', port=443): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/16/d18f0bd33976488d8fa34bc283c8e2a2/artifacts/1.8gbfile (Caused by ResponseError('too many 504 error responses')) During handling of the above exception, another exception occurred: Traceback (most recent call last):\r\n  File \"/home/userid/mlflow-testing/run.py\", line 87, in <module>\r\n    mlflow.log_artifact(\"1.8gbfile\")\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/tracking/fluent.py\", line 778, in log_artifact\r\n    MlflowClient().log_artifact(run_id, local_path, artifact_path)\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/tracking/client.py\", line 1002, in log_artifact\r\n    self._tracking_client.log_artifact(run_id, local_path, artifact_path)\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py\", line 416, in log_artifact\r\n    artifact_repo.log_artifact(local_path, artifact_path)\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/store/artifact/http_artifact_repo.py\", line 25, in log_artifact\r\n    resp = http_request(self._host_creds, endpoint, \"PUT\", data=f)\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/utils/rest_utils.py\", line 184, in http_request\r\n    raise MlflowException(\"API request to %s failed with exception %s\" % (url, e))\r\nmlflow.exceptions.MlflowException: API request to https://mlflow-new-deploy.internal.org.cloud/api/2.0/mlflow-artifacts/artifacts/16/d18f0bd33976488d8fa34bc283c8e2a2/artifacts/1.8gbfile failed with exception HTTPSConnectionPool(host='mlflow-new-deploy.internal.org.cloud', port=443): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/16/d18f0bd33976488d8fa34bc283c8e2a2/artifacts/1.8gbfile (Caused by ResponseError('too many 504 error responses'))\r\n```\r\n\r\n### Tracking information\r\n```\r\npython run.py\r\nMLflow version: 2.0.1\r\nTracking URI: https://mlflow-new-deploy.internal.org.com/\r\nexperiment_id 17\r\nSystem information: Linux #1 SMP Mon Jul 18 11:14:02 EDT 2022\r\nPython version: 3.10.8\r\nMLflow version: 2.0.1\r\nMLflow module location: /home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/__init__.py\r\nTracking URI: https://mlflow-new-deploy.internal.org.com/\r\nRegistry URI: https://mlflow-new-deploy.internal.org.com/\r\nActive experiment ID: 17\r\nActive run ID: 3a80930872d24ad0b0f245bc66d039ff\r\nActive run artifact URI: mlflow-artifacts:/17/3a80930872d24ad0b0f245bc66d039ff/artifacts\r\nMLflow environment variables: {\r\n    \"MLFLOW_TRACKING_INSECURE_TLS\": \"True\"\r\n}\r\nMLflow dependencies: {\r\n    \"click\": \"8.1.3\",\r\n    \"cloudpickle\": \"2.2.0\",\r\n    \"databricks-cli\": \"0.17.4\",\r\n    \"entrypoints\": \"0.4\",\r\n    \"gitpython\": \"3.1.29\",\r\n    \"pyyaml\": \"6.0\",\r\n    \"protobuf\": \"4.21.11\",\r\n    \"pytz\": \"2022.7\",\r\n    \"requests\": \"2.28.1\",\r\n    \"packaging\": \"21.3\",\r\n    \"importlib-metadata\": \"5.2.0\",\r\n    \"sqlparse\": \"0.4.3\",\r\n    \"alembic\": \"1.9.0\",\r\n    \"docker\": \"6.0.0\",\r\n    \"Flask\": \"2.2.2\",\r\n    \"numpy\": \"1.23.5\",\r\n    \"scipy\": \"1.9.3\",\r\n    \"pandas\": \"1.5.2\",\r\n    \"querystring-parser\": \"1.2.4\",\r\n    \"sqlalchemy\": \"1.4.45\",\r\n    \"scikit-learn\": \"1.2.0\",\r\n    \"pyarrow\": \"10.0.1\",\r\n    \"shap\": \"0.41.0\",\r\n    \"markdown\": \"3.4.1\",\r\n    \"matplotlib\": \"3.6.2\",\r\n    \"gunicorn\": \"20.1.0\",\r\n    \"Jinja2\": \"3.1.2\"\r\n}\r\nwrite output\r\n```\r\n> In case of larger file output freezes at this point and later shows 504 error\r\n\r\n\r\n==================================\r\n\r\nCommand :-\r\n\r\n              mlflow db upgrade \"${BACKEND_URI}\"; mlflow server --host 0.0.0.0\r\n              --backend-store-uri \"${BACKEND_URI}\" --artifacts-destination\r\n              \"${ARTIFACT_ROOT}/mlartifacts/\" --serve-artifacts --gunicorn-opts\r\n              \"--log-level debug --timeout 8000 --graceful-timeout 75\r\n              --keep-alive 3600\" --expose-prometheus \"/mlflow/metrics\"  \r\n-----------------------------------------------------\r\n\r\n> Keep-alive and timeout is added as part of troubleshooting\r\n\r\n\r\n### Code to reproduce issue\r\nCode :-\r\n```\r\nimport os\r\nimport mlflow\r\nfrom mlflow.tracking import MlflowClient\r\nfrom random import random, randint\r\nfrom mlflow import log_metric, log_param, log_artifacts\r\nfrom mlflow.store.artifact.runs_artifact_repo import RunsArtifactRepository\r\nfrom mlflow.tracking import MlflowClient\r\nfrom mlflow.store.artifact.mlflow_artifacts_repo import MlflowArtifactsRepository\r\nfrom mlflow.store.tracking import DEFAULT_ARTIFACTS_URI\r\nimport boto3\r\nimport requests\r\nimport sys\r\n\r\nmlflow.set_tracking_uri('https://mlflow-new-deploy.internal.org.cloud/')\r\nclient = MlflowClient()\r\nexperiment_name= 'mlflow_2.0.1_testing'\r\n\r\nprint(\"MLflow version:\", mlflow.__version__)\r\n\r\nmlflow.set_experiment(experiment_name)\r\n\r\nprint(\"Tracking URI:\", mlflow.get_tracking_uri())\r\n\r\nexperiment_id = client.get_experiment_by_name(experiment_name).experiment_id\r\nprint(\"experiment_id\",experiment_id)\r\nexperiment = mlflow.get_experiment(experiment_id)\r\nmlflow.start_run()\r\nmlflow.doctor()\r\nmlflow.log_metric(\"foo\", 2)\r\nmlflow.log_metric(\"a\", 4)\r\nprint (\"write output\")\r\nmlflow.log_artifact(\"largefile_latest\")\r\nprint(\"Artifact URI:\",mlflow.get_artifact_uri())\r\nprint(\"Artifact Location: {}\".format(experiment.artifact_location))\r\n\r\nartifact_uri = mlflow.get_artifact_uri()\r\nmlflow.end_run()\r\n\r\n```\r\n--------------------------------------------------------------\r\n\r\n### Stack trace\r\n\r\n```\r\n(mlflow_env) [userid@server-dl-login4:~/mlflow-testing] $ python run.py\r\nMLflow version: 2.0.1\r\n2022/12/19 18:03:09 INFO mlflow.tracking.fluent: Experiment with name 'mlflow_2_testing' does not exist. Creating a new experiment.\r\nTracking URI: https://mlflow-new-deploy.internal.org.cloud/\r\nexperiment_id 16\r\nActive run_id: d18f0bd33976488d8fa34bc283c8e2a2\r\nwrite output\r\nTraceback (most recent call last):\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/requests/adapters.py\", line 489, in send\r\n    resp = conn.urlopen(\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 878, in urlopen\r\n    return self.urlopen(\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 878, in urlopen\r\n    return self.urlopen(\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 878, in urlopen\r\n    return self.urlopen(\r\n  [Previous line repeated 2 more times]\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 868, in urlopen\r\n    retries = retries.increment(method, url, response=response, _pool=self)\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/urllib3/util/retry.py\", line 592, in increment\r\n    raise MaxRetryError(_pool, url, error or ResponseError(cause))\r\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='https://mlflow-new-deploy.internal.org.cloud', port=443): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/16/d18f0bd33976488d8fa34bc283c8e2a2/artifacts/1.8gbfile (Caused by ResponseError('too many 504 error responses')) During handling of the above exception, another exception occurred: Traceback (most recent call last):\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/utils/rest_utils.py\", line 166, in http_request\r\n    return _get_http_response_with_retries(\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/utils/rest_utils.py\", line 97, in _get_http_response_with_retries\r\n    return session.request(method, url, **kwargs)\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/requests/sessions.py\", line 587, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/requests/sessions.py\", line 701, in send\r\n    r = adapter.send(request, **kwargs)\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/requests/adapters.py\", line 556, in send\r\n    raise RetryError(e, request=request)\r\nrequests.exceptions.RetryError: HTTPSConnectionPool(host='mlflow-new-deploy-https://mlflow-new-deploy.internal.org.cloud/', port=443): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/16/d18f0bd33976488d8fa34bc283c8e2a2/artifacts/1.8gbfile (Caused by ResponseError('too many 504 error responses')) During handling of the above exception, another exception occurred: Traceback (most recent call last):\r\n  File \"/home/userid/mlflow-testing/run.py\", line 87, in <module>\r\n    mlflow.log_artifact(\"1.8gbfile\")\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/tracking/fluent.py\", line 778, in log_artifact\r\n    MlflowClient().log_artifact(run_id, local_path, artifact_path)\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/tracking/client.py\", line 1002, in log_artifact\r\n    self._tracking_client.log_artifact(run_id, local_path, artifact_path)\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py\", line 416, in log_artifact\r\n    artifact_repo.log_artifact(local_path, artifact_path)\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/store/artifact/http_artifact_repo.py\", line 25, in log_artifact\r\n    resp = http_request(self._host_creds, endpoint, \"PUT\", data=f)\r\n  File \"/home/userid/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/utils/rest_utils.py\", line 184, in http_request\r\n    raise MlflowException(\"API request to %s failed with exception %s\" % (url, e))\r\nmlflow.exceptions.MlflowException: API request to https://mlflow-new-deploy.internal.org.cloud/api/2.0/mlflow-artifacts/artifacts/16/d18f0bd33976488d8fa34bc283c8e2a2/artifacts/1.8gbfile failed with exception HTTPSConnectionPool(host='mlflow-new-deploy.internal.org.cloud', port=443): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/16/d18f0bd33976488d8fa34bc283c8e2a2/artifacts/1.8gbfile (Caused by ResponseError('too many 504 error responses'))\r\n```\r\n\r\n\r\n### Other info / logs\r\n\r\n```\r\n2022/12/20 05:49:18 INFO mlflow.store.db.utils: Updating database tables\r\nINFO  [alembic.runtime.migration] Context impl MSSQLImpl.\r\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\r\n[2022-12-20 05:49:22 +0000] [73] [DEBUG] Current configuration:\r\n  config: ./gunicorn.conf.py\r\n  wsgi_app: None\r\n  bind: ['0.0.0.0:5000']\r\n  backlog: 2048\r\n  workers: 4\r\n  worker_class: sync\r\n  threads: 1\r\n  worker_connections: 1000\r\n  max_requests: 0\r\n  max_requests_jitter: 0\r\n  timeout: 8000\r\n  graceful_timeout: 75\r\n  keepalive: 3600\r\n  limit_request_line: 4094\r\n  limit_request_fields: 100\r\n  limit_request_field_size: 8190\r\n  reload: False\r\n  reload_engine: auto\r\n  reload_extra_files: []\r\n  spew: False\r\n  check_config: False\r\n  print_config: False\r\n  preload_app: False\r\n  sendfile: None\r\n  reuse_port: False\r\n  chdir: /\r\n  daemon: False\r\n  raw_env: []\r\n  pidfile: None\r\n  worker_tmp_dir: None\r\n  user: 1002930000\r\n  group: 0\r\n  umask: 0\r\n  initgroups: False\r\n  tmp_upload_dir: None\r\n  secure_scheme_headers: {'X-FORWARDED-PROTOCOL': 'ssl', 'X-FORWARDED-PROTO': 'https', 'X-FORWARDED-SSL': 'on'}\r\n  forwarded_allow_ips: ['127.0.0.1']\r\n  accesslog: None\r\n  disable_redirect_access_to_syslog: False\r\n  access_log_format: %(h)s %(l)s %(u)s %(t)s \"%(r)s\" %(s)s %(b)s \"%(f)s\" \"%(a)s\"\r\n  errorlog: -\r\n  loglevel: debug\r\n  capture_output: False\r\n  logger_class: gunicorn.glogging.Logger\r\n  logconfig: None\r\n  logconfig_dict: {}\r\n  syslog_addr: udp://localhost:514\r\n  syslog: False\r\n  syslog_prefix: None\r\n  syslog_facility: user\r\n  enable_stdio_inheritance: False\r\n  statsd_host: None\r\n  dogstatsd_tags: \r\n  statsd_prefix: \r\n  proc_name: None\r\n  default_proc_name: mlflow.server:app\r\n  pythonpath: None\r\n  paste: None\r\n  on_starting: <function OnStarting.on_starting at 0x7f7e3a55a680>\r\n  on_reload: <function OnReload.on_reload at 0x7f7e3a55a7a0>\r\n  when_ready: <function WhenReady.when_ready at 0x7f7e3a55a8c0>\r\n  pre_fork: <function Prefork.pre_fork at 0x7f7e3a55a9e0>\r\n  post_fork: <function Postfork.post_fork at 0x7f7e3a55ab00>\r\n  post_worker_init: <function PostWorkerInit.post_worker_init at 0x7f7e3a55ac20>\r\n  worker_int: <function WorkerInt.worker_int at 0x7f7e3a55ad40>\r\n  worker_abort: <function WorkerAbort.worker_abort at 0x7f7e3a55ae60>\r\n  pre_exec: <function PreExec.pre_exec at 0x7f7e3a55af80>\r\n  pre_request: <function PreRequest.pre_request at 0x7f7e3a55b0a0>\r\n  post_request: <function PostRequest.post_request at 0x7f7e3a55b130>\r\n  child_exit: <function ChildExit.child_exit at 0x7f7e3a55b250>\r\n  worker_exit: <function WorkerExit.worker_exit at 0x7f7e3a55b370>\r\n  nworkers_changed: <function NumWorkersChanged.nworkers_changed at 0x7f7e3a55b490>\r\n  on_exit: <function OnExit.on_exit at 0x7f7e3a55b5b0>\r\n  proxy_protocol: False\r\n  proxy_allow_ips: ['127.0.0.1']\r\n  keyfile: None\r\n  certfile: None\r\n  ssl_version: 2\r\n  cert_reqs: 0\r\n  ca_certs: None\r\n  suppress_ragged_eofs: True\r\n  do_handshake_on_connect: False\r\n  ciphers: None\r\n  raw_paste_global_conf: []\r\n  strip_header_spaces: False\r\n[2022-12-20 05:49:22 +0000] [73] [INFO] Starting gunicorn 20.1.0\r\n[2022-12-20 05:49:22 +0000] [73] [DEBUG] Arbiter booted\r\n[2022-12-20 05:49:22 +0000] [73] [INFO] Listening at: http://0.0.0.0:5000 (73)\r\n[2022-12-20 05:49:22 +0000] [73] [INFO] Using worker: sync\r\n[2022-12-20 05:49:22 +0000] [74] [INFO] Booting worker with pid: 74\r\n[2022-12-20 05:49:22 +0000] [75] [INFO] Booting worker with pid: 75\r\n[2022-12-20 05:49:22 +0000] [76] [INFO] Booting worker with pid: 76\r\n[2022-12-20 05:49:22 +0000] [77] [INFO] Booting worker with pid: 77\r\n[2022-12-20 05:49:22 +0000] [73] [DEBUG] 4 workers\r\n[2022-12-20 05:49:33 +0000] [75] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 05:57:30 +0000] [77] [DEBUG] GET /api/2.0/mlflow/experiments/get-by-name\r\n[2022-12-20 05:57:30 +0000] [77] [DEBUG] GET /api/2.0/mlflow/experiments/get-by-name\r\n[2022-12-20 05:57:30 +0000] [77] [DEBUG] GET /api/2.0/mlflow/experiments/get\r\n[2022-12-20 05:57:30 +0000] [74] [DEBUG] POST /api/2.0/mlflow/runs/create\r\n[2022-12-20 05:57:30 +0000] [74] [DEBUG] POST /api/2.0/mlflow/runs/log-metric\r\n[2022-12-20 05:57:30 +0000] [74] [DEBUG] POST /api/2.0/mlflow/runs/log-metric\r\n[2022-12-20 05:57:30 +0000] [74] [DEBUG] GET /api/2.0/mlflow/runs/get\r\n[2022-12-20 05:57:30 +0000] [74] [DEBUG] PUT /api/2.0/mlflow-artifacts/artifacts/17/acbc4f3ff7ec4fd3a1fc35c0f91d317c/artifacts/1.8gbfile\r\n[2022-12-20 05:57:38 +0000] [76] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 05:57:47 +0000] [77] [DEBUG] GET /static-files/static/media/fontawesome-webfont.20fd1704ea223900efa9.woff2\r\n[2022-12-20 05:57:49 +0000] [76] [DEBUG] GET /ajax-api/2.0/mlflow/experiments/get\r\n[2022-12-20 05:57:49 +0000] [75] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 05:57:49 +0000] [77] [DEBUG] GET /static-files/static/js/547.a604119a.chunk.js\r\n[2022-12-20 05:57:57 +0000] [76] [DEBUG] GET /static-files/static/media/laptop.f3a6b3016fbf319305f629fcbcf937a9.svg\r\n[2022-12-20 05:58:16 +0000] [76] [DEBUG] PUT /api/2.0/mlflow-artifacts/artifacts/17/acbc4f3ff7ec4fd3a1fc35c0f91d317c/artifacts/1.8gbfile\r\n[2022-12-20 05:58:24 +0000] [75] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 05:58:45 +0000] [74] [DEBUG] Ignoring connection reset\r\n[2022-12-20 05:59:25 +0000] [75] [DEBUG] PUT /api/2.0/mlflow-artifacts/artifacts/17/acbc4f3ff7ec4fd3a1fc35c0f91d317c/artifacts/1.8gbfile\r\n[2022-12-20 05:59:28 +0000] [74] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 05:59:38 +0000] [74] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 05:59:40 +0000] [76] [DEBUG] Ignoring connection reset\r\n[2022-12-20 06:00:28 +0000] [76] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 06:00:28 +0000] [76] [DEBUG] PUT /api/2.0/mlflow-artifacts/artifacts/17/acbc4f3ff7ec4fd3a1fc35c0f91d317c/artifacts/1.8gbfile\r\n[2022-12-20 06:00:38 +0000] [74] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 06:00:41 +0000] [75] [DEBUG] Ignoring connection reset\r\n[2022-12-20 06:00:42 +0000] [74] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 06:01:40 +0000] [76] [DEBUG] Ignoring connection reset\r\n[2022-12-20 06:01:40 +0000] [77] [DEBUG] PUT /api/2.0/mlflow-artifacts/artifacts/17/acbc4f3ff7ec4fd3a1fc35c0f91d317c/artifacts/1.8gbfile\r\n[2022-12-20 06:01:42 +0000] [76] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 06:02:46 +0000] [77] [DEBUG] Ignoring connection reset\r\n[2022-12-20 06:02:49 +0000] [77] [DEBUG] GET /ajax-api/2.0/mlflow/experiments/search\r\n[2022-12-20 06:02:51 +0000] [76] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 06:02:51 +0000] [75] [DEBUG] GET /ajax-api/2.0/mlflow/experiments/get\r\n[2022-12-20 06:02:51 +0000] [75] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 06:02:52 +0000] [77] [DEBUG] GET /ajax-api/2.0/mlflow/experiments/get\r\n[2022-12-20 06:02:53 +0000] [75] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 06:02:54 +0000] [74] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 06:03:00 +0000] [75] [DEBUG] GET /ajax-api/2.0/mlflow/experiments/get\r\n[2022-12-20 06:03:00 +0000] [76] [DEBUG] PUT /api/2.0/mlflow-artifacts/artifacts/17/acbc4f3ff7ec4fd3a1fc35c0f91d317c/artifacts/1.8gbfile\r\n[2022-12-20 06:03:01 +0000] [75] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 06:03:49 +0000] [77] [DEBUG] POST /api/2.0/mlflow/runs/update\r\n[2022-12-20 06:03:54 +0000] [74] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 06:04:02 +0000] [75] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 06:04:09 +0000] [77] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 06:04:12 +0000] [76] [DEBUG] Ignoring connection reset\r\n[2022-12-20 06:04:16 +0000] [75] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 06:08:26 +0000] [77] [DEBUG] GET //\r\n[2022-12-20 06:08:26 +0000] [75] [DEBUG] GET //static-files/static/css/main.3b6f4584.css\r\n[2022-12-20 06:08:26 +0000] [77] [DEBUG] GET //static-files/static/js/main.6125589f.js\r\n[2022-12-20 06:08:34 +0000] [77] [DEBUG] GET //ajax-api/2.0/mlflow/experiments/search\r\n[2022-12-20 06:08:34 +0000] [74] [DEBUG] GET //static-files/static/media/home-logo.b14e3dd7dc63ea1769c6.png\r\n[2022-12-20 06:08:34 +0000] [75] [DEBUG] GET //static-files/static/js/714.c7ed3611.chunk.js\r\n[2022-12-20 06:08:35 +0000] [75] [DEBUG] GET //static-files/favicon.ico\r\n[2022-12-20 06:08:35 +0000] [77] [DEBUG] POST //ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 06:08:35 +0000] [76] [DEBUG] GET //ajax-api/2.0/mlflow/experiments/get\r\n[2022-12-20 06:08:35 +0000] [74] [DEBUG] GET //static-files/static/css/547.f3323e81.chunk.css\r\n[2022-12-20 06:08:35 +0000] [76] [DEBUG] POST //ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 06:08:35 +0000] [76] [DEBUG] GET //static-files/favicon.ico\r\n[2022-12-20 06:08:36 +0000] [74] [DEBUG] GET //static-files/favicon.ico\r\n[2022-12-20 06:08:36 +0000] [74] [DEBUG] GET //static-files/static/js/547.a604119a.chunk.js\r\n[2022-12-20 06:08:36 +0000] [76] [DEBUG] GET //static-files/favicon.ico\r\n[2022-12-20 06:08:36 +0000] [77] [DEBUG] GET //static-files/static/js/869.aae22f22.chunk.js\r\n[2022-12-20 06:08:39 +0000] [75] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n[2022-12-20 06:10:46 +0000] [76] [DEBUG] GET /ajax-api/2.0/mlflow/experiments/get\r\n[2022-12-20 06:10:47 +0000] [76] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search\r\n```\r\n\r\n\r\n### What component(s) does this bug affect?\r\n\r\n- [X] `area/artifacts`: Artifact stores and artifact logging\r\n- [X] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/recipes`: Recipes, Recipe APIs, Recipe configs, Recipe Templates\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [X] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n### What interface(s) does this bug affect?\r\n\r\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\n### What language(s) does this bug affect?\r\n\r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\n### What integration(s) does this bug affect?\r\n\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/7564/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/7564/timeline","performed_via_github_app":null,"state_reason":null}