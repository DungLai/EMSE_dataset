{"url":"https://api.github.com/repos/mlflow/mlflow/issues/6256","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/6256/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/6256/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/6256/events","html_url":"https://github.com/mlflow/mlflow/issues/6256","id":1306477627,"node_id":"I_kwDOCB5Jx85N30Q7","number":6256,"title":"[FR] Spark Model Cache Replacement Policy","user":{"login":"JohnFirth","id":658813,"node_id":"MDQ6VXNlcjY1ODgxMw==","avatar_url":"https://avatars.githubusercontent.com/u/658813?v=4","gravatar_id":"","url":"https://api.github.com/users/JohnFirth","html_url":"https://github.com/JohnFirth","followers_url":"https://api.github.com/users/JohnFirth/followers","following_url":"https://api.github.com/users/JohnFirth/following{/other_user}","gists_url":"https://api.github.com/users/JohnFirth/gists{/gist_id}","starred_url":"https://api.github.com/users/JohnFirth/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JohnFirth/subscriptions","organizations_url":"https://api.github.com/users/JohnFirth/orgs","repos_url":"https://api.github.com/users/JohnFirth/repos","events_url":"https://api.github.com/users/JohnFirth/events{/privacy}","received_events_url":"https://api.github.com/users/JohnFirth/received_events","type":"User","site_admin":false},"labels":[{"id":955449434,"node_id":"MDU6TGFiZWw5NTU0NDk0MzQ=","url":"https://api.github.com/repos/mlflow/mlflow/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"}],"state":"open","locked":false,"assignee":{"login":"WeichenXu123","id":19235986,"node_id":"MDQ6VXNlcjE5MjM1OTg2","avatar_url":"https://avatars.githubusercontent.com/u/19235986?v=4","gravatar_id":"","url":"https://api.github.com/users/WeichenXu123","html_url":"https://github.com/WeichenXu123","followers_url":"https://api.github.com/users/WeichenXu123/followers","following_url":"https://api.github.com/users/WeichenXu123/following{/other_user}","gists_url":"https://api.github.com/users/WeichenXu123/gists{/gist_id}","starred_url":"https://api.github.com/users/WeichenXu123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/WeichenXu123/subscriptions","organizations_url":"https://api.github.com/users/WeichenXu123/orgs","repos_url":"https://api.github.com/users/WeichenXu123/repos","events_url":"https://api.github.com/users/WeichenXu123/events{/privacy}","received_events_url":"https://api.github.com/users/WeichenXu123/received_events","type":"User","site_admin":false},"assignees":[{"login":"WeichenXu123","id":19235986,"node_id":"MDQ6VXNlcjE5MjM1OTg2","avatar_url":"https://avatars.githubusercontent.com/u/19235986?v=4","gravatar_id":"","url":"https://api.github.com/users/WeichenXu123","html_url":"https://github.com/WeichenXu123","followers_url":"https://api.github.com/users/WeichenXu123/followers","following_url":"https://api.github.com/users/WeichenXu123/following{/other_user}","gists_url":"https://api.github.com/users/WeichenXu123/gists{/gist_id}","starred_url":"https://api.github.com/users/WeichenXu123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/WeichenXu123/subscriptions","organizations_url":"https://api.github.com/users/WeichenXu123/orgs","repos_url":"https://api.github.com/users/WeichenXu123/repos","events_url":"https://api.github.com/users/WeichenXu123/events{/privacy}","received_events_url":"https://api.github.com/users/WeichenXu123/received_events","type":"User","site_admin":false}],"milestone":null,"comments":9,"created_at":"2022-07-15T20:44:19Z","updated_at":"2022-08-28T00:18:57Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"### Willingness to contribute\n\nYes. I would be willing to contribute this feature with guidance from the MLflow community.\n\n### Proposal Summary\n\nI'd like the ability to set a cache replacement policy for `SparkModelCache`, which currently has no policy. https://github.com/mlflow/mlflow/blob/9b83b355fc9c64ad1b51c66b1187eaab40d40d61/mlflow/pyfunc/spark_model_cache.py#L15\r\n\n\n### Motivation\n\n> #### What is the use case for this feature?\r\n\r\nPerforming batch inference with multiple models whose combined size would exhaust memory if loading them at the same time were attempted.\r\n\r\n> #### Why is this use case valuable to support for MLflow users in general?\r\n\r\nOthers may wish to perform such an operation. I'm not sure how common the need is.\r\n\r\n> #### Why is this use case valuable to support for your project(s) or organization?\r\n\r\nI'm currently performing batch inference with hundreds of models per Spark cluster, whose individual size can be up to 1GB.\r\n\r\n> #### Why is it currently difficult to achieve this use case?\r\n\r\nThe spark model cache has no replacement policy so attempting the above use case could cause an OOM. https://github.com/mlflow/mlflow/blob/9b83b355fc9c64ad1b51c66b1187eaab40d40d61/mlflow/pyfunc/spark_model_cache.py#L15 \r\n\n\n### Details\n\nPerhaps this could be configured with an environment variable, but I'm not too sure. \r\nHappy to try to supply this feature with some guidance :)\n\n### What component(s) does this bug affect?\n\n- [ ] `area/artifacts`: Artifact stores and artifact logging\n- [ ] `area/build`: Build and test infrastructure for MLflow\n- [ ] `area/docs`: MLflow documentation pages\n- [ ] `area/examples`: Example code\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\n- [ ] `area/pipelines`: Pipelines, Pipeline APIs, Pipeline configs, Pipeline Templates\n- [ ] `area/projects`: MLproject format, project running backends\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\n- [ ] `area/server-infra`: MLflow Tracking server backend\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\n\n### What interface(s) does this bug affect?\n\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\n- [ ] `area/windows`: Windows support\n\n### What language(s) does this bug affect?\n\n- [ ] `language/r`: R APIs and clients\n- [ ] `language/java`: Java APIs and clients\n- [ ] `language/new`: Proposals for new client languages\n\n### What integration(s) does this bug affect?\n\n- [ ] `integrations/azure`: Azure and Azure ML integrations\n- [ ] `integrations/sagemaker`: SageMaker integrations\n- [ ] `integrations/databricks`: Databricks integrations","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/6256/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/6256/timeline","performed_via_github_app":null,"state_reason":null}