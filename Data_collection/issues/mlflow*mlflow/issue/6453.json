{"url":"https://api.github.com/repos/mlflow/mlflow/issues/6453","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/6453/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/6453/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/6453/events","html_url":"https://github.com/mlflow/mlflow/issues/6453","id":1336546620,"node_id":"I_kwDOCB5Jx85PqhU8","number":6453,"title":"[FR] Add environment restoration to `mlflow.pyfunc.load_model` via new `env_manager` parameter","user":{"login":"jerrylian-db","id":66143562,"node_id":"MDQ6VXNlcjY2MTQzNTYy","avatar_url":"https://avatars.githubusercontent.com/u/66143562?v=4","gravatar_id":"","url":"https://api.github.com/users/jerrylian-db","html_url":"https://github.com/jerrylian-db","followers_url":"https://api.github.com/users/jerrylian-db/followers","following_url":"https://api.github.com/users/jerrylian-db/following{/other_user}","gists_url":"https://api.github.com/users/jerrylian-db/gists{/gist_id}","starred_url":"https://api.github.com/users/jerrylian-db/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jerrylian-db/subscriptions","organizations_url":"https://api.github.com/users/jerrylian-db/orgs","repos_url":"https://api.github.com/users/jerrylian-db/repos","events_url":"https://api.github.com/users/jerrylian-db/events{/privacy}","received_events_url":"https://api.github.com/users/jerrylian-db/received_events","type":"User","site_admin":false},"labels":[{"id":955449434,"node_id":"MDU6TGFiZWw5NTU0NDk0MzQ=","url":"https://api.github.com/repos/mlflow/mlflow/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":2022848902,"node_id":"MDU6TGFiZWwyMDIyODQ4OTAy","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/scoring","name":"area/scoring","color":"48eabc","default":false,"description":"MLflow Model server, model deployment tools, Spark UDFs"}],"state":"open","locked":false,"assignee":{"login":"jerrylian-db","id":66143562,"node_id":"MDQ6VXNlcjY2MTQzNTYy","avatar_url":"https://avatars.githubusercontent.com/u/66143562?v=4","gravatar_id":"","url":"https://api.github.com/users/jerrylian-db","html_url":"https://github.com/jerrylian-db","followers_url":"https://api.github.com/users/jerrylian-db/followers","following_url":"https://api.github.com/users/jerrylian-db/following{/other_user}","gists_url":"https://api.github.com/users/jerrylian-db/gists{/gist_id}","starred_url":"https://api.github.com/users/jerrylian-db/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jerrylian-db/subscriptions","organizations_url":"https://api.github.com/users/jerrylian-db/orgs","repos_url":"https://api.github.com/users/jerrylian-db/repos","events_url":"https://api.github.com/users/jerrylian-db/events{/privacy}","received_events_url":"https://api.github.com/users/jerrylian-db/received_events","type":"User","site_admin":false},"assignees":[{"login":"jerrylian-db","id":66143562,"node_id":"MDQ6VXNlcjY2MTQzNTYy","avatar_url":"https://avatars.githubusercontent.com/u/66143562?v=4","gravatar_id":"","url":"https://api.github.com/users/jerrylian-db","html_url":"https://github.com/jerrylian-db","followers_url":"https://api.github.com/users/jerrylian-db/followers","following_url":"https://api.github.com/users/jerrylian-db/following{/other_user}","gists_url":"https://api.github.com/users/jerrylian-db/gists{/gist_id}","starred_url":"https://api.github.com/users/jerrylian-db/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jerrylian-db/subscriptions","organizations_url":"https://api.github.com/users/jerrylian-db/orgs","repos_url":"https://api.github.com/users/jerrylian-db/repos","events_url":"https://api.github.com/users/jerrylian-db/events{/privacy}","received_events_url":"https://api.github.com/users/jerrylian-db/received_events","type":"User","site_admin":false}],"milestone":null,"comments":8,"created_at":"2022-08-11T22:08:34Z","updated_at":"2022-08-19T00:26:52Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"### Willingness to contribute\r\n\r\nYes. I can contribute this feature independently.\r\n\r\n### Proposal Summary\r\n\r\nCurrently,`mlflow.pyfunc.spark_udf` accepts an `env_manager` parameter that enables users to load and score models in an isolated environment with their training time dependencies recovered. We would like to introduce this parameter / feature to the `mlflow.pyfunc.load_model` model flavor and improve model reproducibility for this popular way of loading models.\r\n\r\n### Motivation\r\n\r\n> #### What is the use case for this feature?\r\n\r\nThis feature will make model reproduction simpler. It will be easier to eliminate missing or version-mismatched dependencies for models loaded with `mlflow.pyfunc.load_model`. This would also improve the accuracy and usability of features like model evaluation, which rely on `mlflow.pyfunc.load_model`.\r\n\r\n> #### Why is this use case valuable to support for MLflow users in general?\r\n\r\nMLflow users care about model reproducibility.\r\n\r\n> #### Why is it currently difficult to achieve this use case?\r\n\r\nThere are two options to reproduce a model right now.\r\n1. Manually download the model requirements from the model artifacts and install them in the python script or notebook environment. This makes it difficult to load models in scripts that require different dependencies than the model itself.\r\n2.  Call `mlflow.pyfunc.spark_udf`. This requires setting up Spark (a large dependency, sophisticated to set up in local environments) and converting datasets to spark dataframes (inconvenient).\r\n\r\n\r\n### Details\r\n\r\n#### Interface\r\n\r\nFunction signature:\r\n`mlflow.pyfunc.load_model(model_uri: str, suppress_warnings: bool = False, dst_path: Optional[str] = None, env_manager: str ='local')`\r\n\r\n* When `env_manager='local'`, the current behavior of `load_model` is preserved. No environment restoration is performed and warmings are printed if there is a mismatch between the model's dependencies and libraries installed in the Python script / notebook environment.\r\n* When a model is loaded with `env_manager='virtualenv'` or `env_manager='conda'`, when `predict` is called, we follow `spark_udf`'s approach of preparing an separate python environment (using virtualenv or conda) with the model dependencies installed, starting a MLflow Model Server with the loaded model in that environment, and scoring the input data against it.\r\n\r\n#### Implementation\r\n\r\nThanks to the `mlflow.pyfunc.spark_udf` implementation, there already exists functionality to\r\n* prepare an isolated environment installed with training time model dependencies\r\n* start a model server in that environment with the desired model\r\n* scoring datasets against the server\r\n\r\nWe can simply re-use this functionality in `mlflow.pyfunc.load_model`.\r\n\r\n#### Complexities\r\n\r\nWhen environment restoration for spark UDFs were originally implemented, we did not add the feature to `load_model` because its `predict` function accepts a wider set of input types, which are harder to use in the model server approach. We should look into how to build support for all possible `predict` function inputs.\r\n\r\n### What component(s) does this bug affect?\r\n\r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/pipelines`: Pipelines, Pipeline APIs, Pipeline configs, Pipeline Templates\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [X] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n### What interface(s) does this bug affect?\r\n\r\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\n### What language(s) does this bug affect?\r\n\r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\n### What integration(s) does this bug affect?\r\n\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/6453/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/6453/timeline","performed_via_github_app":null,"state_reason":null}