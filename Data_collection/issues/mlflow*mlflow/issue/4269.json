{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4269","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/4269/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/4269/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/4269/events","html_url":"https://github.com/mlflow/mlflow/issues/4269","id":862729823,"node_id":"MDU6SXNzdWU4NjI3Mjk4MjM=","number":4269,"title":"[BUG] `pytest --verbose tests/autologging --large` is flaky","user":{"login":"harupy","id":17039389,"node_id":"MDQ6VXNlcjE3MDM5Mzg5","avatar_url":"https://avatars.githubusercontent.com/u/17039389?v=4","gravatar_id":"","url":"https://api.github.com/users/harupy","html_url":"https://github.com/harupy","followers_url":"https://api.github.com/users/harupy/followers","following_url":"https://api.github.com/users/harupy/following{/other_user}","gists_url":"https://api.github.com/users/harupy/gists{/gist_id}","starred_url":"https://api.github.com/users/harupy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harupy/subscriptions","organizations_url":"https://api.github.com/users/harupy/orgs","repos_url":"https://api.github.com/users/harupy/repos","events_url":"https://api.github.com/users/harupy/events{/privacy}","received_events_url":"https://api.github.com/users/harupy/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https://avatars.githubusercontent.com/u/39497902?v=4","gravatar_id":"","url":"https://api.github.com/users/dbczumar","html_url":"https://github.com/dbczumar","followers_url":"https://api.github.com/users/dbczumar/followers","following_url":"https://api.github.com/users/dbczumar/following{/other_user}","gists_url":"https://api.github.com/users/dbczumar/gists{/gist_id}","starred_url":"https://api.github.com/users/dbczumar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbczumar/subscriptions","organizations_url":"https://api.github.com/users/dbczumar/orgs","repos_url":"https://api.github.com/users/dbczumar/repos","events_url":"https://api.github.com/users/dbczumar/events{/privacy}","received_events_url":"https://api.github.com/users/dbczumar/received_events","type":"User","site_admin":false},"assignees":[{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https://avatars.githubusercontent.com/u/39497902?v=4","gravatar_id":"","url":"https://api.github.com/users/dbczumar","html_url":"https://github.com/dbczumar","followers_url":"https://api.github.com/users/dbczumar/followers","following_url":"https://api.github.com/users/dbczumar/following{/other_user}","gists_url":"https://api.github.com/users/dbczumar/gists{/gist_id}","starred_url":"https://api.github.com/users/dbczumar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbczumar/subscriptions","organizations_url":"https://api.github.com/users/dbczumar/orgs","repos_url":"https://api.github.com/users/dbczumar/repos","events_url":"https://api.github.com/users/dbczumar/events{/privacy}","received_events_url":"https://api.github.com/users/dbczumar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2021-04-20T11:44:20Z","updated_at":"2021-04-26T12:50:11Z","closed_at":"2021-04-26T12:50:11Z","author_association":"MEMBER","active_lock_reason":null,"body":"`pytest --verbose tests/autologging --large` is flaky:\r\n\r\nhttps://github.com/mlflow/mlflow/runs/2389644344#step:6:2031\r\n\r\nAn error occurs at the teardown of `test_is_testing_respects_environment_variable` in `test_autologging_safety_unit.py`.\r\n\r\nFull error log:\r\n\r\n```\r\npytest --verbose tests/autologging --large\r\n============================= test session starts ==============================\r\nplatform linux -- Python 3.6.13, pytest-3.2.1, py-1.10.0, pluggy-0.4.0 -- /usr/share/miniconda/envs/test-environment/bin/python\r\ncachedir: .cache\r\nrootdir: /home/runner/work/mlflow/mlflow, inifile: pytest.ini\r\nplugins: localserver-0.5.0, cov-2.6.0\r\ncollecting ... collected 150 items\r\n\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_expose_configs_and_support_disablement[integration0] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_expose_configs_and_support_disablement[integration1] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_expose_configs_and_support_disablement[integration2] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_expose_configs_and_support_disablement[integration3] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_expose_configs_and_support_disablement[integration4] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_expose_configs_and_support_disablement[integration5] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_expose_configs_and_support_disablement[integration6] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_expose_configs_and_support_disablement[integration7] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_expose_configs_and_support_disablement[integration8] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_expose_configs_and_support_disablement[integration9] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_use_safe_patch_for_monkey_patching[integration0] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_use_safe_patch_for_monkey_patching[integration1] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_use_safe_patch_for_monkey_patching[integration2] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_use_safe_patch_for_monkey_patching[integration3] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_use_safe_patch_for_monkey_patching[integration4] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_use_safe_patch_for_monkey_patching[integration5] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_use_safe_patch_for_monkey_patching[integration6] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_use_safe_patch_for_monkey_patching[integration7] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_use_safe_patch_for_monkey_patching[integration8] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_use_safe_patch_for_monkey_patching[integration9] PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autolog_respects_exclusive_flag PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autolog_respects_disable_flag PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autolog_respects_disable_flag_across_import_orders PASSED\r\ntests/autologging/test_autologging_behaviors_integration.py::test_autolog_respects_silent_mode PASSED\r\ntests/autologging/test_autologging_behaviors_unit.py::test_autologging_warnings_are_redirected_as_expected PASSED\r\ntests/autologging/test_autologging_behaviors_unit.py::test_autologging_event_logging_and_warnings_respect_silent_mode PASSED\r\ntests/autologging/test_autologging_behaviors_unit.py::test_silent_mode_is_respected_in_multithreaded_environments PASSED\r\ntests/autologging/test_autologging_behaviors_unit.py::test_silent_mode_restores_warning_and_event_logging_behavior_correctly_if_errors_occur PASSED\r\ntests/autologging/test_autologging_behaviors_unit.py::test_silent_mode_operates_independently_across_integrations PASSED\r\ntests/autologging/test_autologging_behaviors_unit.py::test_silent_mode_and_warning_rerouting_respect_disabled_flag[False-False] PASSED\r\ntests/autologging/test_autologging_behaviors_unit.py::test_silent_mode_and_warning_rerouting_respect_disabled_flag[False-True] PASSED\r\ntests/autologging/test_autologging_behaviors_unit.py::test_silent_mode_and_warning_rerouting_respect_disabled_flag[True-False] PASSED\r\ntests/autologging/test_autologging_behaviors_unit.py::test_silent_mode_and_warning_rerouting_respect_disabled_flag[True-True] PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_is_testing_respects_environment_variable PASSED\r\nðŸ”¥ tests/autologging/test_autologging_safety_unit.py::test_is_testing_respects_environment_variable ERROR\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_forwards_expected_arguments_to_function_based_patch_implementation PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_forwards_expected_arguments_to_class_based_patch PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_provides_expected_original_function PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_provides_expected_original_function_to_class_based_patch PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_propagates_exceptions_raised_from_original_function PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_logs_exceptions_raised_outside_of_original_function_as_warnings PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_propagates_exceptions_raised_outside_of_original_function_in_test_mode PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_calls_original_function_when_patch_preamble_throws PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_returns_original_result_without_second_call_when_patch_postamble_throws PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_respects_disable_flag PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_returns_original_result_and_ignores_patch_return_value PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_validates_arguments_to_original_function_in_test_mode PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_throws_when_autologging_runs_are_leaked_in_test_mode PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_does_not_throw_when_autologging_runs_are_leaked_in_standard_mode PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_validates_autologging_runs_when_necessary_in_test_mode PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_does_not_validate_autologging_runs_in_standard_mode PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_manages_run_if_specified_and_sets_expected_run_tags PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_does_not_manage_run_if_unspecified PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_preserves_signature_of_patched_function PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_provides_original_function_with_expected_signature PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_makes_expected_event_logging_calls_for_successful_patch_invocation PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_makes_expected_event_logging_calls_when_patch_implementation_throws PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_makes_expected_event_logging_calls_when_original_function_throws PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_safe_patch_succeeds_when_event_logging_throws_in_standard_mode PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_exception_safe_function_exhibits_expected_behavior_in_standard_mode PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_exception_safe_function_exhibits_expected_behavior_in_test_mode PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_exception_safe_class_exhibits_expected_behavior_in_standard_mode[object-_ExceptionSafeClass] PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_exception_safe_class_exhibits_expected_behavior_in_standard_mode[ABC-_ExceptionSafeClass] PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_exception_safe_class_exhibits_expected_behavior_in_test_mode[object-_ExceptionSafeClass] PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_exception_safe_class_exhibits_expected_behavior_in_test_mode[ABC-_ExceptionSafeClass] PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_patch_function_class_call_invokes_implementation_and_returns_result PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_patch_function_class_call_handles_exceptions_properly[Exception] PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_patch_function_class_call_handles_exceptions_properly[KeyboardInterrupt] PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_with_managed_runs_yields_functions_and_classes_as_expected PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_with_managed_run_with_non_throwing_function_exhibits_expected_behavior PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_with_managed_run_with_throwing_function_exhibits_expected_behavior PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_with_managed_run_with_non_throwing_class_exhibits_expected_behavior PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_with_managed_run_with_throwing_class_exhibits_expected_behavior PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_with_managed_run_sets_specified_run_tags PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_with_managed_run_ends_run_on_keyboard_interrupt PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_validate_args_succeeds_when_arg_sets_are_equivalent_or_identical PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_validate_args_throws_when_extra_args_are_not_functions_classes_or_lists PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_validate_args_throws_when_extra_args_are_not_exception_safe PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_validate_args_succeeds_when_extra_args_are_exception_safe_functions_or_classes[object-_ExceptionSafeClass] PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_validate_args_succeeds_when_extra_args_are_exception_safe_functions_or_classes[ABC-_ExceptionSafeClass] PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_validate_args_throws_when_args_are_omitted PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_validate_args_throws_when_arg_types_or_values_are_changed PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_validate_autologging_run_validates_autologging_tag_correctly PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_validate_autologging_run_validates_run_status_correctly PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_try_mlflow_log_emits_exceptions_as_warnings_in_standard_mode PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_try_mlflow_log_propagates_exceptions_in_test_mode PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_session_manager_creates_session_before_patch_executes PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_session_manager_exits_session_after_patch_executes PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_session_manager_exits_session_if_error_in_patch PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_session_manager_terminates_session_when_appropriate PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_original_fn_runs_if_patch_should_not_be_applied PASSED\r\ntests/autologging/test_autologging_safety_unit.py::test_patch_runs_if_patch_should_be_applied PASSED\r\ntests/autologging/test_autologging_utils.py::test_log_fn_args_as_params[args0-kwargs0-expected0] PASSED\r\ntests/autologging/test_autologging_utils.py::test_log_fn_args_as_params[args1-kwargs1-expected1] PASSED\r\ntests/autologging/test_autologging_utils.py::test_log_fn_args_as_params[args2-kwargs2-expected2] PASSED\r\ntests/autologging/test_autologging_utils.py::test_log_fn_args_as_params[args3-kwargs3-expected3] PASSED\r\ntests/autologging/test_autologging_utils.py::test_log_fn_args_as_params[args4-kwargs4-expected4] PASSED\r\ntests/autologging/test_autologging_utils.py::test_log_fn_args_as_params[args5-kwargs5-expected5] PASSED\r\ntests/autologging/test_autologging_utils.py::test_log_fn_args_as_params_ignores_unwanted_parameters PASSED\r\ntests/autologging/test_autologging_utils.py::test_wrap_patch_with_class PASSED\r\ntests/autologging/test_autologging_utils.py::test_wrap_patch_with_module PASSED\r\ntests/autologging/test_autologging_utils.py::test_if_getting_input_example_fails PASSED\r\ntests/autologging/test_autologging_utils.py::test_if_model_signature_inference_fails PASSED\r\ntests/autologging/test_autologging_utils.py::test_happy_path_works PASSED\r\ntests/autologging/test_autologging_utils.py::test_avoids_collecting_input_example_if_not_needed PASSED\r\ntests/autologging/test_autologging_utils.py::test_avoids_inferring_signature_if_not_needed PASSED\r\ntests/autologging/test_autologging_utils.py::test_batch_metrics_logger_logs_all_metrics PASSED\r\ntests/autologging/test_autologging_utils.py::test_batch_metrics_logger_flush_logs_to_mlflow PASSED\r\ntests/autologging/test_autologging_utils.py::test_batch_metrics_logger_runs_training_and_logging_in_correct_ratio PASSED\r\ntests/autologging/test_autologging_utils.py::test_batch_metrics_logger_chunks_metrics_when_batch_logging PASSED\r\ntests/autologging/test_autologging_utils.py::test_batch_metrics_logger_records_time_correctly PASSED\r\ntests/autologging/test_autologging_utils.py::test_batch_metrics_logger_logs_timestamps_as_int_milliseconds PASSED\r\ntests/autologging/test_autologging_utils.py::test_batch_metrics_logger_continues_if_log_batch_fails PASSED\r\ntests/autologging/test_autologging_utils.py::test_autologging_integration_calls_underlying_function_correctly PASSED\r\ntests/autologging/test_autologging_utils.py::test_autologging_integration_stores_and_updates_config PASSED\r\ntests/autologging/test_autologging_utils.py::test_autologging_integration_forwards_positional_and_keyword_arguments_as_expected PASSED\r\ntests/autologging/test_autologging_utils.py::test_autologging_integration_validates_structure_of_autolog_function PASSED\r\ntests/autologging/test_autologging_utils.py::test_autologging_integration_makes_expected_event_logging_calls PASSED\r\ntests/autologging/test_autologging_utils.py::test_autologging_integration_succeeds_when_event_logging_throws_in_standard_mode PASSED\r\ntests/autologging/test_autologging_utils.py::test_get_autologging_config_returns_configured_values_or_defaults_as_expected PASSED\r\ntests/autologging/test_autologging_utils.py::test_autologging_is_disabled_returns_expected_values PASSED\r\ntests/autologging/test_autologging_utils.py::test_autologging_event_logger_default_implementation_does_not_throw_for_valid_inputs PASSED\r\ntests/autologging/test_autologging_utils.py::test_autologging_event_logger_default_impl_warns_for_log_autolog_called_with_deprecated_args PASSED\r\ntests/autologging/test_autologging_utils.py::test_check_version_in_range PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[fastai-1.0.60-True] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[fastai-1.0.50-False] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[gluon-1.6.1-True] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[gluon-1.5.0-False] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[keras-2.2.4-True] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[keras-2.2.3-False] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[lightgbm-2.3.1-True] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[lightgbm-2.3.0-False] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[statsmodels-0.11.1-True] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[statsmodels-0.11.0-False] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[tensorflow-1.15.4-True] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[tensorflow-1.15.3-False] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[xgboost-0.90-True] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[xgboost-0.89-False] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[sklearn-0.20.3-True] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[sklearn-0.20.2-False] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[pytorch-1.0.5-True] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[pytorch-1.0.4-False] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[pyspark.ml-3.1.0-True] PASSED\r\ntests/autologging/test_autologging_utils.py::test_is_autologging_integration_supported[pyspark.ml-3.0.0-False] PASSED\r\ntests/autologging/test_autologging_utils.py::test_disable_for_unsupported_versions_warning_sklearn_integration PASSED\r\ntests/autologging/test_training_session.py::test_should_log_always_returns_true_in_root_session[True] PASSED\r\ntests/autologging/test_training_session.py::test_should_log_always_returns_true_in_root_session[False] PASSED\r\ntests/autologging/test_training_session.py::test_nested_sessions[True] PASSED\r\ntests/autologging/test_training_session.py::test_nested_sessions[False] PASSED\r\ntests/autologging/test_training_session.py::test_parent_session_overrides_child_session PASSED\r\ntests/autologging/test_training_session.py::test_should_log_returns_false_when_parrent_session_has_the_same_class PASSED\r\n\r\n=========================== slowest 5 test durations ===========================\r\n9.45s call     tests/autologging/test_autologging_behaviors_integration.py::test_autolog_respects_silent_mode\r\n8.91s call     tests/autologging/test_autologging_behaviors_integration.py::test_autolog_respects_exclusive_flag\r\n4.04s call     tests/autologging/test_autologging_utils.py::test_batch_metrics_logger_records_time_correctly\r\n3.72s setup    tests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_expose_configs_and_support_disablement[integration0]\r\n2.51s call     tests/autologging/test_autologging_behaviors_integration.py::test_autologging_integrations_expose_configs_and_support_disablement[integration0]\r\n==================================== ERRORS ====================================\r\n______ ERROR at teardown of test_is_testing_respects_environment_variable ______\r\n\r\n    @pytest.fixture(autouse=True)\r\n    def clean_up_leaked_runs():\r\n        \"\"\"\r\n        Certain test cases validate safety API behavior when runs are leaked. Leaked runs that\r\n        are not cleaned up between test cases may result in cascading failures that are hard to\r\n        debug. Accordingly, this fixture attempts to end any active runs it encounters and\r\n        throws an exception (which reported as an additional error in the pytest execution output).\r\n        \"\"\"\r\n        try:\r\n            yield\r\n>           assert not mlflow.active_run(), \"test case unexpectedly leaked a run!\"\r\nE           AssertionError: test case unexpectedly leaked a run!\r\nE           assert not <ActiveRun: >\r\nE            +  where <ActiveRun: > = <function active_run at 0x7fb66b381f28>()\r\nE            +    where <function active_run at 0x7fb66b381f28> = mlflow.active_run\r\n\r\n\r\ntests/autologging/test_autologging_safety_unit.py:80: AssertionError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n    @pytest.fixture(autouse=True)\r\n    def clean_up_leaked_runs():\r\n        \"\"\"\r\n        Certain test cases validate safety API behavior when runs are leaked. Leaked runs that\r\n        are not cleaned up between test cases may result in cascading failures that are hard to\r\n        debug. Accordingly, this fixture attempts to end any active runs it encounters and\r\n        throws an exception (which reported as an additional error in the pytest execution output).\r\n        \"\"\"\r\n        try:\r\n            yield\r\n            assert not mlflow.active_run(), \"test case unexpectedly leaked a run!\"\r\n        finally:\r\n            while mlflow.active_run():\r\n>               mlflow.end_run()\r\n\r\n\r\ntests/autologging/test_autologging_safety_unit.py:83: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nmlflow/tracking/fluent.py:277: in end_run\r\n    MlflowClient().set_terminated(run.info.run_id, status)\r\nmlflow/tracking/client.py:1373: in set_terminated\r\n    self._tracking_client.set_terminated(run_id, status, end_time)\r\nmlflow/tracking/_tracking_service/client.py:326: in set_terminated\r\n    run_id, run_status=RunStatus.from_string(status), end_time=end_time\r\nmlflow/store/tracking/sqlalchemy_store.py:446: in update_run_info\r\n    run = self._get_run(run_uuid=run_id, session=session)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <mlflow.store.tracking.sqlalchemy_store.SqlAlchemyStore object at 0x7fb5688ee470>\r\nsession = <sqlalchemy.orm.session.Session object at 0x7fb56889b080>\r\nrun_uuid = '9dd96641c29a445aaa4e8ebc886ad61f', eager = False\r\n\r\n    def _get_run(self, session, run_uuid, eager=False):\r\n        \"\"\"\r\n            :param eager: If ``True``, eagerly loads the run's summary metrics (``latest_metrics``),\r\n                          params, and tags when fetching the run. If ``False``, these attributes\r\n                          are not eagerly loaded and will be loaded when their corresponding\r\n                          object properties are accessed from the resulting ``SqlRun`` object.\r\n            \"\"\"\r\n        query_options = self._get_eager_run_query_options() if eager else []\r\n        runs = (\r\n            session.query(SqlRun).options(*query_options).filter(SqlRun.run_uuid == run_uuid).all()\r\n        )\r\n    \r\n        if len(runs) == 0:\r\n            raise MlflowException(\r\n>               \"Run with id={} not found\".format(run_uuid), RESOURCE_DOES_NOT_EXIST\r\n            )\r\nE           mlflow.exceptions.MlflowException: Run with id=9dd96641c29a445aaa4e8ebc886ad61f not found\r\n\r\neager      = False\r\nquery_options = []\r\nrun_uuid   = '9dd96641c29a445aaa4e8ebc886ad61f'\r\nruns       = []\r\nself       = <mlflow.store.tracking.sqlalchemy_store.SqlAlchemyStore object at 0x7fb5688ee470>\r\nsession    = <sqlalchemy.orm.session.Session object at 0x7fb56889b080>\r\n\r\nmlflow/store/tracking/sqlalchemy_store.py:392: MlflowException\r\n--------------------------- Captured stderr teardown ---------------------------\r\n2021/04/20 11:06:28 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\r\n2021/04/20 11:06:28 INFO mlflow.store.db.utils: Updating database tables\r\nINFO  [alembic.runtime.migration] Context impl SQLiteImpl.\r\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\r\nINFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\r\nINFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\r\nINFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\r\nINFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\r\nINFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\r\nINFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\r\nINFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\r\nINFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\r\nINFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\r\nINFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\r\nINFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\r\nINFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\r\nWARNI [0a8213491aaa_drop_duplicate_killed_constraint_py] Failed to drop check constraint. Dropping check constraints may not be supported by your SQL database. Exception content: No support for ALTER of constraints in SQLite dialectPlease refer to the batch mode feature which allows for SQLite migrations using a copy-and-move strategy.\r\nINFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\r\nINFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\r\nINFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\r\nINFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\r\nINFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\r\nINFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\r\nINFO  [alembic.runtime.migration] Context impl SQLiteImpl.\r\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\r\n=============================== warnings summary ===============================\r\ntests/autologging/test_autologging_utils.py::test_batch_metrics_logger_continues_if_log_batch_fails\r\n  /home/runner/work/mlflow/mlflow/mlflow/utils/autologging_utils/__init__.py:202: UserWarning: Logging to MLflow failed: asdf\r\n    try_mlflow_log(MlflowClient().log_batch, run_id=current_run_id, metrics=metrics_slice)\r\n\r\ntests/autologging/test_autologging_utils.py::test_disable_for_unsupported_versions_warning_sklearn_integration\r\n  /home/runner/work/mlflow/mlflow/mlflow/utils/autologging_utils/__init__.py:381: UserWarning: Autologging utilities may not work properly on scikit-learn < 0.20.3 (current version: 0.20.2)\r\n    return _autolog(*args, **kwargs)\r\n  /home/runner/work/mlflow/mlflow/mlflow/utils/autologging_utils/__init__.py:381: UserWarning: Autologging utilities may not work properly on scikit-learn < 0.20.3 (current version: 0.20.2)\r\n    return _autolog(*args, **kwargs)\r\n  /home/runner/work/mlflow/mlflow/mlflow/utils/autologging_utils/__init__.py:381: UserWarning: Autologging utilities may not work properly on scikit-learn < 0.20.3 (current version: 0.20.2)\r\n    return _autolog(*args, **kwargs)\r\n  /home/runner/work/mlflow/mlflow/mlflow/utils/autologging_utils/__init__.py:381: UserWarning: Autologging utilities may not work properly on scikit-learn < 0.20.3 (current version: 0.20.2)\r\n    return _autolog(*args, **kwargs)\r\n\r\n-- Docs: http://doc.pytest.org/en/latest/warnings.html\r\n=============== 150 passed, 5 warnings, 1 error in 48.33 seconds ===============\r\n```","closed_by":{"login":"harupy","id":17039389,"node_id":"MDQ6VXNlcjE3MDM5Mzg5","avatar_url":"https://avatars.githubusercontent.com/u/17039389?v=4","gravatar_id":"","url":"https://api.github.com/users/harupy","html_url":"https://github.com/harupy","followers_url":"https://api.github.com/users/harupy/followers","following_url":"https://api.github.com/users/harupy/following{/other_user}","gists_url":"https://api.github.com/users/harupy/gists{/gist_id}","starred_url":"https://api.github.com/users/harupy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harupy/subscriptions","organizations_url":"https://api.github.com/users/harupy/orgs","repos_url":"https://api.github.com/users/harupy/repos","events_url":"https://api.github.com/users/harupy/events{/privacy}","received_events_url":"https://api.github.com/users/harupy/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4269/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/4269/timeline","performed_via_github_app":null,"state_reason":"completed"}