{"url":"https://api.github.com/repos/mlflow/mlflow/issues/6226","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/6226/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/6226/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/6226/events","html_url":"https://github.com/mlflow/mlflow/issues/6226","id":1300608221,"node_id":"I_kwDOCB5Jx85NhbTd","number":6226,"title":"[BUG] Can't replicate quickstart save and serve example","user":{"login":"smferro54","id":29869015,"node_id":"MDQ6VXNlcjI5ODY5MDE1","avatar_url":"https://avatars.githubusercontent.com/u/29869015?v=4","gravatar_id":"","url":"https://api.github.com/users/smferro54","html_url":"https://github.com/smferro54","followers_url":"https://api.github.com/users/smferro54/followers","following_url":"https://api.github.com/users/smferro54/following{/other_user}","gists_url":"https://api.github.com/users/smferro54/gists{/gist_id}","starred_url":"https://api.github.com/users/smferro54/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/smferro54/subscriptions","organizations_url":"https://api.github.com/users/smferro54/orgs","repos_url":"https://api.github.com/users/smferro54/repos","events_url":"https://api.github.com/users/smferro54/events{/privacy}","received_events_url":"https://api.github.com/users/smferro54/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":968461607,"node_id":"MDU6TGFiZWw5Njg0NjE2MDc=","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/windows","name":"area/windows","color":"ede978","default":false,"description":"Issue is unique to windows."},{"id":2022847277,"node_id":"MDU6TGFiZWwyMDIyODQ3Mjc3","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/examples","name":"area/examples","color":"48eabc","default":false,"description":"Example code"},{"id":2022848043,"node_id":"MDU6TGFiZWwyMDIyODQ4MDQz","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/models","name":"area/models","color":"48eabc","default":false,"description":"MLmodel format, model serialization/deserialization, flavors"},{"id":2022848902,"node_id":"MDU6TGFiZWwyMDIyODQ4OTAy","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/scoring","name":"area/scoring","color":"48eabc","default":false,"description":"MLflow Model server, model deployment tools, Spark UDFs"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2022-07-11T11:58:26Z","updated_at":"2022-07-11T13:59:25Z","closed_at":"2022-07-11T13:59:07Z","author_association":"NONE","active_lock_reason":null,"body":"### Willingness to contribute\r\n\r\nNo. I cannot contribute a bug fix at this time.\r\n\r\n### MLflow version\r\n\r\n1.27.0\r\n\r\n### System information\r\n\r\n- Windows 11\r\n- Python 3.9.7\r\n- conda 4.13.0\r\n\r\n\r\n### Describe the problem\r\n\r\nI'm trying to replicate the quickstart save and serve example. \r\nI go to the example folder, run the python script and can see the model runs and artifacts when I type \"mlflow ui\". \r\nHowever, when I try the mlflow serve command with different model run Ids and ports I get a 404 in my browser, even though the command seems successful:\r\n\r\n```\r\nmlflow models serve -m runs:/e1dabe8fc6e84286af5bee28ca89cdde/model --port 1234\r\n2022/07/11 07:40:01 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\r\n2022/07/11 07:40:02 INFO mlflow.utils.conda: Conda environment mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4 already exists.\r\n2022/07/11 07:40:02 INFO mlflow.pyfunc.backend: === Running command 'conda activate mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4 & waitress-serve --host=127.0.0.1 --port=1234 --ident=mlflow mlflow.pyfunc.scoring_server.wsgi:app'\r\nINFO:waitress:Serving on http://127.0.0.1:1234\r\n```\r\n\r\nI tried running directly from anaconda prompt, and I get the following error:\r\n\r\n```\r\nconda activate mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4 & waitress-serve --host=127.0.0.1 --port=1234 --ident=mlflow mlflow.pyfunc.scoring_server.wsgi:app\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\runpy.py\", line 197, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\Scripts\\waitress-serve.exe\\__main__.py\", line 7, in <module>\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\site-packages\\waitress\\runner.py\", line 283, in run\r\n    app = resolve(module, obj_name)\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\site-packages\\waitress\\runner.py\", line 218, in resolve\r\n    obj = __import__(module_name, fromlist=segments[:1])\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\site-packages\\mlflow\\pyfunc\\scoring_server\\wsgi.py\", line 6, in <module>\r\n    app = scoring_server.init(load_model(os.environ[scoring_server._SERVER_MODEL_PATH]))\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\os.py\", line 679, in __getitem__\r\n    raise KeyError(key) from None\r\nKeyError: '__pyfunc_model_path__'\r\n\r\n```\r\n\r\nI have tried deleting and creating a new anaconda environment, ran from git bash, anaconda prompt, added anaconda3 environment variables. I know it has something to do with the _SERVER_MODEL_PATH variable but I wouldn't know how to set it up or which path add to my environment variables so it can read this variable from there. \r\n\r\nPlease help, \r\n\r\nSergio\r\n\r\n### Tracking information\r\n\r\n```\r\nmlflow models serve -m runs:/e1dabe8fc6e84286af5bee28ca89cdde/model --port 1234\r\n2022/07/11 07:40:01 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\r\n2022/07/11 07:40:02 INFO mlflow.utils.conda: Conda environment mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4 already exists.\r\n2022/07/11 07:40:02 INFO mlflow.pyfunc.backend: === Running command 'conda activate mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4 & waitress-serve --host=127.0.0.1 --port=1234 --ident=mlflow mlflow.pyfunc.scoring_server.wsgi:app'\r\nINFO:waitress:Serving on http://127.0.0.1:1234\r\n```\r\n\r\nI tried running directly from anaconda prompt, and I get the following error:\r\n\r\n```\r\nconda activate mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4 & waitress-serve --host=127.0.0.1 --port=1234 --ident=mlflow mlflow.pyfunc.scoring_server.wsgi:app\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\runpy.py\", line 197, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\Scripts\\waitress-serve.exe\\__main__.py\", line 7, in <module>\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\site-packages\\waitress\\runner.py\", line 283, in run\r\n    app = resolve(module, obj_name)\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\site-packages\\waitress\\runner.py\", line 218, in resolve\r\n    obj = __import__(module_name, fromlist=segments[:1])\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\site-packages\\mlflow\\pyfunc\\scoring_server\\wsgi.py\", line 6, in <module>\r\n    app = scoring_server.init(load_model(os.environ[scoring_server._SERVER_MODEL_PATH]))\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\os.py\", line 679, in __getitem__\r\n    raise KeyError(key) from None\r\nKeyError: '__pyfunc_model_path__'\r\n```\r\n\r\n### Code to reproduce issue\r\n\r\n```\r\nmlflow models serve -m runs:/e1dabe8fc6e84286af5bee28ca89cdde/model --port 1234\r\n2022/07/11 07:40:01 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\r\n2022/07/11 07:40:02 INFO mlflow.utils.conda: Conda environment mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4 already exists.\r\n2022/07/11 07:40:02 INFO mlflow.pyfunc.backend: === Running command 'conda activate mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4 & waitress-serve --host=127.0.0.1 --port=1234 --ident=mlflow mlflow.pyfunc.scoring_server.wsgi:app'\r\nINFO:waitress:Serving on http://127.0.0.1:1234\r\n```\r\n\r\n#I tried running directly from anaconda prompt, and I get the following error:\r\n\r\n```\r\nconda activate mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4 & waitress-serve --host=127.0.0.1 --port=1234 --ident=mlflow mlflow.pyfunc.scoring_server.wsgi:app\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\runpy.py\", line 197, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\Scripts\\waitress-serve.exe\\__main__.py\", line 7, in <module>\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\site-packages\\waitress\\runner.py\", line 283, in run\r\n    app = resolve(module, obj_name)\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\site-packages\\waitress\\runner.py\", line 218, in resolve\r\n    obj = __import__(module_name, fromlist=segments[:1])\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\site-packages\\mlflow\\pyfunc\\scoring_server\\wsgi.py\", line 6, in <module>\r\n    app = scoring_server.init(load_model(os.environ[scoring_server._SERVER_MODEL_PATH]))\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\os.py\", line 679, in __getitem__\r\n    raise KeyError(key) from None\r\nKeyError: '__pyfunc_model_path__'\r\n```\r\n\r\n### Other info / logs\r\n\r\n```\r\nmlflow models serve -m runs:/e1dabe8fc6e84286af5bee28ca89cdde/model --port 1234\r\n2022/07/11 07:40:01 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\r\n2022/07/11 07:40:02 INFO mlflow.utils.conda: Conda environment mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4 already exists.\r\n2022/07/11 07:40:02 INFO mlflow.pyfunc.backend: === Running command 'conda activate mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4 & waitress-serve --host=127.0.0.1 --port=1234 --ident=mlflow mlflow.pyfunc.scoring_server.wsgi:app'\r\nINFO:waitress:Serving on http://127.0.0.1:1234\r\n```\r\n\r\nI tried running directly from anaconda prompt, and I get the following error:\r\n\r\n```\r\nconda activate mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4 & waitress-serve --host=127.0.0.1 --port=1234 --ident=mlflow mlflow.pyfunc.scoring_server.wsgi:app\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\runpy.py\", line 197, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\Scripts\\waitress-serve.exe\\__main__.py\", line 7, in <module>\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\site-packages\\waitress\\runner.py\", line 283, in run\r\n    app = resolve(module, obj_name)\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\site-packages\\waitress\\runner.py\", line 218, in resolve\r\n    obj = __import__(module_name, fromlist=segments[:1])\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\site-packages\\mlflow\\pyfunc\\scoring_server\\wsgi.py\", line 6, in <module>\r\n    app = scoring_server.init(load_model(os.environ[scoring_server._SERVER_MODEL_PATH]))\r\n  File \"C:\\Users\\sergio ferro\\.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\os.py\", line 679, in __getitem__\r\n    raise KeyError(key) from None\r\nKeyError: '__pyfunc_model_path__'\r\n```\r\n\r\n### What component(s) does this bug affect?\r\n\r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [X] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [X] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/pipelines`: Pipelines, Pipeline APIs, Pipeline configs, Pipeline Templates\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [X] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n### What interface(s) does this bug affect?\r\n\r\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [X] `area/windows`: Windows support\r\n\r\n### What language(s) does this bug affect?\r\n\r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\n### What integration(s) does this bug affect?\r\n\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations","closed_by":{"login":"harupy","id":17039389,"node_id":"MDQ6VXNlcjE3MDM5Mzg5","avatar_url":"https://avatars.githubusercontent.com/u/17039389?v=4","gravatar_id":"","url":"https://api.github.com/users/harupy","html_url":"https://github.com/harupy","followers_url":"https://api.github.com/users/harupy/followers","following_url":"https://api.github.com/users/harupy/following{/other_user}","gists_url":"https://api.github.com/users/harupy/gists{/gist_id}","starred_url":"https://api.github.com/users/harupy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harupy/subscriptions","organizations_url":"https://api.github.com/users/harupy/orgs","repos_url":"https://api.github.com/users/harupy/repos","events_url":"https://api.github.com/users/harupy/events{/privacy}","received_events_url":"https://api.github.com/users/harupy/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/6226/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/6226/timeline","performed_via_github_app":null,"state_reason":"completed"}