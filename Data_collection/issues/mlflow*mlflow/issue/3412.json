{"url":"https://api.github.com/repos/mlflow/mlflow/issues/3412","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/3412/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/3412/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/3412/events","html_url":"https://github.com/mlflow/mlflow/issues/3412","id":699375679,"node_id":"MDU6SXNzdWU2OTkzNzU2Nzk=","number":3412,"title":"[BUG] mlflow run with --backend kubernetes fails when local docker image with same IMAGE ID exists","user":{"login":"AdemFr","id":32066272,"node_id":"MDQ6VXNlcjMyMDY2Mjcy","avatar_url":"https://avatars.githubusercontent.com/u/32066272?v=4","gravatar_id":"","url":"https://api.github.com/users/AdemFr","html_url":"https://github.com/AdemFr","followers_url":"https://api.github.com/users/AdemFr/followers","following_url":"https://api.github.com/users/AdemFr/following{/other_user}","gists_url":"https://api.github.com/users/AdemFr/gists{/gist_id}","starred_url":"https://api.github.com/users/AdemFr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AdemFr/subscriptions","organizations_url":"https://api.github.com/users/AdemFr/orgs","repos_url":"https://api.github.com/users/AdemFr/repos","events_url":"https://api.github.com/users/AdemFr/events{/privacy}","received_events_url":"https://api.github.com/users/AdemFr/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":2022848510,"node_id":"MDU6TGFiZWwyMDIyODQ4NTEw","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/projects","name":"area/projects","color":"48eabc","default":false,"description":"MLproject format, project running backends"},{"id":2022851725,"node_id":"MDU6TGFiZWwyMDIyODUxNzI1","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/docker","name":"area/docker","color":"ede978","default":false,"description":"Docker use anywhere, such as MLprojects and MLmodels"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-09-11T14:18:52Z","updated_at":"2021-06-22T09:11:03Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [x] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Catalina 10.15.4\r\n- **MLflow installed from (source or binary)**: source\r\n- **MLflow version (run ``mlflow --version``)**: 1.10.0\r\n- **Python version**: 3.7.6\r\n- **npm version, if running the dev UI**: - \r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI would like to use the kubernetes deployment functionality for running training jobs. For this I have a `MLproject` file in my python package that looks something like this (I omitted details to make the mlflow tracking run properly, this works for now):\r\n```\r\nname: my-mlflow-project\r\n\r\ndocker_env:\r\n  image: eu.gcr.io/my-gcloud-project/project_container_gpu\r\n\r\nentry_points:\r\n  main:\r\n    command: \"python trainer.py\"\r\n```\r\n\r\nI would like to be able to run training locally as well as in kubernetes, just by changing the mlflow command arguments:\r\n1. `mlflow run .``\r\n2. `mlflow run . --backend kubernetes --backend-config ...`\r\n\r\nEvery time I run one of those commands, a docker image with the current code is build based on the base image provided in the `MLproject` file. The only difference is the resulting image repository name:\r\n\r\n```\r\nÂ» docker images                                                                                                                               \r\nREPOSITORY                                                  TAG                             IMAGE ID            CREATED             SIZE\r\nmy-mlflow-project                                    9d6d7a3                         e535a8039eec        2 hours ago         5.85GB\r\neu.gcr.io/my-gcloud-project/project_container_gpu    9d6d7a3                         e535a8039eec        2 hours ago         5.85GB\r\n```\r\n\r\nNote, that the TAG and IMAGE ID is exactly the same in both cases (because it's the same commit and I did not change any code locally).\r\n\r\nOnce I ran the command locally and try to run it with the kubernetes backend **after**, the pushing of the image to the container registry fails with this error:\r\n```\r\n2020/09/11 16:04:33 INFO mlflow.projects: === Building docker image eu.gcr.io/mxlabs-adem-pytorch-test/project_container_gpu:9d6d7a3 ===\r\n2020/09/11 16:04:38 INFO mlflow.projects.kubernetes: === Pushing docker image mxlabs-adem-pytorch-test:9d6d7a3 ===\r\n2020/09/11 16:04:41 ERROR mlflow.cli: === Error while pushing to docker registry: denied: requested access to the resource is denied ===\r\n```\r\n\r\n**I can work around this by deleting the image with the REPOSITORY name of `my_package_name` (so only one image exists with the same docker IMAGE ID).**\r\n\r\nI looked into it a bit, and I am pretty sure that the reason for this is the usage of the first found image tag [in this line](https://github.com/mlflow/mlflow/blob/e34dbf236f7c19e9774365d03c87bc1b746d932f/mlflow/projects/__init__.py#L154) where the first found image repository is chosen with `image.tag[0]`.\r\n\r\nThis leads to it trying to push the image repository `my_package_name` and failing to \"get access\" to the non existent repository.\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [x] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [x] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/3412/reactions","total_count":5,"+1":5,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/3412/timeline","performed_via_github_app":null,"state_reason":null}