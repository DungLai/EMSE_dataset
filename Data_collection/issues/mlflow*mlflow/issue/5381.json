{"url":"https://api.github.com/repos/mlflow/mlflow/issues/5381","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/5381/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/5381/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/5381/events","html_url":"https://github.com/mlflow/mlflow/issues/5381","id":1138571630,"node_id":"I_kwDOCB5Jx85D3Tlu","number":5381,"title":"[FR] Add a timeout argument in model serve (scoring server)","user":{"login":"sniafas","id":4542013,"node_id":"MDQ6VXNlcjQ1NDIwMTM=","avatar_url":"https://avatars.githubusercontent.com/u/4542013?v=4","gravatar_id":"","url":"https://api.github.com/users/sniafas","html_url":"https://github.com/sniafas","followers_url":"https://api.github.com/users/sniafas/followers","following_url":"https://api.github.com/users/sniafas/following{/other_user}","gists_url":"https://api.github.com/users/sniafas/gists{/gist_id}","starred_url":"https://api.github.com/users/sniafas/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sniafas/subscriptions","organizations_url":"https://api.github.com/users/sniafas/orgs","repos_url":"https://api.github.com/users/sniafas/repos","events_url":"https://api.github.com/users/sniafas/events{/privacy}","received_events_url":"https://api.github.com/users/sniafas/received_events","type":"User","site_admin":false},"labels":[{"id":955449434,"node_id":"MDU6TGFiZWw5NTU0NDk0MzQ=","url":"https://api.github.com/repos/mlflow/mlflow/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":978584226,"node_id":"MDU6TGFiZWw5Nzg1ODQyMjY=","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/docs","name":"area/docs","color":"48eabc","default":false,"description":"Documentation issues"},{"id":2022848902,"node_id":"MDU6TGFiZWwyMDIyODQ4OTAy","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/scoring","name":"area/scoring","color":"48eabc","default":false,"description":"MLflow Model server, model deployment tools, Spark UDFs"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2022-02-15T11:39:11Z","updated_at":"2022-05-06T11:40:50Z","closed_at":"2022-05-06T11:40:50Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nFor cases where POST request latency is not the case or a custom inference logic is implemented, the default timeout (60s) of scoring server is not sufficient and a client asking for a response will lead to the following errors.\r\n```\r\nProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\r\nConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\r\n```\r\n\r\n## Motivation\r\n- What is the use case for this feature? Timeout is hardcoded in scoring server. [link to code](https://github.com/mlflow/mlflow/blob/master/mlflow/pyfunc/scoring_server/__init__.py#L358)\r\n- Why is this use case valuable to support for MLflow users in general? We would probably wish to set a timeout for the scoring server\r\n- Why is this use case valuable to support for your project(s) or organization? We have implemented a pyfunc model with custom inference logic and stateful model serving architecture. For applications where latency is not the case, it would be nice to opt for the desired scoring server timeout.\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient) It's not implemented, though we have kept a fork MLFlow version and set a timeout argument to handle this case \r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [x] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [x] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nWe can probably \r\n1. create a new `--timeout` argument in `models serve` [command](https://github.com/mlflow/mlflow/blob/master/mlflow/models/cli.py#L35)\r\n2. remove the hardcoded timeout and create a new parser for timeout argument in scoring server [init](https://github.com/mlflow/mlflow/blob/master/mlflow/pyfunc/scoring_server/__init__.py#L358)","closed_by":{"login":"harupy","id":17039389,"node_id":"MDQ6VXNlcjE3MDM5Mzg5","avatar_url":"https://avatars.githubusercontent.com/u/17039389?v=4","gravatar_id":"","url":"https://api.github.com/users/harupy","html_url":"https://github.com/harupy","followers_url":"https://api.github.com/users/harupy/followers","following_url":"https://api.github.com/users/harupy/following{/other_user}","gists_url":"https://api.github.com/users/harupy/gists{/gist_id}","starred_url":"https://api.github.com/users/harupy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/harupy/subscriptions","organizations_url":"https://api.github.com/users/harupy/orgs","repos_url":"https://api.github.com/users/harupy/repos","events_url":"https://api.github.com/users/harupy/events{/privacy}","received_events_url":"https://api.github.com/users/harupy/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/5381/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/5381/timeline","performed_via_github_app":null,"state_reason":"completed"}