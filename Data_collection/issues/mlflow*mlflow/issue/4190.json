{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4190","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/4190/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/4190/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/4190/events","html_url":"https://github.com/mlflow/mlflow/issues/4190","id":837145393,"node_id":"MDU6SXNzdWU4MzcxNDUzOTM=","number":4190,"title":"[FR] gRPC inference server for pyfunc flavor ","user":{"login":"tokoko","id":9497784,"node_id":"MDQ6VXNlcjk0OTc3ODQ=","avatar_url":"https://avatars.githubusercontent.com/u/9497784?v=4","gravatar_id":"","url":"https://api.github.com/users/tokoko","html_url":"https://github.com/tokoko","followers_url":"https://api.github.com/users/tokoko/followers","following_url":"https://api.github.com/users/tokoko/following{/other_user}","gists_url":"https://api.github.com/users/tokoko/gists{/gist_id}","starred_url":"https://api.github.com/users/tokoko/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tokoko/subscriptions","organizations_url":"https://api.github.com/users/tokoko/orgs","repos_url":"https://api.github.com/users/tokoko/repos","events_url":"https://api.github.com/users/tokoko/events{/privacy}","received_events_url":"https://api.github.com/users/tokoko/received_events","type":"User","site_admin":false},"labels":[{"id":955449434,"node_id":"MDU6TGFiZWw5NTU0NDk0MzQ=","url":"https://api.github.com/repos/mlflow/mlflow/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":2022848043,"node_id":"MDU6TGFiZWwyMDIyODQ4MDQz","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/models","name":"area/models","color":"48eabc","default":false,"description":"MLmodel format, model serialization/deserialization, flavors"},{"id":2022848902,"node_id":"MDU6TGFiZWwyMDIyODQ4OTAy","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/scoring","name":"area/scoring","color":"48eabc","default":false,"description":"MLflow Model server, model deployment tools, Spark UDFs"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-03-21T18:10:58Z","updated_at":"2021-09-01T10:10:36Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"## Willingness to contribute\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [x] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nCurrent `FlavorBackend` implementation for `pyfunc` model flavor serves REST API endpoint for inference. The proposed feature would add an option to deploy `pyfunc` models as gRPC endpoints as well. I have begun a rough draft of the feature in a separate repository ([mlflow-grpc](https://github.com/tokoko/mlflow-grpc)) but i'm unsure how the feature can be incorporated into the main `mlflow` project.\r\n\r\n## Motivation\r\n- What is the use case for this feature?\r\ndeployment of mlflow pyfunc models as gRPC endpoints. \r\n- Why is this use case valuable to support for MLflow users in general?\r\nability to expose faster gRPC inference endpoints might be crucial in production for many ml use cases.\r\n- Why is this use case valuable to support for your project(s) or organization?\r\n- Why is it currently difficult to achieve this use case? (please be as specific as possible about why related MLflow features and components are insufficient)\r\nIt could be implemented by writing a custom Dockerfile and protobuf definitions and keeping them up-to-date with changes in model dependencies and/or input features.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [x] `area/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [ ] `area/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nSeems to me, there are several ways to incorporate this feature into the project, but I don't know which if any would be the right approach.\r\n\r\n- implement it as part of `mlflow.pyfunc.backend.PyFuncBackend` in already existing serve() and build_docker() functions. they would need additional parameters to determine whether to serve REST or gRPC. `mlflow models` API will need to be changed accordingly. This approach seems too messy.\r\n\r\n- implement it as a separate `FlavorBackend`. This seems like a cleaner approach, but there are some problems. `get_flavor_backend` function in `mlflow.models.flavor_backend_registry` right now assumes that there will be at most one `FlavorBackend` per each model `flavor`. if this assumption was dropped, `mlflow models` API would need to be changed to add an additional parameter to specify which `FlavorBackend` should be used. another minor issue with this approach is that it will probably never make sense to have more than one `predict()` implementations per `flavor` and flavor backends would probably need to share it. The way I decided to implement my POC version of the feature is by writing `PyFuncGrpcBackend` that extends `PyFuncBackend` and overrides only `serve` and `build_docker` methods.\r\n\r\n- implement it as a plugin. If I'm not mistaken `FlavorBackend` is not pluggable as of now and I'm not sure if `deployments` plugin mechanism is appropriate for this use case. would love to hear your view on this.\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4190/reactions","total_count":3,"+1":3,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/4190/timeline","performed_via_github_app":null,"state_reason":null}