{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4807","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/4807/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/4807/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/4807/events","html_url":"https://github.com/mlflow/mlflow/issues/4807","id":997430279,"node_id":"I_kwDOCB5Jx847c5QH","number":4807,"title":"[FR] show tags in compare model versions view","user":{"login":"jeremyjordan","id":13970565,"node_id":"MDQ6VXNlcjEzOTcwNTY1","avatar_url":"https://avatars.githubusercontent.com/u/13970565?v=4","gravatar_id":"","url":"https://api.github.com/users/jeremyjordan","html_url":"https://github.com/jeremyjordan","followers_url":"https://api.github.com/users/jeremyjordan/followers","following_url":"https://api.github.com/users/jeremyjordan/following{/other_user}","gists_url":"https://api.github.com/users/jeremyjordan/gists{/gist_id}","starred_url":"https://api.github.com/users/jeremyjordan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jeremyjordan/subscriptions","organizations_url":"https://api.github.com/users/jeremyjordan/orgs","repos_url":"https://api.github.com/users/jeremyjordan/repos","events_url":"https://api.github.com/users/jeremyjordan/events{/privacy}","received_events_url":"https://api.github.com/users/jeremyjordan/received_events","type":"User","site_admin":false},"labels":[{"id":955449434,"node_id":"MDU6TGFiZWw5NTU0NDk0MzQ=","url":"https://api.github.com/repos/mlflow/mlflow/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":1470945519,"node_id":"MDU6TGFiZWwxNDcwOTQ1NTE5","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/uiux","name":"area/uiux","color":"ede978","default":false,"description":"Front-end, user experience, plotting, JavaScript, JavaScript dev server"},{"id":2022847714,"node_id":"MDU6TGFiZWwyMDIyODQ3NzE0","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/model-registry","name":"area/model-registry","color":"48eabc","default":false,"description":"Model registry, model registry APIs, and the fluent client calls for model registry"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-15T19:23:25Z","updated_at":"2021-09-15T19:23:43Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"## Willingness to contribute\r\nThe MLflow Community encourages new feature contributions. Would you or another member of your organization be willing to contribute an implementation of this feature (either as an MLflow Plugin or an enhancement to the MLflow code base)?\r\n\r\n- [ ] Yes. I can contribute this feature independently.\r\n- [ ] Yes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n- [x] No. I cannot contribute this feature at this time.\r\n\r\n## Proposal Summary\r\n\r\nThe current view for comparing model versions shows parameters and metrics, but doesn't have a section to compare tags. Could we add a section which shows tags from the training run?\r\n\r\n## Motivation\r\n\r\nWe're currently storing some information in tags that would be useful to have as context when comparing across model versions. Given that the UI already allows you to compare metrics and parameters, it seems like we should also support comparing tags. We like to keep parameters more focused on data like hyperparameters, but there's additional run metadata that we log as tags. I imagine other teams similarly find it useful to add extra context to model runs through tags, and we should allow visibility of this context from the compare view.\r\n\r\n### What component(s), interfaces, languages, and integrations does this feature affect?\r\nComponents \r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [x] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterfaces\r\n- [x] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguages \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations\r\n\r\n## Details\r\n\r\nWe'd have to extend `CompareModelVersionsView.js` to include a component which compares tags across model versions. It looks like [we're already grabbing the run tags](https://github.com/mlflow/mlflow/blob/master/mlflow/server/js/src/model-registry/components/CompareModelVersionsView.js#L637) (in order to read the run name), we just need to add a table which displays the information.\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4807/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/4807/timeline","performed_via_github_app":null,"state_reason":null}