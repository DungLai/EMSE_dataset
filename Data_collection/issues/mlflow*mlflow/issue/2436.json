{"url":"https://api.github.com/repos/mlflow/mlflow/issues/2436","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/2436/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/2436/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/2436/events","html_url":"https://github.com/mlflow/mlflow/issues/2436","id":566777384,"node_id":"MDU6SXNzdWU1NjY3NzczODQ=","number":2436,"title":"[FR] Ability to select epoch (aka \"best step\") from which to display metrics on UI","user":{"login":"imaluengo","id":1993103,"node_id":"MDQ6VXNlcjE5OTMxMDM=","avatar_url":"https://avatars.githubusercontent.com/u/1993103?v=4","gravatar_id":"","url":"https://api.github.com/users/imaluengo","html_url":"https://github.com/imaluengo","followers_url":"https://api.github.com/users/imaluengo/followers","following_url":"https://api.github.com/users/imaluengo/following{/other_user}","gists_url":"https://api.github.com/users/imaluengo/gists{/gist_id}","starred_url":"https://api.github.com/users/imaluengo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/imaluengo/subscriptions","organizations_url":"https://api.github.com/users/imaluengo/orgs","repos_url":"https://api.github.com/users/imaluengo/repos","events_url":"https://api.github.com/users/imaluengo/events{/privacy}","received_events_url":"https://api.github.com/users/imaluengo/received_events","type":"User","site_admin":false},"labels":[{"id":955449434,"node_id":"MDU6TGFiZWw5NTU0NDk0MzQ=","url":"https://api.github.com/repos/mlflow/mlflow/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":2022849295,"node_id":"MDU6TGFiZWwyMDIyODQ5Mjk1","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/tracking","name":"area/tracking","color":"48eabc","default":false,"description":"Tracking service, tracking client APIs, autologging"},{"id":2022866842,"node_id":"MDU6TGFiZWwyMDIyODY2ODQy","url":"https://api.github.com/repos/mlflow/mlflow/labels/priority/awaiting-more-evidence","name":"priority/awaiting-more-evidence","color":"534cb5","default":false,"description":"Lowest priority. Possibly useful, but not yet enough support to actually get it done."}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-02-18T10:00:27Z","updated_at":"2020-07-13T05:40:49Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Usually I run many experiments i want to compare together. I run them almost with identical settings for a number (lets say 100) epochs. During training for every batch I do register a multitude of metrics and I name them with `T/...` to denote they are batch metrics. Then I do similar for epoch summarization metrics during validation and name them `V/...`:\r\n\r\n```\r\nmlflow.log_metrics({'T/accuracy':  0.9, 'T/loss': 0.2}, step=current_batch_number)\r\n...\r\nmlflow.log_metrics({'V/accuracy':  0.9, 'V/loss': 0.2}, step=current_epoch)\r\n```\r\nIn the UI I can only see the metrics for the last batch/epoch of the run, which it no always (almost never) the one I want to use to compare to other experiments. So, to allow better comparison across experiments from the UI table without having to go into the curves plot, I'd like to suggest two quick modifications to MLFLow tracking UI summary table (e.g. http://<yourmlflowserver>/#/experiments/51):\r\n\r\n1. Make a distinction in `mlflow.tracking` to allow submitting batch metrics and epoch metrics and distinguish them in the database without having to prepend them with some keyword. E.g.\r\n\r\n```\r\nmlflow.log_batch_metrics(....)\r\nmlflow.log_epoch_metrics(...)\r\n```\r\n\r\n2. In the UI, for each individual run, and for the \"epoch metrics\", allow to select which epoch to display (and memorise it). As the number of runs grow, we could manually select the metrics from which epoch to display for each run in the tables so that we could compare future experiments against it very quickly. \r\n\r\nBasically, the ability to select the \"best step\" for each RUN so that those metrics are always visible and comparable across runs.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/2436/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/2436/timeline","performed_via_github_app":null,"state_reason":null}