{"url":"https://api.github.com/repos/mlflow/mlflow/issues/7320","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/7320/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/7320/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/7320/events","html_url":"https://github.com/mlflow/mlflow/issues/7320","id":1446051286,"node_id":"I_kwDOCB5Jx85WMP3W","number":7320,"title":"[BUG] pytorch autologging silently fails with fairscale distributed training strategy","user":{"login":"pavanchhatpar","id":16511756,"node_id":"MDQ6VXNlcjE2NTExNzU2","avatar_url":"https://avatars.githubusercontent.com/u/16511756?v=4","gravatar_id":"","url":"https://api.github.com/users/pavanchhatpar","html_url":"https://github.com/pavanchhatpar","followers_url":"https://api.github.com/users/pavanchhatpar/followers","following_url":"https://api.github.com/users/pavanchhatpar/following{/other_user}","gists_url":"https://api.github.com/users/pavanchhatpar/gists{/gist_id}","starred_url":"https://api.github.com/users/pavanchhatpar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pavanchhatpar/subscriptions","organizations_url":"https://api.github.com/users/pavanchhatpar/orgs","repos_url":"https://api.github.com/users/pavanchhatpar/repos","events_url":"https://api.github.com/users/pavanchhatpar/events{/privacy}","received_events_url":"https://api.github.com/users/pavanchhatpar/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":2022848043,"node_id":"MDU6TGFiZWwyMDIyODQ4MDQz","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/models","name":"area/models","color":"48eabc","default":false,"description":"MLmodel format, model serialization/deserialization, flavors"},{"id":2022849295,"node_id":"MDU6TGFiZWwyMDIyODQ5Mjk1","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/tracking","name":"area/tracking","color":"48eabc","default":false,"description":"Tracking service, tracking client APIs, autologging"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2022-11-11T22:14:26Z","updated_at":"2022-12-09T23:40:08Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"### Issues Policy acknowledgement\n\n- [X] I have read and agree to submit bug reports in accordance with the [issues policy](https://www.github.com/mlflow/mlflow/blob/master/ISSUE_POLICY.md)\n\n### Willingness to contribute\n\nNo. I cannot contribute a bug fix at this time.\n\n### MLflow version\n\nmlflow, version 1.30.0\n\n### System information\n\nPython 3.8.10\r\nDistributor ID:\tUbuntu\r\nDescription:\tUbuntu 20.04.5 LTS\r\nRelease:\t20.04\r\nCodename:\tfocal\r\nDBR 9.1 LTS ML (GPU)\r\ntorch 1.9 (comes pre-installed in DBR)\r\npytorch_lightning 1.8.1\r\nfairscale 0.4.12\n\n### Describe the problem\n\n## Autologging warning\r\n- Using `mlflow.pytorch.autolog` fails silently with an autologging warning mentioned below, which is why despite a successful `trainer.fit` call mlflow does not log the model or even the model summary\r\n- I can confirm training completes successfully and also the trained checkpoint is available through pytorch lightning's default checkpointing mechanism and I'm able to log them as artifacts\r\n- Looking at the warning and lack of any artifact I believe it originates in the following block of code https://github.com/mlflow/mlflow/blob/74f8ca6669273d02060c3bf9d85870262be734cd/mlflow/pytorch/_pytorch_autolog.py#L372-L376\r\n- `ModelSummary` expects `model` to be a `LightningModule` where attribute `example_input_array` will always be present even if its `None` and hence it tries to query it without any checks here https://github.com/Lightning-AI/lightning/blob/0dfb3d28ce858e5d709cba468b374a3d41329655/src/pytorch_lightning/utilities/model_summary/model_summary.py#L245\r\n- When training with fairscale strategy `model` is wrapped into a different class and hence `example_input_array` attribute is not present\r\n\r\n## log_model Exception\r\n - I tried to use `log_model` outside of autologging since its invoked after the failing `ModelSummary` making it unreachable\r\n - The exception message is an open github issue https://github.com/pytorch/pytorch/issues/76927\r\n - There was a suggestion to save `model.module` instead of model but it didn't work either\r\n - pytorch lightning is able to create a checkpoint for this model so its definitely possible to overcome the error\r\n\r\nI found this bug while working on databricks but I don't think its restricted to it or affects only this integration, its in general an issue for pytorch with mlflow\n\n### Tracking information\n\n_No response_\n\n### Code to reproduce issue\n\n```python\r\nimport os\r\nimport mlflow\r\nimport torch\r\nfrom torch.utils.data import DataLoader, Dataset\r\nimport tempfile\r\nimport pickle\r\n\r\nfrom pytorch_lightning import LightningModule, Trainer\r\nimport pytorch_lightning as pl\r\nfrom pytorch_lightning.utilities.model_summary import ModelSummary\r\n\r\nclass RandomDataset(Dataset):\r\n    def __init__(self, size, length):\r\n        self.len = length\r\n        self.data = torch.randn(length, size)\r\n\r\n    def __getitem__(self, index):\r\n        return self.data[index]\r\n\r\n    def __len__(self):\r\n        return self.len\r\n\r\n\r\nclass BoringModel(LightningModule):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.layer = torch.nn.Linear(32, 2)\r\n\r\n    def forward(self, x):\r\n        return self.layer(x)\r\n\r\n    def training_step(self, batch, batch_idx):\r\n        loss = self(batch).sum()\r\n        self.log(\"train_loss\", loss)\r\n        return {\"loss\": loss}\r\n\r\n    def validation_step(self, batch, batch_idx):\r\n        loss = self(batch).sum()\r\n        self.log(\"valid_loss\", loss)\r\n\r\n    def test_step(self, batch, batch_idx):\r\n        loss = self(batch).sum()\r\n        self.log(\"test_loss\", loss)\r\n\r\n    def configure_optimizers(self):\r\n        return torch.optim.AdamW(self.trainer.model.parameters(), lr=0.1)\r\n\r\ndef run():\r\n    pl.seed_everything(1)\r\n    train_data = DataLoader(RandomDataset(32, 64), batch_size=2)\r\n    val_data = DataLoader(RandomDataset(32, 64), batch_size=2)\r\n    test_data = DataLoader(RandomDataset(32, 64), batch_size=2)\r\n    tmpdir = tempfile.mkdtemp()\r\n    print(f\"log location: {tmpdir}\")\r\n    model = BoringModel()\r\n    trainer = Trainer(\r\n        default_root_dir=tmpdir,\r\n        num_sanity_val_steps=0,\r\n        max_epochs=2,\r\n        accelerator=\"gpu\",\r\n        devices=2,\r\n        auto_select_gpus=True,\r\n        strategy=\"fsdp\", # can also try ddp_sharded to reproduce issue\r\n    )\r\n    if trainer.is_global_zero:\r\n        print(\"MLFlow init\")\r\n        mlflow.pytorch.autolog(log_models=False) # True does not matter since code breaks before model logging\r\n        run = mlflow.start_run()\r\n    else:\r\n        print(\"mlflow run exists on rank 0 process\")\r\n    try:\r\n        trainer.fit(model, train_dataloaders=train_data, val_dataloaders=val_data)\r\n        # trainer.test(model, dataloaders=test_data)\r\n    finally:\r\n        if trainer.is_global_zero:\r\n            print('Uploading lightning logs. May take time')\r\n            mlflow.log_artifacts(tmpdir, 'pl_logs') # this works\r\n            mlflow.pytorch.log_model(trainer.model, \"model\") # this fails\r\n            mlflow.end_run()\r\n        \r\n\r\nif __name__ == \"__main__\":\r\n    run()\r\n```\n\n### Stack trace\n\n - With strategy `fsdp`\r\n   - Silent warning about unexpected error in autologging at the end of `trainer.fit` call\r\n     ```python\r\n     2022/11/11 20:58:54 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during pytorch autologging: '_DDPFullyShardedStrategyModuleWrapper' object has no attribute 'example_input_array'\r\n     ```\r\n   - Exception when manually tried logging model using `mlflow.pytorch.log_model`\r\n     ```python\r\n      Traceback (most recent call last):\r\n        File \"/tmp/boring_model_fairscale.py\", line 85, in <module>\r\n          run()\r\n        File \"/tmp/boring_model_fairscale.py\", line 79, in run\r\n          mlflow.pytorch.log_model(trainer.model, \"model\") # this fails\r\n        File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-182eddcc-afbc-4ba1-b007-1f003d511f52/lib/python3.8/site-packages/mlflow/pytorch/__init__.py\", line 306, in log_model\r\n          return Model.log(\r\n        File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-182eddcc-afbc-4ba1-b007-1f003d511f52/lib/python3.8/site-packages/mlflow/models/model.py\", line 373, in log\r\n          flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\r\n        File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-182eddcc-afbc-4ba1-b007-1f003d511f52/lib/python3.8/site-packages/mlflow/pytorch/__init__.py\", line 512, in save_model\r\n          torch.save(pytorch_model, model_path, pickle_module=pickle_module, **kwargs)\r\n        File \"/databricks/python/lib/python3.8/site-packages/torch/serialization.py\", line 379, in save\r\n          _save(obj, opened_zipfile, pickle_module, pickle_protocol)\r\n        File \"/databricks/python/lib/python3.8/site-packages/torch/serialization.py\", line 484, in _save\r\n          pickler.dump(obj)\r\n        File \"/databricks/python/lib/python3.8/site-packages/cloudpickle/cloudpickle_fast.py\", line 563, in dump\r\n          return Pickler.dump(self, obj)\r\n      TypeError: cannot pickle 'torch._C._distributed_c10d.ProcessGroupNCCL' object\r\n     ```\r\n - When switching strategy to `ddp_sharded`\r\n   - Silent warning about unexpected error in autologging at the end of `trainer.fit` call\r\n      ```python\r\n      WARNING mlflow.utils.autologging_utils: Encountered unexpected error during pytorch autologging: '_LightningModuleWrapperBase' object has no attribute 'example_input_array'\r\n      ```\r\n   - Exception when manually tried logging model using `mlflow.pytorch.log_model`\r\n      ```python\r\n      Traceback (most recent call last):\r\n        File \"/tmp/boring_model_fairscale.py\", line 85, in <module>\r\n          run()\r\n        File \"/tmp/boring_model_fairscale.py\", line 79, in run\r\n          mlflow.pytorch.log_model(trainer.model, \"model\") # this fails\r\n        File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-182eddcc-afbc-4ba1-b007-1f003d511f52/lib/python3.8/site-packages/mlflow/pytorch/__init__.py\", line 306, in log_model\r\n          return Model.log(\r\n        File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-182eddcc-afbc-4ba1-b007-1f003d511f52/lib/python3.8/site-packages/mlflow/models/model.py\", line 373, in log\r\n          flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\r\n        File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-182eddcc-afbc-4ba1-b007-1f003d511f52/lib/python3.8/site-packages/mlflow/pytorch/__init__.py\", line 512, in save_model\r\n          torch.save(pytorch_model, model_path, pickle_module=pickle_module, **kwargs)\r\n        File \"/databricks/python/lib/python3.8/site-packages/torch/serialization.py\", line 379, in save\r\n          _save(obj, opened_zipfile, pickle_module, pickle_protocol)\r\n        File \"/databricks/python/lib/python3.8/site-packages/torch/serialization.py\", line 484, in _save\r\n          pickler.dump(obj)\r\n        File \"/databricks/python/lib/python3.8/site-packages/cloudpickle/cloudpickle_fast.py\", line 563, in dump\r\n          return Pickler.dump(self, obj)\r\n      TypeError: cannot pickle 'torch._C._distributed_c10d.ProcessGroupNCCL' object\r\n      ```\n\n### Other info / logs\n\n_No response_\n\n### What component(s) does this bug affect?\n\n- [ ] `area/artifacts`: Artifact stores and artifact logging\n- [ ] `area/build`: Build and test infrastructure for MLflow\n- [ ] `area/docs`: MLflow documentation pages\n- [ ] `area/examples`: Example code\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\n- [X] `area/models`: MLmodel format, model serialization/deserialization, flavors\n- [ ] `area/recipes`: Recipes, Recipe APIs, Recipe configs, Recipe Templates\n- [ ] `area/projects`: MLproject format, project running backends\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\n- [ ] `area/server-infra`: MLflow Tracking server backend\n- [X] `area/tracking`: Tracking Service, tracking client APIs, autologging\n\n### What interface(s) does this bug affect?\n\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\n- [ ] `area/windows`: Windows support\n\n### What language(s) does this bug affect?\n\n- [ ] `language/r`: R APIs and clients\n- [ ] `language/java`: Java APIs and clients\n- [ ] `language/new`: Proposals for new client languages\n\n### What integration(s) does this bug affect?\n\n- [ ] `integrations/azure`: Azure and Azure ML integrations\n- [ ] `integrations/sagemaker`: SageMaker integrations\n- [ ] `integrations/databricks`: Databricks integrations","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/7320/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/7320/timeline","performed_via_github_app":null,"state_reason":null}