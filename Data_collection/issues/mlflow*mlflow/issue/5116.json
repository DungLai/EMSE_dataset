{"url":"https://api.github.com/repos/mlflow/mlflow/issues/5116","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/5116/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/5116/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/5116/events","html_url":"https://github.com/mlflow/mlflow/issues/5116","id":1065391967,"node_id":"I_kwDOCB5Jx84_gJdf","number":5116,"title":"[BUG] Could not find a registered artifact location for c: on Windows (Spark model via databricks-connect)","user":{"login":"olbapjose","id":34943494,"node_id":"MDQ6VXNlcjM0OTQzNDk0","avatar_url":"https://avatars.githubusercontent.com/u/34943494?v=4","gravatar_id":"","url":"https://api.github.com/users/olbapjose","html_url":"https://github.com/olbapjose","followers_url":"https://api.github.com/users/olbapjose/followers","following_url":"https://api.github.com/users/olbapjose/following{/other_user}","gists_url":"https://api.github.com/users/olbapjose/gists{/gist_id}","starred_url":"https://api.github.com/users/olbapjose/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/olbapjose/subscriptions","organizations_url":"https://api.github.com/users/olbapjose/orgs","repos_url":"https://api.github.com/users/olbapjose/repos","events_url":"https://api.github.com/users/olbapjose/events{/privacy}","received_events_url":"https://api.github.com/users/olbapjose/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":2022845866,"node_id":"MDU6TGFiZWwyMDIyODQ1ODY2","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/artifacts","name":"area/artifacts","color":"48eabc","default":false,"description":"Artifact stores and artifact logging"},{"id":2114036915,"node_id":"MDU6TGFiZWwyMTE0MDM2OTE1","url":"https://api.github.com/repos/mlflow/mlflow/labels/integrations/databricks","name":"integrations/databricks","color":"ffbce5","default":false,"description":"Databricks integrations"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-11-28T17:39:46Z","updated_at":"2021-11-28T22:09:30Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Thank you for submitting an issue. Please refer to our [issue policy](https://www.github.com/mlflow/mlflow/blob/master/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https://stackoverflow.com/questions/tagged/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [X] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: YES\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.21.0\r\n- **databricks-connect version**: 9.1.4\r\n- **Python version**: 3.8.8\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: run the code below from pycharm using databricks-connect\r\n\r\n### Describe the problem\r\nIn pycharm, when I call log_model with a Spark model on a Databricks cluster where mlflow works perfectly with databricks-connect and non-Spark models, I get the following error:\r\n\r\n```\r\nERROR mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: c:\\temp\\tmpi32ow6na, flavor: spark)\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\utils\\environment.py\", line 196, in infer_pip_requirements\r\n    return _infer_requirements(model_uri, flavor)\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py\", line 299, in _infer_requirements\r\n    modules = _capture_imported_modules(model_uri, flavor)\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py\", line 235, in _capture_imported_modules\r\n    _run_command(\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py\", line 187, in _run_command\r\n    raise MlflowException(msg)\r\nmlflow.exceptions.MlflowException: Encountered an unexpected error while running ['C:\\\\Users\\\\myself\\\\PycharmProjects\\\\paa-datascience-nbra-model\\\\venv\\\\Scripts\\\\python.exe', 'C:\\\\Users\\\\myself\\\\PycharmProjects\\\\paa-datascience-nbra-model\\\\venv\\\\lib\\\\site-packages\\\\mlflow\\\\utils\\\\_capture_modules.py', '--model-path', 'C:\\\\temp\\\\tmpi32ow6na', '--flavor', 'spark', '--output-file', 'c:\\\\temp\\\\tmpy4sudk9v\\\\imported_modules.txt', '--sys-path', '[\"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\project\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\venv\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\git\\\\\\\\ext\\\\\\\\gitdb\", \"C:\\\\\\\\temp\\\\\\\\spark-11c431d6-347c-4131-8a72-563a2d4ee3f8\\\\\\\\userFiles-cd3f3711-efb4-4fbe-a446-80315c673113\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\venv\\\\\\\\Scripts\\\\\\\\python38.zip\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\Anaconda3\\\\\\\\DLLs\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\Anaconda3\\\\\\\\lib\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\Anaconda3\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\venv\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\venv\\\\\\\\lib\\\\\\\\site-packages\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\venv\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\win32\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\venv\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\win32\\\\\\\\lib\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\venv\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\Pythonwin\", \"C:\\\\\\\\Users\\\\\\\\myself\\\\\\\\PycharmProjects\\\\\\\\paa-datascience-nbra-model\\\\\\\\venv\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\gitdb\\\\\\\\ext\\\\\\\\smmap\"]']\r\nexit status: 1\r\n```\r\nand a few seconds later:\r\n\r\n```\r\nINFO mlflow.spark: File 'C:\\temp\\tmpi32ow6na\\sparkml' not found on DFS. Will attempt to upload the file.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\utils\\_capture_modules.py\", line 134, in <module>\r\n    main()\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\utils\\_capture_modules.py\", line 109, in main\r\n    mlflow.pyfunc.load_model(model_path)\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\pyfunc\\__init__.py\", line 667, in load_model\r\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\utils\\_capture_modules.py\", line 106, in _load_pyfunc_patch\r\n    return original(*args, **kwargs)\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\spark.py\", line 710, in _load_pyfunc\r\n    return _PyFuncModelWrapper(spark, _load_model(model_uri=path))\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\spark.py\", line 631, in _load_model\r\n    model_uri = _HadoopFileSystem.maybe_copy_from_uri(model_uri, dfs_tmpdir)\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\spark.py\", line 373, in maybe_copy_from_uri\r\n    return cls.maybe_copy_from_local_file(_download_artifact_from_uri(src_uri), dst_path)\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\tracking\\artifact_utils.py\", line 95, in _download_artifact_from_uri\r\n    return get_artifact_repository(artifact_uri=root_uri).download_artifacts(\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\store\\artifact\\artifact_repository_registry.py\", line 102, in get_artifact_repository\r\n    return _artifact_repository_registry.get_artifact_repository(artifact_uri)\r\n  File \"C:\\Users\\myself\\PycharmProjects\\paa-datascience-nbra-model\\venv\\lib\\site-packages\\mlflow\\store\\artifact\\artifact_repository_registry.py\", line 65, in get_artifact_repository\r\n    raise MlflowException(\r\nmlflow.exceptions.MlflowException: Could not find a registered artifact repository for: c:. Currently registered schemes are: ['', 'file', 's3', 'gs', 'wasbs', 'ftp', 'sftp', 'dbfs', 'hdfs', 'viewfs', 'runs', 'models']\r\n```\r\n\r\nI have configured mlflow tracking uri to \"databricks\", as well as the databricks-cli and enverything. In fact, this works fine for non-Spark models.\r\n\r\n### Code to reproduce issue\r\n```\r\nimport os\r\nimport mlflow\r\nfrom pyspark.sql import SparkSession\r\nfrom mlflow.tracking import MlflowClient\r\nfrom pyspark.ml.classification import RandomForestClassifier\r\nfrom pyspark.ml.feature import VectorAssembler\r\nfrom pyspark.ml.pipeline import Pipeline\r\n\r\nif __name__ == '__main__':\r\n    \r\n    def dummy_model(data):\r\n        vec_assmblr = VectorAssembler(inputCols=['col2', 'col3'], outputCol='features_norm')\r\n        alg = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features_norm\", maxDepth=3)\r\n        pipeline = Pipeline(stages=[vec_assmblr, alg])\r\n        model = pipeline.fit(data)\r\n        return model\r\n\r\n    os.environ[\"MLFLOW_TRACKING_INSECURE_TLS\"] = \"true\"\r\n    mlflow.set_tracking_uri(\"databricks\")\r\n\r\n    spark = SparkSession.builder \\\r\n        .appName(\"test\") \\\r\n        .getOrCreate()\r\n\r\n    mlflow.set_tracking_uri(\"databricks\")\r\n    client = MlflowClient()\r\n    experiment_path = \"/Users/myDatabricksUser/mlops/ExperimentBug\"  # existing path in Workspace\r\n    artifact_root = '/user/existingfolder/mlops/'   # existing DBFS folder\r\n    model_name = 'trial_1'\r\n\r\n    experiment = mlflow.get_experiment_by_name(name=experiment_path)\r\n    if experiment is None:\r\n        experiment_id = mlflow.create_experiment(name=experiment_path)\r\n    else:\r\n        experiment_id = experiment.experiment_id\r\n\r\n    os.environ[\"MLFLOW_TRACKING_INSECURE_TLS\"] = \"true\"\r\n    mlflow.set_tracking_uri('databricks')\r\n    client = MlflowClient()\r\n\r\n    tst = spark.createDataFrame(\r\n        [('a', 7, 2, 0.0),\r\n         ('b', 3, 4, 1.0),\r\n         ('c', 5, 6, 0.0),\r\n         ('d', 7, 8, 1.0),\r\n         ('a', 9, 10, 0.0),\r\n         ('a', 11, 12, 1.0),\r\n         ('g', 13, 14, 0.0)],\r\n        schema=['col1', 'col2', 'col3', 'label'])\r\n\r\n    model = dummy_model(tst)\r\n    with mlflow.start_run(experiment_id=experiment_id) as run:\r\n        mlflow.spark.log_model(spark_model=model,\r\n                               registered_model_name=model_name,\r\n                               artifact_path=artifact_root + model_name)\r\n\r\n    versions = client.search_model_versions(\"name=\\'\" + model_name + \"\\'\")\r\n    version = versions[0].version  # latest version\r\n\r\n    print('Loading version ' + version + ' from model ' + model_name)\r\n    model_fetched = mlflow.spark.load_model(model_uri='models:/' + model_name + '/' + version)\r\n\r\n    model_fetched.transform(tst).show()\r\n```\r\n\r\nJust FYI, if I change the artifact root variable to start with \"**dbfs:/**\" so that \r\n`artifact_root = 'dbfs:/user/existingfolder/mlops/'` then I get a completely different error: \r\n\r\n```\r\nWARN ProtoSerializer: Failed to deserialize remote exception\r\njava.io.InvalidClassException: failed to read class descriptor\r\n    at java.io.ObjectInputStream.readNonProxyDesc(Unknown Source)\r\n...\r\nCaused by: java.lang.ClassNotFoundException: com.databricks.backend.daemon.data.common.InvalidMountException\r\n...\r\nERROR Instrumentation: com.databricks.service.SparkServiceRemoteException: com.databricks.backend.daemon.data.common.InvalidMountException: Error while using path /databricks/mlflow-tracking/867383642994223/7e16b7270b4940bdaa99e62be008f729/artifacts\\dbfs:/user/existingfolder/mlops/trial_1/sparkml for resolving path '/867383642994223/7e16b7270b4940bdaa99e62be008f729/artifacts\\dbfs:/user/existingfolder/mlops/trial_1/sparkml' within mount at '/databricks/mlflow-tracking'.\r\n```\r\n\r\n### Other info / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [X] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [X] `integrations/databricks`: Databricks integrations\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/5116/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/5116/timeline","performed_via_github_app":null,"state_reason":null}