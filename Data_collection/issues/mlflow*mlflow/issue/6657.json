{"url":"https://api.github.com/repos/mlflow/mlflow/issues/6657","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/6657/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/6657/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/6657/events","html_url":"https://github.com/mlflow/mlflow/issues/6657","id":1357018240,"node_id":"I_kwDOCB5Jx85Q4nSA","number":6657,"title":"[FR] Expose the current model from mlserver `/inference` endpoint","user":{"login":"dingobar","id":41419288,"node_id":"MDQ6VXNlcjQxNDE5Mjg4","avatar_url":"https://avatars.githubusercontent.com/u/41419288?v=4","gravatar_id":"","url":"https://api.github.com/users/dingobar","html_url":"https://github.com/dingobar","followers_url":"https://api.github.com/users/dingobar/followers","following_url":"https://api.github.com/users/dingobar/following{/other_user}","gists_url":"https://api.github.com/users/dingobar/gists{/gist_id}","starred_url":"https://api.github.com/users/dingobar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dingobar/subscriptions","organizations_url":"https://api.github.com/users/dingobar/orgs","repos_url":"https://api.github.com/users/dingobar/repos","events_url":"https://api.github.com/users/dingobar/events{/privacy}","received_events_url":"https://api.github.com/users/dingobar/received_events","type":"User","site_admin":false},"labels":[{"id":955449434,"node_id":"MDU6TGFiZWw5NTU0NDk0MzQ=","url":"https://api.github.com/repos/mlflow/mlflow/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":2022848043,"node_id":"MDU6TGFiZWwyMDIyODQ4MDQz","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/models","name":"area/models","color":"48eabc","default":false,"description":"MLmodel format, model serialization/deserialization, flavors"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2022-08-31T08:52:41Z","updated_at":"2022-09-08T13:42:10Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"### Willingness to contribute\r\n\r\nYes. I would be willing to contribute this feature with guidance from the MLflow community.\r\n\r\n### Proposal Summary\r\n\r\nWhen we serve models with mlserver, it is important to have traceability: Which model gave which predictions? The inferring service calls `POST my.host.com/inferences/` with the data, and gets the predictions back. **Can we also somehow notify the inferring service which model was running behind that endpoint, to trace it back to a single mlflow artifact?** It could for example return it in a header, `x-model-id: my-model`, or have a separate endpoint with metadata. The issue with the `/model/{model name}/metadata endpoint is that it requires you to know which model it is before calling it, which defeats the purpose.\r\n\r\nWhat do you think?\r\n\r\nI think we should remove some model metadata in a header. It can be a feature to be turned on/off. Is this best solved in `mlserver-mlflow` perhaps?\r\n\r\n### Motivation\r\n\r\n> #### What is the use case for this feature?\r\n\r\nWhen we make predictions, it is very important to trace which model was responsible for which predictions. When we save our  ~~We want to pick this metadata up from the `/v2/{model}/metadata` endpoint of mlserver. This allows us to get some reference to the model without breaking the current API contract.~~\r\n\r\n> #### Why is this use case valuable to support for MLflow users in general?\r\n\r\nIn many environments such as fintech and health, traceability is not only very useful and helps with debugging, but also required by regulations.\r\n\r\n> #### Why is this use case valuable to support for your project(s) or organization?\r\n\r\nWe need to be able to enrich inferences with some metadata about which model gave which prediction to\r\n\r\n- Comply with traceability requirements in our field\r\n- Compare models head-to-head in production at the same time\r\n- AB testing (compare base model to best model)\r\n\r\n> #### Why is it currently difficult to achieve this use case?\r\n\r\nThe service does not expose any reference to the model it is currently serving.\r\n\r\n### Details\r\n\r\nSuggested options in the proposal summary.\r\n\r\n### What component(s) does this bug affect?\r\n\r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [X] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/pipelines`: Pipelines, Pipeline APIs, Pipeline configs, Pipeline Templates\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\n### What interface(s) does this bug affect?\r\n\r\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\n### What language(s) does this bug affect?\r\n\r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\n### What integration(s) does this bug affect?\r\n\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/6657/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/6657/timeline","performed_via_github_app":null,"state_reason":null}