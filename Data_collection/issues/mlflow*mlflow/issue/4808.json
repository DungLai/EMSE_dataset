{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4808","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/4808/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/4808/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/4808/events","html_url":"https://github.com/mlflow/mlflow/issues/4808","id":997447596,"node_id":"I_kwDOCB5Jx847c9es","number":4808,"title":"[BUG] unable to re-create tables after the sqlite db is dropped and re-created","user":{"login":"erensahin","id":15085990,"node_id":"MDQ6VXNlcjE1MDg1OTkw","avatar_url":"https://avatars.githubusercontent.com/u/15085990?v=4","gravatar_id":"","url":"https://api.github.com/users/erensahin","html_url":"https://github.com/erensahin","followers_url":"https://api.github.com/users/erensahin/followers","following_url":"https://api.github.com/users/erensahin/following{/other_user}","gists_url":"https://api.github.com/users/erensahin/gists{/gist_id}","starred_url":"https://api.github.com/users/erensahin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/erensahin/subscriptions","organizations_url":"https://api.github.com/users/erensahin/orgs","repos_url":"https://api.github.com/users/erensahin/repos","events_url":"https://api.github.com/users/erensahin/events{/privacy}","received_events_url":"https://api.github.com/users/erensahin/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":2022847714,"node_id":"MDU6TGFiZWwyMDIyODQ3NzE0","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/model-registry","name":"area/model-registry","color":"48eabc","default":false,"description":"Model registry, model registry APIs, and the fluent client calls for model registry"},{"id":2022849295,"node_id":"MDU6TGFiZWwyMDIyODQ5Mjk1","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/tracking","name":"area/tracking","color":"48eabc","default":false,"description":"Tracking service, tracking client APIs, autologging"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-15T19:44:10Z","updated_at":"2021-09-15T19:44:23Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Thank you for submitting an issue. Please refer to our [issue policy](https://www.github.com/mlflow/mlflow/blob/master/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https://stackoverflow.com/questions/tagged/mlflow).\r\n\r\n**Please fill in this bug report template to ensure a timely and thorough response.**\r\n\r\n### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: yes, custom code\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **MLflow installed from (source or binary)**: binary\r\n- **MLflow version (run ``mlflow --version``)**: 1.20.2\r\n- **Python version**: 3.6.9\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nI am running unit tests for mlflow for different cases, and I need to reset the sqlite database and mlruns for each test case. Therefore I use setUp and tearDown to initialize the database and remote it later. I had no problem with this while using version 1.19. After I switched to version 1.20.2, I started having this problem.\r\n\r\nThe problem is, after tearDown removes the sqlite db after first case which have been, and setUp re-creates the database, following error occurs:\r\n\r\n```\r\nMyTests::test_case_3 Failed: [undefined]mlflow.exceptions.MlflowException: (sqlite3.OperationalError) no such table: experiments\r\n[SQL: SELECT experiments.experiment_id AS experiments_experiment_id, experiments.name AS experiments_name, experiments.artifact_location AS experiments_artifact_location, experiments.lifecycle_stage AS experiments_lifecycle_stage \r\nFROM experiments \r\nWHERE experiments.name = ? AND experiments.lifecycle_stage IN (?, ?)]\r\n[parameters: ('foo', 'active', 'deleted')]\r\n```\r\n\r\nIt seems like new test cases are not able to create missing tables.\r\nThanks in advance.\r\n\r\n### Code to reproduce issue\r\n\r\nCode below works well on 1.19, but fails on 1.20.2.\r\n\r\nRun with pytest as `pytest tests/test_dummy.py`\r\n\r\n```\r\nimport unittest\r\nimport os\r\nimport sqlite3\r\nimport shutil\r\nimport stat\r\n\r\nimport pytest\r\nimport pandas as pd\r\nimport lightgbm as lgb\r\nimport mlflow\r\nfrom mlflow.models.signature import infer_signature\r\n\r\n\r\nDB_NAME = \"mock.db\"\r\nos.environ[\"MLFLOW_TRACKING_URI\"] = \"sqlite:///\" + DB_NAME\r\n\r\n\r\nclass MyTests(unittest.TestCase):\r\n\r\n    @classmethod\r\n    def setUp(cls):\r\n        con = sqlite3.connect(DB_NAME)\r\n        con.close()\r\n\r\n    @classmethod\r\n    def tearDown(cls):\r\n        os.remove(DB_NAME)\r\n        if os.path.isdir(\"mlruns\"):\r\n            def _remove_readonly(func, path, excinfo):\r\n                os.chmod(path, stat.S_IWRITE)\r\n                func(path)\r\n\r\n            shutil.rmtree(\"mlruns\", onerror=_remove_readonly)\r\n\r\n    @property\r\n    def train_data(self):\r\n        return pd.DataFrame([\r\n            (1, 2, 3),\r\n            (2, 3, 5),\r\n            (3, 4, 7),\r\n            (4, 5, 9),\r\n            (5, 6, 11),\r\n        ], columns=[\"a\", \"b\", \"y\"])\r\n\r\n    @property\r\n    def test_data(self):\r\n        return pd.DataFrame([\r\n            (6, 7, 13)\r\n        ], columns=[\"a\", \"b\", \"y\"])\r\n\r\n    def test_case_1(self):\r\n        mlflow.set_experiment(\"foo\")\r\n        model_name = \"lgbm_model\"\r\n        parent_run = mlflow.start_run(run_name=\"parent_\" + model_name)\r\n        mlflow.start_run(nested=True, run_name=model_name)\r\n\r\n        train_data = self.train_data\r\n        x_train = train_data[[\"a\", \"b\"]]\r\n        y_train = train_data[\"y\"]\r\n        signature = infer_signature(x_train)\r\n\r\n        model = lgb.LGBMRegressor(n_estimators=10, num_leaves=5)\r\n        model.fit(x_train, y_train)\r\n        mlflow.sklearn.log_model(\r\n            model, \"model\", signature=signature,\r\n            registered_model_name=model_name)\r\n\r\n        mlflow.end_run()\r\n        mlflow.end_run()\r\n\r\n        # prediction\r\n        mlflow.start_run(run_id=parent_run.info.run_id)\r\n        mlflow.start_run(nested=True, run_name=\"prediction_\" + model_name)\r\n\r\n        test_data = self.test_data\r\n        x_test = test_data[[\"a\", \"b\"]]\r\n\r\n        loaded_model = mlflow.sklearn.load_model(\r\n            f\"models:/{model_name}/1\")\r\n        predictions = loaded_model.predict(x_test)\r\n        self.assertEqual(len(predictions), 1)\r\n\r\n        mlflow.end_run()\r\n        mlflow.end_run()\r\n\r\n    def test_case_2(self):\r\n        mlflow.set_experiment(\"foo\")\r\n        model_name = \"lgbm_model\"\r\n        parent_run = mlflow.start_run(run_name=\"parent_\" + model_name)\r\n        mlflow.start_run(nested=True, run_name=model_name)\r\n\r\n        train_data = self.train_data\r\n        x_train = train_data[[\"a\", \"b\"]]\r\n        y_train = train_data[\"y\"]\r\n        signature = infer_signature(x_train)\r\n\r\n        model = lgb.LGBMRegressor(n_estimators=10, num_leaves=5)\r\n        model.fit(x_train, y_train)\r\n        mlflow.sklearn.log_model(\r\n            model, \"model\", signature=signature,\r\n            registered_model_name=model_name)\r\n\r\n        mlflow.end_run()\r\n        mlflow.end_run()\r\n\r\n        # prediction\r\n        mlflow.start_run(run_id=parent_run.info.run_id)\r\n        mlflow.start_run(nested=True, run_name=\"prediction_\" + model_name)\r\n\r\n        test_data = self.test_data\r\n        x_test = test_data[[\"a\", \"b\"]]\r\n\r\n        loaded_model = mlflow.sklearn.load_model(\r\n            f\"models:/{model_name}/1\")\r\n        predictions = loaded_model.predict(x_test)\r\n        self.assertEqual(len(predictions), 1)\r\n\r\n        mlflow.end_run()\r\n        mlflow.end_run()\r\n\r\n    def test_case_3(self):\r\n        mlflow.set_experiment(\"foo\")\r\n        model_name = \"lgbm_model\"\r\n        parent_run = mlflow.start_run(run_name=\"parent_\" + model_name)\r\n        mlflow.start_run(nested=True, run_name=model_name)\r\n\r\n        train_data = self.train_data\r\n        x_train = train_data[[\"a\", \"b\"]]\r\n        y_train = train_data[\"y\"]\r\n        signature = infer_signature(x_train)\r\n\r\n        model = lgb.LGBMRegressor(n_estimators=10, num_leaves=5)\r\n        model.fit(x_train, y_train)\r\n        mlflow.sklearn.log_model(\r\n            model, \"model\", signature=signature,\r\n            registered_model_name=model_name)\r\n\r\n        mlflow.end_run()\r\n        mlflow.end_run()\r\n\r\n        # prediction\r\n        mlflow.start_run(run_id=parent_run.info.run_id)\r\n        mlflow.start_run(nested=True, run_name=\"prediction_\" + model_name)\r\n\r\n        test_data = self.test_data\r\n        x_test = test_data[[\"a\", \"b\"]]\r\n\r\n        loaded_model = mlflow.sklearn.load_model(\r\n            f\"models:/{model_name}/1\")\r\n        predictions = loaded_model.predict(x_test)\r\n        self.assertEqual(len(predictions), 1)\r\n\r\n        mlflow.end_run()\r\n        mlflow.end_run()\r\n\r\n```\r\n\r\n### Other info / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [x] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\r\n- [ ] `area/server-infra`: MLflow Tracking server backend\r\n- [x] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\r\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/4808/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/4808/timeline","performed_via_github_app":null,"state_reason":null}