{"url":"https://api.github.com/repos/mlflow/mlflow/issues/6451","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/6451/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/6451/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/6451/events","html_url":"https://github.com/mlflow/mlflow/issues/6451","id":1336181589,"node_id":"I_kwDOCB5Jx85PpINV","number":6451,"title":"[BUG] When serving predictions from a spark model, column \"prediction\" is expected","user":{"login":"johnyNJ","id":77425417,"node_id":"MDQ6VXNlcjc3NDI1NDE3","avatar_url":"https://avatars.githubusercontent.com/u/77425417?v=4","gravatar_id":"","url":"https://api.github.com/users/johnyNJ","html_url":"https://github.com/johnyNJ","followers_url":"https://api.github.com/users/johnyNJ/followers","following_url":"https://api.github.com/users/johnyNJ/following{/other_user}","gists_url":"https://api.github.com/users/johnyNJ/gists{/gist_id}","starred_url":"https://api.github.com/users/johnyNJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/johnyNJ/subscriptions","organizations_url":"https://api.github.com/users/johnyNJ/orgs","repos_url":"https://api.github.com/users/johnyNJ/repos","events_url":"https://api.github.com/users/johnyNJ/events{/privacy}","received_events_url":"https://api.github.com/users/johnyNJ/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":2022848043,"node_id":"MDU6TGFiZWwyMDIyODQ4MDQz","url":"https://api.github.com/repos/mlflow/mlflow/labels/area/models","name":"area/models","color":"48eabc","default":false,"description":"MLmodel format, model serialization/deserialization, flavors"},{"id":4300304016,"node_id":"LA_kwDOCB5Jx88AAAABAFFukA","url":"https://api.github.com/repos/mlflow/mlflow/labels/has-closing-pr","name":"has-closing-pr","color":"fef2c0","default":false,"description":"This issue has a closing PR"}],"state":"open","locked":false,"assignee":{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https://avatars.githubusercontent.com/u/39497902?v=4","gravatar_id":"","url":"https://api.github.com/users/dbczumar","html_url":"https://github.com/dbczumar","followers_url":"https://api.github.com/users/dbczumar/followers","following_url":"https://api.github.com/users/dbczumar/following{/other_user}","gists_url":"https://api.github.com/users/dbczumar/gists{/gist_id}","starred_url":"https://api.github.com/users/dbczumar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbczumar/subscriptions","organizations_url":"https://api.github.com/users/dbczumar/orgs","repos_url":"https://api.github.com/users/dbczumar/repos","events_url":"https://api.github.com/users/dbczumar/events{/privacy}","received_events_url":"https://api.github.com/users/dbczumar/received_events","type":"User","site_admin":false},"assignees":[{"login":"dbczumar","id":39497902,"node_id":"MDQ6VXNlcjM5NDk3OTAy","avatar_url":"https://avatars.githubusercontent.com/u/39497902?v=4","gravatar_id":"","url":"https://api.github.com/users/dbczumar","html_url":"https://github.com/dbczumar","followers_url":"https://api.github.com/users/dbczumar/followers","following_url":"https://api.github.com/users/dbczumar/following{/other_user}","gists_url":"https://api.github.com/users/dbczumar/gists{/gist_id}","starred_url":"https://api.github.com/users/dbczumar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dbczumar/subscriptions","organizations_url":"https://api.github.com/users/dbczumar/orgs","repos_url":"https://api.github.com/users/dbczumar/repos","events_url":"https://api.github.com/users/dbczumar/events{/privacy}","received_events_url":"https://api.github.com/users/dbczumar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":9,"created_at":"2022-08-11T16:09:14Z","updated_at":"2022-11-01T00:46:13Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"### Willingness to contribute\n\nYes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\n\n### MLflow version\n\n1.27.0\n\n### System information\n\n- **OS Platform and Distribution**: MacOS 12.1\r\n- **Python version**: 3.7.12\r\n\n\n### Describe the problem\n\nImplementation of `predict` for spark flavour in `mlflow.spark` expects column `prediction` to be present in dataframe. So if we want to serve a prediction column of our own choice, we have to name it `prediction` otherwise it will fail. Since this is not documented anywhere, I think this is a bug, not a feature.\r\n\r\nI think this is because it is assuming prediction is what the user will always be doing and `prediction` is the default value for the respective pyspark class `pyspark.ml.param.shared.HasPredictionCol`. However, we should not assume that user will  always be doing only prediction tasks, rather whatever a `PipelineModel` can produce, should be considered as the real \"prediction\". I believe that If a model signature is defined then that should become the real prediction.\r\n\n\n### Tracking information\n\n```python\r\nMLflow version: 1.27.0\r\nTracking URI: sqlite:////*/dev.db\r\nArtifact URI: ./mlruns/1/cc256bfaedcf43f492c8ad681021593f/artifacts\r\n```\n\n### Code to reproduce issue\n\n```python\r\nimport sys, os\r\nimport mlflow\r\nimport subprocess\r\nimport findspark\r\nimport mlflow.exceptions\r\nfrom mlflow.tracking import MlflowClient\r\nfrom mlflow.entities import Metric, Param\r\nfrom mlflow.models.signature import infer_signature\r\nfindspark.init()\r\nfrom pyspark.sql import SparkSession\r\nimport pyspark.sql.functions as F\r\nfrom pyspark.ml import Pipeline\r\nfrom pyspark.ml.feature import VectorAssembler, SQLTransformer\r\nfrom pyspark.ml.classification import LogisticRegression\r\nclient = MlflowClient()\r\ngerman_path = '*.csv'\r\n\r\ndef train_and_serve(kind):\r\n\r\n    pr= ['mlflow', 'pyspark==2.4.0']\r\n    spark = SparkSession.builder.getOrCreate()\r\n    try:\r\n        eid=mlflow.create_experiment(\"spark-serving-prediction-column\")\r\n    except Exception:\r\n        eid=mlflow.get_experiment_by_name(\"spark-serving-prediction-column\").experiment_id\r\n    mlflow.end_run()\r\n    print(\"MLflow version:\", mlflow.__version__)\r\n    print(\"Tracking URI:\", mlflow.get_tracking_uri())\r\n    with mlflow.start_run(experiment_id=eid):\r\n        print(\"Artifact URI:\", mlflow.get_artifact_uri())\r\n        rid1 = mlflow.active_run().info.run_id\r\n        lr = LogisticRegression(labelCol='flag_risk', featuresCol='feat').setElasticNetParam(0.5)\r\n        dp = Pipeline(stages=[\r\n            VectorAssembler(inputCols=['Credit_amount'], outputCol='feat'),\r\n            lr\r\n\r\n        ])\r\n        if kind==\"probability-wrong\":\r\n            # will fail due to hardcoding\r\n            col_prob = 'prob'\r\n            lr.setProbabilityCol(col_prob).setPredictionCol('pred')\r\n            lrn=\"probability\"\r\n            port=5002\r\n            print(\"Giving `probabilityCol` a random name. Will fail.\")\r\n        elif kind==\"breakup\":\r\n            # will succeed\r\n            col_prob = 'prediction'\r\n            lr.setProbabilityCol(\"prob\").setPredictionCol('pred')\r\n            breaker=SQLTransformer(statement=\"\"\"\r\n            select cast(split(substr(cast(prob as string), 2, length(cast(prob as string))-2), \",\")[1] as float) prediction FROM __THIS__\"\"\")\r\n\r\n            dp.setStages(dp.getStages()+[breaker])\r\n            lrn=\"broken-up-probability\"\r\n            port=5004\r\n            print(\"Breaking up vector column and manually naming as `prediction` after fitting.\")\r\n        else:\r\n            raise ValueError(kind)\r\n\r\n        german_credit_spark=spark.read.csv(german_path, inferSchema=True, header=True)\r\n        german_credit_spark = (\r\n        german_credit_spark.withColumn('flag_risk', F.expr(\"case when Risk='good' then 0 when Risk='bad' then 1 else null end\"))\r\n        )\r\n        dpm = dp.fit(german_credit_spark)\r\n        if kind==\"breakup\":\r\n            preds=dpm.transform(german_credit_spark)[[col_prob]]\r\n        else:\r\n            preds=None\r\n\r\n        signature=None\r\n        if preds:\r\n            signature = infer_signature(german_credit_spark[['Credit_amount']], preds)\r\n        mlflow.spark.log_model(dpm, \"model\", registered_model_name=lrn, pip_requirements=pr, signature=signature)\r\n\r\n    latest_version = client.get_latest_versions(lrn, stages=['None'])\r\n    assert len(latest_version)==1\r\n    latest_version=latest_version[0].version\r\n\r\n    serve_cmd = f'mlflow models serve -m models:/{lrn}/{latest_version} --env-manager=local --port {port} --host 127.0.0.1'.split()\r\n    subprocess.run(serve_cmd)\r\n    spark.stop()\r\n\r\n# train_and_serve(\"probability-wrong\")\r\n# THIS WILL FAIL\r\n# curl http://127.0.0.1:5002/invocations -H 'Content-Type: application/json' --data-raw '{\"columns\": [\"Credit_amount\"],\"index\":[0,1],\"data\": [[1304.4], [466.4]]}'\r\n\r\n# train_and_serve(\"breakup\")\r\n# THIS WILL WORK\r\n# curl http://127.0.0.1:5004/invocations -H 'Content-Type: application/json' --data-raw '{\"columns\": [\"Credit_amount\"],\"index\":[0,1],\"data\": [[1304.4], [466.4]]}'\r\n```\n\n### Stack trace\n\n```\r\n\r\n{\"error_code\": \"BAD_REQUEST\",\r\n \"message\": \"Encountered an unexpected error while evaluating the model. Verify that the serialized input Dataframe is compatible with the model for inference.\",\r\n \"stack_trace\": \r\n\"Traceback (most recent call last):\\n  File \\\"/usr/local/anaconda3/envs/mlflow-run/lib/python3.7/site-packages/pyspark/sql/utils.py\\\", line 63, in deco\\n    return f(*a, **kw)\\n\r\n  File \\\"/usr/local/anaconda3/envs/mlflow-run/lib/python3.7/site-packages/py4j/protocol.py\\\", line 328, in get_return_value\\n    format(target_id, \\\".\\\", name), value)\\npy4j.protocol.Py4JJavaError: An error occurred while calling o245.select.\\n: org.apache.spark.sql.AnalysisException: cannot resolve '`prediction`' given input columns: [Credit_amount, prob, pred, rawPrediction, feat];;\\n'Project ['prediction]\\n+- Project [Credit_amount#21, feat#23, rawPrediction#26, prob#30, UDF(rawPrediction#26) AS pred#35]\\n   +- Project [Credit_amount#21, feat#23, rawPrediction#26, UDF(rawPrediction#26) AS prob#30]\\n      +- Project [Credit_amount#21, feat#23, UDF(feat#23) AS rawPrediction#26]\\n         +- Project [Credit_amount#21, UDF(named_struct(Credit_amount, Credit_amount#21)) AS feat#23]\\n            +- LogicalRDD [Credit_amount#21], false\\n\\n\\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:110)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:107)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:278)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:278)\\n\\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\\n\\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:104)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:116)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$2.apply(QueryPlan.scala:121)\\n\\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\\n\\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\\n\\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\\n\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\\n\\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\\n\\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:121)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:126)\\n\\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:93)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:107)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:85)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:127)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:85)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\\n\\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\\n\\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\\n\\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\\n\\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\\n\\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:79)\\n\\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3407)\\n\\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1335)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\n\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\\n\\tat py4j.Gateway.invoke(Gateway.java:282)\\n\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\n\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\n\\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\\n\\tat java.lang.Thread.run(Thread.java:748)\\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n \r\n File \\\"/usr/local/anaconda3/envs/mlflow-run/lib/python3.7/site-packages/mlflow/pyfunc/scoring_server/__init__.py\\\", line 308, in transformation\\n    raw_predictions = model.predict(data)\\n\r\n  File \\\"/usr/local/anaconda3/envs/mlflow-run/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\\\", line 631, in predict\\n    return self._model_impl.predict(data)\\n \r\n File \\\"/usr/local/anaconda3/envs/mlflow-run/lib/python3.7/site-packages/mlflow/spark.py\\\", line 834, in predict\\n    for x in self.spark_model.transform(spark_df).select(prediction_column).collect()\\n \r\n File \\\"/usr/local/anaconda3/envs/mlflow-run/lib/python3.7/site-packages/pyspark/sql/dataframe.py\\\", line 1320, in select\\n    jdf = self._jdf.select(self._jcols(*cols))\\n \r\n File \\\"/usr/local/anaconda3/envs/mlflow-run/lib/python3.7/site-packages/py4j/java_gateway.py\\\", line 1257, in __call__\\n    answer, self.gateway_client, self.target_id, self.name)\\n \r\n File \\\"/usr/local/anaconda3/envs/mlflow-run/lib/python3.7/site-packages/pyspark/sql/utils.py\\\", line 69, in deco\\n    raise AnalysisException(s.split(': ', 1)[1], stackTrace)\\npyspark.sql.utils.AnalysisException: \\**\"cannot resolve '`prediction`' given input columns:** [Credit_amount, prob, pred, rawPrediction, feat];;\\\\n'Project ['prediction]\\\\n+- Project [Credit_amount#21, feat#23, rawPrediction#26, prob#30, UDF(rawPrediction#26) AS pred#35]\\\\n   +- Project [Credit_amount#21, feat#23, rawPrediction#26, UDF(rawPrediction#26) AS prob#30]\\\\n      +- Project [Credit_amount#21, feat#23, UDF(feat#23) AS rawPrediction#26]\\\\n         +- Project [Credit_amount#21, UDF(named_struct(Credit_amount, Credit_amount#21)) AS feat#23]\\\\n            +- LogicalRDD [Credit_amount#21], false\\\\n\\\"\\n\"}%\r\n```\n\n### Other info / logs\n\n_No response_\n\n### What component(s) does this bug affect?\n\n- [ ] `area/artifacts`: Artifact stores and artifact logging\n- [ ] `area/build`: Build and test infrastructure for MLflow\n- [ ] `area/docs`: MLflow documentation pages\n- [ ] `area/examples`: Example code\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\n- [X] `area/models`: MLmodel format, model serialization/deserialization, flavors\n- [ ] `area/pipelines`: Pipelines, Pipeline APIs, Pipeline configs, Pipeline Templates\n- [ ] `area/projects`: MLproject format, project running backends\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\n- [ ] `area/server-infra`: MLflow Tracking server backend\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\n\n### What interface(s) does this bug affect?\n\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\n- [ ] `area/windows`: Windows support\n\n### What language(s) does this bug affect?\n\n- [ ] `language/r`: R APIs and clients\n- [ ] `language/java`: Java APIs and clients\n- [ ] `language/new`: Proposals for new client languages\n\n### What integration(s) does this bug affect?\n\n- [ ] `integrations/azure`: Azure and Azure ML integrations\n- [ ] `integrations/sagemaker`: SageMaker integrations\n- [ ] `integrations/databricks`: Databricks integrations","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/6451/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/6451/timeline","performed_via_github_app":null,"state_reason":null}