{"url":"https://api.github.com/repos/mlflow/mlflow/issues/5985","repository_url":"https://api.github.com/repos/mlflow/mlflow","labels_url":"https://api.github.com/repos/mlflow/mlflow/issues/5985/labels{/name}","comments_url":"https://api.github.com/repos/mlflow/mlflow/issues/5985/comments","events_url":"https://api.github.com/repos/mlflow/mlflow/issues/5985/events","html_url":"https://github.com/mlflow/mlflow/issues/5985","id":1251961275,"node_id":"I_kwDOCB5Jx85Kn2m7","number":5985,"title":"[BUG] Loading mlflow model using spark_udf fails on Databricks with cannot import name '_SparkDirectoryDistributor'","user":{"login":"leweex95","id":74991597,"node_id":"MDQ6VXNlcjc0OTkxNTk3","avatar_url":"https://avatars.githubusercontent.com/u/74991597?v=4","gravatar_id":"","url":"https://api.github.com/users/leweex95","html_url":"https://github.com/leweex95","followers_url":"https://api.github.com/users/leweex95/followers","following_url":"https://api.github.com/users/leweex95/following{/other_user}","gists_url":"https://api.github.com/users/leweex95/gists{/gist_id}","starred_url":"https://api.github.com/users/leweex95/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leweex95/subscriptions","organizations_url":"https://api.github.com/users/leweex95/orgs","repos_url":"https://api.github.com/users/leweex95/repos","events_url":"https://api.github.com/users/leweex95/events{/privacy}","received_events_url":"https://api.github.com/users/leweex95/received_events","type":"User","site_admin":false},"labels":[{"id":955449428,"node_id":"MDU6TGFiZWw5NTU0NDk0Mjg=","url":"https://api.github.com/repos/mlflow/mlflow/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":2114036915,"node_id":"MDU6TGFiZWwyMTE0MDM2OTE1","url":"https://api.github.com/repos/mlflow/mlflow/labels/integrations/databricks","name":"integrations/databricks","color":"ffbce5","default":false,"description":"Databricks integrations"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":11,"created_at":"2022-05-29T18:37:17Z","updated_at":"2022-05-30T12:14:33Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"### Willingness to contribute\n\nNo. I cannot contribute a bug fix at this time.\n\n### MLflow version\n\n1.20.2\n\n### System information\n\n- **Python version**: 3.8.2.\r\n- **Databricks ML Runtime version**: 9.1.\n\n### Describe the problem\n\nI'm working on Databricks with ML Runtime 9.1 and Mlflow, to build a simple training & inference pipeline, by logging trained models to Mlflow's Model Registry and retrieving it during inference as a `spark_udf`.\r\n\r\nI successfully logged the model and artifacts to the Model Registry. Once there, I manually registered the model on the UI, and set the stage to production. In the inference notebook, I simply use the `load_model()` function to load the model, and then `mlflow.pyfunc.spark_udf` to convert the model to spark user defined function.\r\n\r\nAt this last line, a surprising error shows that I don't understand:\r\n```\r\nImportError: cannot import name '_SparkDirectoryDistributor' from \r\n'mlflow.utils._spark_utils' \r\n(/databricks/python/lib/python3.8/site-packages/mlflow/utils/_spark_utils.py)\r\n```\r\n\r\n**Detailed traceback**:\r\n```\r\nImportError                               Traceback (most recent call last)\r\n<command-1233344365339> in <module>\r\n     25 model = mlflow.sklearn.load_model(model_path)\r\n     26 \r\n---> 27 predict = mlflow.pyfunc.spark_udf(spark, model_uri=model_path, result_type=ArrayType(StringType()))\r\n\r\n/databricks/python/lib/python3.8/site-packages/mlflow/pyfunc/__init__.py in spark_udf(spark, model_uri, result_type)\r\n    795 \r\n    796 def get_model_dependencies(model_uri, format=\"pip\"):  # pylint: disable=redefined-builtin\r\n--> 797     \"\"\"\r\n    798     :param model_uri: The uri of the model to get dependencies from.\r\n    799     :param format: The format of the returned dependency file. If the ``\"pip\"`` format is\r\n\r\n/databricks/python_shell/dbruntime/PythonPackageImportsInstrumentation/__init__.py in import_patch(name, globals, locals, fromlist, level)\r\n    160             # Import the desired module. If youâ€™re seeing this while debugging a failed import,\r\n    161             # look at preceding stack frames for relevant error information.\r\n--> 162             original_result = python_builtin_import(name, globals, locals, fromlist, level)\r\n    163 \r\n    164             is_root_import = thread_local._nest_level == 1\r\n\r\n/databricks/python/lib/python3.8/site-packages/mlflow/pyfunc/spark_model_cache.py in <module>\r\n----> 1 from mlflow.utils._spark_utils import _SparkDirectoryDistributor\r\n      2 \r\n      3 \r\n      4 class SparkModelCache:\r\n      5     \"\"\"Caches models in memory on Spark Executors, to avoid continually reloading from disk.\r\n\r\nImportError: cannot import name '_SparkDirectoryDistributor' from 'mlflow.utils._spark_utils' (/databricks/python/lib/python3.8/site-packages/mlflow/utils/_spark_utils.py)\r\n```\n\n### Tracking information\n\n_No response_\n\n### Code to reproduce issue\n\n**training notebook**:\r\n```\r\nimport mlflow\r\nfrom sklearn.datasets import load_digits\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.linear_model import LogisticRegression\r\n\r\nMODEL_NAME = \"model001\"\r\n\r\nmlflow.start_run()\r\n\r\ndigits = load_digits()\r\n\r\nx_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target)\r\n\r\nlogisticRegr = LogisticRegression()\r\nlogisticRegr.fit(x_train, y_train)\r\nscore = logisticRegr.score(x_test, y_test)\r\n\r\nconda_env = mlflow.pyfunc.get_default_conda_env()\r\n        \r\nclass MyModel(mlflow.pyfunc.PythonModel):\r\n    def save_context(self, model, path, conda_env):\r\n        artifacts = {'model': path}\r\n        mlflow.sklearn.save_model(sk_model=model, path=artifacts['model'], conda_env=conda_env)\r\n\r\n    def load_context(self, context: mlflow.pyfunc.PythonModelContext):\r\n        model = mlflow.sklearn.load_model(context.artifacts['model'])\r\n\r\n    def predict(self, context: mlflow.pyfunc.PythonModelContext, input_data):\r\n        return model.predict(input_data.values)\r\n\r\npymodel = MyModel()\r\npymodel.save_context(logisticRegr, MODEL_NAME, conda_env)\r\n\r\nmlflow.sklearn.log_model(artifact_path=MODEL_NAME, sk_model=pymodel, conda_env = conda_env)\r\n\r\nmlflow.end_run()\r\n```\r\n\r\n**inference notebook**:\r\n```\r\nimport mlflow\r\nfrom mlflow.store.artifact.models_artifact_repo import ModelsArtifactRepository\r\n\r\nMODEL_NAME = \"model001\"\r\n\r\nmodel_path = f\"models:/{MODEL_NAME}/production\"\r\nmodel = mlflow.sklearn.load_model(model_path)\r\npredict = mlflow.pyfunc.spark_udf(spark, model_uri=model_path)\r\n```\r\n\n\n### Other info / logs\n\n_No response_\n\n### What component(s) does this bug affect?\n\n- [ ] `area/artifacts`: Artifact stores and artifact logging\n- [ ] `area/build`: Build and test infrastructure for MLflow\n- [ ] `area/docs`: MLflow documentation pages\n- [ ] `area/examples`: Example code\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\n- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors\n- [ ] `area/projects`: MLproject format, project running backends\n- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs\n- [ ] `area/server-infra`: MLflow Tracking server backend\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\n\n### What interface(s) does this bug affect?\n\n- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server\n- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\n- [ ] `area/windows`: Windows support\n\n### What language(s) does this bug affect?\n\n- [ ] `language/r`: R APIs and clients\n- [ ] `language/java`: Java APIs and clients\n- [ ] `language/new`: Proposals for new client languages\n\n### What integration(s) does this bug affect?\n\n- [ ] `integrations/azure`: Azure and Azure ML integrations\n- [ ] `integrations/sagemaker`: SageMaker integrations\n- [X] `integrations/databricks`: Databricks integrations","closed_by":null,"reactions":{"url":"https://api.github.com/repos/mlflow/mlflow/issues/5985/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mlflow/mlflow/issues/5985/timeline","performed_via_github_app":null,"state_reason":null}