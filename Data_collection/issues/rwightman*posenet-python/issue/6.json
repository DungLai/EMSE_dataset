{"url":"https://api.github.com/repos/rwightman/posenet-python/issues/6","repository_url":"https://api.github.com/repos/rwightman/posenet-python","labels_url":"https://api.github.com/repos/rwightman/posenet-python/issues/6/labels{/name}","comments_url":"https://api.github.com/repos/rwightman/posenet-python/issues/6/comments","events_url":"https://api.github.com/repos/rwightman/posenet-python/issues/6/events","html_url":"https://github.com/rwightman/posenet-python/issues/6","id":416833856,"node_id":"MDU6SXNzdWU0MTY4MzM4NTY=","number":6,"title":"Tracking","user":{"login":"ghost","id":10137,"node_id":"MDQ6VXNlcjEwMTM3","avatar_url":"https://avatars.githubusercontent.com/u/10137?v=4","gravatar_id":"","url":"https://api.github.com/users/ghost","html_url":"https://github.com/ghost","followers_url":"https://api.github.com/users/ghost/followers","following_url":"https://api.github.com/users/ghost/following{/other_user}","gists_url":"https://api.github.com/users/ghost/gists{/gist_id}","starred_url":"https://api.github.com/users/ghost/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ghost/subscriptions","organizations_url":"https://api.github.com/users/ghost/orgs","repos_url":"https://api.github.com/users/ghost/repos","events_url":"https://api.github.com/users/ghost/events{/privacy}","received_events_url":"https://api.github.com/users/ghost/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2019-03-04T14:42:42Z","updated_at":"2019-04-25T15:43:18Z","closed_at":"2019-04-25T15:43:18Z","author_association":"NONE","active_lock_reason":null,"body":"I am trying to implement a tracking function for the joint, to reduce the computation as it uses a tracker for the points an look for the movement only around the place it has been detected. It works as by detecting the whole frame each 10 frames and in the 9 in between it only tracks it with the correlation tracker in the dlib. The problem I have is that I have the points tracked it it appears that does not have the same position. Also it appears that because of the number of trackers it needs more computation than before (+200 in 30 frames). I do not know if you have another way of implementing it or accelerating the program. \r\n\r\nThe code I have is:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport cv2\r\nimport time\r\nimport argparse\r\nimport dlib\r\nimport glob\r\nimport cvlib as cv\r\nimport threading\r\nimport time\r\nimport os \r\nimport posenet\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument('--model', type=int, default=101)\r\nparser.add_argument('--cam_id', type=int, default=0)\r\nparser.add_argument('--cam_width', type=int, default=1280)\r\nparser.add_argument('--cam_height', type=int, default=720)\r\nparser.add_argument('--scale_factor', type=float, default=0.7125)\r\nargs = parser.parse_args()\r\n\r\ntrackingQuality_threshold = 7\r\nn_frames_to_detect = 10\r\nmin_confidence = 0.55\r\nsec=5\r\n\r\ndef main():\r\n\r\n    with tf.Session() as sess:\r\n        model_cfg, model_outputs = posenet.load_model(args.model, sess)\r\n        output_stride = model_cfg['output_stride']\r\n\r\n        cap = cv2.VideoCapture(\"data/test_videos/dinner.mp4\")\r\n        cap.set(3, args.cam_width)\r\n        cap.set(4, args.cam_height)\r\n        len_video = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\r\n        fourcc = cv2.VideoWriter_fourcc(*'XVID')\r\n        output_movie = cv2.VideoWriter('data/track_video/pose_detection.avi', fourcc, 29.97, (args.cam_width, args.cam_height))\r\n\r\n        listofcenters = []\r\n        centers = []\r\n        max_displacement = []\r\n        max_movement_single=[]\r\n\r\n        frame_number = 0\r\n        currentFaceID = 0\r\n        cont=0\r\n\r\n        rectangleColor = (0,0,255)\r\n        faceTrackers = {}\r\n\r\n        start = time.time()\r\n        frame_count = 0\r\n        while True:\r\n            if frame_count==len_video:\r\n                break\r\n\r\n            input_image, display_image, output_scale = posenet.read_cap(\r\n                cap, scale_factor=args.scale_factor, output_stride=output_stride)\r\n            frame_count += 1\r\n\r\n            fidsToDelete = []\r\n            for fid in faceTrackers.keys():\r\n                trackingQuality = faceTrackers[ fid ].update( overlay_image )\r\n\r\n                if trackingQuality < trackingQuality_threshold:\r\n                    fidsToDelete.append( fid )\r\n\r\n            for fid in fidsToDelete:\r\n                print(\"Removing fid \" + str(fid) + \" from list of trackers\")\r\n                faceTrackers.pop( fid , None )\r\n\r\n\r\n            if (frame_number % n_frames_to_detect) == 0:\r\n\r\n                heatmaps_result, offsets_result, displacement_fwd_result, displacement_bwd_result = sess.run(\r\n                    model_outputs,\r\n                    feed_dict={'image:0': input_image}\r\n                )\r\n\r\n                pose_scores, keypoint_scores, keypoint_coords = posenet.decode_multi.decode_multiple_poses( heatmaps_result.squeeze(axis=0), offsets_result.squeeze(axis=0), displacement_fwd_result.squeeze(axis=0), displacement_bwd_result.squeeze(axis=0), output_stride=output_stride, max_pose_detections=10, min_pose_score=0.15)\r\n\r\n                keypoint_coords *= output_scale\r\n\r\n                overlay_image = posenet.draw_skel_and_kp( display_image, pose_scores, keypoint_scores, keypoint_coords, min_pose_score=0.15, min_part_score=0.1)\r\n\r\n                \r\n                for idx,esq in enumerate(keypoint_coords):\r\n                    for idx_2,coor in enumerate(esq):\r\n                        x= int(coor[0])\r\n                        y= int(coor[1])\r\n                        w= 5\r\n                        h= 5 \r\n                        x_bar= x + 0.5 * w\r\n                        y_bar= y + 0.5 * h\r\n\r\n                        matchedFid = None\r\n                    \r\n                        for fid in faceTrackers.keys():\r\n                            tracked_position = faceTrackers[fid].get_position()\r\n\r\n                            t_x= int(tracked_position.left())\r\n                            t_y= int(tracked_position.top())\r\n                            t_w= int(tracked_position.width())\r\n                            t_h= int(tracked_position.height())\r\n                            t_x_bar= t_x + 0.5 * t_w\r\n                            t_y_bar= t_y + 0.5 * t_h\r\n    \r\n                            if ( ( t_x <= x_bar   <= (t_x + t_w)) and \r\n                                 ( t_y <= y_bar   <= (t_y + t_h)) and \r\n                                 ( x   <= t_x_bar <= (x   + w  )) and \r\n                                 ( y   <= t_y_bar <= (y   + h  ))):\r\n\r\n                                matchedFid = fid\r\n\r\n                        if ((matchedFid is None)):\r\n\r\n                            print(\"Creating new tracker \" + str(currentFaceID))\r\n                        \r\n                            tracker = dlib.correlation_tracker()\r\n                            tracker.start_track(overlay_image,dlib.rectangle( x-10,y-20,x+w+10,y+h+20))\r\n\r\n                            faceTrackers[ currentFaceID ] = tracker\r\n                            currentFaceID += 1\r\n\r\n\r\n            for fid in faceTrackers.keys():\r\n                tracked_position =  faceTrackers[fid].get_position()\r\n\r\n                t_x = int(tracked_position.left())\r\n                t_y = int(tracked_position.top())\r\n                t_w = int(tracked_position.width())\r\n                t_h = int(tracked_position.height())\r\n                t_x_bar = t_x + 0.5 * t_w\r\n                t_y_bar = t_y + 0.5 * t_h\r\n                cv2.circle(overlay_image, (t_x, t_y),5, rectangleColor ,2)\r\n\r\n\r\n            cv2.imshow('posenet', overlay_image)\r\n            output_movie.write(overlay_image)\r\n            \r\n            if cv2.waitKey(1) & 0xFF == ord('q'):\r\n                break\r\n\r\n        print('Average FPS: ', frame_count / (time.time() - start))\r\n        print('time: ', (time.time() - start))\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```","closed_by":{"login":"rwightman","id":5702664,"node_id":"MDQ6VXNlcjU3MDI2NjQ=","avatar_url":"https://avatars.githubusercontent.com/u/5702664?v=4","gravatar_id":"","url":"https://api.github.com/users/rwightman","html_url":"https://github.com/rwightman","followers_url":"https://api.github.com/users/rwightman/followers","following_url":"https://api.github.com/users/rwightman/following{/other_user}","gists_url":"https://api.github.com/users/rwightman/gists{/gist_id}","starred_url":"https://api.github.com/users/rwightman/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rwightman/subscriptions","organizations_url":"https://api.github.com/users/rwightman/orgs","repos_url":"https://api.github.com/users/rwightman/repos","events_url":"https://api.github.com/users/rwightman/events{/privacy}","received_events_url":"https://api.github.com/users/rwightman/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/rwightman/posenet-python/issues/6/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/rwightman/posenet-python/issues/6/timeline","performed_via_github_app":null,"state_reason":"completed"}