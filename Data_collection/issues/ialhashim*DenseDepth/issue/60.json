{"url":"https://api.github.com/repos/ialhashim/DenseDepth/issues/60","repository_url":"https://api.github.com/repos/ialhashim/DenseDepth","labels_url":"https://api.github.com/repos/ialhashim/DenseDepth/issues/60/labels{/name}","comments_url":"https://api.github.com/repos/ialhashim/DenseDepth/issues/60/comments","events_url":"https://api.github.com/repos/ialhashim/DenseDepth/issues/60/events","html_url":"https://github.com/ialhashim/DenseDepth/issues/60","id":496681262,"node_id":"MDU6SXNzdWU0OTY2ODEyNjI=","number":60,"title":"about depth_shape size ","user":{"login":"mahxn0","id":19154155,"node_id":"MDQ6VXNlcjE5MTU0MTU1","avatar_url":"https://avatars.githubusercontent.com/u/19154155?v=4","gravatar_id":"","url":"https://api.github.com/users/mahxn0","html_url":"https://github.com/mahxn0","followers_url":"https://api.github.com/users/mahxn0/followers","following_url":"https://api.github.com/users/mahxn0/following{/other_user}","gists_url":"https://api.github.com/users/mahxn0/gists{/gist_id}","starred_url":"https://api.github.com/users/mahxn0/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mahxn0/subscriptions","organizations_url":"https://api.github.com/users/mahxn0/orgs","repos_url":"https://api.github.com/users/mahxn0/repos","events_url":"https://api.github.com/users/mahxn0/events{/privacy}","received_events_url":"https://api.github.com/users/mahxn0/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2019-09-21T17:37:30Z","updated_at":"2019-10-15T10:09:43Z","closed_at":"2019-09-21T17:41:00Z","author_association":"NONE","active_lock_reason":null,"body":"thanks for your great work\r\nI can't understand why shape_rgb is 640*480, the shape_depth is 320*240? \r\n\r\nIf I used kitti.h5 to fintuning,my dataset is 1280*720, First I resized all rgb and depth to 370*1224?\r\n\r\nthen there some code do I need to modify ?\r\n\r\nthere is my dataload code:\r\n```\r\nimport numpy as np\r\nfrom utils import DepthNorm\r\nfrom io import BytesIO\r\nfrom PIL import Image\r\nfrom zipfile import ZipFile\r\nfrom keras.utils import Sequence\r\nfrom augment import BasicPolicy\r\n\r\ndef extract_zip(input_zip):\r\n    input_zip=ZipFile(input_zip)\r\n    return {name: input_zip.read(name) for name in input_zip.namelist()}\r\n\r\ndef nyu_resize_x(img, resolution=370, padding=6):\r\n    from skimage.transform import resize\r\n    return resize(img, (resolution, 1224), preserve_range=True, mode='reflect', anti_aliasing=True )\r\n\r\ndef nyu_resize_y(img, resolution=370, padding=6):\r\n    from skimage.transform import resize\r\n    return resize(img, (resolution,612), preserve_range=True, mode='reflect', anti_aliasing=True )\r\n\r\ndef get_nyu_data(batch_size, nyu_data_zipfile='nyu_data.zip'):\r\n    #data = extract_zip(nyu_data_zipfile)\r\n    #nyu2_train = list((row.split(',') for row in (data['data/nyu2_train.csv']).decode(\"utf-8\").split('\\n') if len(row) > 0))\r\n    #nyu2_test = list((row.split(',') for row in (data['data/nyu2_test.csv']).decode(\"utf-8\").split('\\n') if len(row) > 0))\r\n    img_lists,label_lists=None,None\r\n    nyu2_train=[]\r\n    nyu2_test=[]\r\n    with open(\"/media/mahxn0/DATA/rili/train/train.txt\",\"r\") as f1:\r\n        img_lists=f1.readlines()\r\n    with open(\"/media/mahxn0/DATA/rili/train/label.txt\",\"r\") as f2:\r\n        label_lists=f2.readlines()\r\n    for i in range(len(img_lists)):\r\n        item = [img_lists[i].rstrip('\\n'),label_lists[i].rstrip('\\n')]\r\n        nyu2_train.append(item)\r\n    with open(\"/media/mahxn0/DATA/rili/test/test.txt\",\"r\") as f3:\r\n        img_test_lists=f3.readlines()\r\n    with open(\"/media/mahxn0/DATA/rili/test/test_label.txt\",\"r\") as f4:\r\n        label_test_lists=f4.readlines()\r\n    for i in range(len(img_test_lists)):\r\n        item = [img_test_lists[i].rstrip('\\n'),label_test_lists[i].rstrip('\\n')]\r\n        nyu2_test.append(item)\r\n    shape_rgb = (batch_size, 370, 1224, 3)\r\n    shape_depth = (batch_size, 185, 612, 1)\r\n\r\n    # Helpful for testing...\r\n    if False:\r\n        nyu2_train = nyu2_train[:10]\r\n        nyu2_test = nyu2_test[:10]\r\n\r\n    return nyu2_train, nyu2_test, shape_rgb, shape_depth\r\n\r\ndef get_nyu_train_test_data(batch_size):\r\n    nyu2_train, nyu2_test, shape_rgb, shape_depth = get_nyu_data(batch_size)\r\n\r\n    train_generator = NYU_BasicAugmentRGBSequence(nyu2_train, batch_size=batch_size, shape_rgb=shape_rgb, shape_depth=shape_depth)\r\n    test_generator = NYU_BasicRGBSequence(nyu2_test, batch_size=batch_size, shape_rgb=shape_rgb, shape_depth=shape_depth)\r\n\r\n    return train_generator, test_generator\r\n\r\nclass NYU_BasicAugmentRGBSequence(Sequence):\r\n    def __init__(self,dataset, batch_size, shape_rgb, shape_depth, is_flip=False, is_addnoise=False, is_erase=False):\r\n        self.dataset = dataset\r\n        self.policy = BasicPolicy( color_change_ratio=0.50, mirror_ratio=0.50, flip_ratio=0.0 if not is_flip else 0.2, \r\n                                    add_noise_peak=0 if not is_addnoise else 20, erase_ratio=-1.0 if not is_erase else 0.5)\r\n        self.batch_size = batch_size\r\n        self.shape_rgb = shape_rgb\r\n        self.shape_depth = shape_depth\r\n        self.maxDepth = 1000.0\r\n\r\n        from sklearn.utils import shuffle\r\n        self.dataset = shuffle(self.dataset, random_state=0)\r\n\r\n        self.N = len(self.dataset)\r\n\r\n    def __len__(self):\r\n        return int(np.ceil(self.N / float(self.batch_size)))\r\n\r\n    def __getitem__(self, idx, is_apply_policy=True):\r\n        batch_x, batch_y = np.zeros( self.shape_rgb ), np.zeros( self.shape_depth )\r\n        # Augmentation of RGB images\r\n        for i in range(batch_x.shape[0]):\r\n            index = min((idx * self.batch_size) + i, self.N-1)\r\n\r\n            sample = self.dataset[index]\r\n\r\n            x = np.clip(np.asarray(Image.open( sample[0] )).reshape(370, 1224,3)/255,0,1)\r\n            y = np.clip(np.asarray(Image.open( sample[1] )).reshape(370, 1224,1)/255*self.maxDepth,0,self.maxDepth)\r\n            y = DepthNorm(y, maxDepth=self.maxDepth)\r\n            batch_x[i] = nyu_resize_x(x, 370)\r\n            batch_y[i] = nyu_resize_y(y, 185)\r\n\r\n            if is_apply_policy: batch_x[i], batch_y[i] = self.policy(batch_x[i], batch_y[i])\r\n\r\n            # DEBUG:\r\n            #self.policy.debug_img(batch_x[i], np.clip(DepthNorm(batch_y[i])/maxDepth,0,1), idx, i)\r\n        #exit()\r\n\r\n        return batch_x, batch_y\r\n\r\nclass NYU_BasicRGBSequence(Sequence):\r\n    def __init__(self,dataset, batch_size,shape_rgb, shape_depth):\r\n        self.dataset = dataset\r\n        self.batch_size = batch_size\r\n        self.N = len(self.dataset)\r\n        self.shape_rgb = shape_rgb\r\n        self.shape_depth = shape_depth\r\n        self.maxDepth = 1000.0\r\n\r\n    def __len__(self):\r\n        return int(np.ceil(self.N / float(self.batch_size)))\r\n\r\n    def __getitem__(self, idx):\r\n        batch_x, batch_y = np.zeros( self.shape_rgb ), np.zeros( self.shape_depth )\r\n        for i in range(self.batch_size):            \r\n            index = min((idx * self.batch_size) + i, self.N-1)\r\n\r\n            sample = self.dataset[index]\r\n\r\n            x = np.clip(np.asarray(Image.open( sample[0])).reshape(370,1224,3)/255,0,1)\r\n            y = np.asarray(Image.open(sample[1]), dtype=np.float32).reshape(185,612,1).copy().astype(float) / 10.0\r\n            y = DepthNorm(y, maxDepth=self.maxDepth)\r\n\r\n            batch_x[i] = nyu_resize(x, 370)\r\n            batch_y[i] = nyu_resize(y, 185)\r\n\r\n            # DEBUG:\r\n            #self.policy.debug_img(batch_x[i], np.clip(DepthNorm(batch_y[i])/maxDepth,0,1), idx, i)\r\n        #exit()\r\n\r\n        return batch_x, batch_y\r\n```\r\nlook forward you reply ^_^","closed_by":{"login":"ialhashim","id":2434978,"node_id":"MDQ6VXNlcjI0MzQ5Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/2434978?v=4","gravatar_id":"","url":"https://api.github.com/users/ialhashim","html_url":"https://github.com/ialhashim","followers_url":"https://api.github.com/users/ialhashim/followers","following_url":"https://api.github.com/users/ialhashim/following{/other_user}","gists_url":"https://api.github.com/users/ialhashim/gists{/gist_id}","starred_url":"https://api.github.com/users/ialhashim/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ialhashim/subscriptions","organizations_url":"https://api.github.com/users/ialhashim/orgs","repos_url":"https://api.github.com/users/ialhashim/repos","events_url":"https://api.github.com/users/ialhashim/events{/privacy}","received_events_url":"https://api.github.com/users/ialhashim/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/ialhashim/DenseDepth/issues/60/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ialhashim/DenseDepth/issues/60/timeline","performed_via_github_app":null,"state_reason":"completed"}