{"url":"https://api.github.com/repos/ialhashim/DenseDepth/issues/129","repository_url":"https://api.github.com/repos/ialhashim/DenseDepth","labels_url":"https://api.github.com/repos/ialhashim/DenseDepth/issues/129/labels{/name}","comments_url":"https://api.github.com/repos/ialhashim/DenseDepth/issues/129/comments","events_url":"https://api.github.com/repos/ialhashim/DenseDepth/issues/129/events","html_url":"https://github.com/ialhashim/DenseDepth/issues/129","id":631907739,"node_id":"MDU6SXNzdWU2MzE5MDc3Mzk=","number":129,"title":"Scaling outputs","user":{"login":"ahmeda14960","id":30680697,"node_id":"MDQ6VXNlcjMwNjgwNjk3","avatar_url":"https://avatars.githubusercontent.com/u/30680697?v=4","gravatar_id":"","url":"https://api.github.com/users/ahmeda14960","html_url":"https://github.com/ahmeda14960","followers_url":"https://api.github.com/users/ahmeda14960/followers","following_url":"https://api.github.com/users/ahmeda14960/following{/other_user}","gists_url":"https://api.github.com/users/ahmeda14960/gists{/gist_id}","starred_url":"https://api.github.com/users/ahmeda14960/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ahmeda14960/subscriptions","organizations_url":"https://api.github.com/users/ahmeda14960/orgs","repos_url":"https://api.github.com/users/ahmeda14960/repos","events_url":"https://api.github.com/users/ahmeda14960/events{/privacy}","received_events_url":"https://api.github.com/users/ahmeda14960/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":8,"created_at":"2020-06-05T20:01:05Z","updated_at":"2020-06-13T20:37:56Z","closed_at":"2020-06-13T20:37:56Z","author_association":"NONE","active_lock_reason":null,"body":"Hello, I am using DenseDepth to predict depth from an image I generated from the simulation. The image is shown directly below:\r\n![14](https://user-images.githubusercontent.com/30680697/83915206-cd294180-a740-11ea-94eb-92abf29195d9.png)\r\n\r\nAfter looking through the linked paper, I found the following explanation of how to use the outputs from DenseDepth to predict real-world depth: \r\n![image](https://user-images.githubusercontent.com/30680697/83915723-cd760c80-a741-11ea-9b2f-6cd0532471b7.png)\r\n\r\nWhich means that  y_orig = m/y. I implemented this in the following code\r\n```python\r\nexisting = 'kitti.h5'\r\ncustom_objects = {'BilinearUpSampling2D': BilinearUpSampling2D, 'depth_loss_function': None}\r\nmodel = load_model(existing, custom_objects=custom_objects, compile=False)\r\n\r\n# just test on one image\r\n# convert this image to an RGB numpy array\r\nimage_files = ['14.png']\r\ndata = load_images(image_files)\r\n\r\n# maximum depth for KITTI is 80 meters\r\nm = 80\r\npred_arr = predict(model, data, 0, 80)\r\n# output is (1, height, width, 1) for some reason\r\ny = pred_arr[0, :, :, 0]\r\ny_orig = m / y\r\n\r\nplt.imshow(y_orig, cmap='magma_r')\r\nplt.colorbar()\r\nplt.show()\r\n```\r\n\r\nUsing the predict function and other utility functions from this repo. I'll put the predict function below for reference\r\n```python\r\ndef DepthNorm(x, maxDepth):\r\n    return maxDepth / x\r\n\r\ndef predict(model, images, minDepth=10, maxDepth=1000, batch_size=2):\r\n    # Support multiple RGBs, one RGB image, even grayscale \r\n    # I'm guessing this is the grayscale case\r\n    if len(images.shape) < 3: images = np.stack((images,images,images), axis=2)\r\n    # and this is for when we only have one image\r\n    if len(images.shape) < 4: images = images.reshape((1, images.shape[0], images.shape[1], images.shape[2]))\r\n    # Compute predictions\r\n    predictions = model.predict(images, batch_size=batch_size)\r\n    # Put in expected range\r\n    return np.clip(DepthNorm(predictions, maxDepth=maxDepth), minDepth, maxDepth) / maxDepth\r\n```\r\n\r\nAnd I got the following output\r\n![dense_depth](https://user-images.githubusercontent.com/30680697/83917699-53e01d80-a745-11ea-808b-cb790125bc9b.png)\r\n\r\nThis doesn't make sense to me for two reasons. 1) it seems to range from 0 to 1400 when it should range from 0 to 80, and 2) The objects in the foreground which are closer to the camera are given depth predictions that are much larger than objects in the background which are further from the camera. \r\n\r\nAm I using the functions from this library properly?","closed_by":{"login":"ahmeda14960","id":30680697,"node_id":"MDQ6VXNlcjMwNjgwNjk3","avatar_url":"https://avatars.githubusercontent.com/u/30680697?v=4","gravatar_id":"","url":"https://api.github.com/users/ahmeda14960","html_url":"https://github.com/ahmeda14960","followers_url":"https://api.github.com/users/ahmeda14960/followers","following_url":"https://api.github.com/users/ahmeda14960/following{/other_user}","gists_url":"https://api.github.com/users/ahmeda14960/gists{/gist_id}","starred_url":"https://api.github.com/users/ahmeda14960/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ahmeda14960/subscriptions","organizations_url":"https://api.github.com/users/ahmeda14960/orgs","repos_url":"https://api.github.com/users/ahmeda14960/repos","events_url":"https://api.github.com/users/ahmeda14960/events{/privacy}","received_events_url":"https://api.github.com/users/ahmeda14960/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/ialhashim/DenseDepth/issues/129/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ialhashim/DenseDepth/issues/129/timeline","performed_via_github_app":null,"state_reason":"completed"}