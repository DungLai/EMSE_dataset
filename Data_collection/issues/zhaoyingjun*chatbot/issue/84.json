{"url":"https://api.github.com/repos/zhaoyingjun/chatbot/issues/84","repository_url":"https://api.github.com/repos/zhaoyingjun/chatbot","labels_url":"https://api.github.com/repos/zhaoyingjun/chatbot/issues/84/labels{/name}","comments_url":"https://api.github.com/repos/zhaoyingjun/chatbot/issues/84/comments","events_url":"https://api.github.com/repos/zhaoyingjun/chatbot/issues/84/events","html_url":"https://github.com/zhaoyingjun/chatbot/issues/84","id":606032984,"node_id":"MDU6SXNzdWU2MDYwMzI5ODQ=","number":84,"title":"关于embedding","user":{"login":"JavaLeb","id":32377468,"node_id":"MDQ6VXNlcjMyMzc3NDY4","avatar_url":"https://avatars.githubusercontent.com/u/32377468?v=4","gravatar_id":"","url":"https://api.github.com/users/JavaLeb","html_url":"https://github.com/JavaLeb","followers_url":"https://api.github.com/users/JavaLeb/followers","following_url":"https://api.github.com/users/JavaLeb/following{/other_user}","gists_url":"https://api.github.com/users/JavaLeb/gists{/gist_id}","starred_url":"https://api.github.com/users/JavaLeb/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JavaLeb/subscriptions","organizations_url":"https://api.github.com/users/JavaLeb/orgs","repos_url":"https://api.github.com/users/JavaLeb/repos","events_url":"https://api.github.com/users/JavaLeb/events{/privacy}","received_events_url":"https://api.github.com/users/JavaLeb/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-04-24T04:34:40Z","updated_at":"2020-05-12T15:01:57Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"哥们，有个问题请教下。我看代码中的embedding和我理解的有偏差。我的理解是这样，比如对于输入“我爱你”，第一步分词，假设得到三个词“我”\"爱\"“你”，然后对每个词采用one-hot编码，得到三个向量，每个向量维数xt（1,20000），20000是词典大小。然后三个向量作为encoder阶段的t=1,t=2,t=3的输入，首先经过embedding，假设embedding将维数变为128，实际embedding是一个20000*128的矩阵W，生成Wxt 为(1,128)，这样才得到一个低维的实数向量。\r\n\r\n而代码中，embedding初始化如下：\r\nself.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n如下调用：\r\nx = self.embedding(x)\r\n按照代码数据预处理，x是(128,20)维的，120是批次维度，20是一句话coding之后的向量，最后x输出(128,20,128)，vocab_size设置的是20000，好像没用到\r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/zhaoyingjun/chatbot/issues/84/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/zhaoyingjun/chatbot/issues/84/timeline","performed_via_github_app":null,"state_reason":null}