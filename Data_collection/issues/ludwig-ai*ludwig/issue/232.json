{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/232","repository_url":"https://api.github.com/repos/ludwig-ai/ludwig","labels_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/232/labels{/name}","comments_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/232/comments","events_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/232/events","html_url":"https://github.com/ludwig-ai/ludwig/issues/232","id":422816435,"node_id":"MDU6SXNzdWU0MjI4MTY0MzU=","number":232,"title":"most_common_characters text preprocessing parameter doesn't affect anything","user":{"login":"gobzer","id":12876046,"node_id":"MDQ6VXNlcjEyODc2MDQ2","avatar_url":"https://avatars.githubusercontent.com/u/12876046?v=4","gravatar_id":"","url":"https://api.github.com/users/gobzer","html_url":"https://github.com/gobzer","followers_url":"https://api.github.com/users/gobzer/followers","following_url":"https://api.github.com/users/gobzer/following{/other_user}","gists_url":"https://api.github.com/users/gobzer/gists{/gist_id}","starred_url":"https://api.github.com/users/gobzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gobzer/subscriptions","organizations_url":"https://api.github.com/users/gobzer/orgs","repos_url":"https://api.github.com/users/gobzer/repos","events_url":"https://api.github.com/users/gobzer/events{/privacy}","received_events_url":"https://api.github.com/users/gobzer/received_events","type":"User","site_admin":false},"labels":[{"id":1174068769,"node_id":"MDU6TGFiZWwxMTc0MDY4NzY5","url":"https://api.github.com/repos/ludwig-ai/ludwig/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2019-03-19T16:00:17Z","updated_at":"2019-03-20T20:08:17Z","closed_at":"2019-03-20T20:08:17Z","author_association":"NONE","active_lock_reason":null,"body":"Text feature preprocessing parameter `most_common_characters` doesn't seem to work as described in user manual:\r\nhttps://uber.github.io/ludwig/user_guide/#text-features-preprocessing\r\n\r\n**example_data.csv**\r\n```\r\nsometext,cat\r\n\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_.,`!@#$%^&*()<>-+\",0\r\n\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_.,`!@#$%^&*()<>-+\",1\r\n```\r\n\r\n**example_model.yaml**\r\n```\r\ninput_features:\r\n    -\r\n        name: sometext\r\n        type: text\r\n        level: char\r\n        preprocessing:\r\n            lowercase: false\r\n            most_common_characters: 75\r\n\r\noutput_features:\r\n    -\r\n        name: cat\r\n        type: category\r\n\r\npreprocessing:\r\n    text:\r\n        lowercase: false\r\n        most_common_characters: 75\r\n\r\ntraining:\r\n    epochs: 1\r\n\r\n```\r\n\r\n`ludwig experiment -mdf example_model.yaml --data_csv example_data.csv`\r\n\r\nvocabulary at **example_data.json** remains 70 chars, while I expect 75\r\n\r\nI found that `most_common_characters` doesn't seem to be used at all, but the code uses `char_most_common` instead:\r\nhttps://github.com/uber/ludwig/blob/8c31e59343a5da52955c1024f71eb9a3862a0cf7/ludwig/features/text_feature.py#L45\r\n\r\n`char_most_common` seems to work, but if you'll increase it to like 130:\r\n**example_data2.csv**\r\n```\r\nsometext,cat\r\n\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_.,`!@#$%^&*()<>-+абвгдеёжзийклмнопрстуфхцчшэюяАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧЩЬЪЭЮЯ\",0\r\n\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_.,`!@#$%^&*()<>-+абвгдеёжзийклмнопрстуфхцчшэюяАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧЩЬЪЭЮЯ\",1\r\n```\r\n**example_model2.yaml**\r\n```\r\ninput_features:\r\n    -\r\n        name: sometext\r\n        type: text\r\n        level: char\r\n        preprocessing:\r\n            lowercase: false\r\n            char_most_common: 130\r\n\r\noutput_features:\r\n    -\r\n        name: cat\r\n        type: category\r\n\r\npreprocessing:\r\n    text:\r\n        lowercase: false\r\n        char_most_common: 130\r\n\r\ntraining:\r\n    epochs: 1\r\n```\r\nand run:\r\n`ludwig experiment -mdf example_model2.yaml --data_csv example_data2.csv`\r\nYou'll get an InvalidArgumentError (attached)\r\n[char_most_common_130_error_output.txt](https://github.com/uber/ludwig/files/2984272/char_most_common_130_error_output.txt)\r\n\r\nWell, I need to increase vocabulary because my data consists of bi-lingual textual data","closed_by":{"login":"w4nderlust","id":349256,"node_id":"MDQ6VXNlcjM0OTI1Ng==","avatar_url":"https://avatars.githubusercontent.com/u/349256?v=4","gravatar_id":"","url":"https://api.github.com/users/w4nderlust","html_url":"https://github.com/w4nderlust","followers_url":"https://api.github.com/users/w4nderlust/followers","following_url":"https://api.github.com/users/w4nderlust/following{/other_user}","gists_url":"https://api.github.com/users/w4nderlust/gists{/gist_id}","starred_url":"https://api.github.com/users/w4nderlust/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/w4nderlust/subscriptions","organizations_url":"https://api.github.com/users/w4nderlust/orgs","repos_url":"https://api.github.com/users/w4nderlust/repos","events_url":"https://api.github.com/users/w4nderlust/events{/privacy}","received_events_url":"https://api.github.com/users/w4nderlust/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/232/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/232/timeline","performed_via_github_app":null,"state_reason":"completed"}