{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1204","repository_url":"https://api.github.com/repos/ludwig-ai/ludwig","labels_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1204/labels{/name}","comments_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1204/comments","events_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1204/events","html_url":"https://github.com/ludwig-ai/ludwig/issues/1204","id":917328231,"node_id":"MDU6SXNzdWU5MTczMjgyMzE=","number":1204,"title":"<PAD> is not used as the padding token when tagger decoder is used","user":{"login":"farazk86","id":33456896,"node_id":"MDQ6VXNlcjMzNDU2ODk2","avatar_url":"https://avatars.githubusercontent.com/u/33456896?v=4","gravatar_id":"","url":"https://api.github.com/users/farazk86","html_url":"https://github.com/farazk86","followers_url":"https://api.github.com/users/farazk86/followers","following_url":"https://api.github.com/users/farazk86/following{/other_user}","gists_url":"https://api.github.com/users/farazk86/gists{/gist_id}","starred_url":"https://api.github.com/users/farazk86/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/farazk86/subscriptions","organizations_url":"https://api.github.com/users/farazk86/orgs","repos_url":"https://api.github.com/users/farazk86/repos","events_url":"https://api.github.com/users/farazk86/events{/privacy}","received_events_url":"https://api.github.com/users/farazk86/received_events","type":"User","site_admin":false},"labels":[{"id":1174068775,"node_id":"MDU6TGFiZWwxMTc0MDY4Nzc1","url":"https://api.github.com/repos/ludwig-ai/ludwig/labels/waiting%20for%20answer","name":"waiting for answer","color":"fff36b","default":false,"description":"Further information is requested"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2021-06-10T13:09:57Z","updated_at":"2022-07-28T21:00:18Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\nWhen a ``generator`` decoder is used then the predicted output contains the ``<PAD>`` keywords which can be easily removed. But when a ``tagger`` decoder is used, a character from the input string is used as the pad token and it is really difficult to differentiate between the actual data and the padded tokens.\r\n\r\nDue to https://github.com/ludwig-ai/ludwig/issues/1130 I cannot use the latest version have to use version ``0.2.2.8`` which works without giving the error ``0.3.3`` gives. \r\n\r\nBelow is my ``model_definition.yaml`` file:\r\n\r\n```yaml\r\ntraining:\r\n    epochs: 50\r\n    early_stop: 10\r\n    batch_size: 128\r\n\r\ninput_features:\r\n    -\r\n        name: column2\r\n        type: text\r\n        level: word\r\n        encoder: rnn\r\n        cell_type: lstm\r\n        num_layers: 4\r\n        reduce_output: null\r\n        preprocessing:\r\n            word_tokenizer: space\r\n            padding_symbol: <PAD>\r\n\r\noutput_features:\r\n    -\r\n        name: column1\r\n        type: text\r\n        level: word\r\n        decoder: tagger\r\n        cell_type: lstm\r\n        loss:\r\n            type: sampled_softmax_cross_entropy\r\n```\r\nA small subset of my training dataset:\r\n```\r\ncolumn1,column2\r\nk k klk k hjkj hg k kg h k jlk k kj kg hk k k k k k k k klk kjh jkj hg ghk kj kh khgh hg,N S SHL S LHHL LL H SL H H LHL S SL HL HH S S S S S S S SHL SLL HHL LL SHH SL HL HLLH SL\r\nhk lk kh klk l lmlk lml mn m klm mn m ml lj kl klk kjhj jh h h h klm l lm l l l l lk lmkl lkk hjh h h klk kj k klm mlkj kl ml lk lk m lk jkjh jh k k hkh hg hk lm kj gh hg hjk jh,NH HL SL HHL H SHLL HHL HH L LHH SH L SL SL HH LHL SLLH SL S S S HHH L SH L S S S SL HHLH SLS LHL S S HHL SL H SHH SLLL HH HL SL HL H LL LHLL HL H S LHL SL HH HH LL LH SL HHH LL\r\nkj klkjkjh ghg hj j j jh jk hj ghjh hg g fg g g g hjhg hjh gf gh hkjklkjh hjhg hg,NL HHLLHLL LHL HH S S SL HH LH LHHL SL S LH S S S HHLL HHL LL HH SHLHHLLL SHLL HL\r\ng j k l k h k k g g g k k kj g hk k kj h kj h g g,N H H H L L H S L S S H S SL L HH S SL L HL L L S\r\nhkj k k k k kkk kh kl kmlkjk kj h hl l l lk kmlm jlkk j hl l l lk k k kmlm k k k kmlk k k k k kml k kkk hjkjhj jh jkl ljl lmlkj kjhg hg kk hk h kkkh jkl lmlk lkj,NHL H S S S SSS SL HH LHLLLH SL L SH S S SL SHLH LHLS L LH S S SL S S SHLH L S S SHLL S S S S SHL L SSS LHHLLH SL HHH SLH SHLLL HLLL HL HS LH L HSSL HHH SHLL HLL\r\ne e e e de dcded edb cb dc de dc bcdc cb c ac c c bcdcb d dededc bc dcbc ba,N S S S LH LLHHL HLL HL HL HH LL LHHL SL H LH S S LHHLL H SHLHLL LH HLLH LL\r\ng j k l l l k h l k j g h g f gh h k k jk h h g g,N H H H S S L L H L L L H L L HH S H S LH L S L S\r\nf fedf d dfe fg g g ggf ed df ef d dhj h hgf g f efg fe de dd c ed d cd d df ghgfg e,N SLLH L SHL HH S S SSL LL SH LH L SHH L SLL H L LHH LL LH LS L HL S LH S SH HHLLH L\r\nd fgh g g g g gh g g g ge g fgh fe dfc de fefed dc f ghg g gh g g gh g ghkjh jkjh g ghjhgh hg h gf g h kl kjkl lk h gf hkj klk kjh jh hg hg gh g g g fgh fe dfc de fefed g ghgf gh g ghkjh jkjh ghjhgh hg,N HHH L S S S SH L S S SL H LHH LL LHL HH HLHLL SL H HHL S SH L S SH L SHHLL HHLL L SHHLLH SL H LL H H HH LLHH SL L LL HHL HHL SLL HL SL HL SH L S S LHH LL LHL HH HLHLL H SHLL HH L SHHLL HHLL LHHLLH SL\r\n```\r\nmy train command:\r\n```\r\nludwig train --experiment_name tagger_model --data_csv training_file.csv --model_definition_file model_definition.yaml --output_directory results\r\n```\r\nand my test command:\r\n```\r\nludwig test --data_csv small_test.csv --model_path results\\\\tagger_model_run\\\\model --output_directory results\\\\prediction\\\\tagger_model_run\r\n```\r\n\r\nThe predicted result from the above is:\r\n```\r\nk,g,h,kl,l,k,l,m,l,k,l,l,j,l,j,k,hg,hg,fg,hk,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h\r\n\r\ng,j,k,lm,l,mn,m,l,k,lm,l,l,kl,kj,hg,hg,f,h,kh,j,h,g,g,g,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h\r\n\r\nf,f,f,e,g,h,f,fe,dc,c,f,f,f,f,e,g,h,h,hg,gf,f,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h\r\n\r\nghk,h,gf,gh,g,g,k,k,jh,k,l,lm,lm,kj,lm,h,jkl,k,j,kj,h,gf,f,g,g,g,gh,g,fe,def,fe,f,fg,gf,fe,de,d,d,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h,h\r\n```\r\nAs can be seen the character ``h`` is used as pad here..\r\n\r\nBut if I use the ``generator`` decoder using the below model:\r\n\r\n ```yaml\r\ntraining:\r\n    epochs: 50\r\n    early_stop: 30\r\n    batch_size: 128\r\n\r\ninput_features:\r\n    -\r\n        name: column2\r\n        type: text\r\n        level: word\r\n        encoder: rnn\r\n        cell_type: lstm\r\n        num_layers: 4\r\n        reduce_output: null\r\n        preprocessing:\r\n            word_tokenizer: space\r\n            padding_symbol: <PAD>\r\n\r\noutput_features:\r\n    -\r\n        name: column1\r\n        type: text\r\n        level: word\r\n        decoder: generator\r\n        attention: bahdanau\r\n        cell_type: lstm\r\n        loss:\r\n            type: sampled_softmax_cross_entropy\r\n```\r\nthen the predicted output uses the correct ``<PAD>`` token as can be seen from the generated output.\r\n```\r\nk,g,h,kl,l,k,l,m,l,k,l,l,h,l,j,k,hg,hg,fg,hk,h,h,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>\r\n\r\ng,j,k,lm,l,mn,m,k,lm,m,l,l,l,j,l,j,k,hg,f,hk,kj,h,g,g,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>\r\n\r\nf,f,f,e,g,h,f,fe,dc,c,f,f,f,f,e,g,h,h,hg,gf,f,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>\r\n\r\nghk,h,gf,gh,g,g,h,klm,l,l,k,lm,l,kj,hk,k,k,k,l,k,lm,l,kj,klk,h,h,h,h,k,l,k,jk,lk,h,gf,gh,h,g,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>,<PAD>\r\n```\r\n\r\n\r\n\r\n**Environment (please complete the following information):**\r\n - OS: Windows 10\r\n- Python version: 3.6.8\r\n- Ludwig version: 0.2.2.8\r\n","closed_by":{"login":"connor-mccorm","id":97468934,"node_id":"U_kgDOBc9CBg","avatar_url":"https://avatars.githubusercontent.com/u/97468934?v=4","gravatar_id":"","url":"https://api.github.com/users/connor-mccorm","html_url":"https://github.com/connor-mccorm","followers_url":"https://api.github.com/users/connor-mccorm/followers","following_url":"https://api.github.com/users/connor-mccorm/following{/other_user}","gists_url":"https://api.github.com/users/connor-mccorm/gists{/gist_id}","starred_url":"https://api.github.com/users/connor-mccorm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/connor-mccorm/subscriptions","organizations_url":"https://api.github.com/users/connor-mccorm/orgs","repos_url":"https://api.github.com/users/connor-mccorm/repos","events_url":"https://api.github.com/users/connor-mccorm/events{/privacy}","received_events_url":"https://api.github.com/users/connor-mccorm/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1204/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1204/timeline","performed_via_github_app":null,"state_reason":"reopened"}