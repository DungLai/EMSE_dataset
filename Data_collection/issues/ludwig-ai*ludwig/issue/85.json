{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/85","repository_url":"https://api.github.com/repos/ludwig-ai/ludwig","labels_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/85/labels{/name}","comments_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/85/comments","events_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/85/events","html_url":"https://github.com/ludwig-ai/ludwig/issues/85","id":410464553,"node_id":"MDU6SXNzdWU0MTA0NjQ1NTM=","number":85,"title":"KeyError: 'text'","user":{"login":"loretoparisi","id":163333,"node_id":"MDQ6VXNlcjE2MzMzMw==","avatar_url":"https://avatars.githubusercontent.com/u/163333?v=4","gravatar_id":"","url":"https://api.github.com/users/loretoparisi","html_url":"https://github.com/loretoparisi","followers_url":"https://api.github.com/users/loretoparisi/followers","following_url":"https://api.github.com/users/loretoparisi/following{/other_user}","gists_url":"https://api.github.com/users/loretoparisi/gists{/gist_id}","starred_url":"https://api.github.com/users/loretoparisi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/loretoparisi/subscriptions","organizations_url":"https://api.github.com/users/loretoparisi/orgs","repos_url":"https://api.github.com/users/loretoparisi/repos","events_url":"https://api.github.com/users/loretoparisi/events{/privacy}","received_events_url":"https://api.github.com/users/loretoparisi/received_events","type":"User","site_admin":false},"labels":[{"id":1174068775,"node_id":"MDU6TGFiZWwxMTc0MDY4Nzc1","url":"https://api.github.com/repos/ludwig-ai/ludwig/labels/waiting%20for%20answer","name":"waiting for answer","color":"fff36b","default":false,"description":"Further information is requested"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":9,"created_at":"2019-02-14T19:52:10Z","updated_at":"2019-07-24T20:03:10Z","closed_at":"2019-02-15T02:28:56Z","author_association":"NONE","active_lock_reason":null,"body":"Hello,\r\nmy train csv file looks like\r\n\r\n```sh\r\nmbploreto:script loretoparisi$ head -n2 /root/spam_dataset.csv \r\nlabel\ttext\r\nHAM\twaiting waiting waiting waiting solitude stands by the window as someone said i tried hard to find you i found fake promises instead the thought behind to join the thought before i thought i was blind sometimes i feel i feel the way to live i thought i had strength to overcome these walls i thought i was wonderful memories keep together things now would you like to know how it feels to be always stuck in the past without any rest the thought behind to join the thought before i thought i was blind\r\nSPAM\tplease every body click cross\r\n```\r\n\r\nso I have my configuration as string \r\n\r\n`\"{input_features: [{name: text, type: text}], output_features: [{name: label, type: category}]}\"`\r\n\r\nand I start training then:\r\n\r\n```sh\r\nludwig train --data_csv /root/spam_dataset.csv --model_definition \"{input_features: [{name: text, type: text}], output_features: [{name: label, type: category}]}\"\r\n```\r\n\r\nSuddenly I get that error about the `text` field:\r\n\r\n```sh\r\n _         _        _      \r\n| |_  _ __| |_ __ _(_)__ _ \r\n| | || / _` \\ V  V / / _` |\r\n|_|\\_,_\\__,_|\\_/\\_/|_\\__, |\r\n                     |___/ \r\nludwig v0.1.0 - Train\r\n\r\nExperiment name: experiment\r\nModel name: run\r\nOutput path: results/experiment_run_1\r\n\r\n\r\nludwig_version: '0.1.0'\r\ncommand: ('ludwig train '\r\n '--data_csv /root/spam_dataset.csv --model_definition {input_features: '\r\n '[{name: text, type: text}], output_features: [{name: label, type: '\r\n 'category}]}')\r\ncommit_hash: '98b82b3f56c0'\r\ndataset_type: '/root/spam_dataset.csv'\r\nmodel_definition: {   'combiner': {'type': 'concat'},\r\n    'input_features': [   {   'encoder': 'parallel_cnn',\r\n                              'level': 'word',\r\n                              'name': 'text',\r\n                              'tied_weights': None,\r\n                              'type': 'text'}],\r\n    'output_features': [   {   'dependencies': [],\r\n                               'loss': {   'class_distance_temperature': 0,\r\n                                           'class_weights': 1,\r\n                                           'confidence_penalty': 0,\r\n                                           'distortion': 1,\r\n                                           'labels_smoothing': 0,\r\n                                           'negative_samples': 0,\r\n                                           'robust_lambda': 0,\r\n                                           'sampler': None,\r\n                                           'type': 'softmax_cross_entropy',\r\n                                           'unique': False,\r\n                                           'weight': 1},\r\n                               'name': 'label',\r\n                               'reduce_dependencies': 'sum',\r\n                               'reduce_input': 'sum',\r\n                               'top_k': 3,\r\n                               'type': 'category'}],\r\n    'preprocessing': {   'bag': {   'fill_value': '',\r\n                                    'format': 'space',\r\n                                    'lowercase': 10000,\r\n                                    'missing_value_strategy': 'fill_with_const',\r\n                                    'most_common': False},\r\n                         'binary': {   'fill_value': 0,\r\n                                       'missing_value_strategy': 'fill_with_const'},\r\n                         'category': {   'fill_value': '<UNK>',\r\n                                         'lowercase': False,\r\n                                         'missing_value_strategy': 'fill_with_const',\r\n                                         'most_common': 10000},\r\n                         'force_split': False,\r\n                         'image': {'missing_value_strategy': 'backfill'},\r\n                         'numerical': {   'fill_value': 0,\r\n                                          'missing_value_strategy': 'fill_with_const'},\r\n                         'sequence': {   'fill_value': '',\r\n                                         'format': 'space',\r\n                                         'lowercase': False,\r\n                                         'missing_value_strategy': 'fill_with_const',\r\n                                         'most_common': 20000,\r\n                                         'padding': 'right',\r\n                                         'padding_symbol': '<PAD>',\r\n                                         'sequence_length_limit': 256,\r\n                                         'unknown_symbol': '<UNK>'},\r\n                         'set': {   'fill_value': '',\r\n                                    'format': 'space',\r\n                                    'lowercase': False,\r\n                                    'missing_value_strategy': 'fill_with_const',\r\n                                    'most_common': 10000},\r\n                         'split_probabilities': (0.7, 0.1, 0.2),\r\n                         'stratify': None,\r\n                         'text': {   'char_format': 'characters',\r\n                                     'char_most_common': 70,\r\n                                     'char_sequence_length_limit': 1024,\r\n                                     'fill_value': '',\r\n                                     'lowercase': True,\r\n                                     'missing_value_strategy': 'fill_with_const',\r\n                                     'padding': 'right',\r\n                                     'padding_symbol': '<PAD>',\r\n                                     'unknown_symbol': '<UNK>',\r\n                                     'word_format': 'space_punct',\r\n                                     'word_most_common': 20000,\r\n                                     'word_sequence_length_limit': 256},\r\n                         'timeseries': {   'fill_value': '',\r\n                                           'format': 'space',\r\n                                           'missing_value_strategy': 'fill_with_const',\r\n                                           'padding': 'right',\r\n                                           'padding_value': 0,\r\n                                           'timeseries_length_limit': 256}},\r\n    'training': {   'batch_size': 128,\r\n                    'bucketing_field': None,\r\n                    'decay': False,\r\n                    'decay_rate': 0.96,\r\n                    'decay_steps': 10000,\r\n                    'dropout_rate': 0.0,\r\n                    'early_stop': 3,\r\n                    'epochs': 200,\r\n                    'gradient_clipping': None,\r\n                    'increase_batch_size_on_plateau': 0,\r\n                    'increase_batch_size_on_plateau_max': 512,\r\n                    'increase_batch_size_on_plateau_patience': 5,\r\n                    'increase_batch_size_on_plateau_rate': 2,\r\n                    'learning_rate': 0.001,\r\n                    'learning_rate_warmup_epochs': 5,\r\n                    'optimizer': {   'beta1': 0.9,\r\n                                     'beta2': 0.999,\r\n                                     'epsilon': 1e-08,\r\n                                     'type': 'adam'},\r\n                    'reduce_learning_rate_on_plateau': 0,\r\n                    'reduce_learning_rate_on_plateau_patience': 5,\r\n                    'reduce_learning_rate_on_plateau_rate': 0.5,\r\n                    'regularization_lambda': 0,\r\n                    'regularizer': 'l2',\r\n                    'staircase': False,\r\n                    'validation_field': 'combined',\r\n                    'validation_measure': 'loss'}}\r\n\r\n\r\nUsing full raw csv, no hdf5 and json file with the same name have been found\r\nBuilding dataset (it may take a while)\r\nTraceback (most recent call last):\r\n  File \"/Users/loretoparisi/Documents/Projects/AI/ludwig/venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 2656, in get_loc\r\n    return self._engine.get_loc(key)\r\n  File \"pandas/_libs/index.pyx\", line 108, in pandas._libs.index.IndexEngine.get_loc\r\n  File \"pandas/_libs/index.pyx\", line 132, in pandas._libs.index.IndexEngine.get_loc\r\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1601, in pandas._libs.hashtable.PyObjectHashTable.get_item\r\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1608, in pandas._libs.hashtable.PyObjectHashTable.get_item\r\nKeyError: 'text'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"ludwig\", line 11, in <module>\r\n    load_entry_point('ludwig==0.1.0', 'console_scripts', 'ludwig')()\r\n  File \"/Users/loretoparisi/Documents/Projects/AI/ludwig/venv/lib/python3.6/site-packages/ludwig-0.1.0-py3.6.egg/ludwig/cli.py\", line 86, in main\r\n  File \"/Users/loretoparisi/Documents/Projects/AI/ludwig/venv/lib/python3.6/site-packages/ludwig-0.1.0-py3.6.egg/ludwig/cli.py\", line 64, in __init__\r\n  File \"/Users/loretoparisi/Documents/Projects/AI/ludwig/venv/lib/python3.6/site-packages/ludwig-0.1.0-py3.6.egg/ludwig/cli.py\", line 70, in train\r\n  File \"/Users/loretoparisi/Documents/Projects/AI/ludwig/venv/lib/python3.6/site-packages/ludwig-0.1.0-py3.6.egg/ludwig/train.py\", line 663, in cli\r\n  File \"/Users/loretoparisi/Documents/Projects/AI/ludwig/venv/lib/python3.6/site-packages/ludwig-0.1.0-py3.6.egg/ludwig/train.py\", line 224, in full_train\r\n  File \"/Users/loretoparisi/Documents/Projects/AI/ludwig/venv/lib/python3.6/site-packages/ludwig-0.1.0-py3.6.egg/ludwig/data/preprocessing.py\", line 457, in preprocess_for_training\r\n  File \"/Users/loretoparisi/Documents/Projects/AI/ludwig/venv/lib/python3.6/site-packages/ludwig-0.1.0-py3.6.egg/ludwig/data/preprocessing.py\", line 62, in build_dataset\r\n  File \"/Users/loretoparisi/Documents/Projects/AI/ludwig/venv/lib/python3.6/site-packages/ludwig-0.1.0-py3.6.egg/ludwig/data/preprocessing.py\", line 83, in build_dataset_df\r\n  File \"/Users/loretoparisi/Documents/Projects/AI/ludwig/venv/lib/python3.6/site-packages/ludwig-0.1.0-py3.6.egg/ludwig/data/preprocessing.py\", line 123, in build_metadata\r\n  File \"/Users/loretoparisi/Documents/Projects/AI/ludwig/venv/lib/python3.6/site-packages/pandas/core/frame.py\", line 2927, in __getitem__\r\n    indexer = self.columns.get_loc(key)\r\n  File \"/Users/loretoparisi/Documents/Projects/AI/ludwig/venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 2658, in get_loc\r\n    return self._engine.get_loc(self._maybe_cast_indexer(key))\r\n  File \"pandas/_libs/index.pyx\", line 108, in pandas._libs.index.IndexEngine.get_loc\r\n  File \"pandas/_libs/index.pyx\", line 132, in pandas._libs.index.IndexEngine.get_loc\r\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1601, in pandas._libs.hashtable.PyObjectHashTable.get_item\r\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1608, in pandas._libs.hashtable.PyObjectHashTable.get_item\r\nKeyError: 'text'\r\n```","closed_by":{"login":"w4nderlust","id":349256,"node_id":"MDQ6VXNlcjM0OTI1Ng==","avatar_url":"https://avatars.githubusercontent.com/u/349256?v=4","gravatar_id":"","url":"https://api.github.com/users/w4nderlust","html_url":"https://github.com/w4nderlust","followers_url":"https://api.github.com/users/w4nderlust/followers","following_url":"https://api.github.com/users/w4nderlust/following{/other_user}","gists_url":"https://api.github.com/users/w4nderlust/gists{/gist_id}","starred_url":"https://api.github.com/users/w4nderlust/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/w4nderlust/subscriptions","organizations_url":"https://api.github.com/users/w4nderlust/orgs","repos_url":"https://api.github.com/users/w4nderlust/repos","events_url":"https://api.github.com/users/w4nderlust/events{/privacy}","received_events_url":"https://api.github.com/users/w4nderlust/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/85/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/85/timeline","performed_via_github_app":null,"state_reason":"completed"}