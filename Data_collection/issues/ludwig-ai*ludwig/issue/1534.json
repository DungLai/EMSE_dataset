{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1534","repository_url":"https://api.github.com/repos/ludwig-ai/ludwig","labels_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1534/labels{/name}","comments_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1534/comments","events_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1534/events","html_url":"https://github.com/ludwig-ai/ludwig/issues/1534","id":1067035612,"node_id":"I_kwDOCbx2hs4_mavc","number":1534,"title":"Training on GPU throws \"Expected all tensors to be on the same device\" error","user":{"login":"smiralr","id":92856399,"node_id":"U_kgDOBYjgTw","avatar_url":"https://avatars.githubusercontent.com/u/92856399?v=4","gravatar_id":"","url":"https://api.github.com/users/smiralr","html_url":"https://github.com/smiralr","followers_url":"https://api.github.com/users/smiralr/followers","following_url":"https://api.github.com/users/smiralr/following{/other_user}","gists_url":"https://api.github.com/users/smiralr/gists{/gist_id}","starred_url":"https://api.github.com/users/smiralr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/smiralr/subscriptions","organizations_url":"https://api.github.com/users/smiralr/orgs","repos_url":"https://api.github.com/users/smiralr/repos","events_url":"https://api.github.com/users/smiralr/events{/privacy}","received_events_url":"https://api.github.com/users/smiralr/received_events","type":"User","site_admin":false},"labels":[{"id":1174068769,"node_id":"MDU6TGFiZWwxMTc0MDY4NzY5","url":"https://api.github.com/repos/ludwig-ai/ludwig/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":{"login":"ShreyaR","id":5787923,"node_id":"MDQ6VXNlcjU3ODc5MjM=","avatar_url":"https://avatars.githubusercontent.com/u/5787923?v=4","gravatar_id":"","url":"https://api.github.com/users/ShreyaR","html_url":"https://github.com/ShreyaR","followers_url":"https://api.github.com/users/ShreyaR/followers","following_url":"https://api.github.com/users/ShreyaR/following{/other_user}","gists_url":"https://api.github.com/users/ShreyaR/gists{/gist_id}","starred_url":"https://api.github.com/users/ShreyaR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ShreyaR/subscriptions","organizations_url":"https://api.github.com/users/ShreyaR/orgs","repos_url":"https://api.github.com/users/ShreyaR/repos","events_url":"https://api.github.com/users/ShreyaR/events{/privacy}","received_events_url":"https://api.github.com/users/ShreyaR/received_events","type":"User","site_admin":false},"assignees":[{"login":"ShreyaR","id":5787923,"node_id":"MDQ6VXNlcjU3ODc5MjM=","avatar_url":"https://avatars.githubusercontent.com/u/5787923?v=4","gravatar_id":"","url":"https://api.github.com/users/ShreyaR","html_url":"https://github.com/ShreyaR","followers_url":"https://api.github.com/users/ShreyaR/followers","following_url":"https://api.github.com/users/ShreyaR/following{/other_user}","gists_url":"https://api.github.com/users/ShreyaR/gists{/gist_id}","starred_url":"https://api.github.com/users/ShreyaR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ShreyaR/subscriptions","organizations_url":"https://api.github.com/users/ShreyaR/orgs","repos_url":"https://api.github.com/users/ShreyaR/repos","events_url":"https://api.github.com/users/ShreyaR/events{/privacy}","received_events_url":"https://api.github.com/users/ShreyaR/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2021-11-30T10:05:23Z","updated_at":"2022-01-12T18:29:20Z","closed_at":"2021-12-07T09:40:20Z","author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\nEnv: ludwigai/ludwig-gpu:master Docker container\r\non a GPU AWS Instance with all drivers working and GPU Accessible within the docker container\r\nAccording to documentation ludwigmodel takes gpus param as gpus=\"0\"\r\nAccording to documentation model.train takes gpus param as gpus=\"0\"\r\nException thrown:\r\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. spin up a ludwigai/ludwig-gpu:master Docker container with jupyter\r\n2. Intialize config data for parallel cnn + glove embeddings\r\n3. Declare and train model with :\r\nmodel = LudwigModel(model_definition,gpus=\"0\",logging_level=logging.DEBUG)\r\nparallel_cnn_glove_embeds_train_stats, _, _ = model.train(dataset=training_df,experiment_name=experiment_name, model_name=model_name, output_directory=output_directory, gpus=\"0\")\r\n\r\n**Expected behavior**\r\nTrain on gpu start\r\n\r\n**Environment (please complete the following information):**\r\n- Python 3.7.11 (default, Jul 27 2021, 14:32:16) \r\n[GCC 7.5.0] :: Anaconda, Inc. on linux\r\n- ludwigai/ludwig-gpu:master env\r\n\r\n**Additional context**\r\nStacktrace:\r\nExperiment name: ParallelCNN_GLOVE_1\r\nModel name: ParallelCNN_GloveEmbeddings\r\nOutput directory: models/results/ParallelCNN_GLOVE_1_ParallelCNN_GloveEmbeddings\r\n\r\n\r\nludwig_version: '0.5.dev0'\r\ncommand: ('/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py -f '\r\n '/root/.local/share/jupyter/runtime/kernel-65fbea1a-50d2-4c5f-932b-2895ea7abbc9.json')\r\nrandom_seed: 42\r\ndata_format: \"<class 'pandas.core.frame.DataFrame'>\"\r\nconfig: {   'combiner': {'type': 'concat'},\r\n    'input_features': [   {   'column': 'clean_title',\r\n                              'embedding_size': 300,\r\n                              'encoder': 'parallel_cnn',\r\n                              'level': 'word',\r\n                              'name': 'clean_title',\r\n                              'preprocessing': {   'word_vocab_file': '../embeddings/glove/glove.6B.300d.txt'},\r\n                              'pretrained_embeddings': '../embeddings/glove/glove.6B.300d.txt',\r\n                              'proc_column': 'clean_title_Um5Kye',\r\n                              'tied': None,\r\n                              'type': 'text'}],\r\n    'output_features': [   {   'column': 'category',\r\n                               'dependencies': [],\r\n                               'loss': {   'class_similarities_temperature': 0,\r\n                                           'class_weights': 1,\r\n                                           'confidence_penalty': 0,\r\n                                           'labels_smoothing': 0,\r\n                                           'robust_lambda': 0,\r\n                                           'type': 'softmax_cross_entropy',\r\n                                           'weight': 1},\r\n                               'name': 'category',\r\n                               'proc_column': 'category_mZFLky',\r\n                               'reduce_dependencies': 'sum',\r\n                               'reduce_input': 'sum',\r\n                               'top_k': 3,\r\n                               'type': 'category'}],\r\n    'preprocessing': {   'audio': {   'audio_feature': {'type': 'raw'},\r\n                                      'audio_file_length_limit_in_s': 7.5,\r\n                                      'in_memory': True,\r\n                                      'missing_value_strategy': 'backfill',\r\n                                      'norm': None,\r\n                                      'padding_value': 0},\r\n                         'bag': {   'fill_value': '<UNK>',\r\n                                    'lowercase': False,\r\n                                    'missing_value_strategy': 'fill_with_const',\r\n                                    'most_common': 10000,\r\n                                    'tokenizer': 'space'},\r\n                         'binary': {   'fill_value': 0,\r\n                                       'missing_value_strategy': 'fill_with_const'},\r\n                         'category': {   'fill_value': '<UNK>',\r\n                                         'lowercase': False,\r\n                                         'missing_value_strategy': 'fill_with_const',\r\n                                         'most_common': 10000},\r\n                         'date': {   'datetime_format': None,\r\n                                     'fill_value': '',\r\n                                     'missing_value_strategy': 'fill_with_const'},\r\n                         'force_split': True,\r\n                         'h3': {   'fill_value': 576495936675512319,\r\n                                   'missing_value_strategy': 'fill_with_const'},\r\n                         'image': {   'in_memory': True,\r\n                                      'infer_image_dimensions': True,\r\n                                      'infer_image_max_height': 256,\r\n                                      'infer_image_max_width': 256,\r\n                                      'infer_image_num_channels': True,\r\n                                      'infer_image_sample_size': 100,\r\n                                      'missing_value_strategy': 'backfill',\r\n                                      'num_processes': 1,\r\n                                      'resize_method': 'interpolate',\r\n                                      'scaling': 'pixel_normalization'},\r\n                         'numerical': {   'fill_value': 0,\r\n                                          'missing_value_strategy': 'fill_with_const',\r\n                                          'normalization': None},\r\n                         'sequence': {   'fill_value': '<UNK>',\r\n                                         'lowercase': False,\r\n                                         'missing_value_strategy': 'fill_with_const',\r\n                                         'most_common': 20000,\r\n                                         'padding': 'right',\r\n                                         'padding_symbol': '<PAD>',\r\n                                         'sequence_length_limit': 256,\r\n                                         'tokenizer': 'space',\r\n                                         'unknown_symbol': '<UNK>',\r\n                                         'vocab_file': None},\r\n                         'set': {   'fill_value': '<UNK>',\r\n                                    'lowercase': False,\r\n                                    'missing_value_strategy': 'fill_with_const',\r\n                                    'most_common': 10000,\r\n                                    'tokenizer': 'space'},\r\n                         'split_probabilities': [0.7, 0.1, 0.2],\r\n                         'stratify': 'category',\r\n                         'text': {   'char_most_common': 70,\r\n                                     'char_sequence_length_limit': 1024,\r\n                                     'char_tokenizer': 'characters',\r\n                                     'char_vocab_file': None,\r\n                                     'fill_value': '<UNK>',\r\n                                     'lowercase': True,\r\n                                     'missing_value_strategy': 'fill_with_const',\r\n                                     'padding': 'right',\r\n                                     'padding_symbol': '<PAD>',\r\n                                     'pretrained_model_name_or_path': None,\r\n                                     'unknown_symbol': '<UNK>',\r\n                                     'word_most_common': 20000,\r\n                                     'word_sequence_length_limit': 256,\r\n                                     'word_tokenizer': 'space_punct',\r\n                                     'word_vocab_file': None},\r\n                         'timeseries': {   'fill_value': '',\r\n                                           'missing_value_strategy': 'fill_with_const',\r\n                                           'padding': 'right',\r\n                                           'padding_value': 0,\r\n                                           'timeseries_length_limit': 256,\r\n                                           'tokenizer': 'space'},\r\n                         'vector': {   'fill_value': '',\r\n                                       'missing_value_strategy': 'fill_with_const'}},\r\n    'training': {   'batch_size': 128,\r\n                    'bucketing_field': None,\r\n                    'decay': True,\r\n                    'decay_rate': 0.96,\r\n                    'decay_steps': 10000,\r\n                    'early_stop': 5,\r\n                    'epochs': 12,\r\n                    'eval_batch_size': None,\r\n                    'gradient_clipping': None,\r\n                    'increase_batch_size_on_plateau': 0,\r\n                    'increase_batch_size_on_plateau_max': 512,\r\n                    'increase_batch_size_on_plateau_patience': 5,\r\n                    'increase_batch_size_on_plateau_rate': 2,\r\n                    'learning_rate': 0.001,\r\n                    'learning_rate_warmup_epochs': 1,\r\n                    'optimizer': {   'betas': (0.9, 0.999),\r\n                                     'eps': 1e-08,\r\n                                     'type': 'adam'},\r\n                    'reduce_learning_rate_on_plateau': 0,\r\n                    'reduce_learning_rate_on_plateau_patience': 5,\r\n                    'reduce_learning_rate_on_plateau_rate': 0.5,\r\n                    'regularization_lambda': 0,\r\n                    'regularization_type': 'l2',\r\n                    'staircase': False,\r\n                    'validation_field': 'category',\r\n                    'validation_metric': 'accuracy'}}\r\ntorch_version: '1.10.0'\r\n\r\n\r\nUsing full dataframe\r\nBuilding dataset (it may take a while)\r\ncast columns\r\nbuild metadata\r\nbuild data\r\nget split\r\nsplit on split column\r\ncache processed data\r\nWriting preprocessed training set cache\r\nWriting preprocessed test set cache\r\nWriting preprocessed validation set cache\r\nWriting train set metadata\r\ncreate training dataset\r\ncreate validation dataset\r\ncreate test dataset\r\nTraining set: 27445\r\nValidation set: 3838\r\nTest set: 7768\r\n\r\n╒═══════╕\r\n│ MODEL │\r\n╘═══════╛\r\n\r\nInput text feature clean_title\r\n ParallelCNN\r\n  EmbedSequence\r\n  Loading Glove format file ../embeddings/glove/glove.6B.300d.txt\r\n  400000 embeddings loaded\r\n  ParallelConv1D\r\n   parallel layer 0\r\n   Conv1d\r\n   ReLU\r\nParallelConv1D layer 0, input shape torch.Size([256, 300]), output shape torch.Size([256, 256])\r\n   parallel layer 1\r\n   Conv1d\r\n   ReLU\r\nParallelConv1D layer 1, input shape torch.Size([256, 300]), output shape torch.Size([256, 256])\r\n   parallel layer 2\r\n   Conv1d\r\n   ReLU\r\nParallelConv1D layer 2, input shape torch.Size([256, 300]), output shape torch.Size([256, 256])\r\n   parallel layer 3\r\n   Conv1d\r\n   ReLU\r\nParallelConv1D layer 3, input shape torch.Size([256, 300]), output shape torch.Size([256, 256])\r\n  FCStack\r\nCombiner concat\r\n ConcatCombiner\r\n  FCStack\r\nOutput category feature category\r\n output feature fully connected layers\r\n  FCStack\r\n Classifier\r\n  Dense\r\n\r\n╒══════════╕\r\n│ TRAINING │\r\n╘══════════╛\r\n\r\n\r\nEpoch  1\r\nTraining:   0%|                                                                                                                                     | 0/215 [00:00<?, ?it/s]\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n/tmp/ipykernel_12/4050990918.py in <module>\r\n      1 #training the model\r\n      2 model = LudwigModel(model_definition,gpus=\"0\",logging_level=logging.DEBUG)\r\n----> 3 parallel_cnn_glove_embeds_train_stats, _, _ = model.train(dataset=training_df,experiment_name=experiment_name, model_name=model_name, output_directory=output_directory, gpus=\"0\")\r\n\r\n/opt/conda/lib/python3.7/site-packages/ludwig/api.py in train(self, dataset, training_set, validation_set, test_set, training_set_metadata, data_format, experiment_name, model_name, model_resume_path, skip_save_training_description, skip_save_training_statistics, skip_save_model, skip_save_progress, skip_save_log, skip_save_processed_input, output_directory, random_seed, debug, **kwargs)\r\n    551                         validation_set=validation_set,\r\n    552                         test_set=test_set,\r\n--> 553                         save_path=model_dir,\r\n    554                     )\r\n    555 \r\n\r\n/opt/conda/lib/python3.7/site-packages/ludwig/models/trainer.py in train(self, model, training_set, validation_set, test_set, save_path, **kwargs)\r\n    888                         model,\r\n    889                         inputs,\r\n--> 890                         targets,\r\n    891                     )\r\n    892 \r\n\r\n/opt/conda/lib/python3.7/site-packages/ludwig/models/trainer.py in train_step(self, model, inputs, targets)\r\n    312 \r\n    313         # Obtain model predictions and loss\r\n--> 314         model_outputs = model((inputs, targets))\r\n    315         loss, all_losses = model.train_loss(\r\n    316             targets,\r\n\r\n/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\r\n   1100         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\r\n   1101                 or _global_forward_hooks or _global_forward_pre_hooks):\r\n-> 1102             return forward_call(*input, **kwargs)\r\n   1103         # Do not call functions when jit is used\r\n   1104         full_backward_hooks, non_full_backward_hooks = [], []\r\n\r\n/opt/conda/lib/python3.7/site-packages/ludwig/models/ecd.py in forward(self, inputs, mask)\r\n    138         for input_feature_name, input_values in inputs.items():\r\n    139             encoder = self.input_features[input_feature_name]\r\n--> 140             encoder_output = encoder(input_values)\r\n    141             encoder_outputs[input_feature_name] = encoder_output\r\n    142 \r\n\r\n/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\r\n   1100         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\r\n   1101                 or _global_forward_hooks or _global_forward_pre_hooks):\r\n-> 1102             return forward_call(*input, **kwargs)\r\n   1103         # Do not call functions when jit is used\r\n   1104         full_backward_hooks, non_full_backward_hooks = [], []\r\n\r\n/opt/conda/lib/python3.7/site-packages/ludwig/features/text_feature.py in forward(self, inputs, mask)\r\n    278         inputs_exp = inputs.type(torch.int32)\r\n    279         lengths = torch.sum(inputs_mask.type(torch.int32), dim=1)\r\n--> 280         encoder_output = self.encoder_obj(inputs_exp, mask=inputs_mask)\r\n    281         encoder_output[LENGTHS] = lengths\r\n    282 \r\n\r\n/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\r\n   1100         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\r\n   1101                 or _global_forward_hooks or _global_forward_pre_hooks):\r\n-> 1102             return forward_call(*input, **kwargs)\r\n   1103         # Do not call functions when jit is used\r\n   1104         full_backward_hooks, non_full_backward_hooks = [], []\r\n\r\n/opt/conda/lib/python3.7/site-packages/ludwig/encoders/sequence_encoders.py in forward(self, inputs, mask)\r\n    498         # ================ Embeddings ================\r\n    499         if self.should_embed:\r\n--> 500             embedded_sequence = self.embed_sequence(inputs, mask=mask)\r\n    501         else:\r\n    502             embedded_sequence = inputs\r\n\r\n/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\r\n   1100         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\r\n   1101                 or _global_forward_hooks or _global_forward_pre_hooks):\r\n-> 1102             return forward_call(*input, **kwargs)\r\n   1103         # Do not call functions when jit is used\r\n   1104         full_backward_hooks, non_full_backward_hooks = [], []\r\n\r\n/opt/conda/lib/python3.7/site-packages/ludwig/modules/embedding_modules.py in forward(self, inputs, mask)\r\n    417             )\r\n    418 \r\n--> 419         embedded = self.embeddings(inputs)\r\n    420         if self.dropout:\r\n    421             embedded = self.dropout(embedded)\r\n\r\n/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\r\n   1100         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\r\n   1101                 or _global_forward_hooks or _global_forward_pre_hooks):\r\n-> 1102             return forward_call(*input, **kwargs)\r\n   1103         # Do not call functions when jit is used\r\n   1104         full_backward_hooks, non_full_backward_hooks = [], []\r\n\r\n/opt/conda/lib/python3.7/site-packages/torch/nn/modules/sparse.py in forward(self, input)\r\n    158         return F.embedding(\r\n    159             input, self.weight, self.padding_idx, self.max_norm,\r\n--> 160             self.norm_type, self.scale_grad_by_freq, self.sparse)\r\n    161 \r\n    162     def extra_repr(self) -> str:\r\n\r\n/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py in embedding(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\r\n   2042         # remove once script supports set_grad_enabled\r\n   2043         _no_grad_embedding_renorm_(weight, input, max_norm, norm_type)\r\n-> 2044     return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\r\n   2045 \r\n   2046 \r\n\r\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)\r\n\r\n\r\n### **GPU Command outputs:**\r\n!nvidia-smi\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\r\n| N/A   25C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\n\r\n!/usr/local/cuda/bin/nvcc --version\r\n\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2021 NVIDIA Corporation\r\nBuilt on Mon_May__3_19:15:13_PDT_2021\r\nCuda compilation tools, release 11.3, V11.3.109\r\nBuild cuda_11.3.r11.3/compiler.29920130_0\r\n\r\n","closed_by":{"login":"ShreyaR","id":5787923,"node_id":"MDQ6VXNlcjU3ODc5MjM=","avatar_url":"https://avatars.githubusercontent.com/u/5787923?v=4","gravatar_id":"","url":"https://api.github.com/users/ShreyaR","html_url":"https://github.com/ShreyaR","followers_url":"https://api.github.com/users/ShreyaR/followers","following_url":"https://api.github.com/users/ShreyaR/following{/other_user}","gists_url":"https://api.github.com/users/ShreyaR/gists{/gist_id}","starred_url":"https://api.github.com/users/ShreyaR/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ShreyaR/subscriptions","organizations_url":"https://api.github.com/users/ShreyaR/orgs","repos_url":"https://api.github.com/users/ShreyaR/repos","events_url":"https://api.github.com/users/ShreyaR/events{/privacy}","received_events_url":"https://api.github.com/users/ShreyaR/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1534/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1534/timeline","performed_via_github_app":null,"state_reason":"completed"}