{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/589","repository_url":"https://api.github.com/repos/ludwig-ai/ludwig","labels_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/589/labels{/name}","comments_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/589/comments","events_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/589/events","html_url":"https://github.com/ludwig-ai/ludwig/issues/589","id":532630299,"node_id":"MDU6SXNzdWU1MzI2MzAyOTk=","number":589,"title":"One Cycle policy in Ludwig","user":{"login":"lucaventurini","id":2151065,"node_id":"MDQ6VXNlcjIxNTEwNjU=","avatar_url":"https://avatars.githubusercontent.com/u/2151065?v=4","gravatar_id":"","url":"https://api.github.com/users/lucaventurini","html_url":"https://github.com/lucaventurini","followers_url":"https://api.github.com/users/lucaventurini/followers","following_url":"https://api.github.com/users/lucaventurini/following{/other_user}","gists_url":"https://api.github.com/users/lucaventurini/gists{/gist_id}","starred_url":"https://api.github.com/users/lucaventurini/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lucaventurini/subscriptions","organizations_url":"https://api.github.com/users/lucaventurini/orgs","repos_url":"https://api.github.com/users/lucaventurini/repos","events_url":"https://api.github.com/users/lucaventurini/events{/privacy}","received_events_url":"https://api.github.com/users/lucaventurini/received_events","type":"User","site_admin":false},"labels":[{"id":1174068771,"node_id":"MDU6TGFiZWwxMTc0MDY4Nzcx","url":"https://api.github.com/repos/ludwig-ai/ludwig/labels/feature","name":"feature","color":"0377d6","default":false,"description":"New feature or request"},{"id":1174068772,"node_id":"MDU6TGFiZWwxMTc0MDY4Nzcy","url":"https://api.github.com/repos/ludwig-ai/ludwig/labels/help%20wanted","name":"help wanted","color":"ef87ff","default":true,"description":"Help from the community is welcome"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2019-12-04T11:41:09Z","updated_at":"2020-03-05T21:20:58Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi @w4nderlust ,\r\n\r\nis there any plan to implement Smith's One Cycle policy in the learning rate scheduler? (https://arxiv.org/pdf/1803.09820.pdf)\r\n\r\nI see that currently the default policy is to anneal the LR (or the batch size). The One Cycle scheduler has shown very good results since it was introduced, and it seems much faster to converge than other schedulers.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/589/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/589/timeline","performed_via_github_app":null,"state_reason":null}