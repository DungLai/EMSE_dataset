{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/2474","repository_url":"https://api.github.com/repos/ludwig-ai/ludwig","labels_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/2474/labels{/name}","comments_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/2474/comments","events_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/2474/events","html_url":"https://github.com/ludwig-ai/ludwig/issues/2474","id":1369063590,"node_id":"I_kwDOCbx2hs5RmkCm","number":2474,"title":"Memory leak with resnet image encoder","user":{"login":"jimthompson5802","id":1425269,"node_id":"MDQ6VXNlcjE0MjUyNjk=","avatar_url":"https://avatars.githubusercontent.com/u/1425269?v=4","gravatar_id":"","url":"https://api.github.com/users/jimthompson5802","html_url":"https://github.com/jimthompson5802","followers_url":"https://api.github.com/users/jimthompson5802/followers","following_url":"https://api.github.com/users/jimthompson5802/following{/other_user}","gists_url":"https://api.github.com/users/jimthompson5802/gists{/gist_id}","starred_url":"https://api.github.com/users/jimthompson5802/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimthompson5802/subscriptions","organizations_url":"https://api.github.com/users/jimthompson5802/orgs","repos_url":"https://api.github.com/users/jimthompson5802/repos","events_url":"https://api.github.com/users/jimthompson5802/events{/privacy}","received_events_url":"https://api.github.com/users/jimthompson5802/received_events","type":"User","site_admin":false},"labels":[{"id":1434966350,"node_id":"MDU6TGFiZWwxNDM0OTY2MzUw","url":"https://api.github.com/repos/ludwig-ai/ludwig/labels/looking%20into%20it","name":"looking into it","color":"ffa54f","default":false,"description":""}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2022-09-11T21:05:28Z","updated_at":"2022-09-18T03:22:16Z","closed_at":"2022-09-18T03:22:16Z","author_association":"COLLABORATOR","active_lock_reason":null,"body":"**Describe the bug**\r\nWhile testing using synthetic image data, encountered this error during `model.train()` with Ludwig ResNet image encoder.\r\n\r\n```\r\n╒══════════╕\r\n│ TRAINING │\r\n╘══════════╛\r\n\r\nTraining for 2 step(s), approximately 2 epoch(s).\r\nEarly stopping policy: 5 round(s) of evaluation, or 5 step(s), approximately 5 epoch(s).\r\n\r\nStarting with step 0, epoch: 0\r\nTraining:   0%|          | 0/2 [00:00<?, ?it/s]\r\nProcess finished with exit code 137 (interrupted by signal 9: SIGKILL)\r\n\r\n```\r\n\r\nThe error occurs in a 12GB Docker container.  The error occurs ONLY with the `resnet` encoder.  All the other encoders (`stacked_cnn`, `map_mixer` and `vit`) WORK as expected.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n\r\nRun this reproducible example:\r\n```\r\nimport logging\r\nimport os\r\nimport shutil\r\n\r\nfrom ludwig.api import LudwigModel\r\nfrom ludwig.data.dataset_synthesizer import cli_synthesize_dataset\r\n\r\nFEATURES_LIST = [\r\n    {\"name\": \"category\", \"type\": \"category\"},\r\n    {\r\n        \"name\": \"image\", \"type\": \"image\",\r\n        \"destination_folder\": os.path.join(os.getcwd(), \"data2/images\"),\r\n        \"preprocessing\": {\"height\": 224, \"width\": 224, \"num_channels\": 3}\r\n    }\r\n]\r\n\r\nCONFIG = {\r\n    \"input_features\": [\r\n        {\r\n            \"name\": \"image\", \"type\": \"image\",\r\n            \"encoder\": {\r\n                \"type\": \"resnet\",   \r\n            },\r\n        }\r\n    ],\r\n    \"output_features\": [\r\n        {\r\n            \"name\": \"category\", \"type\": \"category\",\r\n        }\r\n    ],\r\n    \"trainer\": {\"epochs\": 2, }\r\n}\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    shutil.rmtree(\"data2\", ignore_errors=True)\r\n    os.makedirs(\"data2\", exist_ok=True)\r\n    cli_synthesize_dataset(40, FEATURES_LIST, \"data2/syn_train.csv\")\r\n\r\n    model = LudwigModel(CONFIG, logging_level=logging.INFO)\r\n    model.train(dataset=\"data2/syn_train.csv\")\r\n\r\n```\r\n\r\n**Expected behavior**\r\nSuccessful running of the `model.train()` method.\r\n\r\n**Screenshots**\r\nHere is a screen shot of the output from `docker stats` for the container just before the out of memory error occurs\r\n![Screen Shot 2022-09-11 at 16 48 28](https://user-images.githubusercontent.com/1425269/189548573-1bf55e98-6d71-4619-b610-975f7ace6c37.png)\r\n\r\nAs the program is running, I can see `MEM USAGE` increase until the Error 137 is reported.\r\n\r\n**Environment (please complete the following information):**\r\n\r\n- OS: MacOS 12.5.1 with Docker Desktop 4.9.1 (81317)\r\n- Version \r\n- Python version 3.8\r\n- Ludwig version: 0.6.dev on the `master` branch\r\n\r\n**Additional context**\r\nHere is full log file\r\n\r\n```\r\n77567a00d862:python -u /opt/project/sandbox/vision_models/mwe_dask_backend_issue1.py\r\nNumExpr defaulting to 8 threads.\r\n\r\n╒════════════════════════╕\r\n│ EXPERIMENT DESCRIPTION │\r\n╘════════════════════════╛\r\n\r\n╒══════════════════╤═══════════════════════════════════════════════════════════════════╕\r\n│ Experiment name  │ api_experiment                                                    │\r\n├──────────────────┼───────────────────────────────────────────────────────────────────┤\r\n│ Model name       │ run                                                               │\r\n├──────────────────┼───────────────────────────────────────────────────────────────────┤\r\n│ Output directory │ /opt/project/sandbox/vision_models/results/api_experiment_run_552 │\r\n├──────────────────┼───────────────────────────────────────────────────────────────────┤\r\n│ ludwig_version   │ '0.6.dev'                                                         │\r\n├──────────────────┼───────────────────────────────────────────────────────────────────┤\r\n│ command          │ '/opt/project/sandbox/vision_models/mwe_dask_backend_issue1.py'   │\r\n├──────────────────┼──────────────────────────────────────────────────────────────��────┤\r\n│ commit_hash      │ '4b0825bd4be7'                                                    │\r\n├──────────────────┼───────────────────────────────────────────────────────────────────┤\r\n│ random_seed      │ 42                                                                │\r\n├──────────────────┼───────────────────────────────────────────────────────────────────┤\r\n│ dataset          │ 'data2/syn_train.csv'                                             │\r\n├──────────────────┼───────────────────────────────────────────────────────────────────┤\r\n│ data_format      │ 'csv'                                                             │\r\n├──────────────────┼───────────────────────────────────────────────────────────────────┤\r\n│ torch_version    │ '1.12.1+cu102'                                                    │\r\n├──────────────────┼───────────────────────────────────────────────────────────────────┤\r\n│ compute          │ {'num_nodes': 1}                                                  │\r\n╘══════════════════╧═════════════════════════���═════════════════════════════════════════╛\r\n\r\n╒═══════════════╕\r\n│ LUDWIG CONFIG │\r\n╘═══════════════╛\r\n\r\n{   'combiner': {   'activation': 'relu',\r\n                    'bias_initializer': 'zeros',\r\n                    'dropout': 0.0,\r\n                    'fc_layers': None,\r\n                    'flatten_inputs': False,\r\n                    'norm': None,\r\n                    'norm_params': None,\r\n                    'num_fc_layers': 0,\r\n                    'output_size': 256,\r\n                    'residual': False,\r\n                    'type': 'concat',\r\n                    'use_bias': True,\r\n                    'weights_initializer': 'xavier_uniform'},\r\n    'defaults': {   'audio': {   'preprocessing': {   'audio_file_length_limit_in_s': 7.5,\r\n                                                      'computed_fill_value': None,\r\n                                                      'fill_value': None,\r\n                                                      'in_memory': True,\r\n                                                      'missing_value_strategy': 'bfill',\r\n                                                      'norm': None,\r\n                                                      'num_fft_points': None,\r\n                                                      'num_filter_bands': 80,\r\n                                                      'padding_value': 0.0,\r\n                                                      'type': 'fbank',\r\n                                                      'window_length_in_s': 0.04,\r\n                                                      'window_shift_in_s': 0.02,\r\n                                                      'window_type': 'hamming'}},\r\n                    'bag': {   'preprocessing': {   'computed_fill_value': '<UNK>',\r\n                                                    'fill_value': '<UNK>',\r\n                                                    'lowercase': False,\r\n                                                    'missing_value_strategy': 'fill_with_const',\r\n                                                    'most_common': 10000,\r\n                                                    'tokenizer': 'space'}},\r\n                    'binary': {   'preprocessing': {   'computed_fill_value': None,\r\n                                                       'fallback_true_label': None,\r\n                                                       'fill_value': None,\r\n                                                       'missing_value_strategy': 'fill_with_false'}},\r\n                    'category': {   'preprocessing': {   'computed_fill_value': '<UNK>',\r\n                                                         'fill_value': '<UNK>',\r\n                                                         'lowercase': False,\r\n                                                         'missing_value_strategy': 'fill_with_const',\r\n                                                         'most_common': 10000}},\r\n                    'date': {   'preprocessing': {   'computed_fill_value': '',\r\n                                                     'datetime_format': None,\r\n                                                     'fill_value': '',\r\n                                                     'missing_value_strategy': 'fill_with_const'}},\r\n                    'h3': {   'preprocessing': {   'computed_fill_value': 576495936675512319,\r\n                                                   'fill_value': 576495936675512319,\r\n                                                   'missing_value_strategy': 'fill_with_const'}},\r\n                    'image': {   'preprocessing': {   'computed_fill_value': None,\r\n                                                      'fill_value': None,\r\n                                                      'height': None,\r\n                                                      'in_memory': True,\r\n                                                      'infer_image_dimensions': True,\r\n                                                      'infer_image_max_height': 256,\r\n                                                      'infer_image_max_width': 256,\r\n                                                      'infer_image_num_channels': True,\r\n                                                      'infer_image_sample_size': 100,\r\n                                                      'missing_value_strategy': 'bfill',\r\n                                                      'num_channels': None,\r\n                                                      'num_processes': 1,\r\n                                                      'resize_method': 'interpolate',\r\n                                                      'scaling': 'pixel_normalization',\r\n                                                      'width': None}},\r\n                    'number': {   'preprocessing': {   'computed_fill_value': 0.0,\r\n                                                       'fill_value': 0.0,\r\n                                                       'missing_value_strategy': 'fill_with_const',\r\n                                                       'normalization': None}},\r\n                    'sequence': {   'preprocessing': {   'computed_fill_value': '<UNK>',\r\n                                                         'fill_value': '<UNK>',\r\n                                                         'lowercase': False,\r\n                                                         'max_sequence_length': 256,\r\n                                                         'missing_value_strategy': 'fill_with_const',\r\n                                                         'most_common': 20000,\r\n                                                         'padding': 'right',\r\n                                                         'padding_symbol': '<PAD>',\r\n                                                         'tokenizer': 'space',\r\n                                                         'unknown_symbol': '<UNK>',\r\n                                                         'vocab_file': None}},\r\n                    'set': {   'preprocessing': {   'computed_fill_value': '<UNK>',\r\n                                                    'fill_value': '<UNK>',\r\n                                                    'lowercase': False,\r\n                                                    'missing_value_strategy': 'fill_with_const',\r\n                                                    'most_common': 10000,\r\n                                                    'tokenizer': 'space'}},\r\n                    'text': {   'preprocessing': {   'computed_fill_value': '<UNK>',\r\n                                                     'fill_value': '<UNK>',\r\n                                                     'lowercase': True,\r\n                                                     'max_sequence_length': 256,\r\n                                                     'missing_value_strategy': 'fill_with_const',\r\n                                                     'most_common': 20000,\r\n                                                     'padding': 'right',\r\n                                                     'padding_symbol': '<PAD>',\r\n                                                     'pretrained_model_name_or_path': None,\r\n                                                     'tokenizer': 'space_punct',\r\n                                                     'unknown_symbol': '<UNK>',\r\n                                                     'vocab_file': None}},\r\n                    'timeseries': {   'preprocessing': {   'computed_fill_value': '',\r\n                                                           'fill_value': '',\r\n                                                           'missing_value_strategy': 'fill_with_const',\r\n                                                           'padding': 'right',\r\n                                                           'padding_value': 0.0,\r\n                                                           'timeseries_length_limit': 256,\r\n                                                           'tokenizer': 'space'}},\r\n                    'vector': {   'preprocessing': {   'computed_fill_value': '',\r\n                                                       'fill_value': '',\r\n                                                       'missing_value_strategy': 'fill_with_const',\r\n                                                       'vector_size': None}}},\r\n    'input_features': [   {   'column': 'image',\r\n                              'encoder': {'type': 'resnet'},\r\n                              'name': 'image',\r\n                              'preprocessing': {},\r\n                              'proc_column': 'image_mZFLky',\r\n                              'tied': None,\r\n                              'type': 'image'}],\r\n    'ludwig_version': '0.6.dev',\r\n    'model_type': 'ecd',\r\n    'output_features': [   {   'column': 'category',\r\n                               'decoder': {'type': 'classifier'},\r\n                               'dependencies': [],\r\n                               'loss': {   'class_similarities_temperature': 0,\r\n                                           'class_weights': None,\r\n                                           'confidence_penalty': 0.0,\r\n                                           'robust_lambda': 0,\r\n                                           'type': 'softmax_cross_entropy',\r\n                                           'weight': 1.0},\r\n                               'name': 'category',\r\n                               'preprocessing': {   'missing_value_strategy': 'drop_row'},\r\n                               'proc_column': 'category_mZFLky',\r\n                               'reduce_dependencies': 'sum',\r\n                               'reduce_input': 'sum',\r\n                               'top_k': 3,\r\n                               'type': 'category'}],\r\n    'preprocessing': {   'oversample_minority': None,\r\n                         'sample_ratio': 1.0,\r\n                         'split': {   'probabilities': [0.7, 0.1, 0.2],\r\n                                      'type': 'random'},\r\n                         'undersample_majority': None},\r\n    'trainer': {   'batch_size': 128,\r\n                   'checkpoints_per_epoch': 0,\r\n                   'decay': False,\r\n                   'decay_rate': 0.96,\r\n                   'decay_steps': 10000,\r\n                   'early_stop': 5,\r\n                   'epochs': 2,\r\n                   'eval_batch_size': None,\r\n                   'evaluate_training_set': True,\r\n                   'gradient_clipping': {   'clipglobalnorm': 0.5,\r\n                                            'clipnorm': None,\r\n                                            'clipvalue': None},\r\n                   'increase_batch_size_eval_metric': 'loss',\r\n                   'increase_batch_size_eval_split': 'training',\r\n                   'increase_batch_size_on_plateau': 0,\r\n                   'increase_batch_size_on_plateau_max': 512,\r\n                   'increase_batch_size_on_plateau_patience': 5,\r\n                   'increase_batch_size_on_plateau_rate': 2.0,\r\n                   'learning_rate': 0.001,\r\n                   'learning_rate_scaling': 'linear',\r\n                   'learning_rate_warmup_epochs': 1.0,\r\n                   'optimizer': {   'amsgrad': False,\r\n                                    'betas': (0.9, 0.999),\r\n                                    'eps': 1e-08,\r\n                                    'lr': 0.001,\r\n                                    'type': 'adam',\r\n                                    'weight_decay': 0.0},\r\n                   'reduce_learning_rate_eval_metric': 'loss',\r\n                   'reduce_learning_rate_eval_split': 'training',\r\n                   'reduce_learning_rate_on_plateau': 0.0,\r\n                   'reduce_learning_rate_on_plateau_patience': 5,\r\n                   'reduce_learning_rate_on_plateau_rate': 0.5,\r\n                   'regularization_lambda': 0.0,\r\n                   'regularization_type': 'l2',\r\n                   'should_shuffle': True,\r\n                   'staircase': False,\r\n                   'steps_per_checkpoint': 0,\r\n                   'train_steps': None,\r\n                   'type': 'trainer',\r\n                   'validation_field': 'combined',\r\n                   'validation_metric': 'loss'}}\r\n\r\n╒═══════════════╕\r\n│ PREPROCESSING │\r\n╘═══════════════╛\r\n\r\nUsing full raw dataset, no hdf5 and json file with the same name have been found\r\nBuilding dataset (it may take a while)\r\nInferring num_channels from the first 40 images.\r\n  images with 3 channels: 40\r\nUsing 3 channels because it is the majority in sample. If an image with a different depth is read, will attempt to convert to 3 channels.\r\nTo explicitly set the number of channels, define num_channels in the preprocessing dictionary of the image input feature config.\r\nBuilding dataset: DONE\r\nWriting preprocessed training set cache\r\nWriting preprocessed test set cache\r\nWriting preprocessed validation set cache\r\nWriting train set metadata\r\n\r\nDataset sizes:\r\n╒════════════╤════════╕\r\n│ Dataset    │   Size │\r\n╞════════════╪════════╡\r\n│ Training   │     28 │\r\n├────────────┼────────┤\r\n│ Validation │      4 │\r\n├────────────┼────────┤\r\n│ Test       │      8 │\r\n╘════════════╧════════╛\r\n\r\n╒═══════╕\r\n│ MODEL │\r\n╘═══════╛\r\n\r\nWarnings and other logs:\r\n/usr/local/lib/python3.8/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\r\n  warnings.warn(\r\n\r\n╒══════════╕\r\n│ TRAINING │\r\n╘══════════╛\r\n\r\nTraining for 2 step(s), approximately 2 epoch(s).\r\nEarly stopping policy: 5 round(s) of evaluation, or 5 step(s), approximately 5 epoch(s).\r\n\r\nStarting with step 0, epoch: 0\r\nTraining:   0%|          | 0/2 [00:00<?, ?it/s]\r\nProcess finished with exit code 137 (interrupted by signal 9: SIGKILL)\r\n\r\n```","closed_by":{"login":"jimthompson5802","id":1425269,"node_id":"MDQ6VXNlcjE0MjUyNjk=","avatar_url":"https://avatars.githubusercontent.com/u/1425269?v=4","gravatar_id":"","url":"https://api.github.com/users/jimthompson5802","html_url":"https://github.com/jimthompson5802","followers_url":"https://api.github.com/users/jimthompson5802/followers","following_url":"https://api.github.com/users/jimthompson5802/following{/other_user}","gists_url":"https://api.github.com/users/jimthompson5802/gists{/gist_id}","starred_url":"https://api.github.com/users/jimthompson5802/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimthompson5802/subscriptions","organizations_url":"https://api.github.com/users/jimthompson5802/orgs","repos_url":"https://api.github.com/users/jimthompson5802/repos","events_url":"https://api.github.com/users/jimthompson5802/events{/privacy}","received_events_url":"https://api.github.com/users/jimthompson5802/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/2474/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/2474/timeline","performed_via_github_app":null,"state_reason":"completed"}