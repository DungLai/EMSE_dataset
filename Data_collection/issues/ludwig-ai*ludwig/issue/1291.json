{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1291","repository_url":"https://api.github.com/repos/ludwig-ai/ludwig","labels_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1291/labels{/name}","comments_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1291/comments","events_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1291/events","html_url":"https://github.com/ludwig-ai/ludwig/issues/1291","id":989907413,"node_id":"MDU6SXNzdWU5ODk5MDc0MTM=","number":1291,"title":"Performance consistency between consecutive training on the same data not achieved even if the random_seed is constant","user":{"login":"plantroots","id":45685687,"node_id":"MDQ6VXNlcjQ1Njg1Njg3","avatar_url":"https://avatars.githubusercontent.com/u/45685687?v=4","gravatar_id":"","url":"https://api.github.com/users/plantroots","html_url":"https://github.com/plantroots","followers_url":"https://api.github.com/users/plantroots/followers","following_url":"https://api.github.com/users/plantroots/following{/other_user}","gists_url":"https://api.github.com/users/plantroots/gists{/gist_id}","starred_url":"https://api.github.com/users/plantroots/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/plantroots/subscriptions","organizations_url":"https://api.github.com/users/plantroots/orgs","repos_url":"https://api.github.com/users/plantroots/repos","events_url":"https://api.github.com/users/plantroots/events{/privacy}","received_events_url":"https://api.github.com/users/plantroots/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-09-07T11:59:42Z","updated_at":"2022-08-04T17:49:14Z","closed_at":"2022-08-04T17:49:14Z","author_association":"NONE","active_lock_reason":null,"body":"summary:\r\nI have tried to train a model on the same dataset with the same random_seed (42 default) and I always get a different final model (text classifier: negative, positive, neutral categories). I might be doing something totally wrong or the random_seed parameter isn't controlling all the variability. \r\n\r\nenv:\r\nOS: Ubuntu 20.04.2 LTS\r\nPython:  3.8.10\r\nludwig_version: '0.3.3'\r\ntf_version: '2.4.3'\r\n\r\ntext sample (romanian):\r\nUn telefon slab pentru \"statutul\" de premium. L-am returnat. Cand zic slab ma refer la urmatoarele minusuri:  - este doar SuperAmoled Plus  - are doar 393 ppi la un ecran de 6.7 \" (un simplu Huawei P30 are 422 ppi, la un ecran de 6.1 \" ). Am pus acelasi film 4k la ambele iar diferenta este uriasa: P30 are culori vii si claritate f. buna, in schimb Note 20 are culori putin sterse in multe cadre si are o luminozitate considerabil mai mica  - rezolutie doar 1080 x 2340 pixeli la un ecran asa mare! (P30 are 1080 x 2400)  - bateria se descarca destul de repede la o folosire medie (100% dimineata, pe la ora 18-19 mai sunt 15 %)  - camera foto nu m-a impresionat (vechiul P30 face poze mai bune)  - amprenta o recunoaste in 70-80% din cazuri din prima (P30 recunoaste amprenta 100% din cazuri din prima)    Concluzie:  - daca vrei ceva premium : Note 10 Plus(are Dynamic Amoled, 1440 x 3040 pixeli, 498 ppi) sau Note 20 Ultra (are Dynamic Amoles 2X, 1440 x 3088, 496 ppi)  - daca nu te uiti la filme si iti doresti 256 GB memorie, atunci ia-ti Note 20. Daca insa vrei rezolutie buna, baterie buna si poze excelente, mergi spre Huawei\r\n\r\n\r\ncommand: \r\n('/usr/local/bin/ludwig experiment --gpus -1 --output_directory '\r\n '/tmp/training_arena/08347ec2-6764-4427-b6f1-8f4f11dc2686_classifier_131 '\r\n '--dataset '\r\n '/tmp/training_arena/08347ec2-6764-4427-b6f1-8f4f11dc2686_classifier_131/dataset.csv '\r\n '--config_file '\r\n '/tmp/training_arena/08347ec2-6764-4427-b6f1-8f4f11dc2686_classifier_131/model_config.yaml')\r\n\r\n\r\nconfig: {   'combiner': {'type': 'concat'},\r\n    'input_features': [   {   'column': 'text',\r\n                              'encoder': 'parallel_cnn',\r\n                              'level': 'word',\r\n                              'name': 'text',\r\n                              'preprocessing': {   'lowercase': True,\r\n                                                   'word_tokenizer': 'romanian_tokenize_punctuation'},\r\n                              'proc_column': 'text_i4HJUa',\r\n                              'tied': None,\r\n                              'type': 'text'}],\r\n    'output_features': [   {   'column': 'class',\r\n                               'dependencies': [],\r\n                               'loss': {   'class_similarities_temperature': 0,\r\n                                           'class_weights': 1,\r\n                                           'confidence_penalty': 0,\r\n                                           'labels_smoothing': 0,\r\n                                           'robust_lambda': 0,\r\n                                           'type': 'softmax_cross_entropy',\r\n                                           'weight': 1},\r\n                               'name': 'class',\r\n                               'proc_column': 'class_mZFLky',\r\n                               'reduce_dependencies': 'sum',\r\n                               'reduce_input': 'sum',\r\n                               'top_k': 3,\r\n                               'type': 'category'}],\r\n    'preprocessing': {   'audio': {   'audio_feature': {'type': 'raw'},\r\n                                      'audio_file_length_limit_in_s': 7.5,\r\n                                      'in_memory': True,\r\n                                      'missing_value_strategy': 'backfill',\r\n                                      'norm': None,\r\n                                      'padding_value': 0},\r\n                         'bag': {   'fill_value': '<UNK>',\r\n                                    'lowercase': False,\r\n                                    'missing_value_strategy': 'fill_with_const',\r\n                                    'most_common': 10000,\r\n                                    'tokenizer': 'space'},\r\n                         'binary': {   'fill_value': 0,\r\n                                       'missing_value_strategy': 'fill_with_const'},\r\n                         'category': {   'fill_value': '<UNK>',\r\n                                         'lowercase': False,\r\n                                         'missing_value_strategy': 'fill_with_const',\r\n                                         'most_common': 10000},\r\n                         'date': {   'datetime_format': None,\r\n                                     'fill_value': '',\r\n                                     'missing_value_strategy': 'fill_with_const'},\r\n                         'force_split': False,\r\n                         'h3': {   'fill_value': 576495936675512319,\r\n                                   'missing_value_strategy': 'fill_with_const'},\r\n                         'image': {   'in_memory': True,\r\n                                      'missing_value_strategy': 'backfill',\r\n                                      'num_processes': 1,\r\n                                      'resize_method': 'interpolate',\r\n                                      'scaling': 'pixel_normalization'},\r\n                         'numerical': {   'fill_value': 0,\r\n                                          'missing_value_strategy': 'fill_with_const',\r\n                                          'normalization': None},\r\n                         'sequence': {   'fill_value': '<UNK>',\r\n                                         'lowercase': False,\r\n                                         'missing_value_strategy': 'fill_with_const',\r\n                                         'most_common': 20000,\r\n                                         'padding': 'right',\r\n                                         'padding_symbol': '<PAD>',\r\n                                         'sequence_length_limit': 256,\r\n                                         'tokenizer': 'space',\r\n                                         'unknown_symbol': '<UNK>',\r\n                                         'vocab_file': None},\r\n                         'set': {   'fill_value': '<UNK>',\r\n                                    'lowercase': False,\r\n                                    'missing_value_strategy': 'fill_with_const',\r\n                                    'most_common': 10000,\r\n                                    'tokenizer': 'space'},\r\n                         'split_probabilities': (0.7, 0.1, 0.2),\r\n                         'stratify': None,\r\n                         'text': {   'char_most_common': 70,\r\n                                     'char_sequence_length_limit': 1024,\r\n                                     'char_tokenizer': 'characters',\r\n                                     'char_vocab_file': None,\r\n                                     'fill_value': '<UNK>',\r\n                                     'lowercase': True,\r\n                                     'missing_value_strategy': 'fill_with_const',\r\n                                     'padding': 'right',\r\n                                     'padding_symbol': '<PAD>',\r\n                                     'pretrained_model_name_or_path': None,\r\n                                     'unknown_symbol': '<UNK>',\r\n                                     'word_most_common': 20000,\r\n                                     'word_sequence_length_limit': 256,\r\n                                     'word_tokenizer': 'romanian_tokenize_punctuation',\r\n                                     'word_vocab_file': None},\r\n                         'timeseries': {   'fill_value': '',\r\n                                           'missing_value_strategy': 'fill_with_const',\r\n                                           'padding': 'right',\r\n                                           'padding_value': 0,\r\n                                           'timeseries_length_limit': 256,\r\n                                           'tokenizer': 'space'},\r\n                         'vector': {   'fill_value': '',\r\n                                       'missing_value_strategy': 'fill_with_const'}},\r\n    'training': {   'batch_size': 32,\r\n                    'bucketing_field': None,\r\n                    'decay': False,\r\n                    'decay_rate': 0.96,\r\n                    'decay_steps': 10000,\r\n                    'early_stop': 5,\r\n                    'epochs': 100,\r\n                    'eval_batch_size': 0,\r\n                    'gradient_clipping': None,\r\n                    'increase_batch_size_on_plateau': 0,\r\n                    'increase_batch_size_on_plateau_max': 512,\r\n                    'increase_batch_size_on_plateau_patience': 5,\r\n                    'increase_batch_size_on_plateau_rate': 2,\r\n                    'learning_rate': 0.001,\r\n                    'learning_rate_warmup_epochs': 1,\r\n                    'optimizer': {   'beta_1': 0.9,\r\n                                     'beta_2': 0.999,\r\n                                     'epsilon': 1e-08,\r\n                                     'type': 'adam'},\r\n                    'reduce_learning_rate_on_plateau': 0,\r\n                    'reduce_learning_rate_on_plateau_patience': 5,\r\n                    'reduce_learning_rate_on_plateau_rate': 0.5,\r\n                    'regularization_lambda': 0,\r\n                    'regularizer': 'l2',\r\n                    'staircase': False,\r\n                    'validation_field': 'combined',\r\n                    'validation_metric': 'loss'}}","closed_by":{"login":"dalianaliu","id":33500844,"node_id":"MDQ6VXNlcjMzNTAwODQ0","avatar_url":"https://avatars.githubusercontent.com/u/33500844?v=4","gravatar_id":"","url":"https://api.github.com/users/dalianaliu","html_url":"https://github.com/dalianaliu","followers_url":"https://api.github.com/users/dalianaliu/followers","following_url":"https://api.github.com/users/dalianaliu/following{/other_user}","gists_url":"https://api.github.com/users/dalianaliu/gists{/gist_id}","starred_url":"https://api.github.com/users/dalianaliu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dalianaliu/subscriptions","organizations_url":"https://api.github.com/users/dalianaliu/orgs","repos_url":"https://api.github.com/users/dalianaliu/repos","events_url":"https://api.github.com/users/dalianaliu/events{/privacy}","received_events_url":"https://api.github.com/users/dalianaliu/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1291/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1291/timeline","performed_via_github_app":null,"state_reason":"completed"}