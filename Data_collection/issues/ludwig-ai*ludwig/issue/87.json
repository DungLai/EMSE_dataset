{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/87","repository_url":"https://api.github.com/repos/ludwig-ai/ludwig","labels_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/87/labels{/name}","comments_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/87/comments","events_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/87/events","html_url":"https://github.com/ludwig-ai/ludwig/issues/87","id":410507496,"node_id":"MDU6SXNzdWU0MTA1MDc0OTY=","number":87,"title":"Predict from stdin or via the programmatic api","user":{"login":"loretoparisi","id":163333,"node_id":"MDQ6VXNlcjE2MzMzMw==","avatar_url":"https://avatars.githubusercontent.com/u/163333?v=4","gravatar_id":"","url":"https://api.github.com/users/loretoparisi","html_url":"https://github.com/loretoparisi","followers_url":"https://api.github.com/users/loretoparisi/followers","following_url":"https://api.github.com/users/loretoparisi/following{/other_user}","gists_url":"https://api.github.com/users/loretoparisi/gists{/gist_id}","starred_url":"https://api.github.com/users/loretoparisi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/loretoparisi/subscriptions","organizations_url":"https://api.github.com/users/loretoparisi/orgs","repos_url":"https://api.github.com/users/loretoparisi/repos","events_url":"https://api.github.com/users/loretoparisi/events{/privacy}","received_events_url":"https://api.github.com/users/loretoparisi/received_events","type":"User","site_admin":false},"labels":[{"id":1174068771,"node_id":"MDU6TGFiZWwxMTc0MDY4Nzcx","url":"https://api.github.com/repos/ludwig-ai/ludwig/labels/feature","name":"feature","color":"0377d6","default":false,"description":"New feature or request"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":10,"created_at":"2019-02-14T21:48:43Z","updated_at":"2019-05-30T20:40:46Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"As soon as my brand new model is ready, I would like `ludwig` the enable predictions via the command line, so that one could do like\r\n\r\n```sh\r\necho \"call me at +3912345679 for offers\" | ludwig predict --only_prediction --model_path /path/to/model -\r\n```\r\n\r\nwhere the `-` may indicate the `stdin` (as an example) and get the model predictions directly. This would help to integrated `ludwing` command in a inference pipeline.\r\n\r\nIf I have understood well the api (my model is not ready yet...) it should be possibile via the programmatic api like that:\r\n\r\n```python\r\nfrom ludwig import LudwigModel\r\n\r\n# load a model\r\nmodel = LudwigModel.load(model_path)\r\n\r\n# obtain predictions\r\nmyDict = { 'text': ['call me at +3912345679 for offers'] }\r\npredictions = model.predict(data_dict=myDict,\r\n  return_type=dict\r\n  batch_size=128,\r\n  gpus=None,\r\n  gpu_fraction=1,\r\n  logging_level=logging.DEBUG)\r\n\r\n# close model (eventually)\r\nmodel.close()\r\n```\r\n\r\nIs that correct?","closed_by":null,"reactions":{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/87/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/87/timeline","performed_via_github_app":null,"state_reason":null}