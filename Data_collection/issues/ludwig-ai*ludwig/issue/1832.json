{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1832","repository_url":"https://api.github.com/repos/ludwig-ai/ludwig","labels_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1832/labels{/name}","comments_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1832/comments","events_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1832/events","html_url":"https://github.com/ludwig-ai/ludwig/issues/1832","id":1174941464,"node_id":"I_kwDOCbx2hs5GCC8Y","number":1832,"title":"Using Sequence Feature Encoders with pretrained embeddings from huggingface","user":{"login":"smiraldr","id":42693530,"node_id":"MDQ6VXNlcjQyNjkzNTMw","avatar_url":"https://avatars.githubusercontent.com/u/42693530?v=4","gravatar_id":"","url":"https://api.github.com/users/smiraldr","html_url":"https://github.com/smiraldr","followers_url":"https://api.github.com/users/smiraldr/followers","following_url":"https://api.github.com/users/smiraldr/following{/other_user}","gists_url":"https://api.github.com/users/smiraldr/gists{/gist_id}","starred_url":"https://api.github.com/users/smiraldr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/smiraldr/subscriptions","organizations_url":"https://api.github.com/users/smiraldr/orgs","repos_url":"https://api.github.com/users/smiraldr/repos","events_url":"https://api.github.com/users/smiraldr/events{/privacy}","received_events_url":"https://api.github.com/users/smiraldr/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2022-03-21T06:28:54Z","updated_at":"2022-03-25T23:21:41Z","closed_at":"2022-03-25T23:21:40Z","author_association":"NONE","active_lock_reason":null,"body":"As mentioned on https://ludwig-ai.github.io/ludwig-docs/0.4/configuration/features/sequence_features/#embed-encoder\r\nWe can use pretrained embeddings in glove format for sequence encoders. Is there any way we could use the pretrained transformer models with sequence encoder from huggingface directly incase glove format is not available? \r\nI've already tried using hf_tokenizer for text feature on word level but i'm looking to use it with sequence encoder.\r\nWould appreciate if anyone could help me out.","closed_by":{"login":"w4nderlust","id":349256,"node_id":"MDQ6VXNlcjM0OTI1Ng==","avatar_url":"https://avatars.githubusercontent.com/u/349256?v=4","gravatar_id":"","url":"https://api.github.com/users/w4nderlust","html_url":"https://github.com/w4nderlust","followers_url":"https://api.github.com/users/w4nderlust/followers","following_url":"https://api.github.com/users/w4nderlust/following{/other_user}","gists_url":"https://api.github.com/users/w4nderlust/gists{/gist_id}","starred_url":"https://api.github.com/users/w4nderlust/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/w4nderlust/subscriptions","organizations_url":"https://api.github.com/users/w4nderlust/orgs","repos_url":"https://api.github.com/users/w4nderlust/repos","events_url":"https://api.github.com/users/w4nderlust/events{/privacy}","received_events_url":"https://api.github.com/users/w4nderlust/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1832/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1832/timeline","performed_via_github_app":null,"state_reason":"completed"}