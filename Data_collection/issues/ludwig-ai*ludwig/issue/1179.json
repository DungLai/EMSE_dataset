{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1179","repository_url":"https://api.github.com/repos/ludwig-ai/ludwig","labels_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1179/labels{/name}","comments_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1179/comments","events_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1179/events","html_url":"https://github.com/ludwig-ai/ludwig/issues/1179","id":891925657,"node_id":"MDU6SXNzdWU4OTE5MjU2NTc=","number":1179,"title":"Error using Named Entity Recognition Tagging","user":{"login":"redfalcoon","id":74205208,"node_id":"MDQ6VXNlcjc0MjA1MjA4","avatar_url":"https://avatars.githubusercontent.com/u/74205208?v=4","gravatar_id":"","url":"https://api.github.com/users/redfalcoon","html_url":"https://github.com/redfalcoon","followers_url":"https://api.github.com/users/redfalcoon/followers","following_url":"https://api.github.com/users/redfalcoon/following{/other_user}","gists_url":"https://api.github.com/users/redfalcoon/gists{/gist_id}","starred_url":"https://api.github.com/users/redfalcoon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/redfalcoon/subscriptions","organizations_url":"https://api.github.com/users/redfalcoon/orgs","repos_url":"https://api.github.com/users/redfalcoon/repos","events_url":"https://api.github.com/users/redfalcoon/events{/privacy}","received_events_url":"https://api.github.com/users/redfalcoon/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-05-14T13:31:28Z","updated_at":"2021-05-16T14:55:29Z","closed_at":"2021-05-16T14:54:54Z","author_association":"NONE","active_lock_reason":null,"body":"Hi Ludwig Authors,\r\nI'm trying to use ludwig to create a NER extractor from italian text, but I got always an error message that preclude the model generation. Maybe I'm using in a wrong way the ludwig training so I'm sorry to create trouble.\r\nMy csv file contains the following data:\r\n\r\nfrase,mappa\r\nLorenzo Liparti e' nato a Roma nel 2000,P P O O O C O D\r\nGiancarlo vive a Milano dal 2011,P O O C O D\r\nNel 2020 si e' diffuso il COVID,O D O O O O M\r\nIl film Titanic e' una vera noia del 2000,O O F O O O O O D\r\nnel libro il signore degli anelli tolkien ha dato il massimo,O O B B B B P O O O O\r\n\r\nand the config.yaml file is:\r\n\r\ninput_features:\r\n    -\r\n        name: frase\r\n        type: text\r\n        level: word\r\n        encoder: rnn\r\n        cell_type: lstm\r\n        reduce_output: null\r\n        preprocessing:\r\n          word_tokenizer: space\r\n\r\noutput_features:\r\n    -\r\n        name: mappa\r\n        type: sequence\r\n        decoder: tagger\r\n\r\nwhen I try to execute the command:\r\n\r\nludwig train --dataset testo.csv --config_file config.yaml \r\n\r\nand the system show this log:\r\n\r\n2021-05-14 15:13:41.778194: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2021-05-14 15:13:41.778237: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n/usr/lib/python3.6/site-packages/typeguard/__init__.py:917: UserWarning: no type annotations present -- not typechecking tensorflow_addons.layers.max_unpooling_2d.MaxUnpooling2D.__init__\r\n  warn('no type annotations present -- not typechecking {}'.format(function_name(func)))\r\n███████████████████████\r\n█ █ █ █  ▜█ █ █ █ █   █\r\n█ █ █ █ █ █ █ █ █ █ ███\r\n█ █   █ █ █ █ █ █ █ ▌ █\r\n█ █████ █ █ █ █ █ █ █ █\r\n█     █  ▟█     █ █   █\r\n███████████████████████\r\nludwig v0.3.3 - Train\r\n\r\n2021-05-14 15:13:43.410379: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-05-14 15:13:43.410616: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2021-05-14 15:13:43.410637: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\r\n2021-05-14 15:13:43.410666: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (app01.localdomain): /proc/driver/nvidia/version does not exist\r\nExperiment name: experiment\r\nModel name: run\r\nOutput directory: results/experiment_run_4\r\n\r\n\r\nludwig_version: '0.3.3'\r\ncommand: '/usr/bin/ludwig train --dataset testo.csv --config_file config.yaml'\r\nrandom_seed: 42\r\ndataset: 'testo.csv'\r\ndata_format: 'csv'\r\nconfig: {   'combiner': {'type': 'concat'},\r\n    'input_features': [   {   'cell_type': 'lstm',\r\n                              'column': 'frase',\r\n                              'encoder': 'rnn',\r\n                              'level': 'word',\r\n                              'name': 'frase',\r\n                              'preprocessing': {'word_tokenizer': 'space'},\r\n                              'proc_column': 'frase_R4V2yq',\r\n                              'reduce_output': None,\r\n                              'tied': None,\r\n                              'type': 'text'}],\r\n    'output_features': [   {   'column': 'mappa',\r\n                               'decoder': 'tagger',\r\n                               'dependencies': [],\r\n                               'loss': {   'class_similarities_temperature': 0,\r\n                                           'class_weights': 1,\r\n                                           'confidence_penalty': 0,\r\n                                           'distortion': 1,\r\n                                           'labels_smoothing': 0,\r\n                                           'negative_samples': 0,\r\n                                           'robust_lambda': 0,\r\n                                           'sampler': None,\r\n                                           'type': 'softmax_cross_entropy',\r\n                                           'unique': False,\r\n                                           'weight': 1},\r\n                               'name': 'mappa',\r\n                               'proc_column': 'mappa_mZFLky',\r\n                               'reduce_dependencies': 'sum',\r\n                               'reduce_input': None,\r\n                               'type': 'sequence'}],\r\n    'preprocessing': {   'audio': {   'audio_feature': {'type': 'raw'},\r\n                                      'audio_file_length_limit_in_s': 7.5,\r\n                                      'in_memory': True,\r\n                                      'missing_value_strategy': 'backfill',\r\n                                      'norm': None,\r\n                                      'padding_value': 0},\r\n                         'bag': {   'fill_value': '<UNK>',\r\n                                    'lowercase': False,\r\n                                    'missing_value_strategy': 'fill_with_const',\r\n                                    'most_common': 10000,\r\n                                    'tokenizer': 'space'},\r\n                         'binary': {   'fill_value': 0,\r\n                                       'missing_value_strategy': 'fill_with_const'},\r\n                         'category': {   'fill_value': '<UNK>',\r\n                                         'lowercase': False,\r\n                                         'missing_value_strategy': 'fill_with_const',\r\n                                         'most_common': 10000},\r\n                         'date': {   'datetime_format': None,\r\n                                     'fill_value': '',\r\n                                     'missing_value_strategy': 'fill_with_const'},\r\n                         'force_split': False,\r\n                         'h3': {   'fill_value': 576495936675512319,\r\n                                   'missing_value_strategy': 'fill_with_const'},\r\n                         'image': {   'in_memory': True,\r\n                                      'missing_value_strategy': 'backfill',\r\n                                      'num_processes': 1,\r\n                                      'resize_method': 'interpolate',\r\n                                      'scaling': 'pixel_normalization'},\r\n                         'numerical': {   'fill_value': 0,\r\n                                          'missing_value_strategy': 'fill_with_const',\r\n                                          'normalization': None},\r\n                         'sequence': {   'fill_value': '<UNK>',\r\n                                         'lowercase': False,\r\n                                         'missing_value_strategy': 'fill_with_const',\r\n                                         'most_common': 20000,\r\n                                         'padding': 'right',\r\n                                         'padding_symbol': '<PAD>',\r\n                                         'sequence_length_limit': 256,\r\n                                         'tokenizer': 'space',\r\n                                         'unknown_symbol': '<UNK>',\r\n                                         'vocab_file': None},\r\n                         'set': {   'fill_value': '<UNK>',\r\n                                    'lowercase': False,\r\n                                    'missing_value_strategy': 'fill_with_const',\r\n                                    'most_common': 10000,\r\n                                    'tokenizer': 'space'},\r\n                         'split_probabilities': (0.7, 0.1, 0.2),\r\n                         'stratify': None,\r\n                         'text': {   'char_most_common': 70,\r\n                                     'char_sequence_length_limit': 1024,\r\n                                     'char_tokenizer': 'characters',\r\n                                     'char_vocab_file': None,\r\n                                     'fill_value': '<UNK>',\r\n                                     'lowercase': True,\r\n                                     'missing_value_strategy': 'fill_with_const',\r\n                                     'padding': 'right',\r\n                                     'padding_symbol': '<PAD>',\r\n                                     'pretrained_model_name_or_path': None,\r\n                                     'unknown_symbol': '<UNK>',\r\n                                     'word_most_common': 20000,\r\n                                     'word_sequence_length_limit': 256,\r\n                                     'word_tokenizer': 'space_punct',\r\n                                     'word_vocab_file': None},\r\n                         'timeseries': {   'fill_value': '',\r\n                                           'missing_value_strategy': 'fill_with_const',\r\n                                           'padding': 'right',\r\n                                           'padding_value': 0,\r\n                                           'timeseries_length_limit': 256,\r\n                                           'tokenizer': 'space'},\r\n                         'vector': {   'fill_value': '',\r\n                                       'missing_value_strategy': 'fill_with_const'}},\r\n    'training': {   'batch_size': 128,\r\n                    'bucketing_field': None,\r\n                    'decay': False,\r\n                    'decay_rate': 0.96,\r\n                    'decay_steps': 10000,\r\n                    'early_stop': 5,\r\n                    'epochs': 100,\r\n                    'eval_batch_size': 0,\r\n                    'gradient_clipping': None,\r\n                    'increase_batch_size_on_plateau': 0,\r\n                    'increase_batch_size_on_plateau_max': 512,\r\n                    'increase_batch_size_on_plateau_patience': 5,\r\n                    'increase_batch_size_on_plateau_rate': 2,\r\n                    'learning_rate': 0.001,\r\n                    'learning_rate_warmup_epochs': 1,\r\n                    'optimizer': {   'beta_1': 0.9,\r\n                                     'beta_2': 0.999,\r\n                                     'epsilon': 1e-08,\r\n                                     'type': 'adam'},\r\n                    'reduce_learning_rate_on_plateau': 0,\r\n                    'reduce_learning_rate_on_plateau_patience': 5,\r\n                    'reduce_learning_rate_on_plateau_rate': 0.5,\r\n                    'regularization_lambda': 0,\r\n                    'regularizer': 'l2',\r\n                    'staircase': False,\r\n                    'validation_field': 'combined',\r\n                    'validation_metric': 'loss'}}\r\ntf_version: '2.4.1'\r\n\r\n\r\nFound hdf5 and meta.json with the same filename of the dataset, but checksum don't match, if saving of processed input is not skipped they will be overridden\r\nUsing full raw csv, no hdf5 and json file with the same name have been found\r\nBuilding dataset (it may take a while)\r\nWriting preprocessed dataset cache\r\nWriting train set metadata\r\nTraining set: 3\r\nValidation set: 1\r\nTest set: 1\r\n2021-05-14 15:13:43.478838: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-05-14 15:13:43.481326: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n  embedding_size (256) is greater than vocab_size (34). Setting embedding size to be equal to vocab_size.\r\n\r\n╒══════════╕\r\n│ TRAINING │\r\n╘══════════╛\r\n\r\n\r\nEpoch   1\r\nTraining:   0%|                                                                                                                                                                               | 0/1 [00:00<?, ?it/s]Traceback (most recent call last):\r\n  File \"/usr/bin/ludwig\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/lib/python3.6/site-packages/ludwig/cli.py\", line 146, in main\r\n    CLI()\r\n  File \"/usr/lib/python3.6/site-packages/ludwig/cli.py\", line 72, in __init__\r\n    getattr(self, args.command)()\r\n  File \"/usr/lib/python3.6/site-packages/ludwig/cli.py\", line 77, in train\r\n    train.cli(sys.argv[2:])\r\n  File \"/usr/lib/python3.6/site-packages/ludwig/train.py\", line 412, in cli\r\n    train_cli(**vars(args))\r\n  File \"/usr/lib/python3.6/site-packages/ludwig/train.py\", line 197, in train_cli\r\n    debug=debug,\r\n  File \"/usr/lib/python3.6/site-packages/ludwig/api.py\", line 487, in train\r\n    save_path=model_dir,\r\n  File \"/usr/lib/python3.6/site-packages/ludwig/models/trainer.py\", line 550, in train\r\n    self.regularization_lambda\r\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 871, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 726, in _initialize\r\n    *args, **kwds))\r\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2969, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/eager/function.py\", line 3361, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/eager/function.py\", line 3206, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 990, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 634, in wrapped_fn\r\n    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/eager/function.py\", line 3887, in bound_method_wrapper\r\n    return wrapped_fn(*args, **kwargs)\r\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 977, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\ntensorflow.python.autograph.impl.api.StagingError: in user code:\r\n\r\n    /usr/lib/python3.6/site-packages/ludwig/models/ecd.py:176 train_step  *\r\n        model_outputs = self((inputs, targets), training=True)\r\n    /usr/lib/python3.6/site-packages/ludwig/models/ecd.py:118 call  *\r\n        decoder_outputs = decoder(\r\n    /usr/lib/python3.6/site-packages/ludwig/features/base_feature.py:271 call  *\r\n        logits = self.logits(logits_input, target=target, training=training)\r\n    /usr/lib/python3.6/site-packages/ludwig/features/sequence_feature.py:243 logits  *\r\n        inputs,\r\n    /usr/lib/python3.6/site-packages/ludwig/decoders/sequence_decoders.py:785 _logits_training  *\r\n        return self.call(inputs, training=training, mask=mask)\r\n    /usr/lib/python3.6/site-packages/ludwig/decoders/sequence_decoders.py:774 call  *\r\n        LENGTHS: inputs[LENGTHS]\r\n\r\n    KeyError: 'lengths'\r\n\r\nTraining:   0%| \r\n\r\n","closed_by":{"login":"jimthompson5802","id":1425269,"node_id":"MDQ6VXNlcjE0MjUyNjk=","avatar_url":"https://avatars.githubusercontent.com/u/1425269?v=4","gravatar_id":"","url":"https://api.github.com/users/jimthompson5802","html_url":"https://github.com/jimthompson5802","followers_url":"https://api.github.com/users/jimthompson5802/followers","following_url":"https://api.github.com/users/jimthompson5802/following{/other_user}","gists_url":"https://api.github.com/users/jimthompson5802/gists{/gist_id}","starred_url":"https://api.github.com/users/jimthompson5802/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jimthompson5802/subscriptions","organizations_url":"https://api.github.com/users/jimthompson5802/orgs","repos_url":"https://api.github.com/users/jimthompson5802/repos","events_url":"https://api.github.com/users/jimthompson5802/events{/privacy}","received_events_url":"https://api.github.com/users/jimthompson5802/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1179/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1179/timeline","performed_via_github_app":null,"state_reason":"completed"}