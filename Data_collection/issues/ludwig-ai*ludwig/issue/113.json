{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/113","repository_url":"https://api.github.com/repos/ludwig-ai/ludwig","labels_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/113/labels{/name}","comments_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/113/comments","events_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/113/events","html_url":"https://github.com/ludwig-ai/ludwig/issues/113","id":411358526,"node_id":"MDU6SXNzdWU0MTEzNTg1MjY=","number":113,"title":"UnicodeDecodeError: 'utf-8' codec","user":{"login":"ghost","id":10137,"node_id":"MDQ6VXNlcjEwMTM3","avatar_url":"https://avatars.githubusercontent.com/u/10137?v=4","gravatar_id":"","url":"https://api.github.com/users/ghost","html_url":"https://github.com/ghost","followers_url":"https://api.github.com/users/ghost/followers","following_url":"https://api.github.com/users/ghost/following{/other_user}","gists_url":"https://api.github.com/users/ghost/gists{/gist_id}","starred_url":"https://api.github.com/users/ghost/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ghost/subscriptions","organizations_url":"https://api.github.com/users/ghost/orgs","repos_url":"https://api.github.com/users/ghost/repos","events_url":"https://api.github.com/users/ghost/events{/privacy}","received_events_url":"https://api.github.com/users/ghost/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2019-02-18T08:38:12Z","updated_at":"2019-02-20T07:04:22Z","closed_at":"2019-02-20T07:04:22Z","author_association":"NONE","active_lock_reason":null,"body":"Hi guys - Getting thrown the following error:\r\n> UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 4: unexpected end of data\r\n\r\nOccurs whilst using the below command with \r\n> ludwig experiment --data_csv trainers.csv --model_definition_file trainers_model.yaml\r\n\r\ntrainers_model.yaml\r\n`input_features:\r\n    -\r\n        name: Image\r\n        type: image\r\n        encoder: stacked_cnn\r\n\r\noutput_features:\r\n    -\r\n        name: Brand\r\n        type: category`\r\n\r\nCSV is in format\r\n\r\nrandomImageofsneaker1.png / Adidas \r\nrandomImageofsneaker2.png / Vans\r\nrandomImageofsneaker3.png / Nike\r\nrandomImageofsneaker4.png / Nike\r\n\r\nSet of files I'm using is available here. Any ideas?\r\n[Ludwig UTF8 Error.zip](https://github.com/uber/ludwig/files/2874640/Ludwig.UTF8.Error.zip)\r\n\r\n\r\nFull error from console here - \r\n`PS E:\\Web Projects\\LUDWIG UBER> ludwig experiment --data_csv trainers.csv --model_definition_file trainers_model.yaml\r\n _         _        _\r\n| |_  _ __| |_ __ _(_)__ _\r\n| | || / _` \\ V  V / / _` |\r\n|_|\\_,_\\__,_|\\_/\\_/|_\\__, |\r\n                     |___/\r\nludwig v0.1.0 - Experiment\r\n\r\nExperiment name: experiment\r\nModel name: run\r\nOutput path: results\\experiment_run_0\r\n\r\nludwig_version: '0.1.0'\r\ncommand: ('C:\\\\Users\\\\GODZILLA\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\Scripts\\\\ludwig '\r\n 'experiment --data_csv trainers.csv --model_definition_file '\r\n 'trainers_model.yaml')\r\ndataset_type: 'trainers.csv'\r\nmodel_definition: {   'combiner': {'type': 'concat'},\r\n    'input_features': [   {   'encoder': 'stacked_cnn',\r\n                              'in_memory': True,\r\n                              'name': 'Image_url',\r\n                              'should_resize': False,\r\n                              'tied_weights': None,\r\n                              'type': 'image'}],\r\n    'output_features': [   {   'dependencies': [],\r\n                               'loss': {   'class_distance_temperature': 0,\r\n                                           'class_weights': 1,\r\n                                           'confidence_penalty': 0,\r\n                                           'distortion': 1,\r\n                                           'labels_smoothing': 0,\r\n                                           'negative_samples': 0,\r\n                                           'robust_lambda': 0,\r\n                                           'sampler': None,\r\n                                           'type': 'softmax_cross_entropy',\r\n                                           'unique': False,\r\n                                           'weight': 1},\r\n                               'name': 'Brand',\r\n                               'reduce_dependencies': 'sum',\r\n                               'reduce_input': 'sum',\r\n                               'top_k': 3,\r\n                               'type': 'category'}],\r\n    'preprocessing': {   'bag': {   'fill_value': '',\r\n                                    'format': 'space',\r\n                                    'lowercase': 10000,\r\n                                    'missing_value_strategy': 'fill_with_const',\r\n                                    'most_common': False},\r\n                         'binary': {   'fill_value': 0,\r\n                                       'missing_value_strategy': 'fill_with_const'},\r\n                         'category': {   'fill_value': '<UNK>',\r\n                                         'lowercase': False,\r\n                                         'missing_value_strategy': 'fill_with_const',\r\n                                         'most_common': 10000},\r\n                         'force_split': False,\r\n                         'image': {'missing_value_strategy': 'backfill'},\r\n                         'numerical': {   'fill_value': 0,\r\n                                          'missing_value_strategy': 'fill_with_const'},\r\n                         'sequence': {   'fill_value': '',\r\n                                         'format': 'space',\r\n                                         'lowercase': False,\r\n                                         'missing_value_strategy': 'fill_with_const',\r\n                                         'most_common': 20000,\r\n                                         'padding': 'right',\r\n                                         'padding_symbol': '<PAD>',\r\n                                         'sequence_length_limit': 256,\r\n                                         'unknown_symbol': '<UNK>'},\r\n                         'set': {   'fill_value': '',\r\n                                    'format': 'space',\r\n                                    'lowercase': False,\r\n                                    'missing_value_strategy': 'fill_with_const',\r\n                                    'most_common': 10000},\r\n                         'split_probabilities': (0.7, 0.1, 0.2),\r\n                         'stratify': None,\r\n                         'text': {   'char_format': 'characters',\r\n                                     'char_most_common': 70,\r\n                                     'char_sequence_length_limit': 1024,\r\n                                     'fill_value': '',\r\n                                     'lowercase': True,\r\n                                     'missing_value_strategy': 'fill_with_const',\r\n                                     'padding': 'right',\r\n                                     'padding_symbol': '<PAD>',\r\n                                     'unknown_symbol': '<UNK>',\r\n                                     'word_format': 'space_punct',\r\n                                     'word_most_common': 20000,\r\n                                     'word_sequence_length_limit': 256},\r\n                         'timeseries': {   'fill_value': '',\r\n                                           'format': 'space',\r\n                                           'missing_value_strategy': 'fill_with_const',\r\n                                           'padding': 'right',\r\n                                           'padding_value': 0,\r\n                                           'timeseries_length_limit': 256}},\r\n    'training': {   'batch_size': 128,\r\n                    'bucketing_field': None,\r\n                    'decay': False,\r\n                    'decay_rate': 0.96,\r\n                    'decay_steps': 10000,\r\n                    'dropout_rate': 0.0,\r\n                    'early_stop': 3,\r\n                    'epochs': 200,\r\n                    'gradient_clipping': None,\r\n                    'increase_batch_size_on_plateau': 0,\r\n                    'increase_batch_size_on_plateau_max': 512,\r\n                    'increase_batch_size_on_plateau_patience': 5,\r\n                    'increase_batch_size_on_plateau_rate': 2,\r\n                    'learning_rate': 0.001,\r\n                    'learning_rate_warmup_epochs': 5,\r\n                    'optimizer': {   'beta1': 0.9,\r\n                                     'beta2': 0.999,\r\n                                     'epsilon': 1e-08,\r\n                                     'type': 'adam'},\r\n                    'reduce_learning_rate_on_plateau': 0,\r\n                    'reduce_learning_rate_on_plateau_patience': 5,\r\n                    'reduce_learning_rate_on_plateau_rate': 0.5,\r\n                    'regularization_lambda': 0,\r\n                    'regularizer': 'l2',\r\n                    'staircase': False,\r\n                    'validation_field': 'combined',\r\n                    'validation_measure': 'loss'}}\r\n\r\nUsing full raw csv, no hdf5 and json file with the same name have been found\r\nBuilding dataset (it may take a while)\r\nTraceback (most recent call last):\r\n  File \"pandas\\_libs\\parsers.pyx\", line 1169, in pandas._libs.parsers.TextReader._convert_tokens\r\n  File \"pandas\\_libs\\parsers.pyx\", line 1299, in pandas._libs.parsers.TextReader._convert_with_dtype\r\n  File \"pandas\\_libs\\parsers.pyx\", line 1315, in pandas._libs.parsers.TextReader._string_convert\r\n  File \"pandas\\_libs\\parsers.pyx\", line 1553, in pandas._libs.parsers._string_box_utf8\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 4: unexpected end of data\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\GODZILLA\\AppData\\Local\\Programs\\Python\\Python36\\Scripts\\ludwig-script.py\", line 11, in <module>\r\n    load_entry_point('ludwig==0.1.0', 'console_scripts', 'ludwig')()\r\n  File \"c:\\users\\godzilla\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ludwig\\cli.py\", line 86, in main\r\n    CLI()\r\n  File \"c:\\users\\godzilla\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ludwig\\cli.py\", line 64, in __init__\r\n    getattr(self, args.command)()\r\n  File \"c:\\users\\godzilla\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ludwig\\cli.py\", line 67, in experiment\r\n    experiment.cli(sys.argv[2:])\r\n  File \"c:\\users\\godzilla\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ludwig\\experiment.py\", line 548, in cli\r\n    experiment(**vars(args))\r\n  File \"c:\\users\\godzilla\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ludwig\\experiment.py\", line 234, in experiment\r\n    random_seed=random_seed\r\n  File \"c:\\users\\godzilla\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ludwig\\data\\preprocessing.py\", line 457, in preprocess_for_training\r\n    random_seed=random_seed\r\n  File \"c:\\users\\godzilla\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ludwig\\data\\preprocessing.py\", line 54, in build_dataset\r\n    dataset_df = read_csv(dataset_csv)\r\n  File \"c:\\users\\godzilla\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ludwig\\utils\\data_utils.py\", line 46, in read_csv\r\n    df = pd.read_csv(data_fp, header=header)\r\n  File \"c:\\users\\godzilla\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\", line 702, in parser_f\r\n    return _read(filepath_or_buffer, kwds)\r\n  File \"c:\\users\\godzilla\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\", line 435, in _read\r\n    data = parser.read(nrows)\r\n  File \"c:\\users\\godzilla\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1139, in read\r\n    ret = self._engine.read(nrows)\r\n  File \"c:\\users\\godzilla\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1995, in read\r\n    data = self._reader.read(nrows)\r\n  File \"pandas\\_libs\\parsers.pyx\", line 899, in pandas._libs.parsers.TextReader.read\r\n  File \"pandas\\_libs\\parsers.pyx\", line 914, in pandas._libs.parsers.TextReader._read_low_memory\r\n  File \"pandas\\_libs\\parsers.pyx\", line 991, in pandas._libs.parsers.TextReader._read_rows\r\n  File \"pandas\\_libs\\parsers.pyx\", line 1123, in pandas._libs.parsers.TextReader._convert_column_data\r\n  File \"pandas\\_libs\\parsers.pyx\", line 1176, in pandas._libs.parsers.TextReader._convert_tokens\r\n  File \"pandas\\_libs\\parsers.pyx\", line 1299, in pandas._libs.parsers.TextReader._convert_with_dtype\r\n  File \"pandas\\_libs\\parsers.pyx\", line 1315, in pandas._libs.parsers.TextReader._string_convert\r\n  File \"pandas\\_libs\\parsers.pyx\", line 1553, in pandas._libs.parsers._string_box_utf8\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 4: unexpected end of data`","closed_by":{"login":"w4nderlust","id":349256,"node_id":"MDQ6VXNlcjM0OTI1Ng==","avatar_url":"https://avatars.githubusercontent.com/u/349256?v=4","gravatar_id":"","url":"https://api.github.com/users/w4nderlust","html_url":"https://github.com/w4nderlust","followers_url":"https://api.github.com/users/w4nderlust/followers","following_url":"https://api.github.com/users/w4nderlust/following{/other_user}","gists_url":"https://api.github.com/users/w4nderlust/gists{/gist_id}","starred_url":"https://api.github.com/users/w4nderlust/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/w4nderlust/subscriptions","organizations_url":"https://api.github.com/users/w4nderlust/orgs","repos_url":"https://api.github.com/users/w4nderlust/repos","events_url":"https://api.github.com/users/w4nderlust/events{/privacy}","received_events_url":"https://api.github.com/users/w4nderlust/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/113/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/113/timeline","performed_via_github_app":null,"state_reason":"completed"}