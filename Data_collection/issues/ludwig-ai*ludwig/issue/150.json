{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/150","repository_url":"https://api.github.com/repos/ludwig-ai/ludwig","labels_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/150/labels{/name}","comments_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/150/comments","events_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/150/events","html_url":"https://github.com/ludwig-ai/ludwig/issues/150","id":415397619,"node_id":"MDU6SXNzdWU0MTUzOTc2MTk=","number":150,"title":"OSError: Can't prepare for writing dat","user":{"login":"jiangweiatgithub","id":14370779,"node_id":"MDQ6VXNlcjE0MzcwNzc5","avatar_url":"https://avatars.githubusercontent.com/u/14370779?v=4","gravatar_id":"","url":"https://api.github.com/users/jiangweiatgithub","html_url":"https://github.com/jiangweiatgithub","followers_url":"https://api.github.com/users/jiangweiatgithub/followers","following_url":"https://api.github.com/users/jiangweiatgithub/following{/other_user}","gists_url":"https://api.github.com/users/jiangweiatgithub/gists{/gist_id}","starred_url":"https://api.github.com/users/jiangweiatgithub/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jiangweiatgithub/subscriptions","organizations_url":"https://api.github.com/users/jiangweiatgithub/orgs","repos_url":"https://api.github.com/users/jiangweiatgithub/repos","events_url":"https://api.github.com/users/jiangweiatgithub/events{/privacy}","received_events_url":"https://api.github.com/users/jiangweiatgithub/received_events","type":"User","site_admin":false},"labels":[{"id":1174068775,"node_id":"MDU6TGFiZWwxMTc0MDY4Nzc1","url":"https://api.github.com/repos/ludwig-ai/ludwig/labels/waiting%20for%20answer","name":"waiting for answer","color":"fff36b","default":false,"description":"Further information is requested"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":8,"created_at":"2019-02-28T00:59:07Z","updated_at":"2019-03-02T00:21:45Z","closed_at":"2019-03-02T00:21:44Z","author_association":"NONE","active_lock_reason":null,"body":"F:\\ezjoiner>ludwig experiment --data_csv eng_incompleteness2.csv --model_definit\r\nion_file sent_complete_model_definition_continuous.yaml\r\nf:\\programdata\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: C\r\nonversion of the second argument of issubdtype from `float` to `np.floating` is\r\ndeprecated. In future, it will be treated as `np.float64 == np.dtype(float).type\r\n`.\r\n  from ._conv import register_converters as _register_converters\r\n _         _        _\r\n| |_  _ __| |_ __ _(_)__ _\r\n| | || / _` \\ V  V / / _` |\r\n|_|\\_,_\\__,_|\\_/\\_/|_\\__, |\r\n                     |___/\r\nludwig v0.1.0 - Experiment\r\n\r\nExperiment name: experiment\r\nModel name: run\r\nOutput path: results\\experiment_run_1\r\n\r\nludwig_version: '0.1.0'\r\ncommand: ('F:\\\\ProgramData\\\\Anaconda3\\\\Scripts\\\\ludwig experiment --data_csv '\r\n 'eng_incompleteness2.csv --model_definition_file '\r\n 'sent_complete_model_definition_continuous.yaml')\r\ndataset_type: 'eng_incompleteness2.csv'\r\nmodel_definition: {   'combiner': {'type': 'concat'},\r\n    'input_features': [   {   'encoder': 'parallel_cnn',\r\n                              'level': 'word',\r\n                              'name': 'English',\r\n                              'tied_weights': None,\r\n                              'type': 'text'}],\r\n    'output_features': [   {   'dependencies': [],\r\n                               'loss': {   'type': 'mean_squared_error',\r\n                                           'weight': 1},\r\n                               'name': 'Incompleteness',\r\n                               'reduce_dependencies': 'sum',\r\n                               'reduce_input': 'sum',\r\n                               'type': 'numerical',\r\n                               'weight': 1}],\r\n    'preprocessing': {   'bag': {   'fill_value': '',\r\n                                    'format': 'space',\r\n                                    'lowercase': 10000,\r\n                                    'missing_value_strategy': 'fill_with_const',\r\n\r\n                                    'most_common': False},\r\n                         'binary': {   'fill_value': 0,\r\n                                       'missing_value_strategy': 'fill_with_cons\r\nt'},\r\n                         'category': {   'fill_value': '<UNK>',\r\n                                         'lowercase': False,\r\n                                         'missing_value_strategy': 'fill_with_co\r\nnst',\r\n                                         'most_common': 10000},\r\n                         'force_split': False,\r\n                         'image': {'missing_value_strategy': 'backfill'},\r\n                         'numerical': {   'fill_value': 0,\r\n                                          'missing_value_strategy': 'fill_with_c\r\nonst'},\r\n                         'sequence': {   'fill_value': '',\r\n                                         'format': 'space',\r\n                                         'lowercase': False,\r\n                                         'missing_value_strategy': 'fill_with_co\r\nnst',\r\n                                         'most_common': 20000,\r\n                                         'padding': 'right',\r\n                                         'padding_symbol': '<PAD>',\r\n                                         'sequence_length_limit': 256,\r\n                                         'unknown_symbol': '<UNK>'},\r\n                         'set': {   'fill_value': '',\r\n                                    'format': 'space',\r\n                                    'lowercase': False,\r\n                                    'missing_value_strategy': 'fill_with_const',\r\n\r\n                                    'most_common': 10000},\r\n                         'split_probabilities': (0.7, 0.1, 0.2),\r\n                         'stratify': None,\r\n                         'text': {   'char_format': 'characters',\r\n                                     'char_most_common': 70,\r\n                                     'char_sequence_length_limit': 1024,\r\n                                     'fill_value': '',\r\n                                     'lowercase': True,\r\n                                     'missing_value_strategy': 'fill_with_const'\r\n,\r\n                                     'padding': 'right',\r\n                                     'padding_symbol': '<PAD>',\r\n                                     'unknown_symbol': '<UNK>',\r\n                                     'word_format': 'space_punct',\r\n                                     'word_most_common': 20000,\r\n                                     'word_sequence_length_limit': 256},\r\n                         'timeseries': {   'fill_value': '',\r\n                                           'format': 'space',\r\n                                           'missing_value_strategy': 'fill_with_\r\nconst',\r\n                                           'padding': 'right',\r\n                                           'padding_value': 0,\r\n                                           'timeseries_length_limit': 256}},\r\n    'training': {   'batch_size': 128,\r\n                    'bucketing_field': None,\r\n                    'decay': False,\r\n                    'decay_rate': 0.96,\r\n                    'decay_steps': 10000,\r\n                    'dropout_rate': 0.0,\r\n                    'early_stop': 3,\r\n                    'epochs': 200,\r\n                    'gradient_clipping': None,\r\n                    'increase_batch_size_on_plateau': 0,\r\n                    'increase_batch_size_on_plateau_max': 512,\r\n                    'increase_batch_size_on_plateau_patience': 5,\r\n                    'increase_batch_size_on_plateau_rate': 2,\r\n                    'learning_rate': 0.001,\r\n                    'learning_rate_warmup_epochs': 5,\r\n                    'optimizer': {   'beta1': 0.9,\r\n                                     'beta2': 0.999,\r\n                                     'epsilon': 1e-08,\r\n                                     'type': 'adam'},\r\n                    'reduce_learning_rate_on_plateau': 0,\r\n                    'reduce_learning_rate_on_plateau_patience': 5,\r\n                    'reduce_learning_rate_on_plateau_rate': 0.5,\r\n                    'regularization_lambda': 0,\r\n                    'regularizer': 'l2',\r\n                    'staircase': False,\r\n                    'validation_field': 'combined',\r\n                    'validation_measure': 'loss'}}\r\n\r\nUsing full raw csv, no hdf5 and json file with the same name have been found\r\nBuilding dataset (it may take a while)\r\nLoading NLP pipeline\r\nf:\\programdata\\anaconda3\\lib\\site-packages\\ludwig\\features\\numerical_feature.py:\r\n63: FutureWarning: Method .as_matrix will be removed in a future version. Use .v\r\nalues instead.\r\n  np.float32).as_matrix()\r\nWriting dataset\r\nTraceback (most recent call last):\r\n  File \"f:\\programdata\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n\r\n    \"__main__\", mod_spec)\r\n  File \"f:\\programdata\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"F:\\ProgramData\\Anaconda3\\Scripts\\ludwig.exe\\__main__.py\", line 9, in <mo\r\ndule>\r\n  File \"f:\\programdata\\anaconda3\\lib\\site-packages\\ludwig\\cli.py\", line 86, in m\r\nain\r\n    CLI()\r\n  File \"f:\\programdata\\anaconda3\\lib\\site-packages\\ludwig\\cli.py\", line 64, in _\r\n_init__\r\n    getattr(self, args.command)()\r\n  File \"f:\\programdata\\anaconda3\\lib\\site-packages\\ludwig\\cli.py\", line 67, in e\r\nxperiment\r\n    experiment.cli(sys.argv[2:])\r\n  File \"f:\\programdata\\anaconda3\\lib\\site-packages\\ludwig\\experiment.py\", line 5\r\n48, in cli\r\n    experiment(**vars(args))\r\n  File \"f:\\programdata\\anaconda3\\lib\\site-packages\\ludwig\\experiment.py\", line 2\r\n34, in experiment\r\n    random_seed=random_seed\r\n  File \"f:\\programdata\\anaconda3\\lib\\site-packages\\ludwig\\data\\preprocessing.py\"\r\n, line 461, in preprocess_for_training\r\n    data_utils.save_hdf5(data_hdf5_fp, data, train_set_metadata)\r\n  File \"f:\\programdata\\anaconda3\\lib\\site-packages\\ludwig\\utils\\data_utils.py\",\r\nline 99, in save_hdf5\r\n    dataset = h5_file.create_dataset(key, data=value)\r\n  File \"f:\\programdata\\anaconda3\\lib\\site-packages\\h5py\\_hl\\group.py\", line 106,\r\n in create_dataset\r\n    dsid = dataset.make_new_dset(self, shape, dtype, data, **kwds)\r\n  File \"f:\\programdata\\anaconda3\\lib\\site-packages\\h5py\\_hl\\dataset.py\", line 14\r\n3, in make_new_dset\r\n    dset_id.write(h5s.ALL, h5s.ALL, data)\r\n  File \"h5py\\_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\r\n  File \"h5py\\_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\r\n  File \"h5py\\h5d.pyx\", line 221, in h5py.h5d.DatasetID.write\r\n  File \"h5py\\_proxy.pyx\", line 132, in h5py._proxy.dset_rw\r\n  File \"h5py\\_proxy.pyx\", line 93, in h5py._proxy.H5PY_H5Dwrite\r\nOSError: Can't prepare for writing data (file write failed: time = Thu Feb 28 02\r\n:52:33 2019\r\n, filename = 'eng_incompleteness2.hdf5', file descriptor = 4, errno = 22, error\r\nmessage = 'Invalid argument', buf = 000000BB97EE4031, total write size = 1477792\r\n7695, bytes this sub-write = 2147483647, bytes actually written = 18446744073709\r\n551615, offset = 32212256753)\r\n","closed_by":{"login":"w4nderlust","id":349256,"node_id":"MDQ6VXNlcjM0OTI1Ng==","avatar_url":"https://avatars.githubusercontent.com/u/349256?v=4","gravatar_id":"","url":"https://api.github.com/users/w4nderlust","html_url":"https://github.com/w4nderlust","followers_url":"https://api.github.com/users/w4nderlust/followers","following_url":"https://api.github.com/users/w4nderlust/following{/other_user}","gists_url":"https://api.github.com/users/w4nderlust/gists{/gist_id}","starred_url":"https://api.github.com/users/w4nderlust/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/w4nderlust/subscriptions","organizations_url":"https://api.github.com/users/w4nderlust/orgs","repos_url":"https://api.github.com/users/w4nderlust/repos","events_url":"https://api.github.com/users/w4nderlust/events{/privacy}","received_events_url":"https://api.github.com/users/w4nderlust/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/150/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/150/timeline","performed_via_github_app":null,"state_reason":"completed"}