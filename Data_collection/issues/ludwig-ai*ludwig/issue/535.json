{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/535","repository_url":"https://api.github.com/repos/ludwig-ai/ludwig","labels_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/535/labels{/name}","comments_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/535/comments","events_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/535/events","html_url":"https://github.com/ludwig-ai/ludwig/issues/535","id":506008617,"node_id":"MDU6SXNzdWU1MDYwMDg2MTc=","number":535,"title":"CUDA_ERROR_OUT_OF_MEMORY: out of memory","user":{"login":"yu-iskw","id":1523515,"node_id":"MDQ6VXNlcjE1MjM1MTU=","avatar_url":"https://avatars.githubusercontent.com/u/1523515?v=4","gravatar_id":"","url":"https://api.github.com/users/yu-iskw","html_url":"https://github.com/yu-iskw","followers_url":"https://api.github.com/users/yu-iskw/followers","following_url":"https://api.github.com/users/yu-iskw/following{/other_user}","gists_url":"https://api.github.com/users/yu-iskw/gists{/gist_id}","starred_url":"https://api.github.com/users/yu-iskw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yu-iskw/subscriptions","organizations_url":"https://api.github.com/users/yu-iskw/orgs","repos_url":"https://api.github.com/users/yu-iskw/repos","events_url":"https://api.github.com/users/yu-iskw/events{/privacy}","received_events_url":"https://api.github.com/users/yu-iskw/received_events","type":"User","site_admin":false},"labels":[{"id":1174068775,"node_id":"MDU6TGFiZWwxMTc0MDY4Nzc1","url":"https://api.github.com/repos/ludwig-ai/ludwig/labels/waiting%20for%20answer","name":"waiting for answer","color":"fff36b","default":false,"description":"Further information is requested"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2019-10-11T18:58:50Z","updated_at":"2020-10-06T09:49:03Z","closed_at":"2020-10-03T23:47:40Z","author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\nI tried to build a multi-task model whose task are something like autoencoder and classification at work.\r\n\r\nIt seems that `allow_growth` is set to `True` appropriately. I am not sure why it happend.\r\nhttps://github.com/uber/ludwig/blob/2b4d53a6180187d383b43742b3389213ddbc29d8/ludwig/utils/tf_utils.py#L43\r\n\r\n**To Reproduce**\r\n```\r\ntraining:\r\n  batch_size: 64\r\n  epochs: 100\r\n  early_stop: 10\r\n\r\npreprocessing:\r\n  text:\r\n    lowercase: true\r\n    most_common_word: 50000\r\n    word_sequence_length_limit: 10\r\n\r\ninput_features:\r\n  -\r\n    name: name\r\n    type: text\r\n    level: word\r\n    encoder: rnn\r\n    cell_type: lstm\r\n    reduce_output: null\r\n    bidirectional: true\r\n    preprocessing:\r\n      word_format: english_tokenize\r\n\r\noutput_features:\r\n  -\r\n    name: name_answer\r\n    type: text\r\n    level: word\r\n    decoder: generator\r\n    cell_type: lstm\r\n    attention: bahdanau\r\n    loss:\r\n      type: sampled_softmax_cross_entropy\r\n    preprocessing:\r\n      word_format: english_tokenize\r\n  -\r\n    name: category_id_answer\r\n    type: category\r\n\r\n```\r\n\r\n**Expected behavior**\r\n\r\n\r\n**Error logs**\r\n```\r\nEvaluation:  95%|███████████████████████████████████████████████████████▏  | 37171/39063 [27:31<01:23, 22.57it/s]2019-10-11 08:31:20.674222: E tensorflow/stream_executor/cuda/cuda_driver.cc:890] failed to alloc 34357641216 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-10-11 08:31:20.674277: W ./tensorflow/core/common_runtime/gpu/gpu_host_allocator.h:44] could not allocate pinned host memory of size: 34357641216\r\n2019-10-11 08:31:20.674321: E tensorflow/stream_executor/cuda/cuda_driver.cc:890] failed to alloc 30921875456 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-10-11 08:31:20.674335: W ./tensorflow/core/common_runtime/gpu/gpu_host_allocator.h:44] could not allocate pinned host memory of size: 30921875456\r\n2019-10-11 08:31:20.674365: E tensorflow/stream_executor/cuda/cuda_driver.cc:890] failed to alloc 27829686272 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-10-11 08:31:20.674375: W ./tensorflow/core/common_runtime/gpu/gpu_host_allocator.h:44] could not allocate pinned host memory of size: 27829686272\r\n2019-10-11 08:31:20.674402: E tensorflow/stream_executor/cuda/cuda_driver.cc:890] failed to alloc 25046716416 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-10-11 08:31:20.674412: W ./tensorflow/core/common_runtime/gpu/gpu_host_allocator.h:44] could not allocate pinned host memory of size: 25046716416\r\n2019-10-11 08:31:20.674440: E tensorflow/stream_executor/cuda/cuda_driver.cc:890] failed to alloc 22542045184 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-10-11 08:31:20.674449: W ./tensorflow/core/common_runtime/gpu/gpu_host_allocator.h:44] could not allocate pinned host memory of size: 22542045184\r\n2019-10-11 08:31:20.674476: E tensorflow/stream_executor/cuda/cuda_driver.cc:890] failed to alloc 20287840256 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-10-11 08:31:20.674487: W ./tensorflow/core/common_runtime/gpu/gpu_host_allocator.h:44] could not allocate pinned host memory of size: 20287840256\r\n2019-10-11 08:31:27.348272: E tensorflow/stream_executor/cuda/cuda_driver.cc:890] failed to alloc 18259056640 bytes on host: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2019-10-11 08:31:27.348338: W ./tensorflow/core/common_runtime/gpu/gpu_host_allocator.h:44] could not allocate pinned host memory of size: 18259056640\r\nKilled\r\n```\r\n\r\n**Environment (please complete the following information):**\r\n - OS: Ubuntu \r\n - Version 18.04.2 LTS\r\n- Python version: 3.6.8\r\n- Ludwig version: 0.2\r\n- GPU: Nvidia V100 x 1\r\n","closed_by":{"login":"w4nderlust","id":349256,"node_id":"MDQ6VXNlcjM0OTI1Ng==","avatar_url":"https://avatars.githubusercontent.com/u/349256?v=4","gravatar_id":"","url":"https://api.github.com/users/w4nderlust","html_url":"https://github.com/w4nderlust","followers_url":"https://api.github.com/users/w4nderlust/followers","following_url":"https://api.github.com/users/w4nderlust/following{/other_user}","gists_url":"https://api.github.com/users/w4nderlust/gists{/gist_id}","starred_url":"https://api.github.com/users/w4nderlust/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/w4nderlust/subscriptions","organizations_url":"https://api.github.com/users/w4nderlust/orgs","repos_url":"https://api.github.com/users/w4nderlust/repos","events_url":"https://api.github.com/users/w4nderlust/events{/privacy}","received_events_url":"https://api.github.com/users/w4nderlust/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/535/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/535/timeline","performed_via_github_app":null,"state_reason":"completed"}