{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1441","repository_url":"https://api.github.com/repos/ludwig-ai/ludwig","labels_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1441/labels{/name}","comments_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1441/comments","events_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1441/events","html_url":"https://github.com/ludwig-ai/ludwig/issues/1441","id":1039803114,"node_id":"I_kwDOCbx2hs49-iLq","number":1441,"title":"[ray] Fix dynamic resource allocation with RayDatasets","user":{"login":"tgaddair","id":1742912,"node_id":"MDQ6VXNlcjE3NDI5MTI=","avatar_url":"https://avatars.githubusercontent.com/u/1742912?v=4","gravatar_id":"","url":"https://api.github.com/users/tgaddair","html_url":"https://github.com/tgaddair","followers_url":"https://api.github.com/users/tgaddair/followers","following_url":"https://api.github.com/users/tgaddair/following{/other_user}","gists_url":"https://api.github.com/users/tgaddair/gists{/gist_id}","starred_url":"https://api.github.com/users/tgaddair/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tgaddair/subscriptions","organizations_url":"https://api.github.com/users/tgaddair/orgs","repos_url":"https://api.github.com/users/tgaddair/repos","events_url":"https://api.github.com/users/tgaddair/events{/privacy}","received_events_url":"https://api.github.com/users/tgaddair/received_events","type":"User","site_admin":false},"labels":[{"id":1174068769,"node_id":"MDU6TGFiZWwxMTc0MDY4NzY5","url":"https://api.github.com/repos/ludwig-ai/ludwig/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-10-29T17:54:56Z","updated_at":"2022-01-25T00:09:28Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"Seems there is a deadlock that arises when using Ray Tune with dynamic resource allocation + RayDatasets. When we set `cache_format = 'parquet'`, everything works fine, but when we use the new default `cache_format = 'ray'`, trials will hang, presumably because RayDatasets are locking out some of the resources needed by dynamic allocation.\r\n\r\nEven if we bump up the number of resources in the cluster, we end up in the same place:\r\n\r\n```\r\n2021-10-29 12:55:53,822\tWARNING worker.py:1227 -- The actor or task with ID eae16da7b2a06f615e017e6d60f6e1ebc6be08064045c345 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\r\nRequired resources for this actor or task: {CPU_group_098d048e4d6df88103b3ad1b5a1e6f44: 1.000000}\r\nAvailable resources on this node: {5.998000/8.000000 CPU, 292485120.019531 GiB/292485120.019531 GiB memory, 7680000.000000 GiB/7680000.000000 GiB object_store_memory, 1.000000/1.000000 CPU_group_1_f26449396dc25d88645e711373b91bd4, 1000.000000/1000.000000 bundle_group_1_098d048e4d6df88103b3ad1b5a1e6f44, 0.000000/0.001000 CPU_group_0_098d048e4d6df88103b3ad1b5a1e6f44, 1.000000/1.000000 CPU_group_1_098d048e4d6df88103b3ad1b5a1e6f44, 2000.000000/2000.000000 bundle_group_098d048e4d6df88103b3ad1b5a1e6f44, 1000.000000/1000.000000 bundle_group_0_098d048e4d6df88103b3ad1b5a1e6f44, 1000.000000/1000.000000 bundle_group_0_f26449396dc25d88645e711373b91bd4, 0.000000/1.001000 CPU_group_098d048e4d6df88103b3ad1b5a1e6f44, 0.000000/0.001000 CPU_group_0_f26449396dc25d88645e711373b91bd4, 1.000000/1.000000 node:192.168.4.54, 2000.000000/2000.000000 bundle_group_f26449396dc25d88645e711373b91bd4, 0.000000/1.001000 CPU_group_f26449396dc25d88645e711373b91bd4, 1000.000000/1000.000000 bundle_group_1_f26449396dc25d88645e711373b91bd4}\r\nIn total there are 6 pending tasks and 0 pending actors on this node.\r\n== Status ==\r\nMemory usage on this node: 9.8/16.0 GiB\r\nUsing FIFO scheduling algorithm.\r\nResources requested: 2.002/8 CPUs, 0/0 GPUs, 0.0/5.58 GiB heap, 0.0/0.15 GiB objects\r\nResult logdir: /tmp/mock-client-8fb5/trainable_func_fiYzhHE\r\nNumber of trials: 2/2 (2 RUNNING)\r\n+-------------------+----------+-------+------------------------+------------------------------+--------------------------+\r\n| Trial name        | status   | loc   |   binary_46001.fc_size |   binary_46001.num_fc_layers |   training.learning_rate |\r\n|-------------------+----------+-------+------------------------+------------------------------+--------------------------|\r\n| trial_23bf9_00000 | RUNNING  |       |                    124 |                            4 |               0.00561152 |\r\n| trial_23bf9_00001 | RUNNING  |       |                    220 |                            2 |               0.0291064  |\r\n+-------------------+----------+-------+------------------------+------------------------------+--------------------------+\r\n```","closed_by":null,"reactions":{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1441/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1441/timeline","performed_via_github_app":null,"state_reason":null}