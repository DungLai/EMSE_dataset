{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1185","repository_url":"https://api.github.com/repos/ludwig-ai/ludwig","labels_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1185/labels{/name}","comments_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1185/comments","events_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1185/events","html_url":"https://github.com/ludwig-ai/ludwig/issues/1185","id":901388906,"node_id":"MDU6SXNzdWU5MDEzODg5MDY=","number":1185,"title":"Latest master expects a test.hdf5 no matter what","user":{"login":"carlogrisetti","id":4464640,"node_id":"MDQ6VXNlcjQ0NjQ2NDA=","avatar_url":"https://avatars.githubusercontent.com/u/4464640?v=4","gravatar_id":"","url":"https://api.github.com/users/carlogrisetti","html_url":"https://github.com/carlogrisetti","followers_url":"https://api.github.com/users/carlogrisetti/followers","following_url":"https://api.github.com/users/carlogrisetti/following{/other_user}","gists_url":"https://api.github.com/users/carlogrisetti/gists{/gist_id}","starred_url":"https://api.github.com/users/carlogrisetti/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/carlogrisetti/subscriptions","organizations_url":"https://api.github.com/users/carlogrisetti/orgs","repos_url":"https://api.github.com/users/carlogrisetti/repos","events_url":"https://api.github.com/users/carlogrisetti/events{/privacy}","received_events_url":"https://api.github.com/users/carlogrisetti/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-05-25T21:26:33Z","updated_at":"2021-06-02T01:37:07Z","closed_at":"2021-06-02T01:37:07Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"(hahahahaha I opened this issue on another project, and was wondering why it took so long for you guys to respond, since you're really quick usually hahah)\r\n\r\nTraining from latest master, with a force_split = False and the valued split column in the dataset.csv file.\r\nIf you only specify split 0 and 1 (to have only the training and validation dataset), this works correctly when no .hdf5 is present and Ludwig has to generate it the first time. Ludwig correctly generates a training.hdf5 and validation.hdf5, but no test.hdf5 (since no test split is present)\r\n\r\nOnce you want to do another training without changing the dataset and\\or data-related parameters in the config.yaml, Ludwig should use the already present hdf5 files. It tries to, but it is still looking for the test.hdf5 that was never generated in the first place.\r\n\r\nFound cached dataset and meta.json with the same filename of the dataset, using them instead\r\nUsing full hdf5 and json\r\nLoading data from: dataset.training.hdf5\r\nLoading data from: dataset.validation.hdf5\r\nLoading data from: dataset.test.hdf5 `<--- this should not happen, since there is no test dataset`\r\nTraceback (most recent call last):\r\nFile \"c:\\program files\\python38\\lib\\runpy.py\", line 192, in _run_module_as_main\r\nreturn _run_code(code, main_globals, None,\r\nFile \"c:\\program files\\python38\\lib\\runpy.py\", line 85, in run_code\r\nexec(code, run_globals)\r\nFile \"C:\\Program Files\\Python38\\Scripts\\ludwig.exe_main.py\", line 7, in\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\ludwig\\cli.py\", line 146, in main\r\nCLI()\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\ludwig\\cli.py\", line 72, in init\r\ngetattr(self, args.command)()\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\ludwig\\cli.py\", line 77, in train\r\ntrain.cli(sys.argv[2:])\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\ludwig\\train.py\", line 412, in cli\r\ntrain_cli(**vars(args))\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\ludwig\\train.py\", line 180, in train_cli\r\nmodel.train(\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\ludwig\\api.py\", line 394, in train\r\npreprocessed_data = self.preprocess(\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\ludwig\\api.py\", line 1263, in preprocess\r\npreprocessed_data = preprocess_for_training(\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\ludwig\\data\\preprocessing.py\", line 1400, in preprocess_for_training\r\nprocessed = data_format_processor.prepare_processed_data(\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\ludwig\\data\\preprocessing.py\", line 1015, in prepare_processed_data\r\ntest_set = load_hdf5(test_set,\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\ludwig\\data\\preprocessing.py\", line 1307, in load_hdf5\r\ndataset = data_utils.load_hdf5(hdf5_file_path)\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\ludwig\\utils\\data_utils.py\", line 276, in load_hdf5\r\nwith download_h5(data_fp) as hdf5_data:\r\nFile \"c:\\program files\\python38\\lib\\contextlib.py\", line 113, in enter\r\nreturn next(self.gen)\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\ludwig\\utils\\fs_utils.py\", line 105, in download_h5\r\nlocal_path = fsspec.open_local(url)\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\fsspec\\core.py\", line 463, in open_local\r\nwith of as files:\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\fsspec\\core.py\", line 184, in enter\r\nreturn [s.enter() for s in self]\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\fsspec\\core.py\", line 184, in\r\nreturn [s.enter() for s in self]\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\fsspec\\core.py\", line 102, in enter\r\nf = self.fs.open(self.path, mode=mode)\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\fsspec\\spec.py\", line 942, in open\r\nf = self._open(\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\fsspec\\implementations\\local.py\", line 120, in _open\r\nreturn LocalFileOpener(path, mode, fs=self, **kwargs)\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\fsspec\\implementations\\local.py\", line 202, in init\r\nself._open()\r\nFile \"c:\\program files\\python38\\lib\\site-packages\\fsspec\\implementations\\local.py\", line 207, in _open\r\nself.f = open(self.path, mode=self.mode)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'C:/some_path/dataset.test.hdf5'\r\n\r\n\r\nOf course a workaround to this is to just provide a single row (even duplicate) in the dataset.csv file with a split of 2, so that the test.hdf5 is generated and then can be loaded again in the future.\r\n\r\nOne thing that might not be obvious: I am not passing separate splits from the commandline, but using the --dataset dataset.csv parameter which contains splits 0 and 1 only","closed_by":{"login":"w4nderlust","id":349256,"node_id":"MDQ6VXNlcjM0OTI1Ng==","avatar_url":"https://avatars.githubusercontent.com/u/349256?v=4","gravatar_id":"","url":"https://api.github.com/users/w4nderlust","html_url":"https://github.com/w4nderlust","followers_url":"https://api.github.com/users/w4nderlust/followers","following_url":"https://api.github.com/users/w4nderlust/following{/other_user}","gists_url":"https://api.github.com/users/w4nderlust/gists{/gist_id}","starred_url":"https://api.github.com/users/w4nderlust/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/w4nderlust/subscriptions","organizations_url":"https://api.github.com/users/w4nderlust/orgs","repos_url":"https://api.github.com/users/w4nderlust/repos","events_url":"https://api.github.com/users/w4nderlust/events{/privacy}","received_events_url":"https://api.github.com/users/w4nderlust/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1185/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1185/timeline","performed_via_github_app":null,"state_reason":"completed"}