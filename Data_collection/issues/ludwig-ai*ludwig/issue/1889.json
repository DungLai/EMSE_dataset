{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1889","repository_url":"https://api.github.com/repos/ludwig-ai/ludwig","labels_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1889/labels{/name}","comments_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1889/comments","events_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1889/events","html_url":"https://github.com/ludwig-ai/ludwig/issues/1889","id":1197944751,"node_id":"I_kwDOCbx2hs5HZy-v","number":1889,"title":"bug: TypeError for float32 in get_dataset_cache when making prediction","user":{"login":"brightsparc","id":360368,"node_id":"MDQ6VXNlcjM2MDM2OA==","avatar_url":"https://avatars.githubusercontent.com/u/360368?v=4","gravatar_id":"","url":"https://api.github.com/users/brightsparc","html_url":"https://github.com/brightsparc","followers_url":"https://api.github.com/users/brightsparc/followers","following_url":"https://api.github.com/users/brightsparc/following{/other_user}","gists_url":"https://api.github.com/users/brightsparc/gists{/gist_id}","starred_url":"https://api.github.com/users/brightsparc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/brightsparc/subscriptions","organizations_url":"https://api.github.com/users/brightsparc/orgs","repos_url":"https://api.github.com/users/brightsparc/repos","events_url":"https://api.github.com/users/brightsparc/events{/privacy}","received_events_url":"https://api.github.com/users/brightsparc/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2022-04-08T23:53:38Z","updated_at":"2022-04-09T03:48:14Z","closed_at":"2022-04-09T03:48:14Z","author_association":"COLLABORATOR","active_lock_reason":null,"body":"**Describe the bug**\r\nWhen predicting against a dictionary that contains python float32 values the [backend.cache.get_dataset_cache(config, dataset)](https://github.com/ludwig-ai/ludwig/blob/master/ludwig/data/preprocessing.py#L1764) returns an error  `TypeError: Object of type float32 is not JSON serializable`\r\n \r\nError stack: \r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nInput In [11], in <cell line: 1>()\r\n----> 1 predictions, _ = model.predict(dataset=test_dict, data_format=dict, return_type=dict)\r\n      2 predictions[target]\r\n\r\nFile ~/projects/ludwig/ludwig/api.py:732, in LudwigModel.predict(self, dataset, data_format, split, batch_size, skip_save_unprocessed_output, skip_save_predictions, output_directory, return_type, **kwargs)\r\n    730 # preprocessing\r\n    731 logger.debug(\"Preprocessing\")\r\n--> 732 dataset, _ = preprocess_for_prediction(\r\n    733     self.config,\r\n    734     dataset=dataset,\r\n    735     training_set_metadata=self.training_set_metadata,\r\n    736     data_format=data_format,\r\n    737     split=split,\r\n    738     include_outputs=False,\r\n    739     backend=self.backend,\r\n    740     callbacks=self.callbacks,\r\n    741 )\r\n    743 logger.debug(\"Predicting\")\r\n    744 with self.backend.create_predictor(self.model, batch_size=batch_size) as predictor:\r\n\r\nFile ~/projects/ludwig/ludwig/data/preprocessing.py:1764, in preprocess_for_prediction(config, dataset, training_set_metadata, data_format, split, include_outputs, backend, callbacks)\r\n   1761 cached = False\r\n   1763 dataset = wrap(dataset)\r\n-> 1764 cache = backend.cache.get_dataset_cache(config, dataset)\r\n   1765 dataset = dataset.unwrap()\r\n   1767 training_set = test_set = validation_set = None\r\n\r\nFile ~/projects/ludwig/ludwig/data/cache/manager.py:95, in CacheManager.get_dataset_cache(self, config, dataset, training_set, test_set, validation_set)\r\n     86 def get_dataset_cache(\r\n     87     self,\r\n     88     config: dict,\r\n   (...)\r\n     92     validation_set: Optional[CacheableDataset] = None,\r\n     93 ) -> DatasetCache:\r\n     94     if dataset is not None:\r\n---> 95         key = self.get_cache_key(dataset, config)\r\n     96         cache_map = {\r\n     97             META: self.get_cache_path(dataset, key, META, \"json\"),\r\n     98             TRAINING: self.get_cache_path(dataset, key, TRAINING),\r\n     99             TEST: self.get_cache_path(dataset, key, TEST),\r\n    100             VALIDATION: self.get_cache_path(dataset, key, VALIDATION),\r\n    101         }\r\n    102         return DatasetCache(config, key, cache_map, self._dataset_manager)\r\n\r\nFile ~/projects/ludwig/ludwig/data/cache/manager.py:114, in CacheManager.get_cache_key(self, dataset, config)\r\n    113 def get_cache_key(self, dataset: CacheableDataset, config: dict) -> str:\r\n--> 114     return calculate_checksum(dataset, config)\r\n\r\nFile ~/projects/ludwig/ludwig/data/cache/util.py:17, in calculate_checksum(original_dataset, config)\r\n      8 features = config.get(\"input_features\", []) + config.get(\"output_features\", []) + config.get(\"features\", [])\r\n      9 info = {\r\n     10     \"ludwig_version\": ludwig.globals.LUDWIG_VERSION,\r\n     11     \"dataset_checksum\": original_dataset.checksum,\r\n   (...)\r\n     15     \"feature_preprocessing\": [feature.get(PREPROCESSING, {}) for feature in features],\r\n     16 }\r\n---> 17 return hash_dict(info, max_length=None).decode(\"ascii\")\r\n\r\nFile ~/projects/ludwig/ludwig/utils/misc_utils.py:128, in hash_dict(d, max_length)\r\n    127 def hash_dict(d: dict, max_length: Union[int, None] = 6) -> bytes:\r\n--> 128     s = json.dumps(d, sort_keys=True, ensure_ascii=True)\r\n    129     h = hashlib.md5(s.encode())\r\n    130     d = h.digest()\r\n\r\nFile ~/mambaforge/envs/base38/lib/python3.8/json/__init__.py:234, in dumps(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\r\n    232 if cls is None:\r\n    233     cls = JSONEncoder\r\n--> 234 return cls(\r\n    235     skipkeys=skipkeys, ensure_ascii=ensure_ascii,\r\n    236     check_circular=check_circular, allow_nan=allow_nan, indent=indent,\r\n    237     separators=separators, default=default, sort_keys=sort_keys,\r\n    238     **kw).encode(obj)\r\n\r\nFile ~/mambaforge/envs/base38/lib/python3.8/json/encoder.py:199, in JSONEncoder.encode(self, o)\r\n    195         return encode_basestring(o)\r\n    196 # This doesn't pass the iterator directly to ''.join() because the\r\n    197 # exceptions aren't as detailed.  The list call should be roughly\r\n    198 # equivalent to the PySequence_Fast that ''.join() would do.\r\n--> 199 chunks = self.iterencode(o, _one_shot=True)\r\n    200 if not isinstance(chunks, (list, tuple)):\r\n    201     chunks = list(chunks)\r\n\r\nFile ~/mambaforge/envs/base38/lib/python3.8/json/encoder.py:257, in JSONEncoder.iterencode(self, o, _one_shot)\r\n    252 else:\r\n    253     _iterencode = _make_iterencode(\r\n    254         markers, self.default, _encoder, self.indent, floatstr,\r\n    255         self.key_separator, self.item_separator, self.sort_keys,\r\n    256         self.skipkeys, _one_shot)\r\n--> 257 return _iterencode(o, 0)\r\n\r\nFile ~/mambaforge/envs/base38/lib/python3.8/json/encoder.py:179, in JSONEncoder.default(self, o)\r\n    160 def default(self, o):\r\n    161     \"\"\"Implement this method in a subclass such that it returns\r\n    162     a serializable object for ``o``, or calls the base implementation\r\n    163     (to raise a ``TypeError``).\r\n   (...)\r\n    177 \r\n    178     \"\"\"\r\n--> 179     raise TypeError(f'Object of type {o.__class__.__name__} '\r\n    180                     f'is not JSON serializable')\r\n\r\nTypeError: Object of type float32 is not JSON serializable\r\n```\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n\r\n1. Create a train a titanic model\r\n2. Make prediction using dict format like below:\r\n\r\n```\r\ntest_dict = [{'Pclass': 3,\r\n  'Sex': 'male',\r\n  'Age': 34.5,\r\n  'SibSp': 0,\r\n  'Parch': 0,\r\n  'Fare': 7.8292,\r\n  'Embarked': 'Q'}]\r\nmodel.predict(dataset=test_dict, data_format=dict, return_type=dict)\r\n```\r\n\r\n**Expected behavior**\r\nExpected that the prediction results will be returned.\r\n\r\n**Environment (please complete the following information):**\r\n\r\n- OS: osx-arm64 \r\n- Version: 12.2.1 (Monterey)\r\n- Python versionL: py38\r\n- Ludwig version: master Fri Apr 8 (commit b86c9ca7545eee0fddfb6b4001eec2a2cd4ad40b)\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n","closed_by":{"login":"brightsparc","id":360368,"node_id":"MDQ6VXNlcjM2MDM2OA==","avatar_url":"https://avatars.githubusercontent.com/u/360368?v=4","gravatar_id":"","url":"https://api.github.com/users/brightsparc","html_url":"https://github.com/brightsparc","followers_url":"https://api.github.com/users/brightsparc/followers","following_url":"https://api.github.com/users/brightsparc/following{/other_user}","gists_url":"https://api.github.com/users/brightsparc/gists{/gist_id}","starred_url":"https://api.github.com/users/brightsparc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/brightsparc/subscriptions","organizations_url":"https://api.github.com/users/brightsparc/orgs","repos_url":"https://api.github.com/users/brightsparc/repos","events_url":"https://api.github.com/users/brightsparc/events{/privacy}","received_events_url":"https://api.github.com/users/brightsparc/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1889/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/1889/timeline","performed_via_github_app":null,"state_reason":"completed"}