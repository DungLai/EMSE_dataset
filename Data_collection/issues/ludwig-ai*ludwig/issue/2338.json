{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/2338","repository_url":"https://api.github.com/repos/ludwig-ai/ludwig","labels_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/2338/labels{/name}","comments_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/2338/comments","events_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/2338/events","html_url":"https://github.com/ludwig-ai/ludwig/issues/2338","id":1326218870,"node_id":"I_kwDOCbx2hs5PDH52","number":2338,"title":"Expose method to pick metrics for output features","user":{"login":"arnavgarg1","id":106701836,"node_id":"U_kgDOBlwkDA","avatar_url":"https://avatars.githubusercontent.com/u/106701836?v=4","gravatar_id":"","url":"https://api.github.com/users/arnavgarg1","html_url":"https://github.com/arnavgarg1","followers_url":"https://api.github.com/users/arnavgarg1/followers","following_url":"https://api.github.com/users/arnavgarg1/following{/other_user}","gists_url":"https://api.github.com/users/arnavgarg1/gists{/gist_id}","starred_url":"https://api.github.com/users/arnavgarg1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arnavgarg1/subscriptions","organizations_url":"https://api.github.com/users/arnavgarg1/orgs","repos_url":"https://api.github.com/users/arnavgarg1/repos","events_url":"https://api.github.com/users/arnavgarg1/events{/privacy}","received_events_url":"https://api.github.com/users/arnavgarg1/received_events","type":"User","site_admin":false},"labels":[{"id":1174068771,"node_id":"MDU6TGFiZWwxMTc0MDY4Nzcx","url":"https://api.github.com/repos/ludwig-ai/ludwig/labels/feature","name":"feature","color":"0377d6","default":false,"description":"New feature or request"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-08-02T18:07:33Z","updated_at":"2022-08-02T18:07:38Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the use case**\r\nIn certain scenarios, not all metrics may actually be useful to compute for a given output feature type. A user may only be interested in a subset of the metrics that are relevant to their problem. Today, Ludwig computes all the metrics for a given output feature type on each epoch, and then again while evaluating and computing overall stats. This can be computationally expensive, particularly in cases where a user is running training and evaluation on a CPU. \r\n\r\n**Describe the solution you'd like**\r\nIt would be great to have a way to expose an optional `metrics` property for output features that takes in a list of metric names to be computed on each epoch and for overall evaluation. That way, a subset of all available metrics can be picked.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/2338/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ludwig-ai/ludwig/issues/2338/timeline","performed_via_github_app":null,"state_reason":null}