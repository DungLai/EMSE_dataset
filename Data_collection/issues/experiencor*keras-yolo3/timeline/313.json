[{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/856391490","html_url":"https://github.com/experiencor/keras-yolo3/issues/313#issuecomment-856391490","issue_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/313","id":856391490,"node_id":"MDEyOklzc3VlQ29tbWVudDg1NjM5MTQ5MA==","user":{"login":"lexuansanh","id":38468965,"node_id":"MDQ6VXNlcjM4NDY4OTY1","avatar_url":"https://avatars.githubusercontent.com/u/38468965?v=4","gravatar_id":"","url":"https://api.github.com/users/lexuansanh","html_url":"https://github.com/lexuansanh","followers_url":"https://api.github.com/users/lexuansanh/followers","following_url":"https://api.github.com/users/lexuansanh/following{/other_user}","gists_url":"https://api.github.com/users/lexuansanh/gists{/gist_id}","starred_url":"https://api.github.com/users/lexuansanh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lexuansanh/subscriptions","organizations_url":"https://api.github.com/users/lexuansanh/orgs","repos_url":"https://api.github.com/users/lexuansanh/repos","events_url":"https://api.github.com/users/lexuansanh/events{/privacy}","received_events_url":"https://api.github.com/users/lexuansanh/received_events","type":"User","site_admin":false},"created_at":"2021-06-08T02:34:32Z","updated_at":"2021-06-08T02:34:32Z","author_association":"NONE","body":"Because you put valid_generator in Model.fit_generator, Then data of valid_generator is augmented same as train_generator. This may affect the valid_generator evaluation. You can use the evaluate() function to evaluate on valid_generator. or tweak in _aug_image() function in BatchGenerator Class so that it doesn't modify the original image of valid data","reactions":{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/856391490/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"lexuansanh","id":38468965,"node_id":"MDQ6VXNlcjM4NDY4OTY1","avatar_url":"https://avatars.githubusercontent.com/u/38468965?v=4","gravatar_id":"","url":"https://api.github.com/users/lexuansanh","html_url":"https://github.com/lexuansanh","followers_url":"https://api.github.com/users/lexuansanh/followers","following_url":"https://api.github.com/users/lexuansanh/following{/other_user}","gists_url":"https://api.github.com/users/lexuansanh/gists{/gist_id}","starred_url":"https://api.github.com/users/lexuansanh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lexuansanh/subscriptions","organizations_url":"https://api.github.com/users/lexuansanh/orgs","repos_url":"https://api.github.com/users/lexuansanh/repos","events_url":"https://api.github.com/users/lexuansanh/events{/privacy}","received_events_url":"https://api.github.com/users/lexuansanh/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/857728633","html_url":"https://github.com/experiencor/keras-yolo3/issues/313#issuecomment-857728633","issue_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/313","id":857728633,"node_id":"MDEyOklzc3VlQ29tbWVudDg1NzcyODYzMw==","user":{"login":"lexuansanh","id":38468965,"node_id":"MDQ6VXNlcjM4NDY4OTY1","avatar_url":"https://avatars.githubusercontent.com/u/38468965?v=4","gravatar_id":"","url":"https://api.github.com/users/lexuansanh","html_url":"https://github.com/lexuansanh","followers_url":"https://api.github.com/users/lexuansanh/followers","following_url":"https://api.github.com/users/lexuansanh/following{/other_user}","gists_url":"https://api.github.com/users/lexuansanh/gists{/gist_id}","starred_url":"https://api.github.com/users/lexuansanh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lexuansanh/subscriptions","organizations_url":"https://api.github.com/users/lexuansanh/orgs","repos_url":"https://api.github.com/users/lexuansanh/repos","events_url":"https://api.github.com/users/lexuansanh/events{/privacy}","received_events_url":"https://api.github.com/users/lexuansanh/received_events","type":"User","site_admin":false},"created_at":"2021-06-09T14:11:22Z","updated_at":"2021-06-09T14:12:28Z","author_association":"NONE","body":"I see few problems here:\r\n1. If you don't aug_image. Training can be overfitting. Because train_Generator is not augmentated. The method is to add 1 argument to the Generator Class. Ex: self.aug = True: Do aug_image (using for train_generator), if self.aug = False: Do not aug_image (Return original image, using for valid_generator).\r\n2. Maybe your Anchors Box does not match the data. Public data with anchors has been carefully calculated by the author through gen_anchors.py. If necessary, the anchor box can be recalculated.\r\n3. It is possible that the evaluate() function does not match your own data. You can check the evaluate() function again and edit it to suit your data.Ex: Check line 83, 84 of evaluate():\r\n`detections = all_detections[i][label]`\r\n`annotations = all_annotations[i][label]`","reactions":{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/857728633/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"lexuansanh","id":38468965,"node_id":"MDQ6VXNlcjM4NDY4OTY1","avatar_url":"https://avatars.githubusercontent.com/u/38468965?v=4","gravatar_id":"","url":"https://api.github.com/users/lexuansanh","html_url":"https://github.com/lexuansanh","followers_url":"https://api.github.com/users/lexuansanh/followers","following_url":"https://api.github.com/users/lexuansanh/following{/other_user}","gists_url":"https://api.github.com/users/lexuansanh/gists{/gist_id}","starred_url":"https://api.github.com/users/lexuansanh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lexuansanh/subscriptions","organizations_url":"https://api.github.com/users/lexuansanh/orgs","repos_url":"https://api.github.com/users/lexuansanh/repos","events_url":"https://api.github.com/users/lexuansanh/events{/privacy}","received_events_url":"https://api.github.com/users/lexuansanh/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/857934104","html_url":"https://github.com/experiencor/keras-yolo3/issues/313#issuecomment-857934104","issue_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/313","id":857934104,"node_id":"MDEyOklzc3VlQ29tbWVudDg1NzkzNDEwNA==","user":{"login":"lexuansanh","id":38468965,"node_id":"MDQ6VXNlcjM4NDY4OTY1","avatar_url":"https://avatars.githubusercontent.com/u/38468965?v=4","gravatar_id":"","url":"https://api.github.com/users/lexuansanh","html_url":"https://github.com/lexuansanh","followers_url":"https://api.github.com/users/lexuansanh/followers","following_url":"https://api.github.com/users/lexuansanh/following{/other_user}","gists_url":"https://api.github.com/users/lexuansanh/gists{/gist_id}","starred_url":"https://api.github.com/users/lexuansanh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lexuansanh/subscriptions","organizations_url":"https://api.github.com/users/lexuansanh/orgs","repos_url":"https://api.github.com/users/lexuansanh/repos","events_url":"https://api.github.com/users/lexuansanh/events{/privacy}","received_events_url":"https://api.github.com/users/lexuansanh/received_events","type":"User","site_admin":false},"created_at":"2021-06-09T18:12:26Z","updated_at":"2021-06-09T18:14:23Z","author_association":"NONE","body":"I see yours iou quite low. I usually get a value of >= 0.8. I usually create anchor box after Generator, because then the bounding boxs are really right to create anchors. you can create many times and choose the one with the biggest iou.\r\nYour data is augmented quite  bit. you can view and remove some augmentation that you think are unnecessary or worsen your train data.","reactions":{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/857934104/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"lexuansanh","id":38468965,"node_id":"MDQ6VXNlcjM4NDY4OTY1","avatar_url":"https://avatars.githubusercontent.com/u/38468965?v=4","gravatar_id":"","url":"https://api.github.com/users/lexuansanh","html_url":"https://github.com/lexuansanh","followers_url":"https://api.github.com/users/lexuansanh/followers","following_url":"https://api.github.com/users/lexuansanh/following{/other_user}","gists_url":"https://api.github.com/users/lexuansanh/gists{/gist_id}","starred_url":"https://api.github.com/users/lexuansanh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lexuansanh/subscriptions","organizations_url":"https://api.github.com/users/lexuansanh/orgs","repos_url":"https://api.github.com/users/lexuansanh/repos","events_url":"https://api.github.com/users/lexuansanh/events{/privacy}","received_events_url":"https://api.github.com/users/lexuansanh/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/858147011","html_url":"https://github.com/experiencor/keras-yolo3/issues/313#issuecomment-858147011","issue_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/313","id":858147011,"node_id":"MDEyOklzc3VlQ29tbWVudDg1ODE0NzAxMQ==","user":{"login":"ghost","id":10137,"node_id":"MDQ6VXNlcjEwMTM3","avatar_url":"https://avatars.githubusercontent.com/u/10137?v=4","gravatar_id":"","url":"https://api.github.com/users/ghost","html_url":"https://github.com/ghost","followers_url":"https://api.github.com/users/ghost/followers","following_url":"https://api.github.com/users/ghost/following{/other_user}","gists_url":"https://api.github.com/users/ghost/gists{/gist_id}","starred_url":"https://api.github.com/users/ghost/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ghost/subscriptions","organizations_url":"https://api.github.com/users/ghost/orgs","repos_url":"https://api.github.com/users/ghost/repos","events_url":"https://api.github.com/users/ghost/events{/privacy}","received_events_url":"https://api.github.com/users/ghost/received_events","type":"User","site_admin":false},"created_at":"2021-06-09T22:38:26Z","updated_at":"2021-06-09T22:38:26Z","author_association":"NONE","body":"Would you advise increasing number of anchors per detection stage such as changing from the default 3 to 4? For my dataset, I would like to have a fast detection speed, but accuracy is more important because it is supposed to be looking for a disease. Perhaps yolo was the wrong algorithm to use all along?","reactions":{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/858147011/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"ghost","id":10137,"node_id":"MDQ6VXNlcjEwMTM3","avatar_url":"https://avatars.githubusercontent.com/u/10137?v=4","gravatar_id":"","url":"https://api.github.com/users/ghost","html_url":"https://github.com/ghost","followers_url":"https://api.github.com/users/ghost/followers","following_url":"https://api.github.com/users/ghost/following{/other_user}","gists_url":"https://api.github.com/users/ghost/gists{/gist_id}","starred_url":"https://api.github.com/users/ghost/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ghost/subscriptions","organizations_url":"https://api.github.com/users/ghost/orgs","repos_url":"https://api.github.com/users/ghost/repos","events_url":"https://api.github.com/users/ghost/events{/privacy}","received_events_url":"https://api.github.com/users/ghost/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/858228313","html_url":"https://github.com/experiencor/keras-yolo3/issues/313#issuecomment-858228313","issue_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/313","id":858228313,"node_id":"MDEyOklzc3VlQ29tbWVudDg1ODIyODMxMw==","user":{"login":"lexuansanh","id":38468965,"node_id":"MDQ6VXNlcjM4NDY4OTY1","avatar_url":"https://avatars.githubusercontent.com/u/38468965?v=4","gravatar_id":"","url":"https://api.github.com/users/lexuansanh","html_url":"https://github.com/lexuansanh","followers_url":"https://api.github.com/users/lexuansanh/followers","following_url":"https://api.github.com/users/lexuansanh/following{/other_user}","gists_url":"https://api.github.com/users/lexuansanh/gists{/gist_id}","starred_url":"https://api.github.com/users/lexuansanh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lexuansanh/subscriptions","organizations_url":"https://api.github.com/users/lexuansanh/orgs","repos_url":"https://api.github.com/users/lexuansanh/repos","events_url":"https://api.github.com/users/lexuansanh/events{/privacy}","received_events_url":"https://api.github.com/users/lexuansanh/received_events","type":"User","site_admin":false},"created_at":"2021-06-10T02:19:47Z","updated_at":"2021-06-10T02:21:02Z","author_association":"NONE","body":"Aha. I understand what you mean. In my opinion, there are 2 ways:\r\n1. Increase the number of Anchor Boxes for each output. Normally each output will have 3 featured anchors, now we will add 1 more anchors box, then it will be 4 anchors for 1 output. Do the same for the other 2 outputs, for a total of 12 anchor boxes. I find this way quite suitable for you. You would edit the following: \r\nex:\r\nLayer 80 => 82: replace 4*(5+nb_class) for 3*(5+nb_class)\r\n`pred_yolo_1 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},                             {'filter': (4*(5+nb_class)), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], do_skip=False)\r\n`\r\nDo the same for # Layer 92 => 94, # Layer 99 => 106\r\nThen calculate the dimensions in yololayer accordingly:\r\nex: \r\nreplace [batch_size, 1, 1, 4, 1] for [batch_size, 1, 1, 3, 1]\r\n`self.cell_grid = tf.tile(tf.concat([cell_x,cell_y],-1), [batch_size, 1, 1, 4, 1])`\r\nadjust the shape of the y_predict [batch, grid_h, grid_w, 4, 4+1+nb_class]\r\n....\r\n2. Modify Model. This way is complicated and requires computing power of the computer and much larger memory, due to the increased number of parameters:\r\nSpecifically:\r\ninput_image = 832, 832\r\nadd more _conv_block and do the same to:\r\noutput1: batch,104,104,3,(4+1+nb_class)\r\noutput2: batch,52,52,3,(4+1+nb_class)\r\noutput3: batch,26,26,3,(4+1+nb_class)\r\noutput4: batch,13,13,3,(4+1+nb_class)\r\n\r\nOr any input value to get 4 outputs whose grid cells are integers and all decrement by base 2. ex (448 -> 56 ---> 28 -> 14 -> 7), ,.. .\r\nThese methods are just my ideas and I'm not sure if it will work for you :D","reactions":{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/858228313/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"lexuansanh","id":38468965,"node_id":"MDQ6VXNlcjM4NDY4OTY1","avatar_url":"https://avatars.githubusercontent.com/u/38468965?v=4","gravatar_id":"","url":"https://api.github.com/users/lexuansanh","html_url":"https://github.com/lexuansanh","followers_url":"https://api.github.com/users/lexuansanh/followers","following_url":"https://api.github.com/users/lexuansanh/following{/other_user}","gists_url":"https://api.github.com/users/lexuansanh/gists{/gist_id}","starred_url":"https://api.github.com/users/lexuansanh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lexuansanh/subscriptions","organizations_url":"https://api.github.com/users/lexuansanh/orgs","repos_url":"https://api.github.com/users/lexuansanh/repos","events_url":"https://api.github.com/users/lexuansanh/events{/privacy}","received_events_url":"https://api.github.com/users/lexuansanh/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/858284762","html_url":"https://github.com/experiencor/keras-yolo3/issues/313#issuecomment-858284762","issue_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/313","id":858284762,"node_id":"MDEyOklzc3VlQ29tbWVudDg1ODI4NDc2Mg==","user":{"login":"ghost","id":10137,"node_id":"MDQ6VXNlcjEwMTM3","avatar_url":"https://avatars.githubusercontent.com/u/10137?v=4","gravatar_id":"","url":"https://api.github.com/users/ghost","html_url":"https://github.com/ghost","followers_url":"https://api.github.com/users/ghost/followers","following_url":"https://api.github.com/users/ghost/following{/other_user}","gists_url":"https://api.github.com/users/ghost/gists{/gist_id}","starred_url":"https://api.github.com/users/ghost/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ghost/subscriptions","organizations_url":"https://api.github.com/users/ghost/orgs","repos_url":"https://api.github.com/users/ghost/repos","events_url":"https://api.github.com/users/ghost/events{/privacy}","received_events_url":"https://api.github.com/users/ghost/received_events","type":"User","site_admin":false},"created_at":"2021-06-10T04:12:53Z","updated_at":"2021-06-10T04:12:53Z","author_association":"NONE","body":"Thank you very much. I tried implementing the first approach, and tried to use 5 anchors per detection layer by printing out 15 anchors in generate_anchors.py instead of the default 9. iou increased from 0.54 (using 9 anchors) to 0.62. Increasing # of anchors increases iou. In the code below, I marked the lines I changed in yolo.py with the comment \"#CHANGED HERE\"\r\n\r\n```\r\nfrom keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D, Lambda\r\nfrom keras.layers.merge import add, concatenate\r\nfrom keras.models import Model\r\nfrom keras.engine.topology import Layer\r\nimport tensorflow as tf\r\nimport keras\r\n\r\n\r\ndebug = False\r\n\r\nclass YoloLayer(Layer):\r\n    def __init__(self, anchors, max_grid, batch_size, warmup_batches, ignore_thresh, \r\n                    grid_scale, obj_scale, noobj_scale, xywh_scale, class_scale, \r\n                    **kwargs):\r\n        # make the model settings persistent\r\n        self.ignore_thresh  = ignore_thresh\r\n        self.warmup_batches = warmup_batches\r\n\r\n\r\n# CHANGED HERE self.anchors to [1, 1, 1, 5, 2] from [1, 1, 1, 3, 2]. Possibly not needed?\r\n\r\n        self.anchors        = tf.constant(anchors, dtype='float', shape=[1,1,1,5,2])\r\n        self.grid_scale     = grid_scale\r\n        self.obj_scale      = obj_scale\r\n        self.noobj_scale    = noobj_scale\r\n        self.xywh_scale     = xywh_scale\r\n        self.class_scale    = class_scale        \r\n\r\n        # make a persistent mesh grid\r\n        max_grid_h, max_grid_w = max_grid\r\n\r\n        cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(max_grid_w), [max_grid_h]), (1, max_grid_h, max_grid_w, 1, 1)))\r\n        cell_y = tf.transpose(cell_x, (0,2,1,3,4))\r\n\r\n\r\n# CHANGED HERE [batch_size, 1, 1, 5, 1] changed from the [batch_size, 1, 1, 3, 1] like suggested\r\n\r\n        self.cell_grid = tf.tile(tf.concat([cell_x,cell_y],-1), [batch_size, 1, 1, 5, 1])\r\n\r\n        super(YoloLayer, self).__init__(**kwargs)\r\n\r\n    def build(self, input_shape):\r\n        super(YoloLayer, self).build(input_shape)  # Be sure to call this somewhere!\r\n\r\n    def call(self, x):\r\n        input_image, y_pred, y_true, true_boxes = x\r\n\r\n        # adjust the shape of the y_predict [batch, grid_h, grid_w, 3, 4+1+nb_class]\r\n\r\n\r\n# CHANGED HERE I am assuming when you say adjust y_predict you have to change tf.constants([3,-1]) to tf.constants([5,-1])\r\n\r\n        y_pred = tf.reshape(y_pred, tf.concat([tf.shape(y_pred)[:3], tf.constant([5, -1])], axis=0))\r\n        \r\n        # initialize the masks\r\n        object_mask     = tf.expand_dims(y_true[..., 4], 4)\r\n\r\n        # the variable to keep track of number of batches processed\r\n        batch_seen = tf.Variable(0.)        \r\n\r\n        # compute grid factor and net factor\r\n        grid_h      = tf.shape(y_true)[1]\r\n        grid_w      = tf.shape(y_true)[2]\r\n        grid_factor = tf.reshape(tf.cast([grid_w, grid_h], tf.float32), [1,1,1,1,2])\r\n\r\n        net_h       = tf.shape(input_image)[1]\r\n        net_w       = tf.shape(input_image)[2]            \r\n        net_factor  = tf.reshape(tf.cast([net_w, net_h], tf.float32), [1,1,1,1,2])\r\n        \r\n        \"\"\"\r\n        Adjust prediction\r\n        \"\"\"\r\n        pred_box_xy    = (self.cell_grid[:,:grid_h,:grid_w,:,:] + tf.sigmoid(y_pred[..., :2]))  # sigma(t_xy) + c_xy\r\n        pred_box_wh    = y_pred[..., 2:4]                                                       # t_wh\r\n        pred_box_conf  = tf.expand_dims(tf.sigmoid(y_pred[..., 4]), 4)                          # adjust confidence\r\n        pred_box_class = y_pred[..., 5:]                                                        # adjust class probabilities      \r\n\r\n        \"\"\"\r\n        Adjust ground truth\r\n        \"\"\"\r\n        true_box_xy    = y_true[..., 0:2] # (sigma(t_xy) + c_xy)\r\n        true_box_wh    = y_true[..., 2:4] # t_wh\r\n        true_box_conf  = tf.expand_dims(y_true[..., 4], 4)\r\n        true_box_class = tf.argmax(y_true[..., 5:], -1)         \r\n\r\n        \"\"\"\r\n        Compare each predicted box to all true boxes\r\n        \"\"\"        \r\n        # initially, drag all objectness of all boxes to 0\r\n        conf_delta  = pred_box_conf - 0 \r\n\r\n        # then, ignore the boxes which have good overlap with some true box\r\n        true_xy = true_boxes[..., 0:2] / grid_factor\r\n        true_wh = true_boxes[..., 2:4] / net_factor\r\n        \r\n        true_wh_half = true_wh / 2.\r\n        true_mins    = true_xy - true_wh_half\r\n        true_maxes   = true_xy + true_wh_half\r\n        \r\n        pred_xy = tf.expand_dims(pred_box_xy / grid_factor, 4)\r\n        pred_wh = tf.expand_dims(tf.exp(pred_box_wh) * self.anchors / net_factor, 4)\r\n        \r\n        pred_wh_half = pred_wh / 2.\r\n        pred_mins    = pred_xy - pred_wh_half\r\n        pred_maxes   = pred_xy + pred_wh_half    \r\n\r\n        intersect_mins  = tf.maximum(pred_mins,  true_mins)\r\n        intersect_maxes = tf.minimum(pred_maxes, true_maxes)\r\n\r\n        intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\r\n        intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\r\n        \r\n        true_areas = true_wh[..., 0] * true_wh[..., 1]\r\n        pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\r\n\r\n        union_areas = pred_areas + true_areas - intersect_areas\r\n        iou_scores  = tf.truediv(intersect_areas, union_areas)\r\n\r\n        best_ious   = tf.reduce_max(iou_scores, axis=4)        \r\n        conf_delta *= tf.expand_dims(tf.to_float(best_ious < self.ignore_thresh), 4)\r\n\r\n        \"\"\"\r\n        Compute some online statistics\r\n        \"\"\"            \r\n        true_xy = true_box_xy / grid_factor\r\n        true_wh = tf.exp(true_box_wh) * self.anchors / net_factor\r\n\r\n        true_wh_half = true_wh / 2.\r\n        true_mins    = true_xy - true_wh_half\r\n        true_maxes   = true_xy + true_wh_half\r\n\r\n        pred_xy = pred_box_xy / grid_factor\r\n        pred_wh = tf.exp(pred_box_wh) * self.anchors / net_factor \r\n        \r\n        pred_wh_half = pred_wh / 2.\r\n        pred_mins    = pred_xy - pred_wh_half\r\n        pred_maxes   = pred_xy + pred_wh_half      \r\n\r\n        intersect_mins  = tf.maximum(pred_mins,  true_mins)\r\n        intersect_maxes = tf.minimum(pred_maxes, true_maxes)\r\n        intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\r\n        intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\r\n        \r\n        true_areas = true_wh[..., 0] * true_wh[..., 1]\r\n        pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\r\n\r\n        union_areas = pred_areas + true_areas - intersect_areas\r\n        iou_scores  = tf.truediv(intersect_areas, union_areas)\r\n        iou_scores  = object_mask * tf.expand_dims(iou_scores, 4)\r\n        \r\n        count       = tf.reduce_sum(object_mask)\r\n        count_noobj = tf.reduce_sum(1 - object_mask)\r\n        detect_mask = tf.to_float((pred_box_conf*object_mask) >= 0.5)\r\n        class_mask  = tf.expand_dims(tf.to_float(tf.equal(tf.argmax(pred_box_class, -1), true_box_class)), 4)\r\n        recall50    = tf.reduce_sum(tf.to_float(iou_scores >= 0.5 ) * detect_mask  * class_mask) / (count + 1e-3)\r\n        recall75    = tf.reduce_sum(tf.to_float(iou_scores >= 0.75) * detect_mask  * class_mask) / (count + 1e-3)    \r\n        avg_iou     = tf.reduce_sum(iou_scores) / (count + 1e-3)\r\n        avg_obj     = tf.reduce_sum(pred_box_conf  * object_mask)  / (count + 1e-3)\r\n        avg_noobj   = tf.reduce_sum(pred_box_conf  * (1-object_mask))  / (count_noobj + 1e-3)\r\n        avg_cat     = tf.reduce_sum(object_mask * class_mask) / (count + 1e-3) \r\n\r\n        \"\"\"\r\n        Warm-up training\r\n        \"\"\"\r\n        batch_seen = tf.assign_add(batch_seen, 1.)\r\n        \r\n        true_box_xy, true_box_wh, xywh_mask = tf.cond(tf.less(batch_seen, self.warmup_batches+1), \r\n                              lambda: [true_box_xy + (0.5 + self.cell_grid[:,:grid_h,:grid_w,:,:]) * (1-object_mask), \r\n                                       true_box_wh + tf.zeros_like(true_box_wh) * (1-object_mask), \r\n                                       tf.ones_like(object_mask)],\r\n                              lambda: [true_box_xy, \r\n                                       true_box_wh,\r\n                                       object_mask])\r\n\r\n        \"\"\"\r\n        Compare each true box to all anchor boxes\r\n        \"\"\"      \r\n        wh_scale = tf.exp(true_box_wh) * self.anchors / net_factor\r\n        wh_scale = tf.expand_dims(2 - wh_scale[..., 0] * wh_scale[..., 1], axis=4) # the smaller the box, the bigger the scale\r\n\r\n        xy_delta    = xywh_mask   * (pred_box_xy-true_box_xy) * wh_scale * self.xywh_scale\r\n        wh_delta    = xywh_mask   * (pred_box_wh-true_box_wh) * wh_scale * self.xywh_scale\r\n        conf_delta  = object_mask * (pred_box_conf-true_box_conf) * self.obj_scale + (1-object_mask) * conf_delta * self.noobj_scale\r\n        class_delta = object_mask * \\\r\n                      tf.expand_dims(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class), 4) * \\\r\n                      self.class_scale\r\n\r\n        loss_xy    = tf.reduce_sum(tf.square(xy_delta),       list(range(1,5)))\r\n        loss_wh    = tf.reduce_sum(tf.square(wh_delta),       list(range(1,5)))\r\n        loss_conf  = tf.reduce_sum(tf.square(conf_delta),     list(range(1,5)))\r\n        loss_class = tf.reduce_sum(class_delta,               list(range(1,5)))\r\n\r\n        loss = loss_xy + loss_wh + loss_conf + loss_class\r\n\r\n        if debug:\r\n            loss = tf.Print(loss, [grid_h, avg_obj], message='avg_obj \\t\\t', summarize=1000)\r\n            loss = tf.Print(loss, [grid_h, avg_noobj], message='avg_noobj \\t\\t', summarize=1000)\r\n            loss = tf.Print(loss, [grid_h, avg_iou], message='avg_iou \\t\\t', summarize=1000)\r\n            loss = tf.Print(loss, [grid_h, avg_cat], message='avg_cat \\t\\t', summarize=1000)\r\n            loss = tf.Print(loss, [grid_h, recall50], message='recall50 \\t', summarize=1000)\r\n            loss = tf.Print(loss, [grid_h, recall75], message='recall75 \\t', summarize=1000)   \r\n            loss = tf.Print(loss, [grid_h, count], message='count \\t', summarize=1000)     \r\n            loss = tf.Print(loss, [grid_h, tf.reduce_sum(loss_xy), \r\n                                        tf.reduce_sum(loss_wh), \r\n                                        tf.reduce_sum(loss_conf), \r\n                                        tf.reduce_sum(loss_class)],  message='loss xy, wh, conf, class: \\t',   summarize=1000)   \r\n\r\n\r\n        return loss*self.grid_scale\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return [(None, 1)]\r\n\r\ndef _conv_block(inp, convs, do_skip=True):\r\n    x = inp\r\n    count = 0\r\n    \r\n    for conv in convs:\r\n        if count == (len(convs) - 2) and do_skip:\r\n            skip_connection = x\r\n        count += 1\r\n        \r\n        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # unlike tensorflow darknet prefer left and top paddings\r\n        x = Conv2D(conv['filter'], \r\n                   conv['kernel'], \r\n                   strides=conv['stride'], \r\n                   padding='valid' if conv['stride'] > 1 else 'same', # unlike tensorflow darknet prefer left and top paddings\r\n                   name='conv_' + str(conv['layer_idx']), \r\n                   use_bias=False if conv['bnorm'] else True)(x)\r\n        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\r\n        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\r\n\r\n    return add([skip_connection, x]) if do_skip else x    \r\n\r\n\r\ndef create_yolov3_model(\r\n    nb_class, \r\n    anchors, \r\n    max_box_per_image, \r\n    max_grid, \r\n    batch_size, \r\n    warmup_batches,\r\n    ignore_thresh,\r\n    grid_scales,\r\n    obj_scale,\r\n    noobj_scale,\r\n    xywh_scale,\r\n    class_scale\r\n):\r\n    input_image = Input(shape=(None, None, 3)) # net_h, net_w, 3\r\n    true_boxes  = Input(shape=(1, 1, 1, max_box_per_image, 4))\r\n    print(len(anchors))\r\n\r\n\r\n# CHANGED HERE well, not really, but I am assuming you keep the len(anchors)//6 the same becasue 15(# of anchors generated) \r\n* 2 = 30, and 30 // 6 equals 5, the number of anchors for each detection layer that I want\r\n* \r\n    true_yolo_1 = Input(shape=(None, None, len(anchors)//6, 4+1+nb_class)) # grid_h, grid_w, nb_anchor, 5+nb_class\r\n    true_yolo_2 = Input(shape=(None, None, len(anchors)//6, 4+1+nb_class)) # grid_h, grid_w, nb_anchor, 5+nb_class\r\n    true_yolo_3 = Input(shape=(None, None, len(anchors)//6, 4+1+nb_class)) # grid_h, grid_w, nb_anchor, 5+nb_class\r\n\r\n    # Layer  0 => 4\r\n    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\r\n                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\r\n                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\r\n                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\r\n\r\n    # Layer  5 => 8\r\n    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\r\n                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\r\n                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\r\n\r\n    # Layer  9 => 11\r\n    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\r\n                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\r\n\r\n    # Layer 12 => 15\r\n    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\r\n                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\r\n                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\r\n\r\n    # Layer 16 => 36\r\n    for i in range(7):\r\n        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\r\n                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\r\n        \r\n    skip_36 = x\r\n        \r\n    # Layer 37 => 40\r\n    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\r\n                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\r\n                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\r\n\r\n    # Layer 41 => 61\r\n    for i in range(7):\r\n        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\r\n                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\r\n        \r\n    skip_61 = x\r\n        \r\n    # Layer 62 => 65\r\n    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\r\n                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\r\n                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\r\n\r\n    # Layer 66 => 74\r\n    for i in range(3):\r\n        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\r\n                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\r\n\r\n    # Layer 75 => 79\r\n    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\r\n                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\r\n                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\r\n                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\r\n                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], do_skip=False)\r\n\r\n    # Layer 80 => 82\r\n\r\n\r\n# CHANGED HERE changed the 'filter': (5*(5+nb_class)) from 'filter': (3*(5+nb_class))\r\n\r\n    pred_yolo_1 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\r\n                             {'filter': (5*(5+nb_class)), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], do_skip=False)\r\n\r\n\r\n# CHANGED HERE original was anchors[12:], but because I generated 15 anchors in generate_anchors.py I adjusted to [20:]\r\n\r\n    loss_yolo_1 = YoloLayer(anchors[20:], \r\n                            [1*num for num in max_grid], \r\n                            batch_size, \r\n                            warmup_batches, \r\n                            ignore_thresh, \r\n                            grid_scales[0],\r\n                            obj_scale,\r\n                            noobj_scale,\r\n                            xywh_scale,\r\n                            class_scale)([input_image, pred_yolo_1, true_yolo_1, true_boxes])\r\n\r\n    # Layer 83 => 86\r\n    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], do_skip=False)\r\n    x = UpSampling2D(2)(x)\r\n    x = concatenate([x, skip_61])\r\n\r\n    # Layer 87 => 91\r\n    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\r\n                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\r\n                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\r\n                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\r\n                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], do_skip=False)\r\n\r\n    # Layer 92 => 94\r\n\r\n# CHANGED HERE changed the 'filter': (5*(5+nb_class)) from 'filter': (3*(5+nb_class))\r\n\r\n    pred_yolo_2 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\r\n                             {'filter': (5*(5+nb_class)), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], do_skip=False)\r\n\r\n# CHANGED HERE original was anchors[6:12], but because I generated 15 anchors in generate_anchors.py I adjusted to [10:20]\r\n\r\n    loss_yolo_2 = YoloLayer(anchors[10:20], \r\n                            [2*num for num in max_grid], \r\n                            batch_size, \r\n                            warmup_batches, \r\n                            ignore_thresh, \r\n                            grid_scales[1],\r\n                            obj_scale,\r\n                            noobj_scale,\r\n                            xywh_scale,\r\n                            class_scale)([input_image, pred_yolo_2, true_yolo_2, true_boxes])\r\n\r\n    # Layer 95 => 98\r\n    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], do_skip=False)\r\n    x = UpSampling2D(2)(x)\r\n    x = concatenate([x, skip_36])\r\n\r\n    # Layer 99 => 106\r\n\r\n# CHANGED HERE changed the 'filter': (5*(5+nb_class)) from 'filter': (3*(5+nb_class))\r\n\r\n    pred_yolo_3 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\r\n                             {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\r\n                             {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\r\n                             {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\r\n                             {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\r\n                             {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\r\n                             {'filter': (5*(5+nb_class)), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], do_skip=False)\r\n\r\n\r\n# CHANGED HERE original was anchors[:6], but because I generated 15 anchors in generate_anchors.py I adjusted to [:10]\r\n\r\n    loss_yolo_3 = YoloLayer(anchors[:10], \r\n                            [4*num for num in max_grid], \r\n                            batch_size, \r\n                            warmup_batches, \r\n                            ignore_thresh, \r\n                            grid_scales[2],\r\n                            obj_scale,\r\n                            noobj_scale,\r\n                            xywh_scale,\r\n                            class_scale)([input_image, pred_yolo_3, true_yolo_3, true_boxes]) \r\n\r\n    train_model = Model([input_image, true_boxes, true_yolo_1, true_yolo_2, true_yolo_3], [loss_yolo_1, loss_yolo_2, loss_yolo_3])\r\n    infer_model = Model(input_image, [pred_yolo_1, pred_yolo_2, pred_yolo_3])\r\n\r\n    return [train_model, infer_model]\r\n\r\ndef dummy_loss(y_true, y_pred):\r\n    return tf.sqrt(tf.reduce_sum(y_pred))\r\n```\r\nThis portion seems to work, but there is an error when I actually start training on epochs. Not sure if it was either something wrong that I did in yolo or generator. It says:\r\n\r\n```\r\nyolo = yolos[max_index//3]\r\nIndexError: list index out of range\r\n```\r\n\r\nOnly thing I can think of is possibly changing something in these lines?\r\n```\r\n# initialize the inputs and the outputs\r\n        yolo_1 = np.zeros((r_bound - l_bound, 1*base_grid_h,  1*base_grid_w, len(self.anchors)//3, 4+1+len(self.labels))) # desired network output 1\r\n        yolo_2 = np.zeros((r_bound - l_bound, 2*base_grid_h,  2*base_grid_w, len(self.anchors)//3, 4+1+len(self.labels))) # desired network output 2\r\n        yolo_3 = np.zeros((r_bound - l_bound, 4*base_grid_h,  4*base_grid_w, len(self.anchors)//3, 4+1+len(self.labels))) # desired network output 3\r\n        yolos = [yolo_3, yolo_2, yolo_1]\r\n```\r\nI didn't touch generator. \r\n\r\n","reactions":{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/858284762/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"ghost","id":10137,"node_id":"MDQ6VXNlcjEwMTM3","avatar_url":"https://avatars.githubusercontent.com/u/10137?v=4","gravatar_id":"","url":"https://api.github.com/users/ghost","html_url":"https://github.com/ghost","followers_url":"https://api.github.com/users/ghost/followers","following_url":"https://api.github.com/users/ghost/following{/other_user}","gists_url":"https://api.github.com/users/ghost/gists{/gist_id}","starred_url":"https://api.github.com/users/ghost/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ghost/subscriptions","organizations_url":"https://api.github.com/users/ghost/orgs","repos_url":"https://api.github.com/users/ghost/repos","events_url":"https://api.github.com/users/ghost/events{/privacy}","received_events_url":"https://api.github.com/users/ghost/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/858291827","html_url":"https://github.com/experiencor/keras-yolo3/issues/313#issuecomment-858291827","issue_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/313","id":858291827,"node_id":"MDEyOklzc3VlQ29tbWVudDg1ODI5MTgyNw==","user":{"login":"lexuansanh","id":38468965,"node_id":"MDQ6VXNlcjM4NDY4OTY1","avatar_url":"https://avatars.githubusercontent.com/u/38468965?v=4","gravatar_id":"","url":"https://api.github.com/users/lexuansanh","html_url":"https://github.com/lexuansanh","followers_url":"https://api.github.com/users/lexuansanh/followers","following_url":"https://api.github.com/users/lexuansanh/following{/other_user}","gists_url":"https://api.github.com/users/lexuansanh/gists{/gist_id}","starred_url":"https://api.github.com/users/lexuansanh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lexuansanh/subscriptions","organizations_url":"https://api.github.com/users/lexuansanh/orgs","repos_url":"https://api.github.com/users/lexuansanh/repos","events_url":"https://api.github.com/users/lexuansanh/events{/privacy}","received_events_url":"https://api.github.com/users/lexuansanh/received_events","type":"User","site_admin":false},"created_at":"2021-06-10T04:34:31Z","updated_at":"2021-06-10T05:06:59Z","author_association":"NONE","body":"`yolo = yolos[max_index//5]`\r\nBecause max_index = 14 (0:14 idx of Anchor boxs). max_index//3 may be  = 4 for yolos --> IndexError: list index out of range.\r\nAnd you should also more change in Generator class same as yololayer class","reactions":{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/858291827/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"lexuansanh","id":38468965,"node_id":"MDQ6VXNlcjM4NDY4OTY1","avatar_url":"https://avatars.githubusercontent.com/u/38468965?v=4","gravatar_id":"","url":"https://api.github.com/users/lexuansanh","html_url":"https://github.com/lexuansanh","followers_url":"https://api.github.com/users/lexuansanh/followers","following_url":"https://api.github.com/users/lexuansanh/following{/other_user}","gists_url":"https://api.github.com/users/lexuansanh/gists{/gist_id}","starred_url":"https://api.github.com/users/lexuansanh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lexuansanh/subscriptions","organizations_url":"https://api.github.com/users/lexuansanh/orgs","repos_url":"https://api.github.com/users/lexuansanh/repos","events_url":"https://api.github.com/users/lexuansanh/events{/privacy}","received_events_url":"https://api.github.com/users/lexuansanh/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/859132907","html_url":"https://github.com/experiencor/keras-yolo3/issues/313#issuecomment-859132907","issue_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/313","id":859132907,"node_id":"MDEyOklzc3VlQ29tbWVudDg1OTEzMjkwNw==","user":{"login":"ghost","id":10137,"node_id":"MDQ6VXNlcjEwMTM3","avatar_url":"https://avatars.githubusercontent.com/u/10137?v=4","gravatar_id":"","url":"https://api.github.com/users/ghost","html_url":"https://github.com/ghost","followers_url":"https://api.github.com/users/ghost/followers","following_url":"https://api.github.com/users/ghost/following{/other_user}","gists_url":"https://api.github.com/users/ghost/gists{/gist_id}","starred_url":"https://api.github.com/users/ghost/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ghost/subscriptions","organizations_url":"https://api.github.com/users/ghost/orgs","repos_url":"https://api.github.com/users/ghost/repos","events_url":"https://api.github.com/users/ghost/events{/privacy}","received_events_url":"https://api.github.com/users/ghost/received_events","type":"User","site_admin":false},"created_at":"2021-06-10T22:46:10Z","updated_at":"2021-06-10T23:04:24Z","author_association":"NONE","body":"Thank you again. It compiles and runs, but now it seems like performance gets worse. This might be an error in my implementation, or maybe more anchors may not be a good idea?\r\n```\r\nimport cv2\r\nimport copy\r\nimport numpy as np\r\nfrom keras.utils import Sequence\r\nfrom utils.bbox import BoundBox, bbox_iou\r\nfrom utils.image import apply_random_scale_and_crop, random_distort_image, random_flip, correct_bounding_boxes\r\n\r\nclass BatchGenerator(Sequence):\r\n    def __init__(self, \r\n        instances, \r\n        anchors,   \r\n        labels,        \r\n        downsample=32, # ratio between network input's size and network output's size, 32 for YOLOv3\r\n        max_box_per_image=30,\r\n        batch_size=1,\r\n        min_net_size=320,\r\n        max_net_size=320,    \r\n        shuffle=True, \r\n        jitter=True, \r\n        norm=None\r\n    ):\r\n        self.instances          = instances\r\n        self.batch_size         = batch_size\r\n        self.labels             = labels\r\n        self.downsample         = downsample\r\n        self.max_box_per_image  = max_box_per_image\r\n        self.min_net_size       = (min_net_size//self.downsample)*self.downsample\r\n        self.max_net_size       = (max_net_size//self.downsample)*self.downsample\r\n        self.shuffle            = shuffle\r\n        self.jitter             = jitter\r\n        self.norm               = norm\r\n        self.anchors            = [BoundBox(0, 0, anchors[2*i], anchors[2*i+1]) for i in range(len(anchors)//2)]\r\n        self.net_h              = 416  \r\n        self.net_w              = 416\r\n\r\n        if shuffle: np.random.shuffle(self.instances)\r\n            \r\n    def __len__(self):\r\n        return int(np.ceil(float(len(self.instances))/self.batch_size))           \r\n\r\n    def __getitem__(self, idx):\r\n        # get image input size, change every 10 batches\r\n        net_h, net_w = self._get_net_size(idx)\r\n        base_grid_h, base_grid_w = net_h//self.downsample, net_w//self.downsample\r\n\r\n        # determine the first and the last indices of the batch\r\n        l_bound = idx*self.batch_size\r\n        r_bound = (idx+1)*self.batch_size\r\n\r\n        if r_bound > len(self.instances):\r\n            r_bound = len(self.instances)\r\n            l_bound = r_bound - self.batch_size\r\n\r\n        x_batch = np.zeros((r_bound - l_bound, net_h, net_w, 3))             # input images\r\n        t_batch = np.zeros((r_bound - l_bound, 1, 1, 1,  self.max_box_per_image, 4))   # list of groundtruth boxes\r\n\r\n        # initialize the inputs and the outputs\r\n\r\n# CHANGED HERE Actually didn't, but this may be a casue for an issue. Reasoning behind self.anchoirs/3 is becasue 15(number of anchors I chose) // 3 is 5, which is number of anchors I want per detection layer\r\n        yolo_1 = np.zeros((r_bound - l_bound, 1*base_grid_h,  1*base_grid_w, len(self.anchors)//3, 4+1+len(self.labels))) # desired network output 1\r\n        yolo_2 = np.zeros((r_bound - l_bound, 2*base_grid_h,  2*base_grid_w, len(self.anchors)//3, 4+1+len(self.labels))) # desired network output 2\r\n        yolo_3 = np.zeros((r_bound - l_bound, 4*base_grid_h,  4*base_grid_w, len(self.anchors)//3, 4+1+len(self.labels))) # desired network output 3\r\n        yolos = [yolo_3, yolo_2, yolo_1]\r\n\r\n        dummy_yolo_1 = np.zeros((r_bound - l_bound, 1))\r\n        dummy_yolo_2 = np.zeros((r_bound - l_bound, 1))\r\n        dummy_yolo_3 = np.zeros((r_bound - l_bound, 1))\r\n        \r\n        instance_count = 0\r\n        true_box_index = 0\r\n\r\n        # do the logic to fill in the inputs and the output\r\n        for train_instance in self.instances[l_bound:r_bound]:\r\n            # augment input image and fix object's position and size\r\n            img, all_objs = self._aug_image(train_instance, net_h, net_w)\r\n            \r\n            for obj in all_objs:\r\n                # find the best anchor box for this object\r\n                max_anchor = None                \r\n                max_index  = -1\r\n                max_iou    = -1\r\n\r\n                shifted_box = BoundBox(0, \r\n                                       0,\r\n                                       obj['xmax']-obj['xmin'],                                                \r\n                                       obj['ymax']-obj['ymin'])    \r\n                \r\n                for i in range(len(self.anchors)):\r\n                    anchor = self.anchors[i]\r\n                    iou    = bbox_iou(shifted_box, anchor)\r\n\r\n                    if max_iou < iou:\r\n                        max_anchor = anchor\r\n                        max_index  = i\r\n                        max_iou    = iou                \r\n                \r\n                # determine the yolo to be responsible for this bounding box\r\n\r\n# CHANGED HERE Solved out of index error! \r\n                yolo = yolos[max_index//5]\r\n                grid_h, grid_w = yolo.shape[1:3]\r\n                \r\n                # determine the position of the bounding box on the grid\r\n                center_x = .5*(obj['xmin'] + obj['xmax'])\r\n                center_x = center_x / float(net_w) * grid_w # sigma(t_x) + c_x\r\n                center_y = .5*(obj['ymin'] + obj['ymax'])\r\n                center_y = center_y / float(net_h) * grid_h # sigma(t_y) + c_y\r\n                \r\n                # determine the sizes of the bounding box\r\n                w = np.log((obj['xmax'] - obj['xmin']) / float(max_anchor.xmax)) # t_w\r\n                h = np.log((obj['ymax'] - obj['ymin']) / float(max_anchor.ymax)) # t_h\r\n\r\n                box = [center_x, center_y, w, h]\r\n\r\n                # determine the index of the label\r\n                obj_indx = self.labels.index(obj['name'])  \r\n\r\n                # determine the location of the cell responsible for this object\r\n                grid_x = int(np.floor(center_x))\r\n                grid_y = int(np.floor(center_y))\r\n\r\n                # assign ground truth x, y, w, h, confidence and class probs to y_batch\r\n\r\n# Am I supposed to change  %3 to %5? I tried both, but performance is still pretty bad for both on racoon dataset.\r\n\r\n                yolo[instance_count, grid_y, grid_x, max_index%3]      = 0\r\n                yolo[instance_count, grid_y, grid_x, max_index%3, 0:4] = box\r\n                yolo[instance_count, grid_y, grid_x, max_index%3, 4  ] = 1.\r\n                yolo[instance_count, grid_y, grid_x, max_index%3, 5+obj_indx] = 1\r\n\r\n                # assign the true box to t_batch\r\n                true_box = [center_x, center_y, obj['xmax'] - obj['xmin'], obj['ymax'] - obj['ymin']]\r\n                t_batch[instance_count, 0, 0, 0, true_box_index] = true_box\r\n\r\n                true_box_index += 1\r\n                true_box_index  = true_box_index % self.max_box_per_image    \r\n\r\n            # assign input image to x_batch\r\n            if self.norm != None: \r\n                x_batch[instance_count] = self.norm(img)\r\n            else:\r\n                # plot image and bounding boxes for sanity check\r\n                for obj in all_objs:\r\n                    cv2.rectangle(img, (obj['xmin'],obj['ymin']), (obj['xmax'],obj['ymax']), (255,0,0), 3)\r\n                    cv2.putText(img, obj['name'], \r\n                                (obj['xmin']+2, obj['ymin']+12), \r\n                                0, 1.2e-3 * img.shape[0], \r\n                                (0,255,0), 2)\r\n                \r\n                x_batch[instance_count] = img\r\n\r\n            # increase instance counter in the current batch\r\n            instance_count += 1                 \r\n                \r\n        return [x_batch, t_batch, yolo_1, yolo_2, yolo_3], [dummy_yolo_1, dummy_yolo_2, dummy_yolo_3]\r\n\r\n    def _get_net_size(self, idx):\r\n        if idx%10 == 0:\r\n            net_size = self.downsample*np.random.randint(self.min_net_size/self.downsample, \\\r\n                                                         self.max_net_size/self.downsample+1)\r\n            # print(\"resizing: \", net_size, net_size)\r\n            self.net_h, self.net_w = net_size, net_size\r\n        return self.net_h, self.net_w\r\n    \r\n    def _aug_image(self, instance, net_h, net_w):\r\n        image_name = instance['filename']\r\n        image = cv2.imread(image_name) # RGB image\r\n        \r\n        if image is None: print('Cannot find ', image_name)\r\n        image = image[:,:,::-1] # RGB image\r\n            \r\n        image_h, image_w, _ = image.shape\r\n        \r\n        # determine the amount of scaling and cropping\r\n        dw = self.jitter * image_w;\r\n        dh = self.jitter * image_h;\r\n\r\n        new_ar = (image_w + np.random.uniform(-dw, dw)) / (image_h + np.random.uniform(-dh, dh));\r\n        # scale = np.random.uniform(0.25, 2);\r\n        scale = 1\r\n\r\n        if (new_ar < 1):\r\n            new_h = int(scale * net_h);\r\n            new_w = int(net_h * new_ar);\r\n        else:\r\n            new_w = int(scale * net_w);\r\n            new_h = int(net_w / new_ar);\r\n            \r\n        #dx = int(np.random.uniform(0, net_w - new_w));\r\n        #dy = int(np.random.uniform(0, net_h - new_h));\r\n        dx = 0\r\n        dy = 0\r\n        \r\n        # apply scaling and cropping\r\n        # print(image.shape)\r\n        im_sized = apply_random_scale_and_crop(image, new_w, new_h, net_w, net_h, dx, dy)\r\n        \r\n        # randomly distort hsv space\r\n        # im_sized = random_distort_image(im_sized)\r\n        \r\n        # randomly flip\r\n        # flip = np.random.randint(2)\r\n        flip = 1\r\n        im_sized = random_flip(im_sized, flip)\r\n            \r\n        # correct the size and pos of bounding boxes\r\n        all_objs = correct_bounding_boxes(instance['object'], new_w, new_h, net_w, net_h, dx, dy, flip, image_w, image_h)\r\n        \r\n\r\n        return im_sized, all_objs   \r\n\r\n    def on_epoch_end(self):\r\n        if self.shuffle: np.random.shuffle(self.instances)\r\n            \r\n    def num_classes(self):\r\n        return len(self.labels)\r\n\r\n    def size(self):\r\n        return len(self.instances)    \r\n\r\n    def get_anchors(self):\r\n        anchors = []\r\n\r\n        for anchor in self.anchors:\r\n            anchors += [anchor.xmax, anchor.ymax]\r\n\r\n        return anchors\r\n\r\n    def load_annotation(self, i):\r\n        annots = []\r\n\r\n        for obj in self.instances[i]['object']:\r\n            annot = [obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax'], self.labels.index(obj['name'])]\r\n            annots += [annot]\r\n\r\n        if len(annots) == 0: annots = [[]]\r\n\r\n        return np.array(annots)\r\n\r\n    def load_image(self, i):\r\n        return cv2.imread(self.instances[i]['filename'])    \r\n```\r\nIn this generator.py, I only changed like 3 lines in total. However, I now get severe overfitting on racoon dataset. For example, training loss = 1 and validation loss = 30. Of course, this may be because racoon dataset is pretty simple, so more anchors may be overkill. Testing it on the plant dataset still results in poor performance, altough interestingly, I did notice that training loss decreases much faster than previously. ","reactions":{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/859132907/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"ghost","id":10137,"node_id":"MDQ6VXNlcjEwMTM3","avatar_url":"https://avatars.githubusercontent.com/u/10137?v=4","gravatar_id":"","url":"https://api.github.com/users/ghost","html_url":"https://github.com/ghost","followers_url":"https://api.github.com/users/ghost/followers","following_url":"https://api.github.com/users/ghost/following{/other_user}","gists_url":"https://api.github.com/users/ghost/gists{/gist_id}","starred_url":"https://api.github.com/users/ghost/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ghost/subscriptions","organizations_url":"https://api.github.com/users/ghost/orgs","repos_url":"https://api.github.com/users/ghost/repos","events_url":"https://api.github.com/users/ghost/events{/privacy}","received_events_url":"https://api.github.com/users/ghost/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/859226475","html_url":"https://github.com/experiencor/keras-yolo3/issues/313#issuecomment-859226475","issue_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/313","id":859226475,"node_id":"MDEyOklzc3VlQ29tbWVudDg1OTIyNjQ3NQ==","user":{"login":"lexuansanh","id":38468965,"node_id":"MDQ6VXNlcjM4NDY4OTY1","avatar_url":"https://avatars.githubusercontent.com/u/38468965?v=4","gravatar_id":"","url":"https://api.github.com/users/lexuansanh","html_url":"https://github.com/lexuansanh","followers_url":"https://api.github.com/users/lexuansanh/followers","following_url":"https://api.github.com/users/lexuansanh/following{/other_user}","gists_url":"https://api.github.com/users/lexuansanh/gists{/gist_id}","starred_url":"https://api.github.com/users/lexuansanh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lexuansanh/subscriptions","organizations_url":"https://api.github.com/users/lexuansanh/orgs","repos_url":"https://api.github.com/users/lexuansanh/repos","events_url":"https://api.github.com/users/lexuansanh/events{/privacy}","received_events_url":"https://api.github.com/users/lexuansanh/received_events","type":"User","site_admin":false},"created_at":"2021-06-11T03:01:19Z","updated_at":"2021-06-11T04:26:10Z","author_association":"NONE","body":"1. Adding anchor boxes is not a bad idea. It is shown by your training on raccoon that has converged and has low loss. Adding anchors will increase the calculation time of the computer and can do Out of Memory if the computer memory is not large enough. Specifically, the number of bounding boxes = anchors * (13 * 13 + 26 * 26 + 52 * 52). For 3 anchors = 10647 boxes. For 5 anchors this value is 17745 boxes. Calculations will take longer, non-max suppression also longer.\r\n\r\n2. I found valid loss = 30 not a bad number. To accurately evaluate your model, evoluate() should be used to calculate the MAP. If this value is low for both train_generator and valid_generator, the training may fail. However, the AP of train_generator is high and the AP of valid_generator is low, indicating that we have overfitting. In the raccoon set, it's probably low on data and you didn't augment the image via the _aug_image() function.\r\n\r\n3. Just 1 data in your data set error (ex: wrong bounding box, or wrongly labeled, ..) is enough for the training to fail.\r\n\r\n4. In addition, if your computer is powerful enough and memory is large, increase batch_size to 32, this is very powerful to optimize the loss function with your large training data.\r\n\r\n5. Or maybe your valid data doesn't really match the augmented training data. Let's augment from the beginning for all data and then divide the data into train and valid data.\r\n\r\n6. edit the code in:\r\n`yolo[instance_count, grid_y, grid_x, max_index%3]      = 0`\r\n`yolo[instance_count, grid_y, grid_x, max_index%3, 0:4] = box`\r\n`yolo[instance_count, grid_y, grid_x, max_index%3, 4  ] = 1`\r\n`yolo[instance_count, grid_y, grid_x, max_index%3, 5+obj_indx] = 1`\r\nto:\r\n`yolo[instance_count, grid_y, grid_x, max_index%5]      = 0`\r\n`yolo[instance_count, grid_y, grid_x, max_index%5, 0:4] = box`\r\n`yolo[instance_count, grid_y, grid_x, max_index%5, 4  ] = 1`\r\n` yolo[instance_count, grid_y, grid_x, max_index%5, 5+obj_indx] = 1`","reactions":{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/comments/859226475/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"lexuansanh","id":38468965,"node_id":"MDQ6VXNlcjM4NDY4OTY1","avatar_url":"https://avatars.githubusercontent.com/u/38468965?v=4","gravatar_id":"","url":"https://api.github.com/users/lexuansanh","html_url":"https://github.com/lexuansanh","followers_url":"https://api.github.com/users/lexuansanh/followers","following_url":"https://api.github.com/users/lexuansanh/following{/other_user}","gists_url":"https://api.github.com/users/lexuansanh/gists{/gist_id}","starred_url":"https://api.github.com/users/lexuansanh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lexuansanh/subscriptions","organizations_url":"https://api.github.com/users/lexuansanh/orgs","repos_url":"https://api.github.com/users/lexuansanh/repos","events_url":"https://api.github.com/users/lexuansanh/events{/privacy}","received_events_url":"https://api.github.com/users/lexuansanh/received_events","type":"User","site_admin":false}}]