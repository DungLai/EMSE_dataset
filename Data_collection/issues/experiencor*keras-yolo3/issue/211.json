{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/211","repository_url":"https://api.github.com/repos/experiencor/keras-yolo3","labels_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/211/labels{/name}","comments_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/211/comments","events_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/211/events","html_url":"https://github.com/experiencor/keras-yolo3/issues/211","id":479424929,"node_id":"MDU6SXNzdWU0Nzk0MjQ5Mjk=","number":211,"title":"Training doesn't utilize GPU","user":{"login":"monocongo","id":1328158,"node_id":"MDQ6VXNlcjEzMjgxNTg=","avatar_url":"https://avatars.githubusercontent.com/u/1328158?v=4","gravatar_id":"","url":"https://api.github.com/users/monocongo","html_url":"https://github.com/monocongo","followers_url":"https://api.github.com/users/monocongo/followers","following_url":"https://api.github.com/users/monocongo/following{/other_user}","gists_url":"https://api.github.com/users/monocongo/gists{/gist_id}","starred_url":"https://api.github.com/users/monocongo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/monocongo/subscriptions","organizations_url":"https://api.github.com/users/monocongo/orgs","repos_url":"https://api.github.com/users/monocongo/repos","events_url":"https://api.github.com/users/monocongo/events{/privacy}","received_events_url":"https://api.github.com/users/monocongo/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2019-08-11T23:07:06Z","updated_at":"2020-04-29T09:42:35Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I am performing training of the model using a custom dataset on an AWS EC2 instance (p2.xlarge) with an NVIDIA Tesla K80 GPU. After launching the training script I see full CPU utilization but no utilization of the GPU, as measured by the output of `$ watch -n0.1 nvidia-smi`.\r\n```bash\r\nSun Aug 11 23:04:01 2019       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 430.40       Driver Version: 430.40       CUDA Version: 10.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           Off  | 00000000:00:1E.0 Off |                    0 |\r\n| N/A   55C    P0    58W / 149W |     67MiB / 11441MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      4546      C   python3                                       56MiB |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\nThe EC2 instance is Ubuntu 18.04 with `nvidia-driver-430` installed.\r\n\r\nThe `config.json` file:\r\n```json\r\n{\r\n    \"model\" : {\r\n        \"min_input_size\":       288,\r\n        \"max_input_size\":       448,\r\n        \"anchors\":              [0,0, 58,58, 114,193, 116,73, 193,123, 210,270, 303,187, 341,282, 373,367],\r\n        \"labels\":               [\"handgun\"]\r\n    },\r\n\r\n    \"train\": {\r\n        \"train_image_folder\":   \"/home/ubuntu/data/yolo3/handgun/images/\",\r\n        \"train_annot_folder\":   \"/home/ubuntu/data/yolo3/handgun/annotations/\",\r\n        \"cache_name\":           \"handgun_train.pkl\",\r\n\r\n        \"train_times\":          8,\r\n        \"batch_size\":           16,\r\n        \"learning_rate\":        1e-4,\r\n        \"nb_epochs\":            100,\r\n        \"warmup_epochs\":        3,\r\n        \"ignore_thresh\":        0.5,\r\n        \"gpus\":                 \"0\",\r\n\r\n        \"grid_scales\":          [1,1,1],\r\n        \"obj_scale\":            5,\r\n        \"noobj_scale\":          1,\r\n        \"xywh_scale\":           1,\r\n        \"class_scale\":          1,\r\n\r\n        \"tensorboard_dir\":      \"logs\",\r\n        \"saved_weights_name\":   \"handgun.h5\",\r\n        \"debug\":                true\r\n    },\r\n\r\n    \"valid\": {\r\n        \"valid_image_folder\":   \"\",\r\n        \"valid_annot_folder\":   \"\",\r\n        \"cache_name\":           \"\",\r\n\r\n        \"valid_times\":          1\r\n    }\r\n}\r\n```\r\n\r\nThe output from the training script looks reasonable and the TensorBoard graphs look good (i.e. continuous drops in the loss graphs). My only concern is that I've not done something correctly in order to utilize the GPU so the training will likely take much longer to complete.\r\n\r\nCan anyone comment as to what I may have done wrong? Thanks in advance for any comments or suggestions.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/211/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/211/timeline","performed_via_github_app":null,"state_reason":null}