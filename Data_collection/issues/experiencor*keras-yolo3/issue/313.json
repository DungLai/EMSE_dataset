{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/313","repository_url":"https://api.github.com/repos/experiencor/keras-yolo3","labels_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/313/labels{/name}","comments_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/313/comments","events_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/313/events","html_url":"https://github.com/experiencor/keras-yolo3/issues/313","id":911818101,"node_id":"MDU6SXNzdWU5MTE4MTgxMDE=","number":313,"title":"Custom Dataset Low Map and No Convergence(with images!)","user":{"login":"ghost","id":10137,"node_id":"MDQ6VXNlcjEwMTM3","avatar_url":"https://avatars.githubusercontent.com/u/10137?v=4","gravatar_id":"","url":"https://api.github.com/users/ghost","html_url":"https://github.com/ghost","followers_url":"https://api.github.com/users/ghost/followers","following_url":"https://api.github.com/users/ghost/following{/other_user}","gists_url":"https://api.github.com/users/ghost/gists{/gist_id}","starred_url":"https://api.github.com/users/ghost/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ghost/subscriptions","organizations_url":"https://api.github.com/users/ghost/orgs","repos_url":"https://api.github.com/users/ghost/repos","events_url":"https://api.github.com/users/ghost/events{/privacy}","received_events_url":"https://api.github.com/users/ghost/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":9,"created_at":"2021-06-04T20:34:19Z","updated_at":"2021-12-20T23:22:21Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I am using custom data. I have modified the callbacks in train.py so that it is now monitoring validation loss from the validation set, as opposed to the training set. Original learning rate was 1e-4\r\n`def create_callbacks(saved_weights_name, tensorboard_logs, model_to_save):\r\n    makedirs(tensorboard_logs)\r\n    \r\n    early_stop = EarlyStopping(\r\n        monitor     = 'val_loss', \r\n        min_delta   = 0.001, \r\n        patience    = 50, \r\n        mode        = 'min', \r\n        verbose     = 1\r\n    )\r\n    checkpoint = CustomModelCheckpoint(\r\n        model_to_save   = model_to_save,\r\n        filepath        = saved_weights_name,# + '{epoch:02d}.h5', \r\n        monitor         = 'val_loss', \r\n        verbose         = 1, \r\n        save_best_only  = True, \r\n        mode            = 'min', \r\n        period          = 1\r\n    )\r\n    reduce_on_plateau = ReduceLROnPlateau(\r\n        monitor  = 'val_loss',\r\n        factor   = 0.1,\r\n        patience = 10,\r\n        verbose  = 1,\r\n        mode     = 'min',\r\n        epsilon  = 0.01,\r\n        cooldown = 0,\r\n    )\r\n    tensorboard = CustomTensorBoard(\r\n        log_dir                = tensorboard_logs,\r\n        write_graph            = True,\r\n        write_images           = True,\r\n    )    \r\n    return [early_stop, checkpoint, reduce_on_plateau, tensorboard]`\r\n\r\n\r\n```\r\nhistory = train_model.fit_generator(\r\n          generator        = train_generator, \r\n          validation_data = valid_generator,\r\n          steps_per_epoch  = len(train_generator) * config['train']['train_times'], \r\n          epochs           = config['train']['nb_epochs'] + config['train']['warmup_epochs'], \r\n          verbose          = 2 if config['train']['debug'] else 1,\r\n          callbacks        = callbacks, \r\n          workers          = 4,\r\n          max_queue_size   = 8\r\n      )\r\n```\r\nHere is a plot of loss, blue being validation loss and red being training loss:\r\n![loss](https://user-images.githubusercontent.com/84977346/120856838-622a6a80-c54e-11eb-87c4-1648ca4e0380.png)\r\n\r\nAnd here is a sample image of my dataset:\r\n\r\n![sample_img](https://user-images.githubusercontent.com/84977346/120857304-03b1bc00-c54f-11eb-99f1-8ca28796809a.png)\r\n\r\nwhere same numbers are top left/bottom right of a bounding box. This example was pretty messy, but other people who have used this dataset claim to reach 70%+ map on a default single shot detector with no modifications. My maximum was 0.2. I am using the default yolov3 and haven't made any configurations. \r\nHere is my config:\r\n`{\r\n    \"model\" : {\r\n        \"min_input_size\":       352,\r\n        \"max_input_size\":       352,\r\n        \"anchors\":              [13,58, 18,14, 30,31, 47,55, 50,128, 75,24, 95,69, 126,121, 161,208],\r\n        \"labels\":               [\"nlb\"]\r\n    },\r\n\r\n    \"train\": {\r\n        \"train_image_folder\":   \"/content/drive/MyDrive/yolo/nlb_train_image/\",\r\n        \"train_annot_folder\":   \"/content/drive/MyDrive/yolo/nlb_train_annot/\",\r\n\t      \"cache_name\":\t\t\"nlb_train.pkl\",\r\n\t      \"pretrained_weights\":   \"\",\r\n\r\n        \"train_times\":          1,\r\n        \"batch_size\":           16,\r\n        \"learning_rate\":        1e-4,\r\n        \"nb_epochs\":            200,\r\n        \"warmup_epochs\":        3,\r\n        \"ignore_thresh\":        0.4,\r\n        \"gpus\":                 \"0\",\r\n\r\n        \"grid_scales\":          [1,1,1],\r\n        \"obj_scale\":            5,\r\n        \"noobj_scale\":          1,\r\n        \"xywh_scale\":           1,\r\n        \"class_scale\":          1,\r\n\r\n        \"tensorboard_dir\":      \"logs\",\r\n        \"saved_weights_name\":   \"nlb.h5\",\r\n        \"debug\":                true\r\n    },\r\n\r\n    \"valid\": {\r\n        \"valid_image_folder\":   \"/content/drive/MyDrive/yolo/nlb_valid_image/\",\r\n        \"valid_annot_folder\":   \"/content/drive/MyDrive/yolo/nlb_valid_image/\",\r\n        \"cache_name\":\t\t\"nlb_valid.pkl\",\r\n\r\n        \"valid_times\":          1\r\n    }\r\n}\r\n`\r\n\r\nData augmented from 612 -> 7140 for training set, valid_set = 152, test_set = 141. I have played around with increasing validation set but still get poor results. I changed initial learning rate from 1e-3 to 1e-5 but again, poor results. If anyone is willing to test it themselves, here are links to the dataset:\r\n\r\ntrain images\r\nhttps://drive.google.com/drive/folders/1qmkCFNNuAtsOtFzQpmEgZyaN-DeSOuyr?usp=sharing\r\ntrain annot\r\nhttps://drive.google.com/drive/folders/1-5SZAcuOXz1Rt_eZ19RtVvgMXr8aId6j?usp=sharing\r\nvalid images\r\nhttps://drive.google.com/drive/folders/1Xxz28iVaxXMIDA_UVQPKOAs0KfU4KtVT?usp=sharing\r\nvalid annot\r\nhttps://drive.google.com/drive/folders/1Ml7DjEBwS50eUaMO378zYGdZTQsdfUNB?usp=sharing\r\ntest images\r\nhttps://drive.google.com/drive/folders/1tEiW-Xx74kWua810sR5e0OyWvPABhJ1z?usp=sharing\r\ntest annot\r\nhttps://drive.google.com/drive/folders/12jvZpb06tRopSpYLUSoiONOlvBWPV1ud?usp=sharing\r\ntrain.pkl file\r\nhttps://drive.google.com/file/d/1-5a1JGGYr6xP8ydCJOBOfhTPOym93u62/view?usp=sharing\r\nvalid.pkl file\r\nhttps://drive.google.com/file/d/1-86kPCtYQKmYVzxyFZfQoNIf03_YdwDA/view?usp=sharing\r\n\r\nI have spent an embarrassing amount of time trying to solve this problem.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/313/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/313/timeline","performed_via_github_app":null,"state_reason":null}