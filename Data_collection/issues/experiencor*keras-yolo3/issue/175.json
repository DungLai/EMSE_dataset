{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/175","repository_url":"https://api.github.com/repos/experiencor/keras-yolo3","labels_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/175/labels{/name}","comments_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/175/comments","events_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/175/events","html_url":"https://github.com/experiencor/keras-yolo3/issues/175","id":419845591,"node_id":"MDU6SXNzdWU0MTk4NDU1OTE=","number":175,"title":"Training on images with resolution 2288 × 1770 floods GPU memory even at batch_size=8","user":{"login":"hyejung-rachel","id":28971973,"node_id":"MDQ6VXNlcjI4OTcxOTcz","avatar_url":"https://avatars.githubusercontent.com/u/28971973?v=4","gravatar_id":"","url":"https://api.github.com/users/hyejung-rachel","html_url":"https://github.com/hyejung-rachel","followers_url":"https://api.github.com/users/hyejung-rachel/followers","following_url":"https://api.github.com/users/hyejung-rachel/following{/other_user}","gists_url":"https://api.github.com/users/hyejung-rachel/gists{/gist_id}","starred_url":"https://api.github.com/users/hyejung-rachel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hyejung-rachel/subscriptions","organizations_url":"https://api.github.com/users/hyejung-rachel/orgs","repos_url":"https://api.github.com/users/hyejung-rachel/repos","events_url":"https://api.github.com/users/hyejung-rachel/events{/privacy}","received_events_url":"https://api.github.com/users/hyejung-rachel/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2019-03-12T07:51:50Z","updated_at":"2019-12-01T00:31:19Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"`2019-03-12 15:23:38.002612: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Sum Total of in-use chunks: 14.42GiB\r\n2019-03-12 15:23:38.002618: I tensorflow/core/common_runtime/bfc_allocator.cc:680] Stats: \r\nLimit:                 15866508084\r\nInUse:                 15487862272\r\nMaxInUse:              15501256704\r\nNumAllocs:                    2093\r\nMaxAllocSize:           2034522624\r\n\r\n2019-03-12 15:23:38.002688: W tensorflow/core/common_runtime/bfc_allocator.cc:279] *********_******************************************************************************************\r\n2019-03-12 15:23:38.002714: W tensorflow/core/framework/op_kernel.cc:1318] OP_REQUIRES failed at transpose_op.cc:199 : Resource exhausted: OOM when allocating tensor with shape[4,32,1952,1952] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\nUsing TensorFlow backend.\r\n/anaconda/envs/py35/lib/python3.5/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\r\n  warnings.warn('`epsilon` argument is deprecated and '\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 280, in <module>\r\n    _main_(args)\r\n  File \"train.py\", line 257, in _main_\r\n    max_queue_size   = 8\r\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\", line 1415, in fit_generator\r\n    initial_epoch=initial_epoch)\r\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training_generator.py\", line 213, in fit_generator\r\n    class_weight=class_weight)\r\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\", line 1215, in train_on_batch\r\n    outputs = self.train_function(ins)\r\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 2666, in __call__\r\n    return self._call(inputs)\r\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 2636, in _call\r\n    fetched = self._callable_fn(*array_vals)\r\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1454, in __call__\r\n    self._session._session, self._handle, args, status, None)\r\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 519, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[4,32,1952,1952] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[Node: replica_0/model_1/leaky_0/LeakyRelu/mul = Mul[T=DT_FLOAT, _class=[\"loc:@train.../Reshape_1\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](replica_0/model_1/leaky_80/LeakyRelu/alpha, replica_0/model_1/bnorm_0/cond/Merge)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n `\r\n\r\nIt is not possible to reduce the resolution of the images I am training on. Can I use this model to train? Because trying to reduce the batch size doesn't work. Nor reducing the data. Thank you!","closed_by":null,"reactions":{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/175/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/175/timeline","performed_via_github_app":null,"state_reason":null}