{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/10","repository_url":"https://api.github.com/repos/experiencor/keras-yolo3","labels_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/10/labels{/name}","comments_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/10/comments","events_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/10/events","html_url":"https://github.com/experiencor/keras-yolo3/issues/10","id":314431325,"node_id":"MDU6SXNzdWUzMTQ0MzEzMjU=","number":10,"title":"Getting error while training","user":{"login":"ninjakx","id":29797787,"node_id":"MDQ6VXNlcjI5Nzk3Nzg3","avatar_url":"https://avatars.githubusercontent.com/u/29797787?v=4","gravatar_id":"","url":"https://api.github.com/users/ninjakx","html_url":"https://github.com/ninjakx","followers_url":"https://api.github.com/users/ninjakx/followers","following_url":"https://api.github.com/users/ninjakx/following{/other_user}","gists_url":"https://api.github.com/users/ninjakx/gists{/gist_id}","starred_url":"https://api.github.com/users/ninjakx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ninjakx/subscriptions","organizations_url":"https://api.github.com/users/ninjakx/orgs","repos_url":"https://api.github.com/users/ninjakx/repos","events_url":"https://api.github.com/users/ninjakx/events{/privacy}","received_events_url":"https://api.github.com/users/ninjakx/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2018-04-15T16:45:01Z","updated_at":"2019-12-28T10:21:51Z","closed_at":"2018-04-15T17:04:47Z","author_association":"NONE","active_lock_reason":null,"body":"`\r\n2018-04-15 16:37:36.355877: W tensorflow/core/common_runtime/bfc_allocator.cc:279] ****************************************************************************************************\r\n2018-04-15 16:37:36.362129: W tensorflow/core/framework/op_kernel.cc:1202] OP_REQUIRES failed at conv_ops.cc:677 : Resource exhausted: OOM when allocating tensor with shape[8,1024,13,13] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1361, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1340, in _run_fn\r\n    target_list, status, run_metadata)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\", line 516, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[8,13,13,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[Node: replica_0/model_1/conv_73/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](replica_0/model_1/leaky_72/LeakyRelu/Maximum, conv_73/kernel/read/_2395)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\t [[Node: training/Adam/gradients/replica_0/model_1/bnorm_47/FusedBatchNorm_grad/FusedBatchNormGrad/_5027 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_39158...chNormGrad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 251, in <module>\r\n    _main_(args)\r\n  File \"train.py\", line 210, in _main_\r\n    max_queue_size   = 8\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 2224, in fit_generator\r\n    class_weight=class_weight)\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1883, in train_on_batch\r\n    outputs = self.train_function(ins)\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2478, in __call__\r\n    **self.session_kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 905, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1137, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1355, in _do_run\r\n    options, run_metadata)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1374, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[8,13,13,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[Node: replica_0/model_1/conv_73/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](replica_0/model_1/leaky_72/LeakyRelu/Maximum, conv_73/kernel/read/_2395)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\t [[Node: training/Adam/gradients/replica_0/model_1/bnorm_47/FusedBatchNorm_grad/FusedBatchNormGrad/_5027 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_39158...chNormGrad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nCaused by op 'replica_0/model_1/conv_73/convolution', defined at:\r\n  File \"train.py\", line 251, in <module>\r\n    _main_(args)\r\n  File \"train.py\", line 190, in _main_\r\n    saved_weights_name  = config['train']['saved_weights_name']\r\n  File \"train.py\", line 113, in create_model\r\n    train_model = multi_gpu_model(template_model, gpus=multi_gpu)\r\n  File \"/content/drive/drive/keras-yolo3/utils/multi_gpu_model.py\", line 48, in multi_gpu_model\r\n    outputs = model(inputs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 619, in __call__\r\n    output = self.call(inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 2085, in call\r\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 2236, in run_internal_graph\r\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/convolutional.py\", line 168, in call\r\n    dilation_rate=self.dilation_rate)\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 3335, in conv2d\r\n    data_format=tf_data_format)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\", line 781, in convolution\r\n    return op(input, filter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\", line 869, in __call__\r\n    return self.conv_op(inp, filter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\", line 521, in __call__\r\n    return self.call(inp, filter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\", line 205, in __call__\r\n    name=self.name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[8,13,13,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[Node: replica_0/model_1/conv_73/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](replica_0/model_1/leaky_72/LeakyRelu/Maximum, conv_73/kernel/read/_2395)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\t [[Node: training/Adam/gradients/replica_0/model_1/bnorm_47/FusedBatchNorm_grad/FusedBatchNormGrad/_5027 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_39158...chNormGrad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n`","closed_by":{"login":"ninjakx","id":29797787,"node_id":"MDQ6VXNlcjI5Nzk3Nzg3","avatar_url":"https://avatars.githubusercontent.com/u/29797787?v=4","gravatar_id":"","url":"https://api.github.com/users/ninjakx","html_url":"https://github.com/ninjakx","followers_url":"https://api.github.com/users/ninjakx/followers","following_url":"https://api.github.com/users/ninjakx/following{/other_user}","gists_url":"https://api.github.com/users/ninjakx/gists{/gist_id}","starred_url":"https://api.github.com/users/ninjakx/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ninjakx/subscriptions","organizations_url":"https://api.github.com/users/ninjakx/orgs","repos_url":"https://api.github.com/users/ninjakx/repos","events_url":"https://api.github.com/users/ninjakx/events{/privacy}","received_events_url":"https://api.github.com/users/ninjakx/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/10/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/10/timeline","performed_via_github_app":null,"state_reason":"completed"}