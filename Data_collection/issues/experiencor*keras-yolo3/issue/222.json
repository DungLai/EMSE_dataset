{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/222","repository_url":"https://api.github.com/repos/experiencor/keras-yolo3","labels_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/222/labels{/name}","comments_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/222/comments","events_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/222/events","html_url":"https://github.com/experiencor/keras-yolo3/issues/222","id":490137108,"node_id":"MDU6SXNzdWU0OTAxMzcxMDg=","number":222,"title":"Resource Exhausted...","user":{"login":"pkr97","id":15801327,"node_id":"MDQ6VXNlcjE1ODAxMzI3","avatar_url":"https://avatars.githubusercontent.com/u/15801327?v=4","gravatar_id":"","url":"https://api.github.com/users/pkr97","html_url":"https://github.com/pkr97","followers_url":"https://api.github.com/users/pkr97/followers","following_url":"https://api.github.com/users/pkr97/following{/other_user}","gists_url":"https://api.github.com/users/pkr97/gists{/gist_id}","starred_url":"https://api.github.com/users/pkr97/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pkr97/subscriptions","organizations_url":"https://api.github.com/users/pkr97/orgs","repos_url":"https://api.github.com/users/pkr97/repos","events_url":"https://api.github.com/users/pkr97/events{/privacy}","received_events_url":"https://api.github.com/users/pkr97/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2019-09-06T05:30:09Z","updated_at":"2019-10-03T15:45:48Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"OS: Ubuntu 16.04\r\nTF Version : 1.13.1\r\nPython 3.5\r\n==========================================\r\n\r\n        \"train_times\":          3,\r\n        \"batch_size\":           16,\r\n        \"learning_rate\":        1e-4,\r\n        \"nb_epochs\":            100,\r\n        \"warmup_epochs\":        3,\r\n        \"ignore_thresh\":        0.5,\r\n        \"gpus\":                 \"0,1\",\r\n\r\n        \"grid_scales\":          [1,1,1],\r\n        \"obj_scale\":            5,\r\n        \"noobj_scale\":          1,\r\n        \"xywh_scale\":           1,\r\n        \"class_scale\":          1,\r\n\r\n===========================================\r\n\r\n    train_model.fit_generator(\r\n        generator        = train_generator, \r\n        steps_per_epoch  = len(train_generator) * config['train']['train_times'], \r\n        epochs           = config['train']['nb_epochs'] + config['train']['warmup_epochs'], \r\n        verbose          = 2 if config['train']['debug'] else 1,\r\n        callbacks        = callbacks, \r\n        workers          = 4,\r\n        max_queue_size   = 8\r\n    )\r\n\r\n===========================================\r\n\r\n\r\ntotalMemory: 3.95GiB freeMemory: 3.41GiB\r\n2019-09-06 10:52:35.252845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-09-06 10:52:35.253593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-09-06 10:52:35.253612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \r\n2019-09-06 10:52:35.253620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \r\n2019-09-06 10:52:35.253748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3190 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n\r\n\r\n\r\n.\r\n.\r\n.\r\n2019-09-06 10:55:03.287913: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Sum Total of in-use chunks: 2.61GiB\r\n2019-09-06 10:55:03.287925: I tensorflow/core/common_runtime/bfc_allocator.cc:647] Stats: \r\nLimit:                  3345481728\r\nInUse:                  2806625280\r\nMaxInUse:               3160186368\r\nNumAllocs:                    1986\r\nMaxAllocSize:            872216064\r\n\r\n\r\n2019-09-06 10:55:03.288000: W tensorflow/core/common_runtime/bfc_allocator.cc:271] **********************************___************************____*****************____************xx\r\n2019-09-06 10:55:03.288027: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at transpose_op.cc:199 : Resource exhausted: OOM when allocating tensor with shape[8,32,417,417] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 281, in <module>\r\n    _main_(args)\r\n  File \"train.py\", line 258, in _main_\r\n    max_queue_size   = 8\r\n  File \"/home/pkumars/TensorFlow/venv/lib/python3.5/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/home/pkumars/TensorFlow/venv/lib/python3.5/site-packages/keras/engine/training.py\", line 1658, in fit_generator\r\n    initial_epoch=initial_epoch)\r\n  File \"/home/pkumars/TensorFlow/venv/lib/python3.5/site-packages/keras/engine/training_generator.py\", line 215, in fit_generator\r\n    class_weight=class_weight)\r\n  File \"/home/pkumars/TensorFlow/venv/lib/python3.5/site-packages/keras/engine/training.py\", line 1449, in train_on_batch\r\n    outputs = self.train_function(ins)\r\n  File \"/home/pkumars/TensorFlow/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 2979, in __call__\r\n    return self._call(inputs)\r\n  File \"/home/pkumars/TensorFlow/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 2937, in _call\r\n    fetched = self._callable_fn(*array_vals)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1439, in __call__\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[8,417,417,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[{{node replica_1/model_1/zero_padding2d_1/Pad}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\t [[{{node training/Adam/gradients/replica_0/model_1/bnorm_13/FusedBatchNorm_grad/FusedBatchNormGrad}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n==========================================================\r\n\r\nI see that there is an error and that is related to resource.\r\n\" Resource exhausted: OOM when allocating tensor with shape[8,32,417,417] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n \"\r\n\r\nHow can I train with available resources?\r\n\r\nI understand that process can be slow but it's possible to train for a single class of Raccoon dataset with available resources.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/222/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/experiencor/keras-yolo3/issues/222/timeline","performed_via_github_app":null,"state_reason":null}