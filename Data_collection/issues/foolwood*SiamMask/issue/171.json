{"url":"https://api.github.com/repos/foolwood/SiamMask/issues/171","repository_url":"https://api.github.com/repos/foolwood/SiamMask","labels_url":"https://api.github.com/repos/foolwood/SiamMask/issues/171/labels{/name}","comments_url":"https://api.github.com/repos/foolwood/SiamMask/issues/171/comments","events_url":"https://api.github.com/repos/foolwood/SiamMask/issues/171/events","html_url":"https://github.com/foolwood/SiamMask/issues/171","id":714177028,"node_id":"MDU6SXNzdWU3MTQxNzcwMjg=","number":171,"title":"RuntimeError: cuda runtime error (11) : invalid argument at /opt/conda/conda-bld/pytorch_1535491974311/work/aten/src/THC/THCGeneral.cpp:663","user":{"login":"danho47","id":50475777,"node_id":"MDQ6VXNlcjUwNDc1Nzc3","avatar_url":"https://avatars.githubusercontent.com/u/50475777?v=4","gravatar_id":"","url":"https://api.github.com/users/danho47","html_url":"https://github.com/danho47","followers_url":"https://api.github.com/users/danho47/followers","following_url":"https://api.github.com/users/danho47/following{/other_user}","gists_url":"https://api.github.com/users/danho47/gists{/gist_id}","starred_url":"https://api.github.com/users/danho47/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danho47/subscriptions","organizations_url":"https://api.github.com/users/danho47/orgs","repos_url":"https://api.github.com/users/danho47/repos","events_url":"https://api.github.com/users/danho47/events{/privacy}","received_events_url":"https://api.github.com/users/danho47/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2020-10-03T21:11:04Z","updated_at":"2021-03-11T15:14:54Z","closed_at":"2020-10-10T06:46:53Z","author_association":"NONE","active_lock_reason":null,"body":"I want to train, but I get this error,\r\n> PyTorch version: 0.4.1.post2\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\nOS: Ubuntu 18.04.4 LTS\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCMake version: Could not collect\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: GPU 0: GeForce RTX 2070\r\nNvidia driver version: 450.57\r\ncuDNN version: Could not collect\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] cuda90                    1.0                  h6433d27_0    pytorch\r\n[conda] pytorch                   0.4.1           py36_py35_py27__9.0.176_7.1.2_2    pytorch\r\n[conda] torch                     0.4.1                    pypi_0    pypi\r\n[conda] torchvision               0.2.1                    pypi_0    pypi\r\n        OpenCV (3.4.3)\r\n[2020-10-04 05:58:21,487-rk0-train_siammask.py#128] Namespace(arch='', batch=64, clip=10.0, config='config.json', epochs=20, log='logs/log.txt', log_dir='board', lr=0.001, momentum=0.9, pretrained='', print_freq=10, resume='', save_dir='snapshot', start_epoch=0, weight_decay=0.0001, workers=20)\r\n[2020-10-04 05:58:21,487-rk0-train_siammask.py#131] config \r\n{\r\n    \"network\": {\r\n        \"arch\": \"Custom\"\r\n    },\r\n    \"hp\": {\r\n        \"instance_size\": 255,\r\n        \"base_size\": 8\r\n    },\r\n    \"lr\": {\r\n        \"feature_lr_mult\": 1.0,\r\n        \"rpn_lr_mult\": 1.0,\r\n        \"mask_lr_mult\": 1.0,\r\n        \"type\": \"log\",\r\n        \"start_lr\": 0.005,\r\n        \"end_lr\": 0.0025,\r\n        \"warmup\": {\r\n            \"start_lr\": 0.001,\r\n            \"end_lr\": 0.005,\r\n            \"type\": \"step\",\r\n            \"step\": 1,\r\n            \"epoch\": 5\r\n        }\r\n    },\r\n    \"loss\": {\r\n        \"weight\": [\r\n            1.0,\r\n            1.2,\r\n            36\r\n        ],\r\n        \"reg\": {\r\n            \"loss\": \"L1Loss\"\r\n        },\r\n        \"cls\": {\r\n            \"split\": true\r\n        }\r\n    },\r\n    \"train_datasets\": {\r\n        \"datasets\": {\r\n            \"ytb_vos\": {\r\n                \"root\": \"../../data/ytb_vos/crop511\",\r\n                \"anno\": \"../../data/ytb_vos/train.json\",\r\n                \"num_use\": 200000,\r\n                \"frame_range\": 20\r\n            },\r\n            \"vid\": {\r\n                \"root\": \"../../data/vid/crop511\",\r\n                \"anno\": \"../../data/vid/train.json\",\r\n                \"num_use\": 200000,\r\n                \"frame_range\": 100\r\n            },\r\n            \"coco\": {\r\n                \"root\": \"../../data/coco/crop511\",\r\n                \"anno\": \"../../data/coco/train2017.json\",\r\n                \"frame_range\": 1\r\n            },\r\n            \"det\": {\r\n                \"root\": \"../../data/det/crop511\",\r\n                \"anno\": \"../../data/det/train.json\",\r\n                \"num_use\": 100000,\r\n                \"frame_range\": 1\r\n            }\r\n        },\r\n        \"template_size\": 127,\r\n        \"search_size\": 255,\r\n        \"base_size\": 8,\r\n        \"size\": 25,\r\n        \"num\": 600000,\r\n        \"augmentation\": {\r\n            \"template\": {\r\n                \"shift\": 4,\r\n                \"scale\": 0.05\r\n            },\r\n            \"search\": {\r\n                \"shift\": 64,\r\n                \"scale\": 0.18,\r\n                \"blur\": 0.18\r\n            },\r\n            \"neg\": 0.2,\r\n            \"gray\": 0.25\r\n        }\r\n    },\r\n    \"val_datasets\": {\r\n        \"datasets\": {\r\n            \"vid\": {\r\n                \"root\": \"../../data/vid/crop511\",\r\n                \"anno\": \"../../data/vid/val.json\",\r\n                \"num_use\": 1000\r\n            }\r\n        },\r\n        \"template_size\": 127,\r\n        \"search_size\": 255,\r\n        \"size\": 17,\r\n        \"num\": 1000,\r\n        \"augmentation\": {\r\n            \"template\": {\r\n                \"shift\": 0,\r\n                \"scale\": 0.0\r\n            },\r\n            \"search\": {\r\n                \"shift\": 12,\r\n                \"scale\": 0.18\r\n            },\r\n            \"neg\": 0,\r\n            \"gray\": 0\r\n        }\r\n    },\r\n    \"anchors\": {\r\n        \"stride\": 8,\r\n        \"ratios\": [\r\n            0.33,\r\n            0.5,\r\n            1,\r\n            2,\r\n            3\r\n        ],\r\n        \"scales\": [\r\n            8\r\n        ],\r\n        \"round_dight\": 0\r\n    },\r\n    \"clip\": {\r\n        \"feature\": 10.0,\r\n        \"rpn\": 10.0,\r\n        \"split\": false\r\n    }\r\n}\r\n[2020-10-04 05:58:21,488-rk0-train_siammask.py# 78] build train dataset\r\n[2020-10-04 05:58:21,488-rk0-siam_mask_dataset.py# 36] loading ../../data/ytb_vos/train.json\r\n[2020-10-04 05:58:21,676-rk0-siam_mask_dataset.py# 74] ../../data/ytb_vos/train.json loaded.\r\n[2020-10-04 05:58:21,764-rk0-siam_mask_dataset.py#134] SubDataSet ytb_vos start-index 0 select [200000/3000] path {}.{}.{}.jpg\r\n[2020-10-04 05:58:21,764-rk0-siam_mask_dataset.py# 36] loading ../../data/vid/train.json\r\n[2020-10-04 05:58:24,045-rk0-siam_mask_dataset.py# 74] ../../data/vid/train.json loaded.\r\n[2020-10-04 05:58:24,132-rk0-siam_mask_dataset.py#134] SubDataSet vid start-index 3000 select [200000/3862] path {}.{}.{}.jpg\r\n[2020-10-04 05:58:24,132-rk0-siam_mask_dataset.py# 36] loading ../../data/coco/train2017.json\r\n[2020-10-04 05:58:26,252-rk0-siam_mask_dataset.py#118] Error, coco train2017/000000512390 12 [366.3, 120.6, 372.24, 120.6]\r\n[2020-10-04 05:58:27,511-rk0-siam_mask_dataset.py# 74] ../../data/coco/train2017.json loaded.\r\n[2020-10-04 05:58:27,571-rk0-siam_mask_dataset.py#134] SubDataSet coco start-index 6862 select [117266/117266] path {}.{}.{}.jpg\r\n[2020-10-04 05:58:27,571-rk0-siam_mask_dataset.py# 36] loading ../../data/det/train.json\r\n[2020-10-04 05:58:29,330-rk0-siam_mask_dataset.py#118] Error, det ILSVRC2014_train_0006/ILSVRC2014_train_00060036 01 [1, 498, 0, 498]\r\n[2020-10-04 05:58:29,944-rk0-siam_mask_dataset.py# 74] ../../data/det/train.json loaded.\r\n[2020-10-04 05:58:30,128-rk0-siam_mask_dataset.py#134] SubDataSet det start-index 124128 select [100000/333474] path {}.{}.{}.jpg\r\n[2020-10-04 05:58:44,469-rk0-siam_mask_dataset.py#508] shuffle done!\r\n[2020-10-04 05:58:44,469-rk0-siam_mask_dataset.py#509] dataset length 12000000\r\n[2020-10-04 05:58:44,472-rk0-siam_mask_dataset.py#477] dataset informations: \r\n{\r\n    \"template\": 127,\r\n    \"search\": 255,\r\n    \"template_small\": false,\r\n    \"gray\": 0.25,\r\n    \"neg\": 0.2,\r\n    \"inner_neg\": 0,\r\n    \"crop_size\": 0,\r\n    \"anchor_target\": {\r\n        \"thr_high\": 0.6,\r\n        \"thr_low\": 0.3,\r\n        \"negative\": 16,\r\n        \"rpn_batch\": 64,\r\n        \"positive\": 16\r\n    },\r\n    \"num\": 600000\r\n}\r\n[2020-10-04 05:58:59,017-rk0-siam_mask_dataset.py#508] shuffle done!\r\n[2020-10-04 05:58:59,018-rk0-siam_mask_dataset.py#509] dataset length 12000000\r\n[2020-10-04 05:58:59,021-rk0-train_siammask.py# 82] build val dataset\r\n[2020-10-04 05:58:59,021-rk0-siam_mask_dataset.py# 36] loading ../../data/vid/val.json\r\n[2020-10-04 05:58:59,695-rk0-siam_mask_dataset.py# 74] ../../data/vid/val.json loaded.\r\n[2020-10-04 05:58:59,696-rk0-siam_mask_dataset.py#134] SubDataSet vid start-index 0 select [1000/555] path {}.{}.{}.jpg\r\n[2020-10-04 05:58:59,697-rk0-siam_mask_dataset.py#508] shuffle done!\r\n[2020-10-04 05:58:59,697-rk0-siam_mask_dataset.py#509] dataset length 1000\r\n[2020-10-04 05:58:59,697-rk0-siam_mask_dataset.py#477] dataset informations: \r\n{\r\n    \"template\": 127,\r\n    \"search\": 255,\r\n    \"template_small\": false,\r\n    \"gray\": 0,\r\n    \"neg\": 0,\r\n    \"inner_neg\": 0,\r\n    \"crop_size\": 0,\r\n    \"anchor_target\": {\r\n        \"thr_high\": 0.6,\r\n        \"thr_low\": 0.3,\r\n        \"negative\": 16,\r\n        \"rpn_batch\": 64,\r\n        \"positive\": 16\r\n    },\r\n    \"num\": 1000\r\n}\r\n[2020-10-04 05:58:59,698-rk0-siam_mask_dataset.py#508] shuffle done!\r\n[2020-10-04 05:58:59,698-rk0-siam_mask_dataset.py#509] dataset length 1000\r\n[2020-10-04 05:58:59,698-rk0-train_siammask.py# 93] build dataset done\r\n[2020-10-04 05:58:59,901-rk0-load_helper.py# 31] load pretrained model from resnet.model\r\n[2020-10-04 05:59:01,346-rk0-load_helper.py# 25] remove prefix 'module.'\r\n[2020-10-04 05:59:01,347-rk0-load_helper.py# 13] [Warning] missing keys: {'layer3.4.bn2.num_batches_tracked', 'layer3.5.bn2.num_batches_tracked', 'layer3.4.bn1.num_batches_tracked', 'layer2.3.bn3.num_batches_tracked', 'layer2.0.bn3.num_batches_tracked', 'layer3.0.downsample.1.num_batches_tracked', 'layer1.2.bn2.num_batches_tracked', 'layer1.0.bn1.num_batches_tracked', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.bn3.num_batches_tracked', 'layer3.1.bn1.num_batches_tracked', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.bn3.num_batches_tracked', 'layer2.1.bn1.num_batches_tracked', 'layer2.0.downsample.1.num_batches_tracked', 'layer1.0.downsample.1.num_batches_tracked', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.bn1.num_batches_tracked', 'bn1.num_batches_tracked', 'layer1.2.bn3.num_batches_tracked', 'layer1.1.bn1.num_batches_tracked', 'layer3.3.bn2.num_batches_tracked', 'layer3.5.bn3.num_batches_tracked', 'layer1.0.bn2.num_batches_tracked', 'layer3.3.bn3.num_batches_tracked', 'layer3.2.bn1.num_batches_tracked', 'layer1.1.bn2.num_batches_tracked', 'layer2.3.bn1.num_batches_tracked', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.bn1.num_batches_tracked', 'layer1.0.bn3.num_batches_tracked', 'layer3.3.bn1.num_batches_tracked', 'layer2.0.bn1.num_batches_tracked', 'layer3.2.bn2.num_batches_tracked', 'layer3.5.bn1.num_batches_tracked', 'layer1.1.bn3.num_batches_tracked', 'layer2.0.bn2.num_batches_tracked', 'layer1.2.bn1.num_batches_tracked', 'layer3.2.bn3.num_batches_tracked', 'layer3.4.bn3.num_batches_tracked', 'layer3.0.bn2.num_batches_tracked', 'layer2.3.bn2.num_batches_tracked'}\r\n[2020-10-04 05:59:01,347-rk0-load_helper.py# 14] missing keys:43\r\n[2020-10-04 05:59:01,347-rk0-load_helper.py# 16] [Warning] unused_pretrained_keys: {'layer4.0.bn2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn1.weight', 'layer4.1.conv3.weight', 'layer4.1.conv1.weight', 'layer4.0.bn2.running_var', 'layer4.0.bn1.bias', 'layer4.0.bn2.bias', 'layer4.0.bn1.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.0.bn3.running_mean', 'layer4.1.conv2.weight', 'layer4.2.bn3.weight', 'layer4.0.bn2.running_mean', 'layer4.0.bn3.weight', 'layer4.0.downsample.1.running_mean', 'layer4.2.conv3.weight', 'layer4.1.bn1.running_var', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.conv3.weight', 'layer4.2.bn2.weight', 'layer4.0.bn3.running_var', 'layer4.2.conv2.weight', 'layer4.2.bn2.running_var', 'layer4.0.downsample.0.weight', 'layer4.2.bn1.running_var', 'layer4.1.bn2.bias', 'layer4.0.downsample.1.bias', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.1.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.0.downsample.1.weight', 'layer4.2.bn2.running_mean', 'layer4.0.conv1.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.weight', 'layer4.0.bn3.bias', 'layer4.1.bn3.running_var', 'layer4.2.bn2.bias', 'layer4.1.bn1.running_mean', 'layer4.2.bn1.bias', 'layer4.0.downsample.1.running_var', 'layer4.0.conv2.weight', 'layer4.0.bn1.weight', 'layer4.1.bn2.running_mean'}\r\n[2020-10-04 05:59:01,347-rk0-load_helper.py# 17] unused checkpoint keys:50\r\n[2020-10-04 05:59:01,347-rk0-load_helper.py# 18] used keys:215\r\n[2020-10-04 05:59:01,358-rk0-features.py# 66] Current training 0 layers:\t\r\n[2020-10-04 05:59:01,359-rk0-features.py# 66] Current training 1 layers:\t\r\n[2020-10-04 05:59:01,384-rk0-train_siammask.py#146] Custom(\r\n  (upSample): UpsamplingBilinear2d(size=[127, 127], mode=bilinear)\r\n  (features): ResDown(\r\n    (features): ResNet(\r\n      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), bias=False)\r\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n      (relu): ReLU(inplace)\r\n      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\r\n      (layer1): Sequential(\r\n        (0): Bottleneck(\r\n          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (relu): ReLU(inplace)\r\n          (downsample): Sequential(\r\n            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          )\r\n        )\r\n        (1): Bottleneck(\r\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (relu): ReLU(inplace)\r\n        )\r\n        (2): Bottleneck(\r\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (relu): ReLU(inplace)\r\n        )\r\n      )\r\n      (layer2): Sequential(\r\n        (0): Bottleneck(\r\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\r\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (relu): ReLU(inplace)\r\n          (downsample): Sequential(\r\n            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), bias=False)\r\n            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          )\r\n        )\r\n        (1): Bottleneck(\r\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (relu): ReLU(inplace)\r\n        )\r\n        (2): Bottleneck(\r\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (relu): ReLU(inplace)\r\n        )\r\n        (3): Bottleneck(\r\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (relu): ReLU(inplace)\r\n        )\r\n      )\r\n      (layer3): Sequential(\r\n        (0): Bottleneck(\r\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (relu): ReLU(inplace)\r\n          (downsample): Sequential(\r\n            (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          )\r\n        )\r\n        (1): Bottleneck(\r\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\r\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (relu): ReLU(inplace)\r\n        )\r\n        (2): Bottleneck(\r\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\r\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (relu): ReLU(inplace)\r\n        )\r\n        (3): Bottleneck(\r\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\r\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (relu): ReLU(inplace)\r\n        )\r\n        (4): Bottleneck(\r\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\r\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (relu): ReLU(inplace)\r\n        )\r\n        (5): Bottleneck(\r\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\r\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n          (relu): ReLU(inplace)\r\n        )\r\n      )\r\n    )\r\n    (downsample): ResDownS(\r\n      (downsample): Sequential(\r\n        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n      )\r\n    )\r\n  )\r\n  (rpn_model): UP(\r\n    (cls): DepthCorr(\r\n      (conv_kernel): Sequential(\r\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\r\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n        (2): ReLU(inplace)\r\n      )\r\n      (conv_search): Sequential(\r\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\r\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n        (2): ReLU(inplace)\r\n      )\r\n      (head): Sequential(\r\n        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n        (2): ReLU(inplace)\r\n        (3): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))\r\n      )\r\n    )\r\n    (loc): DepthCorr(\r\n      (conv_kernel): Sequential(\r\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\r\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n        (2): ReLU(inplace)\r\n      )\r\n      (conv_search): Sequential(\r\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\r\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n        (2): ReLU(inplace)\r\n      )\r\n      (head): Sequential(\r\n        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n        (2): ReLU(inplace)\r\n        (3): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\r\n      )\r\n    )\r\n  )\r\n  (mask_model): MaskCorr(\r\n    (mask): DepthCorr(\r\n      (conv_kernel): Sequential(\r\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\r\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n        (2): ReLU(inplace)\r\n      )\r\n      (conv_search): Sequential(\r\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\r\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n        (2): ReLU(inplace)\r\n      )\r\n      (head): Sequential(\r\n        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n        (2): ReLU(inplace)\r\n        (3): Conv2d(256, 3969, kernel_size=(1, 1), stride=(1, 1))\r\n      )\r\n    )\r\n  )\r\n)\r\n[2020-10-04 05:59:01,406-rk0-train_siammask.py#164] (WarmUPScheduler) lr spaces: \r\n[0.001      0.00137973 0.00190365 0.00262653 0.0036239  0.005\r\n 0.00475848 0.00452862 0.00430986 0.00410168 0.00390355 0.00371499\r\n 0.00353553 0.00336475 0.00320222 0.00304753 0.00290032 0.00276022\r\n 0.00262689 0.0025    ]\r\n[2020-10-04 05:59:01,406-rk0-train_siammask.py#166] model prepare done\r\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1535491974311/work/aten/src/THC/THCGeneral.cpp line=663 error=11 : invalid argument\r\nTraceback (most recent call last):\r\n  File \"/home/honda/SiamMask/tools/train_siammask.py\", line 292, in <module>\r\n    main()\r\n  File \"/home/honda/SiamMask/tools/train_siammask.py\", line 168, in main\r\n    train(train_loader, dist_model, optimizer, lr_scheduler, args.start_epoch, cfg)\r\n  File \"/home/honda/SiamMask/tools/train_siammask.py\", line 236, in train\r\n    outputs = model(x)\r\n  File \"/home/honda/anaconda3/envs/siammask/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/honda/anaconda3/envs/siammask/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 121, in forward\r\n    return self.module(*inputs[0], **kwargs[0])\r\n  File \"/home/honda/anaconda3/envs/siammask/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/honda/SiamMask/models/siammask.py\", line 96, in forward\r\n    self.run(template, search, softmax=self.training)\r\n  File \"/home/honda/SiamMask/models/siammask.py\", line 61, in run\r\n    template_feature = self.feature_extractor(template)\r\n  File \"/home/honda/SiamMask/models/siammask.py\", line 37, in feature_extractor\r\n    return self.features(x)\r\n  File \"/home/honda/anaconda3/envs/siammask/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/honda/SiamMask/experiments/siammask_base/custom.py\", line 58, in forward\r\n    output = self.features(x)\r\n  File \"/home/honda/anaconda3/envs/siammask/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/honda/SiamMask/experiments/siammask_base/resnet.py\", line 219, in forward\r\n    x = self.conv1(x)\r\n  File \"/home/honda/anaconda3/envs/siammask/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/honda/anaconda3/envs/siammask/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 301, in forward\r\n    self.padding, self.dilation, self.groups)\r\nRuntimeError: cuda runtime error (11) : invalid argument at /opt/conda/conda-bld/pytorch_1535491974311/work/aten/src/THC/THCGeneral.cpp:663\r\n\r\nPlease, some advice","closed_by":{"login":"danho47","id":50475777,"node_id":"MDQ6VXNlcjUwNDc1Nzc3","avatar_url":"https://avatars.githubusercontent.com/u/50475777?v=4","gravatar_id":"","url":"https://api.github.com/users/danho47","html_url":"https://github.com/danho47","followers_url":"https://api.github.com/users/danho47/followers","following_url":"https://api.github.com/users/danho47/following{/other_user}","gists_url":"https://api.github.com/users/danho47/gists{/gist_id}","starred_url":"https://api.github.com/users/danho47/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/danho47/subscriptions","organizations_url":"https://api.github.com/users/danho47/orgs","repos_url":"https://api.github.com/users/danho47/repos","events_url":"https://api.github.com/users/danho47/events{/privacy}","received_events_url":"https://api.github.com/users/danho47/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/foolwood/SiamMask/issues/171/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/foolwood/SiamMask/issues/171/timeline","performed_via_github_app":null,"state_reason":"completed"}