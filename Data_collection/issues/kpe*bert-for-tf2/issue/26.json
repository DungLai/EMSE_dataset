{"url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/26","repository_url":"https://api.github.com/repos/kpe/bert-for-tf2","labels_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/26/labels{/name}","comments_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/26/comments","events_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/26/events","html_url":"https://github.com/kpe/bert-for-tf2/issues/26","id":537658858,"node_id":"MDU6SXNzdWU1Mzc2NTg4NTg=","number":26,"title":"Question: Sentence Embedding from BERT layer","user":{"login":"brunopistone","id":10196125,"node_id":"MDQ6VXNlcjEwMTk2MTI1","avatar_url":"https://avatars.githubusercontent.com/u/10196125?v=4","gravatar_id":"","url":"https://api.github.com/users/brunopistone","html_url":"https://github.com/brunopistone","followers_url":"https://api.github.com/users/brunopistone/followers","following_url":"https://api.github.com/users/brunopistone/following{/other_user}","gists_url":"https://api.github.com/users/brunopistone/gists{/gist_id}","starred_url":"https://api.github.com/users/brunopistone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/brunopistone/subscriptions","organizations_url":"https://api.github.com/users/brunopistone/orgs","repos_url":"https://api.github.com/users/brunopistone/repos","events_url":"https://api.github.com/users/brunopistone/events{/privacy}","received_events_url":"https://api.github.com/users/brunopistone/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2019-12-13T16:58:28Z","updated_at":"2019-12-15T13:21:51Z","closed_at":"2019-12-15T00:09:55Z","author_association":"NONE","active_lock_reason":null,"body":"Hi, I've followed your guide for implementing BERT model as Keras layer. I have a question about the output of this layer; I've written this model:\r\n\r\n`\r\nmodel_word_embedding = tf.keras.Sequential([\r\n                tf.keras.layers.Input(shape=(4,), dtype='int32', name='input_ids'),\r\n                bert_layer\r\n])\r\n```\r\nThen I want to extract the embeddings for a word: \r\n`\r\nsentences = [\"ciao\"]\r\npredict = model_word_embedding .predict(sentences)\r\n```\r\n\r\nI receive this \r\n```\r\nprint(predict)\r\nprint(len(predict))\r\n\r\n...\r\n\r\n[[[-0.02768866 -0.7341324   1.9084396  ... -0.65953904  0.26496622\r\n    1.1610721 ]\r\n  [-0.19322394 -1.3134469   0.10383344 ...  1.1250225  -0.2988368\r\n   -0.2323082 ]\r\n  [-1.4576151  -1.4579685   0.78580517 ... -0.8898649  -1.1016986\r\n    0.6008501 ]\r\n  [ 1.41647    -0.92478925 -1.3651332  ... -0.9197768  -1.5469263\r\n    0.03305872]]]\r\n4\r\n```\r\n\r\nMy quesiton is: Since I passed only one word with max_seq_lenght equals to 4, I expect for the output one vector instead of 4.\r\nWhy 4 vectors? \r\nHow can I obtain the embeddings for a sentence?","closed_by":{"login":"kpe","id":2535923,"node_id":"MDQ6VXNlcjI1MzU5MjM=","avatar_url":"https://avatars.githubusercontent.com/u/2535923?v=4","gravatar_id":"","url":"https://api.github.com/users/kpe","html_url":"https://github.com/kpe","followers_url":"https://api.github.com/users/kpe/followers","following_url":"https://api.github.com/users/kpe/following{/other_user}","gists_url":"https://api.github.com/users/kpe/gists{/gist_id}","starred_url":"https://api.github.com/users/kpe/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kpe/subscriptions","organizations_url":"https://api.github.com/users/kpe/orgs","repos_url":"https://api.github.com/users/kpe/repos","events_url":"https://api.github.com/users/kpe/events{/privacy}","received_events_url":"https://api.github.com/users/kpe/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/26/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/26/timeline","performed_via_github_app":null,"state_reason":"completed"}