{"url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/73","repository_url":"https://api.github.com/repos/kpe/bert-for-tf2","labels_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/73/labels{/name}","comments_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/73/comments","events_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/73/events","html_url":"https://github.com/kpe/bert-for-tf2/issues/73","id":682443452,"node_id":"MDU6SXNzdWU2ODI0NDM0NTI=","number":73,"title":"TensorFlow ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type list)","user":{"login":"mitramir55","id":53291220,"node_id":"MDQ6VXNlcjUzMjkxMjIw","avatar_url":"https://avatars.githubusercontent.com/u/53291220?v=4","gravatar_id":"","url":"https://api.github.com/users/mitramir55","html_url":"https://github.com/mitramir55","followers_url":"https://api.github.com/users/mitramir55/followers","following_url":"https://api.github.com/users/mitramir55/following{/other_user}","gists_url":"https://api.github.com/users/mitramir55/gists{/gist_id}","starred_url":"https://api.github.com/users/mitramir55/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mitramir55/subscriptions","organizations_url":"https://api.github.com/users/mitramir55/orgs","repos_url":"https://api.github.com/users/mitramir55/repos","events_url":"https://api.github.com/users/mitramir55/events{/privacy}","received_events_url":"https://api.github.com/users/mitramir55/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-08-20T06:10:07Z","updated_at":"2020-08-26T08:09:41Z","closed_at":"2020-08-26T08:09:41Z","author_association":"NONE","active_lock_reason":null,"body":"I'm trying to write[ this code](https://www.kaggle.com/gunesevitan/nlp-with-disaster-tweets-eda-cleaning-and-bert) into colab. Interestingly, I was running **the same code in colab a few days ago**but now it doesn't work. the code also works in kaggle kernel. Why do you think this error occurs?\r\n\r\nI tried using np.array and tf.convert_to_tensor() for the model's input and also changed the version of tensorflow and tensorflow-hub but none worked. \r\n[This](https://github.com/mitramir55/Kaggle_NLP_competition/blob/master/Error_in_class.ipynb) is the colab notebook if you needed more info. Thanks in advance!\r\n\r\nthe code for short is using this class:\r\n`class DisasterDetector:\r\n    \r\n    def __init__(self, tokenizer, bert_layer, max_len =30, lr = 0.0001,\r\n                 epochs = 15, batch_size = 32, dtype = tf.int32 ,\r\n                 activation = 'sigmoid', optimizer = 'SGD',\r\n                 beta_1=0.9, beta_2=0.999, epsilon=1e-07,\r\n                 metrics = 'accuracy', loss = 'binary_crossentropy'):\r\n        \r\n        self.lr = lr\r\n        self.epochs = epochs\r\n        self.max_len = max_len\r\n        self.batch_size = batch_size\r\n        self.tokenizer = tokenizer\r\n        self.bert_layer = bert_layer\r\n        self.models = []\r\n\r\n        self.activation = activation\r\n        self.optimizer = optimizer\r\n        self.dtype = dtype\r\n        \r\n        self.beta_1 = beta_1\r\n        self.beta_2 = beta_2\r\n        self.epsilon =epsilon\r\n        \r\n        self.metrics = metrics\r\n        self.loss = loss\r\n        \r\n    def encode(self, texts):\r\n        all_tokens = []\r\n        masks = []\r\n        segments = []\r\n        \r\n        for text in texts:\r\n            \r\n            tokenized = self.tokenizer.convert_tokens_to_ids(['[CLS]'] + self.tokenizer.tokenize(text) + ['[SEP]'])\r\n            \r\n            len_zeros = self.max_len - len(tokenized)\r\n            \r\n            \r\n            padded = tokenized + [0] * len_zeros\r\n            mask = [1] * len(tokenized) + [0] * len_zeros\r\n            segment = [0] * self.max_len\r\n            \r\n            all_tokens.append(padded)\r\n            masks.append(mask)\r\n            segments.append(segment)\r\n            \r\n        print(len(all_tokens[0]))\r\n        return np.array(all_tokens), np.array(masks), np.array(segments)\r\n        \r\n    def make_model(self):\r\n        \r\n\r\n        input_word_ids = Input(shape = (self.max_len, ), dtype=tf.int32,\r\n                            name = 'input_word_ids')\r\n        \r\n        input_mask = Input(shape = (self.max_len, ), dtype=tf.int32,\r\n                           name = 'input_mask')\r\n        \r\n        segment_ids = Input(shape = (self.max_len, ), dtype=tf.int32,\r\n                            name = 'segment_ids')\r\n\r\n\r\n        #pooled output is the output of dimention and\r\n\r\n        pooled_output, sequence_output = self.bert_layer([input_word_ids,\r\n                                                     input_mask,\r\n                                                     segment_ids])\r\n\r\n        clf_output = sequence_output[:, 0, :]\r\n        out = tf.keras.layers.Dense(1, activation = self.activation)(clf_output)\r\n        #out = tf.keras.layers.Dense(1, activation = 'sigmoid', input_shape =  (clf_output,) )(clf_output)\r\n        \r\n\r\n        model = Model(inputs = [input_word_ids, input_mask, segment_ids],\r\n                      outputs = out)\r\n        if self.optimizer is 'SGD':\r\n            optimizer = SGD(learning_rate = self.lr)\r\n\r\n        elif self.optimizer is 'Adam': \r\n            optimizer = Adam(learning_rate = self.lr, beta_1=self.beta_1,\r\n                             beta_2=self.beta_2, epsilon=self.epsilon)\r\n\r\n        model.compile(loss = self.loss, optimizer = self.optimizer,\r\n                      metrics = [self.metrics])\r\n        \r\n        return model\r\n    \r\n    \r\n    \r\n    \r\n    def train(self, x, k = 3):    \r\n        kfold = StratifiedKFold(n_splits = k, shuffle = True)\r\n\r\n\r\n        for fold, (train_idx, val_idx) in enumerate(kfold.split(x['cleaned_text'], x['target'])):\r\n            print('fold: ', fold)\r\n\r\n            x_trn = self.encode(x.loc[train_idx, 'cleaned_text'])\r\n            x_val = self.encode(x.loc[val_idx, 'cleaned_text'])\r\n            y_trn = np.array(x.loc[train_idx, 'target'], dtype = np.uint8)\r\n            y_val = np.array(x.loc[val_idx, 'target'], dtype = np.uint8)\r\n            print('the data type of y train: ', type(y_trn))\r\n            print('x_val shape', x_val[0].shape)\r\n            print('x_trn shape', x_trn[0].shape)\r\n            \r\n            model = self.make_model()\r\n            print('model made.')\r\n            model.fit(x_trn, tf.convert_to_tensor(y_trn),\r\n                    validation_data = (x_val, tf.convert_to_tensor(y_val)),\r\n                    batch_size=self.batch_size, epochs = self.epochs)\r\n\r\n            self.models.append(model)`\r\n\r\nAnd after defining it:\r\n\r\n` classifier = DisasterDetector(tokenizer = tokenizer, bert_layer = bert_layer, max_len = max_len, \r\n                                              lr = 0.0001, epochs = 10,  activation = 'sigmoid',\r\n                                              batch_size = 32,optimizer = 'SGD',\r\n                                               beta_1=0.9, beta_2=0.999, epsilon=1e-07)`\r\n\r\nwhen I want to train it:\r\n\r\n`classifier.train(train_cleaned)`\r\n\r\nI get this error:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-9-106c756f2e47> in <module>()\r\n----> 1 classifier.train(train_cleaned)\r\n\r\n<ipython-input-7-2c77803eea5f> in train(self, x, k)\r\n    109             model.fit(x_trn, y_trn,\r\n    110                     validation_data = (x_val, y_val),\r\n--> 111                     batch_size=self.batch_size, epochs = self.epochs)\r\n    112 \r\n    113             self.models.append(model)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n    106   def _method_wrapper(self, *args, **kwargs):\r\n    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n--> 108       return method(self, *args, **kwargs)\r\n    109 \r\n    110     # Running inside `run_distribute_coordinator` already.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1061           use_multiprocessing=use_multiprocessing,\r\n   1062           model=self,\r\n-> 1063           steps_per_execution=self._steps_per_execution)\r\n   1064 \r\n   1065       # Container that configures and calls `tf.keras.Callback`s.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py in __init__(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\r\n   1115         use_multiprocessing=use_multiprocessing,\r\n   1116         distribution_strategy=ds_context.get_strategy(),\r\n-> 1117         model=model)\r\n   1118 \r\n   1119     strategy = ds_context.get_strategy()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py in __init__(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\r\n    263                **kwargs):\r\n    264     super(TensorLikeDataAdapter, self).__init__(x, y, **kwargs)\r\n--> 265     x, y, sample_weights = _process_tensorlike((x, y, sample_weights))\r\n    266     sample_weight_modes = broadcast_sample_weight_modes(\r\n    267         sample_weights, sample_weight_modes)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py in _process_tensorlike(inputs)\r\n   1019     return x\r\n   1020 \r\n-> 1021   inputs = nest.map_structure(_convert_numpy_and_scipy, inputs)\r\n   1022   return nest.list_to_tuple(inputs)\r\n   1023 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in map_structure(func, *structure, **kwargs)\r\n    633 \r\n    634   return pack_sequence_as(\r\n--> 635       structure[0], [func(*x) for x in entries],\r\n    636       expand_composites=expand_composites)\r\n    637 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in <listcomp>(.0)\r\n    633 \r\n    634   return pack_sequence_as(\r\n--> 635       structure[0], [func(*x) for x in entries],\r\n    636       expand_composites=expand_composites)\r\n    637 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py in _convert_numpy_and_scipy(x)\r\n   1014       if issubclass(x.dtype.type, np.floating):\r\n   1015         dtype = backend.floatx()\r\n-> 1016       return ops.convert_to_tensor(x, dtype=dtype)\r\n   1017     elif scipy_sparse and scipy_sparse.issparse(x):\r\n   1018       return _scipy_sparse_to_sparse_tensor(x)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\r\n   1497 \r\n   1498     if ret is None:\r\n-> 1499       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1500 \r\n   1501     if ret is NotImplemented:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py in _default_conversion_function(***failed resolving arguments***)\r\n     50 def _default_conversion_function(value, dtype, name, as_ref):\r\n     51   del as_ref  # Unused.\r\n---> 52   return constant_op.constant(value, dtype, name=name)\r\n     53 \r\n     54 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)\r\n    262   \"\"\"\r\n    263   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n--> 264                         allow_broadcast=True)\r\n    265 \r\n    266 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    273       with trace.Trace(\"tf.constant\"):\r\n    274         return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n--> 275     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n    276 \r\n    277   g = ops.get_default_graph()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n    298 def _constant_eager_impl(ctx, value, dtype, shape, verify_shape):\r\n    299   \"\"\"Implementation of eager constant.\"\"\"\r\n--> 300   t = convert_to_eager_tensor(value, ctx, dtype)\r\n    301   if shape is None:\r\n    302     return t\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\r\n     96       dtype = dtypes.as_dtype(dtype).as_datatype_enum\r\n     97   ctx.ensure_initialized()\r\n---> 98   return ops.EagerTensor(value, ctx.device_name, dtype)\r\n     99 \r\n    100 \r\n\r\nValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type list).","closed_by":{"login":"mitramir55","id":53291220,"node_id":"MDQ6VXNlcjUzMjkxMjIw","avatar_url":"https://avatars.githubusercontent.com/u/53291220?v=4","gravatar_id":"","url":"https://api.github.com/users/mitramir55","html_url":"https://github.com/mitramir55","followers_url":"https://api.github.com/users/mitramir55/followers","following_url":"https://api.github.com/users/mitramir55/following{/other_user}","gists_url":"https://api.github.com/users/mitramir55/gists{/gist_id}","starred_url":"https://api.github.com/users/mitramir55/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mitramir55/subscriptions","organizations_url":"https://api.github.com/users/mitramir55/orgs","repos_url":"https://api.github.com/users/mitramir55/repos","events_url":"https://api.github.com/users/mitramir55/events{/privacy}","received_events_url":"https://api.github.com/users/mitramir55/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/73/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/73/timeline","performed_via_github_app":null,"state_reason":"completed"}