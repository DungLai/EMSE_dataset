{"url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/53","repository_url":"https://api.github.com/repos/kpe/bert-for-tf2","labels_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/53/labels{/name}","comments_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/53/comments","events_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/53/events","html_url":"https://github.com/kpe/bert-for-tf2/issues/53","id":560914958,"node_id":"MDU6SXNzdWU1NjA5MTQ5NTg=","number":53,"title":"Finetune Albert on MovieReview dataset","user":{"login":"PhilippMarquardt","id":28708021,"node_id":"MDQ6VXNlcjI4NzA4MDIx","avatar_url":"https://avatars.githubusercontent.com/u/28708021?v=4","gravatar_id":"","url":"https://api.github.com/users/PhilippMarquardt","html_url":"https://github.com/PhilippMarquardt","followers_url":"https://api.github.com/users/PhilippMarquardt/followers","following_url":"https://api.github.com/users/PhilippMarquardt/following{/other_user}","gists_url":"https://api.github.com/users/PhilippMarquardt/gists{/gist_id}","starred_url":"https://api.github.com/users/PhilippMarquardt/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/PhilippMarquardt/subscriptions","organizations_url":"https://api.github.com/users/PhilippMarquardt/orgs","repos_url":"https://api.github.com/users/PhilippMarquardt/repos","events_url":"https://api.github.com/users/PhilippMarquardt/events{/privacy}","received_events_url":"https://api.github.com/users/PhilippMarquardt/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2020-02-06T10:23:24Z","updated_at":"2020-05-31T15:20:05Z","closed_at":"2020-02-06T10:45:19Z","author_association":"NONE","active_lock_reason":null,"body":"Hi!\r\nI tried finetuning the albert base/large model on the MovieReview dataset that is used in the bert example.  \r\nThe model is created like this:\r\n def create_model(max_seq_len):\r\n\r\n    albert_model_name = \"albert_base\"\r\n    albert_dir = bert.fetch_tfhub_albert_model(albert_model_name, \".models\")\r\n    model_params = bert.albert_params(albert_dir)\r\n    l_bert = bert.BertModelLayer.from_params(model_params, name=\"albert\")    \r\n    input_ids      = keras.layers.Input(shape=(max_seq_len,), dtype='int32', name=\"input_ids\")\r\n    #token_type_ids = keras.layers.Input(shape=(max_seq_len,), dtype='int32', name=\"token_type_ids\")\r\n    #output         = l_bert([input_ids, token_type_ids])\r\n    output         = l_bert(input_ids)\r\n\r\n    print(\"bert shape\", output.shape)\r\n    cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(output)\r\n    cls_out = keras.layers.Dropout(0.5)(cls_out)\r\n    logits = keras.layers.Dense(units=1024, activation=\"tanh\")(cls_out)\r\n    logits = keras.layers.Dropout(0.5)(logits)\r\n    logits = keras.layers.Dense(units=2, activation=\"softmax\")(logits)\r\n\r\n    # model = keras.Model(inputs=[input_ids, token_type_ids], outputs=logits)\r\n    # model.build(input_shape=[(None, max_seq_len), (None, max_seq_len)])\r\n    model = keras.Model(inputs=input_ids, outputs=logits)\r\n    model.build(input_shape=(None, max_seq_len))\r\n    model.compile(optimizer=keras.optimizers.Adam(),\r\n                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n                metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")])\r\n    \r\n    \r\n    # load the pre-trained model weights\r\n    bert.load_albert_weights(l_bert, albert_dir)\r\n\r\n\r\n    \r\n\r\n    model.summary()\r\n\r\n    return model\r\n\r\nI've used `from bert.tokenization.albert_tokenization import FullTokenizer` for tokenization\r\n\r\nEverything else is like in the provided bert example.\r\n\r\nWhen executing the training loop, the accuracy stays at 50% and the loss doesn't really change from .7\r\n\r\n\r\nHas anybody successfully finetuned any pretrained albert model on the MovieReview dataset? If yes, what am I doing wrong? Thanks in advance!","closed_by":{"login":"kpe","id":2535923,"node_id":"MDQ6VXNlcjI1MzU5MjM=","avatar_url":"https://avatars.githubusercontent.com/u/2535923?v=4","gravatar_id":"","url":"https://api.github.com/users/kpe","html_url":"https://github.com/kpe","followers_url":"https://api.github.com/users/kpe/followers","following_url":"https://api.github.com/users/kpe/following{/other_user}","gists_url":"https://api.github.com/users/kpe/gists{/gist_id}","starred_url":"https://api.github.com/users/kpe/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kpe/subscriptions","organizations_url":"https://api.github.com/users/kpe/orgs","repos_url":"https://api.github.com/users/kpe/repos","events_url":"https://api.github.com/users/kpe/events{/privacy}","received_events_url":"https://api.github.com/users/kpe/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/53/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/53/timeline","performed_via_github_app":null,"state_reason":"completed"}