{"url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/80","repository_url":"https://api.github.com/repos/kpe/bert-for-tf2","labels_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/80/labels{/name}","comments_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/80/comments","events_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/80/events","html_url":"https://github.com/kpe/bert-for-tf2/issues/80","id":726103492,"node_id":"MDU6SXNzdWU3MjYxMDM0OTI=","number":80,"title":"Can not load pretrained bert weights when loading chinese_L-12_H-768_A-12/bert_model.ckpt","user":{"login":"yangxudong","id":6253878,"node_id":"MDQ6VXNlcjYyNTM4Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/6253878?v=4","gravatar_id":"","url":"https://api.github.com/users/yangxudong","html_url":"https://github.com/yangxudong","followers_url":"https://api.github.com/users/yangxudong/followers","following_url":"https://api.github.com/users/yangxudong/following{/other_user}","gists_url":"https://api.github.com/users/yangxudong/gists{/gist_id}","starred_url":"https://api.github.com/users/yangxudong/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yangxudong/subscriptions","organizations_url":"https://api.github.com/users/yangxudong/orgs","repos_url":"https://api.github.com/users/yangxudong/repos","events_url":"https://api.github.com/users/yangxudong/events{/privacy}","received_events_url":"https://api.github.com/users/yangxudong/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-10-21T03:36:48Z","updated_at":"2020-10-23T16:35:17Z","closed_at":"2020-10-21T11:07:49Z","author_association":"NONE","active_lock_reason":null,"body":"Here is my code snippets\r\n```\r\nmax_seq_len = 128\r\nbert_params = bert.params_from_pretrained_ckpt(model_dir)\r\nbert_layer = bert.BertModelLayer.from_params(bert_params, name=\"bert\")\r\n\r\ninput_ids = Input(shape=(max_seq_len,), dtype='int32')\r\nmasked = Masking(mask_value=0)(input_ids)\r\nemb = bert_layer.embeddings_layer(masked)  # shape: (None, seq_len, emb_size)\r\n...\r\nmask_ids = np.expand_dims(np.tile(np.array(tokenizer.convert_tokens_to_ids([\"[MASK]\"])), max_seq_len), 0)\r\nemb_mask = bert_layer.embeddings_layer(mask_ids)  # shape(1, seq_len, emb_size)\r\nnew_emb = err_prob * emb_mask + (1. - err_prob) * emb  # broadcast, shape(None, seq_len, emb_size)\r\noutput = bert_layer.encoders_layer(new_emb)  # bert_layer 接受的是input_ids， 不是embedding之后的数据\r\noutput = Dense(num_classes, activation='softmax')(output + emb)\r\ncorrect_model = Model(input_ids, output)\r\ncorrect_model.build(input_shape=(None, max_seq_len))\r\nbert.load_bert_weights(bert_layer, model_ckpt)\r\ncorrect_model.compile(optimizer=Adam(1e-3))\r\ncorrect_model.summary()\r\n```\r\n\r\nWhen I run it, get the problem of loading pretrained weights. Can anyone help me? Thanks!\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/weisu.yxd/PycharmProjects/PY3/soft_mask_bert.py\", line 103, in <module>\r\n    bert.load_bert_weights(bert_layer, model_ckpt)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/bert/loader.py\", line 206, in load_stock_weights\r\n    prefix = bert_prefix(bert)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/bert/loader.py\", line 186, in bert_prefix\r\n    assert match, \"Unexpected bert layer: {} weight:{}\".format(bert, bert.weights[0].name)\r\nAssertionError: Unexpected bert layer: <bert.model.BertModelLayer object at 0x102d56be0> weight:embeddings/word_embeddings/embeddings:0\r\n```","closed_by":{"login":"kpe","id":2535923,"node_id":"MDQ6VXNlcjI1MzU5MjM=","avatar_url":"https://avatars.githubusercontent.com/u/2535923?v=4","gravatar_id":"","url":"https://api.github.com/users/kpe","html_url":"https://github.com/kpe","followers_url":"https://api.github.com/users/kpe/followers","following_url":"https://api.github.com/users/kpe/following{/other_user}","gists_url":"https://api.github.com/users/kpe/gists{/gist_id}","starred_url":"https://api.github.com/users/kpe/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kpe/subscriptions","organizations_url":"https://api.github.com/users/kpe/orgs","repos_url":"https://api.github.com/users/kpe/repos","events_url":"https://api.github.com/users/kpe/events{/privacy}","received_events_url":"https://api.github.com/users/kpe/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/80/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/80/timeline","performed_via_github_app":null,"state_reason":"completed"}