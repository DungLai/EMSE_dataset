{"url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/44","repository_url":"https://api.github.com/repos/kpe/bert-for-tf2","labels_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/44/labels{/name}","comments_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/44/comments","events_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/44/events","html_url":"https://github.com/kpe/bert-for-tf2/issues/44","id":549198030,"node_id":"MDU6SXNzdWU1NDkxOTgwMzA=","number":44,"title":"Unused weights","user":{"login":"Arkin1","id":18368606,"node_id":"MDQ6VXNlcjE4MzY4NjA2","avatar_url":"https://avatars.githubusercontent.com/u/18368606?v=4","gravatar_id":"","url":"https://api.github.com/users/Arkin1","html_url":"https://github.com/Arkin1","followers_url":"https://api.github.com/users/Arkin1/followers","following_url":"https://api.github.com/users/Arkin1/following{/other_user}","gists_url":"https://api.github.com/users/Arkin1/gists{/gist_id}","starred_url":"https://api.github.com/users/Arkin1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Arkin1/subscriptions","organizations_url":"https://api.github.com/users/Arkin1/orgs","repos_url":"https://api.github.com/users/Arkin1/repos","events_url":"https://api.github.com/users/Arkin1/events{/privacy}","received_events_url":"https://api.github.com/users/Arkin1/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-01-13T21:41:57Z","updated_at":"2020-01-22T00:26:13Z","closed_at":"2020-01-22T00:26:13Z","author_association":"NONE","active_lock_reason":null,"body":"When I load a pre-trained bert model(multilingual) it seems that some weights from the checkpoint are unused.\r\n\r\nI load the model in this way.\r\n\r\n```\r\nself.model_dir =\"PretrainedModels/multilingual_L-12_H-768_A-12\" \r\nself.max_seq_len = 64\r\nbert_params = bert.params_from_pretrained_ckpt(self.model_dir)\r\nl_bert = bert.BertModelLayer.from_params(bert_params, name=\"bert\")\r\nl_input_ids = keras.layers.Input(shape=(self.max_seq_len,), dtype='int32')\r\nmodel = keras.Sequential()\r\nmodel.add(l_input_ids)\r\nmodel.add(l_bert)\r\nmodel.add(keras.layers.GlobalAveragePooling1D())\r\noutput = model(l_input_ids)\r\nself.model = keras.Model(inputs=l_input_ids, outputs=output)\r\nself.model.build(input_shape=(None, self.max_seq_len))\r\nbert_ckpt_file   = os.path.join(self.model_dir, \"bert_model.ckpt\")\r\nbert.load_stock_weights(l_bert, bert_ckpt_file)\r\n```\r\n\r\nThe output from the console seems to show these weights:\r\n\r\n```\r\nDone loading 196 BERT weights from: PretrainedModels/multilingual_L-12_H-768_A-12\\bert_model.ckpt into <bert.model.BertModelLayer object at 0x00000209EA5B3188> (prefix:bert). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\r\nunused weights from checkpoint:\r\n\r\nbert/embeddings/token_type_embeddings\r\nbert/pooler/dense/bias\r\nbert/pooler/dense/kernel\r\ncls/predictions/output_bias\r\ncls/predictions/transform/LayerNorm/beta\r\ncls/predictions/transform/LayerNorm/gamma\r\ncls/predictions/transform/dense/bias\r\ncls/predictions/transform/dense/kernel\r\ncls/seq_relationship/output_bias\r\ncls/seq_relationship/output_weights\r\n```","closed_by":{"login":"kpe","id":2535923,"node_id":"MDQ6VXNlcjI1MzU5MjM=","avatar_url":"https://avatars.githubusercontent.com/u/2535923?v=4","gravatar_id":"","url":"https://api.github.com/users/kpe","html_url":"https://github.com/kpe","followers_url":"https://api.github.com/users/kpe/followers","following_url":"https://api.github.com/users/kpe/following{/other_user}","gists_url":"https://api.github.com/users/kpe/gists{/gist_id}","starred_url":"https://api.github.com/users/kpe/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kpe/subscriptions","organizations_url":"https://api.github.com/users/kpe/orgs","repos_url":"https://api.github.com/users/kpe/repos","events_url":"https://api.github.com/users/kpe/events{/privacy}","received_events_url":"https://api.github.com/users/kpe/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/44/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kpe/bert-for-tf2/issues/44/timeline","performed_via_github_app":null,"state_reason":"completed"}