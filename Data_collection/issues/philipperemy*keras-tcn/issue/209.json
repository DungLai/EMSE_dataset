{"url":"https://api.github.com/repos/philipperemy/keras-tcn/issues/209","repository_url":"https://api.github.com/repos/philipperemy/keras-tcn","labels_url":"https://api.github.com/repos/philipperemy/keras-tcn/issues/209/labels{/name}","comments_url":"https://api.github.com/repos/philipperemy/keras-tcn/issues/209/comments","events_url":"https://api.github.com/repos/philipperemy/keras-tcn/issues/209/events","html_url":"https://github.com/philipperemy/keras-tcn/issues/209","id":938079593,"node_id":"MDU6SXNzdWU5MzgwNzk1OTM=","number":209,"title":"The following Variables were used a Lambda layer's call (tf.nn.bias_add_252), but are not present in its tracked objects","user":{"login":"Kartik-Singhal26","id":62858247,"node_id":"MDQ6VXNlcjYyODU4MjQ3","avatar_url":"https://avatars.githubusercontent.com/u/62858247?v=4","gravatar_id":"","url":"https://api.github.com/users/Kartik-Singhal26","html_url":"https://github.com/Kartik-Singhal26","followers_url":"https://api.github.com/users/Kartik-Singhal26/followers","following_url":"https://api.github.com/users/Kartik-Singhal26/following{/other_user}","gists_url":"https://api.github.com/users/Kartik-Singhal26/gists{/gist_id}","starred_url":"https://api.github.com/users/Kartik-Singhal26/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Kartik-Singhal26/subscriptions","organizations_url":"https://api.github.com/users/Kartik-Singhal26/orgs","repos_url":"https://api.github.com/users/Kartik-Singhal26/repos","events_url":"https://api.github.com/users/Kartik-Singhal26/events{/privacy}","received_events_url":"https://api.github.com/users/Kartik-Singhal26/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-07-06T16:43:25Z","updated_at":"2022-01-20T07:04:38Z","closed_at":"2022-01-20T07:04:37Z","author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\nWARNING:tensorflow:\r\nThe following Variables were used a Lambda layer's call (tf.nn.bias_add_252), but\r\nare not present in its tracked objects:\r\n  <tf.Variable 'tcn_17/residual_block_11/conv1D_0/bias:0' shape=(32,) dtype=float32>\r\nIt is possible that this is intended behavior, but it is more likely\r\nan omission. This is a strong indication that this layer should be\r\nformulated as a subclassed Layer rather than a Lambda layer.\r\nWARNING:tensorflow:\r\nThe following Variables were used a Lambda layer's call (tf.nn.convolution_119), but\r\nare not present in its tracked objects:\r\n  <tf.Variable 'tcn_17/residual_block_11/conv1D_1/kernel:0' shape=(4, 32, 32) dtype=float32>\r\nIt is possible that this is intended behavior, but it is more likely\r\nan omission. This is a strong indication that this layer should be\r\nformulated as a subclassed Layer rather than a Lambda layer.\r\nWARNING:tensorflow:\r\nThe following Variables were used a Lambda layer's call (tf.nn.bias_add_253), but\r\nare not present in its tracked objects:\r\n  <tf.Variable 'tcn_17/residual_block_11/conv1D_1/bias:0' shape=(32,) dtype=float32>\r\nIt is possible that this is intended behavior, but it is more likely\r\nan omission. This is a strong indication that this layer should be\r\nformulated as a subclassed Layer rather than a Lambda layer.\r\n\r\n**Paste a snippet**\r\n`batch_size,` timesteps, input_dim = None, None, X_train_transformed.shape[2]\r\ninp = Input(batch_shape=(batch_size, timesteps, input_dim))\r\n\r\nout1 = TCN(nb_filters = 64, # Integral Number of Filters to be used\r\n           kernel_size = 3, # Integral Size of Kernel for each layer\r\n           nb_stacks = 2, # Integral Number of stacks of residual blocks to use\r\n           activation = 'tanh',\r\n           #dilations = (2, 4),\r\n           use_batch_norm = False, \r\n           dropout_rate = 0.2, # Fraction of input units to# drop\r\n           padding = 'causal', # Same for non causal network\r\n           return_sequences = True)(inp)  # The TCN layers are here.\r\n\r\nout2 = TCN(nb_filters = 16, # Integral Number of Filters to be used\r\n           kernel_size = 3, # Integral Size of Kernel for each layer\r\n           nb_stacks = 2, # Integral Number of stacks of residual blocks to use\r\n           #dilations = (2, 4),\r\n           activation = 'tanh',\r\n           use_batch_norm = False, \r\n           #dropout_rate = 0.2, # Fraction of input units to# drop\r\n           padding = 'causal', # Same for non causal network\r\n           return_sequences = True)(out1)  # The TCN layers are here.\r\n\r\nout3 = TCN(nb_filters = 32, # Integral Number of Filters to be used\r\n           kernel_size = 4, # Integral Size of Kernel for each layer\r\n           nb_stacks = 2, # Integral Number of stacks of residual blocks to use\r\n           #dilations = (2, 4),\r\n           activation = 'tanh',\r\n           use_batch_norm = False, \r\n           #dropout_rate = 0.2, # Fraction of input units to# drop\r\n           padding = 'causal', # Same for non causal network\r\n           return_sequences = False)(out2)  # The TCN layers are here.\r\n    \r\nout = Dense(1, activation = 'linear')(out3)\r\nTCNmodel_Try1 = Model(inputs = [inp], outputs = [out])\r\n\r\n%Save Best Model\r\nfilepath = \"TCN1_best.hdf5\"\r\ncheckpoint = ModelCheckpoint(filepath, monitor = 'val_coeff_determination', verbose = 1, save_best_only = True, mode = 'max')\r\ncallbacks_list = [checkpoint]\r\n\r\n%Early Stopping\r\nes = EarlyStopping(monitor = 'val_coeff_determination', mode = 'max', verbose = 1, patience = 45)\r\n%Log History \r\ncsv_logger = CSVLogger('training.log', separator=',', append=False)\r\n\r\n%Compile Model\r\nTCNmodel_Try1.compile(optimizer = 'adam', loss = 'mae', metrics = ['RootMeanSquaredError', 'mse'])'\r\n`\r\n\r\n**Dependencies**\r\ntensorflow 2.5.0\r\n","closed_by":{"login":"philipperemy","id":4516927,"node_id":"MDQ6VXNlcjQ1MTY5Mjc=","avatar_url":"https://avatars.githubusercontent.com/u/4516927?v=4","gravatar_id":"","url":"https://api.github.com/users/philipperemy","html_url":"https://github.com/philipperemy","followers_url":"https://api.github.com/users/philipperemy/followers","following_url":"https://api.github.com/users/philipperemy/following{/other_user}","gists_url":"https://api.github.com/users/philipperemy/gists{/gist_id}","starred_url":"https://api.github.com/users/philipperemy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/philipperemy/subscriptions","organizations_url":"https://api.github.com/users/philipperemy/orgs","repos_url":"https://api.github.com/users/philipperemy/repos","events_url":"https://api.github.com/users/philipperemy/events{/privacy}","received_events_url":"https://api.github.com/users/philipperemy/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/philipperemy/keras-tcn/issues/209/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/philipperemy/keras-tcn/issues/209/timeline","performed_via_github_app":null,"state_reason":"completed"}