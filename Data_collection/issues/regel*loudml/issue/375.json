{"url":"https://api.github.com/repos/regel/loudml/issues/375","repository_url":"https://api.github.com/repos/regel/loudml","labels_url":"https://api.github.com/repos/regel/loudml/issues/375/labels{/name}","comments_url":"https://api.github.com/repos/regel/loudml/issues/375/comments","events_url":"https://api.github.com/repos/regel/loudml/issues/375/events","html_url":"https://github.com/regel/loudml/issues/375","id":668407767,"node_id":"MDU6SXNzdWU2Njg0MDc3Njc=","number":375,"title":"Donut Model doesn't fit well CPU usage , score always 100%","user":{"login":"toni-moreno","id":5883405,"node_id":"MDQ6VXNlcjU4ODM0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/5883405?v=4","gravatar_id":"","url":"https://api.github.com/users/toni-moreno","html_url":"https://github.com/toni-moreno","followers_url":"https://api.github.com/users/toni-moreno/followers","following_url":"https://api.github.com/users/toni-moreno/following{/other_user}","gists_url":"https://api.github.com/users/toni-moreno/gists{/gist_id}","starred_url":"https://api.github.com/users/toni-moreno/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/toni-moreno/subscriptions","organizations_url":"https://api.github.com/users/toni-moreno/orgs","repos_url":"https://api.github.com/users/toni-moreno/repos","events_url":"https://api.github.com/users/toni-moreno/events{/privacy}","received_events_url":"https://api.github.com/users/toni-moreno/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-07-30T06:20:45Z","updated_at":"2020-08-19T12:59:24Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hello.\r\n\r\nI've readed  loudml documentation and also some examples I've found , and I cannot understand, how I should create/train the model to fit well my  example metric \"usage_system cpu\" from my server.\r\n\r\nI've made a  grafana  dashboard with 2 panels\r\n\r\nPanel 1:\r\n * Real metric  (green line)\r\n * Predicted metric  (orange dot)\r\n * Upper bound (blue dashed line)\r\n * Lower bound(purple dashed line)\r\n\r\nPanel 2:\r\n * Real Metric (green line)\r\n * Predicted Metric (orange dot)\r\n * Score (blue bar - right  Y axis)\r\n\r\nThis is how it seems\r\n![image](https://user-images.githubusercontent.com/5883405/88885800-79ffd680-d239-11ea-9ca0-51b76dcde03a.png)\r\n\r\nAs you can see, lower/upper bound seems to be too close one from the other, and always the score is 100%, predicted values doesn't follow the real metric shape.\r\n\r\nAs you can see, in the last 12 hours, cpu seems to have a heavy periodical component, seems easy to predict.\r\n\r\n![image](https://user-images.githubusercontent.com/5883405/88888090-f09ed300-d23d-11ea-86a8-5b8e74d173d2.png)\r\n\r\n\r\n```\r\n> list-models\r\nlinux_metrics_cpu_mean_usage_system_host_myserver_time_5m\r\n> list-model-versions linux_metrics_cpu_mean_usage_system_host_myserver_time_5m\r\nversion  active   loss     trained  \r\n00       0.       353.792  1.       \r\n01       0.       353.806  1.       \r\n02       1.       353.806  1.       \r\n> show-model linux_metrics_cpu_mean_usage_system_host_myserver_time_5m\r\n- settings:\r\n    bucket_interval: 5m\r\n    default_bucket: myserver_linux\r\n    features:\r\n    - default: 0\r\n      field: usage_system\r\n      io: io\r\n      match_all:\r\n      - tag: host\r\n        value: myserver\r\n      measurement: cpu\r\n      metric: mean\r\n      name: mean_usage_system\r\n    grace_period: 0\r\n    interval: 5m\r\n    max_evals: 12\r\n    max_threshold: 90\r\n    min_threshold: 90\r\n    name: linux_metrics_cpu_mean_usage_system_host_myserver_time_5m\r\n    offset: 10s\r\n    run:\r\n      flag_abnormal_data: true\r\n      output_bucket: myserver_loudml\r\n      save_output_data: true\r\n    seasonality:\r\n      daytime: false\r\n      weekday: false\r\n    span: 100\r\n    type: donut\r\n  training:\r\n    job_id: 17b49b96-1c93-424b-9871-b7dd46737c6e\r\n    progress:\r\n      eval: 13\r\n      max_evals: 12\r\n    state: done\r\n> list-scheduled-jobs\r\n_eval(linux_metrics_cpu_mean_usage_system_host_myserver_time_5m)\r\n> list-scheduled-jobs -a\r\n- every:\r\n    count: 300.0\r\n    unit: seconds\r\n  last_run_timestamp: 1596088721.625509\r\n  method: post\r\n  name: _eval(linux_metrics_cpu_mean_usage_system_host_myserver_time_5m)\r\n  ok: true\r\n  params:\r\n    flag_abnormal_data: true\r\n    from: now-310s\r\n    output_bucket: myserver_loudml\r\n    save_output_data: true\r\n    to: now-10s\r\n  relative_url: /models/linux_metrics_cpu_mean_usage_system_host_myserver_time_5m/_eval\r\n  status_code: 200f\r\n\r\n```\r\n\r\n* Any idea on how to config the model to best fit the real metric?\r\n* What exactly means \"loss\" in the output for the command `list-model-versions`?, which value is better greater/lower ?\r\n* Can I train the model again without stopping the current scheduled job? How can switch to the new trained parameters online?\r\n* How I can make the model more \"flexible\" ie:  greater the lower/upper difference in the way more real data can fit inside the difference? \r\n* In the doc (https://loudml.io/en/loudml/reference/current/_evaluate.html) Lower/upper  values are fixed to 99.7 percent confidence, There is any way to change it? should I do if we could ?\r\n\r\nAl least? There is any example where to see how to play with this fine tuning?\r\n\r\nThank you very much to everybody!\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/regel/loudml/issues/375/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/regel/loudml/issues/375/timeline","performed_via_github_app":null,"state_reason":null}