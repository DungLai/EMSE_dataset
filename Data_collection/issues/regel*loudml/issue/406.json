{"url":"https://api.github.com/repos/regel/loudml/issues/406","repository_url":"https://api.github.com/repos/regel/loudml","labels_url":"https://api.github.com/repos/regel/loudml/issues/406/labels{/name}","comments_url":"https://api.github.com/repos/regel/loudml/issues/406/comments","events_url":"https://api.github.com/repos/regel/loudml/issues/406/events","html_url":"https://github.com/regel/loudml/issues/406","id":682121238,"node_id":"MDU6SXNzdWU2ODIxMjEyMzg=","number":406,"title":"HTTP 500 Internal server error when cancelling a job, new jobs stuck in waiting on Docker","user":{"login":"rodrigo-albuquerque","id":42713780,"node_id":"MDQ6VXNlcjQyNzEzNzgw","avatar_url":"https://avatars.githubusercontent.com/u/42713780?v=4","gravatar_id":"","url":"https://api.github.com/users/rodrigo-albuquerque","html_url":"https://github.com/rodrigo-albuquerque","followers_url":"https://api.github.com/users/rodrigo-albuquerque/followers","following_url":"https://api.github.com/users/rodrigo-albuquerque/following{/other_user}","gists_url":"https://api.github.com/users/rodrigo-albuquerque/gists{/gist_id}","starred_url":"https://api.github.com/users/rodrigo-albuquerque/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rodrigo-albuquerque/subscriptions","organizations_url":"https://api.github.com/users/rodrigo-albuquerque/orgs","repos_url":"https://api.github.com/users/rodrigo-albuquerque/repos","events_url":"https://api.github.com/users/rodrigo-albuquerque/events{/privacy}","received_events_url":"https://api.github.com/users/rodrigo-albuquerque/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-08-19T19:32:52Z","updated_at":"2020-09-01T19:40:13Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"```\r\n> version\r\n1.6.0\r\n> list-models\r\nbah\r\nmymodel\r\n```\r\nJob is initially waiting:\r\n```\r\n> list-jobs\r\nid                                    name               state      x/N  time_left  duration\r\n2148faaf-b7b8-436a-82d0-d9b91d74c9ea  training(bah)      waiting                    496.464 <-----\r\n4dd2fb2c-b629-4aad-93a5-ce4df0626121  training(mymodel)  canceling                  1687.226\r\n6eacbedc-c289-4f06-9360-a05e199ac5eb  training(mymodel)  canceling                  1783.785\r\n8f411abc-7a96-440b-b550-505c83f021a5  training(bah)      waiting                    684.152\r\nda80bb65-f1e1-4d42-8c89-1feb49190bf0  training(mymodel)  canceling                  1817.056\r\n```\r\nThen I try to cancel it:\r\n```\r\n> cancel-job 2148faaf-b7b8-436a-82d0-d9b91d74c9ea\r\nERROR:root:TransportError(500, 'internal server error')\r\n```\r\nWhen I check, it's actually trying to cancel it but it's stuck at cancelling for ever:\r\n```\r\n> list-jobs\r\nid                                    name               state      x/N  time_left  duration\r\n2148faaf-b7b8-436a-82d0-d9b91d74c9ea  training(bah)      canceling                  1134.971 <----\r\n4dd2fb2c-b629-4aad-93a5-ce4df0626121  training(mymodel)  canceling                  2325.733\r\n6eacbedc-c289-4f06-9360-a05e199ac5eb  training(mymodel)  canceling                  2422.291\r\n8f411abc-7a96-440b-b550-505c83f021a5  training(bah)      waiting                    1322.659\r\nda80bb65-f1e1-4d42-8c89-1feb49190bf0  training(mymodel)  canceling                  2455.562\r\n```\r\nFor reference:\r\n```\r\n> list-models\r\nbah\r\nmymodel\r\n> show-model mymodel\r\n- settings:\r\n    bucket_interval: 10s\r\n    default_bucket: influxdb\r\n    features:\r\n    - anomaly_type: low_high\r\n      default: null\r\n      field: average_response_ms\r\n      io: io\r\n      match_all:\r\n      - tag: url\r\n        value: host1.example.com\r\n      measurement: ping\r\n      metric: mean\r\n      name: myfeature\r\n    grace_period: 0\r\n    interval: 60s\r\n    max_evals: 20\r\n    max_threshold: 0\r\n    min_threshold: 0\r\n    name: mymodel\r\n    offset: 10s\r\n    seasonality:\r\n      daytime: false\r\n      weekday: false\r\n    span: 10\r\n    type: donut\r\n  training:\r\n    job_id: eebdaf5e-bdad-4936-a8aa-f8595b078120\r\n    state: failed\r\n>\r\n```\r\nI suspect it may have something to do with the database?\r\nHow do I check if it's actually connected and writing to DB?\r\n```\r\n> list-buckets\r\ninfluxdb\r\nloudml\r\n> show-bucket loudml\r\n- addr: myinfluxdb:8086\r\n  database: loudml\r\n  dbuser: admin\r\n  name: loudml\r\n  type: influxdb\r\n\r\n>\r\n```\r\nExternally, I've already confirmed I can access myinfluxdb, I can write data, etc.\r\n\r\nI also see this weird Python exception in the logs when I try to run the training:\r\n```\r\n10.103.130.201 - - [2020-08-19 19:02:11] \"GET /models HTTP/1.1\" 200 1205 0.003390\r\n[2020-08-19 19:02:12,667] ERROR in app: Exception on /models/bah/_train [POST]\r\nTraceback (most recent call last):\r\n  File \"/opt/venv/lib/python3.7/site-packages/flask/app.py\", line 2446, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"/opt/venv/lib/python3.7/site-packages/flask/app.py\", line 1951, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"/opt/venv/lib/python3.7/site-packages/flask_restful/__init__.py\", line 269, in error_router\r\n    return original_handler(e)\r\n  File \"/opt/venv/lib/python3.7/site-packages/flask/app.py\", line 1820, in handle_user_exception\r\n    reraise(exc_type, exc_value, tb)\r\n  File \"/opt/venv/lib/python3.7/site-packages/flask/_compat.py\", line 39, in reraise\r\n    raise value\r\n  File \"/opt/venv/lib/python3.7/site-packages/flask/app.py\", line 1949, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"/opt/venv/lib/python3.7/site-packages/flask/app.py\", line 1935, in dispatch_request\r\n    return self.view_functions[rule.endpoint](**req.view_args)\r\n  File \"/opt/venv/lib/python3.7/site-packages/loudml/server.py\", line 932, in model_train\r\n    job.start(g_config)\r\n  File \"/opt/venv/lib/python3.7/site-packages/loudml/server.py\", line 1430, in start\r\n    kwargs=self.kwargs,\r\n  File \"/opt/venv/lib/python3.7/site-packages/pebble/pool/process.py\", line 84, in schedule\r\n    self._check_pool_state()\r\n  File \"/opt/venv/lib/python3.7/site-packages/pebble/pool/base_pool.py\", line 94, in _check_pool_state\r\n    raise RuntimeError('Unexpected error within the Pool')\r\nRuntimeError: Unexpected error within the Pool\r\nERROR:loudml.server:Exception on /models/bah/_train [POST]\r\nTraceback (most recent call last):\r\n  File \"/opt/venv/lib/python3.7/site-packages/flask/app.py\", line 2446, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"/opt/venv/lib/python3.7/site-packages/flask/app.py\", line 1951, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"/opt/venv/lib/python3.7/site-packages/flask_restful/__init__.py\", line 269, in error_router\r\n    return original_handler(e)\r\n  File \"/opt/venv/lib/python3.7/site-packages/flask/app.py\", line 1820, in handle_user_exception\r\n    reraise(exc_type, exc_value, tb)\r\n  File \"/opt/venv/lib/python3.7/site-packages/flask/_compat.py\", line 39, in reraise\r\n    raise value\r\n  File \"/opt/venv/lib/python3.7/site-packages/flask/app.py\", line 1949, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"/opt/venv/lib/python3.7/site-packages/flask/app.py\", line 1935, in dispatch_request\r\n    return self.view_functions[rule.endpoint](**req.view_args)\r\n  File \"/opt/venv/lib/python3.7/site-packages/loudml/server.py\", line 932, in model_train\r\n    job.start(g_config)\r\n  File \"/opt/venv/lib/python3.7/site-packages/loudml/server.py\", line 1430, in start\r\n    kwargs=self.kwargs,\r\n  File \"/opt/venv/lib/python3.7/site-packages/pebble/pool/process.py\", line 84, in schedule\r\n    self._check_pool_state()\r\n  File \"/opt/venv/lib/python3.7/site-packages/pebble/pool/base_pool.py\", line 94, in _check_pool_state\r\n    raise RuntimeError('Unexpected error within the Pool')\r\nRuntimeError: Unexpected error within the Pool\r\n10.103.130.201 - - [2020-08-19 19:02:12] \"POST /models/bah/_train?from=2020-08-19T18:59:00.000Z&to=2020-08-19T18:59:00.000Z HTTP/1.1\" 500 156 0.005088\r\n10.103.130.201 - - [2020-08-19 19:02:12] \"GET /jobs/4c17ee83-3ebf-419f-8e56-3aa6808b6f42 HTTP/1.1\" 404 134 0.000463\r\n```\r\nAny pointers would be appreciated. I also tried nightly, 1.5.0, they all show the same error.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/regel/loudml/issues/406/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/regel/loudml/issues/406/timeline","performed_via_github_app":null,"state_reason":null}