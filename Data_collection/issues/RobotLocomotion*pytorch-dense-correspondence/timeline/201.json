[{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/comments/508119164","html_url":"https://github.com/RobotLocomotion/pytorch-dense-correspondence/issues/201#issuecomment-508119164","issue_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/201","id":508119164,"node_id":"MDEyOklzc3VlQ29tbWVudDUwODExOTE2NA==","user":{"login":"peteflorence","id":5640360,"node_id":"MDQ6VXNlcjU2NDAzNjA=","avatar_url":"https://avatars.githubusercontent.com/u/5640360?v=4","gravatar_id":"","url":"https://api.github.com/users/peteflorence","html_url":"https://github.com/peteflorence","followers_url":"https://api.github.com/users/peteflorence/followers","following_url":"https://api.github.com/users/peteflorence/following{/other_user}","gists_url":"https://api.github.com/users/peteflorence/gists{/gist_id}","starred_url":"https://api.github.com/users/peteflorence/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/peteflorence/subscriptions","organizations_url":"https://api.github.com/users/peteflorence/orgs","repos_url":"https://api.github.com/users/peteflorence/repos","events_url":"https://api.github.com/users/peteflorence/events{/privacy}","received_events_url":"https://api.github.com/users/peteflorence/received_events","type":"User","site_admin":false},"created_at":"2019-07-03T14:32:25Z","updated_at":"2019-07-03T14:32:25Z","author_association":"COLLABORATOR","body":"Hi Amulya,\r\n1. Given knowledge of (a) the cameras poses, (b) the 3D geometry of the scene, and (c) the camera calibration, then we can use geometry to compute pixel-pixel correspondences.  Some references for you could be the Hartley + Zisserman book, Rich Szeliski's book...  the \"Learning OpenCV\" books too (chapters on camera models, calibration, 3D vision). The `batch_find_pixel_correspondences()` code is admittedly tricky to follow, in part because it could be written cleaner :), in part because it's vectorized pytorch functions.  \r\n2. We can isolate the object from the rest of the scene by 3D segmentation.  A pretty general approach to do this can be found in [1].  Since we are just using table-top scenes, we can do something even simpler, which is just to segment out the object(s) as the thing(s) above the table.  Another easy option is to just do background subtraction in the image-space, but due to subtle lighting changes, etc, this doesn't work as well.\r\n\r\n[1] R. Finman, T. Whelan, M. Kaess, and J. J. Leonard. Toward lifelong object segmentation from\r\nchange detection in dense rgb-d maps. In Mobile Robots (ECMR), 2013 European Conference on,\r\npages 178–185. IEEE, 2013.\r\n","reactions":{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/comments/508119164/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"peteflorence","id":5640360,"node_id":"MDQ6VXNlcjU2NDAzNjA=","avatar_url":"https://avatars.githubusercontent.com/u/5640360?v=4","gravatar_id":"","url":"https://api.github.com/users/peteflorence","html_url":"https://github.com/peteflorence","followers_url":"https://api.github.com/users/peteflorence/followers","following_url":"https://api.github.com/users/peteflorence/following{/other_user}","gists_url":"https://api.github.com/users/peteflorence/gists{/gist_id}","starred_url":"https://api.github.com/users/peteflorence/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/peteflorence/subscriptions","organizations_url":"https://api.github.com/users/peteflorence/orgs","repos_url":"https://api.github.com/users/peteflorence/repos","events_url":"https://api.github.com/users/peteflorence/events{/privacy}","received_events_url":"https://api.github.com/users/peteflorence/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/comments/509020278","html_url":"https://github.com/RobotLocomotion/pytorch-dense-correspondence/issues/201#issuecomment-509020278","issue_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/201","id":509020278,"node_id":"MDEyOklzc3VlQ29tbWVudDUwOTAyMDI3OA==","user":{"login":"Amulya21","id":49370470,"node_id":"MDQ6VXNlcjQ5MzcwNDcw","avatar_url":"https://avatars.githubusercontent.com/u/49370470?v=4","gravatar_id":"","url":"https://api.github.com/users/Amulya21","html_url":"https://github.com/Amulya21","followers_url":"https://api.github.com/users/Amulya21/followers","following_url":"https://api.github.com/users/Amulya21/following{/other_user}","gists_url":"https://api.github.com/users/Amulya21/gists{/gist_id}","starred_url":"https://api.github.com/users/Amulya21/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Amulya21/subscriptions","organizations_url":"https://api.github.com/users/Amulya21/orgs","repos_url":"https://api.github.com/users/Amulya21/repos","events_url":"https://api.github.com/users/Amulya21/events{/privacy}","received_events_url":"https://api.github.com/users/Amulya21/received_events","type":"User","site_admin":false},"created_at":"2019-07-07T18:20:35Z","updated_at":"2019-07-07T18:20:35Z","author_association":"NONE","body":"Thank you for the reply,\r\nSuppose if you have 2 rgb images of the same scene(taken from different view points) and you know know much the camera has rotated and translated(pose data),then by applying those translational and rotational information we can know where a specific point(pixel) in one image has moved to another point in other image. If this is how matches or correspondences are found what is the need of 3d reconstruction.\r\n","reactions":{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/comments/509020278/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"Amulya21","id":49370470,"node_id":"MDQ6VXNlcjQ5MzcwNDcw","avatar_url":"https://avatars.githubusercontent.com/u/49370470?v=4","gravatar_id":"","url":"https://api.github.com/users/Amulya21","html_url":"https://github.com/Amulya21","followers_url":"https://api.github.com/users/Amulya21/followers","following_url":"https://api.github.com/users/Amulya21/following{/other_user}","gists_url":"https://api.github.com/users/Amulya21/gists{/gist_id}","starred_url":"https://api.github.com/users/Amulya21/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Amulya21/subscriptions","organizations_url":"https://api.github.com/users/Amulya21/orgs","repos_url":"https://api.github.com/users/Amulya21/repos","events_url":"https://api.github.com/users/Amulya21/events{/privacy}","received_events_url":"https://api.github.com/users/Amulya21/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/comments/509028242","html_url":"https://github.com/RobotLocomotion/pytorch-dense-correspondence/issues/201#issuecomment-509028242","issue_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/201","id":509028242,"node_id":"MDEyOklzc3VlQ29tbWVudDUwOTAyODI0Mg==","user":{"login":"peteflorence","id":5640360,"node_id":"MDQ6VXNlcjU2NDAzNjA=","avatar_url":"https://avatars.githubusercontent.com/u/5640360?v=4","gravatar_id":"","url":"https://api.github.com/users/peteflorence","html_url":"https://github.com/peteflorence","followers_url":"https://api.github.com/users/peteflorence/followers","following_url":"https://api.github.com/users/peteflorence/following{/other_user}","gists_url":"https://api.github.com/users/peteflorence/gists{/gist_id}","starred_url":"https://api.github.com/users/peteflorence/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/peteflorence/subscriptions","organizations_url":"https://api.github.com/users/peteflorence/orgs","repos_url":"https://api.github.com/users/peteflorence/repos","events_url":"https://api.github.com/users/peteflorence/events{/privacy}","received_events_url":"https://api.github.com/users/peteflorence/received_events","type":"User","site_admin":false},"created_at":"2019-07-07T20:26:06Z","updated_at":"2019-07-07T20:26:06Z","author_association":"COLLABORATOR","body":"Hi there,\nYou also need to know the depth for each pixel in order to geometrically\nmatch between two images, just the camera poses aren’t enough.\nIf you just have two depth images each with cameras poses (and known\ncalibration) that is all you need, but the many-view fused 3D\nreconstruction helps denoise depth images and fill in missing data caused\nby practical limitations of depth sensors.\nAll of the above of course assumes the scene is static. In the Schmidt et\nal reference they also did descriptor training with dynamic scenes, made\npossible by non-rigid dynamic reconstruction.\nGood luck!\n\n\nOn Sun, Jul 7, 2019 at 2:20 PM Amulya21 <notifications@github.com> wrote:\n\n> Thank you for the reply,\n> Suppose if you have 2 rgb images of the same scene(taken from different\n> view points) and you know know much the camera has rotated and\n> translated(pose data),then by applying those translational and rotational\n> information we can know where a specific point(pixel) in one image has\n> moved to another point in other image. If this is how matches or\n> correspondences are found what is the need of 3d reconstruction.\n>\n> —\n> You are receiving this because you commented.\n>\n>\n> Reply to this email directly, view it on GitHub\n> <https://github.com/RobotLocomotion/pytorch-dense-correspondence/issues/201?email_source=notifications&email_token=ABLBBKE6M77KIMSEEWJUDI3P6IXXJA5CNFSM4H5CEPV2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODZLQQ5Q#issuecomment-509020278>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABLBBKETKT2TO2HWNLZPKLTP6IXXJANCNFSM4H5CEPVQ>\n> .\n>\n","reactions":{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/comments/509028242/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"peteflorence","id":5640360,"node_id":"MDQ6VXNlcjU2NDAzNjA=","avatar_url":"https://avatars.githubusercontent.com/u/5640360?v=4","gravatar_id":"","url":"https://api.github.com/users/peteflorence","html_url":"https://github.com/peteflorence","followers_url":"https://api.github.com/users/peteflorence/followers","following_url":"https://api.github.com/users/peteflorence/following{/other_user}","gists_url":"https://api.github.com/users/peteflorence/gists{/gist_id}","starred_url":"https://api.github.com/users/peteflorence/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/peteflorence/subscriptions","organizations_url":"https://api.github.com/users/peteflorence/orgs","repos_url":"https://api.github.com/users/peteflorence/repos","events_url":"https://api.github.com/users/peteflorence/events{/privacy}","received_events_url":"https://api.github.com/users/peteflorence/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/comments/511373124","html_url":"https://github.com/RobotLocomotion/pytorch-dense-correspondence/issues/201#issuecomment-511373124","issue_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/201","id":511373124,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMTM3MzEyNA==","user":{"login":"Amulya21","id":49370470,"node_id":"MDQ6VXNlcjQ5MzcwNDcw","avatar_url":"https://avatars.githubusercontent.com/u/49370470?v=4","gravatar_id":"","url":"https://api.github.com/users/Amulya21","html_url":"https://github.com/Amulya21","followers_url":"https://api.github.com/users/Amulya21/followers","following_url":"https://api.github.com/users/Amulya21/following{/other_user}","gists_url":"https://api.github.com/users/Amulya21/gists{/gist_id}","starred_url":"https://api.github.com/users/Amulya21/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Amulya21/subscriptions","organizations_url":"https://api.github.com/users/Amulya21/orgs","repos_url":"https://api.github.com/users/Amulya21/repos","events_url":"https://api.github.com/users/Amulya21/events{/privacy}","received_events_url":"https://api.github.com/users/Amulya21/received_events","type":"User","site_admin":false},"created_at":"2019-07-15T11:58:14Z","updated_at":"2019-07-15T11:58:14Z","author_association":"NONE","body":"Thank you for the reply,\r\nI understood how matching is done for images within scene because we know rotation and translation so we can find how a pixel  moves from one image to another within scene(that is both images are taken from 2018-04-16-14-40-25) .But how is it done across scene like for example between an image from 2018-04-10-16-05-17 and from 2018-04-16-14-40-25.\r\n\r\nAnd while training the res-net architecture how are you sending two images at a time?If both are sent parallely as like in the below link\r\nhttps://qphs.fs.quoracdn.net/main-qimg-35262db76db5e734c74cdd8d1a97c88d\r\nthen how is the error distributed or back propagated.","reactions":{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/comments/511373124/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"Amulya21","id":49370470,"node_id":"MDQ6VXNlcjQ5MzcwNDcw","avatar_url":"https://avatars.githubusercontent.com/u/49370470?v=4","gravatar_id":"","url":"https://api.github.com/users/Amulya21","html_url":"https://github.com/Amulya21","followers_url":"https://api.github.com/users/Amulya21/followers","following_url":"https://api.github.com/users/Amulya21/following{/other_user}","gists_url":"https://api.github.com/users/Amulya21/gists{/gist_id}","starred_url":"https://api.github.com/users/Amulya21/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Amulya21/subscriptions","organizations_url":"https://api.github.com/users/Amulya21/orgs","repos_url":"https://api.github.com/users/Amulya21/repos","events_url":"https://api.github.com/users/Amulya21/events{/privacy}","received_events_url":"https://api.github.com/users/Amulya21/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/comments/511404886","html_url":"https://github.com/RobotLocomotion/pytorch-dense-correspondence/issues/201#issuecomment-511404886","issue_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/201","id":511404886,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMTQwNDg4Ng==","user":{"login":"peteflorence","id":5640360,"node_id":"MDQ6VXNlcjU2NDAzNjA=","avatar_url":"https://avatars.githubusercontent.com/u/5640360?v=4","gravatar_id":"","url":"https://api.github.com/users/peteflorence","html_url":"https://github.com/peteflorence","followers_url":"https://api.github.com/users/peteflorence/followers","following_url":"https://api.github.com/users/peteflorence/following{/other_user}","gists_url":"https://api.github.com/users/peteflorence/gists{/gist_id}","starred_url":"https://api.github.com/users/peteflorence/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/peteflorence/subscriptions","organizations_url":"https://api.github.com/users/peteflorence/orgs","repos_url":"https://api.github.com/users/peteflorence/repos","events_url":"https://api.github.com/users/peteflorence/events{/privacy}","received_events_url":"https://api.github.com/users/peteflorence/received_events","type":"User","site_admin":false},"created_at":"2019-07-15T13:36:28Z","updated_at":"2019-07-15T13:36:28Z","author_association":"COLLABORATOR","body":"Good question. When we do across scene, we do not know any matches, that’s\nright. We only do cross-scene training when we know the objects are\ndifferent, and we know every pixel is a non-match. No matches.\n\nThe pairs of images are trained in a standard Siamese architecture, I think\nyou can find more elsewhere on this.\n\nOn Mon, Jul 15, 2019 at 7:58 AM Amulya21 <notifications@github.com> wrote:\n\n> Thank you for the reply,\n> I understood how matching is done for images within scene because we know\n> rotation and translation so we can find how a pixel moves from one image to\n> another within scene(that is both images are taken from\n> 2018-04-16-14-40-25) .But how is it done across scene like for example\n> between an image from 2018-04-10-16-05-17 and from 2018-04-16-14-40-25.\n>\n> And while training the res-net architecture how are you sending two images\n> at a time?If both are sent parallely as like in the below link\n> https://qphs.fs.quoracdn.net/main-qimg-35262db76db5e734c74cdd8d1a97c88d\n> then how is the error distributed or back propagated.\n>\n> —\n> You are receiving this because you commented.\n>\n>\n> Reply to this email directly, view it on GitHub\n> <https://github.com/RobotLocomotion/pytorch-dense-correspondence/issues/201?email_source=notifications&email_token=ABLBBKDLWQHIJJLOX6UABATP7RQ5PA5CNFSM4H5CEPV2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODZ5O6RA#issuecomment-511373124>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABLBBKFLX37IBXE3W2DB5NLP7RQ5PANCNFSM4H5CEPVQ>\n> .\n>\n","reactions":{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/comments/511404886/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"peteflorence","id":5640360,"node_id":"MDQ6VXNlcjU2NDAzNjA=","avatar_url":"https://avatars.githubusercontent.com/u/5640360?v=4","gravatar_id":"","url":"https://api.github.com/users/peteflorence","html_url":"https://github.com/peteflorence","followers_url":"https://api.github.com/users/peteflorence/followers","following_url":"https://api.github.com/users/peteflorence/following{/other_user}","gists_url":"https://api.github.com/users/peteflorence/gists{/gist_id}","starred_url":"https://api.github.com/users/peteflorence/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/peteflorence/subscriptions","organizations_url":"https://api.github.com/users/peteflorence/orgs","repos_url":"https://api.github.com/users/peteflorence/repos","events_url":"https://api.github.com/users/peteflorence/events{/privacy}","received_events_url":"https://api.github.com/users/peteflorence/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/comments/513549638","html_url":"https://github.com/RobotLocomotion/pytorch-dense-correspondence/issues/201#issuecomment-513549638","issue_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/201","id":513549638,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzU0OTYzOA==","user":{"login":"Amulya21","id":49370470,"node_id":"MDQ6VXNlcjQ5MzcwNDcw","avatar_url":"https://avatars.githubusercontent.com/u/49370470?v=4","gravatar_id":"","url":"https://api.github.com/users/Amulya21","html_url":"https://github.com/Amulya21","followers_url":"https://api.github.com/users/Amulya21/followers","following_url":"https://api.github.com/users/Amulya21/following{/other_user}","gists_url":"https://api.github.com/users/Amulya21/gists{/gist_id}","starred_url":"https://api.github.com/users/Amulya21/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Amulya21/subscriptions","organizations_url":"https://api.github.com/users/Amulya21/orgs","repos_url":"https://api.github.com/users/Amulya21/repos","events_url":"https://api.github.com/users/Amulya21/events{/privacy}","received_events_url":"https://api.github.com/users/Amulya21/received_events","type":"User","site_admin":false},"created_at":"2019-07-21T12:27:28Z","updated_at":"2019-07-21T12:27:28Z","author_association":"NONE","body":"Hii,\r\nI have a doubt regarding the grasping part .By clicking on a specific point of  the image we are giving the robot at which point to grasp on an other position.By finding the point with least  euclidean distance in descriptor space it will identify the point but how will it know at what orientation it should hold the object.\r\n\r\n![Untitled](https://user-images.githubusercontent.com/49370470/61591143-8db53d80-abe0-11e9-8056-dcf8aabe2d60.png)\r\n\r\nBut suppose if I give the point marked in blue in first image it wll definitely identify the point marked in blue in second image but how will it know it which orientation it needs to grasp it.Because gripper cant grasp it in 90 degree to the table , gripper need to parallel to the table in order to grasp it.How will it identify that oreinattion of gripper?\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/comments/513549638/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"Amulya21","id":49370470,"node_id":"MDQ6VXNlcjQ5MzcwNDcw","avatar_url":"https://avatars.githubusercontent.com/u/49370470?v=4","gravatar_id":"","url":"https://api.github.com/users/Amulya21","html_url":"https://github.com/Amulya21","followers_url":"https://api.github.com/users/Amulya21/followers","following_url":"https://api.github.com/users/Amulya21/following{/other_user}","gists_url":"https://api.github.com/users/Amulya21/gists{/gist_id}","starred_url":"https://api.github.com/users/Amulya21/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Amulya21/subscriptions","organizations_url":"https://api.github.com/users/Amulya21/orgs","repos_url":"https://api.github.com/users/Amulya21/repos","events_url":"https://api.github.com/users/Amulya21/events{/privacy}","received_events_url":"https://api.github.com/users/Amulya21/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/comments/513564570","html_url":"https://github.com/RobotLocomotion/pytorch-dense-correspondence/issues/201#issuecomment-513564570","issue_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/201","id":513564570,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzU2NDU3MA==","user":{"login":"peteflorence","id":5640360,"node_id":"MDQ6VXNlcjU2NDAzNjA=","avatar_url":"https://avatars.githubusercontent.com/u/5640360?v=4","gravatar_id":"","url":"https://api.github.com/users/peteflorence","html_url":"https://github.com/peteflorence","followers_url":"https://api.github.com/users/peteflorence/followers","following_url":"https://api.github.com/users/peteflorence/following{/other_user}","gists_url":"https://api.github.com/users/peteflorence/gists{/gist_id}","starred_url":"https://api.github.com/users/peteflorence/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/peteflorence/subscriptions","organizations_url":"https://api.github.com/users/peteflorence/orgs","repos_url":"https://api.github.com/users/peteflorence/repos","events_url":"https://api.github.com/users/peteflorence/events{/privacy}","received_events_url":"https://api.github.com/users/peteflorence/received_events","type":"User","site_admin":false},"created_at":"2019-07-21T15:36:51Z","updated_at":"2019-07-21T15:36:51Z","author_association":"COLLABORATOR","body":"Please see Section C of the Appendix in the paper\n\nOn Sun, Jul 21, 2019 at 8:27 AM Amulya21 <notifications@github.com> wrote:\n\n> Hii,\n> I have a doubt regarding the grasping part .By clicking on a specific\n> point of the image we are giving the robot at which point to grasp on an\n> other position.By finding the point with least euclidean distance in\n> descriptor space it will identify the point but how will it know at what\n> orientation it should hold the object.\n>\n> [image: Untitled]\n> <https://user-images.githubusercontent.com/49370470/61591143-8db53d80-abe0-11e9-8056-dcf8aabe2d60.png>\n>\n> But suppose if I give the point marked in blue in first image it wll\n> definitely identify the point marked in blue in second image but how will\n> it know it which orientation it needs to grasp it.Because gripper cant\n> grasp it in 90 degree to the table , gripper need to parallel to the table\n> in order to grasp it.How will it identify that oreinattion of gripper?\n>\n> —\n> You are receiving this because you commented.\n>\n>\n> Reply to this email directly, view it on GitHub\n> <https://github.com/RobotLocomotion/pytorch-dense-correspondence/issues/201?email_source=notifications&email_token=ABLBBKAUXPQ5C74TT2BYBITQARI3DA5CNFSM4H5CEPV2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD2OCKRQ#issuecomment-513549638>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABLBBKHKHBDXAZZ4DRQCW43QARI3DANCNFSM4H5CEPVQ>\n> .\n>\n","reactions":{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/comments/513564570/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"peteflorence","id":5640360,"node_id":"MDQ6VXNlcjU2NDAzNjA=","avatar_url":"https://avatars.githubusercontent.com/u/5640360?v=4","gravatar_id":"","url":"https://api.github.com/users/peteflorence","html_url":"https://github.com/peteflorence","followers_url":"https://api.github.com/users/peteflorence/followers","following_url":"https://api.github.com/users/peteflorence/following{/other_user}","gists_url":"https://api.github.com/users/peteflorence/gists{/gist_id}","starred_url":"https://api.github.com/users/peteflorence/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/peteflorence/subscriptions","organizations_url":"https://api.github.com/users/peteflorence/orgs","repos_url":"https://api.github.com/users/peteflorence/repos","events_url":"https://api.github.com/users/peteflorence/events{/privacy}","received_events_url":"https://api.github.com/users/peteflorence/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/comments/513564760","html_url":"https://github.com/RobotLocomotion/pytorch-dense-correspondence/issues/201#issuecomment-513564760","issue_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/201","id":513564760,"node_id":"MDEyOklzc3VlQ29tbWVudDUxMzU2NDc2MA==","user":{"login":"Amulya21","id":49370470,"node_id":"MDQ6VXNlcjQ5MzcwNDcw","avatar_url":"https://avatars.githubusercontent.com/u/49370470?v=4","gravatar_id":"","url":"https://api.github.com/users/Amulya21","html_url":"https://github.com/Amulya21","followers_url":"https://api.github.com/users/Amulya21/followers","following_url":"https://api.github.com/users/Amulya21/following{/other_user}","gists_url":"https://api.github.com/users/Amulya21/gists{/gist_id}","starred_url":"https://api.github.com/users/Amulya21/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Amulya21/subscriptions","organizations_url":"https://api.github.com/users/Amulya21/orgs","repos_url":"https://api.github.com/users/Amulya21/repos","events_url":"https://api.github.com/users/Amulya21/events{/privacy}","received_events_url":"https://api.github.com/users/Amulya21/received_events","type":"User","site_admin":false},"created_at":"2019-07-21T15:39:40Z","updated_at":"2019-07-21T15:39:40Z","author_association":"NONE","body":"Thankyou for the reply.","reactions":{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/comments/513564760/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"Amulya21","id":49370470,"node_id":"MDQ6VXNlcjQ5MzcwNDcw","avatar_url":"https://avatars.githubusercontent.com/u/49370470?v=4","gravatar_id":"","url":"https://api.github.com/users/Amulya21","html_url":"https://github.com/Amulya21","followers_url":"https://api.github.com/users/Amulya21/followers","following_url":"https://api.github.com/users/Amulya21/following{/other_user}","gists_url":"https://api.github.com/users/Amulya21/gists{/gist_id}","starred_url":"https://api.github.com/users/Amulya21/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Amulya21/subscriptions","organizations_url":"https://api.github.com/users/Amulya21/orgs","repos_url":"https://api.github.com/users/Amulya21/repos","events_url":"https://api.github.com/users/Amulya21/events{/privacy}","received_events_url":"https://api.github.com/users/Amulya21/received_events","type":"User","site_admin":false}},{"id":2740791008,"node_id":"MDExOkNsb3NlZEV2ZW50Mjc0MDc5MTAwOA==","url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/events/2740791008","actor":{"login":"manuelli","id":5898488,"node_id":"MDQ6VXNlcjU4OTg0ODg=","avatar_url":"https://avatars.githubusercontent.com/u/5898488?v=4","gravatar_id":"","url":"https://api.github.com/users/manuelli","html_url":"https://github.com/manuelli","followers_url":"https://api.github.com/users/manuelli/followers","following_url":"https://api.github.com/users/manuelli/following{/other_user}","gists_url":"https://api.github.com/users/manuelli/gists{/gist_id}","starred_url":"https://api.github.com/users/manuelli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/manuelli/subscriptions","organizations_url":"https://api.github.com/users/manuelli/orgs","repos_url":"https://api.github.com/users/manuelli/repos","events_url":"https://api.github.com/users/manuelli/events{/privacy}","received_events_url":"https://api.github.com/users/manuelli/received_events","type":"User","site_admin":false},"event":"closed","commit_id":null,"commit_url":null,"created_at":"2019-10-24T13:34:46Z","state_reason":null,"performed_via_github_app":null}]