{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/92","repository_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence","labels_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/92/labels{/name}","comments_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/92/comments","events_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/92/events","html_url":"https://github.com/RobotLocomotion/pytorch-dense-correspondence/issues/92","id":318090765,"node_id":"MDU6SXNzdWUzMTgwOTA3NjU=","number":92,"title":"running out of GPU memory when computing test loss","user":{"login":"manuelli","id":5898488,"node_id":"MDQ6VXNlcjU4OTg0ODg=","avatar_url":"https://avatars.githubusercontent.com/u/5898488?v=4","gravatar_id":"","url":"https://api.github.com/users/manuelli","html_url":"https://github.com/manuelli","followers_url":"https://api.github.com/users/manuelli/followers","following_url":"https://api.github.com/users/manuelli/following{/other_user}","gists_url":"https://api.github.com/users/manuelli/gists{/gist_id}","starred_url":"https://api.github.com/users/manuelli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/manuelli/subscriptions","organizations_url":"https://api.github.com/users/manuelli/orgs","repos_url":"https://api.github.com/users/manuelli/repos","events_url":"https://api.github.com/users/manuelli/events{/privacy}","received_events_url":"https://api.github.com/users/manuelli/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2018-04-26T15:48:29Z","updated_at":"2018-06-22T14:33:41Z","closed_at":"2018-04-27T15:28:10Z","author_association":"COLLABORATOR","active_lock_reason":null,"body":"Error happened at iteration 9000 of 10000. Is the test thing just a red herring or are our batch sizes too big somehow?\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-3-f8bf2b034dd8> in <module>()\r\n     10     train._config[\"dense_correspondence_network\"][\"descriptor_dimension\"] = d\r\n     11     train._config[\"training\"][\"num_iterations\"] = num_iterations\r\n---> 12     train.run()\r\n     13     print \"finished training descriptor of dimension %d\" %(d)\r\n\r\n/home/manuelli/code/dense_correspondence/training/training.pyc in run(self, loss_current_iteration, use_pretrained)\r\n    423                     logging.info(\"Computing test loss\")\r\n    424                     test_loss, test_match_loss, test_non_match_loss = DCE.compute_loss_on_dataset(dcn,\r\n--> 425                                                                                                   self._data_loader_test, self._config['loss_function'], num_iterations=self._config['training']['test_loss_num_iterations'])\r\n    426 \r\n    427                     update_visdom_test_loss_plots(test_loss, test_match_loss, test_non_match_loss)\r\n\r\n/home/manuelli/code/dense_correspondence/evaluation/evaluation.pyc in compute_loss_on_dataset(dcn, data_loader, loss_config, num_iterations)\r\n   1494                                                         matches_b,\r\n   1495                                                         non_matches_a,\r\n-> 1496                                                         non_matches_b)\r\n   1497 \r\n   1498 \r\n\r\n/home/manuelli/code/dense_correspondence/loss_functions/pixelwise_contrastive_loss.pyc in get_loss(self, image_a_pred, image_b_pred, matches_a, matches_b, non_matches_a, non_matches_b, M_descriptor, M_pixel, non_match_loss_weight, use_l2_pixel_loss)\r\n    102                                                        non_matches_a, non_matches_b,\r\n    103                                                        M_descriptor=M_descriptor,\r\n--> 104                                                        M_pixel=M_pixel)\r\n    105         else:\r\n    106             # version with no l2 pixel term\r\n\r\n/home/manuelli/code/dense_correspondence/loss_functions/pixelwise_contrastive_loss.pyc in non_match_loss_with_l2_pixel_norm(self, image_a_pred, image_b_pred, matches_b, non_matches_a, non_matches_b, M_descriptor, M_pixel)\r\n    215         num_non_matches = non_matches_a.size()[0]\r\n    216 \r\n--> 217         non_match_descriptor_loss, num_hard_negatives, _, _ = PCL.non_match_descriptor_loss(image_a_pred, image_b_pred, non_matches_a, non_matches_b, M=M_descriptor)\r\n    218 \r\n    219         non_match_pixel_l2_loss, _, _ = self.l2_pixel_loss(matches_b, non_matches_b, M_pixel=M_pixel)\r\n\r\n/home/manuelli/code/dense_correspondence/loss_functions/pixelwise_contrastive_loss.pyc in non_match_descriptor_loss(image_a_pred, image_b_pred, non_matches_a, non_matches_b, M)\r\n    161         \"\"\"\r\n    162 \r\n--> 163         non_matches_a_descriptors = torch.index_select(image_a_pred, 1, non_matches_a).squeeze()\r\n    164         non_matches_b_descriptors = torch.index_select(image_b_pred, 1, non_matches_b).squeeze()\r\n    165 \r\n\r\nRuntimeError: cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:5\r\n```","closed_by":{"login":"peteflorence","id":5640360,"node_id":"MDQ6VXNlcjU2NDAzNjA=","avatar_url":"https://avatars.githubusercontent.com/u/5640360?v=4","gravatar_id":"","url":"https://api.github.com/users/peteflorence","html_url":"https://github.com/peteflorence","followers_url":"https://api.github.com/users/peteflorence/followers","following_url":"https://api.github.com/users/peteflorence/following{/other_user}","gists_url":"https://api.github.com/users/peteflorence/gists{/gist_id}","starred_url":"https://api.github.com/users/peteflorence/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/peteflorence/subscriptions","organizations_url":"https://api.github.com/users/peteflorence/orgs","repos_url":"https://api.github.com/users/peteflorence/repos","events_url":"https://api.github.com/users/peteflorence/events{/privacy}","received_events_url":"https://api.github.com/users/peteflorence/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/92/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/92/timeline","performed_via_github_app":null,"state_reason":"completed"}