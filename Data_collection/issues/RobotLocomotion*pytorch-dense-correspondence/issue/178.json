{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/178","repository_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence","labels_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/178/labels{/name}","comments_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/178/comments","events_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/178/events","html_url":"https://github.com/RobotLocomotion/pytorch-dense-correspondence/issues/178","id":376786414,"node_id":"MDU6SXNzdWUzNzY3ODY0MTQ=","number":178,"title":"Reproducing without docker","user":{"login":"mmaslennikov","id":17181470,"node_id":"MDQ6VXNlcjE3MTgxNDcw","avatar_url":"https://avatars.githubusercontent.com/u/17181470?v=4","gravatar_id":"","url":"https://api.github.com/users/mmaslennikov","html_url":"https://github.com/mmaslennikov","followers_url":"https://api.github.com/users/mmaslennikov/followers","following_url":"https://api.github.com/users/mmaslennikov/following{/other_user}","gists_url":"https://api.github.com/users/mmaslennikov/gists{/gist_id}","starred_url":"https://api.github.com/users/mmaslennikov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mmaslennikov/subscriptions","organizations_url":"https://api.github.com/users/mmaslennikov/orgs","repos_url":"https://api.github.com/users/mmaslennikov/repos","events_url":"https://api.github.com/users/mmaslennikov/events{/privacy}","received_events_url":"https://api.github.com/users/mmaslennikov/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2018-11-02T12:15:10Z","updated_at":"2018-11-06T12:30:45Z","closed_at":"2018-11-04T18:34:48Z","author_association":"NONE","active_lock_reason":null,"body":"Hello,\r\n\r\nImho, reproducing without Docker is a good practice, also nvidia-docker does not pass the nvidia-smi test on my Ubuntu 18.04 using PyCharm 2018, Python 3.7 and Anaconda. So, I am trying to reproduce the system without Docker and would like to share my experience and get advice.\r\n\r\n(0) I separated the data and project files into some <DATA> and <PROJ> directories:\r\nDIR_DATA = '/home/steve/steve/corpus/robot_locomotion'\r\nDIR_PROJ = '/home/steve/experiments/pytorch-dense-correspondence'\r\n\r\n(1) Downloaded the dataset files. The files are huge, so I chose to download Caterpillar\r\n\r\nFirst, I downloaded the files with wget (for a single night) using <PROJ>/config/download_pdc_data.py. However, later I discovered that wget did not download tar.gz correctly. Hence, I had to redownload the files. So, I chose to download them using aria2c, which is 16x faster\r\n\r\nI created the file caterpillar.txt:\r\nhttp://data.csail.mit.edu/labelfusion/pdccompressed/logs_proto/2018-04-16-14-40-25.tar.gz\r\nhttp://data.csail.mit.edu/labelfusion/pdccompressed/logs_proto/2018-04-16-14-42-26.tar.gz\r\nhttp://data.csail.mit.edu/labelfusion/pdccompressed/logs_proto/2018-04-16-14-44-53.tar.gz\r\nhttp://data.csail.mit.edu/labelfusion/pdccompressed/logs_proto/2018-04-16-14-49-22.tar.gz\r\nhttp://data.csail.mit.edu/labelfusion/pdccompressed/logs_proto/2018-04-16-15-23-41.tar.gz\r\nhttp://data.csail.mit.edu/labelfusion/pdccompressed/logs_proto/2018-04-16-15-25-38.tar.gz\r\nhttp://data.csail.mit.edu/labelfusion/pdccompressed/logs_proto/2018-04-16-15-28-45.tar.gz\r\nhttp://data.csail.mit.edu/labelfusion/pdccompressed/logs_proto/2018-04-16-15-30-50.tar.gz\r\nhttp://data.csail.mit.edu/labelfusion/pdccompressed/logs_proto/2018-04-16-14-46-36.tar.gz\r\nhttp://data.csail.mit.edu/labelfusion/pdccompressed/logs_proto/2018-04-16-17-35-21.tar.gz\r\n\r\nAfterwards, I launched it as\r\n$ aria2c -x 16 -i caterpillar.txt\r\n\r\nand manually unpacked into <DATA>/code/data_volume/pdc/logs_proto. In my experience, downloading time per single file became ~3 minutes instead of ~30-35.\r\n\r\n(3) Debugging is imho important and I like to use Pycharm in my work. So, I extracted training_tutorial.ipynb into training_tutorial.py and created simplified unit tests test_trainingTutorial.py. (as attached). I set the directories <PROJ>/dense_correspondence, <PROJ>/modules and <PROJ>/pytorch-segmentation-detection as the source directories.   \r\n\r\n(4) I am launching the train() function in training_tutorial.py. Currently, I am struggling with ResNet34, and it looks like the ResNet version is different (I used diffnow.com to compare). Essentially, variables fully_conv, remove_avg_pool_layer, output_stride=8, dilation do not exist in the current resnet.py. \r\n\r\nWhen I debug the ResNet initialization line, I get the message \r\n\"RuntimeError: Error(s) in loading state_dict for ResNet:\r\nsize mismatch for fc.weight: copying a param of torch.Size([1000, 512, 1, 1]) from checkpoint, where the shape is torch.Size([1000, 512]) in current model.\"\r\n\r\nI am checking out if this error appears due to some ResNet update. Also, why were you including your version of ResNet into <PROJ>/pytorch-segmentation-detection/vision/torchvision/models/resnet.py ? (you could probably inherit the ResNet class). Would you kindly hint why did you choose ResNet and not e.g. Inception or DenseNet? \r\n\r\nIt would be great if you could give your exposure or kind advice. Below are the files that I created.\r\n\r\n============== <PROJ>/dense_correspondence/training/training_tutorial.py ==============\r\n```\r\nimport os\r\nimport sys\r\nfrom config.params import *\r\nimport logging\r\n\r\nimport modules.dense_correspondence_manipulation.utils.utils as utils\r\nfrom dense_correspondence.training.training import *\r\nfrom dense_correspondence.training.training import DenseCorrespondenceTraining\r\nfrom dense_correspondence.dataset.spartan_dataset_masked import SpartanDataset\r\nfrom dense_correspondence.evaluation.evaluation import DenseCorrespondenceEvaluation\r\n\r\n\r\nclass TrainingTutorial:\r\n    def __init__(self):\r\n        os.chdir(DIR_PROJ)\r\n        sys.path.append(os.path.join(DIR_PROJ, 'modules'))\r\n        os.environ['DC_SOURCE_DIR'] = DIR_DATA\r\n\r\n        utils.add_dense_correspondence_to_python_path()\r\n        logging.basicConfig(level=logging.INFO)\r\n\r\n        self.load_configuration()\r\n\r\n\r\n    def load_configuration(self):\r\n        # config_filename = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence',\r\n        config_filename = os.path.join(DIR_PROJ, 'config', 'dense_correspondence',\r\n                                       'dataset', 'composite', 'caterpillar_only_9.yaml')\r\n        config = utils.getDictFromYamlFilename(config_filename)\r\n\r\n        # train_config_file = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence',\r\n        train_config_file = os.path.join(DIR_PROJ, 'config', 'dense_correspondence',\r\n                                         'training', 'training.yaml')\r\n\r\n        self.train_config = utils.getDictFromYamlFilename(train_config_file)\r\n        self.dataset = SpartanDataset(config=config)\r\n\r\n        logging_dir = \"code/data_volume/pdc/trained_models/tutorials\"\r\n        num_iterations = 3500\r\n        descr_dim = 3  # the descriptor dimension\r\n        self.train_config[\"training\"][\"logging_dir_name\"] = \"caterpillar_%d\" % (descr_dim)\r\n        self.train_config[\"training\"][\"logging_dir\"] = logging_dir\r\n        self.train_config[\"dense_correspondence_network\"][\"descriptor_dimension\"] = descr_dim\r\n        self.train_config[\"training\"][\"num_iterations\"] = num_iterations\r\n\r\n\r\n    def train(self):\r\n        # This should take about ~12-15 minutes with a GTX 1080 Ti\r\n\r\n        # All of the saved data for this network will be located in the\r\n        # code/data_volume/pdc/trained_models/tutorials/caterpillar_3 folder\r\n\r\n        descr_dim = self.train_config[\"dense_correspondence_network\"][\"descriptor_dimension\"]\r\n        print(\"training descriptor of dimension %d\" % (descr_dim))\r\n        train = DenseCorrespondenceTraining(dataset=self.dataset, config=self.train_config)\r\n        train.run()\r\n        print(\"finished training descriptor of dimension %d\" % (descr_dim))\r\n\r\n\r\n    def evaluate(self):\r\n        logging_dir = self.train_config[\"training\"][\"logging_dir\"]\r\n        logging_dir_name = self.train_config[\"training\"][\"logging_dir_name\"]\r\n        model_folder = os.path.join(logging_dir, logging_dir_name)\r\n        model_folder = utils.convert_to_absolute_path(model_folder)\r\n\r\n        DCE = DenseCorrespondenceEvaluation\r\n        num_image_pairs = 100\r\n        DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs)\r\n```\r\n\r\n================ <PROJ>/config/params.py ================\r\n```\r\nDIR_DATA = '/home/steve/steve/corpus/robot_locomotion'\r\nDIR_PROJ = '/home/steve/experiments/pytorch-dense-correspondence'\r\n```\r\nThank you in advance","closed_by":{"login":"manuelli","id":5898488,"node_id":"MDQ6VXNlcjU4OTg0ODg=","avatar_url":"https://avatars.githubusercontent.com/u/5898488?v=4","gravatar_id":"","url":"https://api.github.com/users/manuelli","html_url":"https://github.com/manuelli","followers_url":"https://api.github.com/users/manuelli/followers","following_url":"https://api.github.com/users/manuelli/following{/other_user}","gists_url":"https://api.github.com/users/manuelli/gists{/gist_id}","starred_url":"https://api.github.com/users/manuelli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/manuelli/subscriptions","organizations_url":"https://api.github.com/users/manuelli/orgs","repos_url":"https://api.github.com/users/manuelli/repos","events_url":"https://api.github.com/users/manuelli/events{/privacy}","received_events_url":"https://api.github.com/users/manuelli/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/178/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/RobotLocomotion/pytorch-dense-correspondence/issues/178/timeline","performed_via_github_app":null,"state_reason":"completed"}