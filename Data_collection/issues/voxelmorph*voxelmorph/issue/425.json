{"url":"https://api.github.com/repos/voxelmorph/voxelmorph/issues/425","repository_url":"https://api.github.com/repos/voxelmorph/voxelmorph","labels_url":"https://api.github.com/repos/voxelmorph/voxelmorph/issues/425/labels{/name}","comments_url":"https://api.github.com/repos/voxelmorph/voxelmorph/issues/425/comments","events_url":"https://api.github.com/repos/voxelmorph/voxelmorph/issues/425/events","html_url":"https://github.com/voxelmorph/voxelmorph/issues/425","id":1231116867,"node_id":"I_kwDOB_Nd285JYVpD","number":425,"title":"Conversion of H5 model to PyTorch (SynthMorph)","user":{"login":"EvanBeal","id":32447627,"node_id":"MDQ6VXNlcjMyNDQ3NjI3","avatar_url":"https://avatars.githubusercontent.com/u/32447627?v=4","gravatar_id":"","url":"https://api.github.com/users/EvanBeal","html_url":"https://github.com/EvanBeal","followers_url":"https://api.github.com/users/EvanBeal/followers","following_url":"https://api.github.com/users/EvanBeal/following{/other_user}","gists_url":"https://api.github.com/users/EvanBeal/gists{/gist_id}","starred_url":"https://api.github.com/users/EvanBeal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/EvanBeal/subscriptions","organizations_url":"https://api.github.com/users/EvanBeal/orgs","repos_url":"https://api.github.com/users/EvanBeal/repos","events_url":"https://api.github.com/users/EvanBeal/events{/privacy}","received_events_url":"https://api.github.com/users/EvanBeal/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2022-05-10T12:58:22Z","updated_at":"2022-05-12T11:49:28Z","closed_at":"2022-05-12T11:49:28Z","author_association":"NONE","active_lock_reason":null,"body":"Hello ! \r\nI have been working with the SynthMorph method for the past few months and it has allowed me to get really accurate registration results. So thank you very much for providing this innovative approach to registration and for making the code available.\r\n\r\n## **Task** (what are you trying to do/register?)\r\n\r\nNow, I have some models that I have trained with the TensorFlow implementation of the method and I would like to convert these models (.h5) into PyTorch models (.pt).\r\n\r\n## **What have you tried**\r\n\r\nSo, I used the PyTorch architecture of the registration model available in this repository ([VxmDense](https://github.com/voxelmorph/voxelmorph/blob/dev/voxelmorph/torch/networks.py#L147)) to build the model and then assigned the trained weights layer by layer. \r\n\r\nThis was done using the following code:\r\n```\r\nimport os\r\n\r\n# Import the Keras model and copy the weights\r\nimport voxelmorph as vxm\r\ntf_model = vxm.networks.VxmDense.load('model/shapes-dice-vel-3-res-8-16-32-256f.h5', input_model=None)\r\nweights = tf_model.get_weights()\r\n\r\n# import VoxelMorph with pytorch backend\r\nimport importlib\r\nimport torch\r\nos.environ['VXM_BACKEND'] = 'pytorch'\r\nimportlib.reload(vxm)\r\n\r\n# ---- CONVERT THE KERAS/TENSORFLOW H5 MODEL TO PYTORCH ---- #\r\n\r\n# Build a Torch model and set the weights from the Keras model\r\nreg_args = dict(\r\n    inshape=[160, 160, 192],\r\n    int_steps=5,\r\n    int_downsize=2,   # same as int_resolution=2, in keras model\r\n    unet_half_res=True,  # same as svf_resolution=2, in keras model\r\n    nb_unet_features=([256, 256, 256, 256], [256, 256, 256, 256, 256, 256])\r\n)\r\n# Create the PyTorch model\r\npt_model = vxm.networks.VxmDense(**reg_args)\r\n\r\n# Load the weights onto the PyTorch model\r\ni = 0\r\ni_max = len(list(pt_model.named_parameters()))\r\ntorchparam = pt_model.state_dict()\r\nfor k, v in torchparam.items():\r\n    if i < i_max:\r\n        print(\"{:20s} {}\".format(k, v.shape))\r\n        if k.split('.')[-1] == 'weight':\r\n            torchparam[k] = torch.tensor(weights[i].T)\r\n        else:\r\n            torchparam[k] = torch.tensor(weights[i])\r\n        i += 1\r\n\r\npt_model.load_state_dict(torchparam)\r\n\r\n# Save the PyTorch model\r\ntorch.save(pt_model, 'pt_smshapes.pt')\r\n```\r\n\r\nThe problem I am facing is that the PyTorch registration model leads to poor registration results that differ from the accurate results obtained with the TensorFlow model. \r\n\r\nTherefore, I was wondering if you had any ideas on why the observed differences in the registration results of the two models might be created? And if you have tried to do such a conversion with your models? \r\n\r\nThank you !\r\n\r\n## **Details of experiments**\r\n\r\nHere you can find the code I used to load and apply the PyTorch model and the TensorFlow model (in addition to the part used to do the conversion between the H5 and PT model). \r\n\r\n<details>\r\n  <summary>Code</summary>\r\n  \r\n```\r\nimport os\r\n\r\n# Import the Keras model and copy the weights\r\nimport voxelmorph as vxm\r\ntf_model = vxm.networks.VxmDense.load('model/shapes-dice-vel-3-res-8-16-32-256f.h5', input_model=None)\r\nweights = tf_model.get_weights()\r\n\r\n# import VoxelMorph with pytorch backend\r\nimport importlib\r\nimport torch\r\nos.environ['VXM_BACKEND'] = 'pytorch'\r\nimportlib.reload(vxm)\r\n\r\n# ---- FIRST PART - CONVERT THE KERAS/TENSORFLOW H5 MODEL TO PYTORCH ---- #\r\n\r\n# Build a Torch model and set the weights from the Keras model\r\nreg_args = dict(\r\n    inshape=[160, 160, 192],\r\n    int_steps=5,\r\n    int_downsize=2,   # same as int_resolution=2, in keras model\r\n    unet_half_res=True,  # same as svf_resolution=2, in keras model\r\n    nb_unet_features=([256, 256, 256, 256], [256, 256, 256, 256, 256, 256])\r\n)\r\n# Create the PyTorch model\r\npt_model = vxm.networks.VxmDense(**reg_args)\r\n\r\n# Load the weights onto the PyTorch model\r\ni = 0\r\ni_max = len(list(pt_model.named_parameters()))\r\ntorchparam = pt_model.state_dict()\r\nfor k, v in torchparam.items():\r\n    if i < i_max:\r\n        print(\"{:20s} {}\".format(k, v.shape))\r\n        if k.split('.')[-1] == 'weight':\r\n            torchparam[k] = torch.tensor(weights[i].T)\r\n        else:\r\n            torchparam[k] = torch.tensor(weights[i])\r\n        i += 1\r\n\r\npt_model.load_state_dict(torchparam)\r\n\r\n# Save the PyTorch model\r\ntorch.save(pt_model, 'pt_smshapes.pt')\r\n\r\n# ---- SECOND PART - USE THE PYTORCH MODEL FOR REGISTRATION ---- #\r\n\r\nimport numpy as np\r\nimport nibabel as nib\r\nfrom nilearn.image import resample_img\r\n\r\n# Load preprocessed data (scaled between 0 and 1 and with the moving data in the space of the fixed one)\r\nfixed = nib.load(\"data_processed_time_analysis/data2/sub-geneva06/anat/sub-geneva06_T1w.nii.gz\")\r\nmoving = nib.load(\"data_processed_time_analysis/data2/sub-geneva06/anat/sub-geneva06_T2w.nii.gz\")\r\n# N.B.\r\n# These data are in my local computer but any data could be used to perform the same analysis.\r\n# It only needs to be scaled and set in a common space\r\n\r\n# Load the PyTorch model and specify the device\r\ndevice = 'cpu'\r\npt_model_inference = torch.load('pt_smshapes.pt')\r\npt_model_inference.eval()\r\n\r\n# Prepare the data for inference\r\ndata_moving = np.expand_dims(moving.get_fdata()[:160, :160, :192].squeeze(), axis=(0, -1)).astype(np.float32)\r\ndata_fixed = np.expand_dims(fixed.get_fdata()[:160, :160, :192].squeeze(), axis=(0, -1)).astype(np.float32)\r\n# Set up tensors and permute for inference\r\ninput_moving = torch.from_numpy(data_moving).to(device).float().permute(0, 4, 1, 2, 3)\r\ninput_fixed = torch.from_numpy(data_fixed).to(device).float().permute(0, 4, 1, 2, 3)\r\n\r\n# Predict using PyTorch model\r\nmoved, _ = pt_model_inference(input_moving, input_fixed, registration=True)\r\nmoved_data = moved[0][0].detach().numpy()\r\nmoved_nifti = nib.Nifti1Image(moved_data, fixed.affine)\r\nnib.save(moved_nifti, 'registered_data_pytorch.nii.gz')\r\n\r\n# ---- THIRD PART - USE THE TENSORFLOW/KERAS MODEL FOR REGISTRATION ---- #\r\n\r\nmoved, _ = tf_model.predict([data_moving, data_fixed])\r\nmoved_data = moved.squeeze()\r\nmoved_nifti = nib.Nifti1Image(moved_data, fixed.affine)\r\nnib.save(moved_nifti, 'registered_data_tensorflow.nii.gz')\r\n```\r\n</details>\r\n\r\nAnd here is an example of registration results using either the TensorFlow model (accurate registration) or the PyTorch model (poor registration). In this example, the registration is done with the `sm-shapes` model available in this [repo](https://github.com/voxelmorph/voxelmorph/tree/dev/data#models) and using publicly available data from the [spine-generic dataset](https://github.com/spine-generic/data-multi-subject#spine-generic-public-database-multi-subject). \r\n\r\n<details>\r\n  <summary>Example: multimodal intra subject spinal cord data registration</summary>\r\n  \r\n### Before registration\r\n![ezgif com-gif-maker - 2022-05-10T144008 661](https://user-images.githubusercontent.com/32447627/167631766-7dec1ea5-8a1d-4b4b-979f-7caa8d267853.gif)\r\n\r\n### TensorFlow model registration\r\n![ezgif com-gif-maker - 2022-05-10T144316 992](https://user-images.githubusercontent.com/32447627/167631877-e00e94be-07a3-45b7-9e97-7260f45800f0.gif)\r\n\r\n### PyTorch model registration\r\n![ezgif com-gif-maker - 2022-05-10T144139 126](https://user-images.githubusercontent.com/32447627/167631945-1805ccfb-4251-42b6-9e3d-44d25d1d2037.gif)\r\n\r\n</details>\r\n\r\n","closed_by":{"login":"EvanBeal","id":32447627,"node_id":"MDQ6VXNlcjMyNDQ3NjI3","avatar_url":"https://avatars.githubusercontent.com/u/32447627?v=4","gravatar_id":"","url":"https://api.github.com/users/EvanBeal","html_url":"https://github.com/EvanBeal","followers_url":"https://api.github.com/users/EvanBeal/followers","following_url":"https://api.github.com/users/EvanBeal/following{/other_user}","gists_url":"https://api.github.com/users/EvanBeal/gists{/gist_id}","starred_url":"https://api.github.com/users/EvanBeal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/EvanBeal/subscriptions","organizations_url":"https://api.github.com/users/EvanBeal/orgs","repos_url":"https://api.github.com/users/EvanBeal/repos","events_url":"https://api.github.com/users/EvanBeal/events{/privacy}","received_events_url":"https://api.github.com/users/EvanBeal/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/voxelmorph/voxelmorph/issues/425/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/voxelmorph/voxelmorph/issues/425/timeline","performed_via_github_app":null,"state_reason":"completed"}