{"url":"https://api.github.com/repos/voxelmorph/voxelmorph/issues/287","repository_url":"https://api.github.com/repos/voxelmorph/voxelmorph","labels_url":"https://api.github.com/repos/voxelmorph/voxelmorph/issues/287/labels{/name}","comments_url":"https://api.github.com/repos/voxelmorph/voxelmorph/issues/287/comments","events_url":"https://api.github.com/repos/voxelmorph/voxelmorph/issues/287/events","html_url":"https://github.com/voxelmorph/voxelmorph/issues/287","id":846016529,"node_id":"MDU6SXNzdWU4NDYwMTY1Mjk=","number":287,"title":"Flow loss (grad_loss_fn) converge to zero","user":{"login":"xkdlsxm2","id":12407801,"node_id":"MDQ6VXNlcjEyNDA3ODAx","avatar_url":"https://avatars.githubusercontent.com/u/12407801?v=4","gravatar_id":"","url":"https://api.github.com/users/xkdlsxm2","html_url":"https://github.com/xkdlsxm2","followers_url":"https://api.github.com/users/xkdlsxm2/followers","following_url":"https://api.github.com/users/xkdlsxm2/following{/other_user}","gists_url":"https://api.github.com/users/xkdlsxm2/gists{/gist_id}","starred_url":"https://api.github.com/users/xkdlsxm2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xkdlsxm2/subscriptions","organizations_url":"https://api.github.com/users/xkdlsxm2/orgs","repos_url":"https://api.github.com/users/xkdlsxm2/repos","events_url":"https://api.github.com/users/xkdlsxm2/events{/privacy}","received_events_url":"https://api.github.com/users/xkdlsxm2/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-03-31T06:44:27Z","updated_at":"2021-04-06T21:46:06Z","closed_at":"2021-04-06T21:46:06Z","author_association":"NONE","active_lock_reason":null,"body":"**Task** (what are you trying to do/register?)\r\n\r\nI am registering mono-modal MR liver images with different motion states to have same the motion state.\r\nThere are 5 motion states, and I try to register first 4 motion states to the last motion state. \r\nso, my moving image channel is 4, and 1 channel of fixed image. \r\n\r\n**What have you tried**\r\n\r\nSince my input channel is 4, i have 12 channels of flow.\r\nSo, I changed forward part of the SpatialTransformer method like below\r\n`\r\ndef forward(self, src_, flow_):\r\n  \r\n        warp = []\r\n\r\n        for ch_idx in range(4):\r\n\r\n            src = src_[:, ch_idx:ch_idx + 1, ...]\r\n\r\n            flow = flow_[:, ch_idx * 3:ch_idx * 3 + 3, ...]\r\n\r\n            new_locs = self.grid + flow\r\n\r\n            shape = flow.shape[2:]\r\n\r\n            # Need to normalize grid values to [-1, 1] for resampler\r\n            for i in range(len(shape)):\r\n                new_locs[:, i, ...] = 2 * (new_locs[:, i, ...] / (shape[i] - 1) - 0.5)\r\n\r\n            if len(shape) == 2:\r\n                new_locs = new_locs.permute(0, 2, 3, 1)\r\n                new_locs = new_locs[..., [1, 0]]\r\n\r\n            elif len(shape) == 3:\r\n                new_locs = new_locs.permute(0, 2, 3, 4, 1)\r\n                new_locs = new_locs[..., [2, 1, 0]]\r\n\r\n            warp.append(nnf.grid_sample(src, new_locs, mode=self.mode))\r\n\r\n        return torch.cat(warp, dim=1)\r\n`\r\n\r\nAnd instead of using MSE or CC, I used pytorch built-in method, \"L1\" since my another parallel experiment model was regulated by L1. \r\nI found grad_loss was too small with the parameter you mentioned in the paper (1 for MSE and 0.1 for CC), so I increased the regularizing parameter as 100 to 1000. \r\nfor the first 3 iterations in the first epoch, grad_loss increases a lot, but after 3 epochs, grad_loss finally converges to zero. I mean not exactly zero, but it almost zero so the final result was not very different to the input. \r\n\r\nAnd, 3D image have 2 different size of z direction, 30 and 35, I declare two variables for SpatialTransformer like\r\n`\r\n\r\n        self.spatial_transform_35 = SpatialTransformer((35, *args.image_size))\r\n\r\n        self.spatial_transform_30 = SpatialTransformer((30, *args.image_size))\r\n`\r\n\r\nin initializer of cvpr2018_net class, and in the forward method, I controlled the spatial_trasnform_xx by\r\n\r\n`\r\n\r\n        if src.shape[2] == 35:\r\n            y = self.spatial_transform_35(src, flow)\r\n\r\n        elif src.shape[2] == 30:\r\n            y = self.spatial_transform_30(src, flow)\r\n`\r\n\r\nAnd since I need to use the same network to another parallel experiment, I plug in my ResUNet model in initializer of cvpr2018_net clase like\r\n\r\n`\r\n\r\n         if model == \"UNet_voxelmorph\":\r\n            self.model = unet_core(dim=dim, feats=args.feats, in_channels=args.in_ch, out_channels=args.out_ch, full_size=full_size)\r\n\r\n        elif model == \"ResUNet_voxelmorph\":\r\n            self.model = ResUNet(in_channels=args.in_ch, out_channels=args.out_ch, n_features=args.feats, trilinear=True, kernel=args.kernel, pad=args.padding)\r\n`\r\n\r\n        \r\nThese three parts (4 channels of moving image, 2 different variable of spatial_transform_xx and plugged-in ResUNet model) are only things I changed from your model. \r\n**Details of experiments**\r\n\r\nThe model network is ResUNet which I implemented, and I used L1 loss and Adam optimier. Learning rate is 1e-2 to 1e-3 and it decays by 0.9 every 2 epochs. I run 30 epochs and each epoch iterates 116 which is the number of my 3D dataset. \r\n![7-Loss_plot](https://user-images.githubusercontent.com/12407801/113099807-d49f6700-91fa-11eb-9801-1827198d06b5.png)\r\nThis plot is loss plot and corresponding PSNR and SSIM\r\nThe training loss for the first 2 epochs are high because of high grad_loss, but after it converge to zero, then the loss almost converges at some point. \r\nAs you can see in PSNR or SSIM, it increases very slightly, and it doesn't show any big difference in output image comparing to the input. \r\n\r\nThis image is the result image.\r\nYou can ignore the first column ( I just input to compare with another parallel experiment), and the second column is average image of the 4 moving images, the third is the output of 1 channel, and the last column is the target. \r\n\r\n![7_explicit - b50_0](https://user-images.githubusercontent.com/12407801/113100056-2cd66900-91fb-11eb-85d9-95bb159f431b.png)\r\n\r\nWhat would be the problem to update flow? or how to prevent converging grad_loss to zero?\r\n\r\nThank you very much \r\n\r\nPlease carefully specify details about your experiments. If you are training, when what is the setup? What loss are you using? What does the convergence look like? If you are registering, please show example inputs and outputs. etc.\r\n\r\n","closed_by":{"login":"xkdlsxm2","id":12407801,"node_id":"MDQ6VXNlcjEyNDA3ODAx","avatar_url":"https://avatars.githubusercontent.com/u/12407801?v=4","gravatar_id":"","url":"https://api.github.com/users/xkdlsxm2","html_url":"https://github.com/xkdlsxm2","followers_url":"https://api.github.com/users/xkdlsxm2/followers","following_url":"https://api.github.com/users/xkdlsxm2/following{/other_user}","gists_url":"https://api.github.com/users/xkdlsxm2/gists{/gist_id}","starred_url":"https://api.github.com/users/xkdlsxm2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xkdlsxm2/subscriptions","organizations_url":"https://api.github.com/users/xkdlsxm2/orgs","repos_url":"https://api.github.com/users/xkdlsxm2/repos","events_url":"https://api.github.com/users/xkdlsxm2/events{/privacy}","received_events_url":"https://api.github.com/users/xkdlsxm2/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/voxelmorph/voxelmorph/issues/287/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/voxelmorph/voxelmorph/issues/287/timeline","performed_via_github_app":null,"state_reason":"completed"}