{"url":"https://api.github.com/repos/beringresearch/ivis/issues/59","repository_url":"https://api.github.com/repos/beringresearch/ivis","labels_url":"https://api.github.com/repos/beringresearch/ivis/issues/59/labels{/name}","comments_url":"https://api.github.com/repos/beringresearch/ivis/issues/59/comments","events_url":"https://api.github.com/repos/beringresearch/ivis/issues/59/events","html_url":"https://github.com/beringresearch/ivis/issues/59","id":555703259,"node_id":"MDU6SXNzdWU1NTU3MDMyNTk=","number":59,"title":"Custom generator for training on out-of-memory datasets","user":{"login":"candalfigomoro","id":50733646,"node_id":"MDQ6VXNlcjUwNzMzNjQ2","avatar_url":"https://avatars.githubusercontent.com/u/50733646?v=4","gravatar_id":"","url":"https://api.github.com/users/candalfigomoro","html_url":"https://github.com/candalfigomoro","followers_url":"https://api.github.com/users/candalfigomoro/followers","following_url":"https://api.github.com/users/candalfigomoro/following{/other_user}","gists_url":"https://api.github.com/users/candalfigomoro/gists{/gist_id}","starred_url":"https://api.github.com/users/candalfigomoro/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/candalfigomoro/subscriptions","organizations_url":"https://api.github.com/users/candalfigomoro/orgs","repos_url":"https://api.github.com/users/candalfigomoro/repos","events_url":"https://api.github.com/users/candalfigomoro/events{/privacy}","received_events_url":"https://api.github.com/users/candalfigomoro/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2020-01-27T16:53:37Z","updated_at":"2023-01-11T11:31:10Z","closed_at":"2023-01-11T11:31:10Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"In https://bering-ivis.readthedocs.io/en/latest/oom_datasets.html, for out-of-memory datasets, you say to train on h5 files that exist on disk.\r\n\r\nIn my case, I can't use h5 files, but I could use a custom generator which yields numpy array batched data.\r\n\r\nIs there a way to provide batched data through a custom generator function? Something like keras' `fit_generator`.\r\n\r\nThank you","closed_by":{"login":"Szubie","id":13461031,"node_id":"MDQ6VXNlcjEzNDYxMDMx","avatar_url":"https://avatars.githubusercontent.com/u/13461031?v=4","gravatar_id":"","url":"https://api.github.com/users/Szubie","html_url":"https://github.com/Szubie","followers_url":"https://api.github.com/users/Szubie/followers","following_url":"https://api.github.com/users/Szubie/following{/other_user}","gists_url":"https://api.github.com/users/Szubie/gists{/gist_id}","starred_url":"https://api.github.com/users/Szubie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Szubie/subscriptions","organizations_url":"https://api.github.com/users/Szubie/orgs","repos_url":"https://api.github.com/users/Szubie/repos","events_url":"https://api.github.com/users/Szubie/events{/privacy}","received_events_url":"https://api.github.com/users/Szubie/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/beringresearch/ivis/issues/59/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/beringresearch/ivis/issues/59/timeline","performed_via_github_app":null,"state_reason":"completed"}