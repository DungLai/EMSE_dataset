{"url":"https://api.github.com/repos/beringresearch/ivis/issues/47","repository_url":"https://api.github.com/repos/beringresearch/ivis","labels_url":"https://api.github.com/repos/beringresearch/ivis/issues/47/labels{/name}","comments_url":"https://api.github.com/repos/beringresearch/ivis/issues/47/comments","events_url":"https://api.github.com/repos/beringresearch/ivis/issues/47/events","html_url":"https://github.com/beringresearch/ivis/issues/47","id":499033767,"node_id":"MDU6SXNzdWU0OTkwMzM3Njc=","number":47,"title":"Loss always going towards 1, all embeddings transform to the same values???","user":{"login":"Hellisotherpeople","id":12686966,"node_id":"MDQ6VXNlcjEyNjg2OTY2","avatar_url":"https://avatars.githubusercontent.com/u/12686966?v=4","gravatar_id":"","url":"https://api.github.com/users/Hellisotherpeople","html_url":"https://github.com/Hellisotherpeople","followers_url":"https://api.github.com/users/Hellisotherpeople/followers","following_url":"https://api.github.com/users/Hellisotherpeople/following{/other_user}","gists_url":"https://api.github.com/users/Hellisotherpeople/gists{/gist_id}","starred_url":"https://api.github.com/users/Hellisotherpeople/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Hellisotherpeople/subscriptions","organizations_url":"https://api.github.com/users/Hellisotherpeople/orgs","repos_url":"https://api.github.com/users/Hellisotherpeople/repos","events_url":"https://api.github.com/users/Hellisotherpeople/events{/privacy}","received_events_url":"https://api.github.com/users/Hellisotherpeople/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2019-09-26T18:01:40Z","updated_at":"2019-09-30T13:46:24Z","closed_at":"2019-09-30T13:46:24Z","author_association":"NONE","active_lock_reason":null,"body":"I have a dataset consisting of 1200D concatonated avg pooled FastText vectors (2 seperate documents going through 2 fasttext models for a total of 4 * 300d vectors per example). \r\n\r\nThis dataset properly reduces in dimensionality and projects properly when ran through UMAP, but when ran through Ivis (installed through pip), the loss always goes towards 1 and the embeddings for every example are exactly (err, nearly) the same. \r\n\r\nThis seems like a bug. I can't provide you the exact data to reproduce with but it is easy to generate some fasttext word vectors and try ivis on them. \r\n\r\n\r\n\r\nExample of the what I am seeing for the same data (top is Ivis, bottom is UMAP)  \r\n![image](https://user-images.githubusercontent.com/12686966/65712950-f2f83580-e04c-11e9-903e-79c243d2469f.png)\r\n","closed_by":{"login":"idroz","id":12413294,"node_id":"MDQ6VXNlcjEyNDEzMjk0","avatar_url":"https://avatars.githubusercontent.com/u/12413294?v=4","gravatar_id":"","url":"https://api.github.com/users/idroz","html_url":"https://github.com/idroz","followers_url":"https://api.github.com/users/idroz/followers","following_url":"https://api.github.com/users/idroz/following{/other_user}","gists_url":"https://api.github.com/users/idroz/gists{/gist_id}","starred_url":"https://api.github.com/users/idroz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/idroz/subscriptions","organizations_url":"https://api.github.com/users/idroz/orgs","repos_url":"https://api.github.com/users/idroz/repos","events_url":"https://api.github.com/users/idroz/events{/privacy}","received_events_url":"https://api.github.com/users/idroz/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/beringresearch/ivis/issues/47/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/beringresearch/ivis/issues/47/timeline","performed_via_github_app":null,"state_reason":"completed"}