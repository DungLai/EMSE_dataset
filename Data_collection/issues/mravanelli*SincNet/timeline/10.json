[{"url":"https://api.github.com/repos/mravanelli/SincNet/issues/comments/432265557","html_url":"https://github.com/mravanelli/SincNet/issues/10#issuecomment-432265557","issue_url":"https://api.github.com/repos/mravanelli/SincNet/issues/10","id":432265557,"node_id":"MDEyOklzc3VlQ29tbWVudDQzMjI2NTU1Nw==","user":{"login":"mravanelli","id":16886998,"node_id":"MDQ6VXNlcjE2ODg2OTk4","avatar_url":"https://avatars.githubusercontent.com/u/16886998?v=4","gravatar_id":"","url":"https://api.github.com/users/mravanelli","html_url":"https://github.com/mravanelli","followers_url":"https://api.github.com/users/mravanelli/followers","following_url":"https://api.github.com/users/mravanelli/following{/other_user}","gists_url":"https://api.github.com/users/mravanelli/gists{/gist_id}","starred_url":"https://api.github.com/users/mravanelli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mravanelli/subscriptions","organizations_url":"https://api.github.com/users/mravanelli/orgs","repos_url":"https://api.github.com/users/mravanelli/repos","events_url":"https://api.github.com/users/mravanelli/events{/privacy}","received_events_url":"https://api.github.com/users/mravanelli/received_events","type":"User","site_admin":false},"created_at":"2018-10-23T14:17:39Z","updated_at":"2018-10-23T14:17:39Z","author_association":"OWNER","body":"Hi,\nit's similar to 2 (our setup is also similar to that described in DEEP\nNEURAL NETWORKS FOR SMALL FOOTPRINT TEXT-DEPENDENT SPEAKER VERIFICATION).\nThe difference is that we don't expand the context (since our input is\nalready a chunk of signal of 200 ms). Moreover, our i-vector is the average\nof all activations, and not the sum (very minor difference).\n\n\n\n\n\n\nOn Mon, Oct 22, 2018 at 11:35 PM Incomplete <notifications@github.com>\nwrote:\n\n> *Table 2* of the paper compares the performance on the speaker\n> verification task bewteen SincNet with d-vector and several other models.\n> How's the d-vector extracted? Which of the following is correct?\n>\n>    1.\n>\n>    The naive way. Namely a random chunk (200 ms, not necessarily comes\n>    from the same utterance) of the speaker's audio is pre-processed (\\x\n>    -> x / abs(max(y)), where x is the current chunk and y is whole\n>    signal), and then fed to the network, the output of the last hidden layer\n>    (i.e. the output of DNN1_net) is obtained, do the same for other audio\n>    chunks (thus many audio chunks are consumed), one would get many vectors,\n>    denoted d_1, d_2, ..., d_n, each d_i is L2 normalized to get d'_i and\n>    the final d-vector of this speaker is mean(d'_1, d'_2, ..., d'_n).\n>    2.\n>\n>    The \"original\" way. A speaker is represented by a sequence of\n>    utterance, {O_i: i}, each utterance is consisted of a sequence of\n>    frames, {o_j: j}, during enrollment/verification, each o_j is\n>    companied by its context, (the original paper uses 30 frames to the left\n>    and 10 frames to the right), and fed to the network, the output of the last\n>    hidden layer is extracted, denoted with a_j, a_j is then L2\n>    normalized, the d-vector of utterance O_i is sum_{j} {a_j}; the\n>    d-vector of the speaker is mean({d-vector of O_i: i})\n>\n> The d-vector paper:\n> https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41939.pdf\n>\n> —\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/mravanelli/SincNet/issues/10>, or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AQGs1r_D69phBoW2RsZy-otMYhoGEvgTks5uno52gaJpZM4X0ot7>\n> .\n>\n","reactions":{"url":"https://api.github.com/repos/mravanelli/SincNet/issues/comments/432265557/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"mravanelli","id":16886998,"node_id":"MDQ6VXNlcjE2ODg2OTk4","avatar_url":"https://avatars.githubusercontent.com/u/16886998?v=4","gravatar_id":"","url":"https://api.github.com/users/mravanelli","html_url":"https://github.com/mravanelli","followers_url":"https://api.github.com/users/mravanelli/followers","following_url":"https://api.github.com/users/mravanelli/following{/other_user}","gists_url":"https://api.github.com/users/mravanelli/gists{/gist_id}","starred_url":"https://api.github.com/users/mravanelli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mravanelli/subscriptions","organizations_url":"https://api.github.com/users/mravanelli/orgs","repos_url":"https://api.github.com/users/mravanelli/repos","events_url":"https://api.github.com/users/mravanelli/events{/privacy}","received_events_url":"https://api.github.com/users/mravanelli/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/mravanelli/SincNet/issues/comments/432894661","html_url":"https://github.com/mravanelli/SincNet/issues/10#issuecomment-432894661","issue_url":"https://api.github.com/repos/mravanelli/SincNet/issues/10","id":432894661,"node_id":"MDEyOklzc3VlQ29tbWVudDQzMjg5NDY2MQ==","user":{"login":"qwfy","id":11158705,"node_id":"MDQ6VXNlcjExMTU4NzA1","avatar_url":"https://avatars.githubusercontent.com/u/11158705?v=4","gravatar_id":"","url":"https://api.github.com/users/qwfy","html_url":"https://github.com/qwfy","followers_url":"https://api.github.com/users/qwfy/followers","following_url":"https://api.github.com/users/qwfy/following{/other_user}","gists_url":"https://api.github.com/users/qwfy/gists{/gist_id}","starred_url":"https://api.github.com/users/qwfy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qwfy/subscriptions","organizations_url":"https://api.github.com/users/qwfy/orgs","repos_url":"https://api.github.com/users/qwfy/repos","events_url":"https://api.github.com/users/qwfy/events{/privacy}","received_events_url":"https://api.github.com/users/qwfy/received_events","type":"User","site_admin":false},"created_at":"2018-10-25T02:44:00Z","updated_at":"2018-10-25T02:44:00Z","author_association":"NONE","body":"Thanks :+1: ","reactions":{"url":"https://api.github.com/repos/mravanelli/SincNet/issues/comments/432894661/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"qwfy","id":11158705,"node_id":"MDQ6VXNlcjExMTU4NzA1","avatar_url":"https://avatars.githubusercontent.com/u/11158705?v=4","gravatar_id":"","url":"https://api.github.com/users/qwfy","html_url":"https://github.com/qwfy","followers_url":"https://api.github.com/users/qwfy/followers","following_url":"https://api.github.com/users/qwfy/following{/other_user}","gists_url":"https://api.github.com/users/qwfy/gists{/gist_id}","starred_url":"https://api.github.com/users/qwfy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qwfy/subscriptions","organizations_url":"https://api.github.com/users/qwfy/orgs","repos_url":"https://api.github.com/users/qwfy/repos","events_url":"https://api.github.com/users/qwfy/events{/privacy}","received_events_url":"https://api.github.com/users/qwfy/received_events","type":"User","site_admin":false}},{"id":1925072147,"node_id":"MDExOkNsb3NlZEV2ZW50MTkyNTA3MjE0Nw==","url":"https://api.github.com/repos/mravanelli/SincNet/issues/events/1925072147","actor":{"login":"qwfy","id":11158705,"node_id":"MDQ6VXNlcjExMTU4NzA1","avatar_url":"https://avatars.githubusercontent.com/u/11158705?v=4","gravatar_id":"","url":"https://api.github.com/users/qwfy","html_url":"https://github.com/qwfy","followers_url":"https://api.github.com/users/qwfy/followers","following_url":"https://api.github.com/users/qwfy/following{/other_user}","gists_url":"https://api.github.com/users/qwfy/gists{/gist_id}","starred_url":"https://api.github.com/users/qwfy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qwfy/subscriptions","organizations_url":"https://api.github.com/users/qwfy/orgs","repos_url":"https://api.github.com/users/qwfy/repos","events_url":"https://api.github.com/users/qwfy/events{/privacy}","received_events_url":"https://api.github.com/users/qwfy/received_events","type":"User","site_admin":false},"event":"closed","commit_id":null,"commit_url":null,"created_at":"2018-10-25T02:44:00Z","state_reason":null,"performed_via_github_app":null},{"url":"https://api.github.com/repos/mravanelli/SincNet/issues/comments/453984222","html_url":"https://github.com/mravanelli/SincNet/issues/10#issuecomment-453984222","issue_url":"https://api.github.com/repos/mravanelli/SincNet/issues/10","id":453984222,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1Mzk4NDIyMg==","user":{"login":"seandickert","id":14861440,"node_id":"MDQ6VXNlcjE0ODYxNDQw","avatar_url":"https://avatars.githubusercontent.com/u/14861440?v=4","gravatar_id":"","url":"https://api.github.com/users/seandickert","html_url":"https://github.com/seandickert","followers_url":"https://api.github.com/users/seandickert/followers","following_url":"https://api.github.com/users/seandickert/following{/other_user}","gists_url":"https://api.github.com/users/seandickert/gists{/gist_id}","starred_url":"https://api.github.com/users/seandickert/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/seandickert/subscriptions","organizations_url":"https://api.github.com/users/seandickert/orgs","repos_url":"https://api.github.com/users/seandickert/repos","events_url":"https://api.github.com/users/seandickert/events{/privacy}","received_events_url":"https://api.github.com/users/seandickert/received_events","type":"User","site_admin":false},"created_at":"2019-01-14T12:10:12Z","updated_at":"2019-01-14T12:10:12Z","author_association":"NONE","body":"Hi,\r\n\r\nJust for clarification, to extract a d-vector from a single signal or utterance (referencing the SincNet config file in the repo), we take N 200 ms chunks, with 10ms overlap, of the entire signal, where N is the number of chunks we get by walking through the entire signal.  For each chunk, we run it through the model, extracting the activation of the last layer in the dense network (should be of size 2048), resulting in N activations of length 2048 (N d-vectors for that utterance).  Finally, we apply an L2 norm across the N vectors, followed by taking the mean of them, resulting in 1 d-vector of length 2048?  Is this accurate?\r\n\r\nI'm curious how this approach might be impacted by utterances which contain a large amount of non-speech noise between speech.  Will it effectively \"water down\" the speech samples by averaging it with the d-vectors of the non-speech noise?  Specifically, I'm talking about noise which is difficult to remove from an utterance using off the shelf VAD.  If using cosine scoring to compare d-vectors, I understand that it requires some method for aggregating the vectors so that we can compare utterances of different length without having to cross score many d-vectors or otherwise average scores somehow.  But, given that something like a PLDA model can use a distribution of a speaker's d-vectors to train and predict, would it be better to not normalize and aggregate per utterance and rather feed all of the N d-vectors to the PLDA model?","reactions":{"url":"https://api.github.com/repos/mravanelli/SincNet/issues/comments/453984222/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"seandickert","id":14861440,"node_id":"MDQ6VXNlcjE0ODYxNDQw","avatar_url":"https://avatars.githubusercontent.com/u/14861440?v=4","gravatar_id":"","url":"https://api.github.com/users/seandickert","html_url":"https://github.com/seandickert","followers_url":"https://api.github.com/users/seandickert/followers","following_url":"https://api.github.com/users/seandickert/following{/other_user}","gists_url":"https://api.github.com/users/seandickert/gists{/gist_id}","starred_url":"https://api.github.com/users/seandickert/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/seandickert/subscriptions","organizations_url":"https://api.github.com/users/seandickert/orgs","repos_url":"https://api.github.com/users/seandickert/repos","events_url":"https://api.github.com/users/seandickert/events{/privacy}","received_events_url":"https://api.github.com/users/seandickert/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/mravanelli/SincNet/issues/comments/454060895","html_url":"https://github.com/mravanelli/SincNet/issues/10#issuecomment-454060895","issue_url":"https://api.github.com/repos/mravanelli/SincNet/issues/10","id":454060895,"node_id":"MDEyOklzc3VlQ29tbWVudDQ1NDA2MDg5NQ==","user":{"login":"mravanelli","id":16886998,"node_id":"MDQ6VXNlcjE2ODg2OTk4","avatar_url":"https://avatars.githubusercontent.com/u/16886998?v=4","gravatar_id":"","url":"https://api.github.com/users/mravanelli","html_url":"https://github.com/mravanelli","followers_url":"https://api.github.com/users/mravanelli/followers","following_url":"https://api.github.com/users/mravanelli/following{/other_user}","gists_url":"https://api.github.com/users/mravanelli/gists{/gist_id}","starred_url":"https://api.github.com/users/mravanelli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mravanelli/subscriptions","organizations_url":"https://api.github.com/users/mravanelli/orgs","repos_url":"https://api.github.com/users/mravanelli/repos","events_url":"https://api.github.com/users/mravanelli/events{/privacy}","received_events_url":"https://api.github.com/users/mravanelli/received_events","type":"User","site_admin":false},"created_at":"2019-01-14T16:10:35Z","updated_at":"2019-01-14T16:10:35Z","author_association":"OWNER","body":"Hi,\nyes, your description of d-vector extraction is correct.\nI didn't consider in my study the presence of noise. It can clearly make\nlearning speaker identities much more difficult. One can also consider an\nattention model (as far as I remember someone has used it for speaker\nid/verification) that attributes higher weight to the most important\nframes, and lower to the frames which are considered noisy.\n\nMirco\n\n\n\nOn Mon, Jan 14, 2019 at 7:10 AM seandickert <notifications@github.com>\nwrote:\n\n> Hi,\n>\n> Just for clarification, to extract a d-vector from a single signal or\n> utterance (referencing the SincNet config file in the repo), we take N 200\n> ms chunks, with 10ms overlap, of the entire signal, where N is the number\n> of chunks we get by walking through the entire signal. For each chunk, we\n> run it through the model, extracting the activation of the last layer in\n> the dense network (should be of size 2048), resulting in N activations of\n> length 2048 (N d-vectors for that utterance). Finally, we apply an L2 norm\n> across the N vectors, followed by taking the mean of them, resulting in 1\n> d-vector of length 2048? Is this accurate?\n>\n> I'm curious how this approach might be impacted by utterances which\n> contain a large amount of non-speech noise between speech. Will it\n> effectively \"water down\" the speech samples by averaging it with the\n> d-vectors of the non-speech noise? Specifically, I'm talking about noise\n> which is difficult to remove from an utterance using off the shelf VAD. If\n> using cosine scoring to compare d-vectors, I understand that it requires\n> some method for aggregating the vectors so that we can compare utterances\n> of different length without having to cross score many d-vectors or\n> otherwise average scores somehow. But, given that something like a PLDA\n> model can use a distribution of a speaker's d-vectors to train and predict,\n> would it be better to not normalize and aggregate per utterance and rather\n> feed all of the N d-vectors to the PLDA model?\n>\n> —\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/mravanelli/SincNet/issues/10#issuecomment-453984222>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AQGs1jQbAnSlATpGb3e8TJ16UnUpy8vtks5vDHOkgaJpZM4X0ot7>\n> .\n>\n","reactions":{"url":"https://api.github.com/repos/mravanelli/SincNet/issues/comments/454060895/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"mravanelli","id":16886998,"node_id":"MDQ6VXNlcjE2ODg2OTk4","avatar_url":"https://avatars.githubusercontent.com/u/16886998?v=4","gravatar_id":"","url":"https://api.github.com/users/mravanelli","html_url":"https://github.com/mravanelli","followers_url":"https://api.github.com/users/mravanelli/followers","following_url":"https://api.github.com/users/mravanelli/following{/other_user}","gists_url":"https://api.github.com/users/mravanelli/gists{/gist_id}","starred_url":"https://api.github.com/users/mravanelli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mravanelli/subscriptions","organizations_url":"https://api.github.com/users/mravanelli/orgs","repos_url":"https://api.github.com/users/mravanelli/repos","events_url":"https://api.github.com/users/mravanelli/events{/privacy}","received_events_url":"https://api.github.com/users/mravanelli/received_events","type":"User","site_admin":false}}]