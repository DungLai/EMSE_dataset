{"url":"https://api.github.com/repos/MillionIntegrals/vel/issues/37","repository_url":"https://api.github.com/repos/MillionIntegrals/vel","labels_url":"https://api.github.com/repos/MillionIntegrals/vel/issues/37/labels{/name}","comments_url":"https://api.github.com/repos/MillionIntegrals/vel/issues/37/comments","events_url":"https://api.github.com/repos/MillionIntegrals/vel/issues/37/events","html_url":"https://github.com/MillionIntegrals/vel/issues/37","id":404118855,"node_id":"MDU6SXNzdWU0MDQxMTg4NTU=","number":37,"title":"Loading saved models?","user":{"login":"sgillen","id":9152639,"node_id":"MDQ6VXNlcjkxNTI2Mzk=","avatar_url":"https://avatars.githubusercontent.com/u/9152639?v=4","gravatar_id":"","url":"https://api.github.com/users/sgillen","html_url":"https://github.com/sgillen","followers_url":"https://api.github.com/users/sgillen/followers","following_url":"https://api.github.com/users/sgillen/following{/other_user}","gists_url":"https://api.github.com/users/sgillen/gists{/gist_id}","starred_url":"https://api.github.com/users/sgillen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sgillen/subscriptions","organizations_url":"https://api.github.com/users/sgillen/orgs","repos_url":"https://api.github.com/users/sgillen/repos","events_url":"https://api.github.com/users/sgillen/events{/privacy}","received_events_url":"https://api.github.com/users/sgillen/received_events","type":"User","site_admin":false},"labels":[{"id":928121796,"node_id":"MDU6TGFiZWw5MjgxMjE3OTY=","url":"https://api.github.com/repos/MillionIntegrals/vel/labels/question","name":"question","color":"d876e3","default":true,"description":"Further information is requested"}],"state":"closed","locked":false,"assignee":{"login":"MillionIntegrals","id":2262651,"node_id":"MDQ6VXNlcjIyNjI2NTE=","avatar_url":"https://avatars.githubusercontent.com/u/2262651?v=4","gravatar_id":"","url":"https://api.github.com/users/MillionIntegrals","html_url":"https://github.com/MillionIntegrals","followers_url":"https://api.github.com/users/MillionIntegrals/followers","following_url":"https://api.github.com/users/MillionIntegrals/following{/other_user}","gists_url":"https://api.github.com/users/MillionIntegrals/gists{/gist_id}","starred_url":"https://api.github.com/users/MillionIntegrals/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MillionIntegrals/subscriptions","organizations_url":"https://api.github.com/users/MillionIntegrals/orgs","repos_url":"https://api.github.com/users/MillionIntegrals/repos","events_url":"https://api.github.com/users/MillionIntegrals/events{/privacy}","received_events_url":"https://api.github.com/users/MillionIntegrals/received_events","type":"User","site_admin":false},"assignees":[{"login":"MillionIntegrals","id":2262651,"node_id":"MDQ6VXNlcjIyNjI2NTE=","avatar_url":"https://avatars.githubusercontent.com/u/2262651?v=4","gravatar_id":"","url":"https://api.github.com/users/MillionIntegrals","html_url":"https://github.com/MillionIntegrals","followers_url":"https://api.github.com/users/MillionIntegrals/followers","following_url":"https://api.github.com/users/MillionIntegrals/following{/other_user}","gists_url":"https://api.github.com/users/MillionIntegrals/gists{/gist_id}","starred_url":"https://api.github.com/users/MillionIntegrals/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MillionIntegrals/subscriptions","organizations_url":"https://api.github.com/users/MillionIntegrals/orgs","repos_url":"https://api.github.com/users/MillionIntegrals/repos","events_url":"https://api.github.com/users/MillionIntegrals/events{/privacy}","received_events_url":"https://api.github.com/users/MillionIntegrals/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2019-01-29T04:35:24Z","updated_at":"2019-03-01T07:30:10Z","closed_at":"2019-03-01T07:30:10Z","author_association":"NONE","active_lock_reason":null,"body":"I'm trying to load a trained model to investigate its behavior (I'm interested in for example training a walking agent on one set of obstacles and then investigating that policy's performance on a different set).\r\n\r\nI've run one of the example configs with: \r\n\r\n`python3 -m vel.launcher examples-configs/rl/mujoco/ppo/walker_ppo.yaml train`\r\n\r\n\r\nThat all seems to work fine, when I investigate the output, I see that the field labeled \"PMM:episode_rewards\" gets up to 1500-2000 or so:\r\n\r\n![image](https://user-images.githubusercontent.com/9152639/51883695-ea722280-2338-11e9-9444-62ff8ca1e865.png)\r\n\r\n\r\nSo far so good, now I'm trying to load this trained model into pytorch and run it back in the same environment, just to make sure I can. I went through your example scripts, and also looked into your 'infra-baselines' repo for hints. I've also dug through the meat of the codebase while debugging etc. \r\n\r\nI was able to hack together this script, it seems though that the agent performs poorly, I get an average reward of about 4, and the walker is clearly not walking.\r\n\r\n\r\n``` python\r\nimport torch\r\nimport pprint\r\nimport vel\r\nfrom vel.rl.models.policy_gradient_model_separate import PolicyGradientModelSeparateFactory\r\nfrom vel.rl.models.backbone.mlp import MLPFactory\r\nfrom vel.util.random import set_seed\r\nfrom vel.rl.env.mujoco import MujocoEnv\r\n\r\nstate_dict = torch.load('/Users/sgillen/work_dir/output/checkpoints/walker_ppo/0/checkpoint_00000489.data', map_location = 'cpu')\r\nhidden_dict =  torch.load('/Users/sgillen/work_dir/output/checkpoints/walker_ppo/0/checkpoint_hidden_00000489.data', map_location = 'cpu')\r\n\r\n\r\nseed = 1002\r\nset_seed(seed) # Set random seed in python std lib, numpy and pytorch\r\nenv = MujocoEnv('Walker2d-v2').instantiate(seed=seed)\r\n\r\n\r\npolicy_in_size = state_dict['policy_backbone.model.0.weight'].shape[1]\r\nvalue_in_size = state_dict['value_backbone.model.0.weight'].shape[1]\r\n\r\n\r\nmodel_factory = PolicyGradientModelSeparateFactory(\r\n    policy_backbone=MLPFactory(input_length=policy_in_size, hidden_layers=[64, 64], activation='tanh'),\r\n    value_backbone=MLPFactory(input_length=value_in_size, hidden_layers=[64, 64], activation='tanh'),\r\n)\r\n\r\n#sgillen - pretty sure this infers the output size from the action space\r\nmodel = model_factory.instantiate(action_space=env.action_space)\r\nmodel.load_state_dict(state_dict)\r\n\r\nenv.allow_early_resets = True \r\n\r\n\r\nob = env.reset()    \r\nrewards = []\r\nwhile True:\r\n    #action = model.step(torch.Tensor(ob)).detach().numpy()\r\n    action = model.step(torch.Tensor(ob).view(1,-1))['actions'].detach().numpy()\r\n    ob, reward , done, _ =  env.step(action)\r\n    \r\n    rewards.append(reward)\r\n    \r\n    env.render()\r\n    if done:\r\n        print(max(rewards))\r\n        ob = env.reset()\r\n```\r\n\r\n\r\nIt would be very helpful if you had any advice for why this might be happening, I have a feeling I'm misunderstanding something about your codebase, or possibly pytorch itself (I'm relatively new to it). It would also be great if you could tell me if there is a \"right way\" to do this with your code base, and if there is not if there is any interest in me (trying to) build one up.\r\n\r\nThanks very much!","closed_by":{"login":"sgillen","id":9152639,"node_id":"MDQ6VXNlcjkxNTI2Mzk=","avatar_url":"https://avatars.githubusercontent.com/u/9152639?v=4","gravatar_id":"","url":"https://api.github.com/users/sgillen","html_url":"https://github.com/sgillen","followers_url":"https://api.github.com/users/sgillen/followers","following_url":"https://api.github.com/users/sgillen/following{/other_user}","gists_url":"https://api.github.com/users/sgillen/gists{/gist_id}","starred_url":"https://api.github.com/users/sgillen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sgillen/subscriptions","organizations_url":"https://api.github.com/users/sgillen/orgs","repos_url":"https://api.github.com/users/sgillen/repos","events_url":"https://api.github.com/users/sgillen/events{/privacy}","received_events_url":"https://api.github.com/users/sgillen/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/MillionIntegrals/vel/issues/37/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/MillionIntegrals/vel/issues/37/timeline","performed_via_github_app":null,"state_reason":"completed"}