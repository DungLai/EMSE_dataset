{"url":"https://api.github.com/repos/neo-ai/neo-ai-dlr/issues/215","repository_url":"https://api.github.com/repos/neo-ai/neo-ai-dlr","labels_url":"https://api.github.com/repos/neo-ai/neo-ai-dlr/issues/215/labels{/name}","comments_url":"https://api.github.com/repos/neo-ai/neo-ai-dlr/issues/215/comments","events_url":"https://api.github.com/repos/neo-ai/neo-ai-dlr/issues/215/events","html_url":"https://github.com/neo-ai/neo-ai-dlr/issues/215","id":653889318,"node_id":"MDU6SXNzdWU2NTM4ODkzMTg=","number":215,"title":"Error with running DLR on RPi ","user":{"login":"eddywart","id":57341035,"node_id":"MDQ6VXNlcjU3MzQxMDM1","avatar_url":"https://avatars.githubusercontent.com/u/57341035?v=4","gravatar_id":"","url":"https://api.github.com/users/eddywart","html_url":"https://github.com/eddywart","followers_url":"https://api.github.com/users/eddywart/followers","following_url":"https://api.github.com/users/eddywart/following{/other_user}","gists_url":"https://api.github.com/users/eddywart/gists{/gist_id}","starred_url":"https://api.github.com/users/eddywart/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eddywart/subscriptions","organizations_url":"https://api.github.com/users/eddywart/orgs","repos_url":"https://api.github.com/users/eddywart/repos","events_url":"https://api.github.com/users/eddywart/events{/privacy}","received_events_url":"https://api.github.com/users/eddywart/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-07-09T08:56:05Z","updated_at":"2020-07-29T16:47:00Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I am trying to perform machine learning on the edge using a sagemaker neo model as an AWS greengrass deployment package, as per the tutorial here: https://docs.aws.amazon.com/greengrass/latest/developerguide/ml-dlc-console.html\r\n\r\nI installed the DLR package for raspberry pi model 3b+ using the pre-built wheel here: https://neo-ai-dlr.readthedocs.io/en/latest/install.html\r\n\r\nWhile running the following set of code, it seems that the inference is successful (test-dlr.log), but the following error occurs: **/home/pi/neo-ai-dlr/src/dlr_tvm.cc:71: No metadata found**\r\n\r\n```\r\n#!/usr/bin/env python\r\nimport os\r\nfrom dlr import DLRModel\r\nimport numpy as np\r\nimport time\r\nimport logging\r\n\r\nlogging.basicConfig(filename='test-dlr.log', level=logging.DEBUG)\r\n\r\ncurrent_milli_time = lambda: int(round(time.time() * 1000))\r\n\r\ndef run_inference():\r\n    model_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'models/resnet50')\r\n    device = 'cpu'\r\n    model = DLRModel(model_path, device)\r\n\r\n    synset_path = os.path.join(model_path, 'synset.txt')\r\n    with open(synset_path, 'r') as f:\r\n        synset = eval(f.read())\r\n\r\n    image = np.load(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'dog.npy')).astype(np.float32)\r\n    input_data = {'data': image}\r\n\r\n    for rep in range(4):\r\n        t1 = current_milli_time()\r\n        out = model.run(input_data)\r\n        t2 = current_milli_time()\r\n\r\n        logging.debug('done m.run(), time (ms): {}'.format(t2 - t1))\r\n\r\n        top1 = np.argmax(out[0])\r\n        logging.debug('Inference result: {}, {}'.format(top1, synset[top1]))\r\n    \r\n    import resource\r\n    logging.debug(\"peak memory usage (bytes on OS X, kilobytes on Linux) {}\".format(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss))\r\n\r\n    return {\r\n        'synset_id': top1,\r\n        'prediction': synset[top1],\r\n        'time': t2 - t1\r\n    }\r\n\r\nif __name__ == '__main__':\r\n    res = run_inference()\r\n    cls_id = res['synset_id']\r\n    exp_cls_id = 151\r\n    assert cls_id == exp_cls_id, \"Inference result class id {} is incorrect, expected class id is {}\".format(cls_id, exp_cls_id)\r\n    print(\"All tests PASSED!\")\r\n```\r\n[test-dlr.log](https://github.com/neo-ai/neo-ai-dlr/files/4895643/test-dlr.log)\r\n\r\nAfter deployment on a Lambda function through AWS greengrass, the same error is observed in the log file, but the inference did not successfully run (optimizedImageClassification.log). \r\n\r\n[optimizedImageClassification.log](https://github.com/neo-ai/neo-ai-dlr/files/4895609/optimizedImageClassification.log)\r\n\r\nWhat can I do to resolve this error?\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/neo-ai/neo-ai-dlr/issues/215/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/neo-ai/neo-ai-dlr/issues/215/timeline","performed_via_github_app":null,"state_reason":null}