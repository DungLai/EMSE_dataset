{"url":"https://api.github.com/repos/neo-ai/neo-ai-dlr/issues/331","repository_url":"https://api.github.com/repos/neo-ai/neo-ai-dlr","labels_url":"https://api.github.com/repos/neo-ai/neo-ai-dlr/issues/331/labels{/name}","comments_url":"https://api.github.com/repos/neo-ai/neo-ai-dlr/issues/331/comments","events_url":"https://api.github.com/repos/neo-ai/neo-ai-dlr/issues/331/events","html_url":"https://github.com/neo-ai/neo-ai-dlr/issues/331","id":817502940,"node_id":"MDU6SXNzdWU4MTc1MDI5NDA=","number":331,"title":"CudaLaunchError : CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES","user":{"login":"nwils","id":65023541,"node_id":"MDQ6VXNlcjY1MDIzNTQx","avatar_url":"https://avatars.githubusercontent.com/u/65023541?v=4","gravatar_id":"","url":"https://api.github.com/users/nwils","html_url":"https://github.com/nwils","followers_url":"https://api.github.com/users/nwils/followers","following_url":"https://api.github.com/users/nwils/following{/other_user}","gists_url":"https://api.github.com/users/nwils/gists{/gist_id}","starred_url":"https://api.github.com/users/nwils/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nwils/subscriptions","organizations_url":"https://api.github.com/users/nwils/orgs","repos_url":"https://api.github.com/users/nwils/repos","events_url":"https://api.github.com/users/nwils/events{/privacy}","received_events_url":"https://api.github.com/users/nwils/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-02-26T16:41:35Z","updated_at":"2021-03-02T10:19:55Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\n\r\nI am trying to run the latest sagemaker neo compiled model on Jetson Nano. My compilation parameters are \r\n**os - linux\r\naccelerator - nvidia\r\narch - arm64\r\ncompiler options - {\"cuda-ver\": \"10.0\", \"trt-ver\": \"6.0.1\", \"gpu-code\": \"sm_53\"}\r\n**\r\nneo-ai-dlr release version -1.7\r\nThe board has jetpack4.3. My input model is an MXNet ssd mobilenet model. I am using the libdlr.so module in the compiled model.\r\nBut it produces the cuda out of resources error.\r\n\r\n```\r\nFile` \"/usr/local/lib/python3.8/site-packages/dlr/dlr_model.py\", line 451, in run \r\n    self._run() \r\n  File \"/usr/local/lib/python3.8/site-packages/dlr/dlr_model.py\", line 333, in _run \r\n    self._check_call(self._lib.RunDLRModel(byref(self.handle))) \r\n  File \"/usr/local/lib/python3.8/site-packages/dlr/dlr_model.py\", line 160, in _check_call \r\n    raise DLRError(self._lib.DLRGetLastError().decode('ascii')) \r\ndlr.dlr_model.DLRError: TVMError:  \r\n--------------------------------------------------------------- \r\nAn internal invariant was violated during the execution of TVM. \r\nPlease read TVM's error reporting guidelines. \r\nMore details can be found here: https://discuss.tvm.ai/t/error-reporting/7793. \r\n--------------------------------------------------------------- \r\n \r\n  Check failed: ret == 0 (-1 vs. 0) : TVMError: CUDALaunch Error: CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES \r\n grid=(1,1,1),  block=(1024,1,1) \r\n// func_name=fused_vision_non_max_suppression_kernel2 \r\n// CUDA Source \r\n// ----------- \r\n// \r\n// Generated by NVIDIA NVVM Compiler \r\n// \r\n// Compiler Build ID: CL-24817639 \r\n// Cuda compilation tools, release 10.0, V10.0.130 \r\n// Based on LLVM 3.4svn \r\n// \r\n \r\n.version 6.3 \r\n.target sm_53 \r\n.address_size 64 \r\n \r\n // .globl fused_vision_get_valid_counts_kernel1 \r\n \r\n.visible .entry fused_vision_get_valid_counts_kernel1( \r\n .param .u64 fused_vision_get_valid_counts_kernel1_param_0, \r\n .param .u64 fused_vision_get_valid_counts_kernel1_param_1, \r\n .param .u64 fused_vision_get_valid_counts_kernel1_param_2 \r\n) \r\n{ \r\n .reg .pred  %p<2>; \r\n .reg .b32  %r<6>; \r\n .reg .b64  %rd<12>; \r\n \r\n \r\n ld.param.u64  %rd1, [fused_vision_get_valid_counts_kernel1_param_0]; \r\n ld.param.u64  %rd2, [fused_vision_get_valid_counts_kernel1_param_1]; \r\n ld.param.u64  %rd3, [fused_vision_get_valid_counts_kernel1_param_2]; \r\n mov.u32  %r1, %tid.x; \r\n setp.gt.s32 %p1, %r1, 0; \r\n @%p1 bra  BB0_2; \r\n \r\n cvta.to.global.u64  %rd4, %rd2; \r\n mul.lo.s32  %r2, %r1, 12264; \r\n mul.wide.s32  %rd5, %r2, 4; \r\n add.s64  %rd6, %rd4, %rd5; \r\n cvta.to.global.u64  %rd7, %rd3; \r\n add.s64  %rd8, %rd7, %rd5; \r\n ld.global.nc.u32  %r3, [%rd8+49052]; \r\n ld.global.nc.u32  %r4, [%rd6+49052]; \r\n add.s32  %r5, %r3, %r4; \r\n cvta.to.global.u64  %rd9, %rd1; \r\n mul.wide.s32  %rd10, %r1, 4; \r\n add.s64  %rd11, %rd9, %rd10; \r\n st.global.u32  [%rd11], %r5; \r\n \r\nBB0_2: \r\n ret; \r\n} \r\n \r\n // .globl fused_vision_non_max_suppression_kernel3 \r\n.visible .entry fused_vision_non_max_suppression_kernel3( \r\n .param .u64 fused_vision_non_max_suppression_kernel3_param_0, \r\n .param .u64 fused_vision_non_max_suppression_kernel3_param_1, \r\n .param .u64 fused_vision_non_max_suppression_kernel3_param_2, \r\n .param .u64 fused_vision_non_max_suppression_kernel3_param_3 \r\n) \r\n{ \r\n .reg .pred  %p<2>; \r\n .reg .f32  %f<7>; \r\n .reg .b32  %r<10>; \r\n .reg .b64  %rd<16>; \r\n \r\n \r\n ld.param.u64  %rd1, [fused_vision_non_max_suppression_kernel3_param_0]; \r\n ld.param.u64  %rd2, [fused_vision_non_max_suppression_kernel3_param_1]; \r\n ld.param.u64  %rd3, [fused_vision_non_max_suppression_kernel3_param_2]; \r\n ld.param.u64  %rd4, [fused_vision_non_max_suppression_kernel3_param_3]; \r\n mov.u32  %r1, %ctaid.x; \r\n shl.b32  %r4, %r1, 10; \r\n mov.u32  %r2, %tid.x; \r\n add.s32  %r3, %r4, %r2; \r\n setp.gt.s32 %p1, %r3, 12263; \r\n @%p1 bra  BB1_2; \r\n \r\n cvta.to.global.u64  %rd5, %rd1; \r\n cvta.to.global.u64  %rd6, %rd2; \r\n cvta.to.global.u64  %rd7, %rd3; \r\n shl.b32  %r5, %r2, 2; \r\n shl.b32  %r6, %r1, 12; \r\n add.s32  %r7, %r5, %r6; \r\n mul.wide.s32  %rd8, %r7, 4; \r\n add.s64  %rd9, %rd6, %rd8; \r\n ld.global.nc.f32  %f1, [%rd9]; \r\n mul.lo.s32  %r8, %r1, 6144; \r\n mad.lo.s32  %r9, %r2, 6, %r8; \r\n mul.wide.s32  %rd10, %r9, 4; \r\n add.s64  %rd11, %rd5, %rd10; \r\n ld.global.nc.f32  %f2, [%rd9+4]; \r\n ld.global.nc.f32  %f3, [%rd9+8]; \r\n ld.global.nc.f32  %f4, [%rd9+12]; \r\n st.global.f32  [%rd11+8], %f1; \r\n st.global.f32  [%rd11+12], %f2; \r\n st.global.f32  [%rd11+16], %f3; \r\n st.global.f32  [%rd11+20], %f4; \r\n mul.wide.s32  %rd12, %r3, 4; \r\n add.s64  %rd13, %rd7, %rd12; \r\n ld.global.nc.f32  %f5, [%rd13]; \r\n st.global.f32  [%rd11+4], %f5; \r\n cvta.to.global.u64  %rd14, %rd4; \r\n add.s64  %rd15, %rd14, %rd12; \r\n ld.global.nc.f32  %f6, [%rd15]; \r\n st.global.f32  [%rd11], %f6; \r\n \r\nBB1_2: \r\n ret; \r\n} \r\n \r\n // .globl fused_vision_get_valid_counts_kernel3 \r\n.visible .entry fused_vision_get_valid_counts_kernel3( \r\n .param .u64 fused_vision_get_valid_counts_kernel3_param_0, \r\n .param .u64 fused_vision_get_valid_counts_kernel3_param_1, \r\n .param .u64 fused_vision_get_valid_counts_kernel3_param_2, \r\n .param .u64 fused_vision_get_valid_counts_kernel3_param_3, \r\n .param .u64 fused_vision_get_valid_counts_kernel3_param_4 \r\n) \r\n{ \r\n .reg .pred  %p<3>; \r\n .reg .f32  %f<7>; \r\n .reg .b32  %r<10>; \r\n .reg .b64  %rd<21>; \r\n \r\n \r\n ld.param.u64  %rd1, [fused_vision_get_valid_counts_kernel3_param_0]; \r\n ld.param.u64  %rd2, [fused_vision_get_valid_counts_kernel3_param_1]; \r\n ld.param.u64  %rd3, [fused_vision_get_valid_counts_kernel3_param_2]; \r\n ld.param.u64  %rd4, [fused_vision_get_valid_counts_kernel3_param_3]; \r\n ld.param.u64  %rd5, [fused_vision_get_valid_counts_kernel3_param_4]; \r\n mov.u32  %r1, %ctaid.x; \r\n shl.b32  %r4, %r1, 10; \r\n mov.u32  %r2, %tid.x; \r\n add.s32  %r3, %r4, %r2; \r\n setp.gt.s32 %p1, %r3, 12263; \r\n @%p1 bra  BB2_3; \r\n \r\n cvta.to.global.u64  %rd6, %rd1; \r\n mul.wide.s32  %rd7, %r3, 4; \r\n add.s64  %rd8, %rd6, %rd7; \r\n ld.global.nc.u32  %r5, [%rd8]; \r\n setp.lt.s32 %p2, %r5, 1; \r\n @%p2 bra  BB2_3; \r\n \r\n cvta.to.global.u64  %rd9, %rd2; \r\n cvta.to.global.u64  %rd10, %rd3; \r\n cvta.to.global.u64  %rd11, %rd5; \r\n cvta.to.global.u64  %rd12, %rd4; \r\n add.s64  %rd14, %rd12, %rd7; \r\n mul.lo.s32  %r6, %r1, 6144; \r\n mad.lo.s32  %r7, %r2, 6, %r6; \r\n ld.global.nc.u32  %r8, [%rd14]; \r\n mul.lo.s32  %r9, %r8, 6; \r\n mul.wide.s32  %rd15, %r7, 4; \r\n add.s64  %rd16, %rd10, %rd15; \r\n ld.global.nc.f32  %f1, [%rd16]; \r\n mul.wide.s32  %rd17, %r9, 4; \r\n add.s64  %rd18, %rd9, %rd17; \r\n ld.global.nc.f32  %f2, [%rd16+4]; \r\n ld.global.nc.f32  %f3, [%rd16+8]; \r\n ld.global.nc.f32  %f4, [%rd16+12]; \r\n ld.global.nc.f32  %f5, [%rd16+16]; \r\n ld.global.nc.f32  %f6, [%rd16+20]; \r\n st.global.f32  [%rd18], %f1; \r\n st.global.f32  [%rd18+4], %f2; \r\n st.global.f32  [%rd18+8], %f3; \r\n st.global.f32  [%rd18+12], %f4; \r\n st.global.f32  [%rd18+16], %f5; \r\n st.global.f32  [%rd18+20], %f6; \r\n mul.wide.s32  %rd19, %r8, 4; \r\n add.s64  %rd20, %rd11, %rd19; \r\n st.global.u32  [%rd20], %r3; \r\n \r\nBB2_3: \r\n ret; \r\n} \r\n \r\n // .globl fused_vision_non_max_suppression_kernel1 \r\n.visible .entry fused_vision_non_max_suppression_kernel1( \r\n .param .u64 fused_vision_non_max_suppression_kernel1_param_0, \r\n .param .u64 fused_vision_non_max_suppression_kernel1_param_1, \r\n .pa\r\n```\r\n\r\nI could run the models compiled with neo-ai release 1.7 or earlier. I tried to update the neo-ai-dlr runtime version but the error exists. How can run the new sagemaker neo compiled models? Should I change the compiler_options parameters? \r\nAlso it would be great, if you could mention the regions that use neo-ai release 1.7.\r\n\r\nThank you in advance.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/neo-ai/neo-ai-dlr/issues/331/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/neo-ai/neo-ai-dlr/issues/331/timeline","performed_via_github_app":null,"state_reason":null}