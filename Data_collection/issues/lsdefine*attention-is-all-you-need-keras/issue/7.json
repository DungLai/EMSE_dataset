{"url":"https://api.github.com/repos/lsdefine/attention-is-all-you-need-keras/issues/7","repository_url":"https://api.github.com/repos/lsdefine/attention-is-all-you-need-keras","labels_url":"https://api.github.com/repos/lsdefine/attention-is-all-you-need-keras/issues/7/labels{/name}","comments_url":"https://api.github.com/repos/lsdefine/attention-is-all-you-need-keras/issues/7/comments","events_url":"https://api.github.com/repos/lsdefine/attention-is-all-you-need-keras/issues/7/events","html_url":"https://github.com/lsdefine/attention-is-all-you-need-keras/issues/7","id":352850206,"node_id":"MDU6SXNzdWUzNTI4NTAyMDY=","number":7,"title":"pure language model","user":{"login":"XiaoLiuAI","id":1553482,"node_id":"MDQ6VXNlcjE1NTM0ODI=","avatar_url":"https://avatars.githubusercontent.com/u/1553482?v=4","gravatar_id":"","url":"https://api.github.com/users/XiaoLiuAI","html_url":"https://github.com/XiaoLiuAI","followers_url":"https://api.github.com/users/XiaoLiuAI/followers","following_url":"https://api.github.com/users/XiaoLiuAI/following{/other_user}","gists_url":"https://api.github.com/users/XiaoLiuAI/gists{/gist_id}","starred_url":"https://api.github.com/users/XiaoLiuAI/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/XiaoLiuAI/subscriptions","organizations_url":"https://api.github.com/users/XiaoLiuAI/orgs","repos_url":"https://api.github.com/users/XiaoLiuAI/repos","events_url":"https://api.github.com/users/XiaoLiuAI/events{/privacy}","received_events_url":"https://api.github.com/users/XiaoLiuAI/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2018-08-22T08:23:08Z","updated_at":"2018-08-22T09:03:50Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hello, inspired by openai/finetune-transformer-lm, I am now trying to make a language model based on your code. I got a question during implementation. \r\n```\r\nself.model = Model([src_seq_input, tgt_seq_input], loss)\r\nself.model.add_loss([loss])\r\nself.model.compile(optimizer, None)\r\n```\r\nWhy don't you add the loss function through `compile` api? I am not quite sure about the effect of api `add_loss`. \r\n\r\nBy the way, I made a language model encoder based on your Encoder, but I added `GetSubMask` as you did in Decoder. Then I would like to add a crf layer after the encoder (for sequence labelling, while openAi's model is for text classification). Finally, train the model based on the language model loss + crf loss. Do you have any implementation suggestion?  Especially any idea for verifying the correctness of the code... \r\n\r\nI saw you example data about pinyin and Chinese, are you Chinese? \r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/lsdefine/attention-is-all-you-need-keras/issues/7/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/lsdefine/attention-is-all-you-need-keras/issues/7/timeline","performed_via_github_app":null,"state_reason":null}