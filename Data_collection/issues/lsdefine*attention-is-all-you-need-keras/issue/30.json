{"url":"https://api.github.com/repos/lsdefine/attention-is-all-you-need-keras/issues/30","repository_url":"https://api.github.com/repos/lsdefine/attention-is-all-you-need-keras","labels_url":"https://api.github.com/repos/lsdefine/attention-is-all-you-need-keras/issues/30/labels{/name}","comments_url":"https://api.github.com/repos/lsdefine/attention-is-all-you-need-keras/issues/30/comments","events_url":"https://api.github.com/repos/lsdefine/attention-is-all-you-need-keras/issues/30/events","html_url":"https://github.com/lsdefine/attention-is-all-you-need-keras/issues/30","id":528008358,"node_id":"MDU6SXNzdWU1MjgwMDgzNTg=","number":30,"title":"Using the approach for video encoding.","user":{"login":"kristosh","id":24369160,"node_id":"MDQ6VXNlcjI0MzY5MTYw","avatar_url":"https://avatars.githubusercontent.com/u/24369160?v=4","gravatar_id":"","url":"https://api.github.com/users/kristosh","html_url":"https://github.com/kristosh","followers_url":"https://api.github.com/users/kristosh/followers","following_url":"https://api.github.com/users/kristosh/following{/other_user}","gists_url":"https://api.github.com/users/kristosh/gists{/gist_id}","starred_url":"https://api.github.com/users/kristosh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kristosh/subscriptions","organizations_url":"https://api.github.com/users/kristosh/orgs","repos_url":"https://api.github.com/users/kristosh/repos","events_url":"https://api.github.com/users/kristosh/events{/privacy}","received_events_url":"https://api.github.com/users/kristosh/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2019-11-25T10:58:16Z","updated_at":"2019-11-25T10:58:16Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I am trying to implement and test the approach for video encoding. I would like to have as input to the system sets of image frames from videos and just encode them using only the encoding part. Therefore, I am trying to comment out the decoder part and I am trying to figure out what modifications should I perform to make it work. I am a bit puzzled with the line 30 and 34 in pinyin_main.py:\r\n\r\n`gen = dd.S2SDataGenerator('data/pinyin.corpus.txt', itokens, otokens, batch_size=32, max_len=120)\r\ns2s.model.fit_generator(gen, steps_per_epoch=2000, epochs=5, callbacks=[lr_scheduler, model_saver])`\r\n\r\nCould I replace the gen object with a tensor easily? What exactly gen stands for?\r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/lsdefine/attention-is-all-you-need-keras/issues/30/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/lsdefine/attention-is-all-you-need-keras/issues/30/timeline","performed_via_github_app":null,"state_reason":null}