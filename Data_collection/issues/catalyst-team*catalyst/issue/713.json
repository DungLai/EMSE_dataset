{"url":"https://api.github.com/repos/catalyst-team/catalyst/issues/713","repository_url":"https://api.github.com/repos/catalyst-team/catalyst","labels_url":"https://api.github.com/repos/catalyst-team/catalyst/issues/713/labels{/name}","comments_url":"https://api.github.com/repos/catalyst-team/catalyst/issues/713/comments","events_url":"https://api.github.com/repos/catalyst-team/catalyst/issues/713/events","html_url":"https://github.com/catalyst-team/catalyst/issues/713","id":584401786,"node_id":"MDU6SXNzdWU1ODQ0MDE3ODY=","number":713,"title":"Freezing after training ends, Catalyst 20.03+ version","user":{"login":"litvinich","id":37345721,"node_id":"MDQ6VXNlcjM3MzQ1NzIx","avatar_url":"https://avatars.githubusercontent.com/u/37345721?v=4","gravatar_id":"","url":"https://api.github.com/users/litvinich","html_url":"https://github.com/litvinich","followers_url":"https://api.github.com/users/litvinich/followers","following_url":"https://api.github.com/users/litvinich/following{/other_user}","gists_url":"https://api.github.com/users/litvinich/gists{/gist_id}","starred_url":"https://api.github.com/users/litvinich/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/litvinich/subscriptions","organizations_url":"https://api.github.com/users/litvinich/orgs","repos_url":"https://api.github.com/users/litvinich/repos","events_url":"https://api.github.com/users/litvinich/events{/privacy}","received_events_url":"https://api.github.com/users/litvinich/received_events","type":"User","site_admin":false},"labels":[{"id":1029400270,"node_id":"MDU6TGFiZWwxMDI5NDAwMjcw","url":"https://api.github.com/repos/catalyst-team/catalyst/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2020-03-19T13:12:22Z","updated_at":"2020-04-22T12:49:30Z","closed_at":"2020-04-22T12:49:30Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the bug**\r\nAfter training end I see next picture forever:\r\n```\r\nTop best models:\r\nlogs/4classes/version3_noleak_simpleface_effb0_cosine_ls_e01/112_really_hard_augs/200319.130339.SEybo2/checkpoints/stage1.1.pth  0.6985\r\n```\r\nIt just freezes. This happened with my pipeline after upgrading 20.02 -> 20.03.\r\n\r\n**To Reproduce**\r\nI have 3 GPU server with NVIDIA 1080Ti and Threadripper, if needed I can give detailed hardware. Training is in DataParallel mode, not DDP. \r\nMy config:\r\n```\r\nmodel_params:\r\n  model: MixFace\r\n  encoder_name: efficientnet_b0\r\n  encoder_pretrained: True\r\n  encoder_library: timm\r\n  neck_transform: linear\r\n  embeddings_size: 512\r\n  classes: 4\r\n  head_s: 12\r\n  head_m1: 0.2\r\n  head_m2: 0\r\n\r\n\r\nrunner_params:\r\n  input_key: [\"x\", \"labels\"]\r\n\r\n\r\nargs:\r\n  expdir: \"./experiments/4classes\"\r\n  baselogdir: \"./logs/4classes/version3_mixface_s12_effb0_cosine_ls_e01\"\r\n  seed: 8\r\n  deterministic: True\r\n  benchmark: True\r\n\r\n\r\nstages:\r\n\r\n  stage1:\r\n\r\n    data_params:\r\n      batch_size: 170\r\n      num_workers: 12\r\n      per_gpu_scaling: True\r\n      drop_last: False\r\n      shuffle: True\r\n      loaders_params:\r\n        valid:\r\n          batch_size: 170\r\n\r\n      train_dataset_params:\r\n        image_folder_path: \"/usr/local/FileStorage/data_training/glasses_classification/train\"\r\n        image_file_path: \"/usr/local/FileStorage/data_training/glasses_classification/version_3/train.txt\"\r\n\r\n      valid_dataset_params:\r\n        image_folder_path: \"/usr/local/FileStorage/data_training/glasses_classification/valid\"\r\n        image_file_path: \"/usr/local/FileStorage/data_training/glasses_classification/version_3/valid.txt\"\r\n\r\n\r\n    state_params:\r\n      num_epochs: 70\r\n      main_metric: &main_metric f1\r\n      minimize_metric: False\r\n      valid_loader: valid\r\n\r\n\r\n    criterion_params:\r\n      criterion: CrossEntropyLossLabelSmoothing\r\n      reduction: mean\r\n      smooth_eps: 0.1\r\n\r\n\r\n    scheduler_params:\r\n      scheduler: CosineAnnealingWarmRestarts\r\n      T_0: 900\r\n      T_mult: 2\r\n      eta_min: 0\r\n\r\n\r\n    optimizer_params:\r\n      optimizer: SGD\r\n      lr: 0.1\r\n      weight_decay: 0.001\r\n      nesterov: True\r\n      momentum: 0.9\r\n\r\n\r\n    callbacks_params:\r\n      loss:\r\n        callback: CriterionCallback\r\n\r\n      optimizer:\r\n        callback: OptimizerCallback\r\n\r\n      accuracy:\r\n        callback: AccuracyCallback\r\n        accuracy_args: [1, 2]\r\n\r\n      f1_score:\r\n        callback: F1ScoreMetricCallback\r\n        n_classes: 4\r\n        class_mapping: ['face_in_optical_glasses', 'face_in_protective_glasses', 'face_in_sunglasses', 'face_without_glasses']\r\n\r\n\r\n      scheduler:\r\n        callback: SchedulerCallback\r\n        mode: batch\r\n\r\n      logger:\r\n        callback: AlchemyLogger\r\n        token: \"484b162171bce2dc5371f9acc09d9fd2\"\r\n        project: \"glasses_classification\"\r\n        experiment: \"version3_mixface_s12_effb0_cosine_ls_e01\"\r\n        group: \"validation_version_2\"\r\n```\r\n\r\n\r\n**Additional context**\r\nAfter `Ctrl + C` I see next picture:\r\n```\r\nraceback (most recent call last):\r\n  File \"/home/andrii/anaconda3/envs/face/lib/python3.7/threading.py\", line 1273, in _shutdown\r\n    t.join()\r\n  File \"/home/andrii/anaconda3/envs/face/lib/python3.7/threading.py\", line 1032, in join\r\n    self._wait_for_tstate_lock()\r\n  File \"/home/andrii/anaconda3/envs/face/lib/python3.7/threading.py\", line 1048, in _wait_for_tstate_lock\r\n    elif lock.acquire(block, timeout):\r\nKeyboardInterrupt\r\n```\r\nObviously it's problem with multithreading. I can suggest, that threads are not daemons and they have something like forever loop or there are deadlocks\r\n","closed_by":{"login":"Scitator","id":7606451,"node_id":"MDQ6VXNlcjc2MDY0NTE=","avatar_url":"https://avatars.githubusercontent.com/u/7606451?v=4","gravatar_id":"","url":"https://api.github.com/users/Scitator","html_url":"https://github.com/Scitator","followers_url":"https://api.github.com/users/Scitator/followers","following_url":"https://api.github.com/users/Scitator/following{/other_user}","gists_url":"https://api.github.com/users/Scitator/gists{/gist_id}","starred_url":"https://api.github.com/users/Scitator/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Scitator/subscriptions","organizations_url":"https://api.github.com/users/Scitator/orgs","repos_url":"https://api.github.com/users/Scitator/repos","events_url":"https://api.github.com/users/Scitator/events{/privacy}","received_events_url":"https://api.github.com/users/Scitator/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/catalyst-team/catalyst/issues/713/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/catalyst-team/catalyst/issues/713/timeline","performed_via_github_app":null,"state_reason":"completed"}