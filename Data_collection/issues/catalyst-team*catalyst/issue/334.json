{"url":"https://api.github.com/repos/catalyst-team/catalyst/issues/334","repository_url":"https://api.github.com/repos/catalyst-team/catalyst","labels_url":"https://api.github.com/repos/catalyst-team/catalyst/issues/334/labels{/name}","comments_url":"https://api.github.com/repos/catalyst-team/catalyst/issues/334/comments","events_url":"https://api.github.com/repos/catalyst-team/catalyst/issues/334/events","html_url":"https://github.com/catalyst-team/catalyst/issues/334","id":485841638,"node_id":"MDU6SXNzdWU0ODU4NDE2Mzg=","number":334,"title":"classification-tutorial notebook fails with an error on multi-GPU machine","user":{"login":"Felix-neko","id":5650922,"node_id":"MDQ6VXNlcjU2NTA5MjI=","avatar_url":"https://avatars.githubusercontent.com/u/5650922?v=4","gravatar_id":"","url":"https://api.github.com/users/Felix-neko","html_url":"https://github.com/Felix-neko","followers_url":"https://api.github.com/users/Felix-neko/followers","following_url":"https://api.github.com/users/Felix-neko/following{/other_user}","gists_url":"https://api.github.com/users/Felix-neko/gists{/gist_id}","starred_url":"https://api.github.com/users/Felix-neko/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Felix-neko/subscriptions","organizations_url":"https://api.github.com/users/Felix-neko/orgs","repos_url":"https://api.github.com/users/Felix-neko/repos","events_url":"https://api.github.com/users/Felix-neko/events{/privacy}","received_events_url":"https://api.github.com/users/Felix-neko/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2019-08-27T14:21:22Z","updated_at":"2019-09-25T06:05:20Z","closed_at":"2019-09-25T06:05:20Z","author_association":"NONE","active_lock_reason":null,"body":"Hi! I'm trying to run your `classifcation-tutorial` notebook on a multi-gpu node.\r\n\r\nAlas, it fails with the following error message:\r\n\r\n\r\n```\r\n0/10 * Epoch (train):   0% 0/106 [00:00<?, ?it/s]\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-123-bb8ae99f70ba> in <module>\r\n     21     ],\r\n     22     num_epochs=NUM_EPOCHS,\r\n---> 23     verbose=True\r\n     24 )\r\n\r\n/mnt/host_dump/catalyst/catalyst/dl/runner/supervised.py in train(self, model, criterion, optimizer, loaders, logdir, callbacks, scheduler, num_epochs, valid_loader, main_metric, minimize_metric, verbose, state_kwargs, checkpoint_data, fp16, check)\r\n    127             distributed_params=fp16\r\n    128         )\r\n--> 129         self.run_experiment(experiment, check=check)\r\n    130 \r\n    131     def infer(\r\n\r\n/mnt/host_dump/catalyst/catalyst/dl/core/runner.py in run_experiment(self, experiment, check)\r\n    194         except (Exception, KeyboardInterrupt) as ex:\r\n    195             self.state.exception = ex\r\n--> 196             self._run_event(\"exception\")\r\n    197 \r\n    198         return self\r\n\r\n/mnt/host_dump/catalyst/catalyst/dl/core/runner.py in _run_event(self, event)\r\n     94 \r\n     95         if self.state is not None and hasattr(self.state, f\"on_{event}_post\"):\r\n---> 96             getattr(self.state, f\"on_{event}_post\")()\r\n     97 \r\n     98     @abstractmethod\r\n\r\n/mnt/host_dump/catalyst/catalyst/dl/core/state.py in on_exception_post(self)\r\n    170     def on_exception_post(self):\r\n    171         for logger in self.loggers:\r\n--> 172             logger.on_exception(self)\r\n    173 \r\n    174 \r\n\r\n/mnt/host_dump/catalyst/catalyst/dl/callbacks/logging.py in on_exception(self, state)\r\n    187 \r\n    188         if state.need_reraise_exception:\r\n--> 189             raise exception\r\n    190 \r\n    191 \r\n\r\n/mnt/host_dump/catalyst/catalyst/dl/core/runner.py in run_experiment(self, experiment, check)\r\n    191         try:\r\n    192             for stage in self.experiment.stages:\r\n--> 193                 self._run_stage(stage)\r\n    194         except (Exception, KeyboardInterrupt) as ex:\r\n    195             self.state.exception = ex\r\n\r\n/mnt/host_dump/catalyst/catalyst/dl/core/runner.py in _run_stage(self, stage)\r\n    173 \r\n    174             self._run_event(\"epoch_start\")\r\n--> 175             self._run_epoch(loaders)\r\n    176             self._run_event(\"epoch_end\")\r\n    177 \r\n\r\n/mnt/host_dump/catalyst/catalyst/dl/core/runner.py in _run_epoch(self, loaders)\r\n    160             self._run_event(\"loader_start\")\r\n    161             with torch.set_grad_enabled(self.state.need_backward):\r\n--> 162                 self._run_loader(loader)\r\n    163             self._run_event(\"loader_end\")\r\n    164 \r\n\r\n/mnt/host_dump/catalyst/catalyst/dl/core/runner.py in _run_loader(self, loader)\r\n    129 \r\n    130         for i, batch in enumerate(loader):\r\n--> 131             self._run_batch(batch)\r\n    132 \r\n    133             self.state.timer.reset()\r\n\r\n/mnt/host_dump/catalyst/catalyst/dl/core/runner.py in _run_batch(self, batch)\r\n    108         self._run_event(\"batch_start\")\r\n    109         self.state.timer.start(\"_timers/model_time\")\r\n--> 110         self.state.output = self.predict_batch(batch)\r\n    111         self.state.timer.stop(\"_timers/model_time\")\r\n    112         self.state.timer.stop(\"_timers/batch_time\")\r\n\r\n/mnt/host_dump/catalyst/catalyst/dl/runner/supervised.py in predict_batch(self, batch)\r\n     84 \r\n     85     def predict_batch(self, batch: Mapping[str, Any]):\r\n---> 86         output = self._process_input(batch)\r\n     87         output = self._process_output(output)\r\n     88         return output\r\n\r\n/mnt/host_dump/catalyst/catalyst/dl/runner/supervised.py in _process_input_str(self, batch)\r\n     58 \r\n     59     def _process_input_str(self, batch: Mapping[str, Any]):\r\n---> 60         output = self.model(batch[self.input_key])\r\n     61         return output\r\n     62 \r\n\r\n/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    545             result = self._slow_forward(*input, **kwargs)\r\n    546         else:\r\n--> 547             result = self.forward(*input, **kwargs)\r\n    548         for hook in self._forward_hooks.values():\r\n    549             hook_result = hook(self, input, result)\r\n\r\n/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py in forward(self, *inputs, **kwargs)\r\n    150             return self.module(*inputs[0], **kwargs[0])\r\n    151         replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\r\n--> 152         outputs = self.parallel_apply(replicas, inputs, kwargs)\r\n    153         return self.gather(outputs, self.output_device)\r\n    154 \r\n\r\n/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py in parallel_apply(self, replicas, inputs, kwargs)\r\n    160 \r\n    161     def parallel_apply(self, replicas, inputs, kwargs):\r\n--> 162         return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\r\n    163 \r\n    164     def gather(self, outputs, output_device):\r\n\r\n/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/parallel_apply.py in parallel_apply(modules, inputs, kwargs_tup, devices)\r\n     83         output = results[i]\r\n     84         if isinstance(output, ExceptionWrapper):\r\n---> 85             output.reraise()\r\n     86         outputs.append(output)\r\n     87     return outputs\r\n\r\n/usr/local/lib/python3.7/dist-packages/torch/_utils.py in reraise(self)\r\n    367             # (https://bugs.python.org/issue2651), so we work around it.\r\n    368             msg = KeyErrorMessage(msg)\r\n--> 369         raise self.exc_type(msg)\r\n\r\nRuntimeError: Caught RuntimeError in replica 1 on device 1.\r\nOriginal Traceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\r\n    output = module(*input, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 547, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/pretrainedmodels/models/torchvision_models.py\", line 340, in forward\r\n    x = self.features(input)\r\n  File \"/usr/local/lib/python3.7/dist-packages/pretrainedmodels/models/torchvision_models.py\", line 322, in features\r\n    x = self.conv1(input)\r\n  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 547, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 343, in forward\r\n    return self.conv2d_forward(input, self.weight)\r\n  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 340, in conv2d_forward\r\n    self.padding, self.dilation, self.groups)\r\nRuntimeError: Expected tensor for argument #1 'input' to have the same device as tensor for argument #2 'weight'; but device 1 does not equal 0 (while checking arguments for cudnn_convolution)\r\n\r\n```\r\n\r\nHow can I fix it?\r\n\r\nP.S. I've set `os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"`, it had no effect. I've also set I've set `os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\", it gave the same message. `os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" also gave the same message.","closed_by":{"login":"Scitator","id":7606451,"node_id":"MDQ6VXNlcjc2MDY0NTE=","avatar_url":"https://avatars.githubusercontent.com/u/7606451?v=4","gravatar_id":"","url":"https://api.github.com/users/Scitator","html_url":"https://github.com/Scitator","followers_url":"https://api.github.com/users/Scitator/followers","following_url":"https://api.github.com/users/Scitator/following{/other_user}","gists_url":"https://api.github.com/users/Scitator/gists{/gist_id}","starred_url":"https://api.github.com/users/Scitator/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Scitator/subscriptions","organizations_url":"https://api.github.com/users/Scitator/orgs","repos_url":"https://api.github.com/users/Scitator/repos","events_url":"https://api.github.com/users/Scitator/events{/privacy}","received_events_url":"https://api.github.com/users/Scitator/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/catalyst-team/catalyst/issues/334/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/catalyst-team/catalyst/issues/334/timeline","performed_via_github_app":null,"state_reason":"completed"}