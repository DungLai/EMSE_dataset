{"url":"https://api.github.com/repos/openvinotoolkit/model_server/issues/737","repository_url":"https://api.github.com/repos/openvinotoolkit/model_server","labels_url":"https://api.github.com/repos/openvinotoolkit/model_server/issues/737/labels{/name}","comments_url":"https://api.github.com/repos/openvinotoolkit/model_server/issues/737/comments","events_url":"https://api.github.com/repos/openvinotoolkit/model_server/issues/737/events","html_url":"https://github.com/openvinotoolkit/model_server/issues/737","id":931919975,"node_id":"MDU6SXNzdWU5MzE5MTk5NzU=","number":737,"title":"Custom pipeline broken when batch size greater than 1","user":{"login":"carlosmonteirobefore","id":78358826,"node_id":"MDQ6VXNlcjc4MzU4ODI2","avatar_url":"https://avatars.githubusercontent.com/u/78358826?v=4","gravatar_id":"","url":"https://api.github.com/users/carlosmonteirobefore","html_url":"https://github.com/carlosmonteirobefore","followers_url":"https://api.github.com/users/carlosmonteirobefore/followers","following_url":"https://api.github.com/users/carlosmonteirobefore/following{/other_user}","gists_url":"https://api.github.com/users/carlosmonteirobefore/gists{/gist_id}","starred_url":"https://api.github.com/users/carlosmonteirobefore/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/carlosmonteirobefore/subscriptions","organizations_url":"https://api.github.com/users/carlosmonteirobefore/orgs","repos_url":"https://api.github.com/users/carlosmonteirobefore/repos","events_url":"https://api.github.com/users/carlosmonteirobefore/events{/privacy}","received_events_url":"https://api.github.com/users/carlosmonteirobefore/received_events","type":"User","site_admin":false},"labels":[{"id":1070321717,"node_id":"MDU6TGFiZWwxMDcwMzIxNzE3","url":"https://api.github.com/repos/openvinotoolkit/model_server/labels/help%20wanted","name":"help wanted","color":"008672","default":true,"description":"Extra attention is needed"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":8,"created_at":"2021-06-28T19:47:24Z","updated_at":"2021-07-02T13:36:07Z","closed_at":"2021-07-02T13:22:49Z","author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\nI have a custom pipeline break when model_zoo_intel_object_detection crop two or more images to landmarks_regression_retail_0009, does anyone have ideas to solve this problem? I\r\n tried modify batch_size in model config but haven't get anywhere. \r\nthis is the custom_config.json\r\n\r\n<details><summary>My Custom JSON</summary>\r\n\r\n```JSON\r\n{\r\n    \"model_config_list\": [\r\n        {\r\n            \"config\": {\r\n                \"name\": \"face_detection_model\",\r\n                \"base_path\": \"/models/face-detection\"\r\n            }\r\n        },\r\n        {\r\n            \"config\": {\r\n                \"name\": \"face_recognition_model\",\r\n                \"base_path\": \"/models/face-reidentification\"\r\n            }\r\n        },\r\n        {\r\n            \"config\": {\r\n                \"name\": \"face_landmarks_model\",\r\n                \"base_path\": \"/models/landmarks\"\r\n            }\r\n        },\r\n        {\r\n            \"config\": {\r\n                \"name\": \"person_detection_model\",\r\n                \"base_path\": \"/models/person-detection\"\r\n            }\r\n        },\r\n        {\r\n            \"config\": {\r\n                \"name\": \"emotions_recognition_model\",\r\n                \"base_path\": \"/models/emotions\"\r\n            }\r\n        },\r\n        {\r\n            \"config\": {\r\n                \"name\": \"age_gender_recognition_model\",\r\n                \"base_path\": \"/models/age-gender\",\r\n                \"shape\" : \"(1,3,64,64)\"\r\n            }\r\n        }\r\n    ],\r\n\r\n    \"custom_node_library_config_list\": [\r\n        {\"name\": \"image_transformation_custom\",\r\n            \"base_path\": \"/ovms/lib/libcustom_node_image_transformation.so\"},\r\n        {\"name\": \"object_detection_image_extractor_custom\",\r\n            \"base_path\": \"/ovms/lib/libcustom_node_model_zoo_intel_object_detection.so\"}\r\n    ],\r\n    \r\n    \"pipeline_config_list\": [\r\n        {\r\n            \"name\": \"face_recognition_pipeline\",\r\n            \"inputs\": [\"image\"],\r\n            \r\n            \"nodes\":[\r\n                {\r\n                    \"name\": \"face_detection_node\",\r\n                    \"model_name\": \"face_detection_model\",\r\n                    \"type\": \"DL model\",\r\n                    \"inputs\": [\r\n                        {\"image\": {\r\n                            \"node_name\": \"request\",\r\n                            \"data_item\": \"image\"}}],\r\n                    \"outputs\": [\r\n                        {\"data_item\": \"detection_out\",\r\n                            \"alias\": \"face_rois_out\"}]\r\n                },\r\n                  \r\n                {\r\n                    \"name\": \"extract_node\",\r\n                    \"library_name\": \"object_detection_image_extractor_custom\",\r\n                    \"type\": \"custom\",\r\n                    \"params\": {\r\n                        \"original_image_width\": \"256\",\r\n                        \"original_image_height\": \"256\",\r\n                        \"target_image_width\": \"48\",\r\n                        \"target_image_height\": \"48\",\r\n                        \"convert_to_gray_scale\": \"false\",\r\n                        \"max_output_batch\": \"1\",\r\n                        \"confidence_threshold\": \"0.7\",\r\n                        \"debug\": \"true\"\r\n                    },\r\n                    \"inputs\": [\r\n                        {\"image\": {\r\n                                \"node_name\": \"request\",\r\n                                \"data_item\": \"image\"}},\r\n                        {\"detection\": {\r\n                                \"node_name\": \"face_detection_node\",\r\n                                \"data_item\": \"face_rois_out\"}}],\r\n                    \"outputs\": [\r\n                        {\"data_item\": \"images\",\r\n                            \"alias\": \"face_image_out\"},\r\n                        {\"data_item\": \"coordinates\",\r\n                            \"alias\": \"face_coordinates_out\"},\r\n                        {\"data_item\": \"confidences\",\r\n                            \"alias\": \"confidence_levels_out\"}]\r\n                },\r\n                \r\n                \r\n                {\r\n                    \"name\": \"face_landmark_node\",\r\n                    \"model_name\": \"face_landmarks_model\",\r\n                    \"type\": \"DL model\",\r\n                    \"inputs\": [\r\n                        {\"0\": {\r\n                                \"node_name\": \"extract_node\",\r\n                                \"data_item\": \"face_image_out\"}}],\r\n                    \"outputs\": [\r\n                        {\"data_item\": \"95\",\r\n                            \"alias\": \"face_landmarks_out\"}]\r\n                },\r\n\r\n                {\r\n                    \"name\": \"image_transformation_node\",\r\n                    \"library_name\": \"image_transformation_custom\",\r\n                    \"type\": \"custom\",\r\n                    \"params\": {\r\n                        \"make_transform\": \"true\",\r\n\r\n                        \"target_image_width\": \"128\",\r\n                        \"target_image_height\": \"128\",\r\n\r\n                        \"original_image_color_order\": \"BGR\",\r\n                        \"target_image_color_order\": \"BGR\",\r\n\r\n                        \"original_image_layout\": \"CHW\",\r\n                        \"target_image_layout\": \"CHW\",\r\n\r\n                        \"debug\": \"true\"\r\n\r\n                    },\r\n                    \"inputs\": [\r\n                        {\"image\": {\r\n                                \"node_name\": \"extract_node\",\r\n                                \"data_item\": \"face_image_out\"}},\r\n                        {\"landmarks\": {\r\n                                \"node_name\": \"face_landmark_node\",\r\n                                \"data_item\": \"face_landmarks_out\"}}],\r\n                    \"outputs\": [\r\n                        {\"data_item\": \"image\",\r\n                            \"alias\": \"transformed_image_out\"}]\r\n                },\r\n                \r\n                \r\n                {\r\n                    \"name\": \"face_embedding_node\",\r\n                    \"model_name\": \"face_recognition_model\",\r\n                    \"type\": \"DL model\",\r\n                    \"inputs\": [\r\n                        {\"0\": {\r\n                            \"node_name\": \"image_transformation_node\",\r\n                            \"data_item\": \"transformed_image_out\"}}],\r\n                    \"outputs\": [\r\n                        {\"data_item\": \"658/add_\",\r\n                        \"alias\": \"embeddings_out\"}]\r\n                }\r\n            \r\n            \r\n            ],\r\n            \"outputs\": [\r\n                {\"embeddings\": {\r\n                        \"node_name\": \"face_embedding_node\",\r\n                        \"data_item\": \"embeddings_out\"}},\r\n\r\n                {\"face_landmarks\": {\r\n                        \"node_name\": \"face_landmark_node\",\r\n                        \"data_item\": \"face_landmarks_out\"}},\r\n\r\n                {\"transformed_image\": {\r\n                        \"node_name\": \"image_transformation_node\",\r\n                        \"data_item\": \"transformed_image_out\"}},\r\n\r\n                {\"face_crop\": {\r\n                        \"node_name\": \"face_detection_node\",\r\n                        \"data_item\": \"face_rois_out\"}},\r\n                \r\n                {\"face_image\": {\r\n                    \"node_name\": \"extract_node\",\r\n                    \"data_item\": \"face_image_out\"}},\r\n\r\n                {\"face_coordinates\": {\r\n                    \"node_name\": \"extract_node\",\r\n                    \"data_item\": \"face_coordinates_out\"}},\r\n\r\n                {\"confidence_levels\": {\r\n                    \"node_name\": \"extract_node\",\r\n                    \"data_item\": \"confidence_levels_out\"}}\r\n            ]\r\n        }\r\n    ]\r\n}\r\n```\r\n\r\n</details>","closed_by":{"login":"carlosmonteirobefore","id":78358826,"node_id":"MDQ6VXNlcjc4MzU4ODI2","avatar_url":"https://avatars.githubusercontent.com/u/78358826?v=4","gravatar_id":"","url":"https://api.github.com/users/carlosmonteirobefore","html_url":"https://github.com/carlosmonteirobefore","followers_url":"https://api.github.com/users/carlosmonteirobefore/followers","following_url":"https://api.github.com/users/carlosmonteirobefore/following{/other_user}","gists_url":"https://api.github.com/users/carlosmonteirobefore/gists{/gist_id}","starred_url":"https://api.github.com/users/carlosmonteirobefore/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/carlosmonteirobefore/subscriptions","organizations_url":"https://api.github.com/users/carlosmonteirobefore/orgs","repos_url":"https://api.github.com/users/carlosmonteirobefore/repos","events_url":"https://api.github.com/users/carlosmonteirobefore/events{/privacy}","received_events_url":"https://api.github.com/users/carlosmonteirobefore/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/openvinotoolkit/model_server/issues/737/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/openvinotoolkit/model_server/issues/737/timeline","performed_via_github_app":null,"state_reason":"completed"}