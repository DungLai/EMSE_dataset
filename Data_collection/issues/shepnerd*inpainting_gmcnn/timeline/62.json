[{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/679867224","html_url":"https://github.com/shepnerd/inpainting_gmcnn/issues/62#issuecomment-679867224","issue_url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/62","id":679867224,"node_id":"MDEyOklzc3VlQ29tbWVudDY3OTg2NzIyNA==","user":{"login":"shepnerd","id":5066504,"node_id":"MDQ6VXNlcjUwNjY1MDQ=","avatar_url":"https://avatars.githubusercontent.com/u/5066504?v=4","gravatar_id":"","url":"https://api.github.com/users/shepnerd","html_url":"https://github.com/shepnerd","followers_url":"https://api.github.com/users/shepnerd/followers","following_url":"https://api.github.com/users/shepnerd/following{/other_user}","gists_url":"https://api.github.com/users/shepnerd/gists{/gist_id}","starred_url":"https://api.github.com/users/shepnerd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shepnerd/subscriptions","organizations_url":"https://api.github.com/users/shepnerd/orgs","repos_url":"https://api.github.com/users/shepnerd/repos","events_url":"https://api.github.com/users/shepnerd/events{/privacy}","received_events_url":"https://api.github.com/users/shepnerd/received_events","type":"User","site_admin":false},"created_at":"2020-08-25T07:55:27Z","updated_at":"2020-08-25T07:55:46Z","author_association":"OWNER","body":"Using the absolute paths of the target images, e.g., /data/proj/a.png or D:\\\\\\proj\\\\\\a.png. And yes, one line for one file path in the data file. The file extension name does not matter as long as it is readable text for IO functions.","reactions":{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/679867224/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"shepnerd","id":5066504,"node_id":"MDQ6VXNlcjUwNjY1MDQ=","avatar_url":"https://avatars.githubusercontent.com/u/5066504?v=4","gravatar_id":"","url":"https://api.github.com/users/shepnerd","html_url":"https://github.com/shepnerd","followers_url":"https://api.github.com/users/shepnerd/followers","following_url":"https://api.github.com/users/shepnerd/following{/other_user}","gists_url":"https://api.github.com/users/shepnerd/gists{/gist_id}","starred_url":"https://api.github.com/users/shepnerd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shepnerd/subscriptions","organizations_url":"https://api.github.com/users/shepnerd/orgs","repos_url":"https://api.github.com/users/shepnerd/repos","events_url":"https://api.github.com/users/shepnerd/events{/privacy}","received_events_url":"https://api.github.com/users/shepnerd/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/680044045","html_url":"https://github.com/shepnerd/inpainting_gmcnn/issues/62#issuecomment-680044045","issue_url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/62","id":680044045,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDA0NDA0NQ==","user":{"login":"qwerdbeta","id":36677267,"node_id":"MDQ6VXNlcjM2Njc3MjY3","avatar_url":"https://avatars.githubusercontent.com/u/36677267?v=4","gravatar_id":"","url":"https://api.github.com/users/qwerdbeta","html_url":"https://github.com/qwerdbeta","followers_url":"https://api.github.com/users/qwerdbeta/followers","following_url":"https://api.github.com/users/qwerdbeta/following{/other_user}","gists_url":"https://api.github.com/users/qwerdbeta/gists{/gist_id}","starred_url":"https://api.github.com/users/qwerdbeta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qwerdbeta/subscriptions","organizations_url":"https://api.github.com/users/qwerdbeta/orgs","repos_url":"https://api.github.com/users/qwerdbeta/repos","events_url":"https://api.github.com/users/qwerdbeta/events{/privacy}","received_events_url":"https://api.github.com/users/qwerdbeta/received_events","type":"User","site_admin":false},"created_at":"2020-08-25T14:01:35Z","updated_at":"2020-08-25T14:38:00Z","author_association":"NONE","body":"Thank you! that worked but then I ran into the next issue when trying to train and it's not clear what cauase is. The error stack trace is:\r\n\r\n(inpainting_gmcnn) G:\\pythonAI\\inpainting_gmcnn\\tensorflow>python train.py --dataset celeba --data_file G:\\pythonAI\\training_images\\source_images\\t2.index --pretrain_network 1\r\n------------ Options -------------\r\nae_loss_alpha: 1.2\r\nbatch_size: 24\r\ncheckpoints_dir: ./checkpoints\r\nd_cnum: 64\r\ndata_file: G:\\pythonAI\\training_images\\source_images\\t2.index\r\ndataset: celeba\r\ndataset_path: G:\\pythonAI\\training_images\\source_images\\t2.index\r\ndate_str: 20200825-103721\r\ng_cnum: 32\r\ngan_loss_alpha: 0.001\r\ngpu_ids: ['0', '1']\r\nimg_shapes: [256, 256, 3]\r\nl1_loss_alpha: 1.4\r\nload_model_dir:\r\nlr: 1e-05\r\nmargins: [0, 0]\r\nmask_shapes: [256, 256]\r\nmask_type: rect\r\nmax_delta_shapes: [32, 32]\r\nmax_iters: 1000\r\nmodel_folder: ./checkpoints\\20200825-103721_GMCNN_celeba_b24_s256x256_gc32_dc64_randmask-rect_pretrain\r\nmodel_name: GMCNN\r\nmodel_prefix: snap\r\nmrf_alpha: 0.05\r\npretrain_l1_alpha: 1.2\r\npretrain_network: True\r\nrandom_mask: True\r\nrandom_seed: False\r\ntrain_spe: 1000\r\nvgg19_path: vgg19_weights/imagenet-vgg-verydeep-19.mat\r\nviz_steps: 5\r\nwgan_gp_lambda: 10\r\n-------------- End ----------------\r\n[256, 256, 3]\r\nG:\\pythonAI\\training_images\\source_images\\t2.index\r\n24\r\n['G:\\\\pythonAI\\\\training_images\\\\source_images\\\\001.png', 'G:\\\\pythonAI\\\\training_images\\\\source_images\\\\002.png']\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\data\\data.py:15: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\r\n\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\data\\data.py:17: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:373: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:319: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nTo construct input pipelines, use the `tf.data` module.\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nTo construct input pipelines, use the `tf.data` module.\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\data\\data.py:19: The name tf.read_file is deprecated. Please use tf.io.read_file instead.\r\n\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\data\\data.py:22: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.\r\n\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\data\\data.py:24: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\net\\ops.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\r\n\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\net\\ops.py:155: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\ntf.py_func is deprecated in TF V2. Instead, there are two\r\n    options available in V2.\r\n    - tf.py_function takes a python function which manipulates tf eager\r\n    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\r\n    an ndarray (just call tensor.numpy()) but having access to eager tensors\r\n    means `tf.py_function`s can use accelerators such as GPUs as well as\r\n    being differentiable using a gradient tape.\r\n    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\r\n    (it is not differentiable, and manipulates numpy arrays). It drops the\r\n    stateful argument making all functions stateful.\r\n\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\net\\network.py:35: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.keras.layers.Conv2D` instead.\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\layers\\convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `layer.__call__` method instead.\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\net\\network.py:49: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\r\n\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\net\\network.py:66: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\r\n\r\nPretrain the whole net with only reconstruction loss.\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\net\\network.py:224: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\r\n\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\net\\network.py:225: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\r\n\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\net\\network.py:137: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse keras.layers.flatten instead.\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\net\\network.py:156: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse keras.layers.Dense instead.\r\nSet L1_LOSS_ALPHA to 1.400000\r\nSet GAN_LOSS_ALPHA to 0.001000\r\nSet AE_LOSS_ALPHA to 1.200000\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\net\\network.py:286: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\r\n\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\net\\network.py:287: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\r\n\r\nWARNING:tensorflow:From train.py:20: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\r\n\r\nWARNING:tensorflow:From train.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\r\n\r\nWARNING:tensorflow:From G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nWARNING:tensorflow:From train.py:30: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\r\n\r\nWARNING:tensorflow:From train.py:32: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\r\n\r\nWARNING:tensorflow:From train.py:34: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\r\n\r\n2020-08-25 10:37:24.089038: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\nWARNING:tensorflow:From train.py:35: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\r\n\r\nWARNING:tensorflow:From train.py:50: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\r\n\r\nWARNING:tensorflow:From train.py:53: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nTo construct input pipelines, use the `tf.data` module.\r\n2020-08-25 10:37:27.684580: W tensorflow/core/kernels/queue_base.cc:277] _0_feed/input_producer/input_producer: Skipping cancelled enqueue attempt with queue not closed\r\n2020-08-25 10:37:27.687946: W tensorflow/core/kernels/queue_base.cc:277] _1_feed/batch/fifo_queue: Skipping cancelled enqueue attempt with queue not closed\r\n2020-08-25 10:37:27.691128: W tensorflow/core/kernels/queue_base.cc:277] _1_feed/batch/fifo_queue: Skipping cancelled enqueue attempt with queue not closed\r\n2020-08-25 10:37:27.705672: W tensorflow/core/kernels/queue_base.cc:277] _1_feed/batch/fifo_queue: Skipping cancelled enqueue attempt with queue not closed\r\n2020-08-25 10:37:27.719887: W tensorflow/core/kernels/queue_base.cc:277] _1_feed/batch/fifo_queue: Skipping cancelled enqueue attempt with queue not closed\r\nTraceback (most recent call last):\r\n  File \"G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1365, in _do_call\r\n    return fn(*args)\r\n  File \"G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1350, in _run_fn\r\n    target_list, run_metadata)\r\n  File \"G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1443, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Need minval < maxval, got 0 >= 0\r\n         [[{{node random_uniform_1}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 61, in <module>\r\n    _, g_loss = sess.run([g_train_op, losses['g_loss']])\r\n  File \"G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 956, in run\r\n    run_metadata_ptr)\r\n  File \"G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1180, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1359, in _do_run\r\n    run_metadata)\r\n  File \"G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1384, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Need minval < maxval, got 0 >= 0\r\n         [[node random_uniform_1 (defined at G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\r\n\r\nOriginal stack trace for 'random_uniform_1':\r\n  File \"train.py\", line 18, in <module>\r\n    g_vars, d_vars, losses = model.build_net(images, config=config)\r\n  File \"G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\net\\network.py\", line 172, in build_net\r\n    bbox = random_bbox(config)\r\n  File \"G:\\pythonAI\\inpainting_gmcnn\\tensorflow\\net\\ops.py\", line 122, in random_bbox\r\n    [], minval=config.margins[1], maxval=maxl, dtype=tf.int32)\r\n  File \"G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\ops\\random_ops.py\", line 243, in random_uniform\r\n    shape, minval, maxval, seed=seed1, seed2=seed2, name=name)\r\n  File \"G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_random_ops.py\", line 921, in random_uniform_int\r\n    seed=seed, seed2=seed2, name=name)\r\n  File \"G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\r\n    attrs, op_def, compute_device)\r\n  File \"G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\r\n    op_def=op_def)\r\n  File \"G:\\pythonAI\\inpainting_gmcnn\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\n\r\n(inpainting_gmcnn) G:\\pythonAI\\inpainting_gmcnn\\tensorflow>","reactions":{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/680044045/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"qwerdbeta","id":36677267,"node_id":"MDQ6VXNlcjM2Njc3MjY3","avatar_url":"https://avatars.githubusercontent.com/u/36677267?v=4","gravatar_id":"","url":"https://api.github.com/users/qwerdbeta","html_url":"https://github.com/qwerdbeta","followers_url":"https://api.github.com/users/qwerdbeta/followers","following_url":"https://api.github.com/users/qwerdbeta/following{/other_user}","gists_url":"https://api.github.com/users/qwerdbeta/gists{/gist_id}","starred_url":"https://api.github.com/users/qwerdbeta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qwerdbeta/subscriptions","organizations_url":"https://api.github.com/users/qwerdbeta/orgs","repos_url":"https://api.github.com/users/qwerdbeta/repos","events_url":"https://api.github.com/users/qwerdbeta/events{/privacy}","received_events_url":"https://api.github.com/users/qwerdbeta/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/680067904","html_url":"https://github.com/shepnerd/inpainting_gmcnn/issues/62#issuecomment-680067904","issue_url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/62","id":680067904,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDA2NzkwNA==","user":{"login":"qwerdbeta","id":36677267,"node_id":"MDQ6VXNlcjM2Njc3MjY3","avatar_url":"https://avatars.githubusercontent.com/u/36677267?v=4","gravatar_id":"","url":"https://api.github.com/users/qwerdbeta","html_url":"https://github.com/qwerdbeta","followers_url":"https://api.github.com/users/qwerdbeta/followers","following_url":"https://api.github.com/users/qwerdbeta/following{/other_user}","gists_url":"https://api.github.com/users/qwerdbeta/gists{/gist_id}","starred_url":"https://api.github.com/users/qwerdbeta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qwerdbeta/subscriptions","organizations_url":"https://api.github.com/users/qwerdbeta/orgs","repos_url":"https://api.github.com/users/qwerdbeta/repos","events_url":"https://api.github.com/users/qwerdbeta/events{/privacy}","received_events_url":"https://api.github.com/users/qwerdbeta/received_events","type":"User","site_admin":false},"created_at":"2020-08-25T14:41:59Z","updated_at":"2020-08-25T14:41:59Z","author_association":"NONE","body":"is it because I don't have enough images? This is just a test run with 181 images","reactions":{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/680067904/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"qwerdbeta","id":36677267,"node_id":"MDQ6VXNlcjM2Njc3MjY3","avatar_url":"https://avatars.githubusercontent.com/u/36677267?v=4","gravatar_id":"","url":"https://api.github.com/users/qwerdbeta","html_url":"https://github.com/qwerdbeta","followers_url":"https://api.github.com/users/qwerdbeta/followers","following_url":"https://api.github.com/users/qwerdbeta/following{/other_user}","gists_url":"https://api.github.com/users/qwerdbeta/gists{/gist_id}","starred_url":"https://api.github.com/users/qwerdbeta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qwerdbeta/subscriptions","organizations_url":"https://api.github.com/users/qwerdbeta/orgs","repos_url":"https://api.github.com/users/qwerdbeta/repos","events_url":"https://api.github.com/users/qwerdbeta/events{/privacy}","received_events_url":"https://api.github.com/users/qwerdbeta/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/680120906","html_url":"https://github.com/shepnerd/inpainting_gmcnn/issues/62#issuecomment-680120906","issue_url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/62","id":680120906,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MDEyMDkwNg==","user":{"login":"qwerdbeta","id":36677267,"node_id":"MDQ6VXNlcjM2Njc3MjY3","avatar_url":"https://avatars.githubusercontent.com/u/36677267?v=4","gravatar_id":"","url":"https://api.github.com/users/qwerdbeta","html_url":"https://github.com/qwerdbeta","followers_url":"https://api.github.com/users/qwerdbeta/followers","following_url":"https://api.github.com/users/qwerdbeta/following{/other_user}","gists_url":"https://api.github.com/users/qwerdbeta/gists{/gist_id}","starred_url":"https://api.github.com/users/qwerdbeta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qwerdbeta/subscriptions","organizations_url":"https://api.github.com/users/qwerdbeta/orgs","repos_url":"https://api.github.com/users/qwerdbeta/repos","events_url":"https://api.github.com/users/qwerdbeta/events{/privacy}","received_events_url":"https://api.github.com/users/qwerdbeta/received_events","type":"User","site_admin":false},"created_at":"2020-08-25T16:08:19Z","updated_at":"2020-08-25T16:08:19Z","author_association":"NONE","body":"Above was with tensorflow implementation. I also tried the pytorch implementation in windows but it causes this error on training:\r\n\r\n\r\n(inpainting_gmcnn) G:\\pythonAI\\inpainting_gmcnn\\pytorch>python train.py --dataset celeba --data_file G:\\pythonAI\\training_images\\source_images\\train_images.index\r\n------------ Options -------------\r\nD_max_iters: 5\r\nbatch_size: 16\r\ncheckpoint_dir: ./checkpoints\r\nd_cnum: 64\r\ndata_file: G:\\pythonAI\\training_images\\source_images\\train_images.index\r\ndataset: celeba\r\ndataset_path: G:\\pythonAI\\training_images\\source_images\\train_images.index\r\ndate_str: 20200825-120636\r\nepochs: 40\r\ng_cnum: 32\r\ngpu_ids: ['0']\r\nimg_shapes: [256, 256, 3]\r\nlambda_adv: 0.001\r\nlambda_ae: 1.2\r\nlambda_gp: 10\r\nlambda_mrf: 0.05\r\nlambda_rec: 1.4\r\nload_model_dir:\r\nlr: 1e-05\r\nmargins: [0, 0]\r\nmask_shapes: [128, 128]\r\nmask_type: rect\r\nmax_delta_shapes: [32, 32]\r\nmodel_folder: ./checkpoints\\20200825-120636_GMCNN_celeba_b16_s256x256_gc32_dc64_randmask-rect\r\nmodel_name: GMCNN\r\npadding: SAME\r\nphase: train\r\npretrain_network: False\r\nrandom_crop: True\r\nrandom_mask: True\r\nrandom_seed: False\r\nspectral_norm: True\r\ntrain_spe: 1000\r\nvgg19_path: vgg19_weights/imagenet-vgg-verydeep-19.mat\r\nviz_steps: 5\r\n-------------- End ----------------\r\nloading data..\r\ndata loaded..\r\nconfiguring model..\r\ninitialize network with normal\r\ninitialize network with normal\r\n---------- Networks initialized -------------\r\nGMCNN(\r\n  (EB1): ModuleList(\r\n    (0): Conv2d(4, 32, kernel_size=(7, 7), stride=(1, 1))\r\n    (1): Conv2d(32, 64, kernel_size=(7, 7), stride=(2, 2))\r\n    (2): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\r\n    (3): Conv2d(64, 128, kernel_size=(7, 7), stride=(2, 2))\r\n    (4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n    (5): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n    (6): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(2, 2))\r\n    (7): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(4, 4))\r\n    (8): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(8, 8))\r\n    (9): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(16, 16))\r\n    (10): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n    (11): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n    (12): PureUpsampling()\r\n  )\r\n  (EB2): ModuleList(\r\n    (0): Conv2d(4, 32, kernel_size=(5, 5), stride=(1, 1))\r\n    (1): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2))\r\n    (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\r\n    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2))\r\n    (4): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n    (5): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n    (6): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(2, 2))\r\n    (7): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(4, 4))\r\n    (8): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(8, 8))\r\n    (9): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(16, 16))\r\n    (10): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n    (11): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n    (12): PureUpsampling()\r\n    (13): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1))\r\n    (14): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\r\n    (15): PureUpsampling()\r\n  )\r\n  (EB3): ModuleList(\r\n    (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1))\r\n    (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\r\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\r\n    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\r\n    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\r\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4))\r\n    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(8, 8))\r\n    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(16, 16))\r\n    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n    (12): PureUpsampling()\r\n    (13): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\r\n    (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\r\n    (15): PureUpsampling()\r\n    (16): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\r\n    (17): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\r\n  )\r\n  (decoding_layers): ModuleList(\r\n    (0): Conv2d(224, 16, kernel_size=(3, 3), stride=(1, 1))\r\n    (1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1))\r\n  )\r\n  (pads): ModuleList(\r\n    (0): ReflectionPad2d((0, 0, 0, 0))\r\n    (1): ReflectionPad2d((1, 1, 1, 1))\r\n    (2): ReflectionPad2d((2, 2, 2, 2))\r\n    (3): ReflectionPad2d((3, 3, 3, 3))\r\n    (4): ReflectionPad2d((4, 4, 4, 4))\r\n    (5): ReflectionPad2d((5, 5, 5, 5))\r\n    (6): ReflectionPad2d((6, 6, 6, 6))\r\n    (7): ReflectionPad2d((7, 7, 7, 7))\r\n    (8): ReflectionPad2d((8, 8, 8, 8))\r\n    (9): ReflectionPad2d((9, 9, 9, 9))\r\n    (10): ReflectionPad2d((10, 10, 10, 10))\r\n    (11): ReflectionPad2d((11, 11, 11, 11))\r\n    (12): ReflectionPad2d((12, 12, 12, 12))\r\n    (13): ReflectionPad2d((13, 13, 13, 13))\r\n    (14): ReflectionPad2d((14, 14, 14, 14))\r\n    (15): ReflectionPad2d((15, 15, 15, 15))\r\n    (16): ReflectionPad2d((16, 16, 16, 16))\r\n    (17): ReflectionPad2d((17, 17, 17, 17))\r\n    (18): ReflectionPad2d((18, 18, 18, 18))\r\n    (19): ReflectionPad2d((19, 19, 19, 19))\r\n    (20): ReflectionPad2d((20, 20, 20, 20))\r\n    (21): ReflectionPad2d((21, 21, 21, 21))\r\n    (22): ReflectionPad2d((22, 22, 22, 22))\r\n    (23): ReflectionPad2d((23, 23, 23, 23))\r\n    (24): ReflectionPad2d((24, 24, 24, 24))\r\n    (25): ReflectionPad2d((25, 25, 25, 25))\r\n    (26): ReflectionPad2d((26, 26, 26, 26))\r\n    (27): ReflectionPad2d((27, 27, 27, 27))\r\n    (28): ReflectionPad2d((28, 28, 28, 28))\r\n    (29): ReflectionPad2d((29, 29, 29, 29))\r\n    (30): ReflectionPad2d((30, 30, 30, 30))\r\n    (31): ReflectionPad2d((31, 31, 31, 31))\r\n    (32): ReflectionPad2d((32, 32, 32, 32))\r\n    (33): ReflectionPad2d((33, 33, 33, 33))\r\n    (34): ReflectionPad2d((34, 34, 34, 34))\r\n    (35): ReflectionPad2d((35, 35, 35, 35))\r\n    (36): ReflectionPad2d((36, 36, 36, 36))\r\n    (37): ReflectionPad2d((37, 37, 37, 37))\r\n    (38): ReflectionPad2d((38, 38, 38, 38))\r\n    (39): ReflectionPad2d((39, 39, 39, 39))\r\n    (40): ReflectionPad2d((40, 40, 40, 40))\r\n    (41): ReflectionPad2d((41, 41, 41, 41))\r\n    (42): ReflectionPad2d((42, 42, 42, 42))\r\n    (43): ReflectionPad2d((43, 43, 43, 43))\r\n    (44): ReflectionPad2d((44, 44, 44, 44))\r\n    (45): ReflectionPad2d((45, 45, 45, 45))\r\n    (46): ReflectionPad2d((46, 46, 46, 46))\r\n    (47): ReflectionPad2d((47, 47, 47, 47))\r\n    (48): ReflectionPad2d((48, 48, 48, 48))\r\n  )\r\n)\r\n[Network GM] Total number of parameters : 12.562 M\r\n-----------------------------------------------\r\nmodel setting up..\r\ntraining initializing..\r\n------------ Options -------------\r\nD_max_iters: 5\r\nbatch_size: 16\r\ncheckpoint_dir: ./checkpoints\r\nd_cnum: 64\r\ndata_file: G:\\pythonAI\\training_images\\source_images\\train_images.index\r\ndataset: celeba\r\ndataset_path: G:\\pythonAI\\training_images\\source_images\\train_images.index\r\ndate_str: 20200825-120640\r\nepochs: 40\r\ng_cnum: 32\r\ngpu_ids: ['0']\r\nimg_shapes: [256, 256, 3]\r\nlambda_adv: 0.001\r\nlambda_ae: 1.2\r\nlambda_gp: 10\r\nlambda_mrf: 0.05\r\nlambda_rec: 1.4\r\nload_model_dir:\r\nlr: 1e-05\r\nmargins: [0, 0]\r\nmask_shapes: [128, 128]\r\nmask_type: rect\r\nmax_delta_shapes: [32, 32]\r\nmodel_folder: ./checkpoints\\20200825-120640_GMCNN_celeba_b16_s256x256_gc32_dc64_randmask-rect\r\nmodel_name: GMCNN\r\npadding: SAME\r\nphase: train\r\npretrain_network: False\r\nrandom_crop: True\r\nrandom_mask: True\r\nrandom_seed: False\r\nspectral_norm: True\r\ntrain_spe: 1000\r\nvgg19_path: vgg19_weights/imagenet-vgg-verydeep-19.mat\r\nviz_steps: 5\r\n-------------- End ----------------\r\nloading data..\r\ndata loaded..\r\nconfiguring model..\r\ninitialize network with normal\r\ninitialize network with normal\r\n---------- Networks initialized -------------\r\nGMCNN(\r\n  (EB1): ModuleList(\r\n    (0): Conv2d(4, 32, kernel_size=(7, 7), stride=(1, 1))\r\n    (1): Conv2d(32, 64, kernel_size=(7, 7), stride=(2, 2))\r\n    (2): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\r\n    (3): Conv2d(64, 128, kernel_size=(7, 7), stride=(2, 2))\r\n    (4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n    (5): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n    (6): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(2, 2))\r\n    (7): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(4, 4))\r\n    (8): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(8, 8))\r\n    (9): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(16, 16))\r\n    (10): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n    (11): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n    (12): PureUpsampling()\r\n  )\r\n  (EB2): ModuleList(\r\n    (0): Conv2d(4, 32, kernel_size=(5, 5), stride=(1, 1))\r\n    (1): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2))\r\n    (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\r\n    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2))\r\n    (4): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n    (5): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n    (6): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(2, 2))\r\n    (7): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(4, 4))\r\n    (8): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(8, 8))\r\n    (9): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(16, 16))\r\n    (10): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n    (11): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n    (12): PureUpsampling()\r\n    (13): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1))\r\n    (14): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\r\n    (15): PureUpsampling()\r\n  )\r\n  (EB3): ModuleList(\r\n    (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1))\r\n    (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\r\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\r\n    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\r\n    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\r\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4))\r\n    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(8, 8))\r\n    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(16, 16))\r\n    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n    (12): PureUpsampling()\r\n    (13): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\r\n    (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\r\n    (15): PureUpsampling()\r\n    (16): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\r\n    (17): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\r\n  )\r\n  (decoding_layers): ModuleList(\r\n    (0): Conv2d(224, 16, kernel_size=(3, 3), stride=(1, 1))\r\n    (1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1))\r\n  )\r\n  (pads): ModuleList(\r\n    (0): ReflectionPad2d((0, 0, 0, 0))\r\n    (1): ReflectionPad2d((1, 1, 1, 1))\r\n    (2): ReflectionPad2d((2, 2, 2, 2))\r\n    (3): ReflectionPad2d((3, 3, 3, 3))\r\n    (4): ReflectionPad2d((4, 4, 4, 4))\r\n    (5): ReflectionPad2d((5, 5, 5, 5))\r\n    (6): ReflectionPad2d((6, 6, 6, 6))\r\n    (7): ReflectionPad2d((7, 7, 7, 7))\r\n    (8): ReflectionPad2d((8, 8, 8, 8))\r\n    (9): ReflectionPad2d((9, 9, 9, 9))\r\n    (10): ReflectionPad2d((10, 10, 10, 10))\r\n    (11): ReflectionPad2d((11, 11, 11, 11))\r\n    (12): ReflectionPad2d((12, 12, 12, 12))\r\n    (13): ReflectionPad2d((13, 13, 13, 13))\r\n    (14): ReflectionPad2d((14, 14, 14, 14))\r\n    (15): ReflectionPad2d((15, 15, 15, 15))\r\n    (16): ReflectionPad2d((16, 16, 16, 16))\r\n    (17): ReflectionPad2d((17, 17, 17, 17))\r\n    (18): ReflectionPad2d((18, 18, 18, 18))\r\n    (19): ReflectionPad2d((19, 19, 19, 19))\r\n    (20): ReflectionPad2d((20, 20, 20, 20))\r\n    (21): ReflectionPad2d((21, 21, 21, 21))\r\n    (22): ReflectionPad2d((22, 22, 22, 22))\r\n    (23): ReflectionPad2d((23, 23, 23, 23))\r\n    (24): ReflectionPad2d((24, 24, 24, 24))\r\n    (25): ReflectionPad2d((25, 25, 25, 25))\r\n    (26): ReflectionPad2d((26, 26, 26, 26))\r\n    (27): ReflectionPad2d((27, 27, 27, 27))\r\n    (28): ReflectionPad2d((28, 28, 28, 28))\r\n    (29): ReflectionPad2d((29, 29, 29, 29))\r\n    (30): ReflectionPad2d((30, 30, 30, 30))\r\n    (31): ReflectionPad2d((31, 31, 31, 31))\r\n    (32): ReflectionPad2d((32, 32, 32, 32))\r\n    (33): ReflectionPad2d((33, 33, 33, 33))\r\n    (34): ReflectionPad2d((34, 34, 34, 34))\r\n    (35): ReflectionPad2d((35, 35, 35, 35))\r\n    (36): ReflectionPad2d((36, 36, 36, 36))\r\n    (37): ReflectionPad2d((37, 37, 37, 37))\r\n    (38): ReflectionPad2d((38, 38, 38, 38))\r\n    (39): ReflectionPad2d((39, 39, 39, 39))\r\n    (40): ReflectionPad2d((40, 40, 40, 40))\r\n    (41): ReflectionPad2d((41, 41, 41, 41))\r\n    (42): ReflectionPad2d((42, 42, 42, 42))\r\n    (43): ReflectionPad2d((43, 43, 43, 43))\r\n    (44): ReflectionPad2d((44, 44, 44, 44))\r\n    (45): ReflectionPad2d((45, 45, 45, 45))\r\n    (46): ReflectionPad2d((46, 46, 46, 46))\r\n    (47): ReflectionPad2d((47, 47, 47, 47))\r\n    (48): ReflectionPad2d((48, 48, 48, 48))\r\n  )\r\n)\r\n[Network GM] Total number of parameters : 12.562 M\r\n-----------------------------------------------\r\nmodel setting up..\r\ntraining initializing..\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 34, in <module>\r\n    for i, data in enumerate(dataloader):\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\spawn.py\", line 105, in spawn_main\r\n  File \"G:\\pythonAI\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 819, in __iter__\r\n    exitcode = _main(fd)\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\spawn.py\", line 114, in _main\r\n    return _DataLoaderIter(self)\r\n    prepare(preparation_data)\r\n  File \"G:\\pythonAI\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 560, in __init__\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\spawn.py\", line 225, in prepare\r\n    w.start()\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\process.py\", line 112, in start\r\n    _fixup_main_from_path(data['init_main_from_path'])\r\n    self._popen = self._Popen(self)\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\spawn.py\", line 277, in _fixup_main_from_path\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\context.py\", line 223, in _Popen\r\n    run_name=\"__mp_main__\")\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\runpy.py\", line 263, in run_path\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\context.py\", line 322, in _Popen\r\n    pkg_name=pkg_name, script_name=fname)\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\runpy.py\", line 96, in _run_module_code\r\n    return Popen(process_obj)\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\popen_spawn_win32.py\", line 89, in __init__\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\runpy.py\", line 85, in _run_code\r\n    reduction.dump(process_obj, to_child)\r\n    exec(code, run_globals)\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\reduction.py\", line 60, in dump\r\n  File \"G:\\pythonAI\\inpainting_gmcnn\\pytorch\\train.py\", line 34, in <module>\r\n    ForkingPickler(file, protocol).dump(obj)\r\n    for i, data in enumerate(dataloader):\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n  File \"G:\\pythonAI\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 819, in __iter__\r\n    return _DataLoaderIter(self)\r\n  File \"G:\\pythonAI\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 560, in __init__\r\n    w.start()\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\process.py\", line 112, in start\r\n    self._popen = self._Popen(self)\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\context.py\", line 223, in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\context.py\", line 322, in _Popen\r\n    return Popen(process_obj)\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\popen_spawn_win32.py\", line 46, in __init__\r\n    prep_data = spawn.get_preparation_data(process_obj._name)\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\spawn.py\", line 143, in get_preparation_data\r\n    _check_not_importing_main()\r\n  File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\spawn.py\", line 136, in _check_not_importing_main\r\n    is not going to be frozen to produce an executable.''')\r\nRuntimeError:\r\n        An attempt has been made to start a new process before the\r\n        current process has finished its bootstrapping phase.\r\n\r\n        This probably means that you are not using fork to start your\r\n        child processes and you have forgotten to use the proper idiom\r\n        in the main module:\r\n\r\n            if __name__ == '__main__':\r\n                freeze_support()\r\n                ...\r\n\r\n        The \"freeze_support()\" line can be omitted if the program\r\n        is not going to be frozen to produce an executable.","reactions":{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/680120906/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"qwerdbeta","id":36677267,"node_id":"MDQ6VXNlcjM2Njc3MjY3","avatar_url":"https://avatars.githubusercontent.com/u/36677267?v=4","gravatar_id":"","url":"https://api.github.com/users/qwerdbeta","html_url":"https://github.com/qwerdbeta","followers_url":"https://api.github.com/users/qwerdbeta/followers","following_url":"https://api.github.com/users/qwerdbeta/following{/other_user}","gists_url":"https://api.github.com/users/qwerdbeta/gists{/gist_id}","starred_url":"https://api.github.com/users/qwerdbeta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qwerdbeta/subscriptions","organizations_url":"https://api.github.com/users/qwerdbeta/orgs","repos_url":"https://api.github.com/users/qwerdbeta/repos","events_url":"https://api.github.com/users/qwerdbeta/events{/privacy}","received_events_url":"https://api.github.com/users/qwerdbeta/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/681996967","html_url":"https://github.com/shepnerd/inpainting_gmcnn/issues/62#issuecomment-681996967","issue_url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/62","id":681996967,"node_id":"MDEyOklzc3VlQ29tbWVudDY4MTk5Njk2Nw==","user":{"login":"qwerdbeta","id":36677267,"node_id":"MDQ6VXNlcjM2Njc3MjY3","avatar_url":"https://avatars.githubusercontent.com/u/36677267?v=4","gravatar_id":"","url":"https://api.github.com/users/qwerdbeta","html_url":"https://github.com/qwerdbeta","followers_url":"https://api.github.com/users/qwerdbeta/followers","following_url":"https://api.github.com/users/qwerdbeta/following{/other_user}","gists_url":"https://api.github.com/users/qwerdbeta/gists{/gist_id}","starred_url":"https://api.github.com/users/qwerdbeta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qwerdbeta/subscriptions","organizations_url":"https://api.github.com/users/qwerdbeta/orgs","repos_url":"https://api.github.com/users/qwerdbeta/repos","events_url":"https://api.github.com/users/qwerdbeta/events{/privacy}","received_events_url":"https://api.github.com/users/qwerdbeta/received_events","type":"User","site_admin":false},"created_at":"2020-08-27T14:48:18Z","updated_at":"2020-08-27T14:48:18Z","author_association":"NONE","body":"I finally got the pytorch implementation working after several tweaks.","reactions":{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/681996967/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"qwerdbeta","id":36677267,"node_id":"MDQ6VXNlcjM2Njc3MjY3","avatar_url":"https://avatars.githubusercontent.com/u/36677267?v=4","gravatar_id":"","url":"https://api.github.com/users/qwerdbeta","html_url":"https://github.com/qwerdbeta","followers_url":"https://api.github.com/users/qwerdbeta/followers","following_url":"https://api.github.com/users/qwerdbeta/following{/other_user}","gists_url":"https://api.github.com/users/qwerdbeta/gists{/gist_id}","starred_url":"https://api.github.com/users/qwerdbeta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qwerdbeta/subscriptions","organizations_url":"https://api.github.com/users/qwerdbeta/orgs","repos_url":"https://api.github.com/users/qwerdbeta/repos","events_url":"https://api.github.com/users/qwerdbeta/events{/privacy}","received_events_url":"https://api.github.com/users/qwerdbeta/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/707542980","html_url":"https://github.com/shepnerd/inpainting_gmcnn/issues/62#issuecomment-707542980","issue_url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/62","id":707542980,"node_id":"MDEyOklzc3VlQ29tbWVudDcwNzU0Mjk4MA==","user":{"login":"patricegaofei","id":22410717,"node_id":"MDQ6VXNlcjIyNDEwNzE3","avatar_url":"https://avatars.githubusercontent.com/u/22410717?v=4","gravatar_id":"","url":"https://api.github.com/users/patricegaofei","html_url":"https://github.com/patricegaofei","followers_url":"https://api.github.com/users/patricegaofei/followers","following_url":"https://api.github.com/users/patricegaofei/following{/other_user}","gists_url":"https://api.github.com/users/patricegaofei/gists{/gist_id}","starred_url":"https://api.github.com/users/patricegaofei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/patricegaofei/subscriptions","organizations_url":"https://api.github.com/users/patricegaofei/orgs","repos_url":"https://api.github.com/users/patricegaofei/repos","events_url":"https://api.github.com/users/patricegaofei/events{/privacy}","received_events_url":"https://api.github.com/users/patricegaofei/received_events","type":"User","site_admin":false},"created_at":"2020-10-13T07:16:16Z","updated_at":"2020-10-13T07:16:16Z","author_association":"NONE","body":"Hello @shepnerd  and @qwerdbeta,\r\nPlease, I need your help. I have been trying to run the pytorch version using only the image samples in \"imgs\". However, I have been stuck for many hours with the following error.\r\n\r\n```\r\n python train.py --dataset celebahq_256x256 --data_file /home/gaofei/newResearch/Inpainting_new/inpainting_gmcnn-master/pytorch/imgs/\r\n------------ Options -------------\r\nD_max_iters: 5\r\nbatch_size: 16\r\ncheckpoint_dir: ./checkpoints\r\nd_cnum: 64\r\ndata_file: /home/gaofei/newResearch/Inpainting_new/inpainting_gmcnn-master/pytorch/imgs/\r\ndataset: celebahq_256x256\r\ndataset_path: /home/gaofei/newResearch/Inpainting_new/inpainting_gmcnn-master/pytorch/imgs/\r\ndate_str: 20201013-145021\r\nepochs: 40\r\ng_cnum: 32\r\ngpu_ids: ['0']\r\nimg_shapes: [256, 256, 3]\r\nlambda_adv: 0.001\r\nlambda_ae: 1.2\r\nlambda_gp: 10\r\nlambda_mrf: 0.05\r\nlambda_rec: 1.4\r\nload_model_dir:\r\nlr: 1e-05\r\nmargins: [0, 0]\r\nmask_shapes: [128, 128]\r\nmask_type: rect\r\nmax_delta_shapes: [32, 32]\r\nmodel_folder: ./checkpoints/20201013-145021_GMCNN_celebahq_256x256_b16_s256x256_gc32_dc64_randmask-rect\r\nmodel_name: GMCNN\r\npadding: SAME\r\nphase: train\r\npretrain_network: False\r\nrandom_crop: True\r\nrandom_mask: True\r\nrandom_seed: False\r\nspectral_norm: True\r\ntrain_spe: 1000\r\nvgg19_path: vgg19_weights/imagenet-vgg-verydeep-19.mat\r\nviz_steps: 5\r\n-------------- End ----------------\r\nloading data..\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 15, in <module>\r\n    ToTensor()\r\n  File \"/home/gaofei/newResearch/Inpainting_new/inpainting_gmcnn-master/pytorch/data/data.py\", line 20, in __init__\r\n    self.filenames = open(info_list, 'rt').read().splitlines()\r\nIsADirectoryError: [Errno 21] Is a directory: '/home/gaofei/newResearch/Inpainting_new/inpainting_gmcnn-master/pytorch/imgs/'\r\n```\r\nPlease, how can I fix this error? My aim is to first make the codes run, and then train again with my own dataset. Any comments or suggestions would be highly appreciated.\r\n\r\nBest regards,\r\nPatrice","reactions":{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/707542980/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"patricegaofei","id":22410717,"node_id":"MDQ6VXNlcjIyNDEwNzE3","avatar_url":"https://avatars.githubusercontent.com/u/22410717?v=4","gravatar_id":"","url":"https://api.github.com/users/patricegaofei","html_url":"https://github.com/patricegaofei","followers_url":"https://api.github.com/users/patricegaofei/followers","following_url":"https://api.github.com/users/patricegaofei/following{/other_user}","gists_url":"https://api.github.com/users/patricegaofei/gists{/gist_id}","starred_url":"https://api.github.com/users/patricegaofei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/patricegaofei/subscriptions","organizations_url":"https://api.github.com/users/patricegaofei/orgs","repos_url":"https://api.github.com/users/patricegaofei/repos","events_url":"https://api.github.com/users/patricegaofei/events{/privacy}","received_events_url":"https://api.github.com/users/patricegaofei/received_events","type":"User","site_admin":false}},{"id":3869687199,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50Mzg2OTY4NzE5OQ==","url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/events/3869687199","actor":{"login":"shepnerd","id":5066504,"node_id":"MDQ6VXNlcjUwNjY1MDQ=","avatar_url":"https://avatars.githubusercontent.com/u/5066504?v=4","gravatar_id":"","url":"https://api.github.com/users/shepnerd","html_url":"https://github.com/shepnerd","followers_url":"https://api.github.com/users/shepnerd/followers","following_url":"https://api.github.com/users/shepnerd/following{/other_user}","gists_url":"https://api.github.com/users/shepnerd/gists{/gist_id}","starred_url":"https://api.github.com/users/shepnerd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shepnerd/subscriptions","organizations_url":"https://api.github.com/users/shepnerd/orgs","repos_url":"https://api.github.com/users/shepnerd/repos","events_url":"https://api.github.com/users/shepnerd/events{/privacy}","received_events_url":"https://api.github.com/users/shepnerd/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2020-10-13T07:16:16Z","performed_via_github_app":null},{"id":3869687203,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDM4Njk2ODcyMDM=","url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/events/3869687203","actor":{"login":"shepnerd","id":5066504,"node_id":"MDQ6VXNlcjUwNjY1MDQ=","avatar_url":"https://avatars.githubusercontent.com/u/5066504?v=4","gravatar_id":"","url":"https://api.github.com/users/shepnerd","html_url":"https://github.com/shepnerd","followers_url":"https://api.github.com/users/shepnerd/followers","following_url":"https://api.github.com/users/shepnerd/following{/other_user}","gists_url":"https://api.github.com/users/shepnerd/gists{/gist_id}","starred_url":"https://api.github.com/users/shepnerd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shepnerd/subscriptions","organizations_url":"https://api.github.com/users/shepnerd/orgs","repos_url":"https://api.github.com/users/shepnerd/repos","events_url":"https://api.github.com/users/shepnerd/events{/privacy}","received_events_url":"https://api.github.com/users/shepnerd/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2020-10-13T07:16:16Z","performed_via_github_app":null},{"id":3869687206,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50Mzg2OTY4NzIwNg==","url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/events/3869687206","actor":{"login":"qwerdbeta","id":36677267,"node_id":"MDQ6VXNlcjM2Njc3MjY3","avatar_url":"https://avatars.githubusercontent.com/u/36677267?v=4","gravatar_id":"","url":"https://api.github.com/users/qwerdbeta","html_url":"https://github.com/qwerdbeta","followers_url":"https://api.github.com/users/qwerdbeta/followers","following_url":"https://api.github.com/users/qwerdbeta/following{/other_user}","gists_url":"https://api.github.com/users/qwerdbeta/gists{/gist_id}","starred_url":"https://api.github.com/users/qwerdbeta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qwerdbeta/subscriptions","organizations_url":"https://api.github.com/users/qwerdbeta/orgs","repos_url":"https://api.github.com/users/qwerdbeta/repos","events_url":"https://api.github.com/users/qwerdbeta/events{/privacy}","received_events_url":"https://api.github.com/users/qwerdbeta/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2020-10-13T07:16:16Z","performed_via_github_app":null},{"id":3869687213,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDM4Njk2ODcyMTM=","url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/events/3869687213","actor":{"login":"qwerdbeta","id":36677267,"node_id":"MDQ6VXNlcjM2Njc3MjY3","avatar_url":"https://avatars.githubusercontent.com/u/36677267?v=4","gravatar_id":"","url":"https://api.github.com/users/qwerdbeta","html_url":"https://github.com/qwerdbeta","followers_url":"https://api.github.com/users/qwerdbeta/followers","following_url":"https://api.github.com/users/qwerdbeta/following{/other_user}","gists_url":"https://api.github.com/users/qwerdbeta/gists{/gist_id}","starred_url":"https://api.github.com/users/qwerdbeta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qwerdbeta/subscriptions","organizations_url":"https://api.github.com/users/qwerdbeta/orgs","repos_url":"https://api.github.com/users/qwerdbeta/repos","events_url":"https://api.github.com/users/qwerdbeta/events{/privacy}","received_events_url":"https://api.github.com/users/qwerdbeta/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2020-10-13T07:16:16Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/731627231","html_url":"https://github.com/shepnerd/inpainting_gmcnn/issues/62#issuecomment-731627231","issue_url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/62","id":731627231,"node_id":"MDEyOklzc3VlQ29tbWVudDczMTYyNzIzMQ==","user":{"login":"Cristo-R","id":74836028,"node_id":"MDQ6VXNlcjc0ODM2MDI4","avatar_url":"https://avatars.githubusercontent.com/u/74836028?v=4","gravatar_id":"","url":"https://api.github.com/users/Cristo-R","html_url":"https://github.com/Cristo-R","followers_url":"https://api.github.com/users/Cristo-R/followers","following_url":"https://api.github.com/users/Cristo-R/following{/other_user}","gists_url":"https://api.github.com/users/Cristo-R/gists{/gist_id}","starred_url":"https://api.github.com/users/Cristo-R/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Cristo-R/subscriptions","organizations_url":"https://api.github.com/users/Cristo-R/orgs","repos_url":"https://api.github.com/users/Cristo-R/repos","events_url":"https://api.github.com/users/Cristo-R/events{/privacy}","received_events_url":"https://api.github.com/users/Cristo-R/received_events","type":"User","site_admin":false},"created_at":"2020-11-21T19:44:33Z","updated_at":"2020-11-21T19:44:33Z","author_association":"NONE","body":"> Hello @shepnerd and @qwerdbeta,\r\n> Please, I need your help. I have been trying to run the pytorch version using only the image samples in \"imgs\". However, I have been stuck for many hours with the following error.\r\n> \r\n> ```\r\n>  python train.py --dataset celebahq_256x256 --data_file /home/gaofei/newResearch/Inpainting_new/inpainting_gmcnn-master/pytorch/imgs/\r\n> ------------ Options -------------\r\n> D_max_iters: 5\r\n> batch_size: 16\r\n> checkpoint_dir: ./checkpoints\r\n> d_cnum: 64\r\n> data_file: /home/gaofei/newResearch/Inpainting_new/inpainting_gmcnn-master/pytorch/imgs/\r\n> dataset: celebahq_256x256\r\n> dataset_path: /home/gaofei/newResearch/Inpainting_new/inpainting_gmcnn-master/pytorch/imgs/\r\n> date_str: 20201013-145021\r\n> epochs: 40\r\n> g_cnum: 32\r\n> gpu_ids: ['0']\r\n> img_shapes: [256, 256, 3]\r\n> lambda_adv: 0.001\r\n> lambda_ae: 1.2\r\n> lambda_gp: 10\r\n> lambda_mrf: 0.05\r\n> lambda_rec: 1.4\r\n> load_model_dir:\r\n> lr: 1e-05\r\n> margins: [0, 0]\r\n> mask_shapes: [128, 128]\r\n> mask_type: rect\r\n> max_delta_shapes: [32, 32]\r\n> model_folder: ./checkpoints/20201013-145021_GMCNN_celebahq_256x256_b16_s256x256_gc32_dc64_randmask-rect\r\n> model_name: GMCNN\r\n> padding: SAME\r\n> phase: train\r\n> pretrain_network: False\r\n> random_crop: True\r\n> random_mask: True\r\n> random_seed: False\r\n> spectral_norm: True\r\n> train_spe: 1000\r\n> vgg19_path: vgg19_weights/imagenet-vgg-verydeep-19.mat\r\n> viz_steps: 5\r\n> -------------- End ----------------\r\n> loading data..\r\n> Traceback (most recent call last):\r\n>   File \"train.py\", line 15, in <module>\r\n>     ToTensor()\r\n>   File \"/home/gaofei/newResearch/Inpainting_new/inpainting_gmcnn-master/pytorch/data/data.py\", line 20, in __init__\r\n>     self.filenames = open(info_list, 'rt').read().splitlines()\r\n> IsADirectoryError: [Errno 21] Is a directory: '/home/gaofei/newResearch/Inpainting_new/inpainting_gmcnn-master/pytorch/imgs/'\r\n> ```\r\n> \r\n> Please, how can I fix this error? My aim is to first make the codes run, and then train again with my own dataset. Any comments or suggestions would be highly appreciated.\r\n> \r\n> Best regards,\r\n> Patrice\r\n\r\nu need creat a file.txt or any others file,then input the datasetpath to the file's every lines\r\nfor ex:\r\nc:/xxx/1.png\r\nc:/xxx/2.png","reactions":{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/731627231/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"Cristo-R","id":74836028,"node_id":"MDQ6VXNlcjc0ODM2MDI4","avatar_url":"https://avatars.githubusercontent.com/u/74836028?v=4","gravatar_id":"","url":"https://api.github.com/users/Cristo-R","html_url":"https://github.com/Cristo-R","followers_url":"https://api.github.com/users/Cristo-R/followers","following_url":"https://api.github.com/users/Cristo-R/following{/other_user}","gists_url":"https://api.github.com/users/Cristo-R/gists{/gist_id}","starred_url":"https://api.github.com/users/Cristo-R/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Cristo-R/subscriptions","organizations_url":"https://api.github.com/users/Cristo-R/orgs","repos_url":"https://api.github.com/users/Cristo-R/repos","events_url":"https://api.github.com/users/Cristo-R/events{/privacy}","received_events_url":"https://api.github.com/users/Cristo-R/received_events","type":"User","site_admin":false}},{"id":4024149669,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50NDAyNDE0OTY2OQ==","url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/events/4024149669","actor":{"login":"shepnerd","id":5066504,"node_id":"MDQ6VXNlcjUwNjY1MDQ=","avatar_url":"https://avatars.githubusercontent.com/u/5066504?v=4","gravatar_id":"","url":"https://api.github.com/users/shepnerd","html_url":"https://github.com/shepnerd","followers_url":"https://api.github.com/users/shepnerd/followers","following_url":"https://api.github.com/users/shepnerd/following{/other_user}","gists_url":"https://api.github.com/users/shepnerd/gists{/gist_id}","starred_url":"https://api.github.com/users/shepnerd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shepnerd/subscriptions","organizations_url":"https://api.github.com/users/shepnerd/orgs","repos_url":"https://api.github.com/users/shepnerd/repos","events_url":"https://api.github.com/users/shepnerd/events{/privacy}","received_events_url":"https://api.github.com/users/shepnerd/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2020-11-21T19:44:34Z","performed_via_github_app":null},{"id":4024149670,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDQwMjQxNDk2NzA=","url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/events/4024149670","actor":{"login":"shepnerd","id":5066504,"node_id":"MDQ6VXNlcjUwNjY1MDQ=","avatar_url":"https://avatars.githubusercontent.com/u/5066504?v=4","gravatar_id":"","url":"https://api.github.com/users/shepnerd","html_url":"https://github.com/shepnerd","followers_url":"https://api.github.com/users/shepnerd/followers","following_url":"https://api.github.com/users/shepnerd/following{/other_user}","gists_url":"https://api.github.com/users/shepnerd/gists{/gist_id}","starred_url":"https://api.github.com/users/shepnerd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shepnerd/subscriptions","organizations_url":"https://api.github.com/users/shepnerd/orgs","repos_url":"https://api.github.com/users/shepnerd/repos","events_url":"https://api.github.com/users/shepnerd/events{/privacy}","received_events_url":"https://api.github.com/users/shepnerd/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2020-11-21T19:44:34Z","performed_via_github_app":null},{"id":4024149673,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50NDAyNDE0OTY3Mw==","url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/events/4024149673","actor":{"login":"qwerdbeta","id":36677267,"node_id":"MDQ6VXNlcjM2Njc3MjY3","avatar_url":"https://avatars.githubusercontent.com/u/36677267?v=4","gravatar_id":"","url":"https://api.github.com/users/qwerdbeta","html_url":"https://github.com/qwerdbeta","followers_url":"https://api.github.com/users/qwerdbeta/followers","following_url":"https://api.github.com/users/qwerdbeta/following{/other_user}","gists_url":"https://api.github.com/users/qwerdbeta/gists{/gist_id}","starred_url":"https://api.github.com/users/qwerdbeta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qwerdbeta/subscriptions","organizations_url":"https://api.github.com/users/qwerdbeta/orgs","repos_url":"https://api.github.com/users/qwerdbeta/repos","events_url":"https://api.github.com/users/qwerdbeta/events{/privacy}","received_events_url":"https://api.github.com/users/qwerdbeta/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2020-11-21T19:44:34Z","performed_via_github_app":null},{"id":4024149674,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDQwMjQxNDk2NzQ=","url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/events/4024149674","actor":{"login":"qwerdbeta","id":36677267,"node_id":"MDQ6VXNlcjM2Njc3MjY3","avatar_url":"https://avatars.githubusercontent.com/u/36677267?v=4","gravatar_id":"","url":"https://api.github.com/users/qwerdbeta","html_url":"https://github.com/qwerdbeta","followers_url":"https://api.github.com/users/qwerdbeta/followers","following_url":"https://api.github.com/users/qwerdbeta/following{/other_user}","gists_url":"https://api.github.com/users/qwerdbeta/gists{/gist_id}","starred_url":"https://api.github.com/users/qwerdbeta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qwerdbeta/subscriptions","organizations_url":"https://api.github.com/users/qwerdbeta/orgs","repos_url":"https://api.github.com/users/qwerdbeta/repos","events_url":"https://api.github.com/users/qwerdbeta/events{/privacy}","received_events_url":"https://api.github.com/users/qwerdbeta/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2020-11-21T19:44:34Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/753393313","html_url":"https://github.com/shepnerd/inpainting_gmcnn/issues/62#issuecomment-753393313","issue_url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/62","id":753393313,"node_id":"MDEyOklzc3VlQ29tbWVudDc1MzM5MzMxMw==","user":{"login":"andy8744","id":42409796,"node_id":"MDQ6VXNlcjQyNDA5Nzk2","avatar_url":"https://avatars.githubusercontent.com/u/42409796?v=4","gravatar_id":"","url":"https://api.github.com/users/andy8744","html_url":"https://github.com/andy8744","followers_url":"https://api.github.com/users/andy8744/followers","following_url":"https://api.github.com/users/andy8744/following{/other_user}","gists_url":"https://api.github.com/users/andy8744/gists{/gist_id}","starred_url":"https://api.github.com/users/andy8744/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andy8744/subscriptions","organizations_url":"https://api.github.com/users/andy8744/orgs","repos_url":"https://api.github.com/users/andy8744/repos","events_url":"https://api.github.com/users/andy8744/events{/privacy}","received_events_url":"https://api.github.com/users/andy8744/received_events","type":"User","site_admin":false},"created_at":"2021-01-01T22:16:48Z","updated_at":"2021-01-01T22:16:48Z","author_association":"NONE","body":"> Above was with tensorflow implementation. I also tried the pytorch implementation in windows but it causes this error on training:\r\n> \r\n> ## (inpainting_gmcnn) G:\\pythonAI\\inpainting_gmcnn\\pytorch>python train.py --dataset celeba --data_file G:\\pythonAI\\training_images\\source_images\\train_images.index\r\n> ------------ Options -------------\r\n> D_max_iters: 5\r\n> batch_size: 16\r\n> checkpoint_dir: ./checkpoints\r\n> d_cnum: 64\r\n> data_file: G:\\pythonAI\\training_images\\source_images\\train_images.index\r\n> dataset: celeba\r\n> dataset_path: G:\\pythonAI\\training_images\\source_images\\train_images.index\r\n> date_str: 20200825-120636\r\n> epochs: 40\r\n> g_cnum: 32\r\n> gpu_ids: ['0']\r\n> img_shapes: [256, 256, 3]\r\n> lambda_adv: 0.001\r\n> lambda_ae: 1.2\r\n> lambda_gp: 10\r\n> lambda_mrf: 0.05\r\n> lambda_rec: 1.4\r\n> load_model_dir:\r\n> lr: 1e-05\r\n> margins: [0, 0]\r\n> mask_shapes: [128, 128]\r\n> mask_type: rect\r\n> max_delta_shapes: [32, 32]\r\n> model_folder: ./checkpoints\\20200825-120636_GMCNN_celeba_b16_s256x256_gc32_dc64_randmask-rect\r\n> model_name: GMCNN\r\n> padding: SAME\r\n> phase: train\r\n> pretrain_network: False\r\n> random_crop: True\r\n> random_mask: True\r\n> random_seed: False\r\n> spectral_norm: True\r\n> train_spe: 1000\r\n> vgg19_path: vgg19_weights/imagenet-vgg-verydeep-19.mat\r\n> viz_steps: 5\r\n> -------------- End ----------------\r\n> loading data..\r\n> data loaded..\r\n> configuring model..\r\n> initialize network with normal\r\n> initialize network with normal\r\n> ---------- Networks initialized -------------\r\n> GMCNN(\r\n> (EB1): ModuleList(\r\n> (0): Conv2d(4, 32, kernel_size=(7, 7), stride=(1, 1))\r\n> (1): Conv2d(32, 64, kernel_size=(7, 7), stride=(2, 2))\r\n> (2): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\r\n> (3): Conv2d(64, 128, kernel_size=(7, 7), stride=(2, 2))\r\n> (4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n> (5): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n> (6): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(2, 2))\r\n> (7): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(4, 4))\r\n> (8): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(8, 8))\r\n> (9): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(16, 16))\r\n> (10): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n> (11): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n> (12): PureUpsampling()\r\n> )\r\n> (EB2): ModuleList(\r\n> (0): Conv2d(4, 32, kernel_size=(5, 5), stride=(1, 1))\r\n> (1): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2))\r\n> (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\r\n> (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2))\r\n> (4): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n> (5): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n> (6): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(2, 2))\r\n> (7): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(4, 4))\r\n> (8): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(8, 8))\r\n> (9): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(16, 16))\r\n> (10): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n> (11): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n> (12): PureUpsampling()\r\n> (13): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1))\r\n> (14): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\r\n> (15): PureUpsampling()\r\n> )\r\n> (EB3): ModuleList(\r\n> (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1))\r\n> (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\r\n> (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\r\n> (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\r\n> (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n> (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n> (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\r\n> (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4))\r\n> (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(8, 8))\r\n> (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(16, 16))\r\n> (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n> (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n> (12): PureUpsampling()\r\n> (13): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\r\n> (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\r\n> (15): PureUpsampling()\r\n> (16): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\r\n> (17): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\r\n> )\r\n> (decoding_layers): ModuleList(\r\n> (0): Conv2d(224, 16, kernel_size=(3, 3), stride=(1, 1))\r\n> (1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1))\r\n> )\r\n> (pads): ModuleList(\r\n> (0): ReflectionPad2d((0, 0, 0, 0))\r\n> (1): ReflectionPad2d((1, 1, 1, 1))\r\n> (2): ReflectionPad2d((2, 2, 2, 2))\r\n> (3): ReflectionPad2d((3, 3, 3, 3))\r\n> (4): ReflectionPad2d((4, 4, 4, 4))\r\n> (5): ReflectionPad2d((5, 5, 5, 5))\r\n> (6): ReflectionPad2d((6, 6, 6, 6))\r\n> (7): ReflectionPad2d((7, 7, 7, 7))\r\n> (8): ReflectionPad2d((8, 8, 8, 8))\r\n> (9): ReflectionPad2d((9, 9, 9, 9))\r\n> (10): ReflectionPad2d((10, 10, 10, 10))\r\n> (11): ReflectionPad2d((11, 11, 11, 11))\r\n> (12): ReflectionPad2d((12, 12, 12, 12))\r\n> (13): ReflectionPad2d((13, 13, 13, 13))\r\n> (14): ReflectionPad2d((14, 14, 14, 14))\r\n> (15): ReflectionPad2d((15, 15, 15, 15))\r\n> (16): ReflectionPad2d((16, 16, 16, 16))\r\n> (17): ReflectionPad2d((17, 17, 17, 17))\r\n> (18): ReflectionPad2d((18, 18, 18, 18))\r\n> (19): ReflectionPad2d((19, 19, 19, 19))\r\n> (20): ReflectionPad2d((20, 20, 20, 20))\r\n> (21): ReflectionPad2d((21, 21, 21, 21))\r\n> (22): ReflectionPad2d((22, 22, 22, 22))\r\n> (23): ReflectionPad2d((23, 23, 23, 23))\r\n> (24): ReflectionPad2d((24, 24, 24, 24))\r\n> (25): ReflectionPad2d((25, 25, 25, 25))\r\n> (26): ReflectionPad2d((26, 26, 26, 26))\r\n> (27): ReflectionPad2d((27, 27, 27, 27))\r\n> (28): ReflectionPad2d((28, 28, 28, 28))\r\n> (29): ReflectionPad2d((29, 29, 29, 29))\r\n> (30): ReflectionPad2d((30, 30, 30, 30))\r\n> (31): ReflectionPad2d((31, 31, 31, 31))\r\n> (32): ReflectionPad2d((32, 32, 32, 32))\r\n> (33): ReflectionPad2d((33, 33, 33, 33))\r\n> (34): ReflectionPad2d((34, 34, 34, 34))\r\n> (35): ReflectionPad2d((35, 35, 35, 35))\r\n> (36): ReflectionPad2d((36, 36, 36, 36))\r\n> (37): ReflectionPad2d((37, 37, 37, 37))\r\n> (38): ReflectionPad2d((38, 38, 38, 38))\r\n> (39): ReflectionPad2d((39, 39, 39, 39))\r\n> (40): ReflectionPad2d((40, 40, 40, 40))\r\n> (41): ReflectionPad2d((41, 41, 41, 41))\r\n> (42): ReflectionPad2d((42, 42, 42, 42))\r\n> (43): ReflectionPad2d((43, 43, 43, 43))\r\n> (44): ReflectionPad2d((44, 44, 44, 44))\r\n> (45): ReflectionPad2d((45, 45, 45, 45))\r\n> (46): ReflectionPad2d((46, 46, 46, 46))\r\n> (47): ReflectionPad2d((47, 47, 47, 47))\r\n> (48): ReflectionPad2d((48, 48, 48, 48))\r\n> )\r\n> )\r\n> [Network GM] Total number of parameters : 12.562 M\r\n> ## model setting up..\r\n> training initializing..\r\n> ------------ Options -------------\r\n> D_max_iters: 5\r\n> batch_size: 16\r\n> checkpoint_dir: ./checkpoints\r\n> d_cnum: 64\r\n> data_file: G:\\pythonAI\\training_images\\source_images\\train_images.index\r\n> dataset: celeba\r\n> dataset_path: G:\\pythonAI\\training_images\\source_images\\train_images.index\r\n> date_str: 20200825-120640\r\n> epochs: 40\r\n> g_cnum: 32\r\n> gpu_ids: ['0']\r\n> img_shapes: [256, 256, 3]\r\n> lambda_adv: 0.001\r\n> lambda_ae: 1.2\r\n> lambda_gp: 10\r\n> lambda_mrf: 0.05\r\n> lambda_rec: 1.4\r\n> load_model_dir:\r\n> lr: 1e-05\r\n> margins: [0, 0]\r\n> mask_shapes: [128, 128]\r\n> mask_type: rect\r\n> max_delta_shapes: [32, 32]\r\n> model_folder: ./checkpoints\\20200825-120640_GMCNN_celeba_b16_s256x256_gc32_dc64_randmask-rect\r\n> model_name: GMCNN\r\n> padding: SAME\r\n> phase: train\r\n> pretrain_network: False\r\n> random_crop: True\r\n> random_mask: True\r\n> random_seed: False\r\n> spectral_norm: True\r\n> train_spe: 1000\r\n> vgg19_path: vgg19_weights/imagenet-vgg-verydeep-19.mat\r\n> viz_steps: 5\r\n> -------------- End ----------------\r\n> loading data..\r\n> data loaded..\r\n> configuring model..\r\n> initialize network with normal\r\n> initialize network with normal\r\n> ---------- Networks initialized -------------\r\n> GMCNN(\r\n> (EB1): ModuleList(\r\n> (0): Conv2d(4, 32, kernel_size=(7, 7), stride=(1, 1))\r\n> (1): Conv2d(32, 64, kernel_size=(7, 7), stride=(2, 2))\r\n> (2): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\r\n> (3): Conv2d(64, 128, kernel_size=(7, 7), stride=(2, 2))\r\n> (4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n> (5): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n> (6): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(2, 2))\r\n> (7): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(4, 4))\r\n> (8): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(8, 8))\r\n> (9): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(16, 16))\r\n> (10): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n> (11): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n> (12): PureUpsampling()\r\n> )\r\n> (EB2): ModuleList(\r\n> (0): Conv2d(4, 32, kernel_size=(5, 5), stride=(1, 1))\r\n> (1): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2))\r\n> (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\r\n> (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2))\r\n> (4): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n> (5): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n> (6): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(2, 2))\r\n> (7): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(4, 4))\r\n> (8): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(8, 8))\r\n> (9): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(16, 16))\r\n> (10): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n> (11): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n> (12): PureUpsampling()\r\n> (13): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1))\r\n> (14): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\r\n> (15): PureUpsampling()\r\n> )\r\n> (EB3): ModuleList(\r\n> (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1))\r\n> (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\r\n> (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\r\n> (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\r\n> (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n> (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n> (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\r\n> (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4))\r\n> (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(8, 8))\r\n> (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(16, 16))\r\n> (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n> (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n> (12): PureUpsampling()\r\n> (13): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\r\n> (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\r\n> (15): PureUpsampling()\r\n> (16): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\r\n> (17): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\r\n> )\r\n> (decoding_layers): ModuleList(\r\n> (0): Conv2d(224, 16, kernel_size=(3, 3), stride=(1, 1))\r\n> (1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1))\r\n> )\r\n> (pads): ModuleList(\r\n> (0): ReflectionPad2d((0, 0, 0, 0))\r\n> (1): ReflectionPad2d((1, 1, 1, 1))\r\n> (2): ReflectionPad2d((2, 2, 2, 2))\r\n> (3): ReflectionPad2d((3, 3, 3, 3))\r\n> (4): ReflectionPad2d((4, 4, 4, 4))\r\n> (5): ReflectionPad2d((5, 5, 5, 5))\r\n> (6): ReflectionPad2d((6, 6, 6, 6))\r\n> (7): ReflectionPad2d((7, 7, 7, 7))\r\n> (8): ReflectionPad2d((8, 8, 8, 8))\r\n> (9): ReflectionPad2d((9, 9, 9, 9))\r\n> (10): ReflectionPad2d((10, 10, 10, 10))\r\n> (11): ReflectionPad2d((11, 11, 11, 11))\r\n> (12): ReflectionPad2d((12, 12, 12, 12))\r\n> (13): ReflectionPad2d((13, 13, 13, 13))\r\n> (14): ReflectionPad2d((14, 14, 14, 14))\r\n> (15): ReflectionPad2d((15, 15, 15, 15))\r\n> (16): ReflectionPad2d((16, 16, 16, 16))\r\n> (17): ReflectionPad2d((17, 17, 17, 17))\r\n> (18): ReflectionPad2d((18, 18, 18, 18))\r\n> (19): ReflectionPad2d((19, 19, 19, 19))\r\n> (20): ReflectionPad2d((20, 20, 20, 20))\r\n> (21): ReflectionPad2d((21, 21, 21, 21))\r\n> (22): ReflectionPad2d((22, 22, 22, 22))\r\n> (23): ReflectionPad2d((23, 23, 23, 23))\r\n> (24): ReflectionPad2d((24, 24, 24, 24))\r\n> (25): ReflectionPad2d((25, 25, 25, 25))\r\n> (26): ReflectionPad2d((26, 26, 26, 26))\r\n> (27): ReflectionPad2d((27, 27, 27, 27))\r\n> (28): ReflectionPad2d((28, 28, 28, 28))\r\n> (29): ReflectionPad2d((29, 29, 29, 29))\r\n> (30): ReflectionPad2d((30, 30, 30, 30))\r\n> (31): ReflectionPad2d((31, 31, 31, 31))\r\n> (32): ReflectionPad2d((32, 32, 32, 32))\r\n> (33): ReflectionPad2d((33, 33, 33, 33))\r\n> (34): ReflectionPad2d((34, 34, 34, 34))\r\n> (35): ReflectionPad2d((35, 35, 35, 35))\r\n> (36): ReflectionPad2d((36, 36, 36, 36))\r\n> (37): ReflectionPad2d((37, 37, 37, 37))\r\n> (38): ReflectionPad2d((38, 38, 38, 38))\r\n> (39): ReflectionPad2d((39, 39, 39, 39))\r\n> (40): ReflectionPad2d((40, 40, 40, 40))\r\n> (41): ReflectionPad2d((41, 41, 41, 41))\r\n> (42): ReflectionPad2d((42, 42, 42, 42))\r\n> (43): ReflectionPad2d((43, 43, 43, 43))\r\n> (44): ReflectionPad2d((44, 44, 44, 44))\r\n> (45): ReflectionPad2d((45, 45, 45, 45))\r\n> (46): ReflectionPad2d((46, 46, 46, 46))\r\n> (47): ReflectionPad2d((47, 47, 47, 47))\r\n> (48): ReflectionPad2d((48, 48, 48, 48))\r\n> )\r\n> )\r\n> [Network GM] Total number of parameters : 12.562 M\r\n> model setting up..\r\n> training initializing..\r\n> Traceback (most recent call last):\r\n> File \"\", line 1, in\r\n> Traceback (most recent call last):\r\n> File \"train.py\", line 34, in\r\n> for i, data in enumerate(dataloader):\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\spawn.py\", line 105, in spawn_main\r\n> File \"G:\\pythonAI\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 819, in **iter**\r\n> exitcode = _main(fd)\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\spawn.py\", line 114, in _main\r\n> return _DataLoaderIter(self)\r\n> prepare(preparation_data)\r\n> File \"G:\\pythonAI\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 560, in **init**\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\spawn.py\", line 225, in prepare\r\n> w.start()\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\process.py\", line 112, in start\r\n> _fixup_main_from_path(data['init_main_from_path'])\r\n> self._popen = self._Popen(self)\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\spawn.py\", line 277, in _fixup_main_from_path\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\context.py\", line 223, in _Popen\r\n> run_name=\"**mp_main**\")\r\n> return _default_context.get_context().Process._Popen(process_obj)\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\runpy.py\", line 263, in run_path\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\context.py\", line 322, in _Popen\r\n> pkg_name=pkg_name, script_name=fname)\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\runpy.py\", line 96, in _run_module_code\r\n> return Popen(process_obj)\r\n> mod_name, mod_spec, pkg_name, script_name)\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\popen_spawn_win32.py\", line 89, in **init**\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\runpy.py\", line 85, in _run_code\r\n> reduction.dump(process_obj, to_child)\r\n> exec(code, run_globals)\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\reduction.py\", line 60, in dump\r\n> File \"G:\\pythonAI\\inpainting_gmcnn\\pytorch\\train.py\", line 34, in\r\n> ForkingPickler(file, protocol).dump(obj)\r\n> for i, data in enumerate(dataloader):\r\n> BrokenPipeError: [Errno 32] Broken pipe\r\n> File \"G:\\pythonAI\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 819, in **iter**\r\n> return _DataLoaderIter(self)\r\n> File \"G:\\pythonAI\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 560, in **init**\r\n> w.start()\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\process.py\", line 112, in start\r\n> self._popen = self._Popen(self)\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\context.py\", line 223, in _Popen\r\n> return _default_context.get_context().Process._Popen(process_obj)\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\context.py\", line 322, in _Popen\r\n> return Popen(process_obj)\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\popen_spawn_win32.py\", line 46, in **init**\r\n> prep_data = spawn.get_preparation_data(process_obj._name)\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\spawn.py\", line 143, in get_preparation_data\r\n> _check_not_importing_main()\r\n> File \"G:\\pythonAI\\Miniconda3\\Lib\\multiprocessing\\spawn.py\", line 136, in _check_not_importing_main\r\n> is not going to be frozen to produce an executable.''')\r\n> RuntimeError:\r\n> An attempt has been made to start a new process before the\r\n> current process has finished its bootstrapping phase.\r\n> \r\n> ```\r\n>     This probably means that you are not using fork to start your\r\n>     child processes and you have forgotten to use the proper idiom\r\n>     in the main module:\r\n> \r\n>         if __name__ == '__main__':\r\n>             freeze_support()\r\n>             ...\r\n> \r\n>     The \"freeze_support()\" line can be omitted if the program\r\n>     is not going to be frozen to produce an executable.\r\n> ```\r\n\r\nI got the same error. How did you get the pytorch implementation from working? Thanks","reactions":{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/753393313/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"andy8744","id":42409796,"node_id":"MDQ6VXNlcjQyNDA5Nzk2","avatar_url":"https://avatars.githubusercontent.com/u/42409796?v=4","gravatar_id":"","url":"https://api.github.com/users/andy8744","html_url":"https://github.com/andy8744","followers_url":"https://api.github.com/users/andy8744/followers","following_url":"https://api.github.com/users/andy8744/following{/other_user}","gists_url":"https://api.github.com/users/andy8744/gists{/gist_id}","starred_url":"https://api.github.com/users/andy8744/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andy8744/subscriptions","organizations_url":"https://api.github.com/users/andy8744/orgs","repos_url":"https://api.github.com/users/andy8744/repos","events_url":"https://api.github.com/users/andy8744/events{/privacy}","received_events_url":"https://api.github.com/users/andy8744/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/762870397","html_url":"https://github.com/shepnerd/inpainting_gmcnn/issues/62#issuecomment-762870397","issue_url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/62","id":762870397,"node_id":"MDEyOklzc3VlQ29tbWVudDc2Mjg3MDM5Nw==","user":{"login":"marcomameli1992","id":58846715,"node_id":"MDQ6VXNlcjU4ODQ2NzE1","avatar_url":"https://avatars.githubusercontent.com/u/58846715?v=4","gravatar_id":"","url":"https://api.github.com/users/marcomameli1992","html_url":"https://github.com/marcomameli1992","followers_url":"https://api.github.com/users/marcomameli1992/followers","following_url":"https://api.github.com/users/marcomameli1992/following{/other_user}","gists_url":"https://api.github.com/users/marcomameli1992/gists{/gist_id}","starred_url":"https://api.github.com/users/marcomameli1992/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/marcomameli1992/subscriptions","organizations_url":"https://api.github.com/users/marcomameli1992/orgs","repos_url":"https://api.github.com/users/marcomameli1992/repos","events_url":"https://api.github.com/users/marcomameli1992/events{/privacy}","received_events_url":"https://api.github.com/users/marcomameli1992/received_events","type":"User","site_admin":false},"created_at":"2021-01-19T14:21:51Z","updated_at":"2021-01-19T14:44:07Z","author_association":"NONE","body":"Dear I do not understand how to use my personalized mask as input.\r\nIn particular for the training stage it is only used the image without mask and the masks is random generated? If yes this means that I need to use only correct images withouth error for the input?\r\nFor the test if I would like to use my masks for the network it would be in a separate file or I need to set to white the three color channels on the input image? If the image has to be an input in the test_option which is the right parameter to be used to give it?","reactions":{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/comments/762870397/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"marcomameli1992","id":58846715,"node_id":"MDQ6VXNlcjU4ODQ2NzE1","avatar_url":"https://avatars.githubusercontent.com/u/58846715?v=4","gravatar_id":"","url":"https://api.github.com/users/marcomameli1992","html_url":"https://github.com/marcomameli1992","followers_url":"https://api.github.com/users/marcomameli1992/followers","following_url":"https://api.github.com/users/marcomameli1992/following{/other_user}","gists_url":"https://api.github.com/users/marcomameli1992/gists{/gist_id}","starred_url":"https://api.github.com/users/marcomameli1992/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/marcomameli1992/subscriptions","organizations_url":"https://api.github.com/users/marcomameli1992/orgs","repos_url":"https://api.github.com/users/marcomameli1992/repos","events_url":"https://api.github.com/users/marcomameli1992/events{/privacy}","received_events_url":"https://api.github.com/users/marcomameli1992/received_events","type":"User","site_admin":false}}]