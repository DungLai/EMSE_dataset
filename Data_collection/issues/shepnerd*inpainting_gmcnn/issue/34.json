{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/34","repository_url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn","labels_url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/34/labels{/name}","comments_url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/34/comments","events_url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/34/events","html_url":"https://github.com/shepnerd/inpainting_gmcnn/issues/34","id":503133342,"node_id":"MDU6SXNzdWU1MDMxMzMzNDI=","number":34,"title":"RuntimeError: An attempt has been made to start a new process before the current process has finished","user":{"login":"nywang2019","id":55544699,"node_id":"MDQ6VXNlcjU1NTQ0Njk5","avatar_url":"https://avatars.githubusercontent.com/u/55544699?v=4","gravatar_id":"","url":"https://api.github.com/users/nywang2019","html_url":"https://github.com/nywang2019","followers_url":"https://api.github.com/users/nywang2019/followers","following_url":"https://api.github.com/users/nywang2019/following{/other_user}","gists_url":"https://api.github.com/users/nywang2019/gists{/gist_id}","starred_url":"https://api.github.com/users/nywang2019/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nywang2019/subscriptions","organizations_url":"https://api.github.com/users/nywang2019/orgs","repos_url":"https://api.github.com/users/nywang2019/repos","events_url":"https://api.github.com/users/nywang2019/events{/privacy}","received_events_url":"https://api.github.com/users/nywang2019/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2019-10-06T17:34:13Z","updated_at":"2019-12-12T05:44:15Z","closed_at":"2019-10-07T13:29:05Z","author_association":"NONE","active_lock_reason":null,"body":"Hi, I selected 10000 images from celebA and try to train. I prepared dir and files, and ran the following:\r\npython train.py --dataset CelebA --data_file ./training_data_list/data_list.txt --gpu_ids 0 --pretrain_network 1\r\n--batch_size 8\r\nbut something went wrong.  It seems the dada was loaded twice and the code was trying to start a second training initiallization...... any one can help me? @shepnerd \r\n------------ Options -------------\r\nD_max_iters: 5\r\nbatch_size: 1\r\ncheckpoint_dir: ./checkpoints\r\nd_cnum: 64\r\ndata_file: ./training_data_list/data_list.txt\r\ndataset: CelebA\r\ndataset_path: ./training_data_list/data_list.txt\r\ndate_str: 20191006-131434\r\nepochs: 40\r\ng_cnum: 32\r\ngpu_ids: ['0']\r\nimg_shapes: [256, 256, 3]\r\nlambda_adv: 0.001\r\nlambda_ae: 1.2\r\nlambda_gp: 10\r\nlambda_mrf: 0.05\r\nlambda_rec: 1.4\r\nload_model_dir:\r\nlr: 1e-05\r\nmargins: [0, 0]\r\nmask_shapes: [128, 128]\r\nmask_type: rect\r\nmax_delta_shapes: [32, 32]\r\nmodel_folder: ./checkpoints\\20191006-131434_GMCNN_CelebA_b1_s256x256_gc32_dc64_randmask-rect_pretrain\r\nmodel_name: GMCNN\r\npadding: SAME\r\nphase: train\r\npretrain_network: True\r\nrandom_crop: True\r\nrandom_mask: True\r\nrandom_seed: False\r\nspectral_norm: True\r\ntrain_spe: 1000\r\nvgg19_path: vgg19_weights/imagenet-vgg-verydeep-19.mat\r\nviz_steps: 5\r\n-------------- End ----------------\r\nloading data..\r\ndata loaded..\r\nconfiguring model..\r\ninitialize network with normal\r\n---------- Networks initialized -------------\r\nGMCNN(\r\n  (EB1): ModuleList(\r\n    (0): Conv2d(4, 32, kernel_size=(7, 7), stride=(1, 1))\r\n    (1): Conv2d(32, 64, kernel_size=(7, 7), stride=(2, 2))\r\n    (2): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\r\n    (3): Conv2d(64, 128, kernel_size=(7, 7), stride=(2, 2))\r\n    (4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n    (5): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n    (6): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(2, 2))\r\n    (7): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(4, 4))\r\n    (8): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(8, 8))\r\n    (9): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(16, 16))\r\n    (10): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n    (11): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n    (12): PureUpsampling()\r\n  )\r\n  (EB2): ModuleList(\r\n    (0): Conv2d(4, 32, kernel_size=(5, 5), stride=(1, 1))\r\n    (1): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2))\r\n    (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\r\n    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2))\r\n    (4): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n    (5): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n    (6): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(2, 2))\r\n    (7): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(4, 4))\r\n    (8): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(8, 8))\r\n    (9): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(16, 16))\r\n    (10): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n    (11): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n    (12): PureUpsampling()\r\n    (13): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1))\r\n    (14): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\r\n    (15): PureUpsampling()\r\n  )\r\n  (EB3): ModuleList(\r\n    (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1))\r\n    (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\r\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\r\n    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\r\n    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\r\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4))\r\n    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(8, 8))\r\n    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(16, 16))\r\n    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n    (12): PureUpsampling()\r\n    (13): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\r\n    (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\r\n    (15): PureUpsampling()\r\n    (16): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\r\n    (17): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\r\n  )\r\n  (decoding_layers): ModuleList(\r\n    (0): Conv2d(224, 16, kernel_size=(3, 3), stride=(1, 1))\r\n    (1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1))\r\n  )\r\n  (pads): ModuleList(\r\n    (0): ReflectionPad2d((0, 0, 0, 0))\r\n    (1): ReflectionPad2d((1, 1, 1, 1))\r\n    (2): ReflectionPad2d((2, 2, 2, 2))\r\n    (3): ReflectionPad2d((3, 3, 3, 3))\r\n    (4): ReflectionPad2d((4, 4, 4, 4))\r\n    (5): ReflectionPad2d((5, 5, 5, 5))\r\n    (6): ReflectionPad2d((6, 6, 6, 6))\r\n    (7): ReflectionPad2d((7, 7, 7, 7))\r\n    (8): ReflectionPad2d((8, 8, 8, 8))\r\n    (9): ReflectionPad2d((9, 9, 9, 9))\r\n    (10): ReflectionPad2d((10, 10, 10, 10))\r\n    (11): ReflectionPad2d((11, 11, 11, 11))\r\n    (12): ReflectionPad2d((12, 12, 12, 12))\r\n    (13): ReflectionPad2d((13, 13, 13, 13))\r\n    (14): ReflectionPad2d((14, 14, 14, 14))\r\n    (15): ReflectionPad2d((15, 15, 15, 15))\r\n    (16): ReflectionPad2d((16, 16, 16, 16))\r\n    (17): ReflectionPad2d((17, 17, 17, 17))\r\n    (18): ReflectionPad2d((18, 18, 18, 18))\r\n    (19): ReflectionPad2d((19, 19, 19, 19))\r\n    (20): ReflectionPad2d((20, 20, 20, 20))\r\n    (21): ReflectionPad2d((21, 21, 21, 21))\r\n    (22): ReflectionPad2d((22, 22, 22, 22))\r\n    (23): ReflectionPad2d((23, 23, 23, 23))\r\n    (24): ReflectionPad2d((24, 24, 24, 24))\r\n    (25): ReflectionPad2d((25, 25, 25, 25))\r\n    (26): ReflectionPad2d((26, 26, 26, 26))\r\n    (27): ReflectionPad2d((27, 27, 27, 27))\r\n    (28): ReflectionPad2d((28, 28, 28, 28))\r\n    (29): ReflectionPad2d((29, 29, 29, 29))\r\n    (30): ReflectionPad2d((30, 30, 30, 30))\r\n    (31): ReflectionPad2d((31, 31, 31, 31))\r\n    (32): ReflectionPad2d((32, 32, 32, 32))\r\n    (33): ReflectionPad2d((33, 33, 33, 33))\r\n    (34): ReflectionPad2d((34, 34, 34, 34))\r\n    (35): ReflectionPad2d((35, 35, 35, 35))\r\n    (36): ReflectionPad2d((36, 36, 36, 36))\r\n    (37): ReflectionPad2d((37, 37, 37, 37))\r\n    (38): ReflectionPad2d((38, 38, 38, 38))\r\n    (39): ReflectionPad2d((39, 39, 39, 39))\r\n    (40): ReflectionPad2d((40, 40, 40, 40))\r\n    (41): ReflectionPad2d((41, 41, 41, 41))\r\n    (42): ReflectionPad2d((42, 42, 42, 42))\r\n    (43): ReflectionPad2d((43, 43, 43, 43))\r\n    (44): ReflectionPad2d((44, 44, 44, 44))\r\n    (45): ReflectionPad2d((45, 45, 45, 45))\r\n    (46): ReflectionPad2d((46, 46, 46, 46))\r\n    (47): ReflectionPad2d((47, 47, 47, 47))\r\n    (48): ReflectionPad2d((48, 48, 48, 48))\r\n  )\r\n)\r\n[Network GM] Total number of parameters : 12.562 M\r\n-----------------------------------------------\r\nmodel setting up..\r\ntraining initializing..\r\n------------ Options -------------\r\nD_max_iters: 5\r\nbatch_size: 1\r\ncheckpoint_dir: ./checkpoints\r\nd_cnum: 64\r\ndata_file: ./training_data_list/data_list.txt\r\ndataset: CelebA\r\ndataset_path: ./training_data_list/data_list.txt\r\ndate_str: 20191006-131438\r\nepochs: 40\r\ng_cnum: 32\r\ngpu_ids: ['0']\r\nimg_shapes: [256, 256, 3]\r\nlambda_adv: 0.001\r\nlambda_ae: 1.2\r\nlambda_gp: 10\r\nlambda_mrf: 0.05\r\nlambda_rec: 1.4\r\nload_model_dir:\r\nlr: 1e-05\r\nmargins: [0, 0]\r\nmask_shapes: [128, 128]\r\nmask_type: rect\r\nmax_delta_shapes: [32, 32]\r\nmodel_folder: ./checkpoints\\20191006-131438_GMCNN_CelebA_b1_s256x256_gc32_dc64_randmask-rect_pretrain\r\nmodel_name: GMCNN\r\npadding: SAME\r\nphase: train\r\npretrain_network: True\r\nrandom_crop: True\r\nrandom_mask: True\r\nrandom_seed: False\r\nspectral_norm: True\r\ntrain_spe: 1000\r\nvgg19_path: vgg19_weights/imagenet-vgg-verydeep-19.mat\r\nviz_steps: 5\r\n-------------- End ----------------\r\nloading data..\r\ndata loaded..\r\nconfiguring model..\r\ninitialize network with normal\r\n---------- Networks initialized -------------\r\nGMCNN(\r\n  (EB1): ModuleList(\r\n    (0): Conv2d(4, 32, kernel_size=(7, 7), stride=(1, 1))\r\n    (1): Conv2d(32, 64, kernel_size=(7, 7), stride=(2, 2))\r\n    (2): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\r\n    (3): Conv2d(64, 128, kernel_size=(7, 7), stride=(2, 2))\r\n    (4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n    (5): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n    (6): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(2, 2))\r\n    (7): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(4, 4))\r\n    (8): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(8, 8))\r\n    (9): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), dilation=(16, 16))\r\n    (10): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n    (11): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1))\r\n    (12): PureUpsampling()\r\n  )\r\n  (EB2): ModuleList(\r\n    (0): Conv2d(4, 32, kernel_size=(5, 5), stride=(1, 1))\r\n    (1): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2))\r\n    (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\r\n    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2))\r\n    (4): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n    (5): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n    (6): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(2, 2))\r\n    (7): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(4, 4))\r\n    (8): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(8, 8))\r\n    (9): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), dilation=(16, 16))\r\n    (10): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n    (11): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\r\n    (12): PureUpsampling()\r\n    (13): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1))\r\n    (14): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\r\n    (15): PureUpsampling()\r\n  )\r\n  (EB3): ModuleList(\r\n    (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1))\r\n    (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\r\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\r\n    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\r\n    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\r\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4))\r\n    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(8, 8))\r\n    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(16, 16))\r\n    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\r\n    (12): PureUpsampling()\r\n    (13): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\r\n    (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\r\n    (15): PureUpsampling()\r\n    (16): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\r\n    (17): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\r\n  )\r\n  (decoding_layers): ModuleList(\r\n    (0): Conv2d(224, 16, kernel_size=(3, 3), stride=(1, 1))\r\n    (1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1))\r\n  )\r\n  (pads): ModuleList(\r\n    (0): ReflectionPad2d((0, 0, 0, 0))\r\n    (1): ReflectionPad2d((1, 1, 1, 1))\r\n    (2): ReflectionPad2d((2, 2, 2, 2))\r\n    (3): ReflectionPad2d((3, 3, 3, 3))\r\n    (4): ReflectionPad2d((4, 4, 4, 4))\r\n    (5): ReflectionPad2d((5, 5, 5, 5))\r\n    (6): ReflectionPad2d((6, 6, 6, 6))\r\n    (7): ReflectionPad2d((7, 7, 7, 7))\r\n    (8): ReflectionPad2d((8, 8, 8, 8))\r\n    (9): ReflectionPad2d((9, 9, 9, 9))\r\n    (10): ReflectionPad2d((10, 10, 10, 10))\r\n    (11): ReflectionPad2d((11, 11, 11, 11))\r\n    (12): ReflectionPad2d((12, 12, 12, 12))\r\n    (13): ReflectionPad2d((13, 13, 13, 13))\r\n    (14): ReflectionPad2d((14, 14, 14, 14))\r\n    (15): ReflectionPad2d((15, 15, 15, 15))\r\n    (16): ReflectionPad2d((16, 16, 16, 16))\r\n    (17): ReflectionPad2d((17, 17, 17, 17))\r\n    (18): ReflectionPad2d((18, 18, 18, 18))\r\n    (19): ReflectionPad2d((19, 19, 19, 19))\r\n    (20): ReflectionPad2d((20, 20, 20, 20))\r\n    (21): ReflectionPad2d((21, 21, 21, 21))\r\n    (22): ReflectionPad2d((22, 22, 22, 22))\r\n    (23): ReflectionPad2d((23, 23, 23, 23))\r\n    (24): ReflectionPad2d((24, 24, 24, 24))\r\n    (25): ReflectionPad2d((25, 25, 25, 25))\r\n    (26): ReflectionPad2d((26, 26, 26, 26))\r\n    (27): ReflectionPad2d((27, 27, 27, 27))\r\n    (28): ReflectionPad2d((28, 28, 28, 28))\r\n    (29): ReflectionPad2d((29, 29, 29, 29))\r\n    (30): ReflectionPad2d((30, 30, 30, 30))\r\n    (31): ReflectionPad2d((31, 31, 31, 31))\r\n    (32): ReflectionPad2d((32, 32, 32, 32))\r\n    (33): ReflectionPad2d((33, 33, 33, 33))\r\n    (34): ReflectionPad2d((34, 34, 34, 34))\r\n    (35): ReflectionPad2d((35, 35, 35, 35))\r\n    (36): ReflectionPad2d((36, 36, 36, 36))\r\n    (37): ReflectionPad2d((37, 37, 37, 37))\r\n    (38): ReflectionPad2d((38, 38, 38, 38))\r\n    (39): ReflectionPad2d((39, 39, 39, 39))\r\n    (40): ReflectionPad2d((40, 40, 40, 40))\r\n    (41): ReflectionPad2d((41, 41, 41, 41))\r\n    (42): ReflectionPad2d((42, 42, 42, 42))\r\n    (43): ReflectionPad2d((43, 43, 43, 43))\r\n    (44): ReflectionPad2d((44, 44, 44, 44))\r\n    (45): ReflectionPad2d((45, 45, 45, 45))\r\n    (46): ReflectionPad2d((46, 46, 46, 46))\r\n    (47): ReflectionPad2d((47, 47, 47, 47))\r\n    (48): ReflectionPad2d((48, 48, 48, 48))\r\n  )\r\n)\r\n[Network GM] Total number of parameters : 12.562 M\r\n-----------------------------------------------\r\nmodel setting up..\r\ntraining initializing..\r\nTraceback (most recent call last):\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"train.py\", line 34, in <module>\r\n  File \"D:\\Anaconda3\\lib\\multiprocessing\\spawn.py\", line 105, in spawn_main\r\n    for i, data in enumerate(dataloader):\r\nexitcode = _main(fd)  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 278, in __iter__\r\n\r\n  File \"D:\\Anaconda3\\lib\\multiprocessing\\spawn.py\", line 114, in _main\r\n    return _MultiProcessingDataLoaderIter(self)\r\n      File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 682, in __init__\r\nprepare(preparation_data)\r\n  File \"D:\\Anaconda3\\lib\\multiprocessing\\spawn.py\", line 225, in prepare\r\n        w.start()_fixup_main_from_path(data['init_main_from_path'])\r\n\r\n  File \"D:\\Anaconda3\\lib\\multiprocessing\\process.py\", line 112, in start\r\n  File \"D:\\Anaconda3\\lib\\multiprocessing\\spawn.py\", line 277, in _fixup_main_from_path\r\n    self._popen = self._Popen(self)\r\nrun_name=\"__mp_main__\")  File \"D:\\Anaconda3\\lib\\multiprocessing\\context.py\", line 223, in _Popen\r\n\r\n      File \"D:\\Anaconda3\\lib\\runpy.py\", line 263, in run_path\r\nreturn _default_context.get_context().Process._Popen(process_obj)\r\n      File \"D:\\Anaconda3\\lib\\multiprocessing\\context.py\", line 322, in _Popen\r\npkg_name=pkg_name, script_name=fname)\r\n      File \"D:\\Anaconda3\\lib\\runpy.py\", line 96, in _run_module_code\r\nreturn Popen(process_obj)\r\nmod_name, mod_spec, pkg_name, script_name)  File \"D:\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 89, in __init__\r\n\r\n      File \"D:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\r\nreduction.dump(process_obj, to_child)\r\nexec(code, run_globals)  File \"D:\\Anaconda3\\lib\\multiprocessing\\reduction.py\", line 60, in dump\r\n\r\n      File \"D:\\PycharmProjects2\\inpainting_gmcnn\\pytorch\\train.py\", line 34, in <module>\r\nForkingPickler(file, protocol).dump(obj)\r\nfor i, data in enumerate(dataloader):BrokenPipeError\r\n:   File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 278, in __iter__\r\n[Errno 32] Broken pipe\r\n    return _MultiProcessingDataLoaderIter(self)\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 682, in __init__\r\n    w.start()\r\n  File \"D:\\Anaconda3\\lib\\multiprocessing\\process.py\", line 112, in start\r\n    self._popen = self._Popen(self)\r\n  File \"D:\\Anaconda3\\lib\\multiprocessing\\context.py\", line 223, in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n  File \"D:\\Anaconda3\\lib\\multiprocessing\\context.py\", line 322, in _Popen\r\n    return Popen(process_obj)\r\n  File \"D:\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 46, in __init__\r\n    prep_data = spawn.get_preparation_data(process_obj._name)\r\n  File \"D:\\Anaconda3\\lib\\multiprocessing\\spawn.py\", line 143, in get_preparation_data\r\n    _check_not_importing_main()\r\n  File \"D:\\Anaconda3\\lib\\multiprocessing\\spawn.py\", line 136, in _check_not_importing_main\r\n    is not going to be frozen to produce an executable.''')\r\nRuntimeError:\r\n        An attempt has been made to start a new process before the\r\n        current process has finished its bootstrapping phase.\r\n\r\n        This probably means that you are not using fork to start your\r\n        child processes and you have forgotten to use the proper idiom\r\n        in the main module:\r\n\r\n            if __name__ == '__main__':\r\n                freeze_support()\r\n                ...\r\n\r\n        The \"freeze_support()\" line can be omitted if the program\r\n        is not going to be frozen to produce an executable.\r\n","closed_by":{"login":"nywang2019","id":55544699,"node_id":"MDQ6VXNlcjU1NTQ0Njk5","avatar_url":"https://avatars.githubusercontent.com/u/55544699?v=4","gravatar_id":"","url":"https://api.github.com/users/nywang2019","html_url":"https://github.com/nywang2019","followers_url":"https://api.github.com/users/nywang2019/followers","following_url":"https://api.github.com/users/nywang2019/following{/other_user}","gists_url":"https://api.github.com/users/nywang2019/gists{/gist_id}","starred_url":"https://api.github.com/users/nywang2019/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nywang2019/subscriptions","organizations_url":"https://api.github.com/users/nywang2019/orgs","repos_url":"https://api.github.com/users/nywang2019/repos","events_url":"https://api.github.com/users/nywang2019/events{/privacy}","received_events_url":"https://api.github.com/users/nywang2019/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/34/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/shepnerd/inpainting_gmcnn/issues/34/timeline","performed_via_github_app":null,"state_reason":"completed"}