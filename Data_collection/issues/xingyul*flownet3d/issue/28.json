{"url":"https://api.github.com/repos/xingyul/flownet3d/issues/28","repository_url":"https://api.github.com/repos/xingyul/flownet3d","labels_url":"https://api.github.com/repos/xingyul/flownet3d/issues/28/labels{/name}","comments_url":"https://api.github.com/repos/xingyul/flownet3d/issues/28/comments","events_url":"https://api.github.com/repos/xingyul/flownet3d/issues/28/events","html_url":"https://github.com/xingyul/flownet3d/issues/28","id":519981343,"node_id":"MDU6SXNzdWU1MTk5ODEzNDM=","number":28,"title":"How do you get the point clouds of second frame for KITTI?","user":{"login":"sulashi","id":22641351,"node_id":"MDQ6VXNlcjIyNjQxMzUx","avatar_url":"https://avatars.githubusercontent.com/u/22641351?v=4","gravatar_id":"","url":"https://api.github.com/users/sulashi","html_url":"https://github.com/sulashi","followers_url":"https://api.github.com/users/sulashi/followers","following_url":"https://api.github.com/users/sulashi/following{/other_user}","gists_url":"https://api.github.com/users/sulashi/gists{/gist_id}","starred_url":"https://api.github.com/users/sulashi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sulashi/subscriptions","organizations_url":"https://api.github.com/users/sulashi/orgs","repos_url":"https://api.github.com/users/sulashi/repos","events_url":"https://api.github.com/users/sulashi/events{/privacy}","received_events_url":"https://api.github.com/users/sulashi/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2019-11-08T12:11:03Z","updated_at":"2019-11-08T12:11:03Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Thank you for your great work and code release! \r\nI found that the disparity of  KITTI scene flow dataset is based on frame one, so that the disparity of pixels for the second frame can not be gotten directly. How dou you get them, from the raw lidar data or some method else? \r\n\r\nIf you use the raw lidar data, how could you get so dense depth values?\r\nIf you did not use the raw lidar data, why do you use 150 frames rather than 200?","closed_by":null,"reactions":{"url":"https://api.github.com/repos/xingyul/flownet3d/issues/28/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/xingyul/flownet3d/issues/28/timeline","performed_via_github_app":null,"state_reason":null}