[{"url":"https://api.github.com/repos/stefanonardo/pytorch-esn/issues/comments/1005579546","html_url":"https://github.com/stefanonardo/pytorch-esn/issues/12#issuecomment-1005579546","issue_url":"https://api.github.com/repos/stefanonardo/pytorch-esn/issues/12","id":1005579546,"node_id":"IC_kwDOB438r8477-0a","user":{"login":"stefanonardo","id":11474759,"node_id":"MDQ6VXNlcjExNDc0NzU5","avatar_url":"https://avatars.githubusercontent.com/u/11474759?v=4","gravatar_id":"","url":"https://api.github.com/users/stefanonardo","html_url":"https://github.com/stefanonardo","followers_url":"https://api.github.com/users/stefanonardo/followers","following_url":"https://api.github.com/users/stefanonardo/following{/other_user}","gists_url":"https://api.github.com/users/stefanonardo/gists{/gist_id}","starred_url":"https://api.github.com/users/stefanonardo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stefanonardo/subscriptions","organizations_url":"https://api.github.com/users/stefanonardo/orgs","repos_url":"https://api.github.com/users/stefanonardo/repos","events_url":"https://api.github.com/users/stefanonardo/events{/privacy}","received_events_url":"https://api.github.com/users/stefanonardo/received_events","type":"User","site_admin":false},"created_at":"2022-01-05T10:51:00Z","updated_at":"2022-01-05T10:51:08Z","author_association":"OWNER","body":"Hi, you can create a Deep ESN by setting _num_layers_, e.g.:\r\n\r\n`model = ESN(input_size=10, hidden_size=1000, num_layers=3, output_size=2)\r\n`","reactions":{"url":"https://api.github.com/repos/stefanonardo/pytorch-esn/issues/comments/1005579546/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"stefanonardo","id":11474759,"node_id":"MDQ6VXNlcjExNDc0NzU5","avatar_url":"https://avatars.githubusercontent.com/u/11474759?v=4","gravatar_id":"","url":"https://api.github.com/users/stefanonardo","html_url":"https://github.com/stefanonardo","followers_url":"https://api.github.com/users/stefanonardo/followers","following_url":"https://api.github.com/users/stefanonardo/following{/other_user}","gists_url":"https://api.github.com/users/stefanonardo/gists{/gist_id}","starred_url":"https://api.github.com/users/stefanonardo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stefanonardo/subscriptions","organizations_url":"https://api.github.com/users/stefanonardo/orgs","repos_url":"https://api.github.com/users/stefanonardo/repos","events_url":"https://api.github.com/users/stefanonardo/events{/privacy}","received_events_url":"https://api.github.com/users/stefanonardo/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/stefanonardo/pytorch-esn/issues/comments/1006332848","html_url":"https://github.com/stefanonardo/pytorch-esn/issues/12#issuecomment-1006332848","issue_url":"https://api.github.com/repos/stefanonardo/pytorch-esn/issues/12","id":1006332848,"node_id":"IC_kwDOB438r847-2uw","user":{"login":"RidhwanAmin","id":53149484,"node_id":"MDQ6VXNlcjUzMTQ5NDg0","avatar_url":"https://avatars.githubusercontent.com/u/53149484?v=4","gravatar_id":"","url":"https://api.github.com/users/RidhwanAmin","html_url":"https://github.com/RidhwanAmin","followers_url":"https://api.github.com/users/RidhwanAmin/followers","following_url":"https://api.github.com/users/RidhwanAmin/following{/other_user}","gists_url":"https://api.github.com/users/RidhwanAmin/gists{/gist_id}","starred_url":"https://api.github.com/users/RidhwanAmin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RidhwanAmin/subscriptions","organizations_url":"https://api.github.com/users/RidhwanAmin/orgs","repos_url":"https://api.github.com/users/RidhwanAmin/repos","events_url":"https://api.github.com/users/RidhwanAmin/events{/privacy}","received_events_url":"https://api.github.com/users/RidhwanAmin/received_events","type":"User","site_admin":false},"created_at":"2022-01-06T07:07:08Z","updated_at":"2022-01-06T07:07:08Z","author_association":"NONE","body":"Thank you for your comment. But I encounter new problem where I do not know where to put the washout into the encoder decoder model. The code is beased on lstm encoder-decoder for lstm. \r\n`import numpy as np\r\nimport random\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch import optim\r\n\r\n\r\nclass Encoder(nn.Module):\r\n\r\n    def __init__(self, input_size, hidden_size, num_layers = 5):\r\n        super(Encoder, self).__init__()\r\n        self.input_size = input_size\r\n        self.hidden_size = hidden_size\r\n        self.num_layers = num_layers\r\n        self.washout = washout\r\n\r\n        self.ESN = ESN(input_size = input_size, output_size = input_size,  hidden_size = hidden_size, num_layers = num_layers)\r\n\r\n    def forward(self, x):\r\n        flat = x.view(x.shape[0], x.shape[1], self.input_size)\r\n        out, h = self.lstm(flat)\r\n        return out, h\r\n\r\n\r\nclass Decoder(nn.Module):\r\n\r\n    def __init__(self, input_size, hidden_size, output_size = 1, num_layers = 5):\r\n        super(Decoder, self).__init__()\r\n        self.input_size = input_size\r\n        self.hidden_size = hidden_size\r\n        self.num_layers = num_layers\r\n        self.output_size = output_size\r\n        self.washout = washout\r\n\r\n\r\n        self.ESN = ESN(input_size = input_size, hidden_size = hidden_size,output_size=output_size, num_layers = num_layers)\r\n        self.linear = nn.Linear(hidden_size, output_size)\r\n\r\n    def forward(self, x, h):\r\n        out, h = self.lstm(x.unsqueeze(0), h)\r\n        y = self.linear(out.squeeze(0))\r\n        return y, h\r\n\r\n\r\nclass EncoderDecoder(nn.Module):\r\n\r\n    def __init__(self, hidden_size, input_size = 1, output_size = 1):\r\n        super(EncoderDecoder, self).__init__()\r\n        self.input_size = input_size\r\n        self.hidden_size = hidden_size\r\n\r\n        self.encoder = Encoder(input_size = input_size, hidden_size = hidden_size)\r\n        self.decoder = Decoder(input_size = input_size, hidden_size = hidden_size, output_size = output_size)\r\n\r\n    def train_model(\r\n            self, train,washout, target, epochs, target_len, method = 'recursive',\r\n            tfr = 0.5, lr = 0.01, dynamic_tf = False\r\n    ):\r\n        losses = np.full(epochs, np.nan)\r\n        optimizer = optim.Adam(self.parameters(), lr = lr)\r\n        criterion = nn.MSELoss()\r\n\r\n        for e in range(epochs):\r\n            predicted = torch.zeros(target_len, train.shape[1], train.shape[2])\r\n            optimizer.zero_grad()\r\n            _, enc_h = self.encoder(train, washout)\r\n\r\n            dec_in = train[-1, :, :]\r\n            dec_h = enc_h\r\n\r\n            if method == 'recursive':\r\n                for t in range(target_len):\r\n                    dec_out, dec_h = self.decoder(dec_in, dec_h)\r\n                    predicted[t] = dec_out\r\n                    dec_in = dec_out\r\n\r\n            if method == 'teacher_forcing':\r\n                # use teacher forcing\r\n                if random.random() < tfr:\r\n                    for t in range(target_len):\r\n                        dec_out, dec_h = self.decoder(dec_in, dec_h)\r\n                        predicted[t] = dec_out\r\n                        dec_in = target[t, :, :]\r\n                # predict recursively\r\n                else:\r\n                    for t in range(target_len):\r\n                        dec_out, dec_h = self.decoder(dec_in, dec_h)\r\n                        predicted[t] = dec_out\r\n                        dec_in = dec_out\r\n\r\n            if method == 'mixed_teacher_forcing':\r\n                # predict using mixed teacher forcing\r\n                for t in range(target_len):\r\n                    dec_out, dec_h = self.decoder(dec_in, dec_h)\r\n                    predicted[t] = dec_out\r\n                    # predict with teacher forcing\r\n                    if random.random() < tfr:\r\n                        dec_in = target[t, :, :]\r\n                    # predict recursively\r\n                    else:\r\n                        dec_in = dec_out\r\n\r\n            loss = criterion(predicted, target)\r\n            loss.backward()\r\n            optimizer.step()\r\n\r\n            losses[e] = loss.item()\r\n\r\n            if e % 10 == 0:\r\n                print(f'Epoch {e}/{epochs}: {round(loss.item(), 4)}')\r\n\r\n            # dynamic teacher forcing\r\n            if dynamic_tf and tfr > 0:\r\n                tfr = tfr - 0.02\r\n\r\n        return losses\r\n\r\n    def predict(self, x, target_len):\r\n        y = torch.zeros(target_len, x.shape[1], x.shape[2])\r\n\r\n        _, enc_h = self.encoder(x)\r\n        dec_in = x[-1, :, :]\r\n        dec_h = enc_h\r\n\r\n        for t in range(target_len):\r\n            dec_out, dec_h = self.decoder(dec_in, dec_h)\r\n            y[t] = dec_out\r\n            dec_in = dec_out\r\n\r\n        return y\r\n`","reactions":{"url":"https://api.github.com/repos/stefanonardo/pytorch-esn/issues/comments/1006332848/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"RidhwanAmin","id":53149484,"node_id":"MDQ6VXNlcjUzMTQ5NDg0","avatar_url":"https://avatars.githubusercontent.com/u/53149484?v=4","gravatar_id":"","url":"https://api.github.com/users/RidhwanAmin","html_url":"https://github.com/RidhwanAmin","followers_url":"https://api.github.com/users/RidhwanAmin/followers","following_url":"https://api.github.com/users/RidhwanAmin/following{/other_user}","gists_url":"https://api.github.com/users/RidhwanAmin/gists{/gist_id}","starred_url":"https://api.github.com/users/RidhwanAmin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RidhwanAmin/subscriptions","organizations_url":"https://api.github.com/users/RidhwanAmin/orgs","repos_url":"https://api.github.com/users/RidhwanAmin/repos","events_url":"https://api.github.com/users/RidhwanAmin/events{/privacy}","received_events_url":"https://api.github.com/users/RidhwanAmin/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/stefanonardo/pytorch-esn/issues/comments/1006666034","html_url":"https://github.com/stefanonardo/pytorch-esn/issues/12#issuecomment-1006666034","issue_url":"https://api.github.com/repos/stefanonardo/pytorch-esn/issues/12","id":1006666034,"node_id":"IC_kwDOB438r848AIEy","user":{"login":"stefanonardo","id":11474759,"node_id":"MDQ6VXNlcjExNDc0NzU5","avatar_url":"https://avatars.githubusercontent.com/u/11474759?v=4","gravatar_id":"","url":"https://api.github.com/users/stefanonardo","html_url":"https://github.com/stefanonardo","followers_url":"https://api.github.com/users/stefanonardo/followers","following_url":"https://api.github.com/users/stefanonardo/following{/other_user}","gists_url":"https://api.github.com/users/stefanonardo/gists{/gist_id}","starred_url":"https://api.github.com/users/stefanonardo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stefanonardo/subscriptions","organizations_url":"https://api.github.com/users/stefanonardo/orgs","repos_url":"https://api.github.com/users/stefanonardo/repos","events_url":"https://api.github.com/users/stefanonardo/events{/privacy}","received_events_url":"https://api.github.com/users/stefanonardo/received_events","type":"User","site_admin":false},"created_at":"2022-01-06T15:10:35Z","updated_at":"2022-01-06T15:10:35Z","author_association":"OWNER","body":"You should pass washout as argument when you call the ESN forward method.","reactions":{"url":"https://api.github.com/repos/stefanonardo/pytorch-esn/issues/comments/1006666034/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"stefanonardo","id":11474759,"node_id":"MDQ6VXNlcjExNDc0NzU5","avatar_url":"https://avatars.githubusercontent.com/u/11474759?v=4","gravatar_id":"","url":"https://api.github.com/users/stefanonardo","html_url":"https://github.com/stefanonardo","followers_url":"https://api.github.com/users/stefanonardo/followers","following_url":"https://api.github.com/users/stefanonardo/following{/other_user}","gists_url":"https://api.github.com/users/stefanonardo/gists{/gist_id}","starred_url":"https://api.github.com/users/stefanonardo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stefanonardo/subscriptions","organizations_url":"https://api.github.com/users/stefanonardo/orgs","repos_url":"https://api.github.com/users/stefanonardo/repos","events_url":"https://api.github.com/users/stefanonardo/events{/privacy}","received_events_url":"https://api.github.com/users/stefanonardo/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/stefanonardo/pytorch-esn/issues/comments/1007119640","html_url":"https://github.com/stefanonardo/pytorch-esn/issues/12#issuecomment-1007119640","issue_url":"https://api.github.com/repos/stefanonardo/pytorch-esn/issues/12","id":1007119640,"node_id":"IC_kwDOB438r848B20Y","user":{"login":"RidhwanAmin","id":53149484,"node_id":"MDQ6VXNlcjUzMTQ5NDg0","avatar_url":"https://avatars.githubusercontent.com/u/53149484?v=4","gravatar_id":"","url":"https://api.github.com/users/RidhwanAmin","html_url":"https://github.com/RidhwanAmin","followers_url":"https://api.github.com/users/RidhwanAmin/followers","following_url":"https://api.github.com/users/RidhwanAmin/following{/other_user}","gists_url":"https://api.github.com/users/RidhwanAmin/gists{/gist_id}","starred_url":"https://api.github.com/users/RidhwanAmin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RidhwanAmin/subscriptions","organizations_url":"https://api.github.com/users/RidhwanAmin/orgs","repos_url":"https://api.github.com/users/RidhwanAmin/repos","events_url":"https://api.github.com/users/RidhwanAmin/events{/privacy}","received_events_url":"https://api.github.com/users/RidhwanAmin/received_events","type":"User","site_admin":false},"created_at":"2022-01-07T03:52:20Z","updated_at":"2022-01-07T03:52:20Z","author_association":"NONE","body":"Thanks again for the comment. Here I changed the previous code.\r\n`\r\nimport numpy as np\r\nimport random\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch import optim\r\n\r\n\r\nclass Encoder(nn.Module):\r\n\r\n    def __init__(self, input_size, hidden_size, num_layers = 5):\r\n        super(Encoder, self).__init__()\r\n        self.input_size = input_size\r\n        self.hidden_size = hidden_size\r\n        self.num_layers = num_layers\r\n\r\n        self.ESN = ESN(input_size = input_size, output_size = input_size,  hidden_size = hidden_size, num_layers = num_layers)\r\n\r\n    def forward(self, x, washout = [100]):\r\n        flat = x.view(x.shape[0], x.shape[1], self.input_size)\r\n        out, h = self.ESN(flat, washout)\r\n        return out, h\r\n\r\n\r\nclass Decoder(nn.Module):\r\n\r\n    def __init__(self, input_size, hidden_size, output_size = 1, num_layers = 5):\r\n        super(Decoder, self).__init__()\r\n        self.input_size = input_size\r\n        self.hidden_size = hidden_size\r\n        self.num_layers = num_layers\r\n        self.output_size = output_size\r\n\r\n\r\n        self.ESN = ESN(input_size = input_size, hidden_size = hidden_size,output_size=output_size, num_layers = num_layers)\r\n        self.linear = nn.Linear(hidden_size, output_size)\r\n\r\n    def forward(self, x, h, washout = [100]):\r\n        out, h = self.ESN(x.unsqueeze(0), h, washout)\r\n        y = self.linear(out.squeeze(0))\r\n        return y, h\r\n\r\n\r\nclass EncoderDecoder(nn.Module):\r\n\r\n    def __init__(self, hidden_size, input_size = 1, output_size = 1):\r\n        super(EncoderDecoder, self).__init__()\r\n        self.input_size = input_size\r\n        self.hidden_size = hidden_size\r\n\r\n        self.encoder = Encoder(input_size = input_size, hidden_size = hidden_size)\r\n        self.decoder = Decoder(input_size = input_size, hidden_size = hidden_size, output_size = output_size)\r\n\r\n    def train_model(\r\n            self, train, target, epochs, target_len, method = 'recursive',\r\n            tfr = 0.5, lr = 0.01, dynamic_tf = False\r\n    ):\r\n        losses = np.full(epochs, np.nan)\r\n        optimizer = optim.Adam(self.parameters(), lr = lr)\r\n        criterion = nn.MSELoss()\r\n\r\n        for e in range(epochs):\r\n            predicted = torch.zeros(target_len, train.shape[1], train.shape[2])\r\n            optimizer.zero_grad()\r\n            _, enc_h = self.encoder(train)\r\n\r\n            dec_in = train[-1, :, :]\r\n            dec_h = enc_h\r\n\r\n            if method == 'recursive':\r\n                for t in range(target_len):\r\n                    dec_out, dec_h = self.decoder(dec_in, dec_h)\r\n                    predicted[t] = dec_out\r\n                    dec_in = dec_out\r\n\r\n            if method == 'teacher_forcing':\r\n                # use teacher forcing\r\n                if random.random() < tfr:\r\n                    for t in range(target_len):\r\n                        dec_out, dec_h = self.decoder(dec_in, dec_h)\r\n                        predicted[t] = dec_out\r\n                        dec_in = target[t, :, :]\r\n                # predict recursively\r\n                else:\r\n                    for t in range(target_len):\r\n                        dec_out, dec_h = self.decoder(dec_in, dec_h)\r\n                        predicted[t] = dec_out\r\n                        dec_in = dec_out\r\n\r\n            if method == 'mixed_teacher_forcing':\r\n                # predict using mixed teacher forcing\r\n                for t in range(target_len):\r\n                    dec_out, dec_h = self.decoder(dec_in, dec_h)\r\n                    predicted[t] = dec_out\r\n                    # predict with teacher forcing\r\n                    if random.random() < tfr:\r\n                        dec_in = target[t, :, :]\r\n                    # predict recursively\r\n                    else:\r\n                        dec_in = dec_out\r\n\r\n            loss = criterion(predicted, target)\r\n            loss.backward()\r\n            optimizer.step()\r\n\r\n            losses[e] = loss.item()\r\n\r\n            if e % 10 == 0:\r\n                print(f'Epoch {e}/{epochs}: {round(loss.item(), 4)}')\r\n\r\n            # dynamic teacher forcing\r\n            if dynamic_tf and tfr > 0:\r\n                tfr = tfr - 0.02\r\n\r\n        return losses\r\n\r\n    def predict(self, x, target_len):\r\n        y = torch.zeros(target_len, x.shape[1], x.shape[2])\r\n\r\n        _, enc_h = self.encoder(x)\r\n        dec_in = x[-1, :, :]\r\n        dec_h = enc_h\r\n\r\n        for t in range(target_len):\r\n            dec_out, dec_h = self.decoder(dec_in, dec_h)\r\n            y[t] = dec_out\r\n            dec_in = dec_out\r\n\r\n        return y\r\n\r\nBut when I tried to train the model using: \r\n\r\n`model = EncoderDecoder(hidden_size = hidden_size)\r\nmodel.train()\r\nmodel.train_model(x_train, y_train, epochs, ts_target_len,\r\n                  method = 'mixed_teacher_forcing',\r\n                  tfr = .05, lr = .005)`\r\n\r\nI encountered error like this :\r\n\r\n`     45     for b in range(tensor.size(1)):\r\n`\r\n`---> 46         if washout[b] > 0:\r\n`\r\n`     47             tmp = tensor[washout[b]:seq_lengths[b], b].clone()`\r\n`\r\n     48             tensor[:seq_lengths[b] - washout[b], b] = tmp`\r\nHave you got any idea why the error occurred ?","reactions":{"url":"https://api.github.com/repos/stefanonardo/pytorch-esn/issues/comments/1007119640/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"RidhwanAmin","id":53149484,"node_id":"MDQ6VXNlcjUzMTQ5NDg0","avatar_url":"https://avatars.githubusercontent.com/u/53149484?v=4","gravatar_id":"","url":"https://api.github.com/users/RidhwanAmin","html_url":"https://github.com/RidhwanAmin","followers_url":"https://api.github.com/users/RidhwanAmin/followers","following_url":"https://api.github.com/users/RidhwanAmin/following{/other_user}","gists_url":"https://api.github.com/users/RidhwanAmin/gists{/gist_id}","starred_url":"https://api.github.com/users/RidhwanAmin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RidhwanAmin/subscriptions","organizations_url":"https://api.github.com/users/RidhwanAmin/orgs","repos_url":"https://api.github.com/users/RidhwanAmin/repos","events_url":"https://api.github.com/users/RidhwanAmin/events{/privacy}","received_events_url":"https://api.github.com/users/RidhwanAmin/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/stefanonardo/pytorch-esn/issues/comments/1199049389","html_url":"https://github.com/stefanonardo/pytorch-esn/issues/12#issuecomment-1199049389","issue_url":"https://api.github.com/repos/stefanonardo/pytorch-esn/issues/12","id":1199049389,"node_id":"IC_kwDOB438r85HeAqt","user":{"login":"RidhwanAmin","id":53149484,"node_id":"MDQ6VXNlcjUzMTQ5NDg0","avatar_url":"https://avatars.githubusercontent.com/u/53149484?v=4","gravatar_id":"","url":"https://api.github.com/users/RidhwanAmin","html_url":"https://github.com/RidhwanAmin","followers_url":"https://api.github.com/users/RidhwanAmin/followers","following_url":"https://api.github.com/users/RidhwanAmin/following{/other_user}","gists_url":"https://api.github.com/users/RidhwanAmin/gists{/gist_id}","starred_url":"https://api.github.com/users/RidhwanAmin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RidhwanAmin/subscriptions","organizations_url":"https://api.github.com/users/RidhwanAmin/orgs","repos_url":"https://api.github.com/users/RidhwanAmin/repos","events_url":"https://api.github.com/users/RidhwanAmin/events{/privacy}","received_events_url":"https://api.github.com/users/RidhwanAmin/received_events","type":"User","site_admin":false},"created_at":"2022-07-29T09:08:19Z","updated_at":"2022-07-29T09:08:19Z","author_association":"NONE","body":"I have some update on this issue. I have succeeded to use PyTorch-esn on encoder decoder for time series prediction. But the problem is that the accuracy is too low and I wonder what the reason behind this as I have done echo state network using Tensorflow but the accuracy is not bad as using pytorch. Here is my code :\r\n\r\n`import numpy as np\r\nimport random\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch import optim\r\n\r\n\r\nclass Encoder(nn.Module):\r\n\r\n    #def __init__(self, input_size, hidden_size, num_layers = 1):\r\n    def __init__(self, input_size, hidden_size, num_layers=2,\r\n                 nonlinearity='tanh', batch_first=False, leaking_rate=1,\r\n                 spectral_radius=0.9, w_ih_scale=1, density=1,):\r\n        super(Encoder, self).__init__()\r\n        self.input_size = input_size\r\n        self.hidden_size = hidden_size\r\n        self.num_layers = num_layers\r\n        if nonlinearity == 'tanh':\r\n            mode = 'RES_TANH'\r\n        elif nonlinearity == 'relu':\r\n            mode = 'RES_RELU'\r\n        elif nonlinearity == 'id':\r\n            mode = 'RES_ID'\r\n        else:\r\n            raise ValueError(\"Unknown nonlinearity '{}'\".format(nonlinearity))\r\n\r\n        self.batch_first = batch_first\r\n\r\n        self.leaking_rate = leaking_rate\r\n        self.spectral_radius = spectral_radius\r\n\r\n        if type(w_ih_scale) != torch.Tensor:\r\n            self.w_ih_scale = torch.ones(input_size + 1)\r\n            self.w_ih_scale *= w_ih_scale\r\n        else:\r\n            self.w_ih_scale = w_ih_scale\r\n\r\n        self.density = density\r\n\r\n        self.lstm = Reservoir(mode, input_size, hidden_size, num_layers,\r\n                                   leaking_rate, spectral_radius,\r\n                                   self.w_ih_scale, density,\r\n                                   batch_first=batch_first)\r\n\r\n        #self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers)\r\n        #self.lstm = ESN(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, output_size= input_size, readout_training='gd')\r\n\r\n    def forward(self, x):\r\n        #washout_rate = 0.05\r\n        #washout_list = [int(washout_rate * x.size(0))] * x.size(1)\r\n   \r\n        #flat = x.view(x.shape[0], x.shape[1], self.input_size)\r\n        \r\n        #out, h = self.lstm(flat, washout_list)\r\n\r\n        \r\n        flat = x.view(x.shape[0], x.shape[1], self.input_size)\r\n        output, hidden = self.lstm(flat)\r\n     \r\n        return output, hidden\r\n\r\n\r\nclass Decoder(nn.Module):\r\n\r\n    def __init__(self, input_size, hidden_size, output_size = 1, num_layers = 2):\r\n        super(Decoder, self).__init__()\r\n        self.input_size = input_size\r\n        self.hidden_size = hidden_size\r\n        self.num_layers = num_layers\r\n        self.output_size = output_size\r\n\r\n        #self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers)\r\n        self.lstm = ESN(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, output_size= output_size)\r\n        #self.linear = nn.Linear(input_size, output_size)\r\n\r\n    def forward(self, x, h):\r\n        washout_rate = 0.1\r\n        washout_list = [int(washout_rate * x.unsqueeze(0).size(0))] * x.unsqueeze(0).size(1)\r\n        \r\n\r\n        out, h = self.lstm(x.unsqueeze(0), washout_list, h)\r\n \r\n        #out_new = out.view(out.size(0), -1)\r\n\r\n        #y = self.linear(out.squeeze(0))\r\n        #y = self.linear(out_new)\r\n        #y = self.linear(out)\r\n        return out.squeeze(0), h\r\n\r\n\r\nclass EncoderDecoder(nn.Module):\r\n\r\n    def __init__(self, hidden_size, input_size = 1, output_size = 1):\r\n        super(EncoderDecoder, self).__init__()\r\n        self.input_size = input_size\r\n        self.hidden_size = hidden_size\r\n\r\n        self.encoder = Encoder(input_size = input_size, hidden_size = hidden_size)\r\n        self.decoder = Decoder(input_size = input_size, hidden_size = hidden_size, output_size = output_size)\r\n\r\n    def train_model(\r\n            self, train, target, epochs, target_len, method = 'recursive',\r\n            tfr = 0.5, lr = 0.01, dynamic_tf = False\r\n    ):\r\n        losses = np.full(epochs, np.nan)\r\n        optimizer = optim.Adam(self.parameters(), lr = lr)\r\n        criterion = nn.MSELoss()\r\n\r\n        for e in range(epochs):\r\n            predicted = torch.zeros(target_len, train.shape[1], train.shape[2])\r\n            optimizer.zero_grad()\r\n            _, enc_h = self.encoder(train)\r\n           \r\n\r\n            dec_in = train[-1, :, :]\r\n            dec_h = enc_h\r\n\r\n            if method == 'recursive':\r\n                for t in range(target_len):\r\n                    dec_out, dec_h = self.decoder(dec_in, dec_h)\r\n                  \r\n                    predicted[t] = dec_out\r\n                    dec_in = dec_out\r\n\r\n            if method == 'teacher_forcing':\r\n                # use teacher forcing\r\n                if random.random() < tfr:\r\n                    for t in range(target_len):\r\n                        dec_out, dec_h = self.decoder(dec_in, dec_h)\r\n                        predicted[t] = dec_out\r\n                        dec_in = target[t, :, :]\r\n                # predict recursively\r\n                else:\r\n                    for t in range(target_len):\r\n                        dec_out, dec_h = self.decoder(dec_in, dec_h)\r\n                        predicted[t] = dec_out\r\n                        dec_in = dec_out\r\n\r\n            if method == 'mixed_teacher_forcing':\r\n                # predict using mixed teacher forcing\r\n                for t in range(target_len):\r\n                    dec_out, dec_h = self.decoder(dec_in, dec_h)\r\n                    predicted[t] = dec_out\r\n                    # predict with teacher forcing\r\n                    if random.random() < tfr:\r\n                        dec_in = target[t, :, :]\r\n                    # predict recursively\r\n                    else:\r\n                        dec_in = dec_out\r\n\r\n            loss = criterion(predicted, target)\r\n            loss.backward()\r\n            optimizer.step()\r\n\r\n            losses[e] = loss.item()\r\n\r\n            if e % 10 == 0:\r\n                print(f'Epoch {e}/{epochs}: {round(loss.item(), 4)}')\r\n\r\n            # dynamic teacher forcing\r\n            if dynamic_tf and tfr > 0:\r\n                tfr = tfr - 0.02\r\n\r\n        return losses\r\n\r\n    def forward(self, x, target_len):\r\n        y = torch.zeros(target_len, x.shape[1], x.shape[2])\r\n\r\n        _, enc_h = self.encoder(x)\r\n        dec_in = x[-1, :, :]\r\n        dec_h = enc_h\r\n\r\n        for t in range(target_len):\r\n            dec_out, dec_h = self.decoder(dec_in, dec_h)\r\n            y[t] = dec_out\r\n            dec_in = dec_out\r\n\r\n        return y`\r\n\r\nI attached the whole code of encode decoder for time series forecasting :\r\n[https://colab.research.google.com/drive/1RL1L1b-5Fi7P9p-EOpzQ-w7mZRPK4nKm?usp=sharing](url)","reactions":{"url":"https://api.github.com/repos/stefanonardo/pytorch-esn/issues/comments/1199049389/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"RidhwanAmin","id":53149484,"node_id":"MDQ6VXNlcjUzMTQ5NDg0","avatar_url":"https://avatars.githubusercontent.com/u/53149484?v=4","gravatar_id":"","url":"https://api.github.com/users/RidhwanAmin","html_url":"https://github.com/RidhwanAmin","followers_url":"https://api.github.com/users/RidhwanAmin/followers","following_url":"https://api.github.com/users/RidhwanAmin/following{/other_user}","gists_url":"https://api.github.com/users/RidhwanAmin/gists{/gist_id}","starred_url":"https://api.github.com/users/RidhwanAmin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RidhwanAmin/subscriptions","organizations_url":"https://api.github.com/users/RidhwanAmin/orgs","repos_url":"https://api.github.com/users/RidhwanAmin/repos","events_url":"https://api.github.com/users/RidhwanAmin/events{/privacy}","received_events_url":"https://api.github.com/users/RidhwanAmin/received_events","type":"User","site_admin":false}}]