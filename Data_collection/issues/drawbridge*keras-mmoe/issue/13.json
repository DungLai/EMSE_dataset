{"url":"https://api.github.com/repos/drawbridge/keras-mmoe/issues/13","repository_url":"https://api.github.com/repos/drawbridge/keras-mmoe","labels_url":"https://api.github.com/repos/drawbridge/keras-mmoe/issues/13/labels{/name}","comments_url":"https://api.github.com/repos/drawbridge/keras-mmoe/issues/13/comments","events_url":"https://api.github.com/repos/drawbridge/keras-mmoe/issues/13/events","html_url":"https://github.com/drawbridge/keras-mmoe/issues/13","id":757858402,"node_id":"MDU6SXNzdWU3NTc4NTg0MDI=","number":13,"title":"Have you implemented this in pytorch","user":{"login":"tomtang110","id":33299522,"node_id":"MDQ6VXNlcjMzMjk5NTIy","avatar_url":"https://avatars.githubusercontent.com/u/33299522?v=4","gravatar_id":"","url":"https://api.github.com/users/tomtang110","html_url":"https://github.com/tomtang110","followers_url":"https://api.github.com/users/tomtang110/followers","following_url":"https://api.github.com/users/tomtang110/following{/other_user}","gists_url":"https://api.github.com/users/tomtang110/gists{/gist_id}","starred_url":"https://api.github.com/users/tomtang110/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tomtang110/subscriptions","organizations_url":"https://api.github.com/users/tomtang110/orgs","repos_url":"https://api.github.com/users/tomtang110/repos","events_url":"https://api.github.com/users/tomtang110/events{/privacy}","received_events_url":"https://api.github.com/users/tomtang110/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-12-06T06:19:30Z","updated_at":"2021-04-21T05:05:47Z","closed_at":"2021-04-21T05:05:47Z","author_association":"NONE","active_lock_reason":null,"body":"Hi\r\n\r\nI reimplemented your code in pytorch, I found a strange phenomenon, the auc of income is just 0.56 and the auc of marital is 0.96. I checked the detail and don't know why it does not work?\r\n\r\nHere is the model code:\r\n\r\n    class Model(nn.Module):\r\n        def __init__(self,config):\r\n            super(Model, self).__init__()\r\n\r\n        # accept_unit = config.field_size*config.embed_size\r\n        accept_unit = config.num_feature\r\n        self.expert_kernels = torch.nn.Parameter(torch.randn(accept_unit, config.units, config.num_experts, device=config.device),\r\n                                                 requires_grad=True)\r\n        self.gate_kernels = torch.nn.ParameterList(\r\n            [nn.Parameter(torch.randn(accept_unit, config.num_experts, device=config.device), requires_grad=True) for i in\r\n             range(config.num_tasks)])\r\n\r\n        self.expert_kernels_bias = torch.nn.Parameter(torch.randn(config.units, config.num_experts, device=config.device),\r\n                                                      requires_grad=True)\r\n        self.gate_kernels_bias = torch.nn.ParameterList(\r\n            [torch.nn.Parameter(torch.randn(config.num_experts, device=config.device), requires_grad=True) for i in range(config.num_tasks)])\r\n\r\n        self.output_layer = nn.ModuleList([nn.Sequential(\r\n            nn.Linear(config.units,config.hidden_units),\r\n            nn.ReLU(),\r\n            nn.Linear(config.hidden_units,unit),\r\n        )\r\n            for unit in config.label_dict\r\n        ])\r\n\r\n        self.expert_activation = nn.ReLU()\r\n\r\n        # self.embedding_layer = nn.Embedding(config.num_feature,config.embed_size)\r\n\r\n    def forward(self,x):\r\n        gate_outputs = []\r\n        final_outputs = []\r\n        # xi =x[0]\r\n        # xv = x[1]\r\n\r\n        # self.embeddings = self.embedding_layer(xi)\r\n        # feat_value = xv.view(-1,xv.size(1),1)\r\n        #\r\n        # self.embeddings = feat_value * self.embeddings\r\n        # self.embeddings = self.embeddings.view(xv.size(0),-1)\r\n\r\n\r\n        expert_outputs = torch.einsum(\"ab,bcd->acd\", (x, self.expert_kernels))\r\n        expert_outputs += self.expert_kernels_bias\r\n        expert_outputs = self.expert_activation(expert_outputs)\r\n\r\n        for index, gate_kernel in enumerate(self.gate_kernels):\r\n            gate_output = torch.einsum(\"ab,bc->ac\", (x, gate_kernel))\r\n            gate_output += self.gate_kernels_bias[index]\r\n            gate_output = nn.Softmax(dim=-1)(gate_output)\r\n            gate_outputs.append(gate_output)\r\n\r\n        for gate_output in gate_outputs:\r\n            expanded_gate_output = torch.unsqueeze(gate_output, 1)\r\n            weighted_expert_output = expert_outputs * expanded_gate_output.expand_as(expert_outputs)\r\n            final_outputs.append(torch.sum(weighted_expert_output, 2))\r\n\r\n        output_layers = []\r\n        for i,output in enumerate(final_outputs):\r\n            output_layers.append(torch.sigmoid(self.output_layer[i](output)))\r\n\r\n        return output_layers","closed_by":{"login":"alvin319","id":909071,"node_id":"MDQ6VXNlcjkwOTA3MQ==","avatar_url":"https://avatars.githubusercontent.com/u/909071?v=4","gravatar_id":"","url":"https://api.github.com/users/alvin319","html_url":"https://github.com/alvin319","followers_url":"https://api.github.com/users/alvin319/followers","following_url":"https://api.github.com/users/alvin319/following{/other_user}","gists_url":"https://api.github.com/users/alvin319/gists{/gist_id}","starred_url":"https://api.github.com/users/alvin319/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alvin319/subscriptions","organizations_url":"https://api.github.com/users/alvin319/orgs","repos_url":"https://api.github.com/users/alvin319/repos","events_url":"https://api.github.com/users/alvin319/events{/privacy}","received_events_url":"https://api.github.com/users/alvin319/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/drawbridge/keras-mmoe/issues/13/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/drawbridge/keras-mmoe/issues/13/timeline","performed_via_github_app":null,"state_reason":"completed"}