[{"id":5021598888,"node_id":"MDEzOkFzc2lnbmVkRXZlbnQ1MDIxNTk4ODg4","url":"https://api.github.com/repos/intel/dffml/issues/events/5021598888","actor":{"login":"pdxjohnny","id":5950433,"node_id":"MDQ6VXNlcjU5NTA0MzM=","avatar_url":"https://avatars.githubusercontent.com/u/5950433?v=4","gravatar_id":"","url":"https://api.github.com/users/pdxjohnny","html_url":"https://github.com/pdxjohnny","followers_url":"https://api.github.com/users/pdxjohnny/followers","following_url":"https://api.github.com/users/pdxjohnny/following{/other_user}","gists_url":"https://api.github.com/users/pdxjohnny/gists{/gist_id}","starred_url":"https://api.github.com/users/pdxjohnny/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pdxjohnny/subscriptions","organizations_url":"https://api.github.com/users/pdxjohnny/orgs","repos_url":"https://api.github.com/users/pdxjohnny/repos","events_url":"https://api.github.com/users/pdxjohnny/events{/privacy}","received_events_url":"https://api.github.com/users/pdxjohnny/received_events","type":"User","site_admin":false},"event":"assigned","commit_id":null,"commit_url":null,"created_at":"2021-07-14T19:28:56Z","assignee":{"login":"pdxjohnny","id":5950433,"node_id":"MDQ6VXNlcjU5NTA0MzM=","avatar_url":"https://avatars.githubusercontent.com/u/5950433?v=4","gravatar_id":"","url":"https://api.github.com/users/pdxjohnny","html_url":"https://github.com/pdxjohnny","followers_url":"https://api.github.com/users/pdxjohnny/followers","following_url":"https://api.github.com/users/pdxjohnny/following{/other_user}","gists_url":"https://api.github.com/users/pdxjohnny/gists{/gist_id}","starred_url":"https://api.github.com/users/pdxjohnny/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pdxjohnny/subscriptions","organizations_url":"https://api.github.com/users/pdxjohnny/orgs","repos_url":"https://api.github.com/users/pdxjohnny/repos","events_url":"https://api.github.com/users/pdxjohnny/events{/privacy}","received_events_url":"https://api.github.com/users/pdxjohnny/received_events","type":"User","site_admin":false},"performed_via_github_app":null},{"url":"https://api.github.com/repos/intel/dffml/issues/comments/880211641","html_url":"https://github.com/intel/dffml/issues/1163#issuecomment-880211641","issue_url":"https://api.github.com/repos/intel/dffml/issues/1163","id":880211641,"node_id":"MDEyOklzc3VlQ29tbWVudDg4MDIxMTY0MQ==","user":{"login":"pdxjohnny","id":5950433,"node_id":"MDQ6VXNlcjU5NTA0MzM=","avatar_url":"https://avatars.githubusercontent.com/u/5950433?v=4","gravatar_id":"","url":"https://api.github.com/users/pdxjohnny","html_url":"https://github.com/pdxjohnny","followers_url":"https://api.github.com/users/pdxjohnny/followers","following_url":"https://api.github.com/users/pdxjohnny/following{/other_user}","gists_url":"https://api.github.com/users/pdxjohnny/gists{/gist_id}","starred_url":"https://api.github.com/users/pdxjohnny/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pdxjohnny/subscriptions","organizations_url":"https://api.github.com/users/pdxjohnny/orgs","repos_url":"https://api.github.com/users/pdxjohnny/repos","events_url":"https://api.github.com/users/pdxjohnny/events{/privacy}","received_events_url":"https://api.github.com/users/pdxjohnny/received_events","type":"User","site_admin":false},"created_at":"2021-07-14T21:09:09Z","updated_at":"2021-07-14T22:47:46Z","author_association":"MEMBER","body":"Here's what I've got so far\r\n\r\n```diff\r\ndiff --git a/dffml/df/subprocess.py b/dffml/df/subprocess.py\r\nnew file mode 100644\r\nindex 000000000..38f2dc3cb\r\n--- /dev/null\r\n+++ b/dffml/df/subprocess.py\r\n@@ -0,0 +1,256 @@\r\n+import io\r\n+import abc\r\n+import copy\r\n+import asyncio\r\n+import secrets\r\n+import inspect\r\n+import itertools\r\n+import traceback\r\n+import subprocess\r\n+import concurrent.futures\r\n+from itertools import product, chain\r\n+from contextlib import asynccontextmanager, AsyncExitStack, ExitStack\r\n+from typing import (\r\n+    AsyncIterator,\r\n+    Dict,\r\n+    List,\r\n+    Tuple,\r\n+    Any,\r\n+    NamedTuple,\r\n+    Union,\r\n+    Optional,\r\n+    Set,\r\n+    Callable,\r\n+)\r\n+\r\n+from .exceptions import (\r\n+    ContextNotPresent,\r\n+    DefinitionNotInContext,\r\n+    ValidatorMissing,\r\n+    MultipleAncestorsFoundError,\r\n+)\r\n+from .types import (\r\n+    Input,\r\n+    Parameter,\r\n+    Definition,\r\n+    Operation,\r\n+    Stage,\r\n+    DataFlow,\r\n+)\r\n+from .base import (\r\n+    BaseConfig,\r\n+    OperationImplementation,\r\n+    OperationImplementationContext,\r\n+    OperationImplementationNotInstantiated,\r\n+    OperationImplementationNotInstantiable,\r\n+    BaseOperationImplementationNetworkContext,\r\n+    BaseOperationImplementationNetwork,\r\n+)\r\n+from .memory import (\r\n+    BaseMemoryDataFlowObject,\r\n+    MemoryOperationImplementationNetworkContext,\r\n+)\r\n+\r\n+from ..base import config, field\r\n+from ..plugins import inpath\r\n+from ..util.entrypoint import entrypoint\r\n+from ..util.asynchelper import concurrently\r\n+\r\n+\r\n+@config\r\n+class SubprocessOperationImplementationNetworkConfig:\r\n+    operations: Dict[str, OperationImplementation] = field(\r\n+        \"Operations to load on initialization\", default_factory=lambda: {},\r\n+    )\r\n+\r\n+\r\n+class SubprocessOperationImplementationContext(OperationImplementationContext):\r\n+    async def run(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\r\n+        # TODO Support for daemons? How might we do that? Need to think on this.\r\n+        cmd = [\r\n+            # Operation name is the command to run\r\n+            self.parent.op.name,\r\n+        ] + list(\r\n+            # Create arguments based on inputs in standard format (standard is\r\n+            # debatable, - vs. --, but this is what we'll go with for now)\r\n+            itertools.chain(\r\n+                *[[f\"--{key}\", value] for key, value in inputs.items()]\r\n+            )\r\n+        )\r\n+        # TODO Implement configurable cwd\r\n+        kwargs = {\r\n+            \"stdin\": None,\r\n+            \"stdout\": asyncio.subprocess.PIPE,\r\n+            \"stderr\": asyncio.subprocess.PIPE,\r\n+            # TODO Configurability of start_new_session\r\n+            \"start_new_session\": True,\r\n+        }\r\n+        # Run command\r\n+        self.logger.debug(f\"Running {cmd}, {kwargs}\")\r\n+        proc = await asyncio.create_subprocess_exec(*cmd, **kwargs)\r\n+        # Capture stdout and stderr\r\n+        output = {\r\n+            \"stdout\": b\"\",\r\n+            \"stderr\": b\"\",\r\n+        }\r\n+        # Read output and watch for process return\r\n+        # TODO Configurability of readline vs. reading some number of bytes for\r\n+        # commands with binary outputs\r\n+        work = {\r\n+            asyncio.create_task(proc.stdout.readline()): \"stdout.readline\",\r\n+            asyncio.create_task(proc.stderr.readline()): \"stderr.readline\",\r\n+            asyncio.create_task(proc.wait()): \"wait\",\r\n+        }\r\n+        async for event, result in concurrently(work):\r\n+            self.logger.debug(f\"{event}: {type(result)}: {result}\")\r\n+            if event.endswith(\"readline\"):\r\n+                # Log line read on stderr output\r\n+                # TODO Make this configurable\r\n+                if event == \"stderr.readline\":\r\n+                    self.logger.debug(\r\n+                        f\"{event}: {result.decode(errors='ignore').rstrip()}\"\r\n+                    )\r\n+                # Split the event on ., index 0 will be \"stdout\" or \"stderr\".\r\n+                # See work dict values for event names.\r\n+                stdout_or_stderr = event.split(\".\")[0]\r\n+                # Append to output\r\n+                output[stdout_or_stderr] += result\r\n+                # If the child closes an fd, then output will empty. Do not\r\n+                # attempt to read if this is the case\r\n+                if result:\r\n+                    # Read another line if fd is not closed\r\n+                    coro = getattr(proc, stdout_or_stderr).readline()\r\n+                    task = asyncio.create_task(coro)\r\n+                    work[task] = event\r\n+            else:\r\n+                # When wait() returns process has exited\r\n+                break\r\n+        # TODO Add ability to treat non-zero return code as okay, i.e. don't\r\n+        # raise. An example of this is cve-bin-tool, which returns non-zero when\r\n+        # issues are found (as of 2.0 release). We should return the\r\n+        # proc.returncode when we do this too\r\n+        # Raise if the process exited with an error code (non-zero return code).\r\n+        self.logger.debug(\"proc.returncode: %s\", proc.returncode)\r\n+        if proc.returncode != 0:\r\n+            raise subprocess.CalledProcessError(\r\n+                proc.returncode,\r\n+                cmd,\r\n+                output=output[\"stdout\"],\r\n+                stderr=output[\"stderr\"],\r\n+            )\r\n+        # Return stdout of called process. Inspect the operation output to\r\n+        # determine what it should be called.\r\n+        return {list(self.parent.op.outputs.keys())[0]: output[\"stdout\"]}\r\n+\r\n+\r\n+class SubprocessOperationImplementation(OperationImplementation):\r\n+    CONTEXT = SubprocessOperationImplementationContext\r\n+\r\n+\r\n+class SubprocessOperationImplementationNetworkContext(\r\n+    MemoryOperationImplementationNetworkContext\r\n+):\r\n+    async def instantiable(\r\n+        self, operation: Operation, *, opimp: OperationImplementation = None\r\n+    ) -> bool:\r\n+        \"\"\"\r\n+        Looks for presence of binary on system\r\n+        \"\"\"\r\n+        # This is pure Python, so if we're given an operation implementation we\r\n+        # will be able to instantiate it and use it instead of our default\r\n+        # subprocess operation implementation.\r\n+        if opimp is not None:\r\n+            return True\r\n+        # If the binary is on the system that's all we can do to check. If it\r\n+        # is, we'll try to create a SubprocessOperationImplementation to execute\r\n+        # it.\r\n+        return inpath(operation.name)\r\n+\r\n+    async def instantiate(\r\n+        self,\r\n+        operation: Operation,\r\n+        config: BaseConfig,\r\n+        *,\r\n+        opimp: OperationImplementation = None,\r\n+    ) -> bool:\r\n+        \"\"\"\r\n+        Instantiate instance of SubprocessOperationImplementation for the given\r\n+        operation if a special instance is not given via ``opimp`` keyword\r\n+        argument.\r\n+        \"\"\"\r\n+        if opimp is None:\r\n+            if await self.instantiable(operation):\r\n+                opimp = SubprocessOperationImplementation\r\n+            else:\r\n+                raise OperationImplementationNotInstantiable(operation.name)\r\n+        # Set the correct instance_name\r\n+        opimp = copy.deepcopy(opimp)\r\n+        opimp.op = operation\r\n+        self.operations[\r\n+            operation.instance_name\r\n+        ] = await self._stack.enter_async_context(opimp(config))\r\n+\r\n+\r\n+@entrypoint(\"subprocess\")\r\n+class SubprocessOperationImplementationNetwork(\r\n+    BaseOperationImplementationNetwork, BaseMemoryDataFlowObject\r\n+):\r\n+    \"\"\"\r\n+    Instantiates instances of :py:class:`SubprocessOperationImplementation\r\n+    <dffml.df.subprocess.SubprocessOperationImplementation>` to handle the\r\n+    execution of operating system commands / binaries.\r\n+\r\n+    Examples\r\n+    --------\r\n+\r\n+    **run.py**\r\n+\r\n+    .. code-block:: python\r\n+        :test:\r\n+        :filepath: run.py\r\n+\r\n+        import dffml\r\n+        import dffml.noasync\r\n+\r\n+        import logging\r\n+        logging.basicConfig(level=logging.DEBUG)\r\n+\r\n+        echo_feed = dffml.Definition(name=\"echo.feed\", primitive=\"string\")\r\n+\r\n+        dataflow = dffml.DataFlow(\r\n+            operations={\r\n+                \"echo\": dffml.Operation(\r\n+                    name=\"echo\",\r\n+                    inputs={\r\n+                        \"feed\": echo_feed\r\n+                    },\r\n+                    outputs={\r\n+                        \"out\": dffml.Definition(name=\"echo.out\", primitive=\"bytes\"),\r\n+                    }\r\n+                )\r\n+            },\r\n+        )\r\n+\r\n+        for _ctx, results in dffml.noasync.run(\r\n+            dataflow,\r\n+            [\r\n+                dffml.Input(\r\n+                    value=\"face\",\r\n+                    definition=echo_feed,\r\n+                )\r\n+            ],\r\n+            orchestrator=dffml.MemoryOrchestrator(\r\n+                opimp_network=dffml.SubprocessOperationImplementationNetwork(),\r\n+            ),\r\n+        ):\r\n+            print(results)\r\n+\r\n+    .. code-block:: console\r\n+        :test:\r\n+\r\n+        $ python run.py\r\n+\r\n+    \"\"\"\r\n+\r\n+    CONTEXT = SubprocessOperationImplementationNetworkContext\r\n+    CONFIG = SubprocessOperationImplementationNetworkConfig\r\ndiff --git a/dffml/noasync.py b/dffml/noasync.py\r\nindex 4edba70a5..0c5f1e66a 100644\r\n--- a/dffml/noasync.py\r\n+++ b/dffml/noasync.py\r\n@@ -185,8 +185,47 @@ def run(*args, **kwargs):\r\n     \"\"\"\r\n     async_gen = high_level.run(*args, **kwargs).__aiter__()\r\n \r\n+    # We are running into a common issue.\r\n+    # In Linux, a process has signal handlers. The signal handler\r\n+    # in question right now is SIGCHLD. This signal is sent to a\r\n+    # process when a child of that process exits. subprocess starts\r\n+    # child processes. The process.wait() call has some internal\r\n+    # locking under the hood.\r\n+\r\n+    # Child processes are started by a\r\n+    # fork() and exec() pattern (google that read more).\r\n+    # Essentially what happens is we make a copy (fork()) of the\r\n+    # running process, and replace it with a new process (exec()).\r\n+\r\n+    # When we call asyncio.subprocess.Process.wait(), the internal\r\n+    # lock is taken, and somewhere, SIGCHID is being waited for.\r\n+    # I'm pretty sure this is all done through some sort of queue\r\n+    # system or list or something. Because if we don't have the\r\n+    # a ChildWatcher attached to our loop (which as you'll recall we\r\n+    # create here in dffml.noasync)\r\n     loop = asyncio.new_event_loop()\r\n \r\n+    # We have two options right now\r\n+    # 1. Use the main event loop viaasyncio.get_event_loop()\r\n+    # 2. Grab the existing asyncio hildwatcher and attach our loop to it\r\n+\r\n+    # I haven't been successful in doing either of these over the years,\r\n+    # 1. Sometimes there is no event loop, and get_event_loop() raises.\r\n+    #   - We could I suppose just create one, although I seem to remember\r\n+    #     there being an issue with that too.\r\n+    # 2. Not sure how to do this, let's try this first, since this re-uses an\r\n+    #    existing, probably correcly setup, ChildWatcher.\r\n+\r\n+    # Oh, oops, looks like this worked, I didn't mean to do this. lol. Wow, so\r\n+    # many years of confusion... I have a feeling this approach will fall\r\n+    # apart when the main test suite it run though, but let's give it a shot.\r\n+    watcher = asyncio.FastChildWatcher()\r\n+    # We probably need to check if there is an existing one and try to attach\r\n+    # that though, or at a minimum grab one if it exists and then set it back\r\n+    # when we're done.\r\n+    asyncio.set_child_watcher(watcher)\r\n+    watcher.attach_loop(loop)\r\n+\r\n     def cleanup():\r\n         loop.run_until_complete(loop.shutdown_asyncgens())\r\n         loop.close()\r\n```\r\n\r\n```console\r\n$ python -u -m unittest discover -v -k subprocess\r\ntest_consoletest (tests.test_docstrings.df_subprocess_SubprocessOperationImplementationNetwork) ...\r\nWriting {'root': '/home/johnsa1/Documents/python/dffml', 'docs': '/home/johnsa1/Documents/python/dffml/docs', 'cwd': '/tmp/tmpkbienyj2', 'stack': <contextlib.ExitStack object at 0x7f289836b810>, 'astack': <contextlib.AsyncExitStack object at 0x7f2898359c10>, 'daemons': {}, 'no_serialize': {'astack', 'daemons', 'stack'}} /tmp/tmpkbienyj2/run.py\r\nimport dffml\r\nimport dffml.noasync\r\n\r\nimport logging\r\nlogging.basicConfig(level=logging.DEBUG)\r\n\r\necho_feed = dffml.Definition(name=\"echo.feed\", primitive=\"string\")\r\n\r\ndataflow = dffml.DataFlow(\r\n    operations={\r\n        \"echo\": dffml.Operation(\r\n            name=\"echo\",\r\n            inputs={\r\n                \"feed\": echo_feed\r\n            },\r\n            outputs={\r\n                \"out\": dffml.Definition(name=\"echo.out\", primitive=\"bytes\"),\r\n            }\r\n        )\r\n    },\r\n)\r\n\r\nfor _ctx, results in dffml.noasync.run(\r\n    dataflow,\r\n    [\r\n        dffml.Input(\r\n            value=\"face\",\r\n            definition=echo_feed,\r\n        )\r\n    ],\r\n    orchestrator=dffml.MemoryOrchestrator(\r\n        opimp_network=dffml.SubprocessOperationImplementationNetwork(),\r\n    ),\r\n):\r\n    print(results)\r\n\r\n\r\nRunning {'root': '/home/johnsa1/Documents/python/dffml', 'docs': '/home/johnsa1/Documents/python/dffml/docs', 'cwd': '/tmp/tmpkbienyj2', 'stack': <contextlib.ExitStack object at 0x7f289836b810>, 'astack': <contextlib.AsyncExitStack object at 0x7f2898359c10>, 'daemons': {}, 'no_serialize': {'astack', 'daemons', 'stack'}} ConsoleCommand({'poll_until': False, 'compare_output': None, 'compare_output_imports': None, 'ignore_errors': False, 'daemon': None, 'cmd': ['python', 'run.py'], 'daemon_proc': None, 'replace': None, 'stdin': None, 'stdin_fileobj': None, 'stack': <contextlib.ExitStack object at 0x7f2898365310>})\r\n\r\n\r\nRunning ['/usr/bin/python3.7', 'run.py']\r\n\r\nDEBUG:dffml.SubprocessOperationImplementationNetwork:SubprocessOperationImplementationNetworkConfig(operations={})\r\nDEBUG:dffml.MemoryOperationImplementationNetwork:MemoryOperationImplementationNetworkConfig(operations={})\r\nDEBUG:dffml.MemoryInputNetwork:MemoryInputNetworkConfig()\r\nDEBUG:dffml.MemoryOperationNetwork:MemoryOperationNetworkConfig(operations=[])\r\nDEBUG:dffml.MemoryLockNetwork:MemoryLockNetworkConfig()\r\nDEBUG:dffml.MemoryKeyValueStore:MemoryKeyValueStoreConfig()\r\nDEBUG:dffml.MemoryRedundancyChecker:MemoryRedundancyCheckerConfig(kvstore=MemoryKeyValueStore(MemoryKeyValueStoreConfig()))\r\nDEBUG:dffml.MemoryOrchestrator:MemoryOrchestratorConfig(input_network=MemoryInputNetwork(MemoryInputNetworkConfig()), operation_network=MemoryOperationNetwork(MemoryOperationNetworkConfig(operations=[])), lock_network=MemoryLockNetwork(MemoryLockNetworkConfig()), opimp_network=SubprocessOperationImplementationNetwork(SubprocessOperationImplementationNetworkConfig(operations={})), rchecker=MemoryRedundancyChecker(MemoryRedundancyCheckerConfig(kvstore=MemoryKeyValueStore(MemoryKeyValueStoreConfig()))), max_ctxs=None)\r\nDEBUG:asyncio:Using selector: EpollSelector\r\nDEBUG:dffml.MemoryOrchestratorContext:Initializing dataflow: <dffml.df.types.DataFlow object at 0x7ff1e7fae690>\r\nDEBUG:dffml.MemoryOrchestratorContext:Instantiating operation implementation echo(echo) with base config\r\nDEBUG:dffml.SubprocessOperationImplementation:BaseConfig()\r\nDEBUG:dffml.MemoryOrchestratorContext:Running <dffml.df.types.DataFlow object at 0x7ff1e7fae690>: ([Input(value=face, definition=echo.feed)],)\r\nDEBUG:dffml.MemoryOrchestratorContext:Seeding dataflow with input_set: [Input(value=face, definition=echo.feed)]\r\nDEBUG:dffml.MemoryOrchestratorContext:kickstarting context: a0e14235c35446031256a61d48a325c6b1f1b77cb00f4909bcbdcbe77e366216\r\nDEBUG:dffml.SubprocessOperationImplementationNetworkContext:[DISPATCH] echo\r\nDEBUG:dffml.MemoryOrchestratorContext:[a0e14235c35446031256a61d48a325c6b1f1b77cb00f4909bcbdcbe77e366216]: dispatch operation: echo\r\nDEBUG:dffml.SubprocessOperationImplementationNetworkContext:---\r\nDEBUG:dffml.SubprocessOperationImplementationNetworkContext:Stage: PROCESSING: echo\r\nDEBUG:dffml.SubprocessOperationImplementationNetworkContext:Inputs: {'feed': 'face'}\r\nDEBUG:dffml.SubprocessOperationImplementationNetworkContext:Conditions: {}\r\nDEBUG:dffml.SubprocessOperationImplementationContext:Running ['echo', '--feed', 'face'], {'stdin': None, 'stdout': -1, 'stderr': -1, 'start_new_session': True}\r\nDEBUG:dffml.SubprocessOperationImplementationContext:stderr.readline: <class 'bytes'>: b''\r\nDEBUG:dffml.SubprocessOperationImplementationContext:stderr.readline:\r\nDEBUG:dffml.SubprocessOperationImplementationContext:stdout.readline: <class 'bytes'>: b'--feed face\\n'\r\nDEBUG:dffml.SubprocessOperationImplementationContext:wait: <class 'int'>: 0\r\nDEBUG:dffml.SubprocessOperationImplementationContext:proc.returncode: 0\r\nDEBUG:dffml.SubprocessOperationImplementationNetworkContext:Outputs: {'out': b'--feed face\\n'}\r\nDEBUG:dffml.SubprocessOperationImplementationNetworkContext:---\r\n{}\r\nDEBUG:dffml.MemoryOrchestratorContext:ctx.outstanding: -1\r\nok\r\n\r\n----------------------------------------------------------------------\r\nRan 1 test in 0.685s\r\n\r\nOK\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/intel/dffml/issues/comments/880211641/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"pdxjohnny","id":5950433,"node_id":"MDQ6VXNlcjU5NTA0MzM=","avatar_url":"https://avatars.githubusercontent.com/u/5950433?v=4","gravatar_id":"","url":"https://api.github.com/users/pdxjohnny","html_url":"https://github.com/pdxjohnny","followers_url":"https://api.github.com/users/pdxjohnny/followers","following_url":"https://api.github.com/users/pdxjohnny/following{/other_user}","gists_url":"https://api.github.com/users/pdxjohnny/gists{/gist_id}","starred_url":"https://api.github.com/users/pdxjohnny/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pdxjohnny/subscriptions","organizations_url":"https://api.github.com/users/pdxjohnny/orgs","repos_url":"https://api.github.com/users/pdxjohnny/repos","events_url":"https://api.github.com/users/pdxjohnny/events{/privacy}","received_events_url":"https://api.github.com/users/pdxjohnny/received_events","type":"User","site_admin":false}}]