{"url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/64","repository_url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch","labels_url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/64/labels{/name}","comments_url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/64/comments","events_url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/64/events","html_url":"https://github.com/ajbrock/BigGAN-PyTorch/issues/64","id":619897661,"node_id":"MDU6SXNzdWU2MTk4OTc2NjE=","number":64,"title":"cublas runtime error","user":{"login":"phymhan","id":6815830,"node_id":"MDQ6VXNlcjY4MTU4MzA=","avatar_url":"https://avatars.githubusercontent.com/u/6815830?v=4","gravatar_id":"","url":"https://api.github.com/users/phymhan","html_url":"https://github.com/phymhan","followers_url":"https://api.github.com/users/phymhan/followers","following_url":"https://api.github.com/users/phymhan/following{/other_user}","gists_url":"https://api.github.com/users/phymhan/gists{/gist_id}","starred_url":"https://api.github.com/users/phymhan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/phymhan/subscriptions","organizations_url":"https://api.github.com/users/phymhan/orgs","repos_url":"https://api.github.com/users/phymhan/repos","events_url":"https://api.github.com/users/phymhan/events{/privacy}","received_events_url":"https://api.github.com/users/phymhan/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-05-18T04:24:34Z","updated_at":"2020-05-18T04:24:34Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"First off, huge thanks to Andy for the PyTorch implementation! However, I encountered a cublas error after a few iterations:\r\nwhen using pytorch 1.5 with cuda 10.2 on two RTX 8000,\r\nFile \"BigGAN-PyTorch/layers.py\", line 40, in power_iteration\r\n    u = torch.matmul(v, W.t())\r\nRuntimeError: CUDA error: CUBLAS_STATUS_INTERNAL_ERROR when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`\r\n\r\nwhen using pytorch 1.0.1 with cuda 10.0,\r\nFile \"BigGAN-PyTorch/layers.py\", line 48, in power_iteration\r\n    svs += [torch.squeeze(torch.matmul(torch.matmul(v, W.t()), u.t()))]\r\nRuntimeError: cublas runtime error : the GPU program failed to execute at /opt/conda/conda-bld/pytorch_1549636813070/work/aten/src/THC/THCBlas.cu:258\r\n\r\nPS: with some modifications the error disappears, for example, using vanilla bce loss instead of hinge loss, or removing the linear layer.\r\n\r\nAny idea why this happens? Thanks a lot!","closed_by":null,"reactions":{"url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/64/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/64/timeline","performed_via_github_app":null,"state_reason":null}