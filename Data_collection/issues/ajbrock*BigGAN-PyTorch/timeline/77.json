[{"url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/comments/750892643","html_url":"https://github.com/ajbrock/BigGAN-PyTorch/issues/77#issuecomment-750892643","issue_url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/77","id":750892643,"node_id":"MDEyOklzc3VlQ29tbWVudDc1MDg5MjY0Mw==","user":{"login":"ajbrock","id":7751273,"node_id":"MDQ6VXNlcjc3NTEyNzM=","avatar_url":"https://avatars.githubusercontent.com/u/7751273?v=4","gravatar_id":"","url":"https://api.github.com/users/ajbrock","html_url":"https://github.com/ajbrock","followers_url":"https://api.github.com/users/ajbrock/followers","following_url":"https://api.github.com/users/ajbrock/following{/other_user}","gists_url":"https://api.github.com/users/ajbrock/gists{/gist_id}","starred_url":"https://api.github.com/users/ajbrock/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ajbrock/subscriptions","organizations_url":"https://api.github.com/users/ajbrock/orgs","repos_url":"https://api.github.com/users/ajbrock/repos","events_url":"https://api.github.com/users/ajbrock/events{/privacy}","received_events_url":"https://api.github.com/users/ajbrock/received_events","type":"User","site_admin":false},"created_at":"2020-12-24T14:06:46Z","updated_at":"2020-12-24T14:06:46Z","author_association":"OWNER","body":"1. Yep!\r\n2. Yep!\r\n3. FID is not a measure of generalization like a likelihood would be, it's a measure of similarity between two datasets. While some people prefer to use FID relative to the validation set, this doesn't really provide any meaningful \"defense against overfitting\" like a likelihood or test accuracy would. I'd expect FID against the val set to just be slightly lower but to not result in any meaningful change in trends for model or sample comparison.","reactions":{"url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/comments/750892643/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"ajbrock","id":7751273,"node_id":"MDQ6VXNlcjc3NTEyNzM=","avatar_url":"https://avatars.githubusercontent.com/u/7751273?v=4","gravatar_id":"","url":"https://api.github.com/users/ajbrock","html_url":"https://github.com/ajbrock","followers_url":"https://api.github.com/users/ajbrock/followers","following_url":"https://api.github.com/users/ajbrock/following{/other_user}","gists_url":"https://api.github.com/users/ajbrock/gists{/gist_id}","starred_url":"https://api.github.com/users/ajbrock/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ajbrock/subscriptions","organizations_url":"https://api.github.com/users/ajbrock/orgs","repos_url":"https://api.github.com/users/ajbrock/repos","events_url":"https://api.github.com/users/ajbrock/events{/privacy}","received_events_url":"https://api.github.com/users/ajbrock/received_events","type":"User","site_admin":false}},{"id":4147523596,"node_id":"MDExOkNsb3NlZEV2ZW50NDE0NzUyMzU5Ng==","url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/events/4147523596","actor":{"login":"ajbrock","id":7751273,"node_id":"MDQ6VXNlcjc3NTEyNzM=","avatar_url":"https://avatars.githubusercontent.com/u/7751273?v=4","gravatar_id":"","url":"https://api.github.com/users/ajbrock","html_url":"https://github.com/ajbrock","followers_url":"https://api.github.com/users/ajbrock/followers","following_url":"https://api.github.com/users/ajbrock/following{/other_user}","gists_url":"https://api.github.com/users/ajbrock/gists{/gist_id}","starred_url":"https://api.github.com/users/ajbrock/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ajbrock/subscriptions","organizations_url":"https://api.github.com/users/ajbrock/orgs","repos_url":"https://api.github.com/users/ajbrock/repos","events_url":"https://api.github.com/users/ajbrock/events{/privacy}","received_events_url":"https://api.github.com/users/ajbrock/received_events","type":"User","site_admin":false},"event":"closed","commit_id":null,"commit_url":null,"created_at":"2020-12-24T14:06:46Z","state_reason":null,"performed_via_github_app":null},{"url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/comments/757483986","html_url":"https://github.com/ajbrock/BigGAN-PyTorch/issues/77#issuecomment-757483986","issue_url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/77","id":757483986,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzQ4Mzk4Ng==","user":{"login":"AlexanderMath","id":8614529,"node_id":"MDQ6VXNlcjg2MTQ1Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/8614529?v=4","gravatar_id":"","url":"https://api.github.com/users/AlexanderMath","html_url":"https://github.com/AlexanderMath","followers_url":"https://api.github.com/users/AlexanderMath/followers","following_url":"https://api.github.com/users/AlexanderMath/following{/other_user}","gists_url":"https://api.github.com/users/AlexanderMath/gists{/gist_id}","starred_url":"https://api.github.com/users/AlexanderMath/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AlexanderMath/subscriptions","organizations_url":"https://api.github.com/users/AlexanderMath/orgs","repos_url":"https://api.github.com/users/AlexanderMath/repos","events_url":"https://api.github.com/users/AlexanderMath/events{/privacy}","received_events_url":"https://api.github.com/users/AlexanderMath/received_events","type":"User","site_admin":false},"created_at":"2021-01-10T14:20:17Z","updated_at":"2021-01-10T14:21:28Z","author_association":"NONE","body":"> FID is not a measure of generalization like a likelihood would be ...\r\n\r\n[Newer models](https://github.com/NVlabs/stylegan2-ada/issues/53) seem to attain ```fid(model, train) < fid(train, val)```, i.e., model and training samples are closer to each other than training and validation samples. I fail to see why this is not indicative of overfitting. \r\n\r\nAs scientists, we hypothesize our model generalize, then attempt to falsify the generalization hypothesis using a test set. If FID allow us to falsify the generalization hypothesis, I fail to see why it isn't a meaningful measure of overfitting. ","reactions":{"url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/comments/757483986/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"AlexanderMath","id":8614529,"node_id":"MDQ6VXNlcjg2MTQ1Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/8614529?v=4","gravatar_id":"","url":"https://api.github.com/users/AlexanderMath","html_url":"https://github.com/AlexanderMath","followers_url":"https://api.github.com/users/AlexanderMath/followers","following_url":"https://api.github.com/users/AlexanderMath/following{/other_user}","gists_url":"https://api.github.com/users/AlexanderMath/gists{/gist_id}","starred_url":"https://api.github.com/users/AlexanderMath/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AlexanderMath/subscriptions","organizations_url":"https://api.github.com/users/AlexanderMath/orgs","repos_url":"https://api.github.com/users/AlexanderMath/repos","events_url":"https://api.github.com/users/AlexanderMath/events{/privacy}","received_events_url":"https://api.github.com/users/AlexanderMath/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/comments/757494817","html_url":"https://github.com/ajbrock/BigGAN-PyTorch/issues/77#issuecomment-757494817","issue_url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/77","id":757494817,"node_id":"MDEyOklzc3VlQ29tbWVudDc1NzQ5NDgxNw==","user":{"login":"ajbrock","id":7751273,"node_id":"MDQ6VXNlcjc3NTEyNzM=","avatar_url":"https://avatars.githubusercontent.com/u/7751273?v=4","gravatar_id":"","url":"https://api.github.com/users/ajbrock","html_url":"https://github.com/ajbrock","followers_url":"https://api.github.com/users/ajbrock/followers","following_url":"https://api.github.com/users/ajbrock/following{/other_user}","gists_url":"https://api.github.com/users/ajbrock/gists{/gist_id}","starred_url":"https://api.github.com/users/ajbrock/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ajbrock/subscriptions","organizations_url":"https://api.github.com/users/ajbrock/orgs","repos_url":"https://api.github.com/users/ajbrock/repos","events_url":"https://api.github.com/users/ajbrock/events{/privacy}","received_events_url":"https://api.github.com/users/ajbrock/received_events","type":"User","site_admin":false},"created_at":"2021-01-10T15:29:45Z","updated_at":"2021-01-10T15:29:45Z","author_association":"OWNER","body":"The issue is that FID is only comparing a set of samples generated by your model to some other set of samples, which, simply doesn't say anything about generalization.  A reasonably appropriate  test (and a topic which much research has pursued but without a huge amount of success) would be to invert the model and try to find the nearest point z which minimizes p(x|z), then evaluate the likelihood p(z). This has its own set of flaws (typically you can't invert the model analytically so you're minimizing a reconstruction loss with SGD, which is of course quite fraught) but it will at least tell you \"can my model 'explain away' this new sample to some degree?\"\r\n\r\nNote also that it's important to remember that in general just because a model has something akin to \"lower training loss than validation loss\" does not mean that the model has overfit. It's a common fallacy that the generalization gap is always indicative of overfitting, and I think that's going to be especially misleading when looking at a measure like FID which compares bulk statistics in a very particular feature space.\r\n\r\nOne interesting experiment might be to measure the triplets of FID(model, train), FID(model, val), FID(train, val) for a flow and compare the train and test likelihood for this model as you intentionally overfit it (remove regularization, etc). While you'll likely see that FID(model, train) < FID(model, val) whether or not this will be consistently correlated with L_train vs L_test is a whole nother question :)\r\n\r\nI'm not saying these models aren't overfitting, for the record--GANs in particular operate pretty much exclusively in the \"weaponized overfitting\" regime. FID, however, is not really the metric you should be using to try and measure this, and the difference between reporting FID(model, train) or FID(model, val) is going to be a placebo that isn't actually providing what insights one might hope it would provide.","reactions":{"url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/comments/757494817/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"ajbrock","id":7751273,"node_id":"MDQ6VXNlcjc3NTEyNzM=","avatar_url":"https://avatars.githubusercontent.com/u/7751273?v=4","gravatar_id":"","url":"https://api.github.com/users/ajbrock","html_url":"https://github.com/ajbrock","followers_url":"https://api.github.com/users/ajbrock/followers","following_url":"https://api.github.com/users/ajbrock/following{/other_user}","gists_url":"https://api.github.com/users/ajbrock/gists{/gist_id}","starred_url":"https://api.github.com/users/ajbrock/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ajbrock/subscriptions","organizations_url":"https://api.github.com/users/ajbrock/orgs","repos_url":"https://api.github.com/users/ajbrock/repos","events_url":"https://api.github.com/users/ajbrock/events{/privacy}","received_events_url":"https://api.github.com/users/ajbrock/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/comments/757952648","html_url":"https://github.com/ajbrock/BigGAN-PyTorch/issues/77#issuecomment-757952648","issue_url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/77","id":757952648,"node_id":"MDEyOklzc3VlQ29tbWVudDc1Nzk1MjY0OA==","user":{"login":"AlexanderMath","id":8614529,"node_id":"MDQ6VXNlcjg2MTQ1Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/8614529?v=4","gravatar_id":"","url":"https://api.github.com/users/AlexanderMath","html_url":"https://github.com/AlexanderMath","followers_url":"https://api.github.com/users/AlexanderMath/followers","following_url":"https://api.github.com/users/AlexanderMath/following{/other_user}","gists_url":"https://api.github.com/users/AlexanderMath/gists{/gist_id}","starred_url":"https://api.github.com/users/AlexanderMath/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AlexanderMath/subscriptions","organizations_url":"https://api.github.com/users/AlexanderMath/orgs","repos_url":"https://api.github.com/users/AlexanderMath/repos","events_url":"https://api.github.com/users/AlexanderMath/events{/privacy}","received_events_url":"https://api.github.com/users/AlexanderMath/received_events","type":"User","site_admin":false},"created_at":"2021-01-11T13:31:30Z","updated_at":"2021-01-11T13:53:51Z","author_association":"NONE","body":"Thanks for taking the time to answer. \r\n\r\n> The issue is that FID is only **comparing a set of samples generated by your model to some other set of samples**, which, simply doesn't say anything about generalization.\r\n\r\nI think we mean different things by generalization. By generalization error, I mean some notion of difference between the model distribution <img src=\"https://render.githubusercontent.com/render/math?math=P_{model}\"> and data distribution <img src=\"https://render.githubusercontent.com/render/math?math=P_{data}\">. This notion could be anything from Wasserstein to f-divergences like KL or JS. But Wasserstein [1] and all f-divergences [2] can be approximated by **comparing a set of samples generated by model <img src=\"https://render.githubusercontent.com/render/math?math=P_{model}\"> to  some other set of samples <img src=\"https://render.githubusercontent.com/render/math?math=P_{data}\">**. \r\n\r\nIn other words. Sampling can be used to approximate generalization error. I therefore don't see why a reliance on sampling implies that FID can't say anything about generalization. \r\n\r\n**Question 1.** Do you mean something different by generalization? \r\n\r\nI wrote comments and questions to your entire message, but I think it's best to first post them when we settle on the above. \r\n\r\n[1] use kantorovich-rubinstein duality as done in wgan https://arxiv.org/abs/1701.07875\r\n[2] use variational divergence estimation as done in fgan https://arxiv.org/pdf/1606.00709\r\n","reactions":{"url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/comments/757952648/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"AlexanderMath","id":8614529,"node_id":"MDQ6VXNlcjg2MTQ1Mjk=","avatar_url":"https://avatars.githubusercontent.com/u/8614529?v=4","gravatar_id":"","url":"https://api.github.com/users/AlexanderMath","html_url":"https://github.com/AlexanderMath","followers_url":"https://api.github.com/users/AlexanderMath/followers","following_url":"https://api.github.com/users/AlexanderMath/following{/other_user}","gists_url":"https://api.github.com/users/AlexanderMath/gists{/gist_id}","starred_url":"https://api.github.com/users/AlexanderMath/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AlexanderMath/subscriptions","organizations_url":"https://api.github.com/users/AlexanderMath/orgs","repos_url":"https://api.github.com/users/AlexanderMath/repos","events_url":"https://api.github.com/users/AlexanderMath/events{/privacy}","received_events_url":"https://api.github.com/users/AlexanderMath/received_events","type":"User","site_admin":false}}]