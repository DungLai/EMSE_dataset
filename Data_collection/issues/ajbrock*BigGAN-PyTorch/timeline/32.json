[{"url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/comments/502065265","html_url":"https://github.com/ajbrock/BigGAN-PyTorch/issues/32#issuecomment-502065265","issue_url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/32","id":502065265,"node_id":"MDEyOklzc3VlQ29tbWVudDUwMjA2NTI2NQ==","user":{"login":"ajbrock","id":7751273,"node_id":"MDQ6VXNlcjc3NTEyNzM=","avatar_url":"https://avatars.githubusercontent.com/u/7751273?v=4","gravatar_id":"","url":"https://api.github.com/users/ajbrock","html_url":"https://github.com/ajbrock","followers_url":"https://api.github.com/users/ajbrock/followers","following_url":"https://api.github.com/users/ajbrock/following{/other_user}","gists_url":"https://api.github.com/users/ajbrock/gists{/gist_id}","starred_url":"https://api.github.com/users/ajbrock/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ajbrock/subscriptions","organizations_url":"https://api.github.com/users/ajbrock/orgs","repos_url":"https://api.github.com/users/ajbrock/repos","events_url":"https://api.github.com/users/ajbrock/events{/privacy}","received_events_url":"https://api.github.com/users/ajbrock/received_events","type":"User","site_admin":false},"created_at":"2019-06-14T10:56:42Z","updated_at":"2019-06-14T10:56:42Z","author_association":"OWNER","body":"I'd recommend either (a) selecting your own embeddings if you have them a priori, (b) selecting the two imagenet classes which are closest to your dataset classes [or perhaps interpolating between several classes if you feel adventurous] or (c) initializing the embeddings from scratch. There are almost certainly other strategies one could come up with though, don't let these limit you.","reactions":{"url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/comments/502065265/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"ajbrock","id":7751273,"node_id":"MDQ6VXNlcjc3NTEyNzM=","avatar_url":"https://avatars.githubusercontent.com/u/7751273?v=4","gravatar_id":"","url":"https://api.github.com/users/ajbrock","html_url":"https://github.com/ajbrock","followers_url":"https://api.github.com/users/ajbrock/followers","following_url":"https://api.github.com/users/ajbrock/following{/other_user}","gists_url":"https://api.github.com/users/ajbrock/gists{/gist_id}","starred_url":"https://api.github.com/users/ajbrock/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ajbrock/subscriptions","organizations_url":"https://api.github.com/users/ajbrock/orgs","repos_url":"https://api.github.com/users/ajbrock/repos","events_url":"https://api.github.com/users/ajbrock/events{/privacy}","received_events_url":"https://api.github.com/users/ajbrock/received_events","type":"User","site_admin":false}},{"id":2413311658,"node_id":"MDExOkNsb3NlZEV2ZW50MjQxMzMxMTY1OA==","url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/events/2413311658","actor":{"login":"ajbrock","id":7751273,"node_id":"MDQ6VXNlcjc3NTEyNzM=","avatar_url":"https://avatars.githubusercontent.com/u/7751273?v=4","gravatar_id":"","url":"https://api.github.com/users/ajbrock","html_url":"https://github.com/ajbrock","followers_url":"https://api.github.com/users/ajbrock/followers","following_url":"https://api.github.com/users/ajbrock/following{/other_user}","gists_url":"https://api.github.com/users/ajbrock/gists{/gist_id}","starred_url":"https://api.github.com/users/ajbrock/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ajbrock/subscriptions","organizations_url":"https://api.github.com/users/ajbrock/orgs","repos_url":"https://api.github.com/users/ajbrock/repos","events_url":"https://api.github.com/users/ajbrock/events{/privacy}","received_events_url":"https://api.github.com/users/ajbrock/received_events","type":"User","site_admin":false},"event":"closed","commit_id":null,"commit_url":null,"created_at":"2019-06-14T10:56:43Z","state_reason":null,"performed_via_github_app":null},{"url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/comments/509295011","html_url":"https://github.com/ajbrock/BigGAN-PyTorch/issues/32#issuecomment-509295011","issue_url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/32","id":509295011,"node_id":"MDEyOklzc3VlQ29tbWVudDUwOTI5NTAxMQ==","user":{"login":"VictorZuanazzi","id":31482851,"node_id":"MDQ6VXNlcjMxNDgyODUx","avatar_url":"https://avatars.githubusercontent.com/u/31482851?v=4","gravatar_id":"","url":"https://api.github.com/users/VictorZuanazzi","html_url":"https://github.com/VictorZuanazzi","followers_url":"https://api.github.com/users/VictorZuanazzi/followers","following_url":"https://api.github.com/users/VictorZuanazzi/following{/other_user}","gists_url":"https://api.github.com/users/VictorZuanazzi/gists{/gist_id}","starred_url":"https://api.github.com/users/VictorZuanazzi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/VictorZuanazzi/subscriptions","organizations_url":"https://api.github.com/users/VictorZuanazzi/orgs","repos_url":"https://api.github.com/users/VictorZuanazzi/repos","events_url":"https://api.github.com/users/VictorZuanazzi/events{/privacy}","received_events_url":"https://api.github.com/users/VictorZuanazzi/received_events","type":"User","site_admin":false},"created_at":"2019-07-08T16:22:53Z","updated_at":"2019-07-08T16:25:42Z","author_association":"NONE","body":"Hi,\r\n\r\nI am trying to load the pre-trained model as well. I am having a similar issue, but regarding another tensor:\r\n``` RuntimeError: Error(s) in loading state_dict for Generator:\r\n\tsize mismatch for blocks.0.0.bn1.gain.weight: copying a param with shape torch.Size([1536, 148]) from checkpoint, the shape in current model is torch.Size([1000, 1536]).\r\n\tsize mismatch for blocks.0.0.bn1.bias.weight: copying a param with shape torch.Size([1536, 148]) from checkpoint, the shape in current model is torch.Size([1000, 1536]).\r\n\tsize mismatch for blocks.0.0.bn2.gain.weight: copying a param with shape torch.Size([1536, 148]) from checkpoint, the shape in current model is torch.Size([1000, 1536]).\r\n\tsize mismatch for blocks.0.0.bn2.bias.weight: copying a param with shape torch.Size([1536, 148]) from checkpoint, the shape in current model is torch.Size([1000, 1536]).\r\n\tsize mismatch for blocks.1.0.bn1.gain.weight: copying a param with shape torch.Size([1536, 148]) from checkpoint, the shape in current model is torch.Size([1000, 1536]).\r\n\tsize mismatch for blocks.1.0.bn1.bias.weight: copying a param with shape torch.Size([1536, 148]) from checkpoint, the shape in current model is torch.Size([1000, 1536]).\r\n\tsize mismatch for blocks.1.0.bn2.gain.weight: copying a param with shape torch.Size([768, 148]) from checkpoint, the shape in current model is torch.Size([1000, 768]).\r\n\tsize mismatch for blocks.1.0.bn2.bias.weight: copying a param with shape torch.Size([768, 148]) from checkpoint, the shape in current model is torch.Size([1000, 768]).\r\n\tsize mismatch for blocks.2.0.bn1.gain.weight: copying a param with shape torch.Size([768, 148]) from checkpoint, the shape in current model is torch.Size([1000, 768]).\r\n\tsize mismatch for blocks.2.0.bn1.bias.weight: copying a param with shape torch.Size([768, 148]) from checkpoint, the shape in current model is torch.Size([1000, 768]).\r\n\tsize mismatch for blocks.2.0.bn2.gain.weight: copying a param with shape torch.Size([384, 148]) from checkpoint, the shape in current model is torch.Size([1000, 384]).\r\n\tsize mismatch for blocks.2.0.bn2.bias.weight: copying a param with shape torch.Size([384, 148]) from checkpoint, the shape in current model is torch.Size([1000, 384]).\r\n\tsize mismatch for blocks.3.0.bn1.gain.weight: copying a param with shape torch.Size([384, 148]) from checkpoint, the shape in current model is torch.Size([1000, 384]).\r\n\tsize mismatch for blocks.3.0.bn1.bias.weight: copying a param with shape torch.Size([384, 148]) from checkpoint, the shape in current model is torch.Size([1000, 384]).\r\n\tsize mismatch for blocks.3.0.bn2.gain.weight: copying a param with shape torch.Size([192, 148]) from checkpoint, the shape in current model is torch.Size([1000, 192]).\r\n\tsize mismatch for blocks.3.0.bn2.bias.weight: copying a param with shape torch.Size([192, 148]) from checkpoint, the shape in current model is torch.Size([1000, 192]).\r\n\tsize mismatch for blocks.4.0.bn1.gain.weight: copying a param with shape torch.Size([192, 148]) from checkpoint, the shape in current model is torch.Size([1000, 192]).\r\n\tsize mismatch for blocks.4.0.bn1.bias.weight: copying a param with shape torch.Size([192, 148]) from checkpoint, the shape in current model is torch.Size([1000, 192]).\r\n\tsize mismatch for blocks.4.0.bn2.gain.weight: copying a param with shape torch.Size([96, 148]) from checkpoint, the shape in current model is torch.Size([1000, 96]).\r\n\tsize mismatch for blocks.4.0.bn2.bias.weight: copying a param with shape torch.Size([96, 148]) from checkpoint, the shape in current model is torch.Size([1000, 96]). \r\n```\r\n\r\nI am trying to reverse engineer the hyperparameters, but it would be really nice if you would provide the parameters used to train the pre-trained models available for download. That is what I have so far:\r\n\r\n```parser.add_argument(\r\n    '--dataset', type=str,\r\n    default='I128_hdf5',\r\n    help='Which Dataset to train on, out of I128, I256, C10, C100;'\r\n         'Append \"_hdf5\" to use the hdf5 version for ISLVRC '\r\n         '(default: %(default)s)')\r\n  parser.add_argument(\r\n    '--augment', action='store_true', default=False,\r\n    help='Augment with random crops and flips (default: %(default)s)')\r\n  parser.add_argument(\r\n    '--num_workers', type=int, default=8,\r\n    help='Number of dataloader workers; consider using less for HDF5 '\r\n         '(default: %(default)s)')\r\n  parser.add_argument(\r\n    '--no_pin_memory', action='store_false', dest='pin_memory', default=True,\r\n    help='Pin data into memory through dataloader? (default: %(default)s)') \r\n  parser.add_argument(\r\n    '--shuffle', action='store_true', default=False,\r\n    help='Shuffle the data (strongly recommended)? (default: %(default)s)')\r\n  parser.add_argument(\r\n    '--load_in_mem', action='store_true', default=False,\r\n    help='Load all data into memory? (default: %(default)s)')\r\n  parser.add_argument(\r\n    '--use_multiepoch_sampler', action='store_true', default=False,\r\n    help='Use the multi-epoch sampler for dataloader? (default: %(default)s)')\r\n\r\n  ### Model stuff ###\r\n  parser.add_argument(\r\n    '--model', type=str, default='BigGAN',\r\n    help='Name of the model module (default: %(default)s)')\r\n  parser.add_argument(\r\n    '--G_param', type=str, default='SN',\r\n    help='Parameterization style to use for G, spectral norm (SN) or SVD (SVD)'\r\n          ' or None (default: %(default)s)')\r\n  parser.add_argument(\r\n    '--D_param', type=str, default='SN',\r\n    help='Parameterization style to use for D, spectral norm (SN) or SVD (SVD)'\r\n         ' or None (default: %(default)s)')    \r\n  parser.add_argument(\r\n    '--G_ch', type=int, default=96, #  default=64, CHANGED FOR MODEL LOADING\r\n    help='Channel multiplier for G (default: %(default)s)')\r\n  parser.add_argument(\r\n    '--D_ch', type=int, default=96, #  default=64, CHANGED FOR MODEL LOADING\r\n    help='Channel multiplier for D (default: %(default)s)')\r\n  parser.add_argument(\r\n    '--G_depth', type=int, default=1,\r\n    help='Number of resblocks per stage in G? (default: %(default)s)')\r\n  parser.add_argument(\r\n    '--D_depth', type=int, default=1,\r\n    help='Number of resblocks per stage in D? (default: %(default)s)')\r\n  parser.add_argument(\r\n    '--D_thin', action='store_false', dest='D_wide', default=True,\r\n    help='Use the SN-GAN channel pattern for D? (default: %(default)s)')\r\n  parser.add_argument(\r\n    '--G_shared', action='store_true', default=False,\r\n    help='Use shared embeddings in G? (default: %(default)s)')\r\n  parser.add_argument(\r\n    '--shared_dim', type=int, default=0,\r\n    help='G''s shared embedding dimensionality; if 0, will be equal to dim_z. '\r\n         '(default: %(default)s)')\r\n  parser.add_argument(\r\n    '--dim_z', type=int, default=20, # default=128, CHANGED FOR MODEL LOADING\r\n    help='Noise dimensionality: %(default)s)')\r\n  parser.add_argument(\r\n    '--z_var', type=float, default=1.0,\r\n    help='Noise variance: %(default)s)')    \r\n  parser.add_argument(\r\n    '--hier', action='store_true', default=False,\r\n    help='Use hierarchical z in G? (default: %(default)s)')\r\n  parser.add_argument(\r\n    '--cross_replica', action='store_true', default=False,\r\n    help='Cross_replica batchnorm in G?(default: %(default)s)')\r\n  parser.add_argument(\r\n    '--mybn', action='store_true', default=False,\r\n    help='Use my batchnorm (which supports standing stats?) %(default)s)')\r\n  parser.add_argument(\r\n    '--G_nl', type=str, default='relu',\r\n    help='Activation function for G (default: %(default)s)')\r\n  parser.add_argument(\r\n    '--D_nl', type=str, default='relu',\r\n    help='Activation function for D (default: %(default)s)')\r\n  parser.add_argument(\r\n    '--G_attn', type=str, default='64',  # default='64', ????? 32, 64 OR 32_64  ??????\r\n    help='What resolutions to use attention on for G (underscore separated) '\r\n         '(default: %(default)s)')\r\n  parser.add_argument(\r\n    '--D_attn', type=str, default='64', ????? 32, 64 OR 32_64  ??????\r\n    help='What resolutions to use attention on for D (underscore separated) '\r\n         '(default: %(default)s)')\r\n  parser.add_argument(\r\n    '--norm_style', type=str, default='bn',\r\n    help='Normalizer style for G, one of bn [batchnorm], in [instancenorm], '\r\n         'ln [layernorm], gn [groupnorm] (default: %(default)s)')\r\n```","reactions":{"url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/comments/509295011/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"VictorZuanazzi","id":31482851,"node_id":"MDQ6VXNlcjMxNDgyODUx","avatar_url":"https://avatars.githubusercontent.com/u/31482851?v=4","gravatar_id":"","url":"https://api.github.com/users/VictorZuanazzi","html_url":"https://github.com/VictorZuanazzi","followers_url":"https://api.github.com/users/VictorZuanazzi/followers","following_url":"https://api.github.com/users/VictorZuanazzi/following{/other_user}","gists_url":"https://api.github.com/users/VictorZuanazzi/gists{/gist_id}","starred_url":"https://api.github.com/users/VictorZuanazzi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/VictorZuanazzi/subscriptions","organizations_url":"https://api.github.com/users/VictorZuanazzi/orgs","repos_url":"https://api.github.com/users/VictorZuanazzi/repos","events_url":"https://api.github.com/users/VictorZuanazzi/events{/privacy}","received_events_url":"https://api.github.com/users/VictorZuanazzi/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/comments/509299070","html_url":"https://github.com/ajbrock/BigGAN-PyTorch/issues/32#issuecomment-509299070","issue_url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/32","id":509299070,"node_id":"MDEyOklzc3VlQ29tbWVudDUwOTI5OTA3MA==","user":{"login":"ajbrock","id":7751273,"node_id":"MDQ6VXNlcjc3NTEyNzM=","avatar_url":"https://avatars.githubusercontent.com/u/7751273?v=4","gravatar_id":"","url":"https://api.github.com/users/ajbrock","html_url":"https://github.com/ajbrock","followers_url":"https://api.github.com/users/ajbrock/followers","following_url":"https://api.github.com/users/ajbrock/following{/other_user}","gists_url":"https://api.github.com/users/ajbrock/gists{/gist_id}","starred_url":"https://api.github.com/users/ajbrock/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ajbrock/subscriptions","organizations_url":"https://api.github.com/users/ajbrock/orgs","repos_url":"https://api.github.com/users/ajbrock/repos","events_url":"https://api.github.com/users/ajbrock/events{/privacy}","received_events_url":"https://api.github.com/users/ajbrock/received_events","type":"User","site_admin":false},"created_at":"2019-07-08T16:34:34Z","updated_at":"2019-07-08T16:34:34Z","author_association":"OWNER","body":"The hyperparameters for this checkpoint are those used in the [main launch script](https://github.com/ajbrock/BigGAN-PyTorch/blob/master/scripts/launch_BigGAN_bs256x8.sh).","reactions":{"url":"https://api.github.com/repos/ajbrock/BigGAN-PyTorch/issues/comments/509299070/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":1,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"ajbrock","id":7751273,"node_id":"MDQ6VXNlcjc3NTEyNzM=","avatar_url":"https://avatars.githubusercontent.com/u/7751273?v=4","gravatar_id":"","url":"https://api.github.com/users/ajbrock","html_url":"https://github.com/ajbrock","followers_url":"https://api.github.com/users/ajbrock/followers","following_url":"https://api.github.com/users/ajbrock/following{/other_user}","gists_url":"https://api.github.com/users/ajbrock/gists{/gist_id}","starred_url":"https://api.github.com/users/ajbrock/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ajbrock/subscriptions","organizations_url":"https://api.github.com/users/ajbrock/orgs","repos_url":"https://api.github.com/users/ajbrock/repos","events_url":"https://api.github.com/users/ajbrock/events{/privacy}","received_events_url":"https://api.github.com/users/ajbrock/received_events","type":"User","site_admin":false}}]