{"url":"https://api.github.com/repos/onnx/onnxmltools/issues/216","repository_url":"https://api.github.com/repos/onnx/onnxmltools","labels_url":"https://api.github.com/repos/onnx/onnxmltools/issues/216/labels{/name}","comments_url":"https://api.github.com/repos/onnx/onnxmltools/issues/216/comments","events_url":"https://api.github.com/repos/onnx/onnxmltools/issues/216/events","html_url":"https://github.com/onnx/onnxmltools/issues/216","id":402034334,"node_id":"MDU6SXNzdWU0MDIwMzQzMzQ=","number":216,"title":"Coreml to onnx conversion : conversion succeeded but incorrect value on inference ","user":{"login":"deovrat","id":2981004,"node_id":"MDQ6VXNlcjI5ODEwMDQ=","avatar_url":"https://avatars.githubusercontent.com/u/2981004?v=4","gravatar_id":"","url":"https://api.github.com/users/deovrat","html_url":"https://github.com/deovrat","followers_url":"https://api.github.com/users/deovrat/followers","following_url":"https://api.github.com/users/deovrat/following{/other_user}","gists_url":"https://api.github.com/users/deovrat/gists{/gist_id}","starred_url":"https://api.github.com/users/deovrat/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/deovrat/subscriptions","organizations_url":"https://api.github.com/users/deovrat/orgs","repos_url":"https://api.github.com/users/deovrat/repos","events_url":"https://api.github.com/users/deovrat/events{/privacy}","received_events_url":"https://api.github.com/users/deovrat/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2019-01-23T01:51:37Z","updated_at":"2019-02-06T19:33:25Z","closed_at":"2019-02-06T19:33:25Z","author_association":"NONE","active_lock_reason":null,"body":"I am trying to convert a coreml model to onnx. The conversion succeeded but  predict using winml doesn't give the same values of output as coreml.\r\n\r\nI am doing the same proprocessing for onnx that I am doing for coreml before feeding the input. The coreml model gives the correct output , while onnx outputs much lower values. Using OnnxRuntime to do inference. Am I doing something wrong in conversion ?\r\n\r\nModel details : -\r\ncoreml model input specs : -\r\n```\r\nInput : - float64[None,4,320,320] . \r\n```\r\n4 here is BGRM ( where M stands for mask value for each pixel ) - image size is 320 X 320 . Network is inception based.\r\n\r\n```\r\nOutput :- float64[None,2,320,320]\r\n```\r\n\r\nLast layer of the network is softmax but the onnx output doesn't seem to show softmax property ie - sum of probabilities to 1.\r\n\r\nCode that I used for conversion :- \r\n```\r\nmodel_coreml = load_spec(coreml_model_path)\r\nonnxmodel = onnxmltools.convert_coreml(model_coreml, 'model')\r\nonnxmltools.utils.save_model(onnxml_model, converted_onnxml_path)\r\n```\r\nThe output model has float32 as types of tensors. Can this be a issue ? Is there a way to convert the model into float64 from coreml.","closed_by":{"login":"vinitra-zz","id":10929090,"node_id":"MDQ6VXNlcjEwOTI5MDkw","avatar_url":"https://avatars.githubusercontent.com/u/10929090?v=4","gravatar_id":"","url":"https://api.github.com/users/vinitra-zz","html_url":"https://github.com/vinitra-zz","followers_url":"https://api.github.com/users/vinitra-zz/followers","following_url":"https://api.github.com/users/vinitra-zz/following{/other_user}","gists_url":"https://api.github.com/users/vinitra-zz/gists{/gist_id}","starred_url":"https://api.github.com/users/vinitra-zz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vinitra-zz/subscriptions","organizations_url":"https://api.github.com/users/vinitra-zz/orgs","repos_url":"https://api.github.com/users/vinitra-zz/repos","events_url":"https://api.github.com/users/vinitra-zz/events{/privacy}","received_events_url":"https://api.github.com/users/vinitra-zz/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/onnx/onnxmltools/issues/216/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/onnx/onnxmltools/issues/216/timeline","performed_via_github_app":null,"state_reason":"completed"}