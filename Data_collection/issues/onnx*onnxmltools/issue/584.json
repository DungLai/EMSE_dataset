{"url":"https://api.github.com/repos/onnx/onnxmltools/issues/584","repository_url":"https://api.github.com/repos/onnx/onnxmltools","labels_url":"https://api.github.com/repos/onnx/onnxmltools/issues/584/labels{/name}","comments_url":"https://api.github.com/repos/onnx/onnxmltools/issues/584/comments","events_url":"https://api.github.com/repos/onnx/onnxmltools/issues/584/events","html_url":"https://github.com/onnx/onnxmltools/issues/584","id":1376117685,"node_id":"I_kwDOB0J-H85SBeO1","number":584,"title":"In-memory, the ONNX XGBoost artifact blows up in size","user":{"login":"salmatfq","id":49535845,"node_id":"MDQ6VXNlcjQ5NTM1ODQ1","avatar_url":"https://avatars.githubusercontent.com/u/49535845?v=4","gravatar_id":"","url":"https://api.github.com/users/salmatfq","html_url":"https://github.com/salmatfq","followers_url":"https://api.github.com/users/salmatfq/followers","following_url":"https://api.github.com/users/salmatfq/following{/other_user}","gists_url":"https://api.github.com/users/salmatfq/gists{/gist_id}","starred_url":"https://api.github.com/users/salmatfq/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/salmatfq/subscriptions","organizations_url":"https://api.github.com/users/salmatfq/orgs","repos_url":"https://api.github.com/users/salmatfq/repos","events_url":"https://api.github.com/users/salmatfq/events{/privacy}","received_events_url":"https://api.github.com/users/salmatfq/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2022-09-16T15:38:30Z","updated_at":"2022-12-07T15:01:17Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the issue**\r\nIn trying to convert an XGBoost model artifact to ONNX and tracking its memory footprint, the size blows up. \r\nProfiling the memory usage, loading the resulting ONNX artifact is up to 4x bigger than the artifact's on-disk size. \r\nFor example for an ONNX artifact of size 8MB, the in-memory usage while loading (onnx.load(model)) is almost 30MB.\r\nFor reference, the conversion code used is pretty standard: \r\n```\r\nimport xgboost as xgb \r\nfrom onnxmltools.convert import convert_xgboost \r\nfrom skl2onnx.common.data_types import FloatTensorType\r\n\r\nmodel = xgb.Booster()\r\nmodel.load_model(f'{destination}/xgboost-model')\r\nfts_num = 3000\r\n   \r\ninitial_types = [('feature_input', FloatTensorType(['batch_size', fts_num]))]\r\nonx = convert_xgboost(model, initial_types=initial_types)\r\nwith open(f\"{destination}/{file_name}.onnx\", \"wb\") as fp:\r\n    fp.write(onx.SerializeToString())\r\n```\r\n\r\n**Urgency**\r\nASAP\r\n\r\n**Env info**\r\nPython: 3.8.0\r\nonnxmltools version: 1.11.0\r\nxgboost version: 1.3.1\r\n\r\n\r\n**Question**\r\nIs this behavior expected? Shouldn't the loaded memory be around the same as the model size on disk? How can we reduce the footprint? ","closed_by":null,"reactions":{"url":"https://api.github.com/repos/onnx/onnxmltools/issues/584/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/onnx/onnxmltools/issues/584/timeline","performed_via_github_app":null,"state_reason":null}