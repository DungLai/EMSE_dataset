{"url":"https://api.github.com/repos/onnx/onnxmltools/issues/540","repository_url":"https://api.github.com/repos/onnx/onnxmltools","labels_url":"https://api.github.com/repos/onnx/onnxmltools/issues/540/labels{/name}","comments_url":"https://api.github.com/repos/onnx/onnxmltools/issues/540/comments","events_url":"https://api.github.com/repos/onnx/onnxmltools/issues/540/events","html_url":"https://github.com/onnx/onnxmltools/issues/540","id":1197230823,"node_id":"I_kwDOB0J-H85HXErn","number":540,"title":"PySpark StandardScaler conversion fails","user":{"login":"alvaro-budria","id":48391578,"node_id":"MDQ6VXNlcjQ4MzkxNTc4","avatar_url":"https://avatars.githubusercontent.com/u/48391578?v=4","gravatar_id":"","url":"https://api.github.com/users/alvaro-budria","html_url":"https://github.com/alvaro-budria","followers_url":"https://api.github.com/users/alvaro-budria/followers","following_url":"https://api.github.com/users/alvaro-budria/following{/other_user}","gists_url":"https://api.github.com/users/alvaro-budria/gists{/gist_id}","starred_url":"https://api.github.com/users/alvaro-budria/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alvaro-budria/subscriptions","organizations_url":"https://api.github.com/users/alvaro-budria/orgs","repos_url":"https://api.github.com/users/alvaro-budria/repos","events_url":"https://api.github.com/users/alvaro-budria/events{/privacy}","received_events_url":"https://api.github.com/users/alvaro-budria/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2022-04-08T11:59:34Z","updated_at":"2022-06-06T08:24:29Z","closed_at":"2022-06-06T08:24:29Z","author_association":"NONE","active_lock_reason":null,"body":"While trying to convert a PySpark StandardScaler to ONNX, I came across an error having to do with the data structure the values by which to scale/center are stored in.\r\nThe issue is that PySpark stores these values inside a pyspark.ml.linalg.DenseVector, which cannot be dealt with by function `make_attribute` inside `onnx/helper.py`.\r\nA possible solution is to check the type insider helper.py and typecast the input from DenseVector to python list, but this would add a dependency to pyspark.\r\n\r\nCode to reproduce the error:\r\n\r\n```\r\nfrom pyspark.ml.feature import StandardScaler\r\nfrom pyspark.ml import Pipeline\r\nfrom pyspark.sql import SparkSession\r\nfrom pyspark.ml.feature import VectorAssembler\r\n\r\nfrom onnxconverter_common.data_types import FloatTensorType\r\nfrom onnxmltools.convert import convert_sparkml\r\nfrom onnx.defs import onnx_opset_version\r\nfrom onnxconverter_common.onnx_ex import DEFAULT_OPSET_NUMBER\r\nTARGET_OPSET = min(DEFAULT_OPSET_NUMBER, onnx_opset_version())\r\n\r\nimport numpy as np\r\n\r\n\r\nspark = SparkSession.builder.master(\"local\") \\\r\n                    .appName(\"onnxConversion\") \\\r\n                    .getOrCreate()\r\n\r\n# sample data\r\narr = np.array(\r\n    [\r\n        [1.,    2.02,   3.1],\r\n        [1.01,  2.,     3.05],\r\n        [2.,    3.99,   5.9],\r\n        [1.9,   4.01,   6.1]\r\n    ]\r\n)\r\nrdd = spark.sparkContext.parallelize(arr)\r\nrdd = rdd.map(lambda x: [float(i) for i in x])\r\ndata = rdd.toDF(['0', '1', '2'])\r\n\r\n# Assemble all feature variables with a VectorAssembler\r\nassembler = VectorAssembler(inputCols=['0', '1', '2'], outputCol='features')\r\nstages = [assembler]\r\n\r\nscaler = StandardScaler(\r\n            inputCol='features',\r\n            outputCol='scaledFeatures',\r\n            withStd=True,\r\n            withMean=True,\r\n        )\r\npipeline = Pipeline(stages=stages + [scaler])\r\nmodel = pipeline.fit(data)\r\n\r\n# convert to ONNX\r\ninitial_types = [ (col, FloatTensorType([None, 1])) for col in ['0', '1', '2'] ]\r\nonx = convert_sparkml(\r\n    model,\r\n    'myPCA',\r\n    initial_types,\r\n    spark_session=spark,\r\n    target_opset=TARGET_OPSET\r\n)\r\n\r\n```\r\n\r\nAnd the error message:\r\n\r\n> 22/04/08 13:49:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n> Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\r\n> Setting default log level to \"WARN\".\r\n> To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\r\n> /Users/alvarobudria/anaconda3/envs/py37/lib/python3.7/site-packages/onnxconverter_common/topology.py:749: UserWarning: Some input names are not compliant with ONNX naming convention: ['0', '1', '2']\r\n>   warnings.warn('Some input names are not compliant with ONNX naming convention: %s' % invalid_name)\r\n> Traceback (most recent call last):\r\n>   File \"PCA_PR.py\", line 54, in <module>\r\n>     target_opset=TARGET_OPSET\r\n>   File \"/Users/alvarobudria/anaconda3/envs/py37/lib/python3.7/site-packages/onnxmltools/convert/main.py\", line 167, in convert_sparkml\r\n>     custom_conversion_functions, custom_shape_calculators, spark_session)\r\n>   File \"/Users/alvarobudria/anaconda3/envs/py37/lib/python3.7/site-packages/onnxmltools/convert/sparkml/convert.py\", line 71, in convert\r\n>     onnx_model = convert_topology(topology, name, doc_string, target_opset, targeted_onnx)\r\n>   File \"/Users/alvarobudria/anaconda3/envs/py37/lib/python3.7/site-packages/onnxconverter_common/topology.py\", line 776, in convert_topology\r\n>     get_converter(operator.type)(scope, operator, container)\r\n>   File \"/Users/alvarobudria/anaconda3/envs/py37/lib/python3.7/site-packages/onnxmltools/convert/sparkml/operator_converters/scaler.py\", line 40, in convert_sparkml_scaler\r\n>     container.add_node(op_type, input_name, operator.output_full_names, op_domain='ai.onnx.ml', **attrs)\r\n>   File \"/Users/alvarobudria/anaconda3/envs/py37/lib/python3.7/site-packages/onnxconverter_common/container.py\", line 171, in add_node\r\n>     node = helper.make_node(op_type, inputs, outputs, **attrs)\r\n>   File \"/Users/alvarobudria/anaconda3/envs/py37/lib/python3.7/site-packages/onnx/helper.py\", line 118, in make_node\r\n>     for key, value in sorted(kwargs.items())\r\n>   File \"/Users/alvarobudria/anaconda3/envs/py37/lib/python3.7/site-packages/onnx/helper.py\", line 119, in <genexpr>\r\n>     if value is not None)\r\n>   File \"/Users/alvarobudria/anaconda3/envs/py37/lib/python3.7/site-packages/onnx/helper.py\", line 447, in make_attribute\r\n>     'value \"{}\" is not valid attribute data type.'.format(value))\r\n> TypeError: value \"[1.4775,3.005,4.5375]\" is not valid attribute data type.","closed_by":{"login":"xadupre","id":22452781,"node_id":"MDQ6VXNlcjIyNDUyNzgx","avatar_url":"https://avatars.githubusercontent.com/u/22452781?v=4","gravatar_id":"","url":"https://api.github.com/users/xadupre","html_url":"https://github.com/xadupre","followers_url":"https://api.github.com/users/xadupre/followers","following_url":"https://api.github.com/users/xadupre/following{/other_user}","gists_url":"https://api.github.com/users/xadupre/gists{/gist_id}","starred_url":"https://api.github.com/users/xadupre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xadupre/subscriptions","organizations_url":"https://api.github.com/users/xadupre/orgs","repos_url":"https://api.github.com/users/xadupre/repos","events_url":"https://api.github.com/users/xadupre/events{/privacy}","received_events_url":"https://api.github.com/users/xadupre/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/onnx/onnxmltools/issues/540/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/onnx/onnxmltools/issues/540/timeline","performed_via_github_app":null,"state_reason":"completed"}