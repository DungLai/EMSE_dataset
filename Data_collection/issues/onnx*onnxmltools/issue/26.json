{"url":"https://api.github.com/repos/onnx/onnxmltools/issues/26","repository_url":"https://api.github.com/repos/onnx/onnxmltools","labels_url":"https://api.github.com/repos/onnx/onnxmltools/issues/26/labels{/name}","comments_url":"https://api.github.com/repos/onnx/onnxmltools/issues/26/comments","events_url":"https://api.github.com/repos/onnx/onnxmltools/issues/26/events","html_url":"https://github.com/onnx/onnxmltools/issues/26","id":319729638,"node_id":"MDU6SXNzdWUzMTk3Mjk2Mzg=","number":26,"title":"Specifing input shapes example","user":{"login":"wschin","id":3524474,"node_id":"MDQ6VXNlcjM1MjQ0NzQ=","avatar_url":"https://avatars.githubusercontent.com/u/3524474?v=4","gravatar_id":"","url":"https://api.github.com/users/wschin","html_url":"https://github.com/wschin","followers_url":"https://api.github.com/users/wschin/followers","following_url":"https://api.github.com/users/wschin/following{/other_user}","gists_url":"https://api.github.com/users/wschin/gists{/gist_id}","starred_url":"https://api.github.com/users/wschin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wschin/subscriptions","organizations_url":"https://api.github.com/users/wschin/orgs","repos_url":"https://api.github.com/users/wschin/repos","events_url":"https://api.github.com/users/wschin/events{/privacy}","received_events_url":"https://api.github.com/users/wschin/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2018-05-02T22:10:13Z","updated_at":"2022-05-18T07:58:39Z","closed_at":"2018-11-29T01:32:36Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"When converting models from Core ML, the batch size is unknown (variable-length) by default. To overwrite this setting, one can specify their own input shapes.\r\n\r\nConsider MNIST.mlmodel downloaded at [here](https://github.com/likedan/Awesome-CoreML-Models). We can set batch size to 3 by running the following conversion code.\r\n\r\n```python\r\nfrom onnxmltools.utils import visualize_model\r\nfrom onnxmltools.convert.coreml.convert import convert\r\nfrom onnxmltools.convert.common.data_types import FloatTensorType\r\nfrom winmltools.utils import save_model\r\nfrom winmltools.utils import save_text\r\nfrom coremltools.models.utils import load_spec\r\n\r\ncoreml_model = load_spec('MNIST.mlmodel')\r\n\r\n# Each input type is a tuple of (variable_name, variable_type). To find Core ML variable names\r\n# and their types, you can print out coreml_model.description. If the considered Core ML\r\n# variable, say coreml_model.description.input[0], is an image, you need to find out its color\r\n# space value via printing coreml_model.description.input[0].type.imageType.colorSpace. \r\n# If the value of colorSpace is 10/20/30, the corresponding color space is 'GRAY'/'RGB'/'BGR'.\r\ninitial_type = (coreml_model.description.input[0].name, FloatTensorType(shape=[3, 1, 28, 28], color_space='GRAY')) # Other allowed color spaces are \"RGB\" and \"BGR\"\r\nonnx_model = convert(coreml_model, initial_types=[initial_type])\r\n# The produced ONNX model in text format\r\nsave_text(onnx_model, \"mnist.onnx.txt\")\r\n# The produced ONNX model\r\nsave_model(onnx_model, 'mnist.onnx')\r\n# Call a simple visualization tool\r\nvisualize_model(onnx_model)\r\n```\r\n\r\nAnother [example ](https://coreml.store/fns-candy?download)using BGR image input is show below\r\n\r\n```python\r\nfrom onnxmltools.utils import visualize_model\r\nfrom onnxmltools.convert.coreml.convert import convert\r\nfrom onnxmltools.convert.common.data_types import FloatTensorType\r\nfrom winmltools.utils import save_model\r\nfrom winmltools.utils import save_text\r\nfrom coremltools.models.utils import load_spec\r\n\r\ncoreml_model = load_spec('FNS-Candy.mlmodel')\r\n\r\n# Set batch size to 1 instead of using variable-size batch\r\ninitial_type = (coreml_model.description.input[0].name, FloatTensorType(shape=[1, 3, 720, 720], color_space='BGR')) # Other allowed color spaces are \"RGB\" and \"GRAY\"\r\nonnx_model = convert(coreml_model, initial_types=[initial_type])\r\nsave_text(onnx_model, \"fns.onnx.txt\")\r\nsave_model(onnx_model, 'fns.onnx')\r\n\r\nvisualize_model(onnx_model)\r\n```\r\n","closed_by":{"login":"wenbingl","id":10278425,"node_id":"MDQ6VXNlcjEwMjc4NDI1","avatar_url":"https://avatars.githubusercontent.com/u/10278425?v=4","gravatar_id":"","url":"https://api.github.com/users/wenbingl","html_url":"https://github.com/wenbingl","followers_url":"https://api.github.com/users/wenbingl/followers","following_url":"https://api.github.com/users/wenbingl/following{/other_user}","gists_url":"https://api.github.com/users/wenbingl/gists{/gist_id}","starred_url":"https://api.github.com/users/wenbingl/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wenbingl/subscriptions","organizations_url":"https://api.github.com/users/wenbingl/orgs","repos_url":"https://api.github.com/users/wenbingl/repos","events_url":"https://api.github.com/users/wenbingl/events{/privacy}","received_events_url":"https://api.github.com/users/wenbingl/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/onnx/onnxmltools/issues/26/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/onnx/onnxmltools/issues/26/timeline","performed_via_github_app":null,"state_reason":"completed"}