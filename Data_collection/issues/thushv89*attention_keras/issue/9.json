{"url":"https://api.github.com/repos/thushv89/attention_keras/issues/9","repository_url":"https://api.github.com/repos/thushv89/attention_keras","labels_url":"https://api.github.com/repos/thushv89/attention_keras/issues/9/labels{/name}","comments_url":"https://api.github.com/repos/thushv89/attention_keras/issues/9/comments","events_url":"https://api.github.com/repos/thushv89/attention_keras/issues/9/events","html_url":"https://github.com/thushv89/attention_keras/issues/9","id":449168491,"node_id":"MDU6SXNzdWU0NDkxNjg0OTE=","number":9,"title":"TypeError: Failed to convert object of type <class 'list'> to Tensor. Contents: [1, Dimension(None)]. Consider casting elements to a supported type.","user":{"login":"JiweiZh","id":16006025,"node_id":"MDQ6VXNlcjE2MDA2MDI1","avatar_url":"https://avatars.githubusercontent.com/u/16006025?v=4","gravatar_id":"","url":"https://api.github.com/users/JiweiZh","html_url":"https://github.com/JiweiZh","followers_url":"https://api.github.com/users/JiweiZh/followers","following_url":"https://api.github.com/users/JiweiZh/following{/other_user}","gists_url":"https://api.github.com/users/JiweiZh/gists{/gist_id}","starred_url":"https://api.github.com/users/JiweiZh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JiweiZh/subscriptions","organizations_url":"https://api.github.com/users/JiweiZh/orgs","repos_url":"https://api.github.com/users/JiweiZh/repos","events_url":"https://api.github.com/users/JiweiZh/events{/privacy}","received_events_url":"https://api.github.com/users/JiweiZh/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":9,"created_at":"2019-05-28T09:42:59Z","updated_at":"2021-01-14T07:00:57Z","closed_at":"2019-06-03T08:31:49Z","author_association":"NONE","active_lock_reason":null,"body":"**I try to add your attention layer into my encoder-decoder model. the code is like this** \r\n\r\nlatent_dim = 256 # LSTM hidden units\r\ndropout = .20 \r\nencoder_inputs = Input(shape=(None, n_inputs), name='encoder_inputs') \r\nencoder_lstm = LSTM(latent_dim, dropout=dropout, return_sequences=True, return_state=True, name='encoder_lstm')\r\nencoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\r\nencoder_states = [state_h, state_c]\r\ndecoder_inputs = Input(shape=(None, n_outputs), name='decoder_inputs') \r\n\r\ndecoder_lstm = LSTM(latent_dim, dropout=dropout, return_sequences=True, return_state=True, name='decoder_lstm')\r\ndecoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\r\n\r\nattn_layer = AttentionLayer(name='attention_layer')\r\nattn_outputs, attn_states = attn_layer([encoder_outputs, decoder_outputs])\r\n\r\ndecoder_concat_inputs = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_outputs])\r\n\r\ndecoder_dense = Dense(n_outputs, activation='softmax', name='softmax_layer') # 1 continuous output at each timestep\r\ndecoder_outputs = decoder_dense(decoder_concat_inputs)\r\n\r\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\r\n\r\n\r\n**but i meet the error like**\r\n\r\n TypeError                                 Traceback (most recent call last)\r\n/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape)\r\n    526     try:\r\n--> 527       str_values = [compat.as_bytes(x) for x in proto_values]\r\n    528     except TypeError:\r\n\r\n/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py in <listcomp>(.0)\r\n    526     try:\r\n--> 527       str_values = [compat.as_bytes(x) for x in proto_values]\r\n    528     except TypeError:\r\n\r\n/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/compat.py in as_bytes(bytes_or_text, encoding)\r\n     60     raise TypeError('Expected binary or unicode string, got %r' %\r\n---> 61                     (bytes_or_text,))\r\n     62 \r\n\r\nTypeError: Expected binary or unicode string, got 1\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-42-8488a2e4f458> in <module>()\r\n     29 # define attention layer\r\n     30 attn_layer = AttentionLayer(name='attention_layer')\r\n---> 31 attn_outputs, attn_states = attn_layer([encoder_outputs, decoder_outputs])\r\n     32 \r\n     33 # concatenate attention output and decoder output as an input to the softmax layer\r\n\r\n~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py in __call__(self, inputs, **kwargs)\r\n    455             # Actually call the layer,\r\n    456             # collecting output(s), mask(s), and shape(s).\r\n--> 457             output = self.call(inputs, **kwargs)\r\n    458             output_mask = self.compute_mask(inputs, previous_mask)\r\n    459 \r\n\r\n<ipython-input-38-725b5b4c250e> in call(self, inputs, verbose)\r\n     95 \r\n     96         fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\r\n---> 97         fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\r\n     98 \r\n     99         \"\"\" Computing energy outputs \"\"\"\r\n\r\n<ipython-input-38-725b5b4c250e> in create_inital_state(inputs, hidden_size)\r\n     91             fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\r\n     92             fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\r\n---> 93             fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\r\n     94             return fake_state\r\n     95 \r\n\r\n~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in tile(x, n)\r\n   2189     if isinstance(n, int):\r\n   2190         n = [n]\r\n-> 2191     return tf.tile(x, n)\r\n   2192 \r\n   2193 \r\n\r\n/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py in tile(input, multiples, name)\r\n   8803   if _ctx is None or not _ctx._eager_context.is_eager:\r\n   8804     _, _, _op = _op_def_lib._apply_op_helper(\r\n-> 8805         \"Tile\", input=input, multiples=multiples, name=name)\r\n   8806     _result = _op.outputs[:]\r\n   8807     _inputs_flat = _op.inputs\r\n\r\n/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)\r\n    511           except TypeError as err:\r\n    512             if dtype is None:\r\n--> 513               raise err\r\n    514             else:\r\n    515               raise TypeError(\r\n\r\n/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)\r\n    508                 dtype=dtype,\r\n    509                 as_ref=input_arg.is_ref,\r\n--> 510                 preferred_dtype=default_dtype)\r\n    511           except TypeError as err:\r\n    512             if dtype is None:\r\n\r\n/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx)\r\n   1144 \r\n   1145     if ret is None:\r\n-> 1146       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1147 \r\n   1148     if ret is NotImplemented:\r\n\r\n/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)\r\n    227                                          as_ref=False):\r\n    228   _ = as_ref\r\n--> 229   return constant(v, dtype=dtype, name=name)\r\n    230 \r\n    231 \r\n\r\n/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name, verify_shape)\r\n    206   tensor_value.tensor.CopyFrom(\r\n    207       tensor_util.make_tensor_proto(\r\n--> 208           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n    209   dtype_value = attr_value_pb2.AttrValue(type=tensor_value.tensor.dtype)\r\n    210   const_tensor = g.create_op(\r\n\r\n/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape)\r\n    529       raise TypeError(\"Failed to convert object of type %s to Tensor. \"\r\n    530                       \"Contents: %s. Consider casting elements to a \"\r\n--> 531                       \"supported type.\" % (type(values), values))\r\n    532     tensor_proto.string_val.extend(str_values)\r\n    533     return tensor_proto\r\n\r\nTypeError: Failed to convert object of type <class 'list'> to Tensor. Contents: [1, Dimension(None)]. Consider casting elements to a supported type.\r\n\r\n**Do you have any idea to solve that?  THX a lot!**","closed_by":{"login":"JiweiZh","id":16006025,"node_id":"MDQ6VXNlcjE2MDA2MDI1","avatar_url":"https://avatars.githubusercontent.com/u/16006025?v=4","gravatar_id":"","url":"https://api.github.com/users/JiweiZh","html_url":"https://github.com/JiweiZh","followers_url":"https://api.github.com/users/JiweiZh/followers","following_url":"https://api.github.com/users/JiweiZh/following{/other_user}","gists_url":"https://api.github.com/users/JiweiZh/gists{/gist_id}","starred_url":"https://api.github.com/users/JiweiZh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JiweiZh/subscriptions","organizations_url":"https://api.github.com/users/JiweiZh/orgs","repos_url":"https://api.github.com/users/JiweiZh/repos","events_url":"https://api.github.com/users/JiweiZh/events{/privacy}","received_events_url":"https://api.github.com/users/JiweiZh/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/thushv89/attention_keras/issues/9/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/thushv89/attention_keras/issues/9/timeline","performed_via_github_app":null,"state_reason":"completed"}