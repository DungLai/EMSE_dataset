{"url":"https://api.github.com/repos/thushv89/attention_keras/issues/4","repository_url":"https://api.github.com/repos/thushv89/attention_keras","labels_url":"https://api.github.com/repos/thushv89/attention_keras/issues/4/labels{/name}","comments_url":"https://api.github.com/repos/thushv89/attention_keras/issues/4/comments","events_url":"https://api.github.com/repos/thushv89/attention_keras/issues/4/events","html_url":"https://github.com/thushv89/attention_keras/issues/4","id":429719248,"node_id":"MDU6SXNzdWU0Mjk3MTkyNDg=","number":4,"title":"TypeError: __int__ returned non-int (type NoneType)","user":{"login":"jayeew","id":28797714,"node_id":"MDQ6VXNlcjI4Nzk3NzE0","avatar_url":"https://avatars.githubusercontent.com/u/28797714?v=4","gravatar_id":"","url":"https://api.github.com/users/jayeew","html_url":"https://github.com/jayeew","followers_url":"https://api.github.com/users/jayeew/followers","following_url":"https://api.github.com/users/jayeew/following{/other_user}","gists_url":"https://api.github.com/users/jayeew/gists{/gist_id}","starred_url":"https://api.github.com/users/jayeew/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayeew/subscriptions","organizations_url":"https://api.github.com/users/jayeew/orgs","repos_url":"https://api.github.com/users/jayeew/repos","events_url":"https://api.github.com/users/jayeew/events{/privacy}","received_events_url":"https://api.github.com/users/jayeew/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2019-04-05T11:57:32Z","updated_at":"2019-04-11T20:13:56Z","closed_at":"2019-04-11T20:13:55Z","author_association":"NONE","active_lock_reason":null,"body":"First thank you for your implement of attention.\r\nwhen I built a lstm seq2seq chatbot use your implement, I got an error in line \r\n`attn_out, attn_states = attn_layer([encoder_out, decoder_lstm])`\r\nwhich throw me an error like\r\n`TypeError: __int__ returned non-int (type NoneType)`\r\nAnd my core code here:\r\n`embed_layer = Embedding(input_dim=vocab_size, output_dim=50, trainable=True)`\r\n`embed_layer.build((None,))\r\nembed_layer.set_weights([embedding_matrix])`\r\n\r\n`LSTM_cell = Bidirectional(LSTM(128, return_sequences=True, return_state=True))\r\nLSTM_decoder = LSTM(256, return_sequences=True, return_state=True)`\r\n\r\n`dense = TimeDistributed(Dense(vocab_size, activation='softmax'))`\r\n\r\n`input_context = Input(shape=(maxLen, ), dtype='int32', name='input_context') #maxLen=20`\r\n\r\n`input_target = Input(shape=(maxLen, ), dtype='int32', name='input_target')`\r\n\r\n`input_context_embed = embed_layer(input_context)\r\ninput_target_embed = embed_layer(input_target)`\r\n\r\n`encoder_out, forward_h, forward_c, backward_h, backward_c = LSTM_cell(input_context_embed)\r\ncontext_h = Concatenate()([forward_h, backward_h])\r\ncontext_c = Concatenate()([forward_c, backward_c])`\r\n\r\n`decoder_lstm, _, _ = LSTM_decoder(input_target_embed, \r\n                                  initial_state=[context_h, context_c])`\r\n\r\n`print('decoder_lstm.shape: ', decoder_lstm.shape) #(?, ?, 256)\r\nprint('encoder_out.shape: ', encoder_out.shape) #(?, ?, 256)`\r\n\r\n\r\n`# ***********************Start Code Here**********************`\r\n\r\n\r\n`'''\r\nAttention layer ***** A\r\n'''`\r\n`attn_layer = AttentionLayer(name='attention_layer')\r\nattn_out, attn_states = attn_layer([encoder_out, decoder_lstm])\r\nmerge = Concatenate(axis=-1, \r\n                                   name='concat_layer'\r\n                                  )([decoder_lstm, attn_out])`\r\n\r\n\r\n`# ***********************End Code Here**********************`\r\n\r\n`output = dense(merge)\r\nmodel.summary()\r\nmodel = Model([input_context, input_target, s0, c0], output)`\r\n\r\n`model.compile(optimizer='rmsprop', loss='categorical_crossentropy', \r\n              metrics=['accuracy'])`\r\n\r\n\r\n`model.fit([context_, final_target_], outs, epochs=2, batch_size=128, validation_split=0.2)`\r\n\r\nAnd the error detail below:\r\n`---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nc:\\users\\rnn_n\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py in zeros(shape, dtype, name)\r\n   1810         shape = constant_op._tensor_shape_tensor_conversion_function(\r\n-> 1811             tensor_shape.TensorShape(shape))\r\n   1812       except (TypeError, ValueError):\r\n\r\nc:\\users\\rnn_n\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py in _tensor_shape_tensor_conversion_function(s, dtype, name, as_ref)\r\n    324     raise ValueError(\r\n--> 325         \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\r\n    326   s_list = s.as_list()\r\n\r\nValueError: Cannot convert a partially known TensorShape to a Tensor: (?, 256)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-53-87e51167a357> in <module>\r\n     35 '''\r\n     36 attn_layer = AttentionLayer(name='attention_layer')\r\n---> 37 attn_out, attn_states = attn_layer([encoder_out, decoder_lstm])\r\n     38 merge = Concatenate(axis=-1, \r\n     39                                    name='concat_layer'\r\n\r\nc:\\users\\rnn_n\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    552             # In graph mode, failure to build the layer's graph\r\n    553             # implies a user-side bug. We don't catch exceptions.\r\n--> 554             outputs = self.call(inputs, *args, **kwargs)\r\n    555           else:\r\n    556             try:\r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\layers\\attention.py in call(self, inputs, verbose)\r\n     93 \r\n     94         # We are not using initial states, but need to pass something to K.rnn funciton\r\n---> 95         fake_state_c = K.zeros(shape=(encoder_out_seq.shape[0], encoder_out_seq.shape[-1]))\r\n     96         fake_state_e = K.zeros(shape=(encoder_out_seq.shape[0], encoder_out_seq.shape[1]))\r\n     97 \r\n\r\nc:\\users\\rnn_n\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py in zeros(shape, dtype, name)\r\n   1066       dtype = floatx()\r\n   1067     tf_dtype = dtypes_module.as_dtype(dtype)\r\n-> 1068     v = array_ops.zeros(shape=shape, dtype=tf_dtype, name=name)\r\n   1069     if py_all(v.shape.as_list()):\r\n   1070       return variable(v, dtype=dtype, name=name)\r\n\r\nc:\\users\\rnn_n\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py in zeros(shape, dtype, name)\r\n   1812       except (TypeError, ValueError):\r\n   1813         # Happens when shape is a list with tensor elements\r\n-> 1814         shape = ops.convert_to_tensor(shape, dtype=dtypes.int32)\r\n   1815     if not shape._shape_tuple():\r\n   1816       shape = reshape(shape, [-1])  # Ensure it's a vector\r\n\r\nc:\\users\\rnn_n\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py in convert_to_tensor(value, dtype, name, preferred_dtype)\r\n   1037     ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\r\n   1038   \"\"\"\r\n-> 1039   return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\r\n   1040 \r\n   1041 \r\n\r\nc:\\users\\rnn_n\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py in convert_to_tensor_v2(value, dtype, dtype_hint, name)\r\n   1095       name=name,\r\n   1096       preferred_dtype=dtype_hint,\r\n-> 1097       as_ref=False)\r\n   1098 \r\n   1099 \r\n\r\nc:\\users\\rnn_n\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors)\r\n   1173 \r\n   1174     if ret is None:\r\n-> 1175       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1176 \r\n   1177     if ret is NotImplemented:\r\n\r\nc:\\users\\rnn_n\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)\r\n    302                                          as_ref=False):\r\n    303   _ = as_ref\r\n--> 304   return constant(v, dtype=dtype, name=name)\r\n    305 \r\n    306 \r\n\r\nc:\\users\\rnn_n\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py in constant(value, dtype, shape, name)\r\n    243   \"\"\"\r\n    244   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n--> 245                         allow_broadcast=True)\r\n    246 \r\n    247 \r\n\r\nc:\\users\\rnn_n\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    281       tensor_util.make_tensor_proto(\r\n    282           value, dtype=dtype, shape=shape, verify_shape=verify_shape,\r\n--> 283           allow_broadcast=allow_broadcast))\r\n    284   dtype_value = attr_value_pb2.AttrValue(type=tensor_value.tensor.dtype)\r\n    285   const_tensor = g.create_op(\r\n\r\nc:\\users\\rnn_n\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast)\r\n    465     else:\r\n    466       _AssertCompatible(values, dtype)\r\n--> 467       nparray = np.array(values, dtype=np_dt)\r\n    468       # check to them.\r\n    469       # We need to pass in quantized values as tuples, so don't apply the shape\r\n\r\nTypeError: __int__ returned non-int (type NoneType)`\r\n\r\nThank you for your contribution!","closed_by":{"login":"thushv89","id":1381369,"node_id":"MDQ6VXNlcjEzODEzNjk=","avatar_url":"https://avatars.githubusercontent.com/u/1381369?v=4","gravatar_id":"","url":"https://api.github.com/users/thushv89","html_url":"https://github.com/thushv89","followers_url":"https://api.github.com/users/thushv89/followers","following_url":"https://api.github.com/users/thushv89/following{/other_user}","gists_url":"https://api.github.com/users/thushv89/gists{/gist_id}","starred_url":"https://api.github.com/users/thushv89/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/thushv89/subscriptions","organizations_url":"https://api.github.com/users/thushv89/orgs","repos_url":"https://api.github.com/users/thushv89/repos","events_url":"https://api.github.com/users/thushv89/events{/privacy}","received_events_url":"https://api.github.com/users/thushv89/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/thushv89/attention_keras/issues/4/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/thushv89/attention_keras/issues/4/timeline","performed_via_github_app":null,"state_reason":"completed"}