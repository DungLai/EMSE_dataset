{"url":"https://api.github.com/repos/thushv89/attention_keras/issues/21","repository_url":"https://api.github.com/repos/thushv89/attention_keras","labels_url":"https://api.github.com/repos/thushv89/attention_keras/issues/21/labels{/name}","comments_url":"https://api.github.com/repos/thushv89/attention_keras/issues/21/comments","events_url":"https://api.github.com/repos/thushv89/attention_keras/issues/21/events","html_url":"https://github.com/thushv89/attention_keras/issues/21","id":488633286,"node_id":"MDU6SXNzdWU0ODg2MzMyODY=","number":21,"title":"AttributeError: 'tuple' object has no attribute 'layer'","user":{"login":"Sum02dean","id":36505689,"node_id":"MDQ6VXNlcjM2NTA1Njg5","avatar_url":"https://avatars.githubusercontent.com/u/36505689?v=4","gravatar_id":"","url":"https://api.github.com/users/Sum02dean","html_url":"https://github.com/Sum02dean","followers_url":"https://api.github.com/users/Sum02dean/followers","following_url":"https://api.github.com/users/Sum02dean/following{/other_user}","gists_url":"https://api.github.com/users/Sum02dean/gists{/gist_id}","starred_url":"https://api.github.com/users/Sum02dean/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Sum02dean/subscriptions","organizations_url":"https://api.github.com/users/Sum02dean/orgs","repos_url":"https://api.github.com/users/Sum02dean/repos","events_url":"https://api.github.com/users/Sum02dean/events{/privacy}","received_events_url":"https://api.github.com/users/Sum02dean/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2019-09-03T14:16:19Z","updated_at":"2020-03-27T06:58:32Z","closed_at":"2019-09-05T07:07:42Z","author_association":"NONE","active_lock_reason":null,"body":"Hi, I get the following error message. Can you help resolve this?\r\nThanks.\r\n\r\nDean\r\n\r\nCode:\r\n```\r\nfrom keras.layers import Bidirectional, CuDNNLSTM\r\nfrom keras.callbacks import History, ReduceLROnPlateau, EarlyStopping\r\nfrom keras.optimizers import RMSprop, Adam\r\nfrom keras import regularizers\r\n\r\n#callbacks\r\nh = History()\r\nrlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,patience=10, min_lr=0.000001, verbose=1, min_delta=1e-5)\r\nes = EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=10, verbose=0, mode='auto')\r\n\r\n\r\n#---------------------- Encoder--------------------------#\r\n#peviously used 250\r\nlstm_dim = 500\r\ninput_shape= pr_train.shape[1:]\r\n\r\n#input shape\r\nencoder_input = Input(shape=input_shape)\r\n\r\n#first encoder layer\r\nencoder_LSTM = Bidirectional(CuDNNLSTM(lstm_dim // 2, return_state=True, return_sequences=True, name='bd_enc_LSTM_01'))\r\nencoder1_output, forward_h1, forward_c1, backward_h1, backward_c1 = encoder_LSTM (encoder_input)\r\n\r\n\r\n#second encoder layer\r\nencoder_LSTM2 = Bidirectional(CuDNNLSTM(lstm_dim // 2, return_state=True, return_sequences=True, name='bd_enc_LSTM_02'))\r\nencoder2_output, forward_h2, forward_c2, backward_h2, backward_c2 = encoder_LSTM2 (encoder1_output)\r\n\r\n# Concatenate all states together\r\nencoder_states = Concatenate(axis=-1)([forward_h1, forward_c1, forward_h2, forward_c2,\r\n                                       backward_h1, backward_c1, backward_h2, backward_c2])\r\n\r\nencoder_dense = Dense(lstm_dim, activation='relu', name=\"enc_dense\")(encoder_states)\r\n\r\n#---------------------- Decoder--------------------------#\r\n\r\n#states for the first LSTM layer\r\ndecoder_input = Input(shape=(None, len(charset))) #teacher training\r\ndense_h = Dense(lstm_dim, activation='relu', name=\"dec_dense_h1\")\r\ndense_c = Dense(lstm_dim, activation='relu', name=\"dec_dense_c1\")\r\nstate_h = dense_h(encoder_dense)\r\nstate_c = dense_c(encoder_dense)\r\nstates1 =[state_h, state_c]\r\n\r\n\r\n#states for the second LSTM layer\r\ndense_h2 = Dense(lstm_dim, activation='relu', name=\"dec_dense_h2\")\r\ndense_c2 = Dense(lstm_dim, activation='relu', name=\"dec_dense_c2\")\r\nstate_h2 = dense_h2(encoder_dense)\r\nstate_c2 = dense_c2(encoder_dense)\r\nstates2 =[state_h2, state_c2]\r\n\r\n#this goes through a decoding lstm\r\ndecoder_LSTM1 = CuDNNLSTM(lstm_dim, return_sequences=True, name='bd_dec_LSTM_01')\r\ndecoder1_output = decoder_LSTM1(decoder_input, initial_state=states1)\r\n\r\n\r\n#couple the first LSTM with the 2nd LSTM\r\ndecoder_LSTM2 = CuDNNLSTM(lstm_dim, return_sequences=True, name='bd_dec_LSTM_02')\r\ndecoder2_output = decoder_LSTM2(decoder1_output, initial_state=states2) \r\n\r\n#attention layers\r\nattn_layer = AttentionLayer(name='attention_layer')\r\nattn_out, attn_states = attn_layer([encoder2_output, decoder2_output])\r\ndecoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_out, attn_out])\r\n\r\n\r\n#pass hidden states of decoder2_outputs to dense layer with softmax\r\ndecoder_dense = Dense(len(charset), activation='softmax', name=\"dec_dense_softmax\")\r\ndecoder_out = decoder_dense (decoder_concat_input)\r\n\r\n\r\n\r\n#----------------------compilations------------#\r\n\r\n#model compilation (canonical)\r\nmodel = Model(inputs=[encoder_input, decoder_input], outputs=[decoder_out])\r\n#Run training\r\nstart = time.time()\r\nopt=Adam(lr=0.01) #try 0.005\r\n#test other optimizers (rmsprop)\r\nmodel.compile(optimizer=opt, loss='categorical_crossentropy')\r\n\r\n#fit\r\nmodel.fit(x=[pr_train, rx_train], \r\n          y=rx_target, \r\n          batch_size=250, \r\n          epochs=2,\r\n          shuffle = True,\r\n          validation_split=0.2,\r\n          callbacks = [h, rlr, es])\r\n\r\nend = time.time()\r\nprint(end - start)\r\n\r\n```\r\nError:\r\n\r\n> AttributeError                            Traceback (most recent call last)\r\n> <ipython-input-165-c2269e41013e> in <module>\r\n>      64 #attention layers\r\n>      65 attn_layer = AttentionLayer(name='attention_layer')\r\n> ---> 66 attn_out, attn_states = attn_layer([encoder2_output, decoder2_output])\r\n>      67 decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_out, attn_out])\r\n>      68 \r\n> \r\n> ~/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n>     661               kwargs.pop('training')\r\n>     662             inputs, outputs = self._set_connectivity_metadata_(\r\n> --> 663                 inputs, outputs, args, kwargs)\r\n>     664           self._handle_activity_regularization(inputs, outputs)\r\n>     665           self._set_mask_metadata(inputs, outputs, previous_mask)\r\n> \r\n> ~/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in _set_connectivity_metadata_(self, inputs, outputs, args, kwargs)\r\n>    1706     kwargs.pop('mask', None)  # `mask` should not be serialized.\r\n>    1707     self._add_inbound_node(\r\n> -> 1708         input_tensors=inputs, output_tensors=outputs, arguments=kwargs)\r\n>    1709     return inputs, outputs\r\n>    1710 \r\n> \r\n> ~/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in _add_inbound_node(self, input_tensors, output_tensors, arguments)\r\n>    1793     \"\"\"\r\n>    1794     inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,\r\n> -> 1795                                         input_tensors)\r\n>    1796     node_indices = nest.map_structure(lambda t: t._keras_history.node_index,\r\n>    1797                                       input_tensors)\r\n> \r\n> ~/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/util/nest.py in map_structure(func, *structure, **kwargs)\r\n>     513 \r\n>     514   return pack_sequence_as(\r\n> --> 515       structure[0], [func(*x) for x in entries],\r\n>     516       expand_composites=expand_composites)\r\n>     517 \r\n> \r\n> ~/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/util/nest.py in <listcomp>(.0)\r\n>     513 \r\n>     514   return pack_sequence_as(\r\n> --> 515       structure[0], [func(*x) for x in entries],\r\n>     516       expand_composites=expand_composites)\r\n>     517 \r\n> \r\n> ~/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in <lambda>(t)\r\n>    1792             `call` method of the layer at the call that created the node.\r\n>    1793     \"\"\"\r\n> -> 1794     inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,\r\n>    1795                                         input_tensors)\r\n>    1796     node_indices = nest.map_structure(lambda t: t._keras_history.node_index,\r\n> \r\n> AttributeError: 'tuple' object has no attribute 'layer'","closed_by":{"login":"Sum02dean","id":36505689,"node_id":"MDQ6VXNlcjM2NTA1Njg5","avatar_url":"https://avatars.githubusercontent.com/u/36505689?v=4","gravatar_id":"","url":"https://api.github.com/users/Sum02dean","html_url":"https://github.com/Sum02dean","followers_url":"https://api.github.com/users/Sum02dean/followers","following_url":"https://api.github.com/users/Sum02dean/following{/other_user}","gists_url":"https://api.github.com/users/Sum02dean/gists{/gist_id}","starred_url":"https://api.github.com/users/Sum02dean/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Sum02dean/subscriptions","organizations_url":"https://api.github.com/users/Sum02dean/orgs","repos_url":"https://api.github.com/users/Sum02dean/repos","events_url":"https://api.github.com/users/Sum02dean/events{/privacy}","received_events_url":"https://api.github.com/users/Sum02dean/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/thushv89/attention_keras/issues/21/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/thushv89/attention_keras/issues/21/timeline","performed_via_github_app":null,"state_reason":"completed"}