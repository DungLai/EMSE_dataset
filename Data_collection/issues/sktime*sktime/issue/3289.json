{"url":"https://api.github.com/repos/sktime/sktime/issues/3289","repository_url":"https://api.github.com/repos/sktime/sktime","labels_url":"https://api.github.com/repos/sktime/sktime/issues/3289/labels{/name}","comments_url":"https://api.github.com/repos/sktime/sktime/issues/3289/comments","events_url":"https://api.github.com/repos/sktime/sktime/issues/3289/events","html_url":"https://github.com/sktime/sktime/issues/3289","id":1343589193,"node_id":"I_kwDOCVKAsc5QFYtJ","number":3289,"title":"[ENH] Implement ESPRESSO estimator","user":{"login":"miraep8","id":10511777,"node_id":"MDQ6VXNlcjEwNTExNzc3","avatar_url":"https://avatars.githubusercontent.com/u/10511777?v=4","gravatar_id":"","url":"https://api.github.com/users/miraep8","html_url":"https://github.com/miraep8","followers_url":"https://api.github.com/users/miraep8/followers","following_url":"https://api.github.com/users/miraep8/following{/other_user}","gists_url":"https://api.github.com/users/miraep8/gists{/gist_id}","starred_url":"https://api.github.com/users/miraep8/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/miraep8/subscriptions","organizations_url":"https://api.github.com/users/miraep8/orgs","repos_url":"https://api.github.com/users/miraep8/repos","events_url":"https://api.github.com/users/miraep8/events{/privacy}","received_events_url":"https://api.github.com/users/miraep8/received_events","type":"User","site_admin":false},"labels":[{"id":3796180314,"node_id":"LA_kwDOCVKAsc7iRR1a","url":"https://api.github.com/repos/sktime/sktime/labels/enhancement","name":"enhancement","color":"fef2c0","default":true,"description":"Adding new functionality"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2022-08-18T20:08:12Z","updated_at":"2022-09-01T19:35:43Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"### ESPRESSO Entropy and ShaPe awaRe timE-Series SegmentatiOn\r\n\r\n*Note - you can click on the dropdown menus below to get more details where needed*\r\n\r\n**ESPRESSO** is a single parameter method for segmenting time series data in an unsupervised manner.  The full paper describing the algorithm can be found [here](https://arxiv.org/abs/2008.03230) but below is a short summary and plan of attack!  As you can see there are actually many parts to this algorithm, some of which we should be able to interface from other places, others which we may need to write ourselves.  Please let me know if you have any interest in any of the subparts below!! :)  Thanks to @lmmentel for the suggestion that this algorithm would be useful for sktime.\r\n\r\n#### Overview:\r\n\r\n<img width=\"468\" alt=\"image\" src=\"https://user-images.githubusercontent.com/10511777/185407734-b5c9a7ed-e637-4c08-9ec9-70c786c07b47.png\">\r\n\r\n**ESPRESSO** is really just the combination of 2 separate approaches for segmentation - a shape based segmentation (here using their novel metric for shape) and minimization over an entropy based cost function. First it finds potential segment boundaries in the time series data using shape-based segmentation.  Then it uses a greedy search over these potential segment boundaries to minimize an entropy based cost function.  The use of the entropy based search is said to help account for the bias against smaller segments often baked into shape-based approaches.  A shape-based segmentation strategy alone would also struggle to identify segments without repeating shape-patterns, another downside that the optimization over the Information Gain metric is supposed to counteract.\r\n\r\n\r\n<details>\r\n<summary>Shape-Based Segmentation</summary>\r\n\r\n<br>\r\n\r\n**ESPRESSO** uses a technique *weighted chained arc curve* or `WCAC` to estimate the density of pattern repetition over time. (which they claim is more accurate than the related method of the related method `FLOSS`).  To understand `WCAC` it is useful to first understand the Matrix Profile representation (or `MP`) and the Arc technique, which it builds on.\r\n\r\n<details>\r\n<summary> Matrix Profile </summary>\r\n<br>\r\n\r\nMatrix Profile is an all pairs similarity-search for time series data (originating I believe, from Eamonn Keogh's group at UCR).  It depends on one first having established a set of windows over the time series, typically a list of sliding windows of size $m$ across the whole series.\r\n\r\nFor each window ( $w$ ) in the set of all windows of the time series $W$, calculate the set of its neighbors $N$:\r\n\r\n$N(w_i)$ = { $w_j \\in W, s.t. S(w_i, w_j) > t$ }\r\nfor some similarity function $S$, and some threshold $t$.  \r\n\r\nThere exists some distance function $D(w_i, w_j)$ which returns the \"distance\" between $w_i$ and $w_j$\r\n\r\nThe Matrix profile is simply the vector of distances for each window to the nearest \"neighbor\", ie:\r\n\r\n$MP_i = \\min\\limits_{w_j \\in N(w_i)} D(w_j, w_i)$\r\n\r\n</details>\r\n\r\n<details>\r\n<summary> Arc Curve or AC </summary>\r\n<br>\r\n\r\nAn Arc Curve, or AC can be viewed as another way of representing the information stored in the matrix profile (MP) see above.\r\n\r\nTo derive the AC, first imagine that for each entry in the matrix profile $MP_i$, one draws an arc $a_{ij}$ from that index to the index of its nearest neighbor $MP_j$. Each index has exactly one arc leaving it, but can have zero or more integer numbered arcs entering it.\r\n\r\nThe Arc Curve is defined to be the number of arcs \"crossing over\" that point. (e.g. if you have an arc $a_{i,j}$ where j > i it will cross over the points i+1, i+2...... j-2, j-1.  It is a vector the same length as the Matrix Profile of non-negative integers.\r\n</details>\r\n\r\nThe downside of using minimums in AC alone to define boundaries between time segments is that it may not generalize as well to cases where there are repeated segments multiple places within the time series.  To help deal with this issue (and others) the authors propose chained AC (`CAC`) and weighted chained AC (`WCAC`). \r\n\r\n`CAC` is a set of similar sequences in the $j^{th}$ channel of input.  They are ordered in terms of distance to $X^j_i$\r\n\r\n$CAC^j_i$ = { $x_{s1}, x_{s2},...... x_{sl}$ }, (1 $\\leq$ $s_1$..... $s_l$ $\\leq$ n-L + 1)\r\n\r\n$\\forall s_i$, 1 $\\leq s_i \\leq l$ ,  $x_{si} = MPI^j_{x_{s_i-1}} $\r\n\r\n$WCAC^i_j$ = $\\sum \\limits _A \\frac{MP^i_a}{|a - MPI^j_a|} $\r\n\r\nWhere $A$ is defined to be the set:\r\n\r\n$A$ = { $Arc^j_a \\in CAC^j | i \\in [a, MPI^j_a]$ }\r\n\r\nThe algorithms the authors used for both `CAC` and `WCAC` can be found in Algorithm 1 and 2 in the ESPRESSO paper.\r\n\r\nIn the end - the local minima of `WCAC` are taken to be the *candidate* segment boundaries of the time series, and passed on to the next step, entropy based segmentation!\r\n\r\n </details>\r\n\r\n<details>\r\n<summary> Entropy Based Segmentation </summary>\r\n<br>\r\nBy using the candidate boundaries found in step 1, we try to select for those change points that minimize the entropy of their respective/resulting segments. \r\n\r\nThe cost function they seek to minimize is then very simply:\r\n\r\n$\\mathcal{L}$ = $H(X, 0)$ - $\\sum \\limits _i ^{|S' \\cup b| + 1} \\frac{|s_i|}{|X|} H(s_i)$\r\n\r\nWhere $H(s_i)$ is just the Shannon entropy of segment $i$:\r\n\r\n$H(s_i)$ = - $\\sum \\limits _{j = 1}^n p_i^j log(p_i^j)$\r\n\r\nNote that the first term, $H(X, 0)$ is just the entropy of the entire time series as a single segment and doesn't change, thus maximizing the information gain metric becomes equivalent to minimizing the entropy of the constitutive segments, (ie the second term!).\r\n\r\nThe authors essentially just use a greedy search algorithm to minimize the entropy of the constitutive segments using the pool of candidate change points from `WCAC`.   The exact algorithms for how they do so can be seen in Algorithms 3 and 4 from the paper respectively. \r\n</details>\r\n\r\nThe plan of attack is as follows:  \r\n- [x] write a wrapper for the [matrixprofile](https://github.com/matrix-profile-foundation/matrixprofile) python package.\r\n- [ ] using matrixprofile implement their algorithms for `CAC` and `WCAC` in sktime. \r\n- [ ] wrap [antropy](https://github.com/raphaelvallat/antropy) (or similar time series entropy package) to be able to rapidly calculate the entropy of time segments given their boundaries.\r\n- [ ] tie it all together via a Greedy search algorithm\r\n- [ ] As an extension - can also support doing this separately for each dimension (which they did in the original ESPRESSO paper). \r\n\r\nAgain - I would be happy to collaborate on this!  Let me know if you have any interest in any of the above tasks!  I think that wrapping matrixprofile and/or antropy might be a nice place to start if you are newer to sktime. :) I plan to use this issue to track my progress/what I am currently working on. \r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/sktime/sktime/issues/3289/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/sktime/sktime/issues/3289/timeline","performed_via_github_app":null,"state_reason":null}