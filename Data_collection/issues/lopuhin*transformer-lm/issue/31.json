{"url":"https://api.github.com/repos/lopuhin/transformer-lm/issues/31","repository_url":"https://api.github.com/repos/lopuhin/transformer-lm","labels_url":"https://api.github.com/repos/lopuhin/transformer-lm/issues/31/labels{/name}","comments_url":"https://api.github.com/repos/lopuhin/transformer-lm/issues/31/comments","events_url":"https://api.github.com/repos/lopuhin/transformer-lm/issues/31/events","html_url":"https://github.com/lopuhin/transformer-lm/issues/31","id":860308439,"node_id":"MDU6SXNzdWU4NjAzMDg0Mzk=","number":31,"title":"I would like a longer text result","user":{"login":"r23","id":396063,"node_id":"MDQ6VXNlcjM5NjA2Mw==","avatar_url":"https://avatars.githubusercontent.com/u/396063?v=4","gravatar_id":"","url":"https://api.github.com/users/r23","html_url":"https://github.com/r23","followers_url":"https://api.github.com/users/r23/followers","following_url":"https://api.github.com/users/r23/following{/other_user}","gists_url":"https://api.github.com/users/r23/gists{/gist_id}","starred_url":"https://api.github.com/users/r23/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/r23/subscriptions","organizations_url":"https://api.github.com/users/r23/orgs","repos_url":"https://api.github.com/users/r23/repos","events_url":"https://api.github.com/users/r23/events{/privacy}","received_events_url":"https://api.github.com/users/r23/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-04-17T03:02:48Z","updated_at":"2021-04-18T10:29:13Z","closed_at":"2021-04-17T23:49:01Z","author_association":"NONE","active_lock_reason":null,"body":"Hello,\r\n\r\nThank you very much for the wonderful project. It works great! I just have no question about the text length.\r\n\r\nI use the following script \r\nFrom [https://github.com/lopuhin/transformer-lm/issues/2#issuecomment-511742139](https://github.com/lopuhin/transformer-lm/issues/2#issuecomment-511742139)\r\n\r\n```\r\n\r\n#!/usr/bin/env python\r\n# -*- coding: utf-8 -*-\r\n\r\nfrom pathlib import Path\r\nfrom lm import inference\r\n\r\nimport numpy as np\r\n\r\nMODEL_PATH = Path('/..../pytorch_models/de345-root/')\r\n\r\nTOKENS_TO_GENERATE = 38\r\n\r\nTOP_K = 8\r\n\r\nmw = inference.ModelWrapper.load(MODEL_PATH)\r\n\r\ntxt = \"Die Forschung an der k端nstlichen Intelligenz\"\r\n\r\ntokens = mw.tokenize(txt)\r\n\r\nfor i in range(TOKENS_TO_GENERATE):\r\n\r\n    # generate TOP_K potential next tokens\r\n    ntk = mw.get_next_top_k(tokens, TOP_K)\r\n\r\n    # convert log probs to real probs\r\n    logprobs = np.array(list(map(lambda a: a[0], ntk)))\r\n    probs = np.exp(logprobs) / np.exp(logprobs).sum()\r\n\r\n    # pick next token randomly according to probs distribution\r\n    next_token_n = np.random.choice(TOP_K, p=probs)\r\n    next_token = ntk[next_token_n][1]\r\n    # print (next_token)\r\n\r\n    tokens.append(next_token)\r\n\r\nprint(mw.sp_model.DecodePieces(tokens))\r\n```\r\n\r\n### The result\r\n> \r\nDie Forschung an der k端nstlichen Intelligenz, die sich mit der k端nstlichen Intelligenz befassen und die Entwicklung der k端nstlichen Intelligenz vorantreiben will, soll in der Zukunft fortgesetzt werden. Das berichtet Technology Review in seiner aktuellen Ausgabe (online zu bestellen). Das\r\n\r\n\r\nGreat\r\n\r\nI'm afraid I'd like a longer text, comparable to \r\npython3 src/interactive_conditional_samples.py\r\nhttps://github.com/openai/gpt-2/blob/master/src/interactive_conditional_samples.py\r\n\r\nGPT-2 generates there sample texts with 4 paragraphs with 2338 characters 406 words.\r\n\r\nWhat do I have to change in the above script for a longer result text? \r\n\r\nI look forward to hints and tips and thank you already now\r\n\r\nRalf\r\n","closed_by":{"login":"r23","id":396063,"node_id":"MDQ6VXNlcjM5NjA2Mw==","avatar_url":"https://avatars.githubusercontent.com/u/396063?v=4","gravatar_id":"","url":"https://api.github.com/users/r23","html_url":"https://github.com/r23","followers_url":"https://api.github.com/users/r23/followers","following_url":"https://api.github.com/users/r23/following{/other_user}","gists_url":"https://api.github.com/users/r23/gists{/gist_id}","starred_url":"https://api.github.com/users/r23/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/r23/subscriptions","organizations_url":"https://api.github.com/users/r23/orgs","repos_url":"https://api.github.com/users/r23/repos","events_url":"https://api.github.com/users/r23/events{/privacy}","received_events_url":"https://api.github.com/users/r23/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/lopuhin/transformer-lm/issues/31/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/lopuhin/transformer-lm/issues/31/timeline","performed_via_github_app":null,"state_reason":"completed"}