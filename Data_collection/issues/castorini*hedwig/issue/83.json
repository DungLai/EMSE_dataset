{"url":"https://api.github.com/repos/castorini/hedwig/issues/83","repository_url":"https://api.github.com/repos/castorini/hedwig","labels_url":"https://api.github.com/repos/castorini/hedwig/issues/83/labels{/name}","comments_url":"https://api.github.com/repos/castorini/hedwig/issues/83/comments","events_url":"https://api.github.com/repos/castorini/hedwig/issues/83/events","html_url":"https://github.com/castorini/hedwig/issues/83","id":1348149429,"node_id":"I_kwDOCmqoNM5QWyC1","number":83,"title":"UnpicklingError with different BERT models","user":{"login":"alpoktem","id":26279276,"node_id":"MDQ6VXNlcjI2Mjc5Mjc2","avatar_url":"https://avatars.githubusercontent.com/u/26279276?v=4","gravatar_id":"","url":"https://api.github.com/users/alpoktem","html_url":"https://github.com/alpoktem","followers_url":"https://api.github.com/users/alpoktem/followers","following_url":"https://api.github.com/users/alpoktem/following{/other_user}","gists_url":"https://api.github.com/users/alpoktem/gists{/gist_id}","starred_url":"https://api.github.com/users/alpoktem/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alpoktem/subscriptions","organizations_url":"https://api.github.com/users/alpoktem/orgs","repos_url":"https://api.github.com/users/alpoktem/repos","events_url":"https://api.github.com/users/alpoktem/events{/privacy}","received_events_url":"https://api.github.com/users/alpoktem/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-08-23T15:35:21Z","updated_at":"2022-08-23T15:35:21Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi, I'm trying to perform document classification with Hindi language. I want to use BERT models that are adapted to Hindi and Indian languages like [muril-base-cased](https://huggingface.co/google/muril-base-cased) and [muril-large-cased](https://huggingface.co/google/muril-large-cased).\r\n\r\nIn order to load them, I downloaded the models into `hedwig-data/models/bert_pretrained` directory and I added these lines to `constants.py`: \r\n```\r\nPRETRAINED_MODEL_ARCHIVE_MAP = {\r\n    ...\r\n    'muril-large-cased': os.path.join(MODEL_DATA_DIR, 'bert_pretrained', 'muril-large-cased'),\r\n    'muril-base-cased': os.path.join(MODEL_DATA_DIR, 'bert_pretrained', 'muril-base-cased')\r\n\r\n}\r\nPRETRAINED_VOCAB_ARCHIVE_MAP = {\r\n    ...\r\n    'muril-large-cased': os.path.join(MODEL_DATA_DIR, 'bert_pretrained', 'muril-large-cased', 'vocab.txt'),\r\n    'muril-base-cased': os.path.join(MODEL_DATA_DIR, 'bert_pretrained', 'muril-base-cased', 'vocab.txt')\r\n}\r\n\r\n```\r\nI'm getting this UnpicklingError which I think is because of the `transformers` package version.\r\n\r\n```\r\n.../hedwig$ python -m models.bert --dataset MFIN --model muril-base-cased --max-seq-length 256 --batch-size 8 --lr 2e-5 --epochs 1\r\nDevice: CUDA\r\nNumber of GPUs: 2\r\nFP16: False\r\nTraceback (most recent call last):\r\n  File \"/home/twbgmy/anaconda3/envs/hindiclass/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/home/twbgmy/anaconda3/envs/hindiclass/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/twbgmy/play/MFIN/hedwig/models/bert/__main__.py\", line 87, in <module>\r\n    model = BertForSequenceClassification.from_pretrained(pretrained_model_path, num_labels=args.num_labels)\r\n  File \"/home/twbgmy/anaconda3/envs/hindiclass/lib/python3.6/site-packages/transformers/modeling_utils.py\", line 345, in from_pretrained\r\n    state_dict = torch.load(resolved_archive_file, map_location='cpu')\r\n  File \"/home/twbgmy/anaconda3/envs/hindiclass/lib/python3.6/site-packages/torch/serialization.py\", line 358, in load\r\n    return _load(f, map_location, pickle_module)\r\n  File \"/home/twbgmy/anaconda3/envs/hindiclass/lib/python3.6/site-packages/torch/serialization.py\", line 532, in _load\r\n    magic_number = pickle_module.load(f)\r\n_pickle.UnpicklingError: A load persistent id instruction was encountered,\r\nbut no persistent_load function was specified.\r\n```\r\n\r\nAm I doing something wrong? I'd appreciate any guidance.\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/castorini/hedwig/issues/83/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/castorini/hedwig/issues/83/timeline","performed_via_github_app":null,"state_reason":null}