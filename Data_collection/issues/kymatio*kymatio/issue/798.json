{"url":"https://api.github.com/repos/kymatio/kymatio/issues/798","repository_url":"https://api.github.com/repos/kymatio/kymatio","labels_url":"https://api.github.com/repos/kymatio/kymatio/issues/798/labels{/name}","comments_url":"https://api.github.com/repos/kymatio/kymatio/issues/798/comments","events_url":"https://api.github.com/repos/kymatio/kymatio/issues/798/events","html_url":"https://github.com/kymatio/kymatio/issues/798","id":1159577605,"node_id":"I_kwDOCQLq_c5FHcAF","number":798,"title":"Depth-first vs. breadth-first traversal","user":{"login":"OverLordGoldDragon","id":16495490,"node_id":"MDQ6VXNlcjE2NDk1NDkw","avatar_url":"https://avatars.githubusercontent.com/u/16495490?v=4","gravatar_id":"","url":"https://api.github.com/users/OverLordGoldDragon","html_url":"https://github.com/OverLordGoldDragon","followers_url":"https://api.github.com/users/OverLordGoldDragon/followers","following_url":"https://api.github.com/users/OverLordGoldDragon/following{/other_user}","gists_url":"https://api.github.com/users/OverLordGoldDragon/gists{/gist_id}","starred_url":"https://api.github.com/users/OverLordGoldDragon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/OverLordGoldDragon/subscriptions","organizations_url":"https://api.github.com/users/OverLordGoldDragon/orgs","repos_url":"https://api.github.com/users/OverLordGoldDragon/repos","events_url":"https://api.github.com/users/OverLordGoldDragon/events{/privacy}","received_events_url":"https://api.github.com/users/OverLordGoldDragon/received_events","type":"User","site_admin":false},"labels":[{"id":1076176424,"node_id":"MDU6TGFiZWwxMDc2MTc2NDI0","url":"https://api.github.com/repos/kymatio/kymatio/labels/question","name":"question","color":"d876e3","default":true,"description":"Further information is requested"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2022-03-04T12:08:32Z","updated_at":"2022-05-02T14:27:13Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"JTFS ran 40% faster than TS on GPU, and I couldn't fathom why. On CPU it is several times slower, as expected. TS is an exact *subset* of JTFS, so this should be impossible.\r\n\r\nThen it dawned on me, JTFS _batches_ lowpassing for each `n2`. To test, I swapped the compute graph for TS to mimic JTFS: 87% speedup, beating JTFS. Note this is _only_ the lowpassing stage, the `n2<->n1` computes can still be batched in both TS and JTFS. \r\n\r\nTS was still under 40% faster than JTFS in the config I tested, so torch's FFT is either poorly optimized for singletons or exceptionally optimized for batching. Latter seems to be the case since JTFS is way slower on a multi-core CPU, and per the 40%, since all frequential scattering is batched. Averaged over 10 iters:\r\n\r\n```\r\nQ=8\r\nN      | t_ts_old / t_ts_new | t_jtfs / t_ts_new\r\n2048   | 1.69 | 1.37 \r\n8192   | 1.67 | 1.22\r\n32768  | 1.87 | 1.38\r\n131072 | 1.80 | 1.31\r\n\r\nQ=16\r\nN      | t_ts_old / t_ts_new | t_jtfs / t_ts_new\r\n2048   | 1.56 | 1.37 \r\n8192   | 1.72 | 1.23\r\n32768  | 2.16 | 1.28\r\n131072 | 2.02 | 1.43\r\n```\r\n\r\nThink this should be convincing to rewrite the compute graph for `Scattering1D`. My implem below, still needs matching `meta` etc.\r\n\r\n<details><summary><b>Scattering1D</b></summary>\r\n\r\n```python\r\n\r\ndef scattering1d(x, pad_fn, unpad, backend, J, log2_T, psi1, psi2, phi,\r\n        ind_start=None, ind_end=None, oversampling=0,\r\n        max_order=2, average=True, size_scattering=(0, 0, 0),\r\n        out_type='array'):\r\n    \"\"\"\r\n    Main function implementing the 1-D scattering transform.\r\n\r\n    Parameters\r\n    ----------\r\n    x : Tensor\r\n        a torch Tensor of size `(B, 1, N)` where `N` is the temporal size\r\n    psi1 : dictionary\r\n        a dictionary of filters (in the Fourier domain), with keys (`j`, `q`).\r\n        `j` corresponds to the downsampling factor for\r\n        :math:`x \\\\ast psi1[(j, q)]``, and `q` corresponds to a pitch class\r\n        (chroma).\r\n        * psi1[(j, n)] is itself a dictionary, with keys corresponding to the\r\n        dilation factors: psi1[(j, n)][j2] corresponds to a support of size\r\n        :math:`2^{J_\\\\text{max} - j_2}`, where :math:`J_\\\\text{max}` has been\r\n        defined a priori (`J_max = size` of the padding support of the input)\r\n        * psi1[(j, n)] only has real values;\r\n        the tensors are complex so that broadcasting applies\r\n    psi2 : dictionary\r\n        a dictionary of filters, with keys (j2, n2). Same remarks as for psi1\r\n    phi : dictionary\r\n        a dictionary of filters of scale :math:`2^J` with keys (`j`)\r\n        where :math:`2^j` is the downsampling factor.\r\n        The array `phi[j]` is a real-valued filter.\r\n    J : int\r\n        scale of the scattering\r\n    log2_T : int\r\n        (log2 of) temporal support of low-pass filter, controlling amount of\r\n        imposed time-shift invariance and maximum subsampling\r\n    pad_left : int, optional\r\n        how much to pad the signal on the left. Defaults to `0`\r\n    pad_right : int, optional\r\n        how much to pad the signal on the right. Defaults to `0`\r\n    ind_start : dictionary of ints, optional\r\n        indices to truncate the signal to recover only the\r\n        parts which correspond to the actual signal after padding and\r\n        downsampling. Defaults to None\r\n    ind_end : dictionary of ints, optional\r\n        See description of ind_start\r\n    oversampling : int, optional\r\n        how much to oversample the scattering (with respect to :math:`2^J`):\r\n        the higher, the larger the resulting scattering\r\n        tensor along time. Defaults to `0`\r\n    order2 : boolean, optional\r\n        Whether to compute the 2nd order or not. Defaults to `False`.\r\n    average_U1 : boolean, optional\r\n        whether to average the first order vector. Defaults to `True`\r\n    size_scattering : tuple\r\n        Contains the number of channels of the scattering, precomputed for\r\n        speed-up. Defaults to `(0, 0, 0)`.\r\n    vectorize : boolean, optional\r\n        whether to return a dictionary or a tensor. Defaults to False.\r\n\r\n    \"\"\"\r\n    subsample_fourier = backend.subsample_fourier\r\n    modulus = backend.modulus\r\n    rfft = backend.rfft\r\n    ifft = backend.ifft\r\n    irfft = backend.irfft\r\n    cdgmm = backend.cdgmm\r\n    concatenate = backend.concatenate\r\n    concatenate_v2 = backend.concatenate_v2\r\n\r\n    # S is simply a dictionary if we do not perform the averaging...\r\n    batch_size = x.shape[0]\r\n    kJ = max(log2_T - oversampling, 0)\r\n    temporal_size = ind_end[kJ] - ind_start[kJ]\r\n    out_S_0, out_S_1, out_S_2 = [], [], []\r\n\r\n    # pad to a dyadic size and make it complex\r\n    U_0 = pad_fn(x)\r\n    # compute the Fourier transform\r\n    U_0_hat = rfft(U_0)\r\n\r\n    # Get S0\r\n    k0 = max(log2_T - oversampling, 0)\r\n\r\n    if average:\r\n        S_0_c = cdgmm(U_0_hat, phi[0])\r\n        S_0_hat = subsample_fourier(S_0_c, 2**k0)\r\n        S_0_r = irfft(S_0_hat)\r\n\r\n        S_0 = unpad(S_0_r, ind_start[k0], ind_end[k0])\r\n    else:\r\n        S_0 = x\r\n    out_S_0.append({'coef': S_0,\r\n                    'j': (),\r\n                    'n': ()})\r\n\r\n    # First order:\r\n    U_1_list = []\r\n    for n1 in range(len(psi1)):\r\n        # Convolution + downsampling\r\n        j1 = psi1[n1]['j']\r\n\r\n        k1 = max(min(j1, log2_T) - oversampling, 0)\r\n\r\n        assert psi1[n1]['xi'] < 0.5 / (2**k1)\r\n        U_1_c = cdgmm(U_0_hat, psi1[n1][0])\r\n        U_1_hat = subsample_fourier(U_1_c, 2**k1)\r\n        U_1_c = ifft(U_1_hat)\r\n\r\n        # Take the modulus\r\n        U_1_m = modulus(U_1_c)\r\n\r\n        if average or max_order > 1:\r\n            U_1_hat = rfft(U_1_m)\r\n        U_1_list.append(U_1_hat)\r\n\r\n        if average:\r\n            # Convolve with phi_J\r\n            k1_J = max(log2_T - k1 - oversampling, 0)\r\n            S_1_c = cdgmm(U_1_hat, phi[k1])\r\n            S_1_hat = subsample_fourier(S_1_c, 2**k1_J)\r\n            S_1_r = irfft(S_1_hat)\r\n\r\n            S_1 = unpad(S_1_r, ind_start[k1_J + k1], ind_end[k1_J + k1])\r\n        else:\r\n            S_1 = unpad(U_1_m, ind_start[k1], ind_end[k1])\r\n\r\n        out_S_1.append({'coef': S_1,\r\n                        'j': (j1,),\r\n                        'n': (n1,)})\r\n\r\n    if max_order == 2:\r\n        # 2nd order\r\n        for n2 in range(len(psi2)):\r\n            j2 = psi2[n2]['j']\r\n\r\n            if j2 == 0:\r\n                continue\r\n\r\n            Y_2_list = []\r\n            for n1 in range(len(U_1_list)):\r\n                j1 = psi1[n1]['j']\r\n                if j1 >= j2:\r\n                    continue\r\n                U_1_hat = U_1_list[n1]\r\n                k1 = max(min(j1, log2_T) - oversampling, 0)\r\n\r\n                assert psi2[n2]['xi'] < psi1[n1]['xi']\r\n\r\n                # convolution + downsampling\r\n                k2 = max(min(j2, log2_T) - k1 - oversampling, 0)\r\n\r\n                U_2_c = cdgmm(U_1_hat, psi2[n2][k1])\r\n                U_2_hat = subsample_fourier(U_2_c, 2**k2)\r\n                # take the modulus\r\n                U_2_c = ifft(U_2_hat)\r\n\r\n                U_2_m = modulus(U_2_c)\r\n                Y_2_list.append(U_2_m)\r\n\r\n            if average:\r\n                U_2_arr = concatenate_v2(Y_2_list, axis=1)\r\n                U_2_hat = rfft(U_2_arr)\r\n\r\n                # Convolve with phi_J\r\n                k2_J = max(log2_T - k2 - k1 - oversampling, 0)\r\n\r\n                S_2_c = cdgmm(U_2_hat, phi[k1 + k2])\r\n                S_2_hat = subsample_fourier(S_2_c, 2**k2_J)\r\n                S_2_r = irfft(S_2_hat)\r\n\r\n                S_2 = unpad(S_2_r, ind_start[k1 + k2 + k2_J],\r\n                            ind_end[k1 + k2 + k2_J])\r\n            else:\r\n                S_2 = unpad(U_2_m, ind_start[k1 + k2], ind_end[k1 + k2])\r\n\r\n            for n1 in range(len(U_1_list)):\r\n                j1 = psi1[n1]['j']\r\n                if j1 >= j2:\r\n                    continue\r\n                out_S_2.append({'coef': S_2[:, n1:n1+1],\r\n                                'j': (j1, j2),\r\n                                'n': (n1, n2)})\r\n\r\n    out_S = []\r\n    out_S.extend(out_S_0)\r\n    out_S.extend(out_S_1)\r\n    out_S.extend(out_S_2)\r\n\r\n    if out_type == 'array' and average:\r\n        out_S = concatenate([x['coef'] for x in out_S])\r\n\r\n    return out_S\r\n\r\n__all__ = ['scattering1d']\r\n```\r\n\r\n</details>\r\n\r\n<details><summary><b>benchmark</b></summary>\r\n\r\n```python\r\n# -*- coding: utf-8 -*-\r\nimport numpy as np\r\nimport torch\r\nimport torch.utils.benchmark as benchmark\r\nfrom kymatio import Scattering1D, TimeFrequencyScattering1D\r\nfrom kymatio.visuals import plotscat\r\nfrom timeit import default_timer as dtime\r\n\r\ndef timeit(fn, n_iters=10):\r\n    t0 = dtime()\r\n    for _ in range(n_iters):\r\n        fn()\r\n        torch.cuda.empty_cache()\r\n        torch.cuda.synchronize()\r\n    return (dtime() - t0) / n_iters\r\n\r\n\r\ndef sc0(sc, x):\r\n    return sc(x)\r\n\r\ndef sc1(jtfs, x):\r\n    return jtfs(x)\r\n\r\n#%%\r\ndef bench(device, N, params_tm, params_fr, n_iters=10, dont_print=()):\r\n    GPU = bool(device == 'gpu')\r\n    frontend = 'torch' if GPU else 'numpy'\r\n\r\n    x = (torch.randn(N, device='cuda') if GPU else\r\n         np.random.randn(N))\r\n    sc   = Scattering1D(shape=N, **params_tm, frontend=frontend)\r\n    jtfs = TimeFrequencyScattering1D(shape=N, **params_tm, **params_fr,\r\n                                     frontend=frontend)\r\n    if GPU:\r\n        sc = sc.cuda()\r\n        jtfs = jtfs.cuda()\r\n\r\n    # warmup\r\n    _ = sc(x)\r\n    _ = jtfs(x)\r\n\r\n    if GPU:\r\n        t_sc_fn = benchmark.Timer(\r\n            stmt='sc0(sc, x)',\r\n            setup='from __main__ import sc0',\r\n            globals={'x': x, 'sc': sc},\r\n        )\r\n        t_jtfs_fn = benchmark.Timer(\r\n            stmt='sc1(jtfs, x)',\r\n            setup='from __main__ import sc1',\r\n            globals={'x': x, 'jtfs': jtfs},\r\n        )\r\n        t_sc_obj   = t_sc_fn.timeit(  n_iters)\r\n        t_jtfs_obj = t_jtfs_fn.timeit(n_iters)\r\n        t_sc   = t_sc_obj.mean\r\n        t_jtfs = t_jtfs_obj.mean\r\n    else:\r\n        t_sc   = timeit(lambda: sc(x),   n_iters)\r\n        t_jtfs = timeit(lambda: jtfs(x), n_iters)\r\n\r\n    tm_str = \", \".join(f\"{k}={v}\" for k, v in params_tm.items()\r\n                       if k not in dont_print)\r\n    fr_str = \", \".join(f\"{k}={v}\" for k, v in params_fr.items()\r\n                       if k not in dont_print)\r\n    print((\"N={}, {}\\n\"\r\n           \"{}, {}\\n\"\r\n           \"SC:   {:.3f} sec\\n\"\r\n           \"JTFS: {:.3f} sec\\n\").format(N, device.upper(), tm_str, fr_str,\r\n                                        t_sc, t_jtfs))\r\n    return t_sc, t_jtfs\r\n\r\nn_iters = 10\r\nN_all = (2048, 8192, 32768, 131072)[:]\r\ndevices = ('gpu', 'cpu')[:1]\r\n\r\nparams_tm = dict(Q=8, max_pad_factor=1)\r\nparams_fr = dict(F=8, J_fr=5, Q_fr=1, max_pad_factor_fr=1,\r\n                 pad_mode_fr='zero')\r\ndont_print = ('max_pad_factor', 'max_pad_factor_fr', 'pad_mode_fr')\r\n\r\nt_sc_all, t_jtfs_all = {}, {}\r\nfor device in devices:\r\n    t_sc_all[device], t_jtfs_all[device] = [], []\r\n    for N in N_all:\r\n        params_tm.update(dict(T=N//4, J=int(np.log2(N) - 2)))\r\n        t_sc, t_jtfs = bench(device, N, params_tm, params_fr, n_iters, dont_print)\r\n        t_sc_all[device].append(t_sc)\r\n        t_jtfs_all[device].append(t_jtfs)\r\n\r\n#%%\r\nfor device in devices:\r\n    r = np.array(t_jtfs_all[device]) / np.array(t_sc_all[device])\r\n    plotscat(\r\n        np.log2(N_all), r,\r\n        title=\"t_jtfs / t_sc | {}, {}-iter avg\".format(device.upper(), n_iters),\r\n        xlabel='log2(N)', ylabel='time [sec]', ylims=(0, 1.05*r.max()), show=1)\r\n```\r\n\r\n</details>","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kymatio/kymatio/issues/798/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kymatio/kymatio/issues/798/timeline","performed_via_github_app":null,"state_reason":null}