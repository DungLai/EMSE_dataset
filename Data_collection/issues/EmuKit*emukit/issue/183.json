{"url":"https://api.github.com/repos/EmuKit/emukit/issues/183","repository_url":"https://api.github.com/repos/EmuKit/emukit","labels_url":"https://api.github.com/repos/EmuKit/emukit/issues/183/labels{/name}","comments_url":"https://api.github.com/repos/EmuKit/emukit/issues/183/comments","events_url":"https://api.github.com/repos/EmuKit/emukit/issues/183/events","html_url":"https://github.com/EmuKit/emukit/issues/183","id":429704286,"node_id":"MDU6SXNzdWU0Mjk3MDQyODY=","number":183,"title":"Active Kriging Monte Carlo Simulation","user":{"login":"JCSadeghi","id":23333857,"node_id":"MDQ6VXNlcjIzMzMzODU3","avatar_url":"https://avatars.githubusercontent.com/u/23333857?v=4","gravatar_id":"","url":"https://api.github.com/users/JCSadeghi","html_url":"https://github.com/JCSadeghi","followers_url":"https://api.github.com/users/JCSadeghi/followers","following_url":"https://api.github.com/users/JCSadeghi/following{/other_user}","gists_url":"https://api.github.com/users/JCSadeghi/gists{/gist_id}","starred_url":"https://api.github.com/users/JCSadeghi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JCSadeghi/subscriptions","organizations_url":"https://api.github.com/users/JCSadeghi/orgs","repos_url":"https://api.github.com/users/JCSadeghi/repos","events_url":"https://api.github.com/users/JCSadeghi/events{/privacy}","received_events_url":"https://api.github.com/users/JCSadeghi/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2019-04-05T11:15:24Z","updated_at":"2019-04-10T15:08:42Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi emukit team,\r\n\r\nI am considering implementing results from this paper https://www.sciencedirect.com/science/article/pii/S0167473011000038 in emukit. I don't think it's too different from your quadrature implementation.\r\n\r\nThe main additions would be:\r\n\r\n1. probability of misclassification aquisition function\r\n2. integrate the GP over an arbitrary probability density using Monte Carlo simulation\r\n3. use the Monte Carlo simulation to define an exit criterion for the learning loop (as in the paper)\r\n\r\nI noticed that most of your tutorials (e.g. sensitivity analysis) are using uniform random variables for the inputs, and #130 has already discussed integrating over a normal density. I'm wondering if you have any suggestions/plans for the best way to achieve 2. Perhaps I should make use of the distributions from numpy?\r\n\r\nAny advice is much appreciated,\r\n\r\nKind Regards,\r\nJonathan","closed_by":null,"reactions":{"url":"https://api.github.com/repos/EmuKit/emukit/issues/183/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/EmuKit/emukit/issues/183/timeline","performed_via_github_app":null,"state_reason":null}