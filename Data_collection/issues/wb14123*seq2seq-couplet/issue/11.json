{"url":"https://api.github.com/repos/wb14123/seq2seq-couplet/issues/11","repository_url":"https://api.github.com/repos/wb14123/seq2seq-couplet","labels_url":"https://api.github.com/repos/wb14123/seq2seq-couplet/issues/11/labels{/name}","comments_url":"https://api.github.com/repos/wb14123/seq2seq-couplet/issues/11/comments","events_url":"https://api.github.com/repos/wb14123/seq2seq-couplet/issues/11/events","html_url":"https://github.com/wb14123/seq2seq-couplet/issues/11","id":382112405,"node_id":"MDU6SXNzdWUzODIxMTI0MDU=","number":11,"title":"tensorflow.python.framework.errors_impl.ResourceExhaustedError","user":{"login":"Crescentz","id":35165563,"node_id":"MDQ6VXNlcjM1MTY1NTYz","avatar_url":"https://avatars.githubusercontent.com/u/35165563?v=4","gravatar_id":"","url":"https://api.github.com/users/Crescentz","html_url":"https://github.com/Crescentz","followers_url":"https://api.github.com/users/Crescentz/followers","following_url":"https://api.github.com/users/Crescentz/following{/other_user}","gists_url":"https://api.github.com/users/Crescentz/gists{/gist_id}","starred_url":"https://api.github.com/users/Crescentz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Crescentz/subscriptions","organizations_url":"https://api.github.com/users/Crescentz/orgs","repos_url":"https://api.github.com/users/Crescentz/repos","events_url":"https://api.github.com/users/Crescentz/events{/privacy}","received_events_url":"https://api.github.com/users/Crescentz/received_events","type":"User","site_admin":false},"labels":[{"id":846740465,"node_id":"MDU6TGFiZWw4NDY3NDA0NjU=","url":"https://api.github.com/repos/wb14123/seq2seq-couplet/labels/question","name":"question","color":"d876e3","default":true,"description":"Further information is requested"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2018-11-19T08:53:10Z","updated_at":"2022-05-05T14:07:35Z","closed_at":"2022-05-05T14:06:51Z","author_association":"NONE","active_lock_reason":null,"body":"Traceback (most recent call last):\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1307, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1409, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[32,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[Node: bidirectional_rnn/fw/fw/while/fw/multi_rnn_cell/cell_1/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](bidirectional_rnn/fw/fw/while/fw/multi_rnn_cell/cell_1/basic_lstm_cell/concat, bidirectional_rnn/fw/fw/while/fw/multi_rnn_cell/cell_1/basic_lstm_cell/MatMul/Enter)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\t [[Node: decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/All/_129 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_862_d..._equal/All\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopdecoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_0/_5)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:/CODE/project/tensorflow/seq2seq-couplet/couplet.py\", line 15, in <module>\r\n    m.train(5000000)\r\n  File \"D:\\CODE\\project\\tensorflow\\seq2seq-couplet\\model.py\", line 149, in train\r\n    self.train_target_seq_len: target_seq_len})\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[32,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[Node: bidirectional_rnn/fw/fw/while/fw/multi_rnn_cell/cell_1/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](bidirectional_rnn/fw/fw/while/fw/multi_rnn_cell/cell_1/basic_lstm_cell/concat, bidirectional_rnn/fw/fw/while/fw/multi_rnn_cell/cell_1/basic_lstm_cell/MatMul/Enter)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\t [[Node: decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/All/_129 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_862_d..._equal/All\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopdecoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_0/_5)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nCaused by op 'bidirectional_rnn/fw/fw/while/fw/multi_rnn_cell/cell_1/basic_lstm_cell/MatMul', defined at:\r\n  File \"D:/CODE/project/tensorflow/seq2seq-couplet/couplet.py\", line 13, in <module>\r\n    restore_model=False)\r\n  File \"D:\\CODE\\project\\tensorflow\\seq2seq-couplet\\model.py\", line 45, in __init__\r\n    self._init_train()\r\n  File \"D:\\CODE\\project\\tensorflow\\seq2seq-couplet\\model.py\", line 72, in _init_train\r\n    self.num_units, self.layers, self.dropout)\r\n  File \"D:\\CODE\\project\\tensorflow\\seq2seq-couplet\\seq2seq.py\", line 129, in seq2seq\r\n    num_units, layers, input_keep_prob)\r\n  File \"D:\\CODE\\project\\tensorflow\\seq2seq-couplet\\seq2seq.py\", line 26, in bi_encoder\r\n    time_major = False)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 403, in bidirectional_dynamic_rnn\r\n    time_major=time_major, scope=fw_scope)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 618, in dynamic_rnn\r\n    dtype=dtype)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 815, in _dynamic_rnn_loop\r\n    swap_memory=swap_memory)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3209, in while_loop\r\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2941, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2878, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3179, in <lambda>\r\n    body = lambda i, lv: (i + 1, orig_body(*lv))\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 784, in _time_step\r\n    skip_conditionals=True)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 239, in _rnn_step\r\n    new_output, new_state = call_cell()\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 772, in <lambda>\r\n    call_cell = lambda: cell(input_t, state)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 232, in __call__\r\n    return super(RNNCell, self).__call__(inputs, state)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 329, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 703, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 1325, in call\r\n    cur_inp, new_state = cell(cur_inp, cur_state)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 1126, in __call__\r\n    output, new_state = self._cell(inputs, state, scope=scope)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 339, in __call__\r\n    *args, **kwargs)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 329, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 703, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 638, in call\r\n    array_ops.concat([inputs, h], 1), self._kernel)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2014, in matmul\r\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 4567, in mat_mul\r\n    name=name)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\47263\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[Node: bidirectional_rnn/fw/fw/while/fw/multi_rnn_cell/cell_1/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](bidirectional_rnn/fw/fw/while/fw/multi_rnn_cell/cell_1/basic_lstm_cell/concat, bidirectional_rnn/fw/fw/while/fw/multi_rnn_cell/cell_1/basic_lstm_cell/MatMul/Enter)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\t [[Node: decoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/All/_129 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_862_d..._equal/All\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopdecoder/while/BasicDecoderStep/decoder/attention_wrapper/assert_equal/Assert/Assert/data_0/_5)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.","closed_by":{"login":"wb14123","id":1906051,"node_id":"MDQ6VXNlcjE5MDYwNTE=","avatar_url":"https://avatars.githubusercontent.com/u/1906051?v=4","gravatar_id":"","url":"https://api.github.com/users/wb14123","html_url":"https://github.com/wb14123","followers_url":"https://api.github.com/users/wb14123/followers","following_url":"https://api.github.com/users/wb14123/following{/other_user}","gists_url":"https://api.github.com/users/wb14123/gists{/gist_id}","starred_url":"https://api.github.com/users/wb14123/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wb14123/subscriptions","organizations_url":"https://api.github.com/users/wb14123/orgs","repos_url":"https://api.github.com/users/wb14123/repos","events_url":"https://api.github.com/users/wb14123/events{/privacy}","received_events_url":"https://api.github.com/users/wb14123/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/wb14123/seq2seq-couplet/issues/11/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/wb14123/seq2seq-couplet/issues/11/timeline","performed_via_github_app":null,"state_reason":"completed"}