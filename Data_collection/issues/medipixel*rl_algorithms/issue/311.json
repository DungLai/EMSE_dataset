{"url":"https://api.github.com/repos/medipixel/rl_algorithms/issues/311","repository_url":"https://api.github.com/repos/medipixel/rl_algorithms","labels_url":"https://api.github.com/repos/medipixel/rl_algorithms/issues/311/labels{/name}","comments_url":"https://api.github.com/repos/medipixel/rl_algorithms/issues/311/comments","events_url":"https://api.github.com/repos/medipixel/rl_algorithms/issues/311/events","html_url":"https://github.com/medipixel/rl_algorithms/issues/311","id":836839708,"node_id":"MDU6SXNzdWU4MzY4Mzk3MDg=","number":311,"title":"Reprise RainbowIQN or IQN for PongNoFrameskip-v4","user":{"login":"pytorchinfo","id":39092522,"node_id":"MDQ6VXNlcjM5MDkyNTIy","avatar_url":"https://avatars.githubusercontent.com/u/39092522?v=4","gravatar_id":"","url":"https://api.github.com/users/pytorchinfo","html_url":"https://github.com/pytorchinfo","followers_url":"https://api.github.com/users/pytorchinfo/followers","following_url":"https://api.github.com/users/pytorchinfo/following{/other_user}","gists_url":"https://api.github.com/users/pytorchinfo/gists{/gist_id}","starred_url":"https://api.github.com/users/pytorchinfo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pytorchinfo/subscriptions","organizations_url":"https://api.github.com/users/pytorchinfo/orgs","repos_url":"https://api.github.com/users/pytorchinfo/repos","events_url":"https://api.github.com/users/pytorchinfo/events{/privacy}","received_events_url":"https://api.github.com/users/pytorchinfo/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-03-20T15:39:12Z","updated_at":"2021-03-24T15:21:52Z","closed_at":"2021-03-24T15:21:52Z","author_association":"NONE","active_lock_reason":null,"body":"I notice that there was an amazing result that used RainbowIQN (as well as plain IQN) to accomplishes the perfect score (21) for the environment `PongNoFrameskip-v4`. Thanks for this amazing result.\r\n\r\nUnfortunately, I do not know how to reprise this results. Could the latest repo support such training? If not, what command as well what version of this repo need to be used to reprise the result? Thanks!\r\n\r\n@Curt-Park","closed_by":{"login":"pytorchinfo","id":39092522,"node_id":"MDQ6VXNlcjM5MDkyNTIy","avatar_url":"https://avatars.githubusercontent.com/u/39092522?v=4","gravatar_id":"","url":"https://api.github.com/users/pytorchinfo","html_url":"https://github.com/pytorchinfo","followers_url":"https://api.github.com/users/pytorchinfo/followers","following_url":"https://api.github.com/users/pytorchinfo/following{/other_user}","gists_url":"https://api.github.com/users/pytorchinfo/gists{/gist_id}","starred_url":"https://api.github.com/users/pytorchinfo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pytorchinfo/subscriptions","organizations_url":"https://api.github.com/users/pytorchinfo/orgs","repos_url":"https://api.github.com/users/pytorchinfo/repos","events_url":"https://api.github.com/users/pytorchinfo/events{/privacy}","received_events_url":"https://api.github.com/users/pytorchinfo/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/medipixel/rl_algorithms/issues/311/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/medipixel/rl_algorithms/issues/311/timeline","performed_via_github_app":null,"state_reason":"completed"}