[{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/comments/514255318","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/369#issuecomment-514255318","issue_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/369","id":514255318,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDI1NTMxOA==","user":{"login":"AlexEMG","id":20850270,"node_id":"MDQ6VXNlcjIwODUwMjcw","avatar_url":"https://avatars.githubusercontent.com/u/20850270?v=4","gravatar_id":"","url":"https://api.github.com/users/AlexEMG","html_url":"https://github.com/AlexEMG","followers_url":"https://api.github.com/users/AlexEMG/followers","following_url":"https://api.github.com/users/AlexEMG/following{/other_user}","gists_url":"https://api.github.com/users/AlexEMG/gists{/gist_id}","starred_url":"https://api.github.com/users/AlexEMG/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AlexEMG/subscriptions","organizations_url":"https://api.github.com/users/AlexEMG/orgs","repos_url":"https://api.github.com/users/AlexEMG/repos","events_url":"https://api.github.com/users/AlexEMG/events{/privacy}","received_events_url":"https://api.github.com/users/AlexEMG/received_events","type":"User","site_admin":false},"created_at":"2019-07-23T15:15:37Z","updated_at":"2019-07-23T15:15:37Z","author_association":"MEMBER","body":"Dear @kgj1234,\r\n\r\nYou're right -- the short answer: when the labeling is good enough filtering is not required in our experience. There are filters included in DLC if this is needed (see below).\r\n\r\nLong answer:\r\nWe have thought about this -- in the original paper [DeepLabCut: markerless pose estimation of user-defined body parts with deep learning](https://www.nature.com/articles/s41593-018-0209-y), we write:\r\n\r\n\"As presented, DeepLabCut extracts the posture data frame by frame, but one can add temporal filtering to improve performance (as for other approaches). Here we omitted such methods because of the high precision of the model without these additional steps, as well as to highlight the accurate prediction based on single frames **solely driven by within-frame visual information** in a variety of contexts.\r\n\r\nWhile temporal information could indeed be beneficial in certain contexts, challenges remain to using end-to-end-trained deep architectures for video data to extract postures. Because of the curse of dimensionality, deep architectures on videos must rely on input images with lower spatial resolution, and thus the best-performing action recognition algorithms still rely on frame-by-frame analysis with deep networks pretrained on ImageNet as a result of hardware limitations. As this is an active area of research, we believe this situation is likely to change with improvements in hardware (and in deep learning algorithms), and this should have a strong influence on pose estimation in the future. Therefore currently, in situations where occlusions are very common, such as in social behaviors, pairwise interactions could also be added to improve performance. Here we have focused on the deep feature detectors alone to demonstrate remarkable transfer learning for laboratory tasks without the need for such extensions.\"\r\n\r\nI omitted the references for clarity here - but you can find them in the paper. The package allows filtering as post-processing, after inference. You can use it by:\r\n\r\n```deeplabcut.filterpredictions```\r\n\r\nThe docs state:\r\n```Signature: deeplabcut.filterpredictions(config, video, videotype='avi', shuffle=1, trainingsetindex=0, p_bound=0.001, ARdegree=3, MAdegree=1, alpha=0.01, save_as_csv=True, destfolder=None)\r\nDocstring:\r\nFits frame-by-frame pose predictions with SARIMAX model.\r\n\r\nParameter\r\n----------\r\nconfig : string\r\n    Full path of the config.yaml file as a string.\r\n\r\nvideo : string\r\n    Full path of the video to extract the frame from. Make sure that this video is already analyzed.\r\n\r\nshuffle : int, optional\r\n    The shufle index of training dataset. The extracted frames will be stored in the labeled-dataset for\r\n    the corresponding shuffle of training dataset. Default is set to 1\r\n\r\ntrainingsetindex: int, optional\r\n    Integer specifying which TrainingsetFraction to use. By default the first (note that TrainingFraction is a list in config.yaml).\r\n\r\ncomparisonbodyparts: list of strings, optional\r\n    This select the body parts for which SARIMAX models are fit. Either ``all``, then all body parts\r\n    from config.yaml are used orr a list of strings that are a subset of the full list.\r\n    E.g. ['hand','Joystick'] for the demo Reaching-Mackenzie-2018-08-30/config.yaml to select only these two body parts.\r\n\r\np_bound: float between 0 and 1, optional\r\n    For outlieralgorithm 'uncertain' this parameter defines the likelihood below, \r\n    below which a body part will be consided as missing data for filtering purposes.\r\n\r\nARdegree: int, optional\r\n    For outlieralgorithm 'fitting': Autoregressive degree of Sarimax model degree.\r\n    see https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html\r\n\r\nMAdegree: int\r\n    For outlieralgorithm 'fitting': Moving Avarage degree of Sarimax model degree.\r\n    See https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html\r\n\r\nalpha: float\r\n    Significance level for detecting outliers based on confidence interval of fitted SARIMAX model.\r\n\r\nsave_as_csv: bool, optional\r\n    Saves the predictions in a .csv file. The default is ``False``; if provided it must be either ``True`` or ``False``\r\n\r\ndestfolder: string, optional\r\n    Specifies the destination folder for analysis data (default is the path of the video). Note that for subsequent analysis this \r\n    folder also needs to be passed.\r\n\r\nExample\r\n--------\r\ndeeplabcut.filterpredictions('C:\\myproject\\reaching-task\\config.yaml',['C:\\myproject\\trailtracking-task\\test.mp4'],shuffle=3,ARdegree=5,MAdegree=2)\r\n\r\nOne can then use the filtered rather than the frame-by-frame predictions by calling:\r\n    \r\ndeeplabcut.plot_trajectories('C:\\myproject\\reaching-task\\config.yaml',['C:\\myproject\\trailtracking-task\\test.mp4'],shuffle=3,filtered=True)\r\n\r\ndeeplabcut.create_labeled_video('C:\\myproject\\reaching-task\\config.yaml',['C:\\myproject\\trailtracking-task\\test.mp4'],shuffle=3,filtered=True)\r\n--------\r\n\r\nReturns filtered pandas array with the same structure as normal output of network.```\r\n\r\nHope that helps! There will be some additional filters in the future, so stay tuned!","reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/comments/514255318/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"AlexEMG","id":20850270,"node_id":"MDQ6VXNlcjIwODUwMjcw","avatar_url":"https://avatars.githubusercontent.com/u/20850270?v=4","gravatar_id":"","url":"https://api.github.com/users/AlexEMG","html_url":"https://github.com/AlexEMG","followers_url":"https://api.github.com/users/AlexEMG/followers","following_url":"https://api.github.com/users/AlexEMG/following{/other_user}","gists_url":"https://api.github.com/users/AlexEMG/gists{/gist_id}","starred_url":"https://api.github.com/users/AlexEMG/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AlexEMG/subscriptions","organizations_url":"https://api.github.com/users/AlexEMG/orgs","repos_url":"https://api.github.com/users/AlexEMG/repos","events_url":"https://api.github.com/users/AlexEMG/events{/privacy}","received_events_url":"https://api.github.com/users/AlexEMG/received_events","type":"User","site_admin":false}},{"id":2503447328,"node_id":"MDExOkNsb3NlZEV2ZW50MjUwMzQ0NzMyOA==","url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/events/2503447328","actor":{"login":"AlexEMG","id":20850270,"node_id":"MDQ6VXNlcjIwODUwMjcw","avatar_url":"https://avatars.githubusercontent.com/u/20850270?v=4","gravatar_id":"","url":"https://api.github.com/users/AlexEMG","html_url":"https://github.com/AlexEMG","followers_url":"https://api.github.com/users/AlexEMG/followers","following_url":"https://api.github.com/users/AlexEMG/following{/other_user}","gists_url":"https://api.github.com/users/AlexEMG/gists{/gist_id}","starred_url":"https://api.github.com/users/AlexEMG/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AlexEMG/subscriptions","organizations_url":"https://api.github.com/users/AlexEMG/orgs","repos_url":"https://api.github.com/users/AlexEMG/repos","events_url":"https://api.github.com/users/AlexEMG/events{/privacy}","received_events_url":"https://api.github.com/users/AlexEMG/received_events","type":"User","site_admin":false},"event":"closed","commit_id":null,"commit_url":null,"created_at":"2019-07-23T15:15:38Z","state_reason":null,"performed_via_github_app":null},{"id":2503447343,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MjUwMzQ0NzM0Mw==","url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/events/2503447343","actor":{"login":"kgj1234","id":24851530,"node_id":"MDQ6VXNlcjI0ODUxNTMw","avatar_url":"https://avatars.githubusercontent.com/u/24851530?v=4","gravatar_id":"","url":"https://api.github.com/users/kgj1234","html_url":"https://github.com/kgj1234","followers_url":"https://api.github.com/users/kgj1234/followers","following_url":"https://api.github.com/users/kgj1234/following{/other_user}","gists_url":"https://api.github.com/users/kgj1234/gists{/gist_id}","starred_url":"https://api.github.com/users/kgj1234/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kgj1234/subscriptions","organizations_url":"https://api.github.com/users/kgj1234/orgs","repos_url":"https://api.github.com/users/kgj1234/repos","events_url":"https://api.github.com/users/kgj1234/events{/privacy}","received_events_url":"https://api.github.com/users/kgj1234/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2019-07-23T15:15:38Z","performed_via_github_app":null},{"id":2503447347,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDI1MDM0NDczNDc=","url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/events/2503447347","actor":{"login":"kgj1234","id":24851530,"node_id":"MDQ6VXNlcjI0ODUxNTMw","avatar_url":"https://avatars.githubusercontent.com/u/24851530?v=4","gravatar_id":"","url":"https://api.github.com/users/kgj1234","html_url":"https://github.com/kgj1234","followers_url":"https://api.github.com/users/kgj1234/followers","following_url":"https://api.github.com/users/kgj1234/following{/other_user}","gists_url":"https://api.github.com/users/kgj1234/gists{/gist_id}","starred_url":"https://api.github.com/users/kgj1234/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kgj1234/subscriptions","organizations_url":"https://api.github.com/users/kgj1234/orgs","repos_url":"https://api.github.com/users/kgj1234/repos","events_url":"https://api.github.com/users/kgj1234/events{/privacy}","received_events_url":"https://api.github.com/users/kgj1234/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2019-07-23T15:15:38Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/comments/515206078","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/369#issuecomment-515206078","issue_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/369","id":515206078,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNTIwNjA3OA==","user":{"login":"kgj1234","id":24851530,"node_id":"MDQ6VXNlcjI0ODUxNTMw","avatar_url":"https://avatars.githubusercontent.com/u/24851530?v=4","gravatar_id":"","url":"https://api.github.com/users/kgj1234","html_url":"https://github.com/kgj1234","followers_url":"https://api.github.com/users/kgj1234/followers","following_url":"https://api.github.com/users/kgj1234/following{/other_user}","gists_url":"https://api.github.com/users/kgj1234/gists{/gist_id}","starred_url":"https://api.github.com/users/kgj1234/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kgj1234/subscriptions","organizations_url":"https://api.github.com/users/kgj1234/orgs","repos_url":"https://api.github.com/users/kgj1234/repos","events_url":"https://api.github.com/users/kgj1234/events{/privacy}","received_events_url":"https://api.github.com/users/kgj1234/received_events","type":"User","site_admin":false},"created_at":"2019-07-25T20:40:34Z","updated_at":"2019-07-25T20:40:34Z","author_association":"NONE","body":"Thanks for your response.\n\nOn Tue, Jul 23, 2019 at 8:18 AM Alexander Mathis <notifications@github.com>\nwrote:\n\n> Dear @kgj1234 <https://github.com/kgj1234>,\n>\n> You're right -- the short answer: when the labeling is good enough\n> filtering is not required in our experience. There are filters included in\n> DLC if this is needed (see below).\n>\n> Long answer:\n> We have thought about this -- in the original paper DeepLabCut:\n> markerless pose estimation of user-defined body parts with deep learning\n> <https://www.nature.com/articles/s41593-018-0209-y>, we write:\n>\n> \"As presented, DeepLabCut extracts the posture data frame by frame, but\n> one can add temporal filtering to improve performance (as for other\n> approaches). Here we omitted such methods because of the high precision of\n> the model without these additional steps, as well as to highlight the\n> accurate prediction based on single frames *solely driven by within-frame\n> visual information* in a variety of contexts.\n>\n> While temporal information could indeed be beneficial in certain contexts,\n> challenges remain to using end-to-end-trained deep architectures for video\n> data to extract postures. Because of the curse of dimensionality, deep\n> architectures on videos must rely on input images with lower spatial\n> resolution, and thus the best-performing action recognition algorithms\n> still rely on frame-by-frame analysis with deep networks pretrained on\n> ImageNet as a result of hardware limitations. As this is an active area of\n> research, we believe this situation is likely to change with improvements\n> in hardware (and in deep learning algorithms), and this should have a\n> strong influence on pose estimation in the future. Therefore currently, in\n> situations where occlusions are very common, such as in social behaviors,\n> pairwise interactions could also be added to improve performance. Here we\n> have focused on the deep feature detectors alone to demonstrate remarkable\n> transfer learning for laboratory tasks without the need for such\n> extensions.\"\n>\n> I omitted the references for clarity here - but you can find them in the\n> paper. The package allows filtering as post-processing, after inference.\n> You can use it by:\n>\n> deeplabcut.filterpredictions\n>\n> The docs state:\n>\n> Docstring:\n> Fits frame-by-frame pose predictions with SARIMAX model.\n>\n> Parameter\n> ----------\n> config : string\n>     Full path of the config.yaml file as a string.\n>\n> video : string\n>     Full path of the video to extract the frame from. Make sure that this video is already analyzed.\n>\n> shuffle : int, optional\n>     The shufle index of training dataset. The extracted frames will be stored in the labeled-dataset for\n>     the corresponding shuffle of training dataset. Default is set to 1\n>\n> trainingsetindex: int, optional\n>     Integer specifying which TrainingsetFraction to use. By default the first (note that TrainingFraction is a list in config.yaml).\n>\n> comparisonbodyparts: list of strings, optional\n>     This select the body parts for which SARIMAX models are fit. Either ``all``, then all body parts\n>     from config.yaml are used orr a list of strings that are a subset of the full list.\n>     E.g. ['hand','Joystick'] for the demo Reaching-Mackenzie-2018-08-30/config.yaml to select only these two body parts.\n>\n> p_bound: float between 0 and 1, optional\n>     For outlieralgorithm 'uncertain' this parameter defines the likelihood below,\n>     below which a body part will be consided as missing data for filtering purposes.\n>\n> ARdegree: int, optional\n>     For outlieralgorithm 'fitting': Autoregressive degree of Sarimax model degree.\n>     see https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html\n>\n> MAdegree: int\n>     For outlieralgorithm 'fitting': Moving Avarage degree of Sarimax model degree.\n>     See https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html\n>\n> alpha: float\n>     Significance level for detecting outliers based on confidence interval of fitted SARIMAX model.\n>\n> save_as_csv: bool, optional\n>     Saves the predictions in a .csv file. The default is ``False``; if provided it must be either ``True`` or ``False``\n>\n> destfolder: string, optional\n>     Specifies the destination folder for analysis data (default is the path of the video). Note that for subsequent analysis this\n>     folder also needs to be passed.\n>\n> Example\n> --------\n> deeplabcut.filterpredictions('C:\\myproject\\reaching-task\\config.yaml',['C:\\myproject\\trailtracking-task\\test.mp4'],shuffle=3,ARdegree=5,MAdegree=2)\n>\n> One can then use the filtered rather than the frame-by-frame predictions by calling:\n>\n> deeplabcut.plot_trajectories('C:\\myproject\\reaching-task\\config.yaml',['C:\\myproject\\trailtracking-task\\test.mp4'],shuffle=3,filtered=True)\n>\n> deeplabcut.create_labeled_video('C:\\myproject\\reaching-task\\config.yaml',['C:\\myproject\\trailtracking-task\\test.mp4'],shuffle=3,filtered=True)\n> --------\n>\n> Returns filtered pandas array with the same structure as normal output of network.```\n>\n> Hope that helps! There will be some additional filters in the future, so stay tuned!\n>\n> â€”\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/AlexEMG/DeepLabCut/issues/369?email_source=notifications&email_token=AF5TISRKFTJ3F6IHKAIXMXDQA4OCFA5CNFSM4IFN44JKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD2TOTVQ#issuecomment-514255318>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AF5TISXPEVPRU5V7NQSPGPDQA4OCFANCNFSM4IFN44JA>\n> .\n>\n","reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/comments/515206078/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"kgj1234","id":24851530,"node_id":"MDQ6VXNlcjI0ODUxNTMw","avatar_url":"https://avatars.githubusercontent.com/u/24851530?v=4","gravatar_id":"","url":"https://api.github.com/users/kgj1234","html_url":"https://github.com/kgj1234","followers_url":"https://api.github.com/users/kgj1234/followers","following_url":"https://api.github.com/users/kgj1234/following{/other_user}","gists_url":"https://api.github.com/users/kgj1234/gists{/gist_id}","starred_url":"https://api.github.com/users/kgj1234/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kgj1234/subscriptions","organizations_url":"https://api.github.com/users/kgj1234/orgs","repos_url":"https://api.github.com/users/kgj1234/repos","events_url":"https://api.github.com/users/kgj1234/events{/privacy}","received_events_url":"https://api.github.com/users/kgj1234/received_events","type":"User","site_admin":false}},{"id":2510767337,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MjUxMDc2NzMzNw==","url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/events/2510767337","actor":{"login":"kgj1234","id":24851530,"node_id":"MDQ6VXNlcjI0ODUxNTMw","avatar_url":"https://avatars.githubusercontent.com/u/24851530?v=4","gravatar_id":"","url":"https://api.github.com/users/kgj1234","html_url":"https://github.com/kgj1234","followers_url":"https://api.github.com/users/kgj1234/followers","following_url":"https://api.github.com/users/kgj1234/following{/other_user}","gists_url":"https://api.github.com/users/kgj1234/gists{/gist_id}","starred_url":"https://api.github.com/users/kgj1234/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kgj1234/subscriptions","organizations_url":"https://api.github.com/users/kgj1234/orgs","repos_url":"https://api.github.com/users/kgj1234/repos","events_url":"https://api.github.com/users/kgj1234/events{/privacy}","received_events_url":"https://api.github.com/users/kgj1234/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2019-07-25T20:40:34Z","performed_via_github_app":null},{"id":2510767339,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDI1MTA3NjczMzk=","url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/events/2510767339","actor":{"login":"kgj1234","id":24851530,"node_id":"MDQ6VXNlcjI0ODUxNTMw","avatar_url":"https://avatars.githubusercontent.com/u/24851530?v=4","gravatar_id":"","url":"https://api.github.com/users/kgj1234","html_url":"https://github.com/kgj1234","followers_url":"https://api.github.com/users/kgj1234/followers","following_url":"https://api.github.com/users/kgj1234/following{/other_user}","gists_url":"https://api.github.com/users/kgj1234/gists{/gist_id}","starred_url":"https://api.github.com/users/kgj1234/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kgj1234/subscriptions","organizations_url":"https://api.github.com/users/kgj1234/orgs","repos_url":"https://api.github.com/users/kgj1234/repos","events_url":"https://api.github.com/users/kgj1234/events{/privacy}","received_events_url":"https://api.github.com/users/kgj1234/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2019-07-25T20:40:34Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/comments/552223670","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/369#issuecomment-552223670","issue_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/369","id":552223670,"node_id":"MDEyOklzc3VlQ29tbWVudDU1MjIyMzY3MA==","user":{"login":"monajalal","id":1892917,"node_id":"MDQ6VXNlcjE4OTI5MTc=","avatar_url":"https://avatars.githubusercontent.com/u/1892917?v=4","gravatar_id":"","url":"https://api.github.com/users/monajalal","html_url":"https://github.com/monajalal","followers_url":"https://api.github.com/users/monajalal/followers","following_url":"https://api.github.com/users/monajalal/following{/other_user}","gists_url":"https://api.github.com/users/monajalal/gists{/gist_id}","starred_url":"https://api.github.com/users/monajalal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/monajalal/subscriptions","organizations_url":"https://api.github.com/users/monajalal/orgs","repos_url":"https://api.github.com/users/monajalal/repos","events_url":"https://api.github.com/users/monajalal/events{/privacy}","received_events_url":"https://api.github.com/users/monajalal/received_events","type":"User","site_admin":false},"created_at":"2019-11-10T19:08:51Z","updated_at":"2019-11-10T19:08:51Z","author_association":"NONE","body":"could you please show a little more step by step how to use the smooth filtering for making use of the fact that the input is a video and not a single frame? for example, the current frame correlates with the past frame(s).\r\n\r\nCan we do smooth filtering or tracking using the GUI or could you suggest how this could be done?>\r\n\r\nI wonder if I can do this given the CSV I get after the training?\r\n\r\nAny help is really appreciated.","reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/comments/552223670/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"monajalal","id":1892917,"node_id":"MDQ6VXNlcjE4OTI5MTc=","avatar_url":"https://avatars.githubusercontent.com/u/1892917?v=4","gravatar_id":"","url":"https://api.github.com/users/monajalal","html_url":"https://github.com/monajalal","followers_url":"https://api.github.com/users/monajalal/followers","following_url":"https://api.github.com/users/monajalal/following{/other_user}","gists_url":"https://api.github.com/users/monajalal/gists{/gist_id}","starred_url":"https://api.github.com/users/monajalal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/monajalal/subscriptions","organizations_url":"https://api.github.com/users/monajalal/orgs","repos_url":"https://api.github.com/users/monajalal/repos","events_url":"https://api.github.com/users/monajalal/events{/privacy}","received_events_url":"https://api.github.com/users/monajalal/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/comments/552229098","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/369#issuecomment-552229098","issue_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/369","id":552229098,"node_id":"MDEyOklzc3VlQ29tbWVudDU1MjIyOTA5OA==","user":{"login":"AlexEMG","id":20850270,"node_id":"MDQ6VXNlcjIwODUwMjcw","avatar_url":"https://avatars.githubusercontent.com/u/20850270?v=4","gravatar_id":"","url":"https://api.github.com/users/AlexEMG","html_url":"https://github.com/AlexEMG","followers_url":"https://api.github.com/users/AlexEMG/followers","following_url":"https://api.github.com/users/AlexEMG/following{/other_user}","gists_url":"https://api.github.com/users/AlexEMG/gists{/gist_id}","starred_url":"https://api.github.com/users/AlexEMG/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AlexEMG/subscriptions","organizations_url":"https://api.github.com/users/AlexEMG/orgs","repos_url":"https://api.github.com/users/AlexEMG/repos","events_url":"https://api.github.com/users/AlexEMG/events{/privacy}","received_events_url":"https://api.github.com/users/AlexEMG/received_events","type":"User","site_admin":false},"created_at":"2019-11-10T20:10:31Z","updated_at":"2019-11-10T20:10:31Z","author_association":"MEMBER","body":"The filter is applied after/during the video analysis. \r\nhttps://github.com/AlexEMG/DeepLabCut/blob/53a784b95a0d31b403deab0541b4770fd001448f/docs/functionDetails.md#i-novel-video-analysis-extra-features\r\n\r\n","reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/comments/552229098/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"AlexEMG","id":20850270,"node_id":"MDQ6VXNlcjIwODUwMjcw","avatar_url":"https://avatars.githubusercontent.com/u/20850270?v=4","gravatar_id":"","url":"https://api.github.com/users/AlexEMG","html_url":"https://github.com/AlexEMG","followers_url":"https://api.github.com/users/AlexEMG/followers","following_url":"https://api.github.com/users/AlexEMG/following{/other_user}","gists_url":"https://api.github.com/users/AlexEMG/gists{/gist_id}","starred_url":"https://api.github.com/users/AlexEMG/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AlexEMG/subscriptions","organizations_url":"https://api.github.com/users/AlexEMG/orgs","repos_url":"https://api.github.com/users/AlexEMG/repos","events_url":"https://api.github.com/users/AlexEMG/events{/privacy}","received_events_url":"https://api.github.com/users/AlexEMG/received_events","type":"User","site_admin":false}}]