{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1144","repository_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut","labels_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1144/labels{/name}","comments_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1144/comments","events_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1144/events","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/1144","id":831276042,"node_id":"MDU6SXNzdWU4MzEyNzYwNDI=","number":1144,"title":"ResourceExhaustedError  -- Allocator (GPU_0_bfc) ran out of memory trying to allocate 37.67MiB","user":{"login":"GPU-Shuttle","id":74163973,"node_id":"MDQ6VXNlcjc0MTYzOTcz","avatar_url":"https://avatars.githubusercontent.com/u/74163973?v=4","gravatar_id":"","url":"https://api.github.com/users/GPU-Shuttle","html_url":"https://github.com/GPU-Shuttle","followers_url":"https://api.github.com/users/GPU-Shuttle/followers","following_url":"https://api.github.com/users/GPU-Shuttle/following{/other_user}","gists_url":"https://api.github.com/users/GPU-Shuttle/gists{/gist_id}","starred_url":"https://api.github.com/users/GPU-Shuttle/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/GPU-Shuttle/subscriptions","organizations_url":"https://api.github.com/users/GPU-Shuttle/orgs","repos_url":"https://api.github.com/users/GPU-Shuttle/repos","events_url":"https://api.github.com/users/GPU-Shuttle/events{/privacy}","received_events_url":"https://api.github.com/users/GPU-Shuttle/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2021-03-14T22:21:16Z","updated_at":"2021-03-22T13:00:09Z","closed_at":"2021-03-22T13:00:09Z","author_association":"NONE","active_lock_reason":null,"body":"As per [instructions](https://github.com/DeepLabCut/DeepLabCut) on how to use Effnets, I installed v2.1.10 and passed efficientnet-b6  when creating the trainingset: \"deeplabcut.create_training_dataset(path_config, net_type='efficientnet-b6')\". all good up to this stage, however, DLC returns an error at the training step: \"deeplabcut.train_network(path_config)\", which is copied below.\r\nAny tips would be appreciated.\r\n\r\n```python\r\n-------------------------------------\r\n\r\nW tensorflow/core/common_runtime/bfc_allocator.cc:267] Allocator (GPU_0_bfc) ran out of memory trying to allocate 37.67MiB.  Current allocation summary follows.\r\n\r\n2021-03-15 11:06:07.202518: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at transpose_op.cc:199 : Resource exhausted: OOM when allocating tensor with shape[1,2064,52,92] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n---------------------------------------------------------------------------\r\nResourceExhaustedError                    Traceback (most recent call last)\r\n~/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1333     try:\r\n-> 1334       return fn(*args)\r\n   1335     except errors.OpError as e:\r\n\r\n~/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1318       return self._call_tf_sessionrun(\r\n-> 1319           options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1320\r\n\r\n~/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1406         self._session, options, feed_dict, fetch_list, target_list,\r\n-> 1407         run_metadata)\r\n   1408\r\n\r\nResourceExhaustedError: OOM when allocating tensor with shape[1,2064,52,92] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[{{node efficientnet/efficientnet-b6/model/blocks_41/depthwise_conv2d/depthwise-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[{{node absolute_difference/weighted_loss/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/concat}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nResourceExhaustedError                    Traceback (most recent call last)\r\n<ipython-input-4-18dc6009ffca> in <module>\r\n----> 1 deeplabcut.train_network(path_config)\r\n\r\n~/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/training.py in train_network(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\r\n    191\r\n    192     except BaseException as e:\r\n--> 193         raise e\r\n    194     finally:\r\n    195         os.chdir(str(start_path))\r\n\r\n~/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/training.py in train_network(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\r\n    187                 max_to_keep=max_snapshots_to_keep,\r\n    188                 keepdeconvweights=keepdeconvweights,\r\n--> 189                 allow_growth=allow_growth,\r\n    190             )  # pass on path and file name for pose_cfg.yaml!\r\n    191\r\n\r\n~/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/train.py in train(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\r\n    276         [_, loss_val, summary] = sess.run(\r\n    277             [train_op, total_loss, merged_summaries],\r\n--> 278             feed_dict=dict,\r\n    279         )\r\n    280         cum_loss += loss_val\r\n\r\n~/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    927     try:\r\n    928       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 929                          run_metadata_ptr)\r\n    930       if run_metadata:\r\n    931         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n~/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1150     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1151       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1152                              feed_dict_tensor, options, run_metadata)\r\n   1153     else:\r\n   1154       results = []\r\n\r\n~/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1326     if handle is None:\r\n   1327       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1328                            run_metadata)\r\n   1329     else:\r\n   1330       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\n~/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1346           pass\r\n   1347       message = error_interpolation.interpolate(message, self._graph)\r\n-> 1348       raise type(e)(node_def, op, message)\r\n   1349\r\n   1350   def _extend_graph(self):\r\n\r\nResourceExhaustedError: OOM when allocating tensor with shape[1,2064,52,92] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[{{node efficientnet/efficientnet-b6/model/blocks_41/depthwise_conv2d/depthwise-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[node absolute_difference/weighted_loss/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/concat (defined at /home/user/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/nnet/losses.py:45) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n```","closed_by":{"login":"MMathisLab","id":28102185,"node_id":"MDQ6VXNlcjI4MTAyMTg1","avatar_url":"https://avatars.githubusercontent.com/u/28102185?v=4","gravatar_id":"","url":"https://api.github.com/users/MMathisLab","html_url":"https://github.com/MMathisLab","followers_url":"https://api.github.com/users/MMathisLab/followers","following_url":"https://api.github.com/users/MMathisLab/following{/other_user}","gists_url":"https://api.github.com/users/MMathisLab/gists{/gist_id}","starred_url":"https://api.github.com/users/MMathisLab/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MMathisLab/subscriptions","organizations_url":"https://api.github.com/users/MMathisLab/orgs","repos_url":"https://api.github.com/users/MMathisLab/repos","events_url":"https://api.github.com/users/MMathisLab/events{/privacy}","received_events_url":"https://api.github.com/users/MMathisLab/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1144/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1144/timeline","performed_via_github_app":null,"state_reason":"completed"}