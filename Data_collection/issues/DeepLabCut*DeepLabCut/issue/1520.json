{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1520","repository_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut","labels_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1520/labels{/name}","comments_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1520/comments","events_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1520/events","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/1520","id":1007117477,"node_id":"I_kwDOB5BM6c48B2Sl","number":1520,"title":"Re-training: Initial first learning rate of learning rate schedule is taken ","user":{"login":"AnFrBo","id":39856231,"node_id":"MDQ6VXNlcjM5ODU2MjMx","avatar_url":"https://avatars.githubusercontent.com/u/39856231?v=4","gravatar_id":"","url":"https://api.github.com/users/AnFrBo","html_url":"https://github.com/AnFrBo","followers_url":"https://api.github.com/users/AnFrBo/followers","following_url":"https://api.github.com/users/AnFrBo/following{/other_user}","gists_url":"https://api.github.com/users/AnFrBo/gists{/gist_id}","starred_url":"https://api.github.com/users/AnFrBo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AnFrBo/subscriptions","organizations_url":"https://api.github.com/users/AnFrBo/orgs","repos_url":"https://api.github.com/users/AnFrBo/repos","events_url":"https://api.github.com/users/AnFrBo/events{/privacy}","received_events_url":"https://api.github.com/users/AnFrBo/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-09-25T15:35:34Z","updated_at":"2021-09-25T18:23:22Z","closed_at":"2021-09-25T18:23:16Z","author_association":"NONE","active_lock_reason":null,"body":"### Is there an existing issue for this?\n\n- [X] I have searched the existing issues\n\n### Bug description\n\nHey @jeylau,\r\n\r\nI think the issue is in between a bug and a feature request. When retraining, I noticed that the first learning rate of the learning rate schedule is taken.\r\n\r\nFor instance: I trained a model to 60k iterations with the default learning rate schedule:\r\n- - 0.0001\r\n  - 7500\r\n- - 5.0e-05\r\n  - 12000\r\n- - 1.0e-05\r\n  - 200000\r\n\r\nWhen I trained the model with additional iterations, taken the already trained weights of 60k iterations, it took automatically the first learning rate of 0.0001. Since 7500 iterations were not reached (as it was already at 60k iterations), the learning rate did not change to 5.0e-05 nor 1.0e-05. I attached an image where you can see the influence on the loss.\r\n\r\n![model_loss](https://user-images.githubusercontent.com/39856231/134776735-9fa050f8-24aa-48b5-91f3-3ca295e3f60c.png)\r\n\r\nI am sure this was not implemented intentionally. As a solution, maybe you can write it down somewhere that the learning rate has to be adjusted manually in the pose_conf.yaml file or you could add a if statement or an extra parameter to the function? What do you think?\r\n\n\n### Operating System\n\nUbuntu 18.04. LTS\n\n### DeepLabCut version\n\n2.2.0.2\n\n### DeepLabCut mode\n\nmulti animal\n\n### Device type\n\nNVIDIA GeForce RTX 3090\n\n### Steps To Reproduce\n\nRun iteration > 7500, stop, add saved weights of last iterations as init_weights. Start training again. Look at learning rate. \n\n### Relevant log output\n\n```shell\niteration: 60500\t loss: 0.0016\t scmap loss: 0.0014\t locref loss: 0.0000\t limb loss: 0.0001\t lr: 0.0001\r\niteration: 61000\t loss: 0.0015\t scmap loss: 0.0014\t locref loss: 0.0000\t limb loss: 0.0001\t lr: 0.0001\r\niteration: 61500\t loss: 0.0015\t scmap loss: 0.0014\t locref loss: 0.0000\t limb loss: 0.0001\t lr: 0.0001\r\niteration: 62000\t loss: 0.0015\t scmap loss: 0.0014\t locref loss: 0.0000\t limb loss: 0.0001\t lr: 0.0001\r\niteration: 62500\t loss: 0.0015\t scmap loss: 0.0014\t locref loss: 0.0000\t limb loss: 0.0001\t lr: 0.0001\r\niteration: 63000\t loss: 0.0014\t scmap loss: 0.0013\t locref loss: 0.0000\t limb loss: 0.0001\t lr: 0.0001\r\niteration: 63500\t loss: 0.0014\t scmap loss: 0.0013\t locref loss: 0.0000\t limb loss: 0.0001\t lr: 0.0001\r\niteration: 64000\t loss: 0.0015\t scmap loss: 0.0013\t locref loss: 0.0000\t limb loss: 0.0001\t lr: 0.0001\r\n(...)\n```\n\n\n### Anything else?\n\n_No response_\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/DeepLabCut/DeepLabCut/blob/master/CODE_OF_CONDUCT.md)","closed_by":{"login":"MMathisLab","id":28102185,"node_id":"MDQ6VXNlcjI4MTAyMTg1","avatar_url":"https://avatars.githubusercontent.com/u/28102185?v=4","gravatar_id":"","url":"https://api.github.com/users/MMathisLab","html_url":"https://github.com/MMathisLab","followers_url":"https://api.github.com/users/MMathisLab/followers","following_url":"https://api.github.com/users/MMathisLab/following{/other_user}","gists_url":"https://api.github.com/users/MMathisLab/gists{/gist_id}","starred_url":"https://api.github.com/users/MMathisLab/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MMathisLab/subscriptions","organizations_url":"https://api.github.com/users/MMathisLab/orgs","repos_url":"https://api.github.com/users/MMathisLab/repos","events_url":"https://api.github.com/users/MMathisLab/events{/privacy}","received_events_url":"https://api.github.com/users/MMathisLab/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1520/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1520/timeline","performed_via_github_app":null,"state_reason":"completed"}