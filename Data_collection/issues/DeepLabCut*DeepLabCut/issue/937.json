{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/937","repository_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut","labels_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/937/labels{/name}","comments_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/937/comments","events_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/937/events","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/937","id":713105526,"node_id":"MDU6SXNzdWU3MTMxMDU1MjY=","number":937,"title":"Issue with Pose estimation video compared to generated Tracklets","user":{"login":"CalvinLloyd117","id":45299786,"node_id":"MDQ6VXNlcjQ1Mjk5Nzg2","avatar_url":"https://avatars.githubusercontent.com/u/45299786?v=4","gravatar_id":"","url":"https://api.github.com/users/CalvinLloyd117","html_url":"https://github.com/CalvinLloyd117","followers_url":"https://api.github.com/users/CalvinLloyd117/followers","following_url":"https://api.github.com/users/CalvinLloyd117/following{/other_user}","gists_url":"https://api.github.com/users/CalvinLloyd117/gists{/gist_id}","starred_url":"https://api.github.com/users/CalvinLloyd117/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CalvinLloyd117/subscriptions","organizations_url":"https://api.github.com/users/CalvinLloyd117/orgs","repos_url":"https://api.github.com/users/CalvinLloyd117/repos","events_url":"https://api.github.com/users/CalvinLloyd117/events{/privacy}","received_events_url":"https://api.github.com/users/CalvinLloyd117/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":10,"created_at":"2020-10-01T18:59:38Z","updated_at":"2020-11-18T16:06:48Z","closed_at":"2020-11-18T16:06:48Z","author_association":"NONE","active_lock_reason":null,"body":"Thanks for opening this issue, and thanks for using DeepLabCut (we hope you are enjoying it ;). Please fill out the template completely, including the full \"traceback\" and input code that you ran to hit this error.\r\n\r\n**Your Operating system and DeepLabCut version**\r\n\r\nOS: Windows 10\r\nDeepLabCut Version: 2.2b8\r\nAnaconda env used: The one DLC provides (DLC-GPU)\r\n\r\n**Describe the problem**\r\n\r\nHello. I have been using DLC for a while now, though I still consider myself a novice. I have been using MA DLC to track groups of vervet monkeys, and have been having a pretty good time with the program so far, apart from a few issues which have been resolved. I have extracted and manually labeled around 200 frames (20 frames or so from each of 10 videos, depending on the video length). A couple of the longer videos I have labeled around 50 frames). I created the training dataset, and then trained the network for 100,000 iterations on my GTX 1070TI. I proceeded to evaluate the network and cross-validate as normal. \r\n\r\nI ran the analyse videos function on one of the shorter videos using both box and skeletal tracking. Both provided similar results. I was also sure to select \"create video for checking detections\". After analyzing, I watched the generated video to verify that the pose estimation was good. I was incredibly happy with the quality of the markers on the vervets, though there was some jitter, which I expected. Nonetheless, all of the colored markers appeared to be in the correct spots at least 90% of the time. \r\n\r\nThen I proceed to convert to tracklets and attempt to refine. This is where my problem began. There were either very few tracklets, none at all, or they were entirely in the wrong locations when compared to the 'create video for checking detections'. I did some tinkering with the inference_config.yaml, and attempted to follow some advice found in the forums and in the github issues. Nothing I tried seemed to resemble the great tracking I received from 'create video for checking detections'. I am wondering what is going wrong here? Refining tracklets at this point (even with my best variant of the inference_config) will involve moving each and every tracklet, reassigning entities, etc for nearly every frame, not to mention you cannot replace missing tracklets in the Refine Tracklets GUI for ones that are not generated by the system. Is this the intended workflow? Have I made a mistake is training? I am really not certain. I figured 200 labelled frames would be enough (which it seems to be for creating video for checking detections). \r\n\r\nAnyhow, I would really appreciate any input, advice, or help that you are willing to provide. \r\n\r\nHope to hear back from you.\r\n\r\n**Inference_config**\r\nHere is the content of the inference_config.yaml that I am using. Most of it was generated by the system, but I have been tinkering with the values that are not cross validated (like pafthreshold).\r\n\r\n\r\n```\r\nvariant: 0\r\nminimalnumberofconnections: 4\r\naveragescore: 0.1\r\ndistnormalization: 1500\r\ndistnormalizationLOWER: 0\r\ndetectionthresholdsquare: 0\r\naddlikelihoods: 0.15\r\npafthreshold: 0.03\r\n\r\nmethod: m1\r\nwithid: false\r\ntopktoretain: 3\r\nupperbound_factor: 1.25\r\nlowerbound_factor: .75\r\nboundingboxslack: 0\r\nmax_age: 200\r\nmin_hits: 3\r\niou_threshold: 0.2\r\n```\r\n\r\n**config.yaml**\r\n```\r\n# Project definitions (do not edit)\r\nTask: Vigilence\r\nscorer: Calvin\r\ndate: Jul2\r\nmultianimalproject: true\r\n\r\n    # Project path (change when moving around)\r\n\r\nproject_path: S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\r\n\r\n    # Annotation data set configuration (and individual video cropping parameters)\r\nvideo_sets:\r\n  ? S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\ITE do not mind\r\n    my comments!_cropped\\ITE do not mind my comments!_cropped.mp4\r\n  : crop: 0, 400, 0, 400\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\20170626 095735_cropped\\20170626 095735_cropped.mp4:\r\n    crop: 0, 400, 0, 400\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\20170922_133351_cropped\\20170922_133351_cropped.mp4:\r\n    crop: 0, 400, 0, 400\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\IMG_2379_cropped\\IMG_2379_cropped.MOV:\r\n    crop: 0, 400, 0, 400\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\P6160026_cropped\\P6160026_cropped.MOV:\r\n    crop: 0, 400, 0, 400\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\P6270395_cropped\\P6270395_cropped.MOV:\r\n    crop: 0, 400, 0, 400\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\P7260647_cropped\\P7260647_cropped.MOV:\r\n    crop: 0, 400, 0, 400\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\P9180068_cropped\\P9180068_cropped.MOV:\r\n    crop: 0, 400, 0, 400\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\PA030770_cropped\\PA030770_cropped.MOV:\r\n    crop: 0, 400, 0, 400\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\PA191044_cropped\\PA191044_cropped.MOV:\r\n    crop: 0, 400, 0, 400\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\PA231187_cropped\\PA231187_cropped.MOV:\r\n    crop: 0, 400, 0, 400\r\nindividuals:\r\n- vervet1\r\n- vervet2\r\n- vervet3\r\n- vervet4\r\n- vervet5\r\n- vervet6\r\n- vervet7\r\n- vervet8\r\n- vervet9\r\n- vervet10\r\n- vervet11\r\n- vervet12\r\n- vervet13\r\n- vervet14\r\n- vervet15\r\n\r\nuniquebodyparts: []\r\nmultianimalbodyparts:\r\n- lefteye\r\n- righteye\r\n- leftear\r\n- rightear\r\n- nose\r\n- chin\r\n- lefthand\r\n- leftelbow\r\n- leftshoulder\r\n- righthand\r\n- rightelbow\r\n- rightshoulder\r\n- topback\r\n- midback\r\n- lowerback\r\n- leftfoot\r\n- leftknee\r\n- lefthip\r\n- rightfoot\r\n- rightknee\r\n- righthip\r\n- tailbase\r\n- tailmid\r\n- tailtip\r\nskeleton:\r\n- - lefteye\r\n  - righteye\r\n- - lefteye\r\n  - nose\r\n- - righteye\r\n  - nose\r\n- - lefteye\r\n  - leftear\r\n- - righteye\r\n  - rightear\r\n- - leftear\r\n  - topback\r\n- - rightear\r\n  - topback\r\n- - nose\r\n  - chin\r\n- - nose\r\n  - leftear\r\n- - nose\r\n  - rightear\r\n- - chin\r\n  - leftshoulder\r\n- - chin\r\n  - rightshoulder\r\n- - chin\r\n  - topback\r\n- - leftear\r\n  - leftshoulder\r\n- - rightear\r\n  - rightshoulder\r\n- - chin\r\n  - leftear\r\n- - chin\r\n  - rightear\r\n- - rightshoulder\r\n  - leftshoulder\r\n- - rightshoulder\r\n  - rightelbow\r\n- - rightelbow\r\n  - righthand\r\n- - rightelbow\r\n  - leftelbow\r\n- - righthand\r\n  - lefthand\r\n- - leftshoulder\r\n  - leftelbow\r\n- - leftshoulder\r\n  - lefthand\r\n- - leftshoulder\r\n  - topback\r\n- - rightshoulder\r\n  - righthand\r\n- - rightshoulder\r\n  - topback\r\n- - topback\r\n  - midback\r\n- - topback\r\n  - righthip\r\n- - topback\r\n  - lefthip\r\n- - lowerback\r\n  - midback\r\n- - lowerback\r\n  - lefthip\r\n- - lowerback\r\n  - righthip\r\n- - lowerback\r\n  - tailmid\r\n- - lowerback\r\n  - tailbase\r\n- - leftelbow\r\n  - lefthand\r\n- - rightear\r\n  - midback\r\n- - leftear\r\n  - midback\r\n- - leftshoulder\r\n  - midback\r\n- - leftshoulder\r\n  - lefthip\r\n- - rightshoulder\r\n  - righthip\r\n- - rightshoulder\r\n  - midback\r\n- - midback\r\n  - tailbase\r\n- - midback\r\n  - lefthip\r\n- - midback\r\n  - righthip\r\n- - lefthip\r\n  - righthip\r\n- - lefthip\r\n  - leftknee\r\n- - lefthip\r\n  - tailbase\r\n- - righthip\r\n  - tailbase\r\n- - righthip\r\n  - rightfoot\r\n- - lefthip\r\n  - leftfoot\r\n- - leftknee\r\n  - leftfoot\r\n- - righthip\r\n  - rightknee\r\n- - rightknee\r\n  - rightfoot\r\n- - rightknee\r\n  - leftknee\r\n- - rightfoot\r\n  - leftfoot\r\n- - rightfoot\r\n  - righthand\r\n- - leftfoot\r\n  - lefthand\r\n- - tailbase\r\n  - tailmid\r\n- - tailmid\r\n  - tailtip\r\n- - tailbase\r\n  - tailtip\r\n- - righthip\r\n  - tailmid\r\n- - righthip\r\n  - tailtip\r\n- - lefthip\r\n  - tailmid\r\n- - lefthip\r\n  - tailtip\r\n\r\nbodyparts: MULTI!\r\nstart: 0\r\nstop: 1\r\nnumframes2pick: 30\r\n\r\n    # Plotting configuration\r\nskeleton_color: black\r\npcutoff: 0.6\r\ndotsize: 3\r\nalphavalue: 0.7\r\ncolormap: plasma\r\n\r\n    # Training,Evaluation and Analysis configuration\r\nTrainingFraction:\r\n- 0.95\r\niteration: 0\r\ndefault_net_type: resnet_50\r\ndefault_augmenter: multi-animal-imgaug\r\nsnapshotindex: -1\r\nbatch_size: 8\r\n\r\n    # Cropping Parameters (for analysis and outlier frame detection)\r\ncropping: false\r\ncroppedtraining: true\r\n    #if cropping is true for analysis, then set the values here:\r\nx1: 0\r\nx2: 640\r\ny1: 277\r\ny2: 624\r\n\r\n    # Refinement configuration (parameters from annotation dataset configuration also relevant in this stage)\r\ncorner2move2:\r\n- 50\r\n- 50\r\nmove2corner: true\r\nvideo_sets_original:\r\n  ? S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\ITE do not mind\r\n    my comments!\\ITE do not mind my comments!.mp4\r\n  : crop: 0, 1920, 0, 1080\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\20170626 095735\\20170626 095735.mp4:\r\n    crop: 0, 1920, 0, 1080\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\20170922_133351\\20170922_133351.mp4:\r\n    crop: 0, 1920, 0, 1080\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\IMG_2379\\IMG_2379.MOV:\r\n    crop: 0, 1280, 0, 720\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\P6160026\\P6160026.MOV:\r\n    crop: 0, 1920, 0, 1080\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\P6270395\\P6270395.MOV:\r\n    crop: 0, 1920, 0, 1080\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\P7260647\\P7260647.MOV:\r\n    crop: 0, 1920, 0, 1080\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\P9180068\\P9180068.MOV:\r\n    crop: 0, 1920, 0, 1080\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\PA030770\\PA030770.MOV:\r\n    crop: 0, 1920, 0, 1080\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\PA191044\\PA191044.MOV:\r\n    crop: 0, 1920, 0, 1080\r\n  S:\\Documents\\Barret-HenziRA\\Vigilence-Calvin-2020-07-02\\videos\\PA231187\\PA231187.MOV:\r\n    crop: 0, 1920, 0, 1080\r\n```\r\n\r\nNot sure if these will help to evaluate the issue or not.","closed_by":{"login":"MMathisLab","id":28102185,"node_id":"MDQ6VXNlcjI4MTAyMTg1","avatar_url":"https://avatars.githubusercontent.com/u/28102185?v=4","gravatar_id":"","url":"https://api.github.com/users/MMathisLab","html_url":"https://github.com/MMathisLab","followers_url":"https://api.github.com/users/MMathisLab/followers","following_url":"https://api.github.com/users/MMathisLab/following{/other_user}","gists_url":"https://api.github.com/users/MMathisLab/gists{/gist_id}","starred_url":"https://api.github.com/users/MMathisLab/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MMathisLab/subscriptions","organizations_url":"https://api.github.com/users/MMathisLab/orgs","repos_url":"https://api.github.com/users/MMathisLab/repos","events_url":"https://api.github.com/users/MMathisLab/events{/privacy}","received_events_url":"https://api.github.com/users/MMathisLab/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/937/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/937/timeline","performed_via_github_app":null,"state_reason":"completed"}