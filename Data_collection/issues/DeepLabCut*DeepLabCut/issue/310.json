{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/310","repository_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut","labels_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/310/labels{/name}","comments_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/310/comments","events_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/310/events","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/310","id":452196082,"node_id":"MDU6SXNzdWU0NTIxOTYwODI=","number":310,"title":"conv_3 bank?","user":{"login":"jbohnslav","id":17788259,"node_id":"MDQ6VXNlcjE3Nzg4MjU5","avatar_url":"https://avatars.githubusercontent.com/u/17788259?v=4","gravatar_id":"","url":"https://api.github.com/users/jbohnslav","html_url":"https://github.com/jbohnslav","followers_url":"https://api.github.com/users/jbohnslav/followers","following_url":"https://api.github.com/users/jbohnslav/following{/other_user}","gists_url":"https://api.github.com/users/jbohnslav/gists{/gist_id}","starred_url":"https://api.github.com/users/jbohnslav/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jbohnslav/subscriptions","organizations_url":"https://api.github.com/users/jbohnslav/orgs","repos_url":"https://api.github.com/users/jbohnslav/repos","events_url":"https://api.github.com/users/jbohnslav/events{/privacy}","received_events_url":"https://api.github.com/users/jbohnslav/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2019-06-04T20:37:21Z","updated_at":"2021-02-21T20:42:11Z","closed_at":"2019-06-05T15:42:00Z","author_association":"NONE","active_lock_reason":null,"body":"Hi there,\r\n\r\nThanks for the great work. I'm not used to TensorFlow, so it could be due to my inability to read tf code, but I'm confused about the prediction layers in the model. In both the DeeperCut paper and DeepLabCut paper, the authors describe using a ResNet base followed by 2x upsampling with deconvolution layers. Then, the authors \"connect the final output to the output of the conv3 bank.\"\r\n\r\n In the code, features are extracted with the `net_funcs` imported from `tf.slim`: `resnet_v1.resnet_v1_50` and ` resnet_v1.resnet_v1_101`. Due to the use of atrous convolutions, and the lack of global average pooling (etc)., I think the features should be of shape `(N, H/16, W/16, 2048)`. \r\n\r\nThey are then, I believe, passed to the following prediction layer:\r\n```python\r\ndef prediction_layer(cfg, input, name, num_outputs):\r\n    with slim.arg_scope([slim.conv2d, slim.conv2d_transpose], padding='SAME',\r\n                        activation_fn=None, normalizer_fn=None,\r\n                        weights_regularizer=slim.l2_regularizer(cfg.weight_decay)):\r\n        with tf.variable_scope(name):\r\n            pred = slim.conv2d_transpose(input, num_outputs,\r\n                                         kernel_size=[3, 3], stride=2,\r\n                                         scope='block4')\r\n            return pred\r\n```\r\n\r\nThis just means that the output of the ResNet is passed into a deconvolution layer, without any connection to `conv3`. Did I miss it somewhere? \r\n\r\nBoth papers use the phrasing \"connected to\", so I'm not sure if it's supposed to be concatenate + conv2d, addition, and whether or not the connection happens to the upsampled features or original features. I expected to see (in pseudocode) the prediction layer be something like this:\r\n```\r\nupsampled_features = conv2d_transpose(features)\r\noutputs = conv2d(concatenate(upsampled_features,conv3))\r\n```","closed_by":{"login":"MMathisLab","id":28102185,"node_id":"MDQ6VXNlcjI4MTAyMTg1","avatar_url":"https://avatars.githubusercontent.com/u/28102185?v=4","gravatar_id":"","url":"https://api.github.com/users/MMathisLab","html_url":"https://github.com/MMathisLab","followers_url":"https://api.github.com/users/MMathisLab/followers","following_url":"https://api.github.com/users/MMathisLab/following{/other_user}","gists_url":"https://api.github.com/users/MMathisLab/gists{/gist_id}","starred_url":"https://api.github.com/users/MMathisLab/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MMathisLab/subscriptions","organizations_url":"https://api.github.com/users/MMathisLab/orgs","repos_url":"https://api.github.com/users/MMathisLab/repos","events_url":"https://api.github.com/users/MMathisLab/events{/privacy}","received_events_url":"https://api.github.com/users/MMathisLab/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/310/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/310/timeline","performed_via_github_app":null,"state_reason":"completed"}