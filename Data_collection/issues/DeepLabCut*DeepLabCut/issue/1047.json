{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1047","repository_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut","labels_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1047/labels{/name}","comments_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1047/comments","events_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1047/events","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/1047","id":774940503,"node_id":"MDU6SXNzdWU3NzQ5NDA1MDM=","number":1047,"title":"subprocess.CalledProcessError: Command 'ffprobe -i","user":{"login":"ecresp1el","id":56608164,"node_id":"MDQ6VXNlcjU2NjA4MTY0","avatar_url":"https://avatars.githubusercontent.com/u/56608164?v=4","gravatar_id":"","url":"https://api.github.com/users/ecresp1el","html_url":"https://github.com/ecresp1el","followers_url":"https://api.github.com/users/ecresp1el/followers","following_url":"https://api.github.com/users/ecresp1el/following{/other_user}","gists_url":"https://api.github.com/users/ecresp1el/gists{/gist_id}","starred_url":"https://api.github.com/users/ecresp1el/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ecresp1el/subscriptions","organizations_url":"https://api.github.com/users/ecresp1el/orgs","repos_url":"https://api.github.com/users/ecresp1el/repos","events_url":"https://api.github.com/users/ecresp1el/events{/privacy}","received_events_url":"https://api.github.com/users/ecresp1el/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":9,"created_at":"2020-12-26T22:11:12Z","updated_at":"2021-02-26T20:20:12Z","closed_at":"2020-12-29T12:44:09Z","author_association":"NONE","active_lock_reason":null,"body":"**OS:** Mac OS Catalina 10.15.7 \r\n**DeepLabCut Version:** 2.1.9 \r\n**Anaconda env used:** /Users/cresp1el/anaconda3/envs/DLC-CPU/bin/python\r\n\r\nI would like to use the built-in CPU on my MacBook Pro (Intel UHD Graphics 630) in order to confirm proper installation of DLC-CPU env following the Github doc and youtube tutorial. The goal here is to use CPU for the entire workflow for now before our lab turns to Google colab or purchases a workstation.  When I run thetestscript.py in the provided git CPU environment within anaconda the same errors are generated throughout the code even as I try to reinstall anaconda, the DeepLab repo, or when I delete the test files generated from the testsctipt.py as mentioned in other threads. I am pretty stuck right now. =( Below is the exact code I used in the terminal from activating the environment to running the test script provided: \r\n```python\r\n\r\n`(base) cresp1el@macbook-pro ~ % source activate DLC-CPU       \r\n(DLC-CPU) cresp1el@macbook-pro ~ % cd Desktop/DeepLabCut/examples\r\n(DLC-CPU) cresp1el@macbook-pro examples % pythonw testscript.py         \r\nImported DLC!\r\nOn Windows/OSX tensorpack is not tested by default.\r\nCREATING PROJECT\r\nCreated \"/Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/videos\"\r\nCreated \"/Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/labeled-data\"\r\nCreated \"/Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/training-datasets\"\r\nCreated \"/Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/dlc-models\"\r\nCopying the videos\r\n/Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/videos/reachingvideo1.avi\r\nGenerated \"/Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/config.yaml\"\r\n\r\nA new project with name TEST-Alex-2020-12-26 is created at /Users/cresp1el/Desktop/DeepLabCut/examples and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\r\n Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\r\n. [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\r\nEXTRACTING FRAMES\r\nConfig file read successfully.\r\nExtracting frames based on kmeans ...\r\nKmeans-quantization based extracting of frames from 0.0  seconds to 8.53  seconds.\r\nExtracting and downsampling... 256  frames from the video.\r\n256it [00:01, 148.34it/s]\r\nKmeans clustering ... (this might take a while)\r\nFrames were successfully extracted, for the videos of interest.\r\n\r\nYou can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\r\nCREATING-SOME LABELS FOR THE FRAMES\r\nPlot labels...\r\nCreating images with labels by Alex.\r\n  0%|                                                                                                            | 0/5 [00:00<?, ?it/s]/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/utils/visualization.py:305: FutureWarning: Pass-through of possibly RGB images in gray2rgb is deprecated. In version 0.19, input arrays will always be considered grayscale, even if the last dimension has length 3 or 4. To prevent this warning and ensure compatibility with future versions, detect RGB images outside of this function.\r\n  im.set_data(color.gray2rgb(ic[i]))\r\n100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  2.88it/s]\r\nIf all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\r\nCREATING TRAININGSET\r\nThe training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\r\nCHANGING training parameters to end quickly!\r\nTRAIN\r\nSelecting single-animal trainer\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'],\r\n 'batch_size': 1,\r\n 'crop_pad': 0,\r\n 'cropratio': 0.4,\r\n 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_TESTDec26/TEST_Alex80shuffle1.mat',\r\n 'dataset_type': 'default',\r\n 'deterministic': False,\r\n 'display_iters': 2,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': '/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 0.05,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'max_input_size': 1500,\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_TESTDec26/Documentation_data-TEST_80shuffle1.pickle',\r\n 'min_input_size': 64,\r\n 'mirror': False,\r\n 'multi_step': [[0.001, 5]],\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 4,\r\n 'optimizer': 'sgd',\r\n 'pairwise_huber_loss': False,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_predict': False,\r\n 'pos_dist_thresh': 17,\r\n 'project_path': '/Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26',\r\n 'regularize': False,\r\n 'rotation': 25,\r\n 'rotratio': 0.4,\r\n 'save_iters': 5,\r\n 'scale_jitter_lo': 0.5,\r\n 'scale_jitter_up': 1.25,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': '/Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/dlc-models/iteration-0/TESTDec26-trainset80shuffle1/train/snapshot',\r\n 'stride': 8.0,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nStarting with imgaug pose-dataset loader (=default).\r\nBatch Size is 1\r\nInitializing ResNet\r\nLoading ImageNet-pretrained resnet_50\r\n2020-12-26 16:42:43.088019: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2020-12-26 16:42:43.088403: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 16. Tune using inter_op_parallelism_threads for best performance.\r\nTraining parameter:\r\n{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/dlc-models/iteration-0/TESTDec26-trainset80shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'], 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_TESTDec26/TEST_Alex80shuffle1.mat', 'display_iters': 2, 'init_weights': '/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_TESTDec26/Documentation_data-TEST_80shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.001, 5]], 'net_type': 'resnet_50', 'num_joints': 4, 'pos_dist_thresh': 17, 'project_path': '/Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 5, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': [-90, 90]}}\r\nStarting training....\r\niteration: 2 loss: 1.2704 lr: 0.001\r\niteration: 4 loss: 0.4870 lr: 0.001\r\n2020-12-26 16:43:12.454613: W tensorflow/core/kernels/queue_base.cc:277] _0_fifo_queue: Skipping cancelled enqueue attempt with queue not closed\r\nException in thread Thread-2:\r\nTraceback (most recent call last):\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\r\n\t [[{{node fifo_queue_enqueue}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/train.py\", line 91, in load_and_enqueue\r\n    sess.run(enqueue_op, feed_dict=food)\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\r\n\t [[node fifo_queue_enqueue (defined at /Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/train.py:77) ]]\r\n\r\nCaused by op 'fifo_queue_enqueue', defined at:\r\n  File \"testscript.py\", line 136, in <module>\r\n    deeplabcut.train_network(path_config_file)\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\", line 189, in train_network\r\n    allow_growth=allow_growth,\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/train.py\", line 172, in train\r\n    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/train.py\", line 77, in setup_preloading\r\n    enqueue_op = q.enqueue(placeholders_list)\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 345, in enqueue\r\n    self._queue_ref, vals, name=scope)\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 4158, in queue_enqueue_v2\r\n    timeout_ms=timeout_ms, name=name)\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nCancelledError (see above for traceback): Enqueue operation was cancelled\r\n\t [[node fifo_queue_enqueue (defined at /Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/train.py:77) ]]\r\n\r\n\r\nThe network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\r\nEVALUATE\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'],\r\n 'batch_size': 1,\r\n 'crop_pad': 0,\r\n 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_TESTDec26/TEST_Alex80shuffle1.mat',\r\n 'dataset_type': 'imgaug',\r\n 'deterministic': False,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': '/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 1.0,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'mirror': False,\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 4,\r\n 'optimizer': 'sgd',\r\n 'pairwise_huber_loss': True,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_predict': False,\r\n 'regularize': False,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': '/Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/dlc-models/iteration-0/TESTDec26-trainset80shuffle1/test/snapshot',\r\n 'stride': 8.0,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nRunning  DLC_resnet50_TESTDec26shuffle1_5  with # of trainingiterations: 5\r\nInitializing ResNet\r\nAnalyzing data...\r\n5it [00:08,  1.77s/it]\r\nDone and results stored for snapshot:  snapshot-5\r\nResults for 5  training iterations: 80 1 train error: 386.27 pixels. Test error: 376.4  pixels.\r\nWith pcutoff of 0.01  train error: 386.27 pixels. Test error: 376.4 pixels\r\nThereby, the errors are given by the average distances between the labels by DLC and the scorer.\r\nPlotting...\r\n100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:02<00:00,  2.26it/s]\r\nThe network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\r\nIf it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\r\nUse the function 'analyze_video' to make predictions on new videos.\r\nOtherwise consider retraining the network (see DeepLabCut workflow Fig 2)\r\nCUT SHORT VIDEO AND ANALYZE (with dynamic cropping!)\r\nusing alternative method\r\nMoviepy - Building video /Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/videos/reachingvideo1short.mp4.\r\nMoviepy - Writing video /Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/videos/reachingvideo1short.mp4\r\n\r\nMoviepy - Done !                                                                                                                       \r\nMoviepy - video ready /Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/videos/reachingvideo1short.mp4\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'],\r\n 'batch_size': 1,\r\n 'crop_pad': 0,\r\n 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_TESTDec26/TEST_Alex80shuffle1.mat',\r\n 'dataset_type': 'imgaug',\r\n 'deterministic': False,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': '/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 1.0,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'mirror': False,\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 4,\r\n 'optimizer': 'sgd',\r\n 'pairwise_huber_loss': True,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_predict': False,\r\n 'regularize': False,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': '/Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/dlc-models/iteration-0/TESTDec26-trainset80shuffle1/test/snapshot',\r\n 'stride': 8.0,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nUsing snapshot-5 for model /Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/dlc-models/iteration-0/TESTDec26-trainset80shuffle1\r\nStarting analysis in dynamic cropping mode with parameters: (True, 0.1, 5)\r\nSwitching batchsize to 1, num_outputs (per animal) to 1 and TFGPUinference to False (all these features are not supported in this mode).\r\nInitializing ResNet\r\nStarting to analyze %  /Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/videos/reachingvideo1short.mp4\r\n/Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/videos  already exists!\r\nLoading  /Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/videos/reachingvideo1short.mp4\r\nDuration of video [s]:  1.0 , recorded with  30.0 fps!\r\nOverall # of frames:  30  found with (before cropping) frame dimensions:  832 747\r\nStarting to extract posture\r\n40it [00:05,  7.48it/s]                                                                                                                \r\nSaving results in /Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/videos...\r\nSaving csv poses!\r\nThe videos are analyzed. Now your research can truly start! \r\n You can create labeled videos with 'create_labeled_video'\r\nIf the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\r\nanalyze again...\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'],\r\n 'batch_size': 1,\r\n 'crop_pad': 0,\r\n 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_TESTDec26/TEST_Alex80shuffle1.mat',\r\n 'dataset_type': 'imgaug',\r\n 'deterministic': False,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': '/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 1.0,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'mirror': False,\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 4,\r\n 'optimizer': 'sgd',\r\n 'pairwise_huber_loss': True,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_predict': False,\r\n 'regularize': False,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': '/Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/dlc-models/iteration-0/TESTDec26-trainset80shuffle1/test/snapshot',\r\n 'stride': 8.0,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nUsing snapshot-5 for model /Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/dlc-models/iteration-0/TESTDec26-trainset80shuffle1\r\nInitializing ResNet\r\nStarting to analyze %  /Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/videos/reachingvideo1short.mp4\r\n/Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/videos  already exists!\r\nThe videos are analyzed. Now your research can truly start! \r\n You can create labeled videos with 'create_labeled_video'\r\nIf the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\r\nCREATE VIDEO\r\n/Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/videos  already exists!\r\nStarting to process video: /Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/videos/reachingvideo1short.mp4\r\nLoading /Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/videos/reachingvideo1short.mp4 and data.\r\nDuration of video [s]: 1.0, recorded with 30.0 fps!\r\nOverall # of frames: 30 with cropped frame dimensions: 832 747\r\nGenerating frames and creating video.\r\n[Errno 2] No such file or directory: 'ffmpeg': 'ffmpeg'\r\nMaking plots\r\nLoading  /Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/videos/reachingvideo1short.mp4 and data.\r\nPlots created! Please check the directory \"plot-poses\" within the video directory\r\nEXTRACT OUTLIERS\r\nMethod  jump  found  29  putative outlier frames.\r\nDo you want to proceed with extracting  5  of those?\r\nIf this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\r\nLoading video...\r\nTraceback (most recent call last):\r\n  File \"testscript.py\", line 198, in <module>\r\n    destfolder=dfolder,\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/refine_training_dataset/outlier_frames.py\", line 270, in extract_outlier_frames\r\n    savelabeled,\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/refine_training_dataset/outlier_frames.py\", line 427, in ExtractFramesbasedonPreselection\r\n    duration = vid.calc_duration()\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/utils/auxfun_videos.py\", line 85, in calc_duration\r\n    command, shell=True, stderr=subprocess.STDOUT\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/subprocess.py\", line 411, in check_output\r\n    **kwargs).stdout\r\n  File \"/Users/cresp1el/anaconda3/envs/DLC-CPU/lib/python3.7/subprocess.py\", line 512, in run\r\n    output=stdout, stderr=stderr)\r\nsubprocess.CalledProcessError: Command 'ffprobe -i \"/Users/cresp1el/Desktop/DeepLabCut/examples/TEST-Alex-2020-12-26/videos/reachingvideo1short.mp4\" -show_entries format=duration -v quiet -of csv=\"p=0\"' returned non-zero exit status 127.`\r\n```\r\n\r\n**Additional context**\r\nI have also followed the Anaconda documentation to ensure that anaconda3 is downloaded in the correct directory correctly from other posted threads as I know there were issues with Catalina. \r\n\r\nThank you so much! \r\n\r\n\r\n\r\n","closed_by":{"login":"MMathisLab","id":28102185,"node_id":"MDQ6VXNlcjI4MTAyMTg1","avatar_url":"https://avatars.githubusercontent.com/u/28102185?v=4","gravatar_id":"","url":"https://api.github.com/users/MMathisLab","html_url":"https://github.com/MMathisLab","followers_url":"https://api.github.com/users/MMathisLab/followers","following_url":"https://api.github.com/users/MMathisLab/following{/other_user}","gists_url":"https://api.github.com/users/MMathisLab/gists{/gist_id}","starred_url":"https://api.github.com/users/MMathisLab/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MMathisLab/subscriptions","organizations_url":"https://api.github.com/users/MMathisLab/orgs","repos_url":"https://api.github.com/users/MMathisLab/repos","events_url":"https://api.github.com/users/MMathisLab/events{/privacy}","received_events_url":"https://api.github.com/users/MMathisLab/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1047/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1047/timeline","performed_via_github_app":null,"state_reason":"completed"}