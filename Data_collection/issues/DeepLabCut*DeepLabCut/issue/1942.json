{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1942","repository_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut","labels_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1942/labels{/name}","comments_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1942/comments","events_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1942/events","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/1942","id":1336023188,"node_id":"I_kwDOB5BM6c5PohiU","number":1942,"title":"`RuntimeError: CUDA error: no kernel image is available for execution on the device CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect. For debugging consider passing CUDA_LAUNCH_BLOCKING=1.`","user":{"login":"felipearrudamoura","id":74631204,"node_id":"MDQ6VXNlcjc0NjMxMjA0","avatar_url":"https://avatars.githubusercontent.com/u/74631204?v=4","gravatar_id":"","url":"https://api.github.com/users/felipearrudamoura","html_url":"https://github.com/felipearrudamoura","followers_url":"https://api.github.com/users/felipearrudamoura/followers","following_url":"https://api.github.com/users/felipearrudamoura/following{/other_user}","gists_url":"https://api.github.com/users/felipearrudamoura/gists{/gist_id}","starred_url":"https://api.github.com/users/felipearrudamoura/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/felipearrudamoura/subscriptions","organizations_url":"https://api.github.com/users/felipearrudamoura/orgs","repos_url":"https://api.github.com/users/felipearrudamoura/repos","events_url":"https://api.github.com/users/felipearrudamoura/events{/privacy}","received_events_url":"https://api.github.com/users/felipearrudamoura/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":{"login":"jeylau","id":30733203,"node_id":"MDQ6VXNlcjMwNzMzMjAz","avatar_url":"https://avatars.githubusercontent.com/u/30733203?v=4","gravatar_id":"","url":"https://api.github.com/users/jeylau","html_url":"https://github.com/jeylau","followers_url":"https://api.github.com/users/jeylau/followers","following_url":"https://api.github.com/users/jeylau/following{/other_user}","gists_url":"https://api.github.com/users/jeylau/gists{/gist_id}","starred_url":"https://api.github.com/users/jeylau/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jeylau/subscriptions","organizations_url":"https://api.github.com/users/jeylau/orgs","repos_url":"https://api.github.com/users/jeylau/repos","events_url":"https://api.github.com/users/jeylau/events{/privacy}","received_events_url":"https://api.github.com/users/jeylau/received_events","type":"User","site_admin":false},"assignees":[{"login":"jeylau","id":30733203,"node_id":"MDQ6VXNlcjMwNzMzMjAz","avatar_url":"https://avatars.githubusercontent.com/u/30733203?v=4","gravatar_id":"","url":"https://api.github.com/users/jeylau","html_url":"https://github.com/jeylau","followers_url":"https://api.github.com/users/jeylau/followers","following_url":"https://api.github.com/users/jeylau/following{/other_user}","gists_url":"https://api.github.com/users/jeylau/gists{/gist_id}","starred_url":"https://api.github.com/users/jeylau/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jeylau/subscriptions","organizations_url":"https://api.github.com/users/jeylau/orgs","repos_url":"https://api.github.com/users/jeylau/repos","events_url":"https://api.github.com/users/jeylau/events{/privacy}","received_events_url":"https://api.github.com/users/jeylau/received_events","type":"User","site_admin":false}],"milestone":null,"comments":3,"created_at":"2022-08-11T14:13:35Z","updated_at":"2022-10-09T14:42:05Z","closed_at":"2022-10-09T14:42:05Z","author_association":"NONE","active_lock_reason":null,"body":"### Is there an existing issue for this?\n\n- [X] I have searched the existing issues\n\n### Bug description\n\nAfter analyzing the videos, I tried to perform the reId transform, but the following error occurred:\r\n\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'ball'],\r\n 'batch_size': 1,\r\n 'crop_pad': 0,\r\n 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_UFALAug5/UFAL_CRB18062295shuffle1.pickle',\r\n 'dataset_type': 'multi-animal-imgaug',\r\n 'deterministic': False,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': '/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 1.0,\r\n 'locref_smooth': False,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'minconfidence': 0.01,\r\n 'mirror': False,\r\n 'multi_stage': True,\r\n 'net_type': 'resnet_50',\r\n 'nmsradius': 5.0,\r\n 'num_idchannel': 11,\r\n 'num_joints': 4,\r\n 'num_limbs': 3,\r\n 'optimizer': 'sgd',\r\n 'paf_best': [0, 1, 2],\r\n 'pairwise_huber_loss': True,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_graph': [[0, 1], [0, 2], [1, 2]],\r\n 'partaffinityfield_predict': True,\r\n 'regularize': False,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'sigma': 1,\r\n 'snapshot_prefix': '/home/preto/DLC/UFAL/UFAL-CRB180622-2022-08-05/dlc-models/iteration-0/UFALAug5-trainset95shuffle1/test/snapshot',\r\n 'stride': 8.0,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nUsing snapshot-200000 for model /home/preto/DLC/UFAL/UFAL-CRB180622-2022-08-05/dlc-models/iteration-0/UFALAug5-trainset95shuffle1\r\n/home/preto/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer._call_` method instead.\r\n  warnings.warn('`layer.apply` is deprecated and '\r\nActivating extracting of PAFs\r\n2022-08-11 10:52:27.367998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-08-11 10:52:27.368198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-08-11 10:52:27.368297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-08-11 10:52:27.368432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-08-11 10:52:27.368530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-08-11 10:52:27.368592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22300 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\r\nStarting to analyze %  /home/preto/DLC/UFAL/CRBxAzurra/Cameras_Arquibancada/Cam_03_02.avi\r\nLoading  /home/preto/DLC/UFAL/CRBxAzurra/Cameras_Arquibancada/Cam_03_02.avi\r\nDuration of video [s]:  2129.13 , recorded with  30.0 fps!\r\nOverall # of frames:  63874  found with (before cropping) frame dimensions:  2560 1440\r\nStarting to extract posture\r\n100%|███████████████████████████████████████████████████████████████| 63874/63874 [02:22<00:00, 448.35it/s]\r\nStarting to analyze %  /home/preto/DLC/UFAL/CRBxAzurra/Cameras_Arquibancada/Cam_04_02.avi\r\nLoading  /home/preto/DLC/UFAL/CRBxAzurra/Cameras_Arquibancada/Cam_04_02.avi\r\nDuration of video [s]:  2129.13 , recorded with  30.0 fps!\r\nOverall # of frames:  63874  found with (before cropping) frame dimensions:  2560 1440\r\nStarting to extract posture\r\n100%|███████████████████████████████████████████████████████████████| 63874/63874 [02:23<00:00, 445.83it/s]\r\n/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_tracking_pytorch/tracking_utils/preprocessing.py:54: RuntimeWarning: Mean of empty slice\r\n  match_id = np.argmin(np.nanmean(diff, axis=(1, 2)))\r\nIf the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\r\nstart training\r\nTraceback (most recent call last):\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/deeplabcut/gui/transformerID.py\", line 195, in run_transformer_reID\r\n    deeplabcut.transformer_reID(\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_tracking_pytorch/apis.py\", line 120, in transformer_reID\r\n    deeplabcut.pose_tracking_pytorch.train_tracking_transformer(\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_tracking_pytorch/train_dlctransreid.py\", line 108, in train_tracking_transformer\r\n    do_dlc_train(\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_tracking_pytorch/processor/processor.py\", line 109, in do_dlc_train\r\n    anchor_feat = model(anchor)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_tracking_pytorch/model/make_model.py\", line 37, in forward\r\n    global_feat = self.base(x)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_tracking_pytorch/model/backbones/vit_pytorch.py\", line 301, in forward\r\n    x = self.forward_features(x)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_tracking_pytorch/model/backbones/vit_pytorch.py\", line 275, in forward_features\r\n    x = self.kpt_embed(x)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_tracking_pytorch/model/backbones/vit_pytorch.py\", line 185, in forward\r\n    x = self.proj(x)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 114, in forward\r\n    return F.linear(input, self.weight, self.bias)\r\nRuntimeError: CUDA error: no kernel image is available for execution on the device\r\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\r\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n\n### Operating System\n\nUbuntu 20.04.4 LTS\n\n### DeepLabCut version\n\n2.2.1.1\n\n### DeepLabCut mode\n\nmulti animal\n\n### Device type\n\ngpu\n\n### Steps To Reproduce\n\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'ball'],\r\n 'batch_size': 1,\r\n 'crop_pad': 0,\r\n 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_UFALAug5/UFAL_CRB18062295shuffle1.pickle',\r\n 'dataset_type': 'multi-animal-imgaug',\r\n 'deterministic': False,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': '/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 1.0,\r\n 'locref_smooth': False,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'minconfidence': 0.01,\r\n 'mirror': False,\r\n 'multi_stage': True,\r\n 'net_type': 'resnet_50',\r\n 'nmsradius': 5.0,\r\n 'num_idchannel': 11,\r\n 'num_joints': 4,\r\n 'num_limbs': 3,\r\n 'optimizer': 'sgd',\r\n 'paf_best': [0, 1, 2],\r\n 'pairwise_huber_loss': True,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_graph': [[0, 1], [0, 2], [1, 2]],\r\n 'partaffinityfield_predict': True,\r\n 'regularize': False,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'sigma': 1,\r\n 'snapshot_prefix': '/home/preto/DLC/UFAL/UFAL-CRB180622-2022-08-05/dlc-models/iteration-0/UFALAug5-trainset95shuffle1/test/snapshot',\r\n 'stride': 8.0,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nUsing snapshot-200000 for model /home/preto/DLC/UFAL/UFAL-CRB180622-2022-08-05/dlc-models/iteration-0/UFALAug5-trainset95shuffle1\r\n/home/preto/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer._call_` method instead.\r\n  warnings.warn('`layer.apply` is deprecated and '\r\nActivating extracting of PAFs\r\n2022-08-11 10:52:27.367998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-08-11 10:52:27.368198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-08-11 10:52:27.368297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-08-11 10:52:27.368432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-08-11 10:52:27.368530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-08-11 10:52:27.368592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22300 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\r\nStarting to analyze %  /home/preto/DLC/UFAL/CRBxAzurra/Cameras_Arquibancada/Cam_03_02.avi\r\nLoading  /home/preto/DLC/UFAL/CRBxAzurra/Cameras_Arquibancada/Cam_03_02.avi\r\nDuration of video [s]:  2129.13 , recorded with  30.0 fps!\r\nOverall # of frames:  63874  found with (before cropping) frame dimensions:  2560 1440\r\nStarting to extract posture\r\n100%|███████████████████████████████████████████████████████████████| 63874/63874 [02:22<00:00, 448.35it/s]\r\nStarting to analyze %  /home/preto/DLC/UFAL/CRBxAzurra/Cameras_Arquibancada/Cam_04_02.avi\r\nLoading  /home/preto/DLC/UFAL/CRBxAzurra/Cameras_Arquibancada/Cam_04_02.avi\r\nDuration of video [s]:  2129.13 , recorded with  30.0 fps!\r\nOverall # of frames:  63874  found with (before cropping) frame dimensions:  2560 1440\r\nStarting to extract posture\r\n100%|███████████████████████████████████████████████████████████████| 63874/63874 [02:23<00:00, 445.83it/s]\r\n/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_tracking_pytorch/tracking_utils/preprocessing.py:54: RuntimeWarning: Mean of empty slice\r\n  match_id = np.argmin(np.nanmean(diff, axis=(1, 2)))\r\nIf the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\r\nstart training\r\nTraceback (most recent call last):\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/deeplabcut/gui/transformerID.py\", line 195, in run_transformer_reID\r\n    deeplabcut.transformer_reID(\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_tracking_pytorch/apis.py\", line 120, in transformer_reID\r\n    deeplabcut.pose_tracking_pytorch.train_tracking_transformer(\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_tracking_pytorch/train_dlctransreid.py\", line 108, in train_tracking_transformer\r\n    do_dlc_train(\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_tracking_pytorch/processor/processor.py\", line 109, in do_dlc_train\r\n    anchor_feat = model(anchor)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_tracking_pytorch/model/make_model.py\", line 37, in forward\r\n    global_feat = self.base(x)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_tracking_pytorch/model/backbones/vit_pytorch.py\", line 301, in forward\r\n    x = self.forward_features(x)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_tracking_pytorch/model/backbones/vit_pytorch.py\", line 275, in forward_features\r\n    x = self.kpt_embed(x)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/deeplabcut/pose_tracking_pytorch/model/backbones/vit_pytorch.py\", line 185, in forward\r\n    x = self.proj(x)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/home/preto/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 114, in forward\r\n    return F.linear(input, self.weight, self.bias)\r\nRuntimeError: CUDA error: no kernel image is available for execution on the device\r\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\r\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n\n### Relevant log output\n\n_No response_\n\n### Anything else?\n\n_No response_\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/DeepLabCut/DeepLabCut/blob/master/CODE_OF_CONDUCT.md)","closed_by":{"login":"MMathisLab","id":28102185,"node_id":"MDQ6VXNlcjI4MTAyMTg1","avatar_url":"https://avatars.githubusercontent.com/u/28102185?v=4","gravatar_id":"","url":"https://api.github.com/users/MMathisLab","html_url":"https://github.com/MMathisLab","followers_url":"https://api.github.com/users/MMathisLab/followers","following_url":"https://api.github.com/users/MMathisLab/following{/other_user}","gists_url":"https://api.github.com/users/MMathisLab/gists{/gist_id}","starred_url":"https://api.github.com/users/MMathisLab/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MMathisLab/subscriptions","organizations_url":"https://api.github.com/users/MMathisLab/orgs","repos_url":"https://api.github.com/users/MMathisLab/repos","events_url":"https://api.github.com/users/MMathisLab/events{/privacy}","received_events_url":"https://api.github.com/users/MMathisLab/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1942/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1942/timeline","performed_via_github_app":null,"state_reason":"completed"}