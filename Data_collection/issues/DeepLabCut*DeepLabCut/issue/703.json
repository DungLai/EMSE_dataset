{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/703","repository_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut","labels_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/703/labels{/name}","comments_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/703/comments","events_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/703/events","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/703","id":624909306,"node_id":"MDU6SXNzdWU2MjQ5MDkzMDY=","number":703,"title":"Index error while analyzing the video","user":{"login":"chanduborkar","id":53411725,"node_id":"MDQ6VXNlcjUzNDExNzI1","avatar_url":"https://avatars.githubusercontent.com/u/53411725?v=4","gravatar_id":"","url":"https://api.github.com/users/chanduborkar","html_url":"https://github.com/chanduborkar","followers_url":"https://api.github.com/users/chanduborkar/followers","following_url":"https://api.github.com/users/chanduborkar/following{/other_user}","gists_url":"https://api.github.com/users/chanduborkar/gists{/gist_id}","starred_url":"https://api.github.com/users/chanduborkar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chanduborkar/subscriptions","organizations_url":"https://api.github.com/users/chanduborkar/orgs","repos_url":"https://api.github.com/users/chanduborkar/repos","events_url":"https://api.github.com/users/chanduborkar/events{/privacy}","received_events_url":"https://api.github.com/users/chanduborkar/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":12,"created_at":"2020-05-26T14:03:42Z","updated_at":"2020-06-18T21:19:21Z","closed_at":"2020-05-29T19:02:21Z","author_association":"NONE","active_lock_reason":null,"body":"I am using WIN10, ANconda, Deeplabcut =2.2.b5\r\nAfter analyzing the video I see 'Indexing error: List index out of range' at the end. \r\nPasting here prompt \r\n```\r\n(base) C:\\WINDOWS\\system32>A:\r\n\r\n(base) A:\\>activate DLC-CPU\r\n\r\n(DLC-CPU) A:\\>ipython\r\nPython 3.7.7 (default, Apr 15 2020, 05:09:04) [MSC v.1916 64 bit (AMD64)]\r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 7.13.0 -- An enhanced Interactive Python. Type '?' for help.\r\n\r\nIn [1]: import deeplabcut\r\n\r\nIn [2]: deeplabcut.launch_dlc()\r\nCreated \"A:\\Test\\Demo-chandu-2020-05-25\\videos\"\r\nCreated \"A:\\Test\\Demo-chandu-2020-05-25\\labeled-data\"\r\nCreated \"A:\\Test\\Demo-chandu-2020-05-25\\training-datasets\"\r\nCreated \"A:\\Test\\Demo-chandu-2020-05-25\\dlc-models\"\r\nAttempting to create a symbolic link of the video ...\r\nCreated the symlink of A:\\Test\\Recall.mp4 to A:\\Test\\Demo-chandu-2020-05-25\\videos\\Recall.mp4\r\nA:\\Test\\Demo-chandu-2020-05-25\\videos\\Recall.mp4\r\nGenerated \"A:\\Test\\Demo-chandu-2020-05-25\\config.yaml\"\r\n\r\nA new project with name Demo-chandu-2020-05-25 is created at A:\\Test and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\r\n Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\r\n. [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\r\nConfig file read successfully.\r\nExtracting frames based on kmeans ...\r\nKmeans-quantization based extracting of frames from 0.0  seconds to 935.9  seconds.\r\nExtracting and downsampling... 28077  frames from the video.\r\n28077it [00:17, 1561.99it/s]\r\nKmeans clustering ... (this might take a while)\r\nFrames were successfully extracted.\r\n\r\nYou can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\r\nNo images found!!\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\n~\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\labeling_toolbox.py in browseDir(self, event)\r\n    487\r\n    488 # Reading the image name\r\n--> 489         self.img = self.index[self.iter]\r\n    490         img_name = Path(self.index[self.iter]).name\r\n    491         self.norm,self.colorIndex = self.image_panel.getColorIndices(self.img,self.bodyparts)\r\n\r\nIndexError: index 0 is out of bounds for axis 0 with size 0\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n~\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\labeling_toolbox.py in nextImage(self, event)\r\n    569\r\n    570         self.statusbar.SetStatusText('Working on folder: {}'.format(os.path.split(str(self.dir))[-1]))\r\n--> 571         self.rdb.SetSelection(0)\r\n    572         self.file = 1\r\n    573 # Refreshing the button counter\r\n\r\nAttributeError: 'MainFrame' object has no attribute 'rdb'\r\nYou can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\r\nDownloading a ImageNet-pretrained model from https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.0_224.tgz....\r\nThe training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\r\nConfig:\r\n{'all_joints': [[0], [1], [2]],\r\n 'all_joints_names': ['EarL', 'EarR', 'Tail'],\r\n 'batch_size': 1,\r\n 'bottomheight': 400,\r\n 'crop': True,\r\n 'crop_pad': 0,\r\n 'cropratio': 0.4,\r\n 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_DemoMay25\\\\Demo_chandu95shuffle1.mat',\r\n 'dataset_type': 'default',\r\n 'deterministic': False,\r\n 'display_iters': 1000,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': 'C:\\\\Users\\\\chand\\\\anaconda3\\\\envs\\\\DLC-CPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\mobilenet_v2_1.0_224.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'leftwidth': 400,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 0.05,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'max_input_size': 1500,\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_DemoMay25\\\\Documentation_data-Demo_95shuffle1.pickle',\r\n 'min_input_size': 64,\r\n 'minsize': 100,\r\n 'mirror': False,\r\n 'multi_step': [[0.005, 10000],\r\n                [0.02, 430000],\r\n                [0.002, 730000],\r\n                [0.001, 1030000]],\r\n 'net_type': 'mobilenet_v2_1.0',\r\n 'num_joints': 3,\r\n 'optimizer': 'sgd',\r\n 'pos_dist_thresh': 17,\r\n 'project_path': 'A:\\\\Test\\\\Demo-chandu-2020-05-25',\r\n 'regularize': False,\r\n 'rightwidth': 400,\r\n 'save_iters': 50000,\r\n 'scale_jitter_lo': 0.5,\r\n 'scale_jitter_up': 1.25,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': 'A:\\\\Test\\\\Demo-chandu-2020-05-25\\\\dlc-models\\\\iteration-0\\\\DemoMay25-trainset95shuffle1\\\\train\\\\snapshot',\r\n 'stride': 8.0,\r\n 'topheight': 400,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nSwitching batchsize to 1, as default/tensorpack/deterministic loaders do not support batches >1. Use imgaug loader.\r\nStarting with standard pose-dataset loader.\r\nInitializing MobileNet\r\nWARNING:tensorflow:From C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nWARNING:tensorflow:From C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.cast instead.\r\nLoading ImageNet-pretrained mobilenet_v2_1.0\r\nWARNING:tensorflow:From C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to check for files with this prefix.\r\nINFO:tensorflow:Restoring parameters from C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\mobilenet_v2_1.0_224.ckpt\r\nMax_iters overwritten as 1000\r\nDisplay_iters overwritten as 100\r\nSave_iters overwritten as 1000\r\nTraining parameter:\r\n{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'A:\\\\Test\\\\Demo-chandu-2020-05-25\\\\dlc-models\\\\iteration-0\\\\DemoMay25-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2]], 'all_joints_names': ['EarL', 'EarR', 'Tail'], 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_DemoMay25\\\\Demo_chandu95shuffle1.mat', 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\chand\\\\anaconda3\\\\envs\\\\DLC-CPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\mobilenet_v2_1.0_224.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_DemoMay25\\\\Documentation_data-Demo_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'mobilenet_v2_1.0', 'num_joints': 3, 'pos_dist_thresh': 17, 'project_path': 'A:\\\\Test\\\\Demo-chandu-2020-05-25', 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25}\r\nStarting training....\r\niteration: 100 loss: 0.1297 lr: 0.005\r\niteration: 200 loss: 0.0409 lr: 0.005\r\niteration: 300 loss: 0.0346 lr: 0.005\r\niteration: 400 loss: 0.0309 lr: 0.005\r\niteration: 500 loss: 0.0296 lr: 0.005\r\niteration: 600 loss: 0.0264 lr: 0.005\r\niteration: 700 loss: 0.0260 lr: 0.005\r\niteration: 800 loss: 0.0250 lr: 0.005\r\niteration: 900 loss: 0.0224 lr: 0.005\r\niteration: 1000 loss: 0.0219 lr: 0.005\r\nException in thread Thread-2:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\r\n         [[{{node fifo_queue_enqueue}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 81, in load_and_enqueue\r\n    sess.run(enqueue_op, feed_dict=food)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\r\n         [[node fifo_queue_enqueue (defined at C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:67) ]]\r\n\r\nCaused by op 'fifo_queue_enqueue', defined at:\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\Scripts\\ipython-script.py\", line 10, in <module>\r\n    sys.exit(start_ipython())\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\IPython\\__init__.py\", line 126, in start_ipython\r\n    return launch_new_instance(argv=argv, **kwargs)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\r\n    app.start()\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\IPython\\terminal\\ipapp.py\", line 356, in start\r\n    self.shell.mainloop()\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\IPython\\terminal\\interactiveshell.py\", line 558, in mainloop\r\n    self.interact()\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\IPython\\terminal\\interactiveshell.py\", line 549, in interact\r\n    self.run_cell(code, store_history=True)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2858, in run_cell\r\n    raw_cell, store_history, silent, shell_futures)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2886, in _run_cell\r\n    return runner(coro)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\r\n    coro.send(None)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3063, in run_cell_async\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-1ced4355ffc5>\", line 1, in <module>\r\n    deeplabcut.launch_dlc()\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\gui\\launch_script.py\", line 45, in launch_dlc\r\n    app.MainLoop()\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\wx\\core.py\", line 2167, in MainLoop\r\n    rv = wx.PyApp.MainLoop(self)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\gui\\label_frames.py\", line 102, in label_frames\r\n    deeplabcut.label_frames(self.config)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\trainingsetmanipulation.py\", line 260, in label_frames\r\n    labeling_toolbox.show(config,imtypes=imtypes)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\labeling_toolbox.py\", line 702, in show\r\n    app.MainLoop()\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\wx\\core.py\", line 2167, in MainLoop\r\n    rv = wx.PyApp.MainLoop(self)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\gui\\label_frames.py\", line 102, in label_frames\r\n    deeplabcut.label_frames(self.config)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\trainingsetmanipulation.py\", line 260, in label_frames\r\n    labeling_toolbox.show(config,imtypes=imtypes)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\labeling_toolbox.py\", line 702, in show\r\n    app.MainLoop()\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\wx\\core.py\", line 2167, in MainLoop\r\n    rv = wx.PyApp.MainLoop(self)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\gui\\train_network.py\", line 268, in train_network\r\n    maxiters=maxiters)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 132, in train_network\r\n    train(str(poseconfigfile),displayiters,saveiters,maxiters,max_to_keep=max_snapshots_to_keep,keepdeconvweights=keepdeconvweights,allow_growth=allow_growth) #pass on path and file name for pose_cfg.yaml!\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 118, in train\r\n    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 67, in setup_preloading\r\n    enqueue_op = q.enqueue(placeholders_list)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 345, in enqueue\r\n    self._queue_ref, vals, name=scope)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 4157, in queue_enqueue_v2\r\n    timeout_ms=timeout_ms, name=name)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nCancelledError (see above for traceback): Enqueue operation was cancelled\r\n         [[node fifo_queue_enqueue (defined at C:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:67) ]]\r\n\r\n\r\nThe network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\r\nConfig:\r\n{'all_joints': [[0], [1], [2]],\r\n 'all_joints_names': ['EarL', 'EarR', 'Tail'],\r\n 'batch_size': 1,\r\n 'bottomheight': 400,\r\n 'crop': True,\r\n 'crop_pad': 0,\r\n 'cropratio': 0.4,\r\n 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_DemoMay25\\\\Demo_chandu95shuffle1.mat',\r\n 'dataset_type': 'default',\r\n 'deterministic': False,\r\n 'display_iters': 1000,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': 'C:\\\\Users\\\\chand\\\\anaconda3\\\\envs\\\\DLC-CPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\mobilenet_v2_1.0_224.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'leftwidth': 400,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 0.05,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'max_input_size': 1500,\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_DemoMay25\\\\Documentation_data-Demo_95shuffle1.pickle',\r\n 'min_input_size': 64,\r\n 'minsize': 100,\r\n 'mirror': False,\r\n 'multi_step': [[0.005, 10000],\r\n                [0.02, 430000],\r\n                [0.002, 730000],\r\n                [0.001, 1030000]],\r\n 'net_type': 'mobilenet_v2_1.0',\r\n 'num_joints': 3,\r\n 'optimizer': 'sgd',\r\n 'pos_dist_thresh': 17,\r\n 'project_path': 'A:\\\\Test\\\\Demo-chandu-2020-05-25',\r\n 'regularize': False,\r\n 'rightwidth': 400,\r\n 'save_iters': 50000,\r\n 'scale_jitter_lo': 0.5,\r\n 'scale_jitter_up': 1.25,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': 'A:\\\\Test\\\\Demo-chandu-2020-05-25\\\\dlc-models\\\\iteration-0\\\\DemoMay25-trainset95shuffle1\\\\test\\\\snapshot',\r\n 'stride': 8.0,\r\n 'topheight': 400,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nRunning  DLC_mobnet_100_DemoMay25shuffle1_1000  with # of trainingiterations: 1000\r\nInitializing MobileNet\r\nINFO:tensorflow:Restoring parameters from A:\\Test\\Demo-chandu-2020-05-25\\dlc-models\\iteration-0\\DemoMay25-trainset95shuffle1\\train\\snapshot-1000\r\nAnalyzing data...\r\n10it [00:08,  1.24it/s]\r\nDone and results stored for snapshot:  snapshot-1000\r\nC:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\evaluate.py:370: RuntimeWarning: Mean of empty slice\r\n  testerrorpcutoff = np.nanmean(RMSEpcutoff.iloc[testIndices].values.flatten())\r\nC:\\Users\\chand\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\evaluate.py:371: RuntimeWarning: Mean of empty slice\r\n  trainerrorpcutoff = np.nanmean(RMSEpcutoff.iloc[trainIndices].values.flatten())\r\nResults for 1000  training iterations: 95 1 train error: 19.45 pixels. Test error: 8.02  pixels.\r\nWith pcutoff of 0.6  train error: nan pixels. Test error: nan pixels\r\nThereby, the errors are given by the average distances between the labels by DLC and the scorer.\r\nPlotting...\r\n100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.40it/s]\r\nThe network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\r\nIf it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\r\nUse the function 'analyze_video' to make predictions on new videos.\r\nOtherwise consider retraining the network (see DeepLabCut workflow Fig 2)\r\nConfig:\r\n{'all_joints': [[0], [1], [2]],\r\n 'all_joints_names': ['EarL', 'EarR', 'Tail'],\r\n 'batch_size': 1,\r\n 'bottomheight': 400,\r\n 'crop': True,\r\n 'crop_pad': 0,\r\n 'cropratio': 0.4,\r\n 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_DemoMay25\\\\Demo_chandu95shuffle1.mat',\r\n 'dataset_type': 'default',\r\n 'deterministic': False,\r\n 'display_iters': 1000,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': 'C:\\\\Users\\\\chand\\\\anaconda3\\\\envs\\\\DLC-CPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\mobilenet_v2_1.0_224.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'leftwidth': 400,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 0.05,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'max_input_size': 1500,\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_DemoMay25\\\\Documentation_data-Demo_95shuffle1.pickle',\r\n 'min_input_size': 64,\r\n 'minsize': 100,\r\n 'mirror': False,\r\n 'multi_step': [[0.005, 10000],\r\n                [0.02, 430000],\r\n                [0.002, 730000],\r\n                [0.001, 1030000]],\r\n 'net_type': 'mobilenet_v2_1.0',\r\n 'num_joints': 3,\r\n 'optimizer': 'sgd',\r\n 'pos_dist_thresh': 17,\r\n 'project_path': 'A:\\\\Test\\\\Demo-chandu-2020-05-25',\r\n 'regularize': False,\r\n 'rightwidth': 400,\r\n 'save_iters': 50000,\r\n 'scale_jitter_lo': 0.5,\r\n 'scale_jitter_up': 1.25,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': 'A:\\\\Test\\\\Demo-chandu-2020-05-25\\\\dlc-models\\\\iteration-0\\\\DemoMay25-trainset95shuffle1\\\\test\\\\snapshot',\r\n 'stride': 8.0,\r\n 'topheight': 400,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nUsing snapshot-1000 for model A:\\Test\\Demo-chandu-2020-05-25\\dlc-models\\iteration-0\\DemoMay25-trainset95shuffle1\r\nInitializing MobileNet\r\nINFO:tensorflow:Restoring parameters from A:\\Test\\Demo-chandu-2020-05-25\\dlc-models\\iteration-0\\DemoMay25-trainset95shuffle1\\train\\snapshot-1000\r\nStarting to analyze %  A:\\Test\\Recall.mp4\r\nLoading  A:\\Test\\Recall.mp4\r\nDuration of video [s]:  935.9 , recorded with  30.0 fps!\r\nOverall # of frames:  28077  found with (before cropping) frame dimensions:  640 480\r\nStarting to extract posture\r\n28280it [9:07:00,  1.18s/it]                                                                                           Detected frames:  28077\r\n28280it [9:08:35,  1.16s/it]\r\nSaving results in A:\\Test...\r\nSaving csv poses!\r\nThe videos are analyzed. Now your research can truly start!\r\n You can create labeled videos with 'create_labeled_video'.\r\nIf the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\r\nFiltering with median model A:\\Test\\Recall.mp4\r\n3it [00:00, 33.80it/s]\r\nSaving filtered csv poses!\r\nStarting %  A:\\Test ['A:\\\\Test\\\\Recall.mp4']\r\nLoading  A:\\Test\\Recall.mp4 and data.\r\n28077\r\nDuration of video [s]:  935.9 , recorded with  30.0 fps!\r\nOverall # of frames:  28077 with cropped frame dimensions:  640 480\r\nGenerating frames and creating video.\r\n100%|███████████████████████████████████████████████████████████████████████████| 28077/28077 [01:22<00:00, 341.93it/s]\r\nA:\\Test\\Recall.mp4\r\nStarting %  A:\\Test A:\\Test\\Recall.mp4\r\nLoading  A:\\Test\\Recall.mp4 and data.\r\nA:\\Test  already exists!\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\n~\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\gui\\analyze_videos.py in analyze_videos(self, event)\r\n    271         if self.trajectory.GetStringSelection() == \"Yes\":\r\n    272             deeplabcut.plot_trajectories(self.config, self.filelist, displayedbodyparts=self.bodyparts,\r\n--> 273                                          videotype=self.videotype.GetValue(), shuffle=shuffle, trainingsetindex=trainingsetindex, filtered=True, showfigures=False, destfolder=self.destfolder)\r\n    274\r\n    275     def reset_analyze_videos(self,event):\r\n\r\n~\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\utils\\plotting.py in plot_trajectories(config, videos, videotype, shuffle, trainingsetindex, filtered, displayedbodyparts, showfigures, destfolder)\r\n    183                 tmpfolder = os.path.join(basefolder,'plot-poses', vname)\r\n    184                 auxiliaryfunctions.attempttomakefolder(tmpfolder)\r\n--> 185                 PlottingResults(tmpfolder, Dataframe, DLCscorer, cfg, bodyparts, showfigures, suffix+'.png')\r\n    186\r\n    187     print('Plots created! Please check the directory \"plot-poses\" within the video directory')\r\n\r\n~\\anaconda3\\envs\\DLC-CPU\\lib\\site-packages\\deeplabcut\\utils\\plotting.py in PlottingResults(tmpfolder, Dataframe, scorer, cfg, bodyparts2plot, showfigures, suffix)\r\n     53     plt.savefig(os.path.join(tmpfolder,\"trajectory\"+suffix))\r\n     54     plt.figure(figsize=(30, 10))\r\n---> 55     Time=np.arange(np.size(Dataframe[scorer][bodyparts2plot[0]]['x'].values))\r\n     56\r\n     57     for bpindex, bp in enumerate(bodyparts2plot):\r\n\r\nIndexError: list index out of range\r\n```\r\n\r\n**A separate folder is created for 'plot-poses' with trajectory plot which is blank.** \r\n![trajectory_filtered](https://user-images.githubusercontent.com/53411725/82910934-dcceac00-9f30-11ea-9153-ad214fe44f7a.png)\r\n\r\n","closed_by":{"login":"MMathisLab","id":28102185,"node_id":"MDQ6VXNlcjI4MTAyMTg1","avatar_url":"https://avatars.githubusercontent.com/u/28102185?v=4","gravatar_id":"","url":"https://api.github.com/users/MMathisLab","html_url":"https://github.com/MMathisLab","followers_url":"https://api.github.com/users/MMathisLab/followers","following_url":"https://api.github.com/users/MMathisLab/following{/other_user}","gists_url":"https://api.github.com/users/MMathisLab/gists{/gist_id}","starred_url":"https://api.github.com/users/MMathisLab/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MMathisLab/subscriptions","organizations_url":"https://api.github.com/users/MMathisLab/orgs","repos_url":"https://api.github.com/users/MMathisLab/repos","events_url":"https://api.github.com/users/MMathisLab/events{/privacy}","received_events_url":"https://api.github.com/users/MMathisLab/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/703/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/703/timeline","performed_via_github_app":null,"state_reason":"completed"}