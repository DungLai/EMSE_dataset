{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/662","repository_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut","labels_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/662/labels{/name}","comments_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/662/comments","events_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/662/events","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/662","id":605910663,"node_id":"MDU6SXNzdWU2MDU5MTA2NjM=","number":662,"title":"Out of memory error at train network","user":{"login":"mich11","id":283777,"node_id":"MDQ6VXNlcjI4Mzc3Nw==","avatar_url":"https://avatars.githubusercontent.com/u/283777?v=4","gravatar_id":"","url":"https://api.github.com/users/mich11","html_url":"https://github.com/mich11","followers_url":"https://api.github.com/users/mich11/followers","following_url":"https://api.github.com/users/mich11/following{/other_user}","gists_url":"https://api.github.com/users/mich11/gists{/gist_id}","starred_url":"https://api.github.com/users/mich11/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mich11/subscriptions","organizations_url":"https://api.github.com/users/mich11/orgs","repos_url":"https://api.github.com/users/mich11/repos","events_url":"https://api.github.com/users/mich11/events{/privacy}","received_events_url":"https://api.github.com/users/mich11/received_events","type":"User","site_admin":false},"labels":[{"id":1816193536,"node_id":"MDU6TGFiZWwxODE2MTkzNTM2","url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/labels/tensorflow/training","name":"tensorflow/training","color":"0052cc","default":false,"description":""}],"state":"closed","locked":false,"assignee":{"login":"MMathisLab","id":28102185,"node_id":"MDQ6VXNlcjI4MTAyMTg1","avatar_url":"https://avatars.githubusercontent.com/u/28102185?v=4","gravatar_id":"","url":"https://api.github.com/users/MMathisLab","html_url":"https://github.com/MMathisLab","followers_url":"https://api.github.com/users/MMathisLab/followers","following_url":"https://api.github.com/users/MMathisLab/following{/other_user}","gists_url":"https://api.github.com/users/MMathisLab/gists{/gist_id}","starred_url":"https://api.github.com/users/MMathisLab/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MMathisLab/subscriptions","organizations_url":"https://api.github.com/users/MMathisLab/orgs","repos_url":"https://api.github.com/users/MMathisLab/repos","events_url":"https://api.github.com/users/MMathisLab/events{/privacy}","received_events_url":"https://api.github.com/users/MMathisLab/received_events","type":"User","site_admin":false},"assignees":[{"login":"MMathisLab","id":28102185,"node_id":"MDQ6VXNlcjI4MTAyMTg1","avatar_url":"https://avatars.githubusercontent.com/u/28102185?v=4","gravatar_id":"","url":"https://api.github.com/users/MMathisLab","html_url":"https://github.com/MMathisLab","followers_url":"https://api.github.com/users/MMathisLab/followers","following_url":"https://api.github.com/users/MMathisLab/following{/other_user}","gists_url":"https://api.github.com/users/MMathisLab/gists{/gist_id}","starred_url":"https://api.github.com/users/MMathisLab/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MMathisLab/subscriptions","organizations_url":"https://api.github.com/users/MMathisLab/orgs","repos_url":"https://api.github.com/users/MMathisLab/repos","events_url":"https://api.github.com/users/MMathisLab/events{/privacy}","received_events_url":"https://api.github.com/users/MMathisLab/received_events","type":"User","site_admin":false}],"milestone":null,"comments":9,"created_at":"2020-04-23T22:18:56Z","updated_at":"2021-03-03T12:54:56Z","closed_at":"2020-04-27T17:29:41Z","author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\nI'm getting an out of memory error when I try to train the network, using either my data or the example data (run testscript.py).  I'm wondering if there's something wrong with our installation. \r\n\r\n**Operating system and DeepLabCut version**\r\nCentos 7.7\r\nAnaconda Env, Python 3.6.8\r\nDeepLabCut 2.1.6\r\nTensorflow 1.14\r\nCuda 10.0\r\nGPU Tesla P-100 (12GB RAM)\r\nData: mp4, 646x482 frame size, <500MB/video\r\n\r\n**Describe the problem**\r\nWhen I try to train the classifier, I get the following error: CUDA_ERROR_OUT_OF_MEMORY, followed by a core dump. I've tried reducing the number of display iterations, and I've tried running with some of the provided example data (testscript.py). Each time, the error happens after the command line report \"Loading ImageNet-pretrained resnet_50\", and I've confirmed with nvidia-smi that deeplabcut does put something on the GPU before running out of memory. \r\n\r\n**How to Reproduce the problem**\r\nTo try with the example data, in ipython: \r\nimport deeplabcut\r\nrun testscript.py\r\n\r\n**Context**\r\n\r\nNVIDIA-SMI output just before/during error\r\n```\r\nMon Apr 20 16:17:29 2020       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 410.129      Driver Version: 410.129      CUDA Version: 10.0     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla P100-PCIE...  Off  | 00000000:81:00.0 Off |                    0 |\r\n| N/A   78C    P0    47W / 250W |   4444MiB / 12198MiB |      9%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      2953      C   ...y/.conda/envs/dlc-ubuntu-GPU/bin/python  3607MiB |\r\n|    0      9214      C   /oldhome/MATLAB/R2019a/bin/glnxa64/MATLAB    827MiB |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\nCommand-line output after running testscript.py\r\n```\r\nrun testscript.py                                                                                                                                                                               \r\nImported DLC!\r\nCREATING PROJECT\r\nCreated \"/home/melody/DeepLabCut-master/examples/TEST-Alex-2020-04-20/videos\"\r\nCreated \"/home/melody/DeepLabCut-master/examples/TEST-Alex-2020-04-20/labeled-data\"\r\nCreated \"/home/melody/DeepLabCut-master/examples/TEST-Alex-2020-04-20/training-datasets\"\r\nCreated \"/home/melody/DeepLabCut-master/examples/TEST-Alex-2020-04-20/dlc-models\"\r\nCopying the videos\r\n/home/melody/DeepLabCut-master/examples/TEST-Alex-2020-04-20/videos/reachingvideo1.avi\r\nGenerated \"/home/melody/DeepLabCut-master/examples/TEST-Alex-2020-04-20/config.yaml\"\r\n\r\nA new project with name TEST-Alex-2020-04-20 is created at /home/melody/DeepLabCut-master/examples and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\r\n Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\r\n. [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\r\nEXTRACTING FRAMES\r\nConfig file read successfully.\r\nExtracting frames based on kmeans ...\r\nKmeans-quantization based extracting of frames from 0.0  seconds to 8.53  seconds.\r\nExtracting and downsampling... 256  frames from the video.\r\n256it [00:01, 220.90it/s]\r\nKmeans clustering ... (this might take a while)\r\n\r\nFrames were selected.\r\nYou can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\r\nCREATING-SOME LABELS FOR THE FRAMES\r\nPlot labels...\r\nCreating images with labels by Alex.\r\nThey are stored in the following folder: /home/melody/DeepLabCut-master/examples/TEST-Alex-2020-04-20/labeled-data/reachingvideo1_labeled.\r\nIf all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\r\nCREATING TRAININGSET\r\nThe training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\r\nCHANGING training parameters to end quickly!\r\nTRAIN\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'],\r\n 'batch_size': 1,\r\n 'bottomheight': 400,\r\n 'crop': True,\r\n 'crop_pad': 0,\r\n 'cropratio': 0.4,\r\n 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_TESTApr20/TEST_Alex80shuffle1.mat',\r\n 'dataset_type': 'default',\r\n 'deterministic': False,\r\n 'display_iters': 2,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': '/home/melody/.conda/envs/dlc-ubuntu-GPU/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'leftwidth': 400,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 0.05,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'max_input_size': 1500,\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_TESTApr20/Documentation_data-TEST_80shuffle1.pickle',\r\n 'min_input_size': 64,\r\n 'minsize': 100,\r\n 'mirror': False,\r\n 'multi_step': [[0.001, 5]],\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 4,\r\n 'optimizer': 'sgd',\r\n 'pos_dist_thresh': 17,\r\n 'project_path': '/home/melody/DeepLabCut-master/examples/TEST-Alex-2020-04-20',\r\n 'regularize': False,\r\n 'rightwidth': 400,\r\n 'save_iters': 5,\r\n 'scale_jitter_lo': 0.5,\r\n 'scale_jitter_up': 1.25,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': '/home/melody/DeepLabCut-master/examples/TEST-Alex-2020-04-20/dlc-models/iteration-0/TESTApr20-trainset80shuffle1/train/snapshot',\r\n 'stride': 8.0,\r\n 'topheight': 400,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nSwitching batchsize to 1, as default/tensorpack/deterministic loaders do not support batches >1. Use imgaug loader.\r\nStarting with standard pose-dataset loader.\r\nInitializing ResNet\r\nWARNING:tensorflow:From /home/melody/.conda/envs/dlc-ubuntu-GPU/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/nnet/pose_net.py:62: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\r\n\r\nWARNING:tensorflow:From /home/melody/.conda/envs/dlc-ubuntu-GPU/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/nnet/pose_net.py:160: The name tf.losses.sigmoid_cross_entropy is deprecated. Please use tf.compat.v1.losses.sigmoid_cross_entropy instead.\r\n\r\nWARNING:tensorflow:From /home/melody/.conda/envs/dlc-ubuntu-GPU/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nWARNING:tensorflow:From /home/melody/.conda/envs/dlc-ubuntu-GPU/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/nnet/losses.py:38: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nLoading ImageNet-pretrained resnet_50\r\n2020-04-20 16:17:28.765790: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 10.28G (11037684480 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-04-20 16:17:28.765865: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 9.25G (9933916160 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-04-20 16:17:28.765884: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 8.33G (8940524544 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-04-20 16:17:28.765900: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 7.49G (8046471680 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-04-20 16:17:28.765915: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 6.74G (7241824256 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-04-20 16:17:28.765934: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 6.07G (6517641728 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-04-20 16:17:28.765949: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 5.46G (5865877504 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-04-20 16:17:28.765963: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 4.92G (5279289856 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-04-20 16:17:28.765978: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 4.42G (4751360512 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-04-20 16:17:28.765993: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 3.98G (4276224256 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-04-20 16:17:28.766024: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 3.58G (3848601856 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-04-20 16:17:28.929887: F tensorflow/stream_executor/cuda/cuda_driver.cc:175] Check failed: err == cudaSuccess || err == cudaErrorInvalidValue Unexpected CUDA error: out of memory\r\nAborted (core dumped)\r\n```\r\n\r\n","closed_by":{"login":"MMathisLab","id":28102185,"node_id":"MDQ6VXNlcjI4MTAyMTg1","avatar_url":"https://avatars.githubusercontent.com/u/28102185?v=4","gravatar_id":"","url":"https://api.github.com/users/MMathisLab","html_url":"https://github.com/MMathisLab","followers_url":"https://api.github.com/users/MMathisLab/followers","following_url":"https://api.github.com/users/MMathisLab/following{/other_user}","gists_url":"https://api.github.com/users/MMathisLab/gists{/gist_id}","starred_url":"https://api.github.com/users/MMathisLab/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MMathisLab/subscriptions","organizations_url":"https://api.github.com/users/MMathisLab/orgs","repos_url":"https://api.github.com/users/MMathisLab/repos","events_url":"https://api.github.com/users/MMathisLab/events{/privacy}","received_events_url":"https://api.github.com/users/MMathisLab/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/662/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/662/timeline","performed_via_github_app":null,"state_reason":"completed"}