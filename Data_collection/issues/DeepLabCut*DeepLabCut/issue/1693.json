{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1693","repository_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut","labels_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1693/labels{/name}","comments_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1693/comments","events_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1693/events","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/1693","id":1143207603,"node_id":"I_kwDOB5BM6c5EI_az","number":1693,"title":"Empty tracklets","user":{"login":"GozuNaz","id":77155628,"node_id":"MDQ6VXNlcjc3MTU1NjI4","avatar_url":"https://avatars.githubusercontent.com/u/77155628?v=4","gravatar_id":"","url":"https://api.github.com/users/GozuNaz","html_url":"https://github.com/GozuNaz","followers_url":"https://api.github.com/users/GozuNaz/followers","following_url":"https://api.github.com/users/GozuNaz/following{/other_user}","gists_url":"https://api.github.com/users/GozuNaz/gists{/gist_id}","starred_url":"https://api.github.com/users/GozuNaz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/GozuNaz/subscriptions","organizations_url":"https://api.github.com/users/GozuNaz/orgs","repos_url":"https://api.github.com/users/GozuNaz/repos","events_url":"https://api.github.com/users/GozuNaz/events{/privacy}","received_events_url":"https://api.github.com/users/GozuNaz/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":{"login":"jeylau","id":30733203,"node_id":"MDQ6VXNlcjMwNzMzMjAz","avatar_url":"https://avatars.githubusercontent.com/u/30733203?v=4","gravatar_id":"","url":"https://api.github.com/users/jeylau","html_url":"https://github.com/jeylau","followers_url":"https://api.github.com/users/jeylau/followers","following_url":"https://api.github.com/users/jeylau/following{/other_user}","gists_url":"https://api.github.com/users/jeylau/gists{/gist_id}","starred_url":"https://api.github.com/users/jeylau/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jeylau/subscriptions","organizations_url":"https://api.github.com/users/jeylau/orgs","repos_url":"https://api.github.com/users/jeylau/repos","events_url":"https://api.github.com/users/jeylau/events{/privacy}","received_events_url":"https://api.github.com/users/jeylau/received_events","type":"User","site_admin":false},"assignees":[{"login":"jeylau","id":30733203,"node_id":"MDQ6VXNlcjMwNzMzMjAz","avatar_url":"https://avatars.githubusercontent.com/u/30733203?v=4","gravatar_id":"","url":"https://api.github.com/users/jeylau","html_url":"https://github.com/jeylau","followers_url":"https://api.github.com/users/jeylau/followers","following_url":"https://api.github.com/users/jeylau/following{/other_user}","gists_url":"https://api.github.com/users/jeylau/gists{/gist_id}","starred_url":"https://api.github.com/users/jeylau/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jeylau/subscriptions","organizations_url":"https://api.github.com/users/jeylau/orgs","repos_url":"https://api.github.com/users/jeylau/repos","events_url":"https://api.github.com/users/jeylau/events{/privacy}","received_events_url":"https://api.github.com/users/jeylau/received_events","type":"User","site_admin":false}],"milestone":null,"comments":3,"created_at":"2022-02-18T14:55:52Z","updated_at":"2022-03-01T12:12:29Z","closed_at":"2022-03-01T12:12:29Z","author_association":"NONE","active_lock_reason":null,"body":"### Is there an existing issue for this?\n\n- [X] I have searched the existing issues\n\n### Bug description\n\nHello,\r\n\r\nthis is my first topic, so at the beggining I wanted to thank you for your great software, documentation and community, many other threads already helped me a lot ^^,\r\n\r\nRight now I am using maDLC 2.2.06 on fresh env and in my behaviour and I get this bug that tracklets are empty. I have two distinctable mice (one has marked tail) which can interact freely. I labeled 30 frames from 28 videos (videos are quite different) and trained my network which works quite fine (there are major ID swaps, but it is not that much work in refining tracklets). While reading documentation I noticed that I should set identity=true in config.yaml and while analising I should assemble using animal identity which really worked and I got less major ID swaps. I have done it on earlier version of maDLC (cant remember which one exactly) and then I updated DLC to 2.2.0.6 version and wanted to train the network once again with the same labled data and settings. (saving 10k, max 120k)\r\nPrior to analysing videos evetyhing works normal and here is the problem, when I want to analyse videos with assembling using identity I get this bug that tracklets are empty (when I set it to not use animal identity while assembling it works just fine). Even when I use my network trained on earlier version of DLC I have the same issue (even tough it didint happen earlier). \r\nI would love to use animal identity during assemble because it reduced the number of ID swaps and here is my question is it some kind of bug, or like I read in other threads zero tracklets error means that my network is not trained well enough and I need more labled frames when animals intermingle?\r\n\r\nThank you,\r\ncheers\n\n### Operating System\n\nWindows 10\n\n### DeepLabCut version\n\n2.2.0.6\n\n### DeepLabCut mode\n\nmulti animal\n\n### Device type\n\ngpu\n\n### Steps To Reproduce\n\n_No response_\n\n### Relevant log output\n\n```shell\nconfig.yaml\r\n    # Project definitions (do not edit)\r\nTask: Remote\r\nscorer: Gozu\r\ndate: Feb17\r\nmultianimalproject: true\r\nidentity: true\r\n\r\n    # Project path (change when moving around)\r\nproject_path: D:\\praca\\ML\\Remote-Gozu-2022-02-17\r\n\r\n    # Annotation data set configuration (and individual video cropping parameters)\r\nvideo_sets:\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\EXP_KO_5.mp4:\r\n    crop: 0, 550, 0, 380\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\EXP_KO_4.mp4:\r\n    crop: 0, 550, 0, 380\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\EXP_KO_3.mp4:\r\n    crop: 0, 550, 0, 380\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\EXP_KO_2.mp4:\r\n    crop: 0, 550, 0, 380\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\EXP_KO_1.mp4:\r\n    crop: 0, 550, 0, 380\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\CTRL_KO_6.mp4:\r\n    crop: 0, 550, 0, 380\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\CTRL_KO_5.mp4:\r\n    crop: 0, 550, 0, 380\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\CTRL_KO_4.mp4:\r\n    crop: 0, 550, 0, 380\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\CTRL_KO_3.mp4:\r\n    crop: 0, 550, 0, 380\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\CTRL_KO_1.mp4:\r\n    crop: 0, 550, 0, 380\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\day1_wt9-05182020154959-0000.mp4:\r\n    crop: 0, 1024, 0, 600\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\day1_wt8-05182020152929-0000.mp4:\r\n    crop: 0, 1024, 0, 600\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\day1_wt7-05182020151130-0000.mp4:\r\n    crop: 0, 1024, 0, 600\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\day1_wt6-05182020145325-0000.mp4:\r\n    crop: 0, 1024, 0, 600\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\day1_wt5-05182020143434-0000.mp4:\r\n    crop: 0, 1024, 0, 600\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\day1_ko4-05182020141654-0000.mp4:\r\n    crop: 0, 1024, 0, 600\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\day1_ko3-05182020135627-0000.mp4:\r\n    crop: 0, 1024, 0, 600\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\day1_ko2-05182020134006-0000.mp4:\r\n    crop: 0, 1024, 0, 600\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\day1_ko1-05182020131911-0000.mp4:\r\n    crop: 0, 1024, 0, 600\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\hab1_WT5.mp4:\r\n    crop: 0, 344, 0, 224\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\hab1_WT4.mp4:\r\n    crop: 0, 344, 0, 224\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\hab1_WT2.mp4:\r\n    crop: 0, 344, 0, 224\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\hab1_WT1.mp4:\r\n    crop: 0, 344, 0, 224\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\hab1_KO6.mp4:\r\n    crop: 0, 344, 0, 224\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\hab1_KO5.mp4:\r\n    crop: 0, 344, 0, 224\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\hab1_KO4.mp4:\r\n    crop: 0, 344, 0, 224\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\hab1_KO3.mp4:\r\n    crop: 0, 344, 0, 224\r\n  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\videos\\hab1_KO2.mp4:\r\n    crop: 0, 344, 0, 224\r\nindividuals:\r\n- Dem\r\n- Obs\r\nuniquebodyparts: []\r\nmultianimalbodyparts:\r\n- Ear_left\r\n- Ear_right\r\n- Nose\r\n- Center\r\n- Lateral_left\r\n- Lateral_right\r\n- Tail_base\r\n- Tail_end\r\nskeleton:\r\n- - Center\r\n  - Lateral_left\r\n- - Lateral_left\r\n  - Tail_base\r\n- - Lateral_right\r\n  - Tail_end\r\n- - Ear_left\r\n  - Nose\r\n- - Ear_left\r\n  - Lateral_right\r\n- - Nose\r\n  - Lateral_right\r\n- - Ear_right\r\n  - Center\r\n- - Lateral_right\r\n  - Tail_base\r\n- - Center\r\n  - Tail_base\r\n- - Ear_left\r\n  - Ear_right\r\n- - Nose\r\n  - Lateral_left\r\n- - Ear_right\r\n  - Nose\r\n- - Ear_left\r\n  - Lateral_left\r\n- - Ear_right\r\n  - Lateral_right\r\n- - Tail_base\r\n  - Tail_end\r\n- - Lateral_left\r\n  - Tail_end\r\n- - Center\r\n  - Lateral_right\r\n- - Ear_left\r\n  - Center\r\n- - Ear_right\r\n  - Lateral_left\r\n- - Nose\r\n  - Center\r\nbodyparts: MULTI!\r\nstart: 0\r\nstop: 1\r\nnumframes2pick: 20\r\n\r\n    # Plotting configuration\r\nskeleton_color: gray\r\npcutoff: 0.6\r\ndotsize: 3\r\nalphavalue: 0.7\r\ncolormap: rainbow\r\n\r\n    # Training,Evaluation and Analysis configuration\r\nTrainingFraction:\r\n- 0.95\r\niteration: 0\r\ndefault_net_type: dlcrnet_ms5\r\ndefault_augmenter: multi-animal-imgaug\r\ndefault_track_method: ellipse\r\nsnapshotindex: -1\r\nbatch_size: 8\r\n\r\n    # Cropping Parameters (for analysis and outlier frame detection)\r\ncropping: false\r\n    #if cropping is true for analysis, then set the values here:\r\nx1: 0\r\nx2: 640\r\ny1: 277\r\ny2: 624\r\n\r\n    # Refinement configuration (parameters from annotation dataset configuration also relevant in this stage)\r\ncorner2move2:\r\n- 50\r\n- 50\r\nmove2corner: true\r\n\r\n\r\n\r\nBug:\r\n\r\nDLC network loading and video analysis starting ...\r\nUsing snapshot-120000 for model D:\\praca\\ML\\Remote-Gozu-2022-02-17\\dlc-models\\iteration-0\\RemoteFeb17-trainset95shuffle1\r\nC:\\Users\\Tomek\\anaconda3\\envs\\deep_lab_cut\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\r\n  warnings.warn('`layer.apply` is deprecated and '\r\nC:\\Users\\Tomek\\anaconda3\\envs\\deep_lab_cut\\lib\\site-packages\\tf_slim\\layers\\layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\r\n  outputs = layer.apply(inputs, training=is_training)\r\nActivating extracting of PAFs\r\n2022-02-18 15:25:57.541769: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2022-02-18 15:25:58.313642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3497 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\r\nStarting to analyze %  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\test\\CTRL_KO_1.mp4\r\nLoading  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\test\\CTRL_KO_1.mp4\r\nDuration of video [s]:  540.0 , recorded with  25.0 fps!\r\nOverall # of frames:  13500  found with (before cropping) frame dimensions:  550 380\r\nStarting to extract posture from the video(s) with batchsize: 8\r\n  0%|                                                                                        | 0/13500 [00:00<?, ?it/s]2022-02-18 15:26:01.917130: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\r\n100%|████████████████████████████████████████████████████████████████████████████| 13500/13500 [02:46<00:00, 81.23it/s]\r\nVideo Analyzed. Saving results in D:\\praca\\ML\\Remote-Gozu-2022-02-17\\test...\r\nUsing snapshot-120000 for model D:\\praca\\ML\\Remote-Gozu-2022-02-17\\dlc-models\\iteration-0\\RemoteFeb17-trainset95shuffle1\r\nProcessing...  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\test\\CTRL_KO_1.mp4\r\nAnalyzing D:\\praca\\ML\\Remote-Gozu-2022-02-17\\test\\CTRL_KO_1DLC_dlcrnetms5_RemoteFeb17shuffle1_120000.h5\r\n13500it [00:02, 5259.09it/s]\r\n13500it [00:00, 2685723.28it/s]\r\nThe tracklets were created (i.e., under the hood deeplabcut.convert_detections2tracklets was run). Now you can 'refine_tracklets' in the GUI, or run 'deeplabcut.stitch_tracklets'.\r\nProcessing...  D:\\praca\\ML\\Remote-Gozu-2022-02-17\\test\\CTRL_KO_1.mp4\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Tomek\\anaconda3\\envs\\deep_lab_cut\\lib\\site-packages\\deeplabcut\\gui\\analyze_videos.py\", line 459, in analyze_videos\r\n    scorername = deeplabcut.analyze_videos(\r\n  File \"C:\\Users\\Tomek\\anaconda3\\envs\\deep_lab_cut\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\predict_videos.py\", line 357, in analyze_videos\r\n    stitch_tracklets(\r\n  File \"C:\\Users\\Tomek\\anaconda3\\envs\\deep_lab_cut\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\stitch.py\", line 1113, in stitch_tracklets\r\n    stitcher = TrackletStitcher.from_pickle(\r\n  File \"C:\\Users\\Tomek\\anaconda3\\envs\\deep_lab_cut\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\stitch.py\", line 504, in from_pickle\r\n    class_ = cls.from_dict_of_dict(\r\n  File \"C:\\Users\\Tomek\\anaconda3\\envs\\deep_lab_cut\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\stitch.py\", line 536, in from_dict_of_dict\r\n    class_ = cls(\r\n  File \"C:\\Users\\Tomek\\anaconda3\\envs\\deep_lab_cut\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\stitch.py\", line 457, in __init__\r\n    raise IOError(\"Tracklets are empty.\")\r\nOSError: Tracklets are empty.\n```\n\n\n### Anything else?\n\n_No response_\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/DeepLabCut/DeepLabCut/blob/master/CODE_OF_CONDUCT.md)","closed_by":{"login":"jeylau","id":30733203,"node_id":"MDQ6VXNlcjMwNzMzMjAz","avatar_url":"https://avatars.githubusercontent.com/u/30733203?v=4","gravatar_id":"","url":"https://api.github.com/users/jeylau","html_url":"https://github.com/jeylau","followers_url":"https://api.github.com/users/jeylau/followers","following_url":"https://api.github.com/users/jeylau/following{/other_user}","gists_url":"https://api.github.com/users/jeylau/gists{/gist_id}","starred_url":"https://api.github.com/users/jeylau/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jeylau/subscriptions","organizations_url":"https://api.github.com/users/jeylau/orgs","repos_url":"https://api.github.com/users/jeylau/repos","events_url":"https://api.github.com/users/jeylau/events{/privacy}","received_events_url":"https://api.github.com/users/jeylau/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1693/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1693/timeline","performed_via_github_app":null,"state_reason":"completed"}