{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1050","repository_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut","labels_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1050/labels{/name}","comments_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1050/comments","events_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1050/events","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/1050","id":776906496,"node_id":"MDU6SXNzdWU3NzY5MDY0OTY=","number":1050,"title":"Errors running Testscript.py: ","user":{"login":"Anske","id":8816806,"node_id":"MDQ6VXNlcjg4MTY4MDY=","avatar_url":"https://avatars.githubusercontent.com/u/8816806?v=4","gravatar_id":"","url":"https://api.github.com/users/Anske","html_url":"https://github.com/Anske","followers_url":"https://api.github.com/users/Anske/followers","following_url":"https://api.github.com/users/Anske/following{/other_user}","gists_url":"https://api.github.com/users/Anske/gists{/gist_id}","starred_url":"https://api.github.com/users/Anske/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Anske/subscriptions","organizations_url":"https://api.github.com/users/Anske/orgs","repos_url":"https://api.github.com/users/Anske/repos","events_url":"https://api.github.com/users/Anske/events{/privacy}","received_events_url":"https://api.github.com/users/Anske/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2020-12-31T10:18:02Z","updated_at":"2021-01-04T23:18:48Z","closed_at":"2021-01-04T14:42:00Z","author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\nI ran the testscript.py in the conda dlc-gpu environment (as defined in DLC-GPU.yaml, downloaded as part of the projefct from github). Initially when running the first time, I got the following error:\r\nERROR: Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED\r\n\r\nAs advised in issue #458, to work around this apparent tensorflow issue I added \"os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' \" in the testscript.py on line 24, straight after the existing imports (because I'm pretty sure my tensorflow-cuda-cudnn versions are the right combination).\r\nHowever, I now run into another error when running the testscript.py, right after the 4th training iteration. \r\n\r\nAlso, this error causes the testscript to seemingly run itself over and over again, and it cannot be terminated from the terminal (as it keeps starting over, it keeps trying to create the project anew, and generates the error over and over again that the project folder already exists, duh). \r\n\r\n**Desktop (please complete the following information about your system):**\r\n - OS: Windows10\r\n - DeepLabCut Version 2.1.9 \r\n- python=3.7, tensorflow-gpu==1.13.1, cudatoolkit  10.0.130, cudnn  7.6.5\r\n\r\n\r\n**To Reproduce**\r\n1. conda activate dlc-gpu\r\n2. python testscript.py (from the examples folder).\r\n3. See error:\r\n\r\n<details><summary>\r\nStarting training....\r\niteration: 2 loss: 1.4638 lr: 0.001\r\niteration: 4 loss: 0.7428 lr: 0.001\r\n2020-12-31 10:30:30.966427: W tensorflow/core/kernels/queue_base.cc:277] _0_fifo_queue: Skipping cancelled enqueue attempt with queue not closed\r\nException in thread Thread-2:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\r\n         [[{{node fifo_queue_enqueue}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 91, in load_and_enqueue\r\n    sess.run(enqueue_op, feed_dict=food)\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\r\n         [[node fifo_queue_enqueue (defined at C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77) ]]\r\n\r\nCaused by op 'fifo_queue_enqueue', defined at:\r\n  File \"testscript.py\", line 138, in <module>\r\n    deeplabcut.train_network(path_config_file)\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 189, in train_network\r\n    allow_growth=allow_growth,\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 172, in train\r\n    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 77, in setup_preloading\r\n    enqueue_op = q.enqueue(placeholders_list)\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 345, in enqueue\r\n    self._queue_ref, vals, name=scope)\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 4158, in queue_enqueue_v2\r\n    timeout_ms=timeout_ms, name=name)\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nCancelledError (see above for traceback): Enqueue operation was cancelled\r\n         [[node fifo_queue_enqueue (defined at C:\\Users\\avlui\\anaconda3\\envs\\dlc-gpu\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77) ]]</summary><p>\r\n\r\n```python\r\n\r\n#my modified testscript.py, the only line I added to the original was line 25, to set allow growth to true.\r\n#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n\"\"\"\r\nCreated on Tue Oct  2 13:56:11 2018\r\n@author: alex\r\n\r\nDEVELOPERS:\r\nThis script tests various functionalities in an automatic way.\r\n\r\nIt should take about 3:30 minutes to run this in a CPU.\r\nIt should take about 1:30 minutes on a GPU (incl. downloading the ResNet weights)\r\n\r\nIt produces nothing of interest scientifically.\r\n\"\"\"\r\n\r\ntask = \"TEST\"  # Enter the name of your experiment Task\r\nscorer = \"Alex\"  # Enter the name of the experimenter/labeler\r\n\r\nimport os, subprocess, deeplabcut\r\nfrom pathlib import Path\r\nimport pandas as pd\r\nimport numpy as np\r\nimport platform\r\n\r\nos.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\r\n\r\nprint(\"Imported DLC!\")\r\nbasepath = os.path.dirname(os.path.abspath(\"testscript.py\"))\r\nvideoname = \"reachingvideo1\"\r\nvideo = [\r\n    os.path.join(\r\n        basepath, \"Reaching-Mackenzie-2018-08-30\", \"videos\", videoname + \".avi\"\r\n    )\r\n]\r\n\r\n# For testing a color video:\r\n# videoname='baby4hin2min'\r\n# video=[os.path.join('/home/alex/Desktop/Data',videoname+'.mp4')]\r\n# to test destination folder:\r\n# dfolder=basepath\r\n\r\ndfolder = None\r\nnet_type = \"resnet_50\"  #'mobilenet_v2_0.35' #'resnet_50'\r\naugmenter_type = \"default\"  # = imgaug!!\r\naugmenter_type2 = \"scalecrop\"\r\n\r\nif platform.system() == \"Darwin\" or platform.system() == \"Windows\":\r\n    print(\"On Windows/OSX tensorpack is not tested by default.\")\r\n    augmenter_type3 = \"imgaug\"\r\nelse:\r\n    augmenter_type3 = \"tensorpack\"  # Does not work on WINDOWS\r\n\r\nnumiter = 5\r\n\r\nprint(\"CREATING PROJECT\")\r\npath_config_file = deeplabcut.create_new_project(task, scorer, video, copy_videos=True)\r\n\r\ncfg = deeplabcut.auxiliaryfunctions.read_config(path_config_file)\r\ncfg[\"numframes2pick\"] = 5\r\ncfg[\"pcutoff\"] = 0.01\r\ncfg[\"TrainingFraction\"] = [0.8]\r\ncfg[\"skeleton\"] = [[\"bodypart1\", \"bodypart2\"], [\"bodypart1\", \"bodypart3\"]]\r\n\r\ndeeplabcut.auxiliaryfunctions.write_config(path_config_file, cfg)\r\n\r\nprint(\"EXTRACTING FRAMES\")\r\ndeeplabcut.extract_frames(path_config_file, mode=\"automatic\", userfeedback=False)\r\n\r\nprint(\"CREATING-SOME LABELS FOR THE FRAMES\")\r\nframes = os.listdir(os.path.join(cfg[\"project_path\"], \"labeled-data\", videoname))\r\n# As this next step is manual, we update the labels by putting them on the diagonal (fixed for all frames)\r\nfor index, bodypart in enumerate(cfg[\"bodyparts\"]):\r\n    columnindex = pd.MultiIndex.from_product(\r\n        [[scorer], [bodypart], [\"x\", \"y\"]], names=[\"scorer\", \"bodyparts\", \"coords\"]\r\n    )\r\n    frame = pd.DataFrame(\r\n        100 + np.ones((len(frames), 2)) * 50 * index,\r\n        columns=columnindex,\r\n        index=[os.path.join(\"labeled-data\", videoname, fn) for fn in frames],\r\n    )\r\n    if index == 0:\r\n        dataFrame = frame\r\n    else:\r\n        dataFrame = pd.concat([dataFrame, frame], axis=1)\r\n\r\ndataFrame.to_csv(\r\n    os.path.join(\r\n        cfg[\"project_path\"],\r\n        \"labeled-data\",\r\n        videoname,\r\n        \"CollectedData_\" + scorer + \".csv\",\r\n    )\r\n)\r\ndataFrame.to_hdf(\r\n    os.path.join(\r\n        cfg[\"project_path\"],\r\n        \"labeled-data\",\r\n        videoname,\r\n        \"CollectedData_\" + scorer + \".h5\",\r\n    ),\r\n    \"df_with_missing\",\r\n    format=\"table\",\r\n    mode=\"w\",\r\n)\r\n\r\nprint(\"Plot labels...\")\r\n\r\ndeeplabcut.check_labels(path_config_file)\r\n\r\nprint(\"CREATING TRAININGSET\")\r\ndeeplabcut.create_training_dataset(\r\n    path_config_file, net_type=net_type, augmenter_type=augmenter_type\r\n)\r\n\r\nposefile = os.path.join(\r\n    cfg[\"project_path\"],\r\n    \"dlc-models/iteration-\"\r\n    + str(cfg[\"iteration\"])\r\n    + \"/\"\r\n    + cfg[\"Task\"]\r\n    + cfg[\"date\"]\r\n    + \"-trainset\"\r\n    + str(int(cfg[\"TrainingFraction\"][0] * 100))\r\n    + \"shuffle\"\r\n    + str(1),\r\n    \"train/pose_cfg.yaml\",\r\n)\r\n\r\nDLC_config = deeplabcut.auxiliaryfunctions.read_plainconfig(posefile)\r\nDLC_config[\"save_iters\"] = numiter\r\nDLC_config[\"display_iters\"] = 2\r\nDLC_config[\"multi_step\"] = [[0.001, numiter]]\r\n\r\nprint(\"CHANGING training parameters to end quickly!\")\r\ndeeplabcut.auxiliaryfunctions.write_plainconfig(posefile, DLC_config)\r\n\r\nprint(\"TRAIN\")\r\ndeeplabcut.train_network(path_config_file)\r\n\r\nprint(\"EVALUATE\")\r\ndeeplabcut.evaluate_network(path_config_file, plotting=True)\r\n# deeplabcut.evaluate_network(path_config_file,plotting=True,trainingsetindex=33)\r\nprint(\"CUT SHORT VIDEO AND ANALYZE (with dynamic cropping!)\")\r\n\r\n# Make super short video (so the analysis is quick!)\r\n\r\ntry:  # you need ffmpeg command line interface\r\n    # subprocess.call(['ffmpeg','-i',video[0],'-ss','00:00:00','-to','00:00:00.4','-c','copy',newvideo])\r\n    newvideo = deeplabcut.ShortenVideo(\r\n        video[0],\r\n        start=\"00:00:00\",\r\n        stop=\"00:00:01\",\r\n        outsuffix=\"short\",\r\n        outpath=os.path.join(cfg[\"project_path\"], \"videos\"),\r\n    )\r\nexcept:  # if ffmpeg is broken/missing\r\n    print(\"using alternative method\")\r\n    newvideo = os.path.join(cfg[\"project_path\"], \"videos\", videoname + \"short.mp4\")\r\n    from moviepy.editor import VideoFileClip, VideoClip\r\n\r\n    clip = VideoFileClip(video[0])\r\n    clip.reader.initialize()\r\n\r\n    def make_frame(t):\r\n        return clip.get_frame(1)\r\n\r\n    newclip = VideoClip(make_frame, duration=1)\r\n    newclip.write_videofile(newvideo, fps=30)\r\n\r\nvname = Path(newvideo).stem\r\n\r\ndeeplabcut.analyze_videos(\r\n    path_config_file,\r\n    [newvideo],\r\n    save_as_csv=True,\r\n    destfolder=dfolder,\r\n    dynamic=(True, 0.1, 5),\r\n)\r\n\r\nprint(\"analyze again...\")\r\ndeeplabcut.analyze_videos(\r\n    path_config_file, [newvideo], save_as_csv=True, destfolder=dfolder\r\n)\r\n\r\nprint(\"CREATE VIDEO\")\r\ndeeplabcut.create_labeled_video(\r\n    path_config_file, [newvideo], destfolder=dfolder, save_frames=True\r\n)\r\n\r\nprint(\"Making plots\")\r\ndeeplabcut.plot_trajectories(path_config_file, [newvideo], destfolder=dfolder)\r\n\r\nprint(\"EXTRACT OUTLIERS\")\r\ndeeplabcut.extract_outlier_frames(\r\n    path_config_file,\r\n    [newvideo],\r\n    outlieralgorithm=\"jump\",\r\n    epsilon=0,\r\n    automatic=True,\r\n    destfolder=dfolder,\r\n)\r\n\r\ndeeplabcut.extract_outlier_frames(\r\n    path_config_file,\r\n    [newvideo],\r\n    outlieralgorithm=\"fitting\",\r\n    automatic=True,\r\n    destfolder=dfolder,\r\n)\r\n\r\nfile = os.path.join(\r\n    cfg[\"project_path\"],\r\n    \"labeled-data\",\r\n    vname,\r\n    \"machinelabels-iter\" + str(cfg[\"iteration\"]) + \".h5\",\r\n)\r\n\r\nprint(\"RELABELING\")\r\nDF = pd.read_hdf(file, \"df_with_missing\")\r\nDLCscorer = np.unique(DF.columns.get_level_values(0))[0]\r\nDF.columns.set_levels([scorer.replace(DLCscorer, scorer)], level=0, inplace=True)\r\nDF = DF.drop(\"likelihood\", axis=1, level=2)\r\nDF.to_csv(\r\n    os.path.join(\r\n        cfg[\"project_path\"], \"labeled-data\", vname, \"CollectedData_\" + scorer + \".csv\"\r\n    )\r\n)\r\nDF.to_hdf(\r\n    os.path.join(\r\n        cfg[\"project_path\"], \"labeled-data\", vname, \"CollectedData_\" + scorer + \".h5\"\r\n    ),\r\n    \"df_with_missing\",\r\n    format=\"table\",\r\n    mode=\"w\",\r\n)\r\n\r\nprint(\"MERGING\")\r\ndeeplabcut.merge_datasets(path_config_file)  # iteration + 1\r\n\r\nprint(\"CREATING TRAININGSET\")\r\ndeeplabcut.create_training_dataset(\r\n    path_config_file, net_type=net_type, augmenter_type=augmenter_type2\r\n)\r\n\r\ncfg = deeplabcut.auxiliaryfunctions.read_config(path_config_file)\r\nposefile = os.path.join(\r\n    cfg[\"project_path\"],\r\n    \"dlc-models/iteration-\"\r\n    + str(cfg[\"iteration\"])\r\n    + \"/\"\r\n    + cfg[\"Task\"]\r\n    + cfg[\"date\"]\r\n    + \"-trainset\"\r\n    + str(int(cfg[\"TrainingFraction\"][0] * 100))\r\n    + \"shuffle\"\r\n    + str(1),\r\n    \"train/pose_cfg.yaml\",\r\n)\r\nDLC_config = deeplabcut.auxiliaryfunctions.read_plainconfig(posefile)\r\nDLC_config[\"save_iters\"] = numiter\r\nDLC_config[\"display_iters\"] = 1\r\nDLC_config[\"multi_step\"] = [[0.001, numiter]]\r\n\r\nprint(\"CHANGING training parameters to end quickly!\")\r\ndeeplabcut.auxiliaryfunctions.write_config(posefile, DLC_config)\r\n\r\nprint(\"TRAIN\")\r\ndeeplabcut.train_network(path_config_file)\r\n\r\ntry:  # you need ffmpeg command line interface\r\n    # subprocess.call(['ffmpeg','-i',video[0],'-ss','00:00:00','-to','00:00:00.4','-c','copy',newvideo])\r\n    newvideo2 = deeplabcut.ShortenVideo(\r\n        video[0],\r\n        start=\"00:00:00\",\r\n        stop=\"00:00:01\",\r\n        outsuffix=\"short2\",\r\n        outpath=os.path.join(cfg[\"project_path\"], \"videos\"),\r\n    )\r\n\r\nexcept:  # if ffmpeg is broken\r\n    newvideo2 = os.path.join(cfg[\"project_path\"], \"videos\", videoname + \"short2.mp4\")\r\n    from moviepy.editor import VideoFileClip, VideoClip\r\n\r\n    clip = VideoFileClip(video[0])\r\n    clip.reader.initialize()\r\n\r\n    def make_frame(t):\r\n        return clip.get_frame(1)\r\n\r\n    newclip = VideoClip(make_frame, duration=1)\r\n    newclip.write_videofile(newvideo2, fps=30)\r\n\r\nvname = Path(newvideo2).stem\r\n\r\nprint(\"Inference with direct cropping\")\r\ndeeplabcut.analyze_videos(\r\n    path_config_file,\r\n    [newvideo2],\r\n    save_as_csv=True,\r\n    destfolder=dfolder,\r\n    cropping=[0, 50, 0, 50],\r\n)\r\n\r\nprint(\"Extracting skeleton distances, filter and plot filtered output\")\r\ndeeplabcut.analyzeskeleton(\r\n    path_config_file, [newvideo2], save_as_csv=True, destfolder=dfolder\r\n)\r\ndeeplabcut.filterpredictions(path_config_file, [newvideo2])\r\n\r\n# deeplabcut.create_labeled_video(path_config_file,[newvideo], destfolder=dfolder,filtered=True)\r\ndeeplabcut.create_labeled_video(\r\n    path_config_file,\r\n    [newvideo2],\r\n    destfolder=dfolder,\r\n    displaycropped=True,\r\n    filtered=True,\r\n)\r\n\r\nprint(\"Creating a Johansson video!\")\r\ndeeplabcut.create_labeled_video(\r\n    path_config_file, [newvideo], destfolder=dfolder, keypoints_only=True\r\n)\r\n\r\ndeeplabcut.plot_trajectories(\r\n    path_config_file, [newvideo2], destfolder=dfolder, filtered=True\r\n)\r\n\r\nprint(\"ALL DONE!!! - default cases without Tensorpack loader are functional.\")\r\n\r\nprint(\"CREATING TRAININGSET for shuffle 2\")\r\nprint(\"will be used for 3D testscript...\")\r\n# TENSORPACK could fail in WINDOWS...\r\ndeeplabcut.create_training_dataset(\r\n    path_config_file, Shuffles=[2], net_type=net_type, augmenter_type=augmenter_type3\r\n)\r\n\r\nposefile = os.path.join(\r\n    cfg[\"project_path\"],\r\n    \"dlc-models/iteration-\"\r\n    + str(cfg[\"iteration\"])\r\n    + \"/\"\r\n    + cfg[\"Task\"]\r\n    + cfg[\"date\"]\r\n    + \"-trainset\"\r\n    + str(int(cfg[\"TrainingFraction\"][0] * 100))\r\n    + \"shuffle\"\r\n    + str(2),\r\n    \"train/pose_cfg.yaml\",\r\n)\r\n\r\nDLC_config = deeplabcut.auxiliaryfunctions.read_plainconfig(posefile)\r\nDLC_config[\"save_iters\"] = 10\r\nDLC_config[\"display_iters\"] = 2\r\nDLC_config[\"multi_step\"] = [[0.001, 10]]\r\n\r\nprint(\"CHANGING training parameters to end quickly!\")\r\ndeeplabcut.auxiliaryfunctions.write_plainconfig(posefile, DLC_config)\r\n\r\nprint(\"TRAINING shuffle 2, with smaller allocated memory\")\r\ndeeplabcut.train_network(path_config_file, shuffle=2, allow_growth=True)\r\n\r\nprint(\"ANALYZING some individual frames\")\r\ndeeplabcut.analyze_time_lapse_frames(\r\n    path_config_file, os.path.join(cfg[\"project_path\"], \"labeled-data/reachingvideo1/\")\r\n)\r\n\r\nprint(\"Export model...\")\r\ndeeplabcut.export_model(path_config_file, shuffle=2, make_tar=False)\r\n\r\n\r\ntrainIndices, testIndices = deeplabcut.mergeandsplit(\r\n    path_config_file, trainindex=0, uniform=True\r\n)\r\n\r\ndeeplabcut.create_training_dataset(\r\n    path_config_file,\r\n    Shuffles=[4, 5],\r\n    trainIndices=[trainIndices, trainIndices],\r\n    testIndices=[testIndices, testIndices],\r\n)\r\n\r\nprint(\"ALL DONE!!! - default cases are functional.\")\r\nprint(\"Re-import DLC with env. variable set to test DLC light mode.\")\r\nos.environ[\"DLClight\"] = \"True\"\r\nsubprocess.call([\"python3\", \"-c\", \"import deeplabcut\"])\r\n\r\n\r\n```\r\n</p></details>\r\n\r\n\r\n**Expected behavior**\r\nTestscript running without errors, and not running itself over and over again.\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\n\r\n","closed_by":{"login":"jeylau","id":30733203,"node_id":"MDQ6VXNlcjMwNzMzMjAz","avatar_url":"https://avatars.githubusercontent.com/u/30733203?v=4","gravatar_id":"","url":"https://api.github.com/users/jeylau","html_url":"https://github.com/jeylau","followers_url":"https://api.github.com/users/jeylau/followers","following_url":"https://api.github.com/users/jeylau/following{/other_user}","gists_url":"https://api.github.com/users/jeylau/gists{/gist_id}","starred_url":"https://api.github.com/users/jeylau/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jeylau/subscriptions","organizations_url":"https://api.github.com/users/jeylau/orgs","repos_url":"https://api.github.com/users/jeylau/repos","events_url":"https://api.github.com/users/jeylau/events{/privacy}","received_events_url":"https://api.github.com/users/jeylau/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1050/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1050/timeline","performed_via_github_app":null,"state_reason":"completed"}