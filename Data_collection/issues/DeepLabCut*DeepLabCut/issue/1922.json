{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1922","repository_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut","labels_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1922/labels{/name}","comments_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1922/comments","events_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1922/events","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/1922","id":1317506423,"node_id":"I_kwDOB5BM6c5Oh413","number":1922,"title":"Skeleton not being drawn after analysis","user":{"login":"Zachary-Ip","id":47134386,"node_id":"MDQ6VXNlcjQ3MTM0Mzg2","avatar_url":"https://avatars.githubusercontent.com/u/47134386?v=4","gravatar_id":"","url":"https://api.github.com/users/Zachary-Ip","html_url":"https://github.com/Zachary-Ip","followers_url":"https://api.github.com/users/Zachary-Ip/followers","following_url":"https://api.github.com/users/Zachary-Ip/following{/other_user}","gists_url":"https://api.github.com/users/Zachary-Ip/gists{/gist_id}","starred_url":"https://api.github.com/users/Zachary-Ip/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Zachary-Ip/subscriptions","organizations_url":"https://api.github.com/users/Zachary-Ip/orgs","repos_url":"https://api.github.com/users/Zachary-Ip/repos","events_url":"https://api.github.com/users/Zachary-Ip/events{/privacy}","received_events_url":"https://api.github.com/users/Zachary-Ip/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":{"login":"jeylau","id":30733203,"node_id":"MDQ6VXNlcjMwNzMzMjAz","avatar_url":"https://avatars.githubusercontent.com/u/30733203?v=4","gravatar_id":"","url":"https://api.github.com/users/jeylau","html_url":"https://github.com/jeylau","followers_url":"https://api.github.com/users/jeylau/followers","following_url":"https://api.github.com/users/jeylau/following{/other_user}","gists_url":"https://api.github.com/users/jeylau/gists{/gist_id}","starred_url":"https://api.github.com/users/jeylau/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jeylau/subscriptions","organizations_url":"https://api.github.com/users/jeylau/orgs","repos_url":"https://api.github.com/users/jeylau/repos","events_url":"https://api.github.com/users/jeylau/events{/privacy}","received_events_url":"https://api.github.com/users/jeylau/received_events","type":"User","site_admin":false},"assignees":[{"login":"jeylau","id":30733203,"node_id":"MDQ6VXNlcjMwNzMzMjAz","avatar_url":"https://avatars.githubusercontent.com/u/30733203?v=4","gravatar_id":"","url":"https://api.github.com/users/jeylau","html_url":"https://github.com/jeylau","followers_url":"https://api.github.com/users/jeylau/followers","following_url":"https://api.github.com/users/jeylau/following{/other_user}","gists_url":"https://api.github.com/users/jeylau/gists{/gist_id}","starred_url":"https://api.github.com/users/jeylau/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jeylau/subscriptions","organizations_url":"https://api.github.com/users/jeylau/orgs","repos_url":"https://api.github.com/users/jeylau/repos","events_url":"https://api.github.com/users/jeylau/events{/privacy}","received_events_url":"https://api.github.com/users/jeylau/received_events","type":"User","site_admin":false}],"milestone":null,"comments":6,"created_at":"2022-07-25T23:47:37Z","updated_at":"2022-08-08T12:29:44Z","closed_at":"2022-08-08T12:29:44Z","author_association":"NONE","active_lock_reason":null,"body":"### Is there an existing issue for this?\n\n- [X] I have searched the existing issues\n\n### Bug description\n\nWhen I initially train a model, everything works as expected: I get skeletons drawn over my video. However, sometimes, if the model is not as accurate as I would like, I go to continue training. After training a second time, when I go to create a video that has been analyzed, it no longer draws the skeleton in the create labeled video function. I have made sure to check the \"include skeleton\" box in the create video GUI page.\r\n\r\nWhen I analyze new videos, I do get pose estimate files, though I suspect it may be an issue of low confidence? I am not sure why that would be when the model had achieved confidence previously during training. \n\n### Operating System\n\nRed Hat Enterprise Linux 8.4 (Ootpa)\r\n\n\n### DeepLabCut version\n\ndlc version 2.2.1.1\n\n### DeepLabCut mode\n\nsingle animal\n\n### Device type\n\ngpu: Tesla M10\r\nCUDA Version: 11.5\n\n### Steps To Reproduce\n\n1. Go back to train page, select \"click to open the pose config file\"\r\n2. Edit the init weights from downloaded model (in this case efficientnet-b0), and change to /project-folder/dlc-models/iteration-0/Aproject-folderDate-trainset95shuffle1/train/snapshot-#\r\n3. Save and close\r\n4. Update Maximum iterations and save parameters\r\n5. Execute training.\r\n6. Analyze video (new or old, doesn't matter)\r\n7. Create video -> include skeleton in video\r\n\r\n* Note that it is inconsistent, only some models fail, some can successfully continue training. \n\n### Relevant log output\n\n```shell\niteration: 61000 loss: 0.0533 lr: 0.0005983894225209951                                                                                                                                                  [176/1555]\r\n2022-07-25 10:05:46.910031: W tensorflow/core/kernels/queue_base.cc:277] _3_fifo_queue: Skipping cancelled enqueue attempt with queue not closed                                                                  \r\nException in thread Thread-17:\r\nTraceback (most recent call last):\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1377, in _do_call                                                                             \r\n    return fn(*args)\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn                                                                              \r\n    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun                                                                  \r\n    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\r\ntensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\r\n         [[{{node fifo_queue_enqueue}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\n    self.run()\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 83, in load_and_enqueue                                                       \r\n    sess.run(enqueue_op, feed_dict=food)\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 967, in run                                                                                   \r\n    result = self._run(None, fetches, feed_dict, options_ptr,\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1190, in _run                                                                                 \r\n    results = self._do_run(handle, final_targets, final_fetches,\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1370, in _do_run                                                                              \r\n    return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1396, in _do_call                                                                             \r\n    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\r\ntensorflow.python.framework.errors_impl.CancelledError: Graph execution error:\r\nDetected at node 'fifo_queue_enqueue' defined at (most recent call last):                                                                                                                                [144/1555]\r\n    File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\r\n      return _run_code(code, main_globals, None,\r\n    File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/runpy.py\", line 87, in _run_code\r\n      exec(code, run_globals)\r\n    File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/__main__.py\", line 22, in <module>\r\n      deeplabcut.launch_dlc()\r\n    File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/gui/launch_script.py\", line 50, in launch_dlc\r\n      app.MainLoop()\r\n    File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/wx/core.py\", line 2237, in MainLoop\r\n      rv = wx.PyApp.MainLoop(self)\r\n    File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/gui/label_frames.py\", line 232, in label_frames\r\n      label_frames(self.config)\r\n    File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/gui/label_frames.py\", line 101, in label_frames\r\n      labeling_toolbox.show(config, config3d, sourceCam, imtypes, jump_unlabeled)\r\n    File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/gui/labeling_toolbox.py\", line 971, in show\r\n      app.MainLoop()\r\n    File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/wx/core.py\", line 2237, in MainLoop\r\n      rv = wx.PyApp.MainLoop(self)\r\n    File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/gui/train_network.py\", line 315, in train_network\r\n      deeplabcut.train_network(\r\n    File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\", line 207, in train_network\r\n      train(\r\n    File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 168, in train\r\n      batch, enqueue_op, placeholders = setup_preloading(batch_spec)\r\n    File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 69, in setup_preloading\r\n      enqueue_op = q.enqueue(placeholders_list)\r\nNode: 'fifo_queue_enqueue'\r\nEnqueue operation was cancelled\r\n         [[{{node fifo_queue_enqueue}}]]\r\n\r\n\r\nOriginal stack trace for 'fifo_queue_enqueue':\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/__main__.py\", line 22, in <module>\r\n    deeplabcut.launch_dlc()\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/gui/launch_script.py\", line 50, in launch_dlc\r\n    app.MainLoop()\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/wx/core.py\", line 2237, in MainLoop\r\n    rv = wx.PyApp.MainLoop(self)\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/gui/label_frames.py\", line 232, in label_frames\r\n    label_frames(self.config)\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/gui/label_frames.py\", line 101, in label_frames\r\n    labeling_toolbox.show(config, config3d, sourceCam, imtypes, jump_unlabeled)\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/gui/labeling_toolbox.py\", line 971, in show\r\n    app.MainLoop()\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/wx/core.py\", line 2237, in MainLoop\r\n    rv = wx.PyApp.MainLoop(self)\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/gui/train_network.py\", line 315, in train_network\r\n    deeplabcut.train_network(\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\", line 207, in train_network\r\n    train(\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 168, in train\r\n    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 69, in setup_preloading\r\n    enqueue_op = q.enqueue(placeholders_list)\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 346, in enqueue\r\n    return gen_data_flow_ops.queue_enqueue_v2(\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 4063, in queue_enqueue_v2\r\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 797, in _apply_op_helper\r\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3754, in _create_op_internal\r\n    ret = Operation(\r\n  File \"/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 2133, in __init__\r\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\r\n                                                                                                                                                                                                                \r\nThe network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.                                                                                                     \r\nConfig:                                                                                                                                                                                                            \r\n{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\r\n 'all_joints_names': ['nose',\r\n                      'R_ear',\r\n                      'L_ear',\r\n                      'center',\r\n                      'base_tail',\r\n                      'tail_tip',\r\n                      'L_object',\r\n                      'R_object'],\r\n 'batch_size': 1,\r\n 'crop_pad': 0,\r\n 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ARTE-NORJul12/ARTE-NOR_Zach95shuffle1.mat',\r\n 'dataset_type': 'imgaug',\r\n 'deterministic': False,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': '/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/efficientnet-b0/model.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 1.0,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'mirror': False,\r\n 'net_type': 'efficientnet-b0',\r\n 'num_joints': 8,\r\n 'optimizer': 'sgd',\r\n 'pairwise_huber_loss': True,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_predict': False,\r\n 'regularize': False,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': '/ariel/data2/zip/ARTE-NOR-Zach-2022-07-12/dlc-models/iteration-0/ARTE-NORJul12-trainset95shuffle1/test/snapshot',\r\n 'stride': 8.0,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\n                                                                                                                                                                                          \r\nUsing snapshot-61000 for model /ariel/data2/zip/ARTE-NOR-Zach-2022-07-12/dlc-models/iteration-0/ARTE-NORJul12-trainset95shuffle1                                                                                   \r\n2022-07-25 11:49:42.096302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7323 MB memory:  -> device: 0, name: Tesla M10, pci bus id: 0\r\n000:28:00.0, compute capability: 5.0                                                                                                                                                                               \r\nStarting to analyze %  /ariel/data2/zip/ARTE-NOR-Zach-2022-07-12/videos/2022-06-29-16-52-16_video_e3v82a4-20220629T165219-170322.avi\r\nLoading  /ariel/data2/zip/ARTE-NOR-Zach-2022-07-12/videos/2022-06-29-16-52-16_video_e3v82a4-20220629T165219-170322.avi\r\nDuration of video [s]:  663.05 , recorded with  20.0 fps!\r\nOverall # of frames:  13261  found with (before cropping) frame dimensions:  1600 1200\r\nStarting to extract posture\r\n  1%|??                                                     | 132/13261 [00:54<1:30:04,  2.43it/s]100%|????????????????????????????????????????????????????????????????????????????????????????????????????????| 13200/13261 [1:33:17<00:25,  2.36it/s]\r\nSaving results in /ariel/data2/zip/ARTE-NOR-Zach-2022-07-12/videos...\r\nThe videos are analyzed. Now your research can truly start!\r\n You can create labeled videos with 'create_labeled_video'\r\nIf the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\r\nStarting to process video: /ariel/data2/zip/ARTE-NOR-Zach-2022-07-12/videos/2022-06-29-16-52-16_video_e3v82a4-20220629T165219-170322.avi\r\nLoading /ariel/data2/zip/ARTE-NOR-Zach-2022-07-12/videos/2022-06-29-16-52-16_video_e3v82a4-20220629T165219-170322.avi and data.\r\nDuration of video [s]: 663.05, recorded with 20.0 fps!\r\nOverall # of frames: 13261 with cropped frame dimensions: 1600 1200\r\nGenerating frames and creating video.\r\n100%|????????????????????????????????????????????????????????????????????????????????????????????????????????????| 13261/13261 [03:26<00:00, 64.27it/s]\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\r\n 'all_joints_names': ['nose',\r\n                      'R_ear',\r\n                      'L_ear',\r\n                      'center',\r\n                      'base_tail',\r\n                      'tail_tip',\r\n                      'L_object',\r\n                      'R_object'],\r\n'batch_size': 1,\r\n 'crop_pad': 0,\r\n 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ARTE-NORJul12/ARTE-NOR_Zach95shuffle1.mat',\r\n 'dataset_type': 'imgaug',\r\n 'deterministic': False,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': '/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/efficientnet-b0/model.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 1.0,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'mirror': False,\r\n 'net_type': 'efficientnet-b0',\r\n 'num_joints': 8,\r\n 'optimizer': 'sgd',\r\n 'pairwise_huber_loss': True,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_predict': False,\r\n 'regularize': False,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': '/ariel/data2/zip/ARTE-NOR-Zach-2022-07-12/dlc-models/iteration-0/ARTE-NORJul12-trainset95shuffle1/test/snapshot',\r\n 'stride': 8.0,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nUsing snapshot-61000 for model /ariel/data2/zip/ARTE-NOR-Zach-2022-07-12/dlc-models/iteration-0/ARTE-NORJul12-trainset95shuffle1\r\n/home/zip/miniconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use\r\n `layer.__call__` method instead.\r\n  warnings.warn('`layer.apply` is deprecated and '\r\n2022-07-25 14:13:49.920290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7323 MB memory:  -> device: 0, name: Tesla M10, pci bus id: 0\r\n000:28:00.0, compute capability: 5.0\r\nStarting to analyze %  /ariel/data2/zip/ARTE-NOR-Zach-2022-07-12/videos/2022-06-29-14-14-48_video_e3v82a4-20220629T141452-142455.avi\r\nLoading  /ariel/data2/zip/ARTE-NOR-Zach-2022-07-12/videos/2022-06-29-14-14-48_video_e3v82a4-20220629T141452-142455.avi\r\nDuration of video [s]:  603.0 , recorded with  20.0 fps!\r\nOverall # of frames:  12060  found with (before cropping) frame dimensions:  1600 1200\r\nStarting to extract posture\r\n100%|????????????????????????????????????????????????????????????????????????????????????????????????????????| 12000/12060 [1:16:29<00:22,  2.61it/s]\r\nSaving results in /ariel/data2/zip/ARTE-NOR-Zach-2022-07-12/videos...\r\nSaving csv poses!\r\nThe videos are analyzed. Now your research can truly start!\r\n You can create labeled videos with 'create_labeled_video'\r\nIf the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\r\nStarting to process video: /ariel/data2/zip/ARTE-NOR-Zach-2022-07-12/videos/2022-06-29-14-14-48_video_e3v82a4-20220629T141452-142455.avi\r\nLoading /ariel/data2/zip/ARTE-NOR-Zach-2022-07-12/videos/2022-06-29-14-14-48_video_e3v82a4-20220629T141452-142455.avi and data.\r\nDuration of video [s]: 603.0, recorded with 20.0 fps!\r\nOverall # of frames: 12060 with cropped frame dimensions: 1600 1200\r\nGenerating frames and creating video.\r\n100%|????????????????????????????????????????????????????????????????????????????????????????????????????????????| 12060/12060 [03:03<00:00, 65.61it/s]\n```\n\n\n### Anything else?\n\n_No response_\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/DeepLabCut/DeepLabCut/blob/master/CODE_OF_CONDUCT.md)","closed_by":{"login":"MMathisLab","id":28102185,"node_id":"MDQ6VXNlcjI4MTAyMTg1","avatar_url":"https://avatars.githubusercontent.com/u/28102185?v=4","gravatar_id":"","url":"https://api.github.com/users/MMathisLab","html_url":"https://github.com/MMathisLab","followers_url":"https://api.github.com/users/MMathisLab/followers","following_url":"https://api.github.com/users/MMathisLab/following{/other_user}","gists_url":"https://api.github.com/users/MMathisLab/gists{/gist_id}","starred_url":"https://api.github.com/users/MMathisLab/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MMathisLab/subscriptions","organizations_url":"https://api.github.com/users/MMathisLab/orgs","repos_url":"https://api.github.com/users/MMathisLab/repos","events_url":"https://api.github.com/users/MMathisLab/events{/privacy}","received_events_url":"https://api.github.com/users/MMathisLab/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1922/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1922/timeline","performed_via_github_app":null,"state_reason":"completed"}