{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/753","repository_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut","labels_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/753/labels{/name}","comments_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/753/comments","events_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/753/events","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/753","id":639859555,"node_id":"MDU6SXNzdWU2Mzk4NTk1NTU=","number":753,"title":"pickle file not saved to dlc_models subfolder","user":{"login":"neurologic","id":4777333,"node_id":"MDQ6VXNlcjQ3NzczMzM=","avatar_url":"https://avatars.githubusercontent.com/u/4777333?v=4","gravatar_id":"","url":"https://api.github.com/users/neurologic","html_url":"https://github.com/neurologic","followers_url":"https://api.github.com/users/neurologic/followers","following_url":"https://api.github.com/users/neurologic/following{/other_user}","gists_url":"https://api.github.com/users/neurologic/gists{/gist_id}","starred_url":"https://api.github.com/users/neurologic/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/neurologic/subscriptions","organizations_url":"https://api.github.com/users/neurologic/orgs","repos_url":"https://api.github.com/users/neurologic/repos","events_url":"https://api.github.com/users/neurologic/events{/privacy}","received_events_url":"https://api.github.com/users/neurologic/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":{"login":"AlexEMG","id":20850270,"node_id":"MDQ6VXNlcjIwODUwMjcw","avatar_url":"https://avatars.githubusercontent.com/u/20850270?v=4","gravatar_id":"","url":"https://api.github.com/users/AlexEMG","html_url":"https://github.com/AlexEMG","followers_url":"https://api.github.com/users/AlexEMG/followers","following_url":"https://api.github.com/users/AlexEMG/following{/other_user}","gists_url":"https://api.github.com/users/AlexEMG/gists{/gist_id}","starred_url":"https://api.github.com/users/AlexEMG/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AlexEMG/subscriptions","organizations_url":"https://api.github.com/users/AlexEMG/orgs","repos_url":"https://api.github.com/users/AlexEMG/repos","events_url":"https://api.github.com/users/AlexEMG/events{/privacy}","received_events_url":"https://api.github.com/users/AlexEMG/received_events","type":"User","site_admin":false},"assignees":[{"login":"AlexEMG","id":20850270,"node_id":"MDQ6VXNlcjIwODUwMjcw","avatar_url":"https://avatars.githubusercontent.com/u/20850270?v=4","gravatar_id":"","url":"https://api.github.com/users/AlexEMG","html_url":"https://github.com/AlexEMG","followers_url":"https://api.github.com/users/AlexEMG/followers","following_url":"https://api.github.com/users/AlexEMG/following{/other_user}","gists_url":"https://api.github.com/users/AlexEMG/gists{/gist_id}","starred_url":"https://api.github.com/users/AlexEMG/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AlexEMG/subscriptions","organizations_url":"https://api.github.com/users/AlexEMG/orgs","repos_url":"https://api.github.com/users/AlexEMG/repos","events_url":"https://api.github.com/users/AlexEMG/events{/privacy}","received_events_url":"https://api.github.com/users/AlexEMG/received_events","type":"User","site_admin":false},{"login":"jeylau","id":30733203,"node_id":"MDQ6VXNlcjMwNzMzMjAz","avatar_url":"https://avatars.githubusercontent.com/u/30733203?v=4","gravatar_id":"","url":"https://api.github.com/users/jeylau","html_url":"https://github.com/jeylau","followers_url":"https://api.github.com/users/jeylau/followers","following_url":"https://api.github.com/users/jeylau/following{/other_user}","gists_url":"https://api.github.com/users/jeylau/gists{/gist_id}","starred_url":"https://api.github.com/users/jeylau/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jeylau/subscriptions","organizations_url":"https://api.github.com/users/jeylau/orgs","repos_url":"https://api.github.com/users/jeylau/repos","events_url":"https://api.github.com/users/jeylau/events{/privacy}","received_events_url":"https://api.github.com/users/jeylau/received_events","type":"User","site_admin":false}],"milestone":null,"comments":20,"created_at":"2020-06-16T17:51:53Z","updated_at":"2020-07-08T20:41:13Z","closed_at":"2020-07-08T18:49:26Z","author_association":"NONE","active_lock_reason":null,"body":"**Your Operating system and DeepLabCut version**\r\nMacOS with Anaconda Env DLC-CPU created from deeplabcut's env file\r\nDeepLabCut version 2.2b6\r\n\r\n**Describe the problem**\r\nI have successfully created a project, labelled frames, checked frames, and trained the dataset. \r\nI am working from within pythonw for the following steps.\r\n\r\nBefore training the dataset I ran:\r\n\r\n```python\r\ndeeplabcut.cropimagesandlabels(config_path)\r\n```\r\n\r\nTo train the dataset I ran:\r\n\r\n```python\r\n[deeplabcut.create_multianimaltraining_dataset(config_path)]\r\n```\r\n\r\nThere were some errors, but an alternate path was taken?\r\n<details><summary>Code output</summary><p>\r\n\r\n```python\r\n[/Users/kperks/Documents/Wesleyan_Research/DLC_data/GroupFish/GroupFish-KPerks-2020-06-15/labeled-data/GroupFish1_dnsampled_cropped_cropped/CollectedData_KPerks.h5  not found (perhaps not annotated). If training on cropped data, make sure to call `cropimagesandlabels` prior to creating the dataset.\r\n/Users/kperks/Documents/Wesleyan_Research/DLC_data/GroupFish/GroupFish-KPerks-2020-06-15/labeled-data/GroupFish4_compressed_cropped_cropped/CollectedData_KPerks.h5  not found (perhaps not annotated). If training on cropped data, make sure to call `cropimagesandlabels` prior to creating the dataset.\r\n/Users/kperks/Documents/Wesleyan_Research/DLC_data/GroupFish/GroupFish-KPerks-2020-06-15/labeled-data/GroupFish3_compressed_cropped_cropped/CollectedData_KPerks.h5  not found (perhaps not annotated). If training on cropped data, make sure to call `cropimagesandlabels` prior to creating the dataset.\r\n/Users/kperks/Documents/Wesleyan_Research/DLC_data/GroupFish/GroupFish-KPerks-2020-06-15/labeled-data/GroupFish2_compressed_cropped_cropped/CollectedData_KPerks.h5  not found (perhaps not annotated). If training on cropped data, make sure to call `cropimagesandlabels` prior to creating the dataset.\r\nAnnotation data was not found by splitting video paths (from config['video_sets']). An alternative route is taken...\r\nThe following folders were found: ['/Users/kperks/Documents/Wesleyan_Research/DLC_data/GroupFish/GroupFish-KPerks-2020-06-15/labeled-data/GroupFish3_compressed_cropped', '/Users/kperks/Documents/Wesleyan_Research/DLC_data/GroupFish/GroupFish-KPerks-2020-06-15/labeled-data/GroupFish1_dnsampled_cropped', '/Users/kperks/Documents/Wesleyan_Research/DLC_data/GroupFish/GroupFish-KPerks-2020-06-15/labeled-data/GroupFish4_compressed_cropped', '/Users/kperks/Documents/Wesleyan_Research/DLC_data/GroupFish/GroupFish-KPerks-2020-06-15/labeled-data/GroupFish2_compressed_cropped']\r\nUtilizing the following graph: [[0, 1], [1, 2], [1, 3], [1, 4], [2, 4], [2, 3], [0, 4], [0, 3], [3, 4], [0, 2]]\r\nCreating training data for  1 0.95]\r\n```\r\n</p></details>\r\n\r\nThen to train the network (this is a multi-animal project so I reduced save and max iters).\r\n\r\n```python\r\n[deeplabcut.train_network(config_path,saveiters=10000,maxiters=50000)]\r\n```\r\n\r\nHowever, when I went to train the network I got an error about the pickle file not existing.\r\nAlthough dlc-models/iteration-0/[project_name][date]trainset95shuffle1/train was created, and there is a pose_cfg.yaml file in it, there is no pickle file here.\r\nI DO see a pickle file in the iteration-0 subfolder created under training-datasets:\r\n     training-datasets/iteration-0/UnaugmentedData[etc]/GroupFish_KPerks95shuffle1.pickle\r\nIn addition, there are 3 other files in UnaugmentedDatea[etc]: CollectedData_KPerks.csv, CollectedData_KPerks.h5, Documentation_data-GroupFish_95shuffle1.pickle.\r\n\r\nSpecifically, the error from the train_network command is this:\r\n<details><summary>Code input</summary><p>\r\n\r\n```python\r\n[Activating limb prediction...\r\nStarting with multi-animal imaug + adam pose-dataset loader.\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\", line 193, in train_network\r\n    raise e\r\n  File \"/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\", line 176, in train_network\r\n    allow_growth=allow_growth,\r\n  File \"/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/train_multianimal.py\", line 137, in train\r\n    dataset = create_dataset(cfg)\r\n  File \"/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/dataset/factory.py\", line 56, in create\r\n    data = MAPoseDataset(cfg)\r\n  File \"/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/dataset/pose_multianimal_imgaug.py\", line 34, in __init__\r\n    self.data = self.load_dataset()\r\n  File \"/anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/dataset/pose_multianimal_imgaug.py\", line 42, in load_dataset\r\n    with open(os.path.join(self.cfg.project_path, file_name), \"rb\") as f:\r\nFileNotFoundError: [Errno 2] No such file or directory: 'training-datasets/iteration-0/UnaugmentedDataSet_GroupFishJun15/GroupFish_KPerks95shuffle1.pickle']\r\n```\r\n</p></details>\r\n\r\nI copied the 4 files from training-datasets/iteration-0/UnaugmentedData[etc]/ to dlc-models/iteration-0/[project_name][date]trainset95shuffle1/train/ and tried to train again:\r\n<details><summary>Code input</summary><p>\r\n[deeplabcut.train_network(config_path,saveiters=10000,maxiters=50000)]\r\n</p></details>\r\n\r\nThe output got to the stage of \"Starting multi-animal training\" but needing to copy and paste those files seems like something that should not need to happen. \r\nIs there something that I am missing or misplacing that is preventing the file structure from being generated correctly?\r\n\r\nThank you for your help!\r\n\r\n-Krista Perks\r\n(working on tracking multiple weakly electric fish for studying electrocommunication behavior)\r\n\r\n\r\nIf it is helpful, here is the pose_cfg.yaml that was created and did end up automatically in the dlc-models///train subdirectory:\r\n<details><summary>pose_cfg.yaml</summary><p>\r\n\r\n```python\r\n[all_joints:\r\n- - 0\r\n- - 1\r\n- - 2\r\n- - 3\r\n- - 4\r\nall_joints_names:\r\n- head\r\n- finL\r\n- finR\r\n- tail_attach\r\n- tail_tip\r\nbatch_size: 8\r\nbottomheight: 400\r\ncrop: true\r\ncropratio: 0.4\r\ndataset: training-datasets/iteration-0/UnaugmentedDataSet_GroupFishJun15/GroupFish_KPerks95shuffle1.pickle\r\ndataset_type: multi-animal-imgaug\r\ndisplay_iters: 500\r\nglobal_scale: 0.8\r\ninit_weights: /anaconda3/envs/DLC-CPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt\r\nintermediate_supervision: false\r\nintermediate_supervision_layer: 12\r\nleftwidth: 400\r\nlocation_refinement: true\r\nlocref_huber_loss: true\r\nlocref_loss_weight: 0.05\r\nlocref_stdev: 7.2801\r\nmax_input_size: 1500\r\nmetadataset: training-datasets/iteration-0/UnaugmentedDataSet_GroupFishJun15/Documentation_data-GroupFish_95shuffle1.pickle\r\nmin_input_size: 64\r\nminsize: 100\r\nmirror: false\r\nmulti_step:\r\n- - 0.0001\r\n  - 7500\r\n- - 5.0e-05\r\n  - 12000\r\n- - 1.0e-05\r\n  - 200000\r\nnet_type: resnet_50\r\nnum_joints: 5\r\nnum_limbs: 10\r\noptimizer: adam\r\npafwidth: 20\r\npairwise_huber_loss: false\r\npairwise_loss_weight: 0.1\r\npairwise_predict: false\r\npartaffinityfield_graph:\r\n- - 0\r\n  - 1\r\n- - 1\r\n  - 2\r\n- - 1\r\n  - 3\r\n- - 1\r\n  - 4\r\n- - 2\r\n  - 4\r\n- - 2\r\n  - 3\r\n- - 0\r\n  - 4\r\n- - 0\r\n  - 3\r\n- - 3\r\n  - 4\r\n- - 0\r\n  - 2\r\npartaffinityfield_predict: true\r\npos_dist_thresh: 17\r\nproject_path: /Users/kperks/Documents/Wesleyan_Research/DLC_data/GroupFish/GroupFish-KPerks-2020-06-15\r\nrightwidth: 400\r\nsave_iters: 10000\r\nscale_jitter_lo: 0.5\r\nscale_jitter_up: 1.25\r\ntopheight: 400\r\nweigh_only_present_joints: false]\r\n```\r\n</p></details>","closed_by":{"login":"MMathisLab","id":28102185,"node_id":"MDQ6VXNlcjI4MTAyMTg1","avatar_url":"https://avatars.githubusercontent.com/u/28102185?v=4","gravatar_id":"","url":"https://api.github.com/users/MMathisLab","html_url":"https://github.com/MMathisLab","followers_url":"https://api.github.com/users/MMathisLab/followers","following_url":"https://api.github.com/users/MMathisLab/following{/other_user}","gists_url":"https://api.github.com/users/MMathisLab/gists{/gist_id}","starred_url":"https://api.github.com/users/MMathisLab/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MMathisLab/subscriptions","organizations_url":"https://api.github.com/users/MMathisLab/orgs","repos_url":"https://api.github.com/users/MMathisLab/repos","events_url":"https://api.github.com/users/MMathisLab/events{/privacy}","received_events_url":"https://api.github.com/users/MMathisLab/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/753/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/753/timeline","performed_via_github_app":null,"state_reason":"completed"}