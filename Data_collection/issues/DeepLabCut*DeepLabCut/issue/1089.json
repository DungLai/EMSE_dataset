{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1089","repository_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut","labels_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1089/labels{/name}","comments_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1089/comments","events_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1089/events","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/1089","id":790335025,"node_id":"MDU6SXNzdWU3OTAzMzUwMjU=","number":1089,"title":"InternalError (see above for traceback): cuDNN launch failure : input shape([8,3,220,220]) filter shape([7,7,3,64])","user":{"login":"donglabimaging","id":50585879,"node_id":"MDQ6VXNlcjUwNTg1ODc5","avatar_url":"https://avatars.githubusercontent.com/u/50585879?v=4","gravatar_id":"","url":"https://api.github.com/users/donglabimaging","html_url":"https://github.com/donglabimaging","followers_url":"https://api.github.com/users/donglabimaging/followers","following_url":"https://api.github.com/users/donglabimaging/following{/other_user}","gists_url":"https://api.github.com/users/donglabimaging/gists{/gist_id}","starred_url":"https://api.github.com/users/donglabimaging/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/donglabimaging/subscriptions","organizations_url":"https://api.github.com/users/donglabimaging/orgs","repos_url":"https://api.github.com/users/donglabimaging/repos","events_url":"https://api.github.com/users/donglabimaging/events{/privacy}","received_events_url":"https://api.github.com/users/donglabimaging/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":12,"created_at":"2021-01-20T21:25:04Z","updated_at":"2021-04-08T12:32:13Z","closed_at":"2021-01-25T20:31:19Z","author_association":"NONE","active_lock_reason":null,"body":"**Your Operating system and DeepLabCut version**\r\nWindows 10, Anaconda Env\r\nDeeplabcut 2.1.9\r\nTensorflow 1.12\r\nCuda v9.0\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2017 NVIDIA Corporation\r\nBuilt on Fri_Sep__1_21:08:32_Central_Daylight_Time_2017\r\nCuda compilation tools, release 9.0, V9.0.176\r\n\r\n\r\n**Describe the problem**\r\nWe recently updated Deeplabcut to 2.1.9.  In the CPU env <activate dlc-windowsCPU>, we passed the testscript.py test and was able to train with the Deeplabcut GUI.  \r\n\r\nWe then tried running Deeplabcut in the GPU env <activate dlc-windowsGPU>.  The testscript seems to be running just fine.  We got \"ALL DONE!!! - default cases are functional.\"  However, once we start training in the Deeplabcut GUI, we received the cuDNN launch failure error.  \r\n\r\nWe have looked at #823, #971, and #786.  Following all those threads, we downgraded Cuda from v10.1 to cuda v9.0 since Tensorfow 1.12 should be compatible with Cuda v.9.0.  Those threads also suggested that it may be due to the memory issue.  I have also tried reducing patch size from 8 to 4, but that did not fix the issue.  We are a bit lost.  Any suggestions would be greatly appreciated.  Thank you!\r\n\r\nBelow is the output from the testscript:\r\n<details><summary>Code output</summary><p>\r\n[(dlc-windowsGPU) C:\\Users\\allenli\\DeepLabCut\\examples>python testscript.py\r\nImported DLC!\r\nOn Windows/OSX tensorpack is not tested by default.\r\nCREATING PROJECT\r\nCreated \"C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\"\r\nCreated \"C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\labeled-data\"\r\nCreated \"C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\training-datasets\"\r\nCreated \"C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\dlc-models\"\r\nCopying the videos\r\nC:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1.avi\r\nGenerated \"C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\config.yaml\"\r\n\r\nA new project with name TEST-Alex-2021-01-20 is created at C:\\Users\\allenli\\DeepLabCut\\examples and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\r\n Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\r\n. [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\r\nEXTRACTING FRAMES\r\nConfig file read successfully.\r\nExtracting frames based on kmeans ...\r\nKmeans-quantization based extracting of frames from 0.0  seconds to 8.53  seconds.\r\nExtracting and downsampling... 256  frames from the video.\r\n256it [00:02, 123.72it/s]\r\nKmeans clustering ... (this might take a while)\r\nFrames were successfully extracted, for the videos of interest.\r\n\r\nYou can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\r\nCREATING-SOME LABELS FOR THE FRAMES\r\nPlot labels...\r\nCreating images with labels by Alex.\r\n100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  5.99it/s]\r\nIf all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\r\nCREATING TRAININGSET\r\nThe training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\r\nCHANGING training parameters to end quickly!\r\nTRAIN\r\nSelecting single-animal trainer\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'],\r\n 'batch_size': 1,\r\n 'crop_pad': 0,\r\n 'cropratio': 0.4,\r\n 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTJan20\\\\TEST_Alex80shuffle1.mat',\r\n 'dataset_type': 'default',\r\n 'deterministic': False,\r\n 'display_iters': 2,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 0.05,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'max_input_size': 1500,\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTJan20\\\\Documentation_data-TEST_80shuffle1.pickle',\r\n 'min_input_size': 64,\r\n 'mirror': False,\r\n 'multi_step': [[0.001, 5]],\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 4,\r\n 'optimizer': 'sgd',\r\n 'pairwise_huber_loss': False,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_predict': False,\r\n 'pos_dist_thresh': 17,\r\n 'project_path': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20',\r\n 'regularize': False,\r\n 'rotation': 25,\r\n 'rotratio': 0.4,\r\n 'save_iters': 5,\r\n 'scale_jitter_lo': 0.5,\r\n 'scale_jitter_up': 1.25,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20\\\\dlc-models\\\\iteration-0\\\\TESTJan20-trainset80shuffle1\\\\train\\\\snapshot',\r\n 'stride': 8.0,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nStarting with imgaug pose-dataset loader (=default).\r\nBatch Size is 1\r\nInitializing ResNet\r\nLoading ImageNet-pretrained resnet_50\r\n2021-01-20 15:24:42.946652: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2021-01-20 15:24:43.180394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties:\r\nname: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.74\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 8.00GiB freeMemory: 6.59GiB\r\n2021-01-20 15:24:43.188094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2021-01-20 15:24:45.855088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-20 15:24:45.860935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0\r\n2021-01-20 15:24:45.863147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N\r\n2021-01-20 15:24:45.868393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6329 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\nTraining parameter:\r\n{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20\\\\dlc-models\\\\iteration-0\\\\TESTJan20-trainset80shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'], 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTJan20\\\\TEST_Alex80shuffle1.mat', 'display_iters': 2, 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTJan20\\\\Documentation_data-TEST_80shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.001, 5]], 'net_type': 'resnet_50', 'num_joints': 4, 'pos_dist_thresh': 17, 'project_path': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 5, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': [-90, 90]}}\r\nStarting training....\r\niteration: 2 loss: 1.2384 lr: 0.001\r\niteration: 4 loss: 0.6374 lr: 0.001\r\n2021-01-20 15:25:04.617990: W tensorflow/core/kernels/queue_base.cc:277] _0_fifo_queue: Skipping cancelled enqueue attempt with queue not closed\r\nException in thread Thread-3:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\r\n         [[{{node fifo_queue_enqueue}} = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](fifo_queue, _arg_Placeholder_0_0, _arg_Placeholder_1_0_1, _arg_Placeholder_2_0_2, _arg_Placeholder_3_0_3, _arg_Placeholder_4_0_4)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 91, in load_and_enqueue\r\n    sess.run(enqueue_op, feed_dict=food)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\r\n         [[node fifo_queue_enqueue (defined at C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77)  = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](fifo_queue, _arg_Placeholder_0_0, _arg_Placeholder_1_0_1, _arg_Placeholder_2_0_2, _arg_Placeholder_3_0_3, _arg_Placeholder_4_0_4)]]\r\n\r\nCaused by op 'fifo_queue_enqueue', defined at:\r\n  File \"testscript.py\", line 145, in <module>\r\n    deeplabcut.train_network(path_config_file)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 189, in train_network\r\n    allow_growth=allow_growth,\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 172, in train\r\n    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 77, in setup_preloading\r\n    enqueue_op = q.enqueue(placeholders_list)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 341, in enqueue\r\n    self._queue_ref, vals, name=scope)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 4381, in queue_enqueue_v2\r\n    timeout_ms=timeout_ms, name=name)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nCancelledError (see above for traceback): Enqueue operation was cancelled\r\n         [[node fifo_queue_enqueue (defined at C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77)  = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](fifo_queue, _arg_Placeholder_0_0, _arg_Placeholder_1_0_1, _arg_Placeholder_2_0_2, _arg_Placeholder_3_0_3, _arg_Placeholder_4_0_4)]]\r\n\r\n\r\nThe network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\r\nEVALUATE\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'],\r\n 'batch_size': 1,\r\n 'crop_pad': 0,\r\n 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTJan20\\\\TEST_Alex80shuffle1.mat',\r\n 'dataset_type': 'imgaug',\r\n 'deterministic': False,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 1.0,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'mirror': False,\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 4,\r\n 'optimizer': 'sgd',\r\n 'pairwise_huber_loss': True,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_predict': False,\r\n 'regularize': False,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20\\\\dlc-models\\\\iteration-0\\\\TESTJan20-trainset80shuffle1\\\\test\\\\snapshot',\r\n 'stride': 8.0,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nRunning  DLC_resnet50_TESTJan20shuffle1_5  with # of trainingiterations: 5\r\nInitializing ResNet\r\n2021-01-20 15:25:06.290925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2021-01-20 15:25:06.294963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-20 15:25:06.300423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0\r\n2021-01-20 15:25:06.302756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N\r\n2021-01-20 15:25:06.305069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6329 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\nAnalyzing data...\r\n5it [00:01,  1.55it/s]\r\nDone and results stored for snapshot:  snapshot-5\r\nResults for 5  training iterations: 80 1 train error: 368.86 pixels. Test error: 419.28  pixels.\r\nWith pcutoff of 0.01  train error: 368.86 pixels. Test error: 419.28 pixels\r\nThereby, the errors are given by the average distances between the labels by DLC and the scorer.\r\nPlotting...\r\n100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  4.60it/s]\r\nThe network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\r\nIf it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\r\nUse the function 'analyze_video' to make predictions on new videos.\r\nOtherwise consider retraining the network (see DeepLabCut workflow Fig 2)\r\nCUT SHORT VIDEO AND ANALYZE (with dynamic cropping!)\r\nffmpeg version N-94129-g098ab93257 Copyright (c) 2000-2019 the FFmpeg developers\r\n  built with gcc 9.1.1 (GCC) 20190621\r\n  configuration: --enable-gpl --enable-version3 --enable-sdl2 --enable-fontconfig --enable-gnutls --enable-iconv --enable-libass --enable-libdav1d --enable-libbluray --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopus --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libtheora --enable-libtwolame --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libzimg --enable-lzma --enable-zlib --enable-gmp --enable-libvidstab --enable-libvorbis --enable-libvo-amrwbenc --enable-libmysofa --enable-libspeex --enable-libxvid --enable-libaom --enable-libmfx --enable-amf --enable-ffnvcodec --enable-cuvid --enable-d3d11va --enable-nvenc --enable-nvdec --enable-dxva2 --enable-avisynth --enable-libopenmpt\r\n  libavutil      56. 29.100 / 56. 29.100\r\n  libavcodec     58. 53.100 / 58. 53.100\r\n  libavformat    58. 28.101 / 58. 28.101\r\n  libavdevice    58.  7.100 / 58.  7.100\r\n  libavfilter     7. 55.100 /  7. 55.100\r\n  libswscale      5.  4.101 /  5.  4.101\r\n  libswresample   3.  4.100 /  3.  4.100\r\n  libpostproc    55.  4.100 / 55.  4.100\r\nInput #0, avi, from 'C:\\Users\\allenli\\DeepLabCut\\examples\\Reaching-Mackenzie-2018-08-30\\videos\\reachingvideo1.avi':\r\n  Duration: 00:00:08.53, start: 0.000000, bitrate: 12642 kb/s\r\n    Stream #0:0: Video: mjpeg (Baseline) (MJPG / 0x47504A4D), yuvj420p(pc, bt470bg/unknown/unknown), 832x747 [SAR 1:1 DAR 832:747], 12682 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\r\n    Metadata:\r\n      title           : ImageJ AVI\r\nStream mapping:\r\n  Stream #0:0 -> #0:0 (mjpeg (native) -> mpeg4 (native))\r\nPress [q] to stop, [?] for help\r\n[swscaler @ 0000019a1e199f80] deprecated pixel format used, make sure you did set range correctly\r\nOutput #0, avi, to 'C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1short.avi':\r\n  Metadata:\r\n    ISFT            : Lavf58.28.101\r\n    Stream #0:0: Video: mpeg4 (FMP4 / 0x34504D46), yuv420p, 832x747 [SAR 1:1 DAR 832:747], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc\r\n    Metadata:\r\n      title           : ImageJ AVI\r\n      encoder         : Lavc58.53.100 mpeg4\r\n    Side data:\r\n      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\r\nframe=   30 fps=0.0 q=31.0 Lsize=     240kB time=00:00:01.00 bitrate=1964.0kbits/s speed=8.73x\r\nvideo:233kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.731339%\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'],\r\n 'batch_size': 1,\r\n 'crop_pad': 0,\r\n 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTJan20\\\\TEST_Alex80shuffle1.mat',\r\n 'dataset_type': 'imgaug',\r\n 'deterministic': False,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 1.0,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'mirror': False,\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 4,\r\n 'optimizer': 'sgd',\r\n 'pairwise_huber_loss': True,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_predict': False,\r\n 'regularize': False,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20\\\\dlc-models\\\\iteration-0\\\\TESTJan20-trainset80shuffle1\\\\test\\\\snapshot',\r\n 'stride': 8.0,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nUsing snapshot-5 for model C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\dlc-models\\iteration-0\\TESTJan20-trainset80shuffle1\r\nStarting analysis in dynamic cropping mode with parameters: (True, 0.1, 5)\r\nSwitching batchsize to 1, num_outputs (per animal) to 1 and TFGPUinference to False (all these features are not supported in this mode).\r\nInitializing ResNet\r\n2021-01-20 15:25:14.559079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2021-01-20 15:25:14.563177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-20 15:25:14.569534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0\r\n2021-01-20 15:25:14.572123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N\r\n2021-01-20 15:25:14.574789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6329 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\nStarting to analyze %  C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1short.avi\r\nC:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos  already exists!\r\nLoading  C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1short.avi\r\nDuration of video [s]:  1.0 , recorded with  30.0 fps!\r\nOverall # of frames:  30  found with (before cropping) frame dimensions:  832 747\r\nStarting to extract posture\r\n40it [00:05,  6.97it/s]\r\nSaving results in C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos...\r\nSaving csv poses!\r\nThe videos are analyzed. Now your research can truly start!\r\n You can create labeled videos with 'create_labeled_video'\r\nIf the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\r\nanalyze again...\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'],\r\n 'batch_size': 1,\r\n 'crop_pad': 0,\r\n 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTJan20\\\\TEST_Alex80shuffle1.mat',\r\n 'dataset_type': 'imgaug',\r\n 'deterministic': False,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 1.0,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'mirror': False,\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 4,\r\n 'optimizer': 'sgd',\r\n 'pairwise_huber_loss': True,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_predict': False,\r\n 'regularize': False,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20\\\\dlc-models\\\\iteration-0\\\\TESTJan20-trainset80shuffle1\\\\test\\\\snapshot',\r\n 'stride': 8.0,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nUsing snapshot-5 for model C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\dlc-models\\iteration-0\\TESTJan20-trainset80shuffle1\r\nInitializing ResNet\r\n2021-01-20 15:25:22.727708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2021-01-20 15:25:22.732039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-20 15:25:22.737867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0\r\n2021-01-20 15:25:22.741520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N\r\n2021-01-20 15:25:22.744449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6329 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\nStarting to analyze %  C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1short.avi\r\nC:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos  already exists!\r\nThe videos are analyzed. Now your research can truly start!\r\n You can create labeled videos with 'create_labeled_video'\r\nIf the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\r\nCREATE VIDEO\r\nC:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos  already exists!\r\nStarting to process video: C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1short.avi\r\nLoading C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1short.avi and data.\r\nDuration of video [s]: 1.0, recorded with 30.0 fps!\r\nOverall # of frames: 30 with cropped frame dimensions: 832 747\r\nGenerating frames and creating video.\r\n100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:04<00:00,  7.83it/s]\r\nLabeled video C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1shortDLC_resnet50_TESTJan20shuffle1_5_labeled.mp4 successfully created.\r\nMaking plots\r\nLoading  C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1short.avi and data.\r\nPlots created! Please check the directory \"plot-poses\" within the video directory\r\nEXTRACT OUTLIERS\r\nMethod  jump  found  29  putative outlier frames.\r\nDo you want to proceed with extracting  5  of those?\r\nIf this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\r\nLoading video...\r\nDuration of video [s]:  1.0 , recorded @  30.0 fps!\r\nOverall # of frames:  30 with (cropped) frame dimensions:\r\nKmeans-quantization based extracting of frames from 0.0  seconds to 1.0  seconds.\r\nExtracting and downsampling... 29  frames from the video.\r\n29it [00:00, 146.83it/s]\r\nKmeans clustering ... (this might take a while)\r\nLet's select frames indices: [15, 29, 27, 8, 25]\r\nNew video was added to the project! Use the function 'extract_frames' to select frames for labeling.\r\nThe outlier frames are extracted. They are stored in the subdirectory labeled-data\\reachingvideo1short.\r\nOnce you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\r\nFitting state-space models with parameters: 3 1\r\nC:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\r\n  warn('Non-stationary starting autoregressive parameters'\r\nC:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\r\n  ConvergenceWarning)\r\nC:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\r\n  ConvergenceWarning)\r\nMethod  fitting  found  23  putative outlier frames.\r\nDo you want to proceed with extracting  5  of those?\r\nIf this list is very large, perhaps consider changing the parameters (start, stop, epsilon, ARdegree, MAdegree, alpha, comparisonbodyparts) or use a different method.\r\nFrames from video reachingvideo1short  already extracted (more will be added)!\r\nLoading video...\r\nDuration of video [s]:  1.0 , recorded @  30.0 fps!\r\nOverall # of frames:  30 with (cropped) frame dimensions:\r\nKmeans-quantization based extracting of frames from 0.0  seconds to 1.0  seconds.\r\nExtracting and downsampling... 22  frames from the video.\r\n22it [00:00, 90.27it/s]\r\nKmeans clustering ... (this might take a while)\r\nLet's select frames indices: [19, 12, 5, 10, 26]\r\nNew video was added to the project! Use the function 'extract_frames' to select frames for labeling.\r\nThe outlier frames are extracted. They are stored in the subdirectory labeled-data\\reachingvideo1short.\r\nOnce you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\r\nRELABELING\r\nMERGING\r\nMerged data sets and updated refinement iteration to 1.\r\nNow you can create a new training set for the expanded annotated images (use create_training_dataset).\r\nCREATING TRAININGSET\r\nThe training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\r\nCHANGING training parameters to end quickly!\r\nTRAIN\r\nSelecting single-animal trainer\r\nConfig:\r\n{'Task': None,\r\n 'TrainingFraction': None,\r\n 'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'],\r\n 'alphavalue': None,\r\n 'batch_size': 1,\r\n 'bodyparts': None,\r\n 'colormap': None,\r\n 'corner2move2': None,\r\n 'crop_pad': 0,\r\n 'croppedtraining': None,\r\n 'cropping': None,\r\n 'cropratio': 0.4,\r\n 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_TESTJan20\\\\TEST_Alex80shuffle1.mat',\r\n 'dataset_type': 'scalecrop',\r\n 'date': None,\r\n 'default_augmenter': None,\r\n 'default_net_type': None,\r\n 'deterministic': False,\r\n 'display_iters': 1,\r\n 'dotsize': None,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'iteration': None,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 0.05,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'max_input_size': 1500,\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'metadataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_TESTJan20\\\\Documentation_data-TEST_80shuffle1.pickle',\r\n 'min_input_size': 64,\r\n 'mirror': False,\r\n 'move2corner': None,\r\n 'multi_step': [[0.001, 5]],\r\n 'multianimalproject': None,\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 4,\r\n 'numframes2pick': None,\r\n 'optimizer': 'sgd',\r\n 'pairwise_huber_loss': False,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_predict': False,\r\n 'pcutoff': None,\r\n 'pos_dist_thresh': 17,\r\n 'project_path': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20',\r\n 'regularize': False,\r\n 'save_iters': 5,\r\n 'scale_jitter_lo': 0.5,\r\n 'scale_jitter_up': 1.25,\r\n 'scoremap_dir': 'test',\r\n 'scorer': None,\r\n 'shuffle': True,\r\n 'skeleton': [],\r\n 'skeleton_color': 'black',\r\n 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20\\\\dlc-models\\\\iteration-1\\\\TESTJan20-trainset80shuffle1\\\\train\\\\snapshot',\r\n 'snapshotindex': None,\r\n 'start': None,\r\n 'stop': None,\r\n 'stride': 8.0,\r\n 'video_sets': None,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001,\r\n 'x1': None,\r\n 'x2': None,\r\n 'y1': None,\r\n 'y2': None}\r\nStarting with scalecrop pose-dataset loader.\r\nInitializing ResNet\r\nLoading ImageNet-pretrained resnet_50\r\n2021-01-20 15:25:42.253076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2021-01-20 15:25:42.258518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-20 15:25:42.264033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0\r\n2021-01-20 15:25:42.268514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N\r\n2021-01-20 15:25:42.272401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6329 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\nTraining parameter:\r\n{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20\\\\dlc-models\\\\iteration-1\\\\TESTJan20-trainset80shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'scalecrop', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'Task': None, 'scorer': None, 'date': None, 'multianimalproject': None, 'project_path': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20', 'video_sets': None, 'bodyparts': None, 'start': None, 'stop': None, 'numframes2pick': None, 'skeleton': [], 'skeleton_color': 'black', 'pcutoff': None, 'dotsize': None, 'alphavalue': None, 'colormap': None, 'TrainingFraction': None, 'iteration': None, 'default_net_type': None, 'default_augmenter': None, 'snapshotindex': None, 'cropping': None, 'croppedtraining': None, 'x1': None, 'x2': None, 'y1': None, 'y2': None, 'corner2move2': None, 'move2corner': None, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'], 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_TESTJan20\\\\TEST_Alex80shuffle1.mat', 'display_iters': 1, 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_TESTJan20\\\\Documentation_data-TEST_80shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.001, 5]], 'net_type': 'resnet_50', 'num_joints': 4, 'pos_dist_thresh': 17, 'save_iters': 5, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'crop': True, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400}\r\nStarting training....\r\niteration: 1 loss: 1.7497 lr: 0.001\r\niteration: 2 loss: 0.7298 lr: 0.001\r\niteration: 3 loss: 0.6694 lr: 0.001\r\niteration: 4 loss: 0.5855 lr: 0.001\r\niteration: 5 loss: 0.4910 lr: 0.001\r\n2021-01-20 15:25:57.331746: W tensorflow/core/kernels/queue_base.cc:277] _1_fifo_queue: Skipping cancelled enqueue attempt with queue not closed\r\nException in thread Thread-13:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\r\n         [[{{node fifo_queue_enqueue}} = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](fifo_queue, _arg_Placeholder_0_0, _arg_Placeholder_1_0_1, _arg_Placeholder_2_0_2, _arg_Placeholder_3_0_3, _arg_Placeholder_4_0_4)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 91, in load_and_enqueue\r\n    sess.run(enqueue_op, feed_dict=food)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\r\n         [[node fifo_queue_enqueue (defined at C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77)  = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](fifo_queue, _arg_Placeholder_0_0, _arg_Placeholder_1_0_1, _arg_Placeholder_2_0_2, _arg_Placeholder_3_0_3, _arg_Placeholder_4_0_4)]]\r\n\r\nCaused by op 'fifo_queue_enqueue', defined at:\r\n  File \"testscript.py\", line 275, in <module>\r\n    deeplabcut.train_network(path_config_file)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 189, in train_network\r\n    allow_growth=allow_growth,\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 172, in train\r\n    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 77, in setup_preloading\r\n    enqueue_op = q.enqueue(placeholders_list)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 341, in enqueue\r\n    self._queue_ref, vals, name=scope)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 4381, in queue_enqueue_v2\r\n    timeout_ms=timeout_ms, name=name)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nCancelledError (see above for traceback): Enqueue operation was cancelled\r\n         [[node fifo_queue_enqueue (defined at C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77)  = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](fifo_queue, _arg_Placeholder_0_0, _arg_Placeholder_1_0_1, _arg_Placeholder_2_0_2, _arg_Placeholder_3_0_3, _arg_Placeholder_4_0_4)]]\r\n\r\n\r\nThe network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\r\nffmpeg version N-94129-g098ab93257 Copyright (c) 2000-2019 the FFmpeg developers\r\n  built with gcc 9.1.1 (GCC) 20190621\r\n  configuration: --enable-gpl --enable-version3 --enable-sdl2 --enable-fontconfig --enable-gnutls --enable-iconv --enable-libass --enable-libdav1d --enable-libbluray --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopus --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libtheora --enable-libtwolame --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libzimg --enable-lzma --enable-zlib --enable-gmp --enable-libvidstab --enable-libvorbis --enable-libvo-amrwbenc --enable-libmysofa --enable-libspeex --enable-libxvid --enable-libaom --enable-libmfx --enable-amf --enable-ffnvcodec --enable-cuvid --enable-d3d11va --enable-nvenc --enable-nvdec --enable-dxva2 --enable-avisynth --enable-libopenmpt\r\n  libavutil      56. 29.100 / 56. 29.100\r\n  libavcodec     58. 53.100 / 58. 53.100\r\n  libavformat    58. 28.101 / 58. 28.101\r\n  libavdevice    58.  7.100 / 58.  7.100\r\n  libavfilter     7. 55.100 /  7. 55.100\r\n  libswscale      5.  4.101 /  5.  4.101\r\n  libswresample   3.  4.100 /  3.  4.100\r\n  libpostproc    55.  4.100 / 55.  4.100\r\nInput #0, avi, from 'C:\\Users\\allenli\\DeepLabCut\\examples\\Reaching-Mackenzie-2018-08-30\\videos\\reachingvideo1.avi':\r\n  Duration: 00:00:08.53, start: 0.000000, bitrate: 12642 kb/s\r\n    Stream #0:0: Video: mjpeg (Baseline) (MJPG / 0x47504A4D), yuvj420p(pc, bt470bg/unknown/unknown), 832x747 [SAR 1:1 DAR 832:747], 12682 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\r\n    Metadata:\r\n      title           : ImageJ AVI\r\nStream mapping:\r\n  Stream #0:0 -> #0:0 (mjpeg (native) -> mpeg4 (native))\r\nPress [q] to stop, [?] for help\r\n[swscaler @ 0000021cf0589f80] deprecated pixel format used, make sure you did set range correctly\r\nOutput #0, avi, to 'C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1short2.avi':\r\n  Metadata:\r\n    ISFT            : Lavf58.28.101\r\n    Stream #0:0: Video: mpeg4 (FMP4 / 0x34504D46), yuv420p, 832x747 [SAR 1:1 DAR 832:747], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc\r\n    Metadata:\r\n      title           : ImageJ AVI\r\n      encoder         : Lavc58.53.100 mpeg4\r\n    Side data:\r\n      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\r\nframe=   30 fps=0.0 q=31.0 Lsize=     240kB time=00:00:01.00 bitrate=1964.0kbits/s speed=9.28x\r\nvideo:233kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.731339%\r\nInference with direct cropping\r\nOverwriting cropping parameters: [0, 50, 0, 50]\r\nThese are used for all videos, but won't be save to the cfg file.\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'],\r\n 'batch_size': 1,\r\n 'crop_pad': 0,\r\n 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_TESTJan20\\\\TEST_Alex80shuffle1.mat',\r\n 'dataset_type': 'imgaug',\r\n 'deterministic': False,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 1.0,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'mirror': False,\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 4,\r\n 'optimizer': 'sgd',\r\n 'pairwise_huber_loss': True,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_predict': False,\r\n 'regularize': False,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20\\\\dlc-models\\\\iteration-1\\\\TESTJan20-trainset80shuffle1\\\\test\\\\snapshot',\r\n 'stride': 8.0,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nUsing snapshot-5 for model C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\dlc-models\\iteration-1\\TESTJan20-trainset80shuffle1\r\nInitializing ResNet\r\n2021-01-20 15:25:59.279936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2021-01-20 15:25:59.285578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-20 15:25:59.291243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0\r\n2021-01-20 15:25:59.294105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N\r\n2021-01-20 15:25:59.297337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6329 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\nStarting to analyze %  C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1short2.avi\r\nC:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos  already exists!\r\nLoading  C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1short2.avi\r\nDuration of video [s]:  1.0 , recorded with  30.0 fps!\r\nOverall # of frames:  30  found with (before cropping) frame dimensions:  832 747\r\nStarting to extract posture\r\nCropping based on the x1 = 0 x2 = 50 y1 = 0 y2 = 50. You can adjust the cropping coordinates in the config.yaml file.\r\n 67%|██████████████████████████████████████████████████████▋                           | 20/30 [00:00<00:00, 29.78it/s]Detected frames:  30\r\n40it [00:00, 51.46it/s]\r\nSaving results in C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos...\r\nSaving csv poses!\r\nThe videos are analyzed. Now your research can truly start!\r\n You can create labeled videos with 'create_labeled_video'\r\nIf the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\r\nExtracting skeleton distances, filter and plot filtered output\r\nProcessing C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1short2.avi\r\nFiltering with median model C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1short2.avi\r\nSaving filtered csv poses!\r\nC:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos  already exists!\r\nStarting to process video: C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1short2.avi\r\nLoading C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1short2.avi and data.\r\nDuration of video [s]: 1.0, recorded with 30.0 fps!\r\nOverall # of frames: 30 with cropped frame dimensions: 50 50\r\nGenerating frames and creating video.\r\n100%|█████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 224.55it/s]\r\nCreating a Johansson video!\r\nC:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos  already exists!\r\nStarting to process video: C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1short.avi\r\nLabeled video reachingvideo1short already created.\r\nLoading  C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\videos\\reachingvideo1short2.avi and data.\r\nPlots created! Please check the directory \"plot-poses\" within the video directory\r\nALL DONE!!! - default cases without Tensorpack loader are functional.\r\nCREATING TRAININGSET for shuffle 2\r\nwill be used for 3D testscript...\r\nC:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\training-datasets\\iteration-1\\UnaugmentedDataSet_TESTJan20  already exists!\r\nThe training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\r\nCHANGING training parameters to end quickly!\r\nTRAINING shuffle 2, with smaller allocated memory\r\nSelecting single-animal trainer\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'],\r\n 'batch_size': 1,\r\n 'crop_pad': 0,\r\n 'cropratio': 0.4,\r\n 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_TESTJan20\\\\TEST_Alex80shuffle2.mat',\r\n 'dataset_type': 'imgaug',\r\n 'deterministic': False,\r\n 'display_iters': 2,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 0.05,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'max_input_size': 1500,\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'metadataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_TESTJan20\\\\Documentation_data-TEST_80shuffle2.pickle',\r\n 'min_input_size': 64,\r\n 'mirror': False,\r\n 'multi_step': [[0.001, 10]],\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 4,\r\n 'optimizer': 'sgd',\r\n 'pairwise_huber_loss': False,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_predict': False,\r\n 'pos_dist_thresh': 17,\r\n 'project_path': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20',\r\n 'regularize': False,\r\n 'rotation': 25,\r\n 'rotratio': 0.4,\r\n 'save_iters': 10,\r\n 'scale_jitter_lo': 0.5,\r\n 'scale_jitter_up': 1.25,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20\\\\dlc-models\\\\iteration-1\\\\TESTJan20-trainset80shuffle2\\\\train\\\\snapshot',\r\n 'stride': 8.0,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nStarting with imgaug pose-dataset loader (=default).\r\nBatch Size is 1\r\nInitializing ResNet\r\nLoading ImageNet-pretrained resnet_50\r\n2021-01-20 15:26:19.696823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2021-01-20 15:26:19.702350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-20 15:26:19.708793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0\r\n2021-01-20 15:26:19.711706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N\r\n2021-01-20 15:26:19.714220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6329 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\nTraining parameter:\r\n{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20\\\\dlc-models\\\\iteration-1\\\\TESTJan20-trainset80shuffle2\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'imgaug', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'], 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_TESTJan20\\\\TEST_Alex80shuffle2.mat', 'display_iters': 2, 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_TESTJan20\\\\Documentation_data-TEST_80shuffle2.pickle', 'min_input_size': 64, 'multi_step': [[0.001, 10]], 'net_type': 'resnet_50', 'num_joints': 4, 'pos_dist_thresh': 17, 'project_path': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 10, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': [-90, 90]}}\r\nStarting training....\r\niteration: 2 loss: 1.2654 lr: 0.001\r\niteration: 4 loss: 0.6740 lr: 0.001\r\niteration: 6 loss: 0.5270 lr: 0.001\r\niteration: 8 loss: 0.4229 lr: 0.001\r\niteration: 10 loss: 0.2994 lr: 0.001\r\n2021-01-20 15:26:41.806012: W tensorflow/core/kernels/queue_base.cc:277] _2_fifo_queue: Skipping cancelled enqueue attempt with queue not closed\r\nException in thread Thread-22:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\r\n         [[{{node fifo_queue_enqueue}} = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](fifo_queue, _arg_Placeholder_0_0, _arg_Placeholder_1_0_1, _arg_Placeholder_2_0_2, _arg_Placeholder_3_0_3, _arg_Placeholder_4_0_4)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 91, in load_and_enqueue\r\n    sess.run(enqueue_op, feed_dict=food)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\r\n         [[node fifo_queue_enqueue (defined at C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77)  = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](fifo_queue, _arg_Placeholder_0_0, _arg_Placeholder_1_0_1, _arg_Placeholder_2_0_2, _arg_Placeholder_3_0_3, _arg_Placeholder_4_0_4)]]\r\n\r\nCaused by op 'fifo_queue_enqueue', defined at:\r\n  File \"testscript.py\", line 367, in <module>\r\n    deeplabcut.train_network(path_config_file, shuffle=2, allow_growth=True)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 189, in train_network\r\n    allow_growth=allow_growth,\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 172, in train\r\n    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 77, in setup_preloading\r\n    enqueue_op = q.enqueue(placeholders_list)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 341, in enqueue\r\n    self._queue_ref, vals, name=scope)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 4381, in queue_enqueue_v2\r\n    timeout_ms=timeout_ms, name=name)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nCancelledError (see above for traceback): Enqueue operation was cancelled\r\n         [[node fifo_queue_enqueue (defined at C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77)  = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](fifo_queue, _arg_Placeholder_0_0, _arg_Placeholder_1_0_1, _arg_Placeholder_2_0_2, _arg_Placeholder_3_0_3, _arg_Placeholder_4_0_4)]]\r\n\r\n\r\nThe network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\r\nANALYZING some individual frames\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'],\r\n 'batch_size': 1,\r\n 'crop_pad': 0,\r\n 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_TESTJan20\\\\TEST_Alex80shuffle1.mat',\r\n 'dataset_type': 'imgaug',\r\n 'deterministic': False,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 1.0,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'mirror': False,\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 4,\r\n 'optimizer': 'sgd',\r\n 'pairwise_huber_loss': True,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_predict': False,\r\n 'regularize': False,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20\\\\dlc-models\\\\iteration-1\\\\TESTJan20-trainset80shuffle1\\\\test\\\\snapshot',\r\n 'stride': 8.0,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nUsing snapshot-5 for model C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\dlc-models\\iteration-1\\TESTJan20-trainset80shuffle1\r\nInitializing ResNet\r\n2021-01-20 15:26:43.420461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2021-01-20 15:26:43.425894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-20 15:26:43.431536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0\r\n2021-01-20 15:26:43.434388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N\r\n2021-01-20 15:26:43.437354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6329 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\nAnalyzing all frames in the directory:  C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\labeled-data/reachingvideo1/\r\nStarting to extract posture\r\nOverall # of frames:  5  found with (before cropping) frame dimensions:  832 747\r\n10it [00:02,  4.56it/s]\r\nSaving results in C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\labeled-data/reachingvideo1/...\r\nThe folder was analyzed. Now your research can truly start!\r\nIf the tracking is not satisfactory for some frome, consider expanding the training set.\r\nExport model...\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'],\r\n 'batch_size': 1,\r\n 'crop_pad': 0,\r\n 'cropratio': 0.4,\r\n 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_TESTJan20\\\\TEST_Alex80shuffle2.mat',\r\n 'dataset_type': 'imgaug',\r\n 'deterministic': False,\r\n 'display_iters': 2,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 0.05,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'max_input_size': 1500,\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'metadataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_TESTJan20\\\\Documentation_data-TEST_80shuffle2.pickle',\r\n 'min_input_size': 64,\r\n 'mirror': False,\r\n 'multi_step': [[0.001, 10]],\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 4,\r\n 'optimizer': 'sgd',\r\n 'pairwise_huber_loss': False,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_predict': False,\r\n 'pos_dist_thresh': 17,\r\n 'project_path': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20',\r\n 'regularize': False,\r\n 'rotation': 25,\r\n 'rotratio': 0.4,\r\n 'save_iters': 10,\r\n 'scale_jitter_lo': 0.5,\r\n 'scale_jitter_up': 1.25,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-20\\\\dlc-models\\\\iteration-1\\\\TESTJan20-trainset80shuffle2\\\\train\\\\snapshot',\r\n 'stride': 8.0,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nInitializing ResNet\r\n2021-01-20 15:26:47.827422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2021-01-20 15:26:47.831902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-20 15:26:47.837443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0\r\n2021-01-20 15:26:47.840742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N\r\n2021-01-20 15:26:47.844166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6329 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n2021-01-20 15:26:50.131547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2021-01-20 15:26:50.136031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-20 15:26:50.141996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0\r\n2021-01-20 15:26:50.144825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N\r\n2021-01-20 15:26:50.147346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6329 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\nMerging datasets...\r\nC:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\training-datasets\\iteration-1\\UnaugmentedDataSet_TESTJan20  already exists!\r\nCreating two identical splits...\r\nC:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-20\\training-datasets\\iteration-1\\UnaugmentedDataSet_TESTJan20  already exists!\r\nYou passed a split with the following fraction: 80%\r\nYou passed a split with the following fraction: 80%\r\nThe training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\r\nThe training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\r\nALL DONE!!! - default cases are functional.\r\nRe-import DLC with env. variable set to test DLC light mode.\r\nPython was not found; run without arguments to install from the Microsoft Store, or disable this shortcut from Settings > Manage App Execution Aliases.]\r\n</p></details>\r\n\r\nWe initiated the deeplabcut GUI, labeled the frames and build the skeleton.  These all went fine.  However, an error popped up at the training stage.\r\n\r\nBelow contains the error message:\r\n<details><summary>Code output</summary><p>\r\n\r\n[Starting GUI...\r\nnote to user: currently only ResNet50-v1 is available for maDLC\r\nnote to user: currently model comparison is not available in maDLC\r\nC:\\Users\\allenli\\M83_GPU-AK-2021-01-19\\training-datasets\\iteration-0\\UnaugmentedDataSet_M83_GPUJan19  already exists!\r\nUtilizing the following graph: [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [1, 2], [1, 3], [2, 3], [3, 4], [3, 6], [3, 5], [4, 5], [5, 6]]\r\nCreating training data for  1 0.95\r\nThis can take some time...\r\n100%|████████████████████████████████████████████████████████████████████████████████| 280/280 [00:03<00:00, 80.93it/s]\r\nThe training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\r\nSelecting multi-animal trainer\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\r\n 'all_joints_names': ['miniscope',\r\n                      'leftear',\r\n                      'rightear',\r\n                      'button',\r\n                      'midbody',\r\n                      'tailbase',\r\n                      'midtail',\r\n                      'lever'],\r\n 'batch_size': 8,\r\n 'crop_pad': 0,\r\n 'cropratio': 0.4,\r\n 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_M83_GPUJan19\\\\M83_GPU_AK95shuffle1.pickle',\r\n 'dataset_type': 'multi-animal-imgaug',\r\n 'deterministic': False,\r\n 'display_iters': 500,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 0.05,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'max_input_size': 1500,\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_M83_GPUJan19\\\\Documentation_data-M83_GPU_95shuffle1.pickle',\r\n 'min_input_size': 64,\r\n 'mirror': False,\r\n 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 200000]],\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 8,\r\n 'num_limbs': 14,\r\n 'optimizer': 'adam',\r\n 'pafwidth': 20,\r\n 'pairwise_huber_loss': False,\r\n 'pairwise_loss_weight': 0.1,\r\n 'pairwise_predict': False,\r\n 'partaffinityfield_graph': [[0, 1],\r\n                             [0, 2],\r\n                             [0, 3],\r\n                             [0, 4],\r\n                             [0, 5],\r\n                             [0, 6],\r\n                             [1, 2],\r\n                             [1, 3],\r\n                             [2, 3],\r\n                             [3, 4],\r\n                             [3, 6],\r\n                             [3, 5],\r\n                             [4, 5],\r\n                             [5, 6]],\r\n 'partaffinityfield_predict': True,\r\n 'pos_dist_thresh': 17,\r\n 'project_path': 'C:\\\\Users\\\\allenli\\\\M83_GPU-AK-2021-01-19',\r\n 'regularize': False,\r\n 'rotation': 25,\r\n 'rotratio': 0.4,\r\n 'save_iters': 10000,\r\n 'scale_jitter_lo': 0.5,\r\n 'scale_jitter_up': 1.25,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\M83_GPU-AK-2021-01-19\\\\dlc-models\\\\iteration-0\\\\M83_GPUJan19-trainset95shuffle1\\\\train\\\\snapshot',\r\n 'stride': 8.0,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nActivating limb prediction...\r\nStarting with multi-animal imaug + adam pose-dataset loader.\r\nBatch Size is 8\r\nGetting specs multi-animal-imgaug 14 8\r\nInitializing ResNet\r\nLoading ImageNet-pretrained resnet_50\r\n2021-01-20 15:38:20.032502: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2021-01-20 15:38:20.181026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties:\r\nname: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.74\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 8.00GiB freeMemory: 6.59GiB\r\n2021-01-20 15:38:20.188921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2021-01-20 15:38:20.894864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-20 15:38:20.900246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0\r\n2021-01-20 15:38:20.902636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N\r\n2021-01-20 15:38:20.905549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6329 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\nMax_iters overwritten as 50000\r\nDisplay_iters overwritten as 1000\r\nSave_iters overwritten as 5000\r\nTraining parameters:\r\n{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\M83_GPU-AK-2021-01-19\\\\dlc-models\\\\iteration-0\\\\M83_GPUJan19-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'adam', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 8, 'dataset_type': 'multi-animal-imgaug', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': True, 'pairwise_predict': True, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]], 'all_joints_names': ['miniscope', 'leftear', 'rightear', 'button', 'midbody', 'tailbase', 'midtail', 'lever'], 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_M83_GPUJan19\\\\M83_GPU_AK95shuffle1.pickle', 'display_iters': 500, 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_M83_GPUJan19\\\\Documentation_data-M83_GPU_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 200000]], 'net_type': 'resnet_50', 'num_joints': 8, 'num_limbs': 14, 'pafwidth': 20, 'pairwise_loss_weight': 0.1, 'partaffinityfield_graph': [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [1, 2], [1, 3], [2, 3], [3, 4], [3, 6], [3, 5], [4, 5], [5, 6]], 'pos_dist_thresh': 17, 'project_path': 'C:\\\\Users\\\\allenli\\\\M83_GPU-AK-2021-01-19', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 10000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25}\r\nStarting multi-animal training....\r\n2021-01-20 15:38:29.884985: E tensorflow/stream_executor/cuda/cuda_dnn.cc:82] CUDNN_STATUS_EXECUTION_FAILED\r\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(2531): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd.handle(), input_data.opaque(), filter.handle(), filter_data.opaque(), conv.handle(), ToConvForwardAlgo(algo_desc), scratch.opaque(), scratch.size(), beta, output_nd.handle(), output_data->opaque())'\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InternalError: cuDNN launch failure : input shape([8,3,220,220]) filter shape([7,7,3,64])\r\n         [[{{node resnet_v1_50/conv1/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 2, 2], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/resnet_v1_50/conv1/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer, resnet_v1_50/conv1/weights/read)]]\r\n         [[{{node mean_squared_error/num_present/broadcast_weights/assert_broadcastable/AssertGuard/Assert/Switch/_647}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1707_...ert/Switch\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\gui\\train_network.py\", line 329, in train_network\r\n    maxiters=maxiters,\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 193, in train_network\r\n    raise e\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 176, in train_network\r\n    allow_growth=allow_growth,\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train_multianimal.py\", line 217, in train\r\n    feed_dict={learning_rate: current_lr},\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InternalError: cuDNN launch failure : input shape([8,3,220,220]) filter shape([7,7,3,64])\r\n         [[node resnet_v1_50/conv1/Conv2D (defined at C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1057)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 2, 2], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/resnet_v1_50/conv1/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer, resnet_v1_50/conv1/weights/read)]]\r\n         [[{{node mean_squared_error/num_present/broadcast_weights/assert_broadcastable/AssertGuard/Assert/Switch/_647}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1707_...ert/Switch\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nCaused by op 'resnet_v1_50/conv1/Conv2D', defined at:\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\__main__.py\", line 20, in <module>\r\n    deeplabcut.launch_dlc()\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\gui\\launch_script.py\", line 66, in launch_dlc\r\n    app.MainLoop()\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\wx\\core.py\", line 2134, in MainLoop\r\n    rv = wx.PyApp.MainLoop(self)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\gui\\train_network.py\", line 329, in train_network\r\n    maxiters=maxiters,\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 176, in train_network\r\n    allow_growth=allow_growth,\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train_multianimal.py\", line 141, in train\r\n    losses = pose_net(cfg).train(batch)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\nnet\\pose_net.py\", line 279, in train\r\n    heads = self.get_net(batch[Batch.inputs])\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\nnet\\pose_net.py\", line 178, in get_net\r\n    net, end_points = self.extract_features(inputs)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\nnet\\pose_net.py\", line 130, in extract_features\r\n    im_centered, global_pool=False, output_stride=16, is_training=False\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\nets\\resnet_v1.py\", line 274, in resnet_v1_50\r\n    scope=scope)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\nets\\resnet_v1.py\", line 205, in resnet_v1\r\n    net = resnet_utils.conv2d_same(net, 64, 7, stride=2, scope='conv1')\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\nets\\resnet_utils.py\", line 146, in conv2d_same\r\n    scope=scope)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\", line 1154, in convolution2d\r\n    conv_dims=2)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\", line 1057, in convolution\r\n    outputs = layer.apply(inputs)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 817, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 374, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 757, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 194, in call\r\n    outputs = self._convolution_op(inputs, self.kernel)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 868, in __call__\r\n    return self.conv_op(inp, filter)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 520, in __call__\r\n    return self.call(inp, filter)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 204, in __call__\r\n    name=self.name)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1044, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInternalError (see above for traceback): cuDNN launch failure : input shape([8,3,220,220]) filter shape([7,7,3,64])\r\n         [[node resnet_v1_50/conv1/Conv2D (defined at C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1057)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 2, 2], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/resnet_v1_50/conv1/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer, resnet_v1_50/conv1/weights/read)]]\r\n         [[{{node mean_squared_error/num_present/broadcast_weights/assert_broadcastable/AssertGuard/Assert/Switch/_647}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1707_...ert/Switch\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n]\r\n</p></details>\r\n\r\n**How to Reproduce the problem**\r\nSteps to reproduce the behavior:\r\n1. activate dlc-windowsGPU\r\n2. python -m deeplabcut\r\n3. Start training\r\n4. See error","closed_by":{"login":"MMathisLab","id":28102185,"node_id":"MDQ6VXNlcjI4MTAyMTg1","avatar_url":"https://avatars.githubusercontent.com/u/28102185?v=4","gravatar_id":"","url":"https://api.github.com/users/MMathisLab","html_url":"https://github.com/MMathisLab","followers_url":"https://api.github.com/users/MMathisLab/followers","following_url":"https://api.github.com/users/MMathisLab/following{/other_user}","gists_url":"https://api.github.com/users/MMathisLab/gists{/gist_id}","starred_url":"https://api.github.com/users/MMathisLab/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MMathisLab/subscriptions","organizations_url":"https://api.github.com/users/MMathisLab/orgs","repos_url":"https://api.github.com/users/MMathisLab/repos","events_url":"https://api.github.com/users/MMathisLab/events{/privacy}","received_events_url":"https://api.github.com/users/MMathisLab/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1089/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1089/timeline","performed_via_github_app":null,"state_reason":"completed"}