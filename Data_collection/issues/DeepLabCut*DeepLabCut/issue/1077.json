{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1077","repository_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut","labels_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1077/labels{/name}","comments_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1077/comments","events_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1077/events","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/1077","id":783955666,"node_id":"MDU6SXNzdWU3ODM5NTU2NjY=","number":1077,"title":"2 Errors running testscript.py","user":{"login":"donglabimaging","id":50585879,"node_id":"MDQ6VXNlcjUwNTg1ODc5","avatar_url":"https://avatars.githubusercontent.com/u/50585879?v=4","gravatar_id":"","url":"https://api.github.com/users/donglabimaging","html_url":"https://github.com/donglabimaging","followers_url":"https://api.github.com/users/donglabimaging/followers","following_url":"https://api.github.com/users/donglabimaging/following{/other_user}","gists_url":"https://api.github.com/users/donglabimaging/gists{/gist_id}","starred_url":"https://api.github.com/users/donglabimaging/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/donglabimaging/subscriptions","organizations_url":"https://api.github.com/users/donglabimaging/orgs","repos_url":"https://api.github.com/users/donglabimaging/repos","events_url":"https://api.github.com/users/donglabimaging/events{/privacy}","received_events_url":"https://api.github.com/users/donglabimaging/received_events","type":"User","site_admin":false},"labels":[{"id":880550034,"node_id":"MDU6TGFiZWw4ODA1NTAwMzQ=","url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":{"login":"jeylau","id":30733203,"node_id":"MDQ6VXNlcjMwNzMzMjAz","avatar_url":"https://avatars.githubusercontent.com/u/30733203?v=4","gravatar_id":"","url":"https://api.github.com/users/jeylau","html_url":"https://github.com/jeylau","followers_url":"https://api.github.com/users/jeylau/followers","following_url":"https://api.github.com/users/jeylau/following{/other_user}","gists_url":"https://api.github.com/users/jeylau/gists{/gist_id}","starred_url":"https://api.github.com/users/jeylau/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jeylau/subscriptions","organizations_url":"https://api.github.com/users/jeylau/orgs","repos_url":"https://api.github.com/users/jeylau/repos","events_url":"https://api.github.com/users/jeylau/events{/privacy}","received_events_url":"https://api.github.com/users/jeylau/received_events","type":"User","site_admin":false},"assignees":[{"login":"jeylau","id":30733203,"node_id":"MDQ6VXNlcjMwNzMzMjAz","avatar_url":"https://avatars.githubusercontent.com/u/30733203?v=4","gravatar_id":"","url":"https://api.github.com/users/jeylau","html_url":"https://github.com/jeylau","followers_url":"https://api.github.com/users/jeylau/followers","following_url":"https://api.github.com/users/jeylau/following{/other_user}","gists_url":"https://api.github.com/users/jeylau/gists{/gist_id}","starred_url":"https://api.github.com/users/jeylau/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jeylau/subscriptions","organizations_url":"https://api.github.com/users/jeylau/orgs","repos_url":"https://api.github.com/users/jeylau/repos","events_url":"https://api.github.com/users/jeylau/events{/privacy}","received_events_url":"https://api.github.com/users/jeylau/received_events","type":"User","site_admin":false}],"milestone":null,"comments":4,"created_at":"2021-01-12T06:34:07Z","updated_at":"2021-01-14T19:11:48Z","closed_at":"2021-01-14T19:11:48Z","author_association":"NONE","active_lock_reason":null,"body":"Thanks for opening this issue, and thanks for using DeepLabCut (we hope you are enjoying it ;). Please fill out the template completely, including the full \"traceback\" and input code that you ran to hit this error.\r\n\r\n**Your Operating system and DeepLabCut version**\r\n\r\n- OS: Windows 10\r\n- DeepLabCut Version 2.1.9\r\n- dlc-windowsCPU\r\n- DeepLabCut testscript.py\r\n\r\n**Describe the problem**\r\nHi, I updated DLC to 2.1.9 using <pip install --upgrade deeplabcut>, ran the testscript.py, and received two errors.  The first error shows up in the middle of training and the other one at the CREATE VIDEO part.  I have looked into #992 or #1050, but they seem different.  Any suggestions would be greatly appreciated.  Many thanks!\r\n\r\nHere are the errors:\r\nCancelledError (see above for traceback): Enqueue operation was cancelled\r\n[[Node: fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](fifo_queue, _arg_Placeholder_0_0, _arg_Placeholder_1_0_1, _arg_Placeholder_2_0_2, _arg_Placeholder_3_0_3, _arg_Placeholder_4_0_4)]]\r\n\r\nCREATE VIDEO\r\nTraceback (most recent call last):\r\n  File \"testscript.py\", line 107, in <module>\r\n    deeplabcut.create_labeled_video(path_config_file,[newvideo], destfolder=dfolder)\r\nTypeError: create_labeled_video() got an unexpected keyword argument 'destfolder'\r\n\r\n<details><summary>Code output</summary><p>\r\n\r\n[Imported DLC!\r\nCREATING PROJECT\r\nCreated \"C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-12\\videos\"\r\nCreated \"C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-12\\labeled-data\"\r\nCreated \"C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-12\\training-datasets\"\r\nCreated \"C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-12\\dlc-models\"\r\nCopying the videos\r\nC:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-12\\videos\\reachingvideo1.avi\r\nGenerated \"C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-12\\config.yaml\"\r\n\r\nA new project with name TEST-Alex-2021-01-12 is created at C:\\Users\\allenli\\DeepLabCut\\examples and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\r\n Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\r\n. [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\r\nEXTRACTING FRAMES\r\nC:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\frame_extraction.py:100: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\n  cfg = yaml.load(ymlfile)\r\nConfig file read successfully.\r\nExtracting frames based on kmeans ...\r\nKmeans-quantization based extracting of frames from 0.0  seconds to 8.53  seconds.\r\nExtracting and downsampling... 256  frames from the video.\r\n256it [00:01, 251.22it/s]\r\nKmeans clustering ... (this might take a while)\r\n\r\nFrames were selected.\r\nYou can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\r\nCREATING-SOME LABELS FOR THE FRAMES\r\nPlot labels...\r\nCreating images with labels by Alex.\r\nThey are stored in the following folder: C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-12\\labeled-data\\reachingvideo1_labeled.\r\nIf all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\r\nCREATING TRAININGSET\r\nC:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\trainingsetmanipulation.py:328: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\n  docs.append(yaml.load(raw_doc))\r\nThe training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\r\nC:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\deeplabcut\\utils\\auxiliaryfunctions.py:101: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\n  yaml_cfg = yaml.load(f)\r\nCHANGING training parameters to end quickly!\r\nTRAIN\r\nC:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\config.py:43: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\n  yaml_cfg = edict(yaml.load(f))\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['Hand', 'Finger1', 'Finger2', 'Joystick'],\r\n 'batch_size': 1,\r\n 'bottomheight': 400,\r\n 'crop': True,\r\n 'crop_pad': 0,\r\n 'cropratio': 0.4,\r\n 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTJan12\\\\TEST_Alex80shuffle1.mat',\r\n 'dataset_type': 'default',\r\n 'display_iters': 2,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsCPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'leftwidth': 400,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 0.05,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'max_input_size': 1500,\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTJan12\\\\Documentation_data-TEST_80shuffle1.pickle',\r\n 'min_input_size': 64,\r\n 'minsize': 100,\r\n 'mirror': False,\r\n 'multi_step': [[0.001, 10]],\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 4,\r\n 'optimizer': 'sgd',\r\n 'pos_dist_thresh': 17,\r\n 'project_path': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-12',\r\n 'regularize': False,\r\n 'rightwidth': 400,\r\n 'save_iters': 10,\r\n 'scale_jitter_lo': 0.5,\r\n 'scale_jitter_up': 1.25,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-12\\\\dlc-models\\\\iteration-0\\\\TESTJan12-trainset80shuffle1\\\\train\\\\snapshot',\r\n 'stride': 8.0,\r\n 'topheight': 400,\r\n 'use_gt_segm': False,\r\n 'video': False,\r\n 'video_batch': False,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nINFO:tensorflow:Restoring parameters from C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt\r\nRestoring parameters from C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt\r\nTraining parameter:\r\n{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-12\\\\dlc-models\\\\iteration-0\\\\TESTJan12-trainset80shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'dataset_type': 'default', 'use_gt_segm': False, 'batch_size': 1, 'video': False, 'video_batch': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['Hand', 'Finger1', 'Finger2', 'Joystick'], 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTJan12\\\\TEST_Alex80shuffle1.mat', 'display_iters': 2, 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsCPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTJan12\\\\Documentation_data-TEST_80shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.001, 10]], 'net_type': 'resnet_50', 'num_joints': 4, 'pos_dist_thresh': 17, 'project_path': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-12', 'save_iters': 10, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25}\r\nStarting training....\r\niteration: 2 loss: 1.2938 lr: 0.001\r\niteration: 4 loss: 0.6296 lr: 0.001\r\niteration: 6 loss: 0.4733 lr: 0.001\r\niteration: 8 loss: 0.3677 lr: 0.001\r\niteration: 10 loss: 0.2125 lr: 0.001\r\nException in thread Thread-2:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1307, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1409, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\r\n         [[Node: fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](fifo_queue, _arg_Placeholder_0_0, _arg_Placeholder_1_0_1, _arg_Placeholder_2_0_2, _arg_Placeholder_3_0_3, _arg_Placeholder_4_0_4)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 53, in load_and_enqueue\r\n    sess.run(enqueue_op, feed_dict=food)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\r\n         [[Node: fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](fifo_queue, _arg_Placeholder_0_0, _arg_Placeholder_1_0_1, _arg_Placeholder_2_0_2, _arg_Placeholder_3_0_3, _arg_Placeholder_4_0_4)]]\r\n\r\nCaused by op 'fifo_queue_enqueue', defined at:\r\n  File \"testscript.py\", line 81, in <module>\r\n    deeplabcut.train_network(path_config_file)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 79, in train_network\r\n    train(str(poseconfigfile),displayiters,saveiters,maxiters,max_to_keep=max_snapshots_to_keep) #pass on path and file name for pose_cfg.yaml!\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 88, in train\r\n    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 39, in setup_preloading\r\n    enqueue_op = q.enqueue(placeholders_list)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 346, in enqueue\r\n    self._queue_ref, vals, name=scope)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 4373, in queue_enqueue_v2\r\n    timeout_ms=timeout_ms, name=name)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\allenli\\anaconda3\\envs\\dlc-windowsCPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nCancelledError (see above for traceback): Enqueue operation was cancelled\r\n         [[Node: fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](fifo_queue, _arg_Placeholder_0_0, _arg_Placeholder_1_0_1, _arg_Placeholder_2_0_2, _arg_Placeholder_3_0_3, _arg_Placeholder_4_0_4)]]\r\n\r\n\r\nThe network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\r\nEVALUATE\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['Hand', 'Finger1', 'Finger2', 'Joystick'],\r\n 'batch_size': 1,\r\n 'bottomheight': 400,\r\n 'crop': True,\r\n 'crop_pad': 0,\r\n 'cropratio': 0.4,\r\n 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTJan12\\\\TEST_Alex80shuffle1.mat',\r\n 'dataset_type': 'default',\r\n 'display_iters': 2,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsCPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'leftwidth': 400,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 0.05,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'max_input_size': 1500,\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTJan12\\\\Documentation_data-TEST_80shuffle1.pickle',\r\n 'min_input_size': 64,\r\n 'minsize': 100,\r\n 'mirror': False,\r\n 'multi_step': [[0.001, 10]],\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 4,\r\n 'optimizer': 'sgd',\r\n 'pos_dist_thresh': 17,\r\n 'project_path': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-12',\r\n 'regularize': False,\r\n 'rightwidth': 400,\r\n 'save_iters': 10,\r\n 'scale_jitter_lo': 0.5,\r\n 'scale_jitter_up': 1.25,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-12\\\\dlc-models\\\\iteration-0\\\\TESTJan12-trainset80shuffle1\\\\test\\\\snapshot',\r\n 'stride': 8.0,\r\n 'topheight': 400,\r\n 'use_gt_segm': False,\r\n 'video': False,\r\n 'video_batch': False,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nRunning  DeepCut_resnet50_TESTJan12shuffle1_10  with # of trainingiterations: 10\r\nINFO:tensorflow:Restoring parameters from C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-12\\dlc-models\\iteration-0\\TESTJan12-trainset80shuffle1\\train\\snapshot-10\r\nRestoring parameters from C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-12\\dlc-models\\iteration-0\\TESTJan12-trainset80shuffle1\\train\\snapshot-10\r\nAnalyzing data...\r\n5it [00:13,  2.72s/it]\r\nDone and results stored for snapshot:  snapshot-10\r\nResults for 10  training iterations: 80 1 train error: 472.51 pixels. Test error: 388.32  pixels.\r\nWith pcutoff of 0.01  train error: 472.51 pixels. Test error: 388.32 pixels\r\nThereby, the errors are given by the average distances between the labels by DLC and the scorer.\r\nPlotting...\r\nThe network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\r\nIf it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\r\nUse the function 'analyze_video' to make predictions on new videos.\r\nOtherwise consider retraining the network (see DeepLabCut workflow Fig 2)\r\nCUT SHORT VIDEO AND ANALYZE\r\nffmpeg version N-94129-g098ab93257 Copyright (c) 2000-2019 the FFmpeg developers\r\n  built with gcc 9.1.1 (GCC) 20190621\r\n  configuration: --enable-gpl --enable-version3 --enable-sdl2 --enable-fontconfig --enable-gnutls --enable-iconv --enable-libass --enable-libdav1d --enable-libbluray --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopus --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libtheora --enable-libtwolame --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libzimg --enable-lzma --enable-zlib --enable-gmp --enable-libvidstab --enable-libvorbis --enable-libvo-amrwbenc --enable-libmysofa --enable-libspeex --enable-libxvid --enable-libaom --enable-libmfx --enable-amf --enable-ffnvcodec --enable-cuvid --enable-d3d11va --enable-nvenc --enable-nvdec --enable-dxva2 --enable-avisynth --enable-libopenmpt\r\n  libavutil      56. 29.100 / 56. 29.100\r\n  libavcodec     58. 53.100 / 58. 53.100\r\n  libavformat    58. 28.101 / 58. 28.101\r\n  libavdevice    58.  7.100 / 58.  7.100\r\n  libavfilter     7. 55.100 /  7. 55.100\r\n  libswscale      5.  4.101 /  5.  4.101\r\n  libswresample   3.  4.100 /  3.  4.100\r\n  libpostproc    55.  4.100 / 55.  4.100\r\nInput #0, avi, from 'C:\\Users\\allenli\\DeepLabCut\\examples\\Reaching-Mackenzie-2018-08-30\\videos\\reachingvideo1.avi':\r\n  Duration: 00:00:08.53, start: 0.000000, bitrate: 12642 kb/s\r\n    Stream #0:0: Video: mjpeg (Baseline) (MJPG / 0x47504A4D), yuvj420p(pc, bt470bg/unknown/unknown), 832x747 [SAR 1:1 DAR 832:747], 12682 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\r\n    Metadata:\r\n      title           : ImageJ AVI\r\nOutput #0, mp4, to 'C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-12\\videos\\brief.mp4':\r\n  Metadata:\r\n    encoder         : Lavf58.28.101\r\n    Stream #0:0: Video: mjpeg (Baseline) (mp4v / 0x7634706D), yuvj420p(pc, bt470bg/unknown/unknown), 832x747 [SAR 1:1 DAR 832:747], q=2-31, 12682 kb/s, 30 fps, 30 tbr, 15360 tbn, 30 tbc\r\n    Metadata:\r\n      title           : ImageJ AVI\r\nStream mapping:\r\n  Stream #0:0 -> #0:0 (copy)\r\nPress [q] to stop, [?] for help\r\nframe=   12 fps=0.0 q=-1.0 Lsize=     635kB time=00:00:00.36 bitrate=14176.5kbits/s speed=69.2x\r\nvideo:634kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.136212%\r\nConfig:\r\n{'all_joints': [[0], [1], [2], [3]],\r\n 'all_joints_names': ['Hand', 'Finger1', 'Finger2', 'Joystick'],\r\n 'batch_size': 1,\r\n 'bottomheight': 400,\r\n 'crop': True,\r\n 'crop_pad': 0,\r\n 'cropratio': 0.4,\r\n 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTJan12\\\\TEST_Alex80shuffle1.mat',\r\n 'dataset_type': 'default',\r\n 'display_iters': 2,\r\n 'fg_fraction': 0.25,\r\n 'global_scale': 0.8,\r\n 'init_weights': 'C:\\\\Users\\\\allenli\\\\anaconda3\\\\envs\\\\dlc-windowsCPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\r\n 'intermediate_supervision': False,\r\n 'intermediate_supervision_layer': 12,\r\n 'leftwidth': 400,\r\n 'location_refinement': True,\r\n 'locref_huber_loss': True,\r\n 'locref_loss_weight': 0.05,\r\n 'locref_stdev': 7.2801,\r\n 'log_dir': 'log',\r\n 'max_input_size': 1500,\r\n 'mean_pixel': [123.68, 116.779, 103.939],\r\n 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTJan12\\\\Documentation_data-TEST_80shuffle1.pickle',\r\n 'min_input_size': 64,\r\n 'minsize': 100,\r\n 'mirror': False,\r\n 'multi_step': [[0.001, 10]],\r\n 'net_type': 'resnet_50',\r\n 'num_joints': 4,\r\n 'optimizer': 'sgd',\r\n 'pos_dist_thresh': 17,\r\n 'project_path': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-12',\r\n 'regularize': False,\r\n 'rightwidth': 400,\r\n 'save_iters': 10,\r\n 'scale_jitter_lo': 0.5,\r\n 'scale_jitter_up': 1.25,\r\n 'scoremap_dir': 'test',\r\n 'shuffle': True,\r\n 'snapshot_prefix': 'C:\\\\Users\\\\allenli\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2021-01-12\\\\dlc-models\\\\iteration-0\\\\TESTJan12-trainset80shuffle1\\\\test\\\\snapshot',\r\n 'stride': 8.0,\r\n 'topheight': 400,\r\n 'use_gt_segm': False,\r\n 'video': False,\r\n 'video_batch': False,\r\n 'weigh_negatives': False,\r\n 'weigh_only_present_joints': False,\r\n 'weigh_part_predictions': False,\r\n 'weight_decay': 0.0001}\r\nUsing snapshot-10 for model C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-12\\dlc-models\\iteration-0\\TESTJan12-trainset80shuffle1\r\nINFO:tensorflow:Restoring parameters from C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-12\\dlc-models\\iteration-0\\TESTJan12-trainset80shuffle1\\train\\snapshot-10\r\nRestoring parameters from C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-12\\dlc-models\\iteration-0\\TESTJan12-trainset80shuffle1\\train\\snapshot-10\r\nStarting to analyze %  C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-12\\videos\\brief.mp4\r\nLoading  C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-12\\videos\\brief.mp4\r\nDuration of video [s]:  0.4 , recorded with  30.0 fps!\r\nOverall # of frames:  12  found with (before cropping) frame dimensions:  832 747\r\nStarting to extract posture\r\n20it [00:20,  1.05s/it]                                                                                                                                                  Detected frames:  12\r\n\r\nSaving results in C:\\Users\\allenli\\DeepLabCut\\examples\\TEST-Alex-2021-01-12\\videos...\r\nSaving csv poses!\r\nThe videos are analyzed. Now your research can truly start!\r\n You can create labeled videos with 'create_labeled_video'.\r\nIf the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\r\nCREATE VIDEO\r\nTraceback (most recent call last):\r\n  File \"testscript.py\", line 107, in <module>\r\n    deeplabcut.create_labeled_video(path_config_file,[newvideo], destfolder=dfolder)\r\nTypeError: create_labeled_video() got an unexpected keyword argument 'destfolder']\r\n\r\n</p></details>\r\n\r\n**How to Reproduce the problem**\r\nSteps to reproduce the behavior:\r\n1. Go to env 'activate dlc-windowsCPU'\r\n2. run 'python testscript.py'\r\n3. See error","closed_by":{"login":"donglabimaging","id":50585879,"node_id":"MDQ6VXNlcjUwNTg1ODc5","avatar_url":"https://avatars.githubusercontent.com/u/50585879?v=4","gravatar_id":"","url":"https://api.github.com/users/donglabimaging","html_url":"https://github.com/donglabimaging","followers_url":"https://api.github.com/users/donglabimaging/followers","following_url":"https://api.github.com/users/donglabimaging/following{/other_user}","gists_url":"https://api.github.com/users/donglabimaging/gists{/gist_id}","starred_url":"https://api.github.com/users/donglabimaging/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/donglabimaging/subscriptions","organizations_url":"https://api.github.com/users/donglabimaging/orgs","repos_url":"https://api.github.com/users/donglabimaging/repos","events_url":"https://api.github.com/users/donglabimaging/events{/privacy}","received_events_url":"https://api.github.com/users/donglabimaging/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1077/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/1077/timeline","performed_via_github_app":null,"state_reason":"completed"}