{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/791","repository_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut","labels_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/791/labels{/name}","comments_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/791/comments","events_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/791/events","html_url":"https://github.com/DeepLabCut/DeepLabCut/issues/791","id":653546428,"node_id":"MDU6SXNzdWU2NTM1NDY0Mjg=","number":791,"title":"ResourceExhaustedError: OOM","user":{"login":"neurologic","id":4777333,"node_id":"MDQ6VXNlcjQ3NzczMzM=","avatar_url":"https://avatars.githubusercontent.com/u/4777333?v=4","gravatar_id":"","url":"https://api.github.com/users/neurologic","html_url":"https://github.com/neurologic","followers_url":"https://api.github.com/users/neurologic/followers","following_url":"https://api.github.com/users/neurologic/following{/other_user}","gists_url":"https://api.github.com/users/neurologic/gists{/gist_id}","starred_url":"https://api.github.com/users/neurologic/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/neurologic/subscriptions","organizations_url":"https://api.github.com/users/neurologic/orgs","repos_url":"https://api.github.com/users/neurologic/repos","events_url":"https://api.github.com/users/neurologic/events{/privacy}","received_events_url":"https://api.github.com/users/neurologic/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":17,"created_at":"2020-07-08T19:38:04Z","updated_at":"2021-01-08T22:01:37Z","closed_at":"2020-07-08T22:03:53Z","author_association":"NONE","active_lock_reason":null,"body":"**The Train Network Step raised a bunch of exceptions and errors and fails. I then re-tested testscript.py and also got exceptions/errors (but different ones?) during scriptÂ´s test of \"ImageNet-pretrained resnet_50\". Testscript.py does advance past these exceptions to test Evaluate Network, but then finally fails and terminates script with an error ```TypeError: analyze_videos() got an unexpected keyword argument 'cropping' ```**\r\n\r\n**Desktop (please complete the following information about your system):**\r\n - OS: Windows10\r\n- conda environment DLC-GPU.yaml\r\n - DeepLabCut Version 2.2b6 **Note: since there was a fix on my last issue recently merged in master I am working from an updated (git pull) cloned DeepLabCut directory instead of using pip install deeplabcut. deeplabcut.__version__ = 2.2b6 confirmed with import deeplabcut.\r\n\r\n**To Reproduce Train Network error from GUI**\r\n1. Launch GUI with deeplabcut.launch_dlc() and go through the pipeline: \r\ncreate project (multianimal = True); \r\nload videos; \r\nextract frames; \r\nlabel frames; \r\ncheck labels (this was the stage at which I had errors previously with the labels being incorrect in the images. This error is now fixed with the recently updated repo! yay!); create training dataset; \r\ntrain network...\r\n2. See error (as printed in the Anaconda PowerShell):\r\n<details><summary>TraceBack</summary><p>\r\n\r\n```python\r\n2020-07-08 14:22:26.874356: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 10 Chunks of size 9437184 totalling 90.00MiB\r\n2020-07-08 14:22:26.876724: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 20633088 totalling 39.35MiB\r\n2020-07-08 14:22:26.881282: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 1 Chunks of size 141814528 totalling 135.24MiB\r\n2020-07-08 14:22:26.883832: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 10 Chunks of size 187353088 totalling 1.74GiB\r\n2020-07-08 14:22:26.886272: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 1 Chunks of size 263616256 totalling 251.40MiB\r\n2020-07-08 14:22:26.890915: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 5 Chunks of size 749412352 totalling 3.49GiB\r\n2020-07-08 14:22:26.893368: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Sum Total of in-use chunks: 5.98GiB\r\n2020-07-08 14:22:26.895760: I tensorflow/core/common_runtime/bfc_allocator.cc:647] Stats:\r\nLimit:                  6705216225\r\nInUse:                  6423041280\r\nMaxInUse:               6423042560\r\nNumAllocs:                    1298\r\nMaxAllocSize:            749412352\r\n\r\n2020-07-08 14:22:26.903968: W tensorflow/core/common_runtime/bfc_allocator.cc:271] *****__**_*****************************************************************************************x\r\n2020-07-08 14:22:26.907110: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at pad_op.cc:122 : Resource exhausted: OOM when allocating tensor with shape[512,229,405] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n---------------------------------------------------------------------------\r\nResourceExhaustedError                    Traceback (most recent call last)\r\n~\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _do_call(self, fn, *args)\r\n   1333     try:\r\n-> 1334       return fn(*args)\r\n   1335     except errors.OpError as e:\r\n\r\n~\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1318       return self._call_tf_sessionrun(\r\n-> 1319           options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1320\r\n\r\n~\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1406         self._session, options, feed_dict, fetch_list, target_list,\r\n-> 1407         run_metadata)\r\n   1408\r\n\r\nResourceExhaustedError: OOM when allocating tensor with shape[8,227,403,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[{{node resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/Conv2D-1-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[{{node mean_squared_error/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/concat}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nResourceExhaustedError                    Traceback (most recent call last)\r\nD:\\DLC\\DeepLabCut\\deeplabcut\\gui\\train_network.py in train_network(self, event)\r\n    327             displayiters=displayiters,\r\n    328             saveiters=saveiters,\r\n--> 329             maxiters=maxiters,\r\n    330         )\r\n    331\r\n\r\nD:\\DLC\\DeepLabCut\\deeplabcut\\pose_estimation_tensorflow\\training.py in train_network(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\r\n    191\r\n    192     except BaseException as e:\r\n--> 193         raise e\r\n    194     finally:\r\n    195         os.chdir(str(start_path))\r\n\r\nD:\\DLC\\DeepLabCut\\deeplabcut\\pose_estimation_tensorflow\\training.py in train_network(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\r\n    174                 max_to_keep=max_snapshots_to_keep,\r\n    175                 keepdeconvweights=keepdeconvweights,\r\n--> 176                 allow_growth=allow_growth,\r\n    177             )  # pass on path and file name for pose_cfg.yaml!\r\n    178         else:\r\n\r\nD:\\DLC\\DeepLabCut\\deeplabcut\\pose_estimation_tensorflow\\train_multianimal.py in train(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\r\n    215         [_, alllosses, loss_val, summary] = sess.run(\r\n    216             [train_op, losses, total_loss, merged_summaries],\r\n--> 217             feed_dict={learning_rate: current_lr},\r\n    218         )\r\n    219\r\n\r\n~\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    927     try:\r\n    928       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 929                          run_metadata_ptr)\r\n    930       if run_metadata:\r\n    931         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n~\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1150     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1151       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1152                              feed_dict_tensor, options, run_metadata)\r\n   1153     else:\r\n   1154       results = []\r\n\r\n~\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1326     if handle is None:\r\n   1327       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1328                            run_metadata)\r\n   1329     else:\r\n   1330       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\n~\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _do_call(self, fn, *args)\r\n   1346           pass\r\n   1347       message = error_interpolation.interpolate(message, self._graph)\r\n-> 1348       raise type(e)(node_def, op, message)\r\n   1349\r\n   1350   def _extend_graph(self):\r\n\r\nResourceExhaustedError: OOM when allocating tensor with shape[8,227,403,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[{{node resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/Conv2D-1-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[node mean_squared_error/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/concat (defined at D:\\DLC\\DeepLabCut\\deeplabcut\\pose_estimation_tensorflow\\nnet\\pose_net.py:323) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n```\r\n</p></details>\r\n\r\n**I then ran ```python testscript.py``` from within the \\examples\\ directory to see if it would illuminate anything about my error encountered when trying to do the Train Network step from the GUI**\r\n[NOTE: testscript.py was previously successful on my machine in this OS/environment before updating the cloned repo to get the merged fixes. I donÂ´t think anything else has changed since then. Though after the first round of having the training network stage fail I removed the DLC-GPU environment and deleted the repo locally and then re-created the environment from a fresh .yaml download file and freshly cloned the DeepLabCut repo to work from. Failure to train network persisted after this fresh re-\"install\".\r\nSee error from where testscript.py failed/terminated: \r\n(printed in the Anaconda PowerShell):\r\n<details><summary>TraceBack</summary><p>\r\n\r\n```python\r\n\r\nInitializing ResNet\r\nLoading ImageNet-pretrained resnet_50\r\nTraining parameter:\r\n{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'D:\\\\DLC\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2020-07-08\\\\dlc-models\\\\iteration-1\\\\TESTJul8-trainset80shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'imgaug', 'deterministic': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3', 'objectA'], 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_TESTJul8\\\\TEST_Alex80shuffle1.mat', 'display_iters': 1, 'init_weights': 'C:\\\\Users\\\\kperks\\\\Anaconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_TESTJul8\\\\Documentation_data-TEST_80shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.001, 5]], 'net_type': 'resnet_50', 'num_joints': 4, 'pos_dist_thresh': 17, 'project_path': 'D:\\\\DLC\\\\DeepLabCut\\\\examples\\\\TEST-Alex-2020-07-08', 'save_iters': 5, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'output_stride': 16, 'deconvolutionstride': 2, 'num_outputs': 1, 'Task': None, 'scorer': None, 'date': None, 'video_sets': None, 'bodyparts': None, 'start': None, 'stop': None, 'numframes2pick': None, 'skeleton': [], 'skeleton_color': 'black', 'pcutoff': None, 'dotsize': None, 'alphavalue': None, 'colormap': None, 'TrainingFraction': None, 'iteration': None, 'resnet': None, 'snapshotindex': None, 'cropping': None, 'x1': None, 'x2': None, 'y1': None, 'y2': None, 'corner2move2': None, 'move2corner': None}\r\nStarting training....\r\niteration: 1 loss: 1.8074 lr: 0.001\r\niteration: 2 loss: 0.7578 lr: 0.001\r\niteration: 3 loss: 0.6583 lr: 0.001\r\niteration: 4 loss: 0.5593 lr: 0.001\r\niteration: 5 loss: 0.4439 lr: 0.001\r\nException in thread Thread-9:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\r\n         [[{{node fifo_queue_enqueue}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 81, in load_and_enqueue\r\n    sess.run(enqueue_op, feed_dict=food)\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\r\n         [[node fifo_queue_enqueue (defined at C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:67) ]]\r\n\r\nCaused by op 'fifo_queue_enqueue', defined at:\r\n  File \"testscript.py\", line 265, in <module>\r\n    deeplabcut.train_network(path_config_file)\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 132, in train_network\r\n    train(str(poseconfigfile),displayiters,saveiters,maxiters,max_to_keep=max_snapshots_to_keep,keepdeconvweights=keepdeconvweights,allow_growth=allow_growth) #pass on path and file name for pose_cfg.yaml!\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 118, in train\r\n    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 67, in setup_preloading\r\n    enqueue_op = q.enqueue(placeholders_list)\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 345, in enqueue\r\n    self._queue_ref, vals, name=scope)\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 4158, in queue_enqueue_v2\r\n    timeout_ms=timeout_ms, name=name)\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nCancelledError (see above for traceback): Enqueue operation was cancelled\r\n         [[node fifo_queue_enqueue (defined at C:\\Users\\kperks\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:67) ]]\r\n\r\n\r\nThe network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\r\nSlicing and saving to name D:\\DLC\\DeepLabCut\\examples\\TEST-Alex-2020-07-08\\videos\\reachingvideo1short2.avi\r\nffmpeg version git-2020-06-20-29ea4e1 Copyright (c) 2000-2020 the FFmpeg developers\r\n  built with gcc 9.3.1 (GCC) 20200523\r\n  configuration: --enable-gpl --enable-version3 --enable-sdl2 --enable-fontconfig --enable-gnutls --enable-iconv --enable-libass --enable-libdav1d --enable-libbluray --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopus --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libsrt --enable-libtheora --enable-libtwolame --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libzimg --enable-lzma --enable-zlib --enable-gmp --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvo-amrwbenc --enable-libmysofa --enable-libspeex --enable-libxvid --enable-libaom --enable-libgsm --disable-w32threads --enable-libmfx --enable-ffnvcodec --enable-cuda-llvm --enable-cuvid --enable-d3d11va --enable-nvenc --enable-nvdec --enable-dxva2 --enable-avisynth --enable-libopenmpt --enable-amf\r\n  libavutil      56. 55.100 / 56. 55.100\r\n  libavcodec     58. 93.100 / 58. 93.100\r\n  libavformat    58. 47.100 / 58. 47.100\r\n  libavdevice    58. 11.100 / 58. 11.100\r\n  libavfilter     7. 86.100 /  7. 86.100\r\n  libswscale      5.  8.100 /  5.  8.100\r\n  libswresample   3.  8.100 /  3.  8.100\r\n  libpostproc    55.  8.100 / 55.  8.100\r\nInput #0, avi, from 'D:\\DLC\\DeepLabCut\\examples\\Reaching-Mackenzie-2018-08-30\\videos\\reachingvideo1.avi':\r\n  Duration: 00:00:08.53, start: 0.000000, bitrate: 12642 kb/s\r\n    Stream #0:0: Video: mjpeg (Baseline) (MJPG / 0x47504A4D), yuvj420p(pc, bt470bg/unknown/unknown), 832x747 [SAR 1:1 DAR 832:747], 12682 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\r\n    Metadata:\r\n      title           : ImageJ AVI\r\nStream mapping:\r\n  Stream #0:0 -> #0:0 (mjpeg (native) -> mpeg4 (native))\r\nPress [q] to stop, [?] for help\r\n[swscaler @ 000002492d4857c0] deprecated pixel format used, make sure you did set range correctly\r\nOutput #0, avi, to 'D:\\DLC\\DeepLabCut\\examples\\TEST-Alex-2020-07-08\\videos\\reachingvideo1short2.avi':\r\n  Metadata:\r\n    ISFT            : Lavf58.47.100\r\n    Stream #0:0: Video: mpeg4 (FMP4 / 0x34504D46), yuv420p, 832x747 [SAR 1:1 DAR 832:747], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc\r\n    Metadata:\r\n      title           : ImageJ AVI\r\n      encoder         : Lavc58.93.100 mpeg4\r\n    Side data:\r\n      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: N/A\r\nframe=   12 fps=0.0 q=24.4 Lsize=     199kB time=00:00:00.40 bitrate=4070.4kbits/s speed=4.26x\r\nvideo:193kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.080492%\r\nInference with direct cropping\r\nTraceback (most recent call last):\r\n  File \"testscript.py\", line 299, in <module>\r\n    cropping=[0, 50, 0, 50],\r\nTypeError: analyze_videos() got an unexpected keyword argument 'cropping'\r\n```\r\n</p></details>\r\n\r\n\r\n","closed_by":{"login":"MMathisLab","id":28102185,"node_id":"MDQ6VXNlcjI4MTAyMTg1","avatar_url":"https://avatars.githubusercontent.com/u/28102185?v=4","gravatar_id":"","url":"https://api.github.com/users/MMathisLab","html_url":"https://github.com/MMathisLab","followers_url":"https://api.github.com/users/MMathisLab/followers","following_url":"https://api.github.com/users/MMathisLab/following{/other_user}","gists_url":"https://api.github.com/users/MMathisLab/gists{/gist_id}","starred_url":"https://api.github.com/users/MMathisLab/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MMathisLab/subscriptions","organizations_url":"https://api.github.com/users/MMathisLab/orgs","repos_url":"https://api.github.com/users/MMathisLab/repos","events_url":"https://api.github.com/users/MMathisLab/events{/privacy}","received_events_url":"https://api.github.com/users/MMathisLab/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/791/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/DeepLabCut/DeepLabCut/issues/791/timeline","performed_via_github_app":null,"state_reason":"completed"}