[{"id":2880200764,"node_id":"MDEyOkxhYmVsZWRFdmVudDI4ODAyMDA3NjQ=","url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/events/2880200764","actor":{"login":"eric-haibin-lin","id":5545640,"node_id":"MDQ6VXNlcjU1NDU2NDA=","avatar_url":"https://avatars.githubusercontent.com/u/5545640?v=4","gravatar_id":"","url":"https://api.github.com/users/eric-haibin-lin","html_url":"https://github.com/eric-haibin-lin","followers_url":"https://api.github.com/users/eric-haibin-lin/followers","following_url":"https://api.github.com/users/eric-haibin-lin/following{/other_user}","gists_url":"https://api.github.com/users/eric-haibin-lin/gists{/gist_id}","starred_url":"https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eric-haibin-lin/subscriptions","organizations_url":"https://api.github.com/users/eric-haibin-lin/orgs","repos_url":"https://api.github.com/users/eric-haibin-lin/repos","events_url":"https://api.github.com/users/eric-haibin-lin/events{/privacy}","received_events_url":"https://api.github.com/users/eric-haibin-lin/received_events","type":"User","site_admin":false},"event":"labeled","commit_id":null,"commit_url":null,"created_at":"2019-12-13T05:04:39Z","label":{"name":"enhancement","color":"135caf"},"performed_via_github_app":null},{"id":2880200765,"node_id":"MDEyOkxhYmVsZWRFdmVudDI4ODAyMDA3NjU=","url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/events/2880200765","actor":{"login":"eric-haibin-lin","id":5545640,"node_id":"MDQ6VXNlcjU1NDU2NDA=","avatar_url":"https://avatars.githubusercontent.com/u/5545640?v=4","gravatar_id":"","url":"https://api.github.com/users/eric-haibin-lin","html_url":"https://github.com/eric-haibin-lin","followers_url":"https://api.github.com/users/eric-haibin-lin/followers","following_url":"https://api.github.com/users/eric-haibin-lin/following{/other_user}","gists_url":"https://api.github.com/users/eric-haibin-lin/gists{/gist_id}","starred_url":"https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eric-haibin-lin/subscriptions","organizations_url":"https://api.github.com/users/eric-haibin-lin/orgs","repos_url":"https://api.github.com/users/eric-haibin-lin/repos","events_url":"https://api.github.com/users/eric-haibin-lin/events{/privacy}","received_events_url":"https://api.github.com/users/eric-haibin-lin/received_events","type":"User","site_admin":false},"event":"labeled","commit_id":null,"commit_url":null,"created_at":"2019-12-13T05:04:39Z","label":{"name":"discussion","color":"c5def5"},"performed_via_github_app":null},{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/comments/565303530","html_url":"https://github.com/dmlc/gluon-nlp/issues/1043#issuecomment-565303530","issue_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1043","id":565303530,"node_id":"MDEyOklzc3VlQ29tbWVudDU2NTMwMzUzMA==","user":{"login":"leezu","id":946903,"node_id":"MDQ6VXNlcjk0NjkwMw==","avatar_url":"https://avatars.githubusercontent.com/u/946903?v=4","gravatar_id":"","url":"https://api.github.com/users/leezu","html_url":"https://github.com/leezu","followers_url":"https://api.github.com/users/leezu/followers","following_url":"https://api.github.com/users/leezu/following{/other_user}","gists_url":"https://api.github.com/users/leezu/gists{/gist_id}","starred_url":"https://api.github.com/users/leezu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leezu/subscriptions","organizations_url":"https://api.github.com/users/leezu/orgs","repos_url":"https://api.github.com/users/leezu/repos","events_url":"https://api.github.com/users/leezu/events{/privacy}","received_events_url":"https://api.github.com/users/leezu/received_events","type":"User","site_admin":false},"created_at":"2019-12-13T05:14:45Z","updated_at":"2019-12-13T05:14:45Z","author_association":"CONTRIBUTOR","body":"Yes, it's commonly needed to access the pre-trained tokenizer.\r\nSome API in the scripts folder also returns the tokenizer as part of `get_model`. For example\r\n\r\nhttps://github.com/dmlc/gluon-nlp/blob/aff29217d4a1233d9b5a069366e2b80e30184e30/scripts/language_model/transformer/model.py#L198-L252\r\n\r\nBut I'm not sure if this a good API","reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/comments/565303530/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"leezu","id":946903,"node_id":"MDQ6VXNlcjk0NjkwMw==","avatar_url":"https://avatars.githubusercontent.com/u/946903?v=4","gravatar_id":"","url":"https://api.github.com/users/leezu","html_url":"https://github.com/leezu","followers_url":"https://api.github.com/users/leezu/followers","following_url":"https://api.github.com/users/leezu/following{/other_user}","gists_url":"https://api.github.com/users/leezu/gists{/gist_id}","starred_url":"https://api.github.com/users/leezu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leezu/subscriptions","organizations_url":"https://api.github.com/users/leezu/orgs","repos_url":"https://api.github.com/users/leezu/repos","events_url":"https://api.github.com/users/leezu/events{/privacy}","received_events_url":"https://api.github.com/users/leezu/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/comments/565315525","html_url":"https://github.com/dmlc/gluon-nlp/issues/1043#issuecomment-565315525","issue_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1043","id":565315525,"node_id":"MDEyOklzc3VlQ29tbWVudDU2NTMxNTUyNQ==","user":{"login":"eric-haibin-lin","id":5545640,"node_id":"MDQ6VXNlcjU1NDU2NDA=","avatar_url":"https://avatars.githubusercontent.com/u/5545640?v=4","gravatar_id":"","url":"https://api.github.com/users/eric-haibin-lin","html_url":"https://github.com/eric-haibin-lin","followers_url":"https://api.github.com/users/eric-haibin-lin/followers","following_url":"https://api.github.com/users/eric-haibin-lin/following{/other_user}","gists_url":"https://api.github.com/users/eric-haibin-lin/gists{/gist_id}","starred_url":"https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eric-haibin-lin/subscriptions","organizations_url":"https://api.github.com/users/eric-haibin-lin/orgs","repos_url":"https://api.github.com/users/eric-haibin-lin/repos","events_url":"https://api.github.com/users/eric-haibin-lin/events{/privacy}","received_events_url":"https://api.github.com/users/eric-haibin-lin/received_events","type":"User","site_admin":false},"created_at":"2019-12-13T06:15:28Z","updated_at":"2019-12-13T06:15:28Z","author_association":"MEMBER","body":"I think it's more convenient than the current one. Users are free to discard it if they want to change it. Are there use cases where we want to change the tokenizer? ","reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/comments/565315525/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"eric-haibin-lin","id":5545640,"node_id":"MDQ6VXNlcjU1NDU2NDA=","avatar_url":"https://avatars.githubusercontent.com/u/5545640?v=4","gravatar_id":"","url":"https://api.github.com/users/eric-haibin-lin","html_url":"https://github.com/eric-haibin-lin","followers_url":"https://api.github.com/users/eric-haibin-lin/followers","following_url":"https://api.github.com/users/eric-haibin-lin/following{/other_user}","gists_url":"https://api.github.com/users/eric-haibin-lin/gists{/gist_id}","starred_url":"https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eric-haibin-lin/subscriptions","organizations_url":"https://api.github.com/users/eric-haibin-lin/orgs","repos_url":"https://api.github.com/users/eric-haibin-lin/repos","events_url":"https://api.github.com/users/eric-haibin-lin/events{/privacy}","received_events_url":"https://api.github.com/users/eric-haibin-lin/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/comments/565316006","html_url":"https://github.com/dmlc/gluon-nlp/issues/1043#issuecomment-565316006","issue_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1043","id":565316006,"node_id":"MDEyOklzc3VlQ29tbWVudDU2NTMxNjAwNg==","user":{"login":"eric-haibin-lin","id":5545640,"node_id":"MDQ6VXNlcjU1NDU2NDA=","avatar_url":"https://avatars.githubusercontent.com/u/5545640?v=4","gravatar_id":"","url":"https://api.github.com/users/eric-haibin-lin","html_url":"https://github.com/eric-haibin-lin","followers_url":"https://api.github.com/users/eric-haibin-lin/followers","following_url":"https://api.github.com/users/eric-haibin-lin/following{/other_user}","gists_url":"https://api.github.com/users/eric-haibin-lin/gists{/gist_id}","starred_url":"https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eric-haibin-lin/subscriptions","organizations_url":"https://api.github.com/users/eric-haibin-lin/orgs","repos_url":"https://api.github.com/users/eric-haibin-lin/repos","events_url":"https://api.github.com/users/eric-haibin-lin/events{/privacy}","received_events_url":"https://api.github.com/users/eric-haibin-lin/received_events","type":"User","site_admin":false},"created_at":"2019-12-13T06:17:41Z","updated_at":"2019-12-13T06:17:41Z","author_association":"MEMBER","body":"For reference, fairseq's RoBERTa's encoding function takes a string as the input. The model object holds the tokenizer, and applies the tokenizer directly on the input string. It might be hard to modify the tokenization method there, but I do see they couple the pre-trained model and tokenizer","reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/comments/565316006/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"eric-haibin-lin","id":5545640,"node_id":"MDQ6VXNlcjU1NDU2NDA=","avatar_url":"https://avatars.githubusercontent.com/u/5545640?v=4","gravatar_id":"","url":"https://api.github.com/users/eric-haibin-lin","html_url":"https://github.com/eric-haibin-lin","followers_url":"https://api.github.com/users/eric-haibin-lin/followers","following_url":"https://api.github.com/users/eric-haibin-lin/following{/other_user}","gists_url":"https://api.github.com/users/eric-haibin-lin/gists{/gist_id}","starred_url":"https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eric-haibin-lin/subscriptions","organizations_url":"https://api.github.com/users/eric-haibin-lin/orgs","repos_url":"https://api.github.com/users/eric-haibin-lin/repos","events_url":"https://api.github.com/users/eric-haibin-lin/events{/privacy}","received_events_url":"https://api.github.com/users/eric-haibin-lin/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/comments/565318589","html_url":"https://github.com/dmlc/gluon-nlp/issues/1043#issuecomment-565318589","issue_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1043","id":565318589,"node_id":"MDEyOklzc3VlQ29tbWVudDU2NTMxODU4OQ==","user":{"login":"leezu","id":946903,"node_id":"MDQ6VXNlcjk0NjkwMw==","avatar_url":"https://avatars.githubusercontent.com/u/946903?v=4","gravatar_id":"","url":"https://api.github.com/users/leezu","html_url":"https://github.com/leezu","followers_url":"https://api.github.com/users/leezu/followers","following_url":"https://api.github.com/users/leezu/following{/other_user}","gists_url":"https://api.github.com/users/leezu/gists{/gist_id}","starred_url":"https://api.github.com/users/leezu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leezu/subscriptions","organizations_url":"https://api.github.com/users/leezu/orgs","repos_url":"https://api.github.com/users/leezu/repos","events_url":"https://api.github.com/users/leezu/events{/privacy}","received_events_url":"https://api.github.com/users/leezu/received_events","type":"User","site_admin":false},"created_at":"2019-12-13T06:28:45Z","updated_at":"2019-12-13T06:28:45Z","author_association":"CONTRIBUTOR","body":"> I think it's more convenient than the current one. Users are free to discard it if they want to change it. Are there use cases where we want to change the tokenizer?\r\n\r\nYes, but those involve initializing the model randomly and training it.\r\n\r\nA better API may be to have separate functions for obtaining each of pretrained model, vocab and tokenizer.","reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/comments/565318589/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"leezu","id":946903,"node_id":"MDQ6VXNlcjk0NjkwMw==","avatar_url":"https://avatars.githubusercontent.com/u/946903?v=4","gravatar_id":"","url":"https://api.github.com/users/leezu","html_url":"https://github.com/leezu","followers_url":"https://api.github.com/users/leezu/followers","following_url":"https://api.github.com/users/leezu/following{/other_user}","gists_url":"https://api.github.com/users/leezu/gists{/gist_id}","starred_url":"https://api.github.com/users/leezu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leezu/subscriptions","organizations_url":"https://api.github.com/users/leezu/orgs","repos_url":"https://api.github.com/users/leezu/repos","events_url":"https://api.github.com/users/leezu/events{/privacy}","received_events_url":"https://api.github.com/users/leezu/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/comments/565545055","html_url":"https://github.com/dmlc/gluon-nlp/issues/1043#issuecomment-565545055","issue_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1043","id":565545055,"node_id":"MDEyOklzc3VlQ29tbWVudDU2NTU0NTA1NQ==","user":{"login":"sxjscience","id":5178350,"node_id":"MDQ6VXNlcjUxNzgzNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5178350?v=4","gravatar_id":"","url":"https://api.github.com/users/sxjscience","html_url":"https://github.com/sxjscience","followers_url":"https://api.github.com/users/sxjscience/followers","following_url":"https://api.github.com/users/sxjscience/following{/other_user}","gists_url":"https://api.github.com/users/sxjscience/gists{/gist_id}","starred_url":"https://api.github.com/users/sxjscience/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sxjscience/subscriptions","organizations_url":"https://api.github.com/users/sxjscience/orgs","repos_url":"https://api.github.com/users/sxjscience/repos","events_url":"https://api.github.com/users/sxjscience/events{/privacy}","received_events_url":"https://api.github.com/users/sxjscience/received_events","type":"User","site_admin":false},"created_at":"2019-12-13T18:03:52Z","updated_at":"2019-12-13T18:03:52Z","author_association":"MEMBER","body":"In terms of the pretrained model, we should include:\r\n- model configuration\r\n- vocab + tokenizer\r\n- weights\r\n\r\nThis should be the format used in TF hub: https://tfhub.dev/google/albert_base/2\r\n\r\nIf the user needs to pretrain from scratch, we will provide another script to do so and teaches the user about how to train your own subword tokenizer + train with your own data. ","reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/comments/565545055/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"sxjscience","id":5178350,"node_id":"MDQ6VXNlcjUxNzgzNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5178350?v=4","gravatar_id":"","url":"https://api.github.com/users/sxjscience","html_url":"https://github.com/sxjscience","followers_url":"https://api.github.com/users/sxjscience/followers","following_url":"https://api.github.com/users/sxjscience/following{/other_user}","gists_url":"https://api.github.com/users/sxjscience/gists{/gist_id}","starred_url":"https://api.github.com/users/sxjscience/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sxjscience/subscriptions","organizations_url":"https://api.github.com/users/sxjscience/orgs","repos_url":"https://api.github.com/users/sxjscience/repos","events_url":"https://api.github.com/users/sxjscience/events{/privacy}","received_events_url":"https://api.github.com/users/sxjscience/received_events","type":"User","site_admin":false}}]