{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1549","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1549/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1549/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1549/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/1549","id":858056075,"node_id":"MDU6SXNzdWU4NTgwNTYwNzU=","number":1549,"title":"Loading 'distilbert_6_768_12' is broken","user":{"login":"craffel","id":417568,"node_id":"MDQ6VXNlcjQxNzU2OA==","avatar_url":"https://avatars.githubusercontent.com/u/417568?v=4","gravatar_id":"","url":"https://api.github.com/users/craffel","html_url":"https://github.com/craffel","followers_url":"https://api.github.com/users/craffel/followers","following_url":"https://api.github.com/users/craffel/following{/other_user}","gists_url":"https://api.github.com/users/craffel/gists{/gist_id}","starred_url":"https://api.github.com/users/craffel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/craffel/subscriptions","organizations_url":"https://api.github.com/users/craffel/orgs","repos_url":"https://api.github.com/users/craffel/repos","events_url":"https://api.github.com/users/craffel/events{/privacy}","received_events_url":"https://api.github.com/users/craffel/received_events","type":"User","site_admin":false},"labels":[{"id":890393501,"node_id":"MDU6TGFiZWw4OTAzOTM1MDE=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-04-14T16:19:44Z","updated_at":"2021-04-15T16:22:46Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"## Description\r\n\r\nThe example code at https://nlp.gluon.ai/model_zoo/bert/index.html for the DistilBERT model produces an exception at HEAD.\r\n\r\n### Error Message\r\n\r\n```\r\n---------------------------------------------------------------------------\r\n\r\nValueError                                Traceback (most recent call last)\r\n\r\n<ipython-input-1-fbb321631ad8> in <module>()\r\n      2 get_ipython().system('pip install mxnet')\r\n      3 import gluonnlp as nlp; import mxnet as mx;\r\n----> 4 model, vocab = nlp.model.get_model('distilbert_6_768_12', dataset_name='distil_book_corpus_wiki_en_uncased')\r\n\r\n5 frames\r\n\r\n/usr/local/lib/python3.7/dist-packages/gluonnlp/model/__init__.py in get_model(name, **kwargs)\r\n    154             'Model %s is not supported. Available options are\\n\\t%s'%(\r\n    155                 name, '\\n\\t'.join(sorted(models.keys()))))\r\n--> 156     return models[name](**kwargs)\r\n\r\n/usr/local/lib/python3.7/dist-packages/gluonnlp/model/bert.py in distilbert_6_768_12(dataset_name, vocab, pretrained, ctx, output_attention, output_all_encodings, root, hparam_allow_override, **kwargs)\r\n   1311 \r\n   1312     from ..vocab import Vocab  # pylint: disable=import-outside-toplevel\r\n-> 1313     bert_vocab = _load_vocab(dataset_name, vocab, root, cls=Vocab)\r\n   1314     # DistilBERT\r\n   1315     net = DistilBERTModel(encoder, len(bert_vocab),\r\n\r\n/usr/local/lib/python3.7/dist-packages/gluonnlp/model/utils.py in _load_vocab(dataset_name, vocab, root, cls)\r\n    269                           'Loading vocab based on dataset_name. '\r\n    270                           'Input \"vocab\" argument will be ignored.')\r\n--> 271         vocab = _load_pretrained_vocab(dataset_name, root, cls)\r\n    272     else:\r\n    273         assert vocab is not None, 'Must specify vocab if not loading from predefined datasets.'\r\n\r\n/usr/local/lib/python3.7/dist-packages/gluonnlp/data/utils.py in _load_pretrained_vocab(name, root, cls)\r\n    387         Loaded vocabulary object and Tokenizer for the pre-trained model.\r\n    388     \"\"\"\r\n--> 389     file_name, file_ext, sha1_hash, special_tokens = _get_vocab_tokenizer_info(name, root)\r\n    390     file_path = os.path.join(root, file_name + file_ext)\r\n    391     if os.path.exists(file_path):\r\n\r\n/usr/local/lib/python3.7/dist-packages/gluonnlp/data/utils.py in _get_vocab_tokenizer_info(name, root)\r\n    346 def _get_vocab_tokenizer_info(name, root):\r\n    347     file_name = '{name}-{short_hash}'.format(name=name,\r\n--> 348                                              short_hash=short_hash(name))\r\n    349     root = os.path.expanduser(root)\r\n    350     sha1_hash, file_ext, special_tokens = _vocab_sha1[name]\r\n\r\n/usr/local/lib/python3.7/dist-packages/gluonnlp/data/utils.py in short_hash(name)\r\n    340         raise ValueError('Vocabulary for {name} is not available. '\r\n    341                          'Hosted vocabularies include: {vocabs}'.format(name=name,\r\n--> 342                                                                         vocabs=vocabs))\r\n    343     return _vocab_sha1[name][0][:8]\r\n    344 \r\n\r\nValueError: Vocabulary for distil_book_corpus_wiki_en_uncased is not available. Hosted vocabularies include: ['wikitext-2', 'gbw', 'WMT2014_src', 'WMT2014_tgt', 'book_corpus_wiki_en_cased', 'book_corpus_wiki_en_uncased', 'openwebtext_book_corpus_wiki_en_uncased', 'openwebtext_ccnews_stories_books_cased', 'wiki_multilingual_cased', 'distilbert_book_corpus_wiki_en_uncased', 'wiki_cn_cased', 'wiki_multilingual_uncased', 'scibert_scivocab_uncased', 'scibert_scivocab_cased', 'scibert_basevocab_uncased', 'scibert_basevocab_cased', 'biobert_v1.0_pmc_cased', 'biobert_v1.0_pubmed_cased', 'biobert_v1.0_pubmed_pmc_cased', 'biobert_v1.1_pubmed_cased', 'clinicalbert_uncased', 'baidu_ernie_uncased', 'openai_webtext', 'xlnet_126gb', 'kobert_news_wiki_ko_cased']\r\n```\r\n\r\n## To Reproduce\r\n\r\nHere is a colab: https://colab.research.google.com/drive/1PhShfNvXWQIzPbBiSZwo3uwfNzv2n0UJ?usp=sharing\r\nIt is as simple as\r\n\r\n```\r\n!pip install gluonnlp\r\n!pip install mxnet\r\nimport gluonnlp as nlp; import mxnet as mx;\r\nmodel, vocab = nlp.model.get_model('distilbert_6_768_12', dataset_name='distil_book_corpus_wiki_en_uncased')\r\n```\r\n\r\n### Steps to reproduce\r\n(Paste the commands you ran that produced the error.)\r\n\r\n```\r\n!pip install gluonnlp\r\n!pip install mxnet\r\nimport gluonnlp as nlp; import mxnet as mx;\r\nmodel, vocab = nlp.model.get_model('distilbert_6_768_12', dataset_name='distil_book_corpus_wiki_en_uncased')\r\n```\r\n\r\n## What have you tried to solve it?\r\n\r\n1. I tried other models, they worked.\r\n2. I tried replacing the dataset_name with `book_corpus_wiki_en_uncased` which did not work\r\n\r\n## Environment\r\n\r\nWe recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\r\n```\r\ncurl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\r\n\r\n# paste outputs here\r\n```\r\n\r\nThis script (https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py) does not exist, it gives a 404.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1549/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1549/timeline","performed_via_github_app":null,"state_reason":null}