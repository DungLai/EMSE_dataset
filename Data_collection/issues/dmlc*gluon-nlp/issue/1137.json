{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1137","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1137/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1137/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1137/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/1137","id":558656918,"node_id":"MDU6SXNzdWU1NTg2NTY5MTg=","number":1137,"title":"flaky test: test_sequence_sampler","user":{"login":"eric-haibin-lin","id":5545640,"node_id":"MDQ6VXNlcjU1NDU2NDA=","avatar_url":"https://avatars.githubusercontent.com/u/5545640?v=4","gravatar_id":"","url":"https://api.github.com/users/eric-haibin-lin","html_url":"https://github.com/eric-haibin-lin","followers_url":"https://api.github.com/users/eric-haibin-lin/followers","following_url":"https://api.github.com/users/eric-haibin-lin/following{/other_user}","gists_url":"https://api.github.com/users/eric-haibin-lin/gists{/gist_id}","starred_url":"https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eric-haibin-lin/subscriptions","organizations_url":"https://api.github.com/users/eric-haibin-lin/orgs","repos_url":"https://api.github.com/users/eric-haibin-lin/repos","events_url":"https://api.github.com/users/eric-haibin-lin/events{/privacy}","received_events_url":"https://api.github.com/users/eric-haibin-lin/received_events","type":"User","site_admin":false},"labels":[{"id":890393501,"node_id":"MDU6TGFiZWw4OTAzOTM1MDE=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":1516016541,"node_id":"MDU6TGFiZWwxNTE2MDE2NTQx","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/CI","name":"CI","color":"e884d9","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-02-02T07:37:36Z","updated_at":"2020-02-02T07:37:36Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"https://ci.mxnet.io/blue/organizations/jenkins/GluonNLP-py3-master-cpu-unittest/detail/PR-922/15/pipeline\r\n\r\n```\r\n[2020-02-02T07:32:53.166Z] =================================== FAILURES ===================================\r\n\r\n[2020-02-02T07:32:53.166Z] _________________________ test_sequence_sampler[None] __________________________\r\n\r\n[2020-02-02T07:32:53.166Z] \r\n\r\n[2020-02-02T07:32:53.166Z] top_k = None\r\n\r\n[2020-02-02T07:32:53.166Z] \r\n\r\n[2020-02-02T07:32:53.166Z]     @pytest.mark.serial\r\n\r\n[2020-02-02T07:32:53.166Z]     @pytest.mark.parametrize('top_k', [None, 5])\r\n\r\n[2020-02-02T07:32:53.166Z]     def test_sequence_sampler(top_k):\r\n\r\n[2020-02-02T07:32:53.166Z]         vocab_size = np.random.randint(5, 20)\r\n\r\n[2020-02-02T07:32:53.166Z]         batch_size = 1000\r\n\r\n[2020-02-02T07:32:53.166Z]         dist = mx.random.uniform(shape=(vocab_size,))\r\n\r\n[2020-02-02T07:32:53.166Z]         def context_free_distribution(step_input, states):\r\n\r\n[2020-02-02T07:32:53.166Z]             batch_size = step_input.shape[0]\r\n\r\n[2020-02-02T07:32:53.166Z]             return dist.expand_dims(0).broadcast_to(shape=(batch_size, vocab_size)), states\r\n\r\n[2020-02-02T07:32:53.166Z]         sampler = model.SequenceSampler(2, context_free_distribution, vocab_size+1, max_length=500,\r\n\r\n[2020-02-02T07:32:53.166Z]                                         top_k=top_k)\r\n\r\n[2020-02-02T07:32:53.166Z] >       samples, _, _ = sampler(mx.nd.ones((batch_size,)), mx.nd.ones((batch_size,)))\r\n\r\n[2020-02-02T07:32:53.166Z] \r\n\r\n[2020-02-02T07:32:53.166Z] tests/unittest/test_sequence_sampler.py:41: \r\n\r\n[2020-02-02T07:32:53.166Z] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\n[2020-02-02T07:32:53.166Z] src/gluonnlp/model/sequence_sampler.py:803: in __call__\r\n\r\n[2020-02-02T07:32:53.166Z]     if mx.nd.sum(beam_alive_mask).asscalar() == 0:\r\n\r\n[2020-02-02T07:32:53.166Z] conda/cpu/py3-master/lib/python3.5/site-packages/mxnet/ndarray/ndarray.py:2572: in asscalar\r\n\r\n[2020-02-02T07:32:53.166Z]     return self.asnumpy()[0]\r\n\r\n[2020-02-02T07:32:53.166Z] conda/cpu/py3-master/lib/python3.5/site-packages/mxnet/ndarray/ndarray.py:2554: in asnumpy\r\n\r\n[2020-02-02T07:32:53.166Z]     ctypes.c_size_t(data.size)))\r\n\r\n[2020-02-02T07:32:53.166Z] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\n[2020-02-02T07:32:53.166Z] \r\n\r\n[2020-02-02T07:32:53.166Z] ret = -1\r\n\r\n[2020-02-02T07:32:53.166Z] \r\n\r\n[2020-02-02T07:32:53.166Z]     def check_call(ret):\r\n\r\n[2020-02-02T07:32:53.166Z]         \"\"\"Check the return value of C API call.\r\n\r\n[2020-02-02T07:32:53.166Z]     \r\n\r\n[2020-02-02T07:32:53.166Z]         This function will raise an exception when an error occurs.\r\n\r\n[2020-02-02T07:32:53.166Z]         Wrap every API call with this function.\r\n\r\n[2020-02-02T07:32:53.166Z]     \r\n\r\n[2020-02-02T07:32:53.166Z]         Parameters\r\n\r\n[2020-02-02T07:32:53.166Z]         ----------\r\n\r\n[2020-02-02T07:32:53.166Z]         ret : int\r\n\r\n[2020-02-02T07:32:53.166Z]             return value from API calls.\r\n\r\n[2020-02-02T07:32:53.166Z]         \"\"\"\r\n\r\n[2020-02-02T07:32:53.166Z]         if ret != 0:\r\n\r\n[2020-02-02T07:32:53.166Z] >           raise get_last_ffi_error()\r\n\r\n[2020-02-02T07:32:53.166Z] E           IndexError: Traceback (most recent call last):\r\n\r\n[2020-02-02T07:32:53.166Z] E             File \"src/operator/tensor/indexing_op.cc\", line 455\r\n\r\n[2020-02-02T07:32:53.166Z] E           IndexError: index 19 is out of bounds for axis 1 with size 19\r\n\r\n```","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1137/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1137/timeline","performed_via_github_app":null,"state_reason":null}