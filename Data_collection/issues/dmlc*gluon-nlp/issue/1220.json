{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1220","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1220/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1220/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1220/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/1220","id":611531896,"node_id":"MDU6SXNzdWU2MTE1MzE4OTY=","number":1220,"title":"BeamSearchSampler failing with mx.numpy input","user":{"login":"pasmargo","id":7614942,"node_id":"MDQ6VXNlcjc2MTQ5NDI=","avatar_url":"https://avatars.githubusercontent.com/u/7614942?v=4","gravatar_id":"","url":"https://api.github.com/users/pasmargo","html_url":"https://github.com/pasmargo","followers_url":"https://api.github.com/users/pasmargo/followers","following_url":"https://api.github.com/users/pasmargo/following{/other_user}","gists_url":"https://api.github.com/users/pasmargo/gists{/gist_id}","starred_url":"https://api.github.com/users/pasmargo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pasmargo/subscriptions","organizations_url":"https://api.github.com/users/pasmargo/orgs","repos_url":"https://api.github.com/users/pasmargo/repos","events_url":"https://api.github.com/users/pasmargo/events{/privacy}","received_events_url":"https://api.github.com/users/pasmargo/received_events","type":"User","site_admin":false},"labels":[{"id":890393501,"node_id":"MDU6TGFiZWw4OTAzOTM1MDE=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-05-03T23:21:33Z","updated_at":"2020-07-19T21:51:46Z","closed_at":"2020-07-19T21:51:46Z","author_association":"NONE","active_lock_reason":null,"body":"## Description\r\n\r\nI follow [the instructions to generate sequences with Beam Search](https://gluon-nlp.mxnet.io/examples/sequence_sampling/sequence_sampling.html) and it works correctly when the input is an mx.nd object. However, I get an error message when the input is an mx.numpy object.\r\n\r\nWith the original line, it works correctly:\r\n```\r\ninputs = mx.nd.full(shape=(1,), ctx=ctx, val=bos_ids[-1])\r\n```\r\n\r\nWith this other line, it makes the sampler fail:\r\n```\r\ninputs = mx.numpy.full((1,), bos_ids[-1], ctx=ctx)\r\n```\r\n\r\n### Error Message\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-18-711d82cb4e91> in <module>()\r\n----> 1 generate_sequences(beam_sampler, inputs, begin_states, 5)\r\n\r\n<ipython-input-17-c4c52c7fd9b6> in generate_sequences(sampler, inputs, begin_states, num_print_outcomes)\r\n      1 def generate_sequences(sampler, inputs, begin_states, num_print_outcomes):\r\n      2 \r\n----> 3     samples, scores, valid_lengths = sampler(inputs, begin_states)\r\n      4     samples = samples[0].asnumpy()\r\n      5     scores = scores[0].asnumpy()\r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonnlp/model/sequence_sampler.py in __call__(self, inputs, states)\r\n    525                                       state_info=state_info)\r\n    526         step_input = _expand_to_beam_size(inputs, beam_size=beam_size,\r\n--> 527                                           batch_size=batch_size).astype(np.int32)\r\n    528         # All beams are initialized to alive\r\n    529         # Generated samples are initialized to be the inputs\r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonnlp/model/sequence_sampler.py in _expand_to_beam_size(data, beam_size, batch_size, state_info)\r\n    199         new_shape[batch_axis] = batch_size * beam_size\r\n    200         new_shape = tuple(new_shape)\r\n--> 201         return data.expand_dims(batch_axis+1)\\\r\n    202                    .broadcast_axes(axis=batch_axis+1, size=beam_size)\\\r\n    203                    .reshape(new_shape)\r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/numpy/multiarray.py in expand_dims(self, *args, **kwargs)\r\n   1435         this array as data.\r\n   1436         \"\"\"\r\n-> 1437         raise AttributeError('mxnet.numpy.ndarray object has no attribute expand_dims')\r\n   1438 \r\n   1439     def tile(self, *args, **kwargs):\r\n\r\nAttributeError: mxnet.numpy.ndarray object has no attribute expand_dims\r\n```\r\n\r\n## To Reproduce\r\n\r\nUse the code for the sequence generation using Beam Search in this link:\r\n\r\nhttps://gluon-nlp.mxnet.io/examples/sequence_sampling/sequence_sampling.html\r\n\r\nAnd substitute the line\r\n\r\n```\r\ninputs = mx.nd.full(shape=(1,), ctx=ctx, val=bos_ids[-1])\r\n```\r\n\r\nwith\r\n\r\n```\r\ninputs = mx.numpy.full((1,), bos_ids[-1], ctx=ctx)\r\n```\r\n\r\n## What have you tried to solve it?\r\n\r\n1. I tried to convert the mx.numpy input to mx.nd with `.as_nd_ndarray()`. It gets passed that error, but then Gluon Blocks requires all outputs to be mx.numpy and it fails in an old reshape method (mx.numpy should not have a named shape argument):\r\n\r\n```\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonnlp/model/sequence_sampler.py in hybrid_forward(self, F, samples, valid_length, outputs, scores, beam_alive_mask, states)\r\n    418         beam_size = self._beam_size\r\n    419         # outputs: (batch_size, beam_size, vocab_size)\r\n--> 420         outputs = outputs.reshape(shape=(-4, -1, beam_size, 0))\r\n    421         if self._top_k:\r\n    422             ranks = outputs.argsort(is_ascend=False, dtype='int32')\r\n```\r\n\r\n## Environment\r\n\r\nWe recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\r\n```\r\ncurl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\r\n```\r\n# paste outputs here\r\n```\r\n----------Python Info----------\r\nVersion      : 3.6.5\r\nCompiler     : GCC 7.2.0\r\nBuild        : ('default', 'Apr 29 2018 16:14:56')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 10.0.1\r\nDirectory    : /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.6.0\r\nDirectory    : /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet\r\nNum GPUs     : 1\r\nCommit Hash   : 6eec9da55c5096079355d1f1a5fa58dcf35d6752\r\n----------System Info----------\r\nPlatform     : Linux-4.14.171-105.231.amzn1.x86_64-x86_64-with-glibc2.9\r\nsystem       : Linux\r\nnode         : ip-172-16-83-169\r\nrelease      : 4.14.171-105.231.amzn1.x86_64\r\nversion      : #1 SMP Thu Feb 27 23:49:15 UTC 2020\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                4\r\nOn-line CPU(s) list:   0-3\r\nThread(s) per core:    2\r\nCore(s) per socket:    2\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\nStepping:              1\r\nCPU MHz:               2701.008\r\nCPU max MHz:           3000.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              4600.14\r\nHypervisor vendor:     Xen\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              46080K\r\nNUMA node0 CPU(s):     0-3\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0022 sec, LOAD: 0.4192 sec.\r\nTiming for GluonNLP GitHub: https://github.com/dmlc/gluon-nlp, DNS: 0.0005 sec, LOAD: 0.3731 sec.\r\nTiming for GluonNLP: http://gluon-nlp.mxnet.io, DNS: 0.0927 sec, LOAD: 0.0981 sec.\r\nTiming for D2L: http://d2l.ai, DNS: 0.0303 sec, LOAD: 0.0695 sec.\r\nTiming for D2L (zh-cn): http://zh.d2l.ai, DNS: 0.0307 sec, LOAD: 0.1809 sec.\r\nTiming for FashionMNIST: https://repo.mxnet.io/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0259 sec, LOAD: 0.3750 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0034 sec, LOAD: 0.0990 sec.\r\nError open Conda: https://repo.continuum.io/pkgs/free/, HTTP Error 403: Forbidden, DNS finished in 0.003132343292236328 sec.\r\n\r\n```","closed_by":{"login":"szha","id":2626883,"node_id":"MDQ6VXNlcjI2MjY4ODM=","avatar_url":"https://avatars.githubusercontent.com/u/2626883?v=4","gravatar_id":"","url":"https://api.github.com/users/szha","html_url":"https://github.com/szha","followers_url":"https://api.github.com/users/szha/followers","following_url":"https://api.github.com/users/szha/following{/other_user}","gists_url":"https://api.github.com/users/szha/gists{/gist_id}","starred_url":"https://api.github.com/users/szha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/szha/subscriptions","organizations_url":"https://api.github.com/users/szha/orgs","repos_url":"https://api.github.com/users/szha/repos","events_url":"https://api.github.com/users/szha/events{/privacy}","received_events_url":"https://api.github.com/users/szha/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1220/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1220/timeline","performed_via_github_app":null,"state_reason":"completed"}