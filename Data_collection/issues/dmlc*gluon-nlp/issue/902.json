{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/902","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/902/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/902/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/902/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/902","id":486028018,"node_id":"MDU6SXNzdWU0ODYwMjgwMTg=","number":902,"title":"Loading BERT external vocab file error","user":{"login":"mohammedkhalilia","id":6099774,"node_id":"MDQ6VXNlcjYwOTk3NzQ=","avatar_url":"https://avatars.githubusercontent.com/u/6099774?v=4","gravatar_id":"","url":"https://api.github.com/users/mohammedkhalilia","html_url":"https://github.com/mohammedkhalilia","followers_url":"https://api.github.com/users/mohammedkhalilia/followers","following_url":"https://api.github.com/users/mohammedkhalilia/following{/other_user}","gists_url":"https://api.github.com/users/mohammedkhalilia/gists{/gist_id}","starred_url":"https://api.github.com/users/mohammedkhalilia/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mohammedkhalilia/subscriptions","organizations_url":"https://api.github.com/users/mohammedkhalilia/orgs","repos_url":"https://api.github.com/users/mohammedkhalilia/repos","events_url":"https://api.github.com/users/mohammedkhalilia/events{/privacy}","received_events_url":"https://api.github.com/users/mohammedkhalilia/received_events","type":"User","site_admin":false},"labels":[{"id":890393501,"node_id":"MDU6TGFiZWw4OTAzOTM1MDE=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":{"login":"eric-haibin-lin","id":5545640,"node_id":"MDQ6VXNlcjU1NDU2NDA=","avatar_url":"https://avatars.githubusercontent.com/u/5545640?v=4","gravatar_id":"","url":"https://api.github.com/users/eric-haibin-lin","html_url":"https://github.com/eric-haibin-lin","followers_url":"https://api.github.com/users/eric-haibin-lin/followers","following_url":"https://api.github.com/users/eric-haibin-lin/following{/other_user}","gists_url":"https://api.github.com/users/eric-haibin-lin/gists{/gist_id}","starred_url":"https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eric-haibin-lin/subscriptions","organizations_url":"https://api.github.com/users/eric-haibin-lin/orgs","repos_url":"https://api.github.com/users/eric-haibin-lin/repos","events_url":"https://api.github.com/users/eric-haibin-lin/events{/privacy}","received_events_url":"https://api.github.com/users/eric-haibin-lin/received_events","type":"User","site_admin":false},"assignees":[{"login":"eric-haibin-lin","id":5545640,"node_id":"MDQ6VXNlcjU1NDU2NDA=","avatar_url":"https://avatars.githubusercontent.com/u/5545640?v=4","gravatar_id":"","url":"https://api.github.com/users/eric-haibin-lin","html_url":"https://github.com/eric-haibin-lin","followers_url":"https://api.github.com/users/eric-haibin-lin/followers","following_url":"https://api.github.com/users/eric-haibin-lin/following{/other_user}","gists_url":"https://api.github.com/users/eric-haibin-lin/gists{/gist_id}","starred_url":"https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eric-haibin-lin/subscriptions","organizations_url":"https://api.github.com/users/eric-haibin-lin/orgs","repos_url":"https://api.github.com/users/eric-haibin-lin/repos","events_url":"https://api.github.com/users/eric-haibin-lin/events{/privacy}","received_events_url":"https://api.github.com/users/eric-haibin-lin/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2019-08-27T20:51:44Z","updated_at":"2019-08-28T19:17:04Z","closed_at":"2019-08-28T11:44:44Z","author_association":"NONE","active_lock_reason":null,"body":"## Description\r\nWhen calling  [get_model(name, **kwargs)](https://github.com/dmlc/gluon-nlp/blob/ea1ae703afd9c9e59d55718ae32e91e74ce25ef4/src/gluonnlp/model/__init__.py#L99), we can specify either the `--dataset_name`, which will load the vocab for that dataset, or we can pass the `--vocab` for custom BERT vocabulary. An error occurs when calling a BERT model such as `bert_12_768_12` with `--vocab` and without passing `--dataset_name`.\r\n\r\n### Error Message\r\n    Traceback (most recent call last):\r\n      File \"finetune_ner.py\", line 260, in <module>\r\n        main(parse_args())\r\n      File \"finetune_ner.py\", line 121, in main\r\n        bert_model.load_parameters(config.parameters, ctx=ctx, ignore_extra=True)\r\n      File \"/env/mx_1.5_gnlp_0.8/lib/python3.5/site-packages/mxnet/gluon/block.py\", line 410, in load_parameters\r\n        params[name]._load_init(loaded[name], ctx, cast_dtype=cast_dtype, dtype_source=dtype_source)\r\n      File \"/env/mx_1.5_gnlp_0.8/lib/python3.5/site-packages/mxnet/gluon/parameter.py\", line 279, in _load_init\r\n        self.name, str(self.shape), str(data.shape))\r\n    AssertionError: Failed loading Parameter 'bertmodel0_word_embed_embedding0_weight' from saved params: shape incompatible expected (98, 768) vs saved (28996, 768)\r\n\r\nNote that I did make minor modification to finetune_ner.py script, but that is irrelevant. The correct vocabulary size in this example is 28996 and the 98 is the length of the filename passed in the vocab argument in the function [_load_vocab(dataset_name, vocab, root, cls=None)](https://github.com/dmlc/gluon-nlp/blob/master/src/gluonnlp/model/utils.py#L265)\r\n\r\n## To Reproduce\r\nTo reproduce, you need to convert a BERT to Gluon. In my case I convereted [Clinical BERT \r\n](https://github.com/EmilyAlsentzer/clinicalBERT) TensorFlow model to Gluon using [convert_tf_model.py](https://github.com/dmlc/gluon-nlp/blob/master/scripts/bert/conversion_tools/convert_tf_model.py). Then try loading a model using [get_model(name, **kwargs)](https://github.com/dmlc/gluon-nlp/blob/ea1ae703afd9c9e59d55718ae32e91e74ce25ef4/src/gluonnlp/model/__init__.py#L99). See instructions below.\r\n\r\n### Steps to reproduce\r\n\r\n1. Download Clinical BERT. [See instructions here](https://github.com/EmilyAlsentzer/clinicalBERT)\r\n2. Convert any of the Clinical BERT models to Gluon using [convert_tf_model.py](https://github.com/dmlc/gluon-nlp/blob/master/scripts/bert/conversion_tools/convert_tf_model.py)\r\n3. Call [get_model(name, **kwargs)](https://github.com/dmlc/gluon-nlp/blob/ea1ae703afd9c9e59d55718ae32e91e74ce25ef4/src/gluonnlp/model/__init__.py#L99) without specifying `--dataset_name` and pass the converted vocabulary using `--vocab` argument.  \r\n\r\n```\r\n    params = {\r\n        'dataset_name': None,\r\n        'vocab': 'path/to/filename.vocab',\r\n        'pretrained': False,\r\n        'ctx': ctx,\r\n        'use_pooler': False,\r\n        'use_decoder': False,\r\n        'use_classifier': False,\r\n        'dropout': 0.1,\r\n        'embed_dropout': 0.1\r\n    }\r\n\r\n    bert_model, text_vocab = gluonnlp.model.get_model('bert_12_768_12', **params)\r\n```\r\n\r\n## What have you tried to solve it?\r\n[_load_vocab(dataset_name, vocab, root, cls=None)](https://github.com/dmlc/gluon-nlp/blob/master/src/gluonnlp/model/utils.py#L265) returns the vocab variable (str) if `--dataset_name` is not set, hence the vocab length 98 you see in the error message above. To resolve the issue, I modified the function [_load_vocab(dataset_name, vocab, root, cls=None)](https://github.com/dmlc/gluon-nlp/blob/master/src/gluonnlp/model/utils.py#L265) and added the following lines after line [273](https://github.com/dmlc/gluon-nlp/blob/b7332817c77ab40451043fad81f3e91a9bb677a2/src/gluonnlp/model/utils.py#L273)\r\n\r\n    with open(vocab, 'r') as fh:\r\n        vocab = gluonnlp.Vocab().from_json(fh.read())\r\n        return vocab\r\n\r\n\r\n## Environment\r\n```\r\n    Architecture:          x86_64\r\n    CPU op-mode(s):        32-bit, 64-bit\r\n    Byte Order:            Little Endian\r\n    CPU(s):                64\r\n    On-line CPU(s) list:   0-63\r\n    Thread(s) per core:    2\r\n    Core(s) per socket:    16\r\n    Socket(s):             2\r\n    NUMA node(s):          2\r\n    Vendor ID:             GenuineIntel\r\n    CPU family:            6\r\n    Model:                 79\r\n    Model name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\n    Stepping:              1\r\n    CPU MHz:               2089.316\r\n    CPU max MHz:           3000.0000\r\n    CPU min MHz:           1200.0000\r\n    BogoMIPS:              4600.15\r\n    Hypervisor vendor:     Xen\r\n    Virtualization type:   full\r\n    L1d cache:             32K\r\n    L1i cache:             32K\r\n    L2 cache:              256K\r\n    L3 cache:              46080K\r\n    NUMA node0 CPU(s):     0-15,32-47\r\n    NUMA node1 CPU(s):     16-31,48-63\r\n    Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq monitor est ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt ida\r\n    ----------Python Info----------\r\n    Version      : 3.5.2\r\n    Compiler     : GCC 5.4.0 20160609\r\n    Build        : ('default', 'Nov 12 2018 13:43:14')\r\n    Arch         : ('64bit', 'ELF')\r\n    ------------Pip Info-----------\r\n    Version      : 19.2.2\r\n    Directory    : /env/mx_1.5_gnlp_0.8/lib/python3.5/site-packages/pip\r\n    ----------MXNet Info-----------\r\n    Version      : 1.5.0\r\n    Directory    : /env/mx_1.5_gnlp_0.8/lib/python3.5/site-packages/mxnet\r\n    Num GPUs     : 8\r\n    Commit Hash   : 75a9e187d00a8b7ebc71412a02ed0e3ae489d91f\r\n    ----------System Info----------\r\n    Platform     : Linux-4.4.0-1090-aws-x86_64-with-Ubuntu-16.04-xenial\r\n    system       : Linux\r\n    node         : ip-172-31-30-122\r\n    release      : 4.4.0-1090-aws\r\n    version      : #101-Ubuntu SMP Fri Aug 2 15:21:01 UTC 2019\r\n    ----------Hardware Info----------\r\n    machine      : x86_64\r\n    processor    : x86_64\r\n    ----------Network Test----------\r\n    Setting timeout: 10\r\n    Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0011 sec, LOAD: 0.5163 sec.\r\n    Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0004 sec, LOAD: 0.0498 sec.\r\n    Timing for D2L (zh-cn): http://zh.d2l.ai, DNS: 0.0004 sec, LOAD: 0.0210 sec.\r\n    Timing for D2L: http://d2l.ai, DNS: 0.0004 sec, LOAD: 0.0183 sec.\r\n    Timing for FashionMNIST: https://repo.mxnet.io/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0003 sec, LOAD: 0.0373 sec.\r\n    Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0003 sec, LOAD: 0.1360 sec.\r\n    Timing for GluonNLP: http://gluon-nlp.mxnet.io, DNS: 0.0003 sec, LOAD: 0.0211 sec.\r\n    Timing for GluonNLP GitHub: https://github.com/dmlc/gluon-nlp, DNS: 0.0003 sec, LOAD: 0.3963 sec.\r\n```\r\n","closed_by":{"login":"leezu","id":946903,"node_id":"MDQ6VXNlcjk0NjkwMw==","avatar_url":"https://avatars.githubusercontent.com/u/946903?v=4","gravatar_id":"","url":"https://api.github.com/users/leezu","html_url":"https://github.com/leezu","followers_url":"https://api.github.com/users/leezu/followers","following_url":"https://api.github.com/users/leezu/following{/other_user}","gists_url":"https://api.github.com/users/leezu/gists{/gist_id}","starred_url":"https://api.github.com/users/leezu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leezu/subscriptions","organizations_url":"https://api.github.com/users/leezu/orgs","repos_url":"https://api.github.com/users/leezu/repos","events_url":"https://api.github.com/users/leezu/events{/privacy}","received_events_url":"https://api.github.com/users/leezu/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/902/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/902/timeline","performed_via_github_app":null,"state_reason":"completed"}