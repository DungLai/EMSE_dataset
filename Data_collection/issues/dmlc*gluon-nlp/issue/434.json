{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/434","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/434/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/434/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/434/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/434","id":384494848,"node_id":"MDU6SXNzdWUzODQ0OTQ4NDg=","number":434,"title":"Allow assigning backoff method to fastText embedding models","user":{"login":"Ishitori","id":3286787,"node_id":"MDQ6VXNlcjMyODY3ODc=","avatar_url":"https://avatars.githubusercontent.com/u/3286787?v=4","gravatar_id":"","url":"https://api.github.com/users/Ishitori","html_url":"https://github.com/Ishitori","followers_url":"https://api.github.com/users/Ishitori/followers","following_url":"https://api.github.com/users/Ishitori/following{/other_user}","gists_url":"https://api.github.com/users/Ishitori/gists{/gist_id}","starred_url":"https://api.github.com/users/Ishitori/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Ishitori/subscriptions","organizations_url":"https://api.github.com/users/Ishitori/orgs","repos_url":"https://api.github.com/users/Ishitori/repos","events_url":"https://api.github.com/users/Ishitori/events{/privacy}","received_events_url":"https://api.github.com/users/Ishitori/received_events","type":"User","site_admin":false},"labels":[{"id":890393503,"node_id":"MDU6TGFiZWw4OTAzOTM1MDM=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement","name":"enhancement","color":"135caf","default":true,"description":"New feature or request"},{"id":890393504,"node_id":"MDU6TGFiZWw4OTAzOTM1MDQ=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/help%20wanted","name":"help wanted","color":"b0f22e","default":true,"description":"Extra attention is needed"},{"id":890393505,"node_id":"MDU6TGFiZWw4OTAzOTM1MDU=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/good%20first%20issue","name":"good first issue","color":"7057ff","default":true,"description":"Good for newcomers"},{"id":963101581,"node_id":"MDU6TGFiZWw5NjMxMDE1ODE=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/discussion","name":"discussion","color":"c5def5","default":false,"description":""},{"id":994710322,"node_id":"MDU6TGFiZWw5OTQ3MTAzMjI=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/API%20change","name":"API change","color":"d93f0b","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2018-11-26T20:20:46Z","updated_at":"2018-11-27T05:08:12Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"I get `KeyError` exception if I use `cc.zh.300` embedding with `load_ngrams=True` and provide a token which has no default embedding. \r\n\r\nMy expectation is that for an unknown token a ngrams strategy would kick in and I would get a combination of vectors. But maybe due to the size of the token (only 2 characters) or maybe because I use specifically `cc.zh.300` embedding I get an error. \r\n\r\nThe minimum reproducing example is below:\r\n\r\n```\r\nimport mxnet as mx\r\nimport gluonnlp\r\nfrom gluonnlp import Vocab, data\r\n\r\nzh_embedding = gluonnlp.embedding.create('fasttext', source='cc.zh.300', load_ngrams=True)\r\ncntr = data.count_tokens(['猴姆'])\r\nvocab = Vocab(cntr)\r\nvocab.set_embedding(zh_embedding)\r\n```\r\n\r\nException is:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/gluonnlp/vocab/vocab.py\", line 333, in set_embedding\r\n    new_idx_to_vec[1:, col_start:col_end] = embs[self._idx_to_token[1:]]\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/gluonnlp/embedding/token_embedding.py\", line 544, in __getitem__\r\n    for token in tokens\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/gluonnlp/embedding/token_embedding.py\", line 544, in <listcomp>\r\n    for token in tokens\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/gluonnlp/model/train/embedding.py\", line 444, in __getitem__\r\n    raise KeyError\r\n```\r\n\r\nIf I change token, for example by adding an exclamation mark to the end, to '猴姆!' the error disappear. The problem doesn't appear as well, if I change embedding to 'wiki.zh'.\r\n\r\nGluonNLP version is '0.4.1'.\r\n\r\n@leezu ","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/434/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/434/timeline","performed_via_github_app":null,"state_reason":null}