{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/178","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/178/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/178/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/178/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/178","id":336776557,"node_id":"MDU6SXNzdWUzMzY3NzY1NTc=","number":178,"title":"Position encoding bug in transformer?","user":{"login":"JulianSlzr","id":4734836,"node_id":"MDQ6VXNlcjQ3MzQ4MzY=","avatar_url":"https://avatars.githubusercontent.com/u/4734836?v=4","gravatar_id":"","url":"https://api.github.com/users/JulianSlzr","html_url":"https://github.com/JulianSlzr","followers_url":"https://api.github.com/users/JulianSlzr/followers","following_url":"https://api.github.com/users/JulianSlzr/following{/other_user}","gists_url":"https://api.github.com/users/JulianSlzr/gists{/gist_id}","starred_url":"https://api.github.com/users/JulianSlzr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JulianSlzr/subscriptions","organizations_url":"https://api.github.com/users/JulianSlzr/orgs","repos_url":"https://api.github.com/users/JulianSlzr/repos","events_url":"https://api.github.com/users/JulianSlzr/events{/privacy}","received_events_url":"https://api.github.com/users/JulianSlzr/received_events","type":"User","site_admin":false},"labels":[{"id":963101581,"node_id":"MDU6TGFiZWw5NjMxMDE1ODE=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/discussion","name":"discussion","color":"c5def5","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"szhengac","id":3960020,"node_id":"MDQ6VXNlcjM5NjAwMjA=","avatar_url":"https://avatars.githubusercontent.com/u/3960020?v=4","gravatar_id":"","url":"https://api.github.com/users/szhengac","html_url":"https://github.com/szhengac","followers_url":"https://api.github.com/users/szhengac/followers","following_url":"https://api.github.com/users/szhengac/following{/other_user}","gists_url":"https://api.github.com/users/szhengac/gists{/gist_id}","starred_url":"https://api.github.com/users/szhengac/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/szhengac/subscriptions","organizations_url":"https://api.github.com/users/szhengac/orgs","repos_url":"https://api.github.com/users/szhengac/repos","events_url":"https://api.github.com/users/szhengac/events{/privacy}","received_events_url":"https://api.github.com/users/szhengac/received_events","type":"User","site_admin":false},"assignees":[{"login":"szhengac","id":3960020,"node_id":"MDQ6VXNlcjM5NjAwMjA=","avatar_url":"https://avatars.githubusercontent.com/u/3960020?v=4","gravatar_id":"","url":"https://api.github.com/users/szhengac","html_url":"https://github.com/szhengac","followers_url":"https://api.github.com/users/szhengac/followers","following_url":"https://api.github.com/users/szhengac/following{/other_user}","gists_url":"https://api.github.com/users/szhengac/gists{/gist_id}","starred_url":"https://api.github.com/users/szhengac/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/szhengac/subscriptions","organizations_url":"https://api.github.com/users/szhengac/orgs","repos_url":"https://api.github.com/users/szhengac/repos","events_url":"https://api.github.com/users/szhengac/events{/privacy}","received_events_url":"https://api.github.com/users/szhengac/received_events","type":"User","site_admin":false}],"milestone":null,"comments":9,"created_at":"2018-06-28T20:54:37Z","updated_at":"2019-07-29T14:20:33Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"The way the position encoding in `scripts/nmt/transformer.py` is written computes `sin` on `2i` and `cos` on `2i+1`. This is opposed to computing `sin` and `cos` on `2i` at positions `2i`, `2i+1` (@szhengac perhaps I'm misunderstanding? Please check).\r\n\r\nHere is my proposed fix:\r\n```python\r\ndef _position_encoding_init(max_length, dim):\r\n    \"\"\" Init the sinusoid position encoding table \"\"\"\r\n    assert dim % 2 == 0\r\n\r\n    # time-wise list [0, ..., max_length] of shape (max_length, 1)\r\n    position_enc_time = np.arange(max_length).reshape((-1, 1))\r\n\r\n    # hidden-wise list [0, 0, 1, 1, ..., dim/2, dim/2] of shape (1, dim)\r\n    position_enc_hidden = np.repeat(np.arange(int(dim/2)), 2).reshape((1, -1))\r\n\r\n    # combine by broadcasting in both dimensions\r\n    position_enc = position_enc_time / (np.power(10000, (2. / dim) * position_enc_hidden))\r\n\r\n    # Apply the cosine to even columns and sin to odds.\r\n    position_enc[:, 0::2] = np.sin(position_enc[:, 0::2])  # dim 2i\r\n    position_enc[:, 1::2] = np.cos(position_enc[:, 1::2])  # dim 2i+1\r\n\r\n    return position_enc\r\n```","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/178/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/178/timeline","performed_via_github_app":null,"state_reason":null}