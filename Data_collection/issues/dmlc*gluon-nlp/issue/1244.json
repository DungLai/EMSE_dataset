{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1244","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1244/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1244/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1244/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/1244","id":636009941,"node_id":"MDU6SXNzdWU2MzYwMDk5NDE=","number":1244,"title":"[Numpy Refactor] [Model Deployment] Use TVM to accelerate model inference + deployment","user":{"login":"sxjscience","id":5178350,"node_id":"MDQ6VXNlcjUxNzgzNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5178350?v=4","gravatar_id":"","url":"https://api.github.com/users/sxjscience","html_url":"https://github.com/sxjscience","followers_url":"https://api.github.com/users/sxjscience/followers","following_url":"https://api.github.com/users/sxjscience/following{/other_user}","gists_url":"https://api.github.com/users/sxjscience/gists{/gist_id}","starred_url":"https://api.github.com/users/sxjscience/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sxjscience/subscriptions","organizations_url":"https://api.github.com/users/sxjscience/orgs","repos_url":"https://api.github.com/users/sxjscience/repos","events_url":"https://api.github.com/users/sxjscience/events{/privacy}","received_events_url":"https://api.github.com/users/sxjscience/received_events","type":"User","site_admin":false},"labels":[{"id":890393503,"node_id":"MDU6TGFiZWw4OTAzOTM1MDM=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement","name":"enhancement","color":"135caf","default":true,"description":"New feature or request"},{"id":1689031381,"node_id":"MDU6TGFiZWwxNjg5MDMxMzgx","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/numpyrefactor","name":"numpyrefactor","color":"2f38ed","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2020-06-10T07:38:28Z","updated_at":"2020-11-26T01:48:43Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Currently, we do have Relay VM support of the NDArray version of MXNet: https://github.com/apache/incubator-tvm/blob/master/python/tvm/relay/frontend/mxnet.py\r\n\r\nHowever, we still miss the numpy array support in Relay frontend converter and we should first add the numpy support.\r\n\r\nI checked the workloads of BERT + ALBERT + ELECTRA + MobileBERT + RoBERTa  (only backbone) and these are the ops used:\r\n\r\n```\r\n_npi_transpose\r\nFullyConnected\r\n_npi_pad\r\n_contrib_arange_like\r\nexpand_dims\r\nnull\r\n_npi_multiply_scalar\r\n_npi_true_divide_scalar\r\nActivation\r\n_npi_add\r\n_npi_concatenate\r\n_npi_multiply\r\nSwapAxis\r\n_np_copy\r\n_npi_tanh\r\ntake\r\nsoftmax\r\n_npi_power_scalar\r\n_npi_less\r\nSequenceMask\r\nLayerNorm\r\nDropout\r\nerf\r\nEmbedding\r\n_npi_add_scalar\r\n_npx_reshape\r\n_split_v2\r\n_npi_where_rscalar\r\nslice\r\nCast\r\nbatch_dot\r\n```\r\n\r\nAfter some investigation, the following are the the ops that need to be converted:\r\n```\r\n_npi_transpose\r\n_npi_pad\r\n_contrib_arange_like\r\nnull\r\n_npi_multiply_scalar\r\n_npi_true_divide_scalar\r\n_npi_add\r\n_npi_concatenate\r\n_npi_multiply\r\n_np_copy\r\n_npi_tanh\r\n_npi_power_scalar\r\n_npi_less\r\n_npi_add_scalar\r\n_npx_reshape\r\n_split_v2\r\n_npi_where_rscalar\r\n```\r\n\r\nWe will revise the relay runtime in TVM accordingly.\r\n\r\nCode for getting the missing ops for relay:\r\n\r\n```python\r\nimport json\r\nimport mxnet as mx\r\nfrom gluonnlp.models import list_backbone_names, get_backbone\r\n\r\nmx.npx.set_np()\r\nbatch_size = 1\r\nsequence_length = 32\r\nall_possible_ops = []\r\nfor name in list_backbone_names():\r\n    model_cls, cfg, tokenizer, local_params_path, others = get_backbone(model_name=name)\r\n    net = model_cls.from_cfg(cfg)\r\n    net.initialize()\r\n    net.hybridize()\r\n    print('Save the architecture of {} to {}.json'.format(name, name))\r\n    inputs = mx.np.random.randint(0, 10, (batch_size, sequence_length))\r\n    token_types = mx.np.random.randint(0, 2, (batch_size, sequence_length))\r\n    valid_length = mx.np.random.randint(1, 10, (batch_size,))\r\n    if 'roberta' in name or 'xlmr' in name:\r\n        out = net(inputs, valid_length)\r\n    else:\r\n        out = net(inputs, token_types, valid_length)\r\n    sym = net._cached_graph[1]\r\n    sym.save('{}.json'.format(name), remove_amp_cast=True)\r\n    all_ops = set()\r\n    with open('{}.json'.format(name), 'r') as f:\r\n        sym_info = json.load(f)\r\n        for ele in sym_info['nodes']:\r\n            all_ops.add(ele['op'])\r\n    with open('{}_all_ops.json'.format(name), 'w') as f:\r\n        json.dump(list(all_ops), f)\r\n    all_possible_ops.extend(list(all_ops))\r\n\r\nwith open('all_possible_ops.json', 'w') as f:\r\n    json.dump(list(set(all_possible_ops)), f)\r\n\r\n\r\nfrom tvm.relay.frontend.mxnet import _convert_map\r\n\r\nfor op in all_possible_ops:\r\n    if op not in _convert_map:\r\n        print(op)\r\n```","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1244/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1244/timeline","performed_via_github_app":null,"state_reason":null}