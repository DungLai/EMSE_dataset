{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1436","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1436/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1436/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1436/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/1436","id":744423051,"node_id":"MDU6SXNzdWU3NDQ0MjMwNTE=","number":1436,"title":"[Performance] Speed comparison between GluonNLP and other packages","user":{"login":"sxjscience","id":5178350,"node_id":"MDQ6VXNlcjUxNzgzNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5178350?v=4","gravatar_id":"","url":"https://api.github.com/users/sxjscience","html_url":"https://github.com/sxjscience","followers_url":"https://api.github.com/users/sxjscience/followers","following_url":"https://api.github.com/users/sxjscience/following{/other_user}","gists_url":"https://api.github.com/users/sxjscience/gists{/gist_id}","starred_url":"https://api.github.com/users/sxjscience/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sxjscience/subscriptions","organizations_url":"https://api.github.com/users/sxjscience/orgs","repos_url":"https://api.github.com/users/sxjscience/repos","events_url":"https://api.github.com/users/sxjscience/events{/privacy}","received_events_url":"https://api.github.com/users/sxjscience/received_events","type":"User","site_admin":false},"labels":[{"id":890393503,"node_id":"MDU6TGFiZWw4OTAzOTM1MDM=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement","name":"enhancement","color":"135caf","default":true,"description":"New feature or request"},{"id":890393504,"node_id":"MDU6TGFiZWw4OTAzOTM1MDQ=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/help%20wanted","name":"help wanted","color":"b0f22e","default":true,"description":"Extra attention is needed"},{"id":2278734280,"node_id":"MDU6TGFiZWwyMjc4NzM0Mjgw","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/performance","name":"performance","color":"e99695","default":false,"description":"Performance issues"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2020-11-17T05:26:57Z","updated_at":"2021-01-10T16:54:55Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"## Description\r\nSimilar to the efforts in our recently added benchmarking script (https://github.com/dmlc/gluon-nlp/tree/master/scripts/benchmarks), we are also interested in comparing the end-to-end training speed of training NLP models between GluonNLP and the other packages. This helps us track the performance of GluonNLP and measure the out-of-the-box speed of different toolkits. (This also helps with the goal of democratizing NLP to everyone).  @ZheyuYe has helped in trying out huggingface/transformer to see its performance on a g4.12dn instance.\r\n\r\nHuggingface command:\r\n\r\n```bash\r\nexport SQUAD_DIR=/home/ubuntu/squad\r\npython3 -m torch.distributed.launch --nproc_per_node=4 ./examples/question-answering/run_squad.py \\\r\n    --model_type albert \\\r\n    --model_name_or_path albert-base-v2 \\\r\n    --do_train \\\r\n    --do_eval \\\r\n    --version_2_with_negative \\\r\n    --train_file $SQUAD_DIR/train-v2.0.json \\\r\n    --predict_file $SQUAD_DIR/dev-v2.0.json \\\r\n    --learning_rate 3e-5 \\\r\n    --weight_decay 0.01 \\\r\n    --max_grad_norm 1.0 \\\r\n    --num_train_epochs 3 \\\r\n    --warmup_ratio 0.1 \\\r\n    --max_seq_length 512 \\\r\n    --doc_stride 128 \\\r\n    --output_dir ./examples/models/albert-base-v2_finetuned_squad2.0/ \\\r\n    --per_gpu_eval_batch_size=24   \\\r\n    --per_gpu_train_batch_size=12   \\\r\n    --gradient_accumulation_steps=1 \\\r\n    --overwrite_cache \\\r\n    --threads 8 \\\r\n    --overwrite_output_dir \\\r\n```\r\n\r\nThe whole log is available in https://gist.github.com/sxjscience/9ef5c957bb4447e8fd35ccd4d96328f0. From the log, the huggingface training and evaluation starts at `11/15/2020 14:36:09` and finishes in `11/15/2020 17:36:20`, which takes roughly 3 hours.\r\n\r\nThe training log of albert-base in gluonnlp is attached [here](https://gluon-nlp-log.s3.amazonaws.com/squad_training_log/20201106/squad_v2_horovod_fp32/test_squad2_albert_base/fintune_google_albert_base_v2_squad_2.0/finetune_squad2.0.log): (also see the question answering examples in https://github.com/dmlc/gluon-nlp/tree/master/scripts/question_answering). It started at `2020-11-05 15:45:33,862` and finished at `2020-11-05 17:57:04,681`, which is roughly 2hour and 15 minutes. Thus, the QA implementation in GluonNLP is somewhat faster than that in huggingface. However, the comparison is not totally fair since we are using different ways for preprocessing the training samples.\r\n\r\nWe may try to maintain our own benchmark of end-to-end training performance and extend the comparison to other packages like DeepSpeed. I opened this issue to track the status.\r\n\r\n@dmlc/gluon-nlp-team  ","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1436/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1436/timeline","performed_via_github_app":null,"state_reason":null}