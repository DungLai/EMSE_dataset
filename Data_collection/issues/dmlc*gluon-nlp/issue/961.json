{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/961","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/961/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/961/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/961/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/961","id":502690125,"node_id":"MDU6SXNzdWU1MDI2OTAxMjU=","number":961,"title":"HybridBeamSearchSampler fails where regular BeamSearchSampler works fine","user":{"login":"zeeshansayyed","id":543495,"node_id":"MDQ6VXNlcjU0MzQ5NQ==","avatar_url":"https://avatars.githubusercontent.com/u/543495?v=4","gravatar_id":"","url":"https://api.github.com/users/zeeshansayyed","html_url":"https://github.com/zeeshansayyed","followers_url":"https://api.github.com/users/zeeshansayyed/followers","following_url":"https://api.github.com/users/zeeshansayyed/following{/other_user}","gists_url":"https://api.github.com/users/zeeshansayyed/gists{/gist_id}","starred_url":"https://api.github.com/users/zeeshansayyed/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zeeshansayyed/subscriptions","organizations_url":"https://api.github.com/users/zeeshansayyed/orgs","repos_url":"https://api.github.com/users/zeeshansayyed/repos","events_url":"https://api.github.com/users/zeeshansayyed/events{/privacy}","received_events_url":"https://api.github.com/users/zeeshansayyed/received_events","type":"User","site_admin":false},"labels":[{"id":890393501,"node_id":"MDU6TGFiZWw4OTAzOTM1MDE=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2019-10-04T15:06:18Z","updated_at":"2019-10-04T23:40:31Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"## Description\r\n(A clear and concise description of what the bug is.)\r\nI modified an existing `BeamSearchTranslator` class in this [example](https://github.com/dmlc/gluon-nlp/blob/master/scripts/machine_translation/translation.py) to use `HybridBeamSearchSampler` instead of regular `BeamSearchSampler`. The code for the modification is as follows:\r\n```python\r\nclass HybridBeamSearchTranslator:\r\n    def __init__(self, model, batch_size=16, beam_size=5, max_length=35):\r\n        self._model = model\r\n        self._scorer = BeamSearchScorer()\r\n        self._scorer.hybridize()\r\n        self._sampler = HybridBeamSearchSampler(\r\n            batch_size=batch_size,\r\n            beam_size=beam_size,\r\n            decoder=self._decode_logprob,\r\n            eos_id=self._model.tgt_vocab.token_to_idx[self._model.tgt_vocab.sep_token],\r\n            scorer=self._scorer,\r\n            max_length=35,\r\n            vocab_size=len(self._model.tgt_vocab)\r\n        )\r\n        self._sampler.hybridize()\r\n\r\n    def _decode_logprob(self, step_input, states):\r\n        out, states, _ = self._model.decode_step(step_input, states)\r\n        return mx.nd.log_softmax(out), states\r\n\r\n    def translate(self, src_seq, src_valid_length):\r\n        batch_size = src_seq.shape[0]\r\n        encoder_outputs, _ = self._model.encode(src_seq, valid_length=src_valid_length)\r\n        decoder_states = self._model.decoder.init_state_from_encoder(encoder_outputs,\r\n                                                                     src_valid_length)\r\n        inputs = mx.nd.full(shape=(batch_size,), ctx=src_seq.context, dtype=np.float32,\r\n                            val=self._model.tgt_vocab.token_to_idx[self._model.tgt_vocab.cls_token])\r\n        samples, scores, sample_valid_length = self._sampler(inputs, decoder_states)\r\n        return samples, scores, sample_valid_length\r\n```\r\n\r\nWhile the original works as expected, the new HybridBeamSearchTranslator gives the following error:\r\n\r\n### Error Message\r\n```\r\nTraceback (most recent call last):\r\n  File \"translation.py\", line 135, in <module>\r\n    samples, scores, sample_valid_length = translator.translate(src_seq, src_valid_length)\r\n  File \"translation.py\", line 116, in translate\r\n    samples, scores, sample_valid_length = self._sampler(inputs, decoder_states)\r\n  File \"/home/ec2-user/anaconda3/envs/gluon/lib/python3.7/site-packages/mxnet/gluon/block.py\", line 548, in __call__\r\n    out = self.forward(*args)\r\n  File \"/home/ec2-user/anaconda3/envs/gluon/lib/python3.7/site-packages/mxnet/gluon/block.py\", line 915, in forward\r\n    return self._call_cached_op(x, *args)\r\n  File \"/home/ec2-user/anaconda3/envs/gluon/lib/python3.7/site-packages/mxnet/gluon/block.py\", line 805, in _call_cached_op\r\n    self._build_cache(*args)\r\n  File \"/home/ec2-user/anaconda3/envs/gluon/lib/python3.7/site-packages/mxnet/gluon/block.py\", line 757, in _build_cache\r\n    data, out = self._get_graph(*args)\r\n  File \"/home/ec2-user/anaconda3/envs/gluon/lib/python3.7/site-packages/mxnet/gluon/block.py\", line 749, in _get_graph\r\n    out = self.hybrid_forward(symbol, *grouped_inputs, **params)  # pylint: disable=no-value-for-parameter\r\n  File \"/home/ec2-user/anaconda3/envs/gluon/lib/python3.7/site-packages/gluonnlp/model/sequence_sampler.py\", line 687, in hybrid_forward\r\n    ) + tuple(states)\r\n  File \"/home/ec2-user/anaconda3/envs/gluon/lib/python3.7/site-packages/mxnet/symbol/contrib.py\", line 574, in while_loop\r\n    _create_subgraph(loop_vars, _func_wrapper, name + \"_func\")\r\n  File \"/home/ec2-user/anaconda3/envs/gluon/lib/python3.7/site-packages/mxnet/symbol/contrib.py\", line 493, in _create_subgraph\r\n    outputs, final_state, out_fmt, var_fmt = graph_func(new_graph_vars)\r\n  File \"/home/ec2-user/anaconda3/envs/gluon/lib/python3.7/site-packages/mxnet/symbol/contrib.py\", line 470, in _func_wrapper\r\n    step_output, new_loop_vars = func(*loop_vars)\r\n  File \"/home/ec2-user/anaconda3/envs/gluon/lib/python3.7/site-packages/gluonnlp/model/sequence_sampler.py\", line 658, in _loop_func\r\n    step_input, _reconstruct_flattened_structure(state_structure, states))\r\n  File \"translation.py\", line 106, in _decode_logprob\r\n    out, states, _ = self._model.decode_step(step_input, states)\r\n  File \"/home/ec2-user/anaconda3/envs/gluon/lib/python3.7/site-packages/gluonnlp/model/translation.py\", line 188, in decode_step\r\n    self.decoder(self.tgt_embed(step_input), states)\r\n  File \"/home/ec2-user/anaconda3/envs/gluon/lib/python3.7/site-packages/gluonnlp/model/transformer.py\", line 1080, in __call__\r\n    return super(TransformerDecoder, self).__call__(step_input, states)\r\n  File \"/home/ec2-user/anaconda3/envs/gluon/lib/python3.7/site-packages/gluonnlp/model/seq2seq_encoder_decoder.py\", line 218, in __call__\r\n    return super(Seq2SeqDecoder, self).__call__(step_input, states)\r\n  File \"/home/ec2-user/anaconda3/envs/gluon/lib/python3.7/site-packages/mxnet/gluon/block.py\", line 548, in __call__\r\n    out = self.forward(*args)\r\n  File \"/home/ec2-user/anaconda3/envs/gluon/lib/python3.7/site-packages/gluonnlp/model/transformer.py\", line 1083, in forward\r\n    input_shape = step_input.shape\r\nAttributeError: 'Symbol' object has no attribute 'shape'\r\n```\r\n\r\n## To Reproduce\r\n(If you developed your own code, please provide a short script that reproduces the error. For existing examples, please provide link.)\r\n\r\n### Steps to reproduce\r\nThe way I call the above class is as follows:\r\n```python\r\n    tokenizer, model = load_model('some_model_name', 2)\r\n    # translator = BeamSearchTranslator(model)\r\n    translator = HybridBeamSearchTranslator(model)\r\n    train_loader, dev_loader, test_loader = load_data(tokenizer, tokenizer, 20, 20, dev_batch_size=8)\r\n    ctx = mx.gpu(0)\r\n    for _, (src_seq, src_valid_length, __, tgt_seq, tgt_valid_length, inst_ids) in enumerate(dev_loader):\r\n        src_seq = src_seq.as_in_context(ctx)\r\n        tgt_seq = tgt_seq.as_in_context(ctx)\r\n        src_valid_length = src_valid_length.as_in_context(ctx)\r\n        tgt_valid_length = tgt_valid_length.as_in_context(ctx)\r\n        if _ == 5:\r\n            break\r\n\r\n    samples, scores, sample_valid_length = translator.translate(src_seq, src_valid_length)\r\n    print(samples.shape)\r\n    print(scores)\r\n    print(sample_valid_length)\r\n```\r\n\r\n## Environment\r\n```\r\n----------Python Info----------\r\nVersion      : 3.7.4\r\nCompiler     : GCC 7.3.0\r\nBuild        : ('default', 'Aug 13 2019 20:35:49')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 19.2.2\r\nDirectory    : /home/ec2-user/anaconda3/envs/gluon/lib/python3.7/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.5.0\r\nDirectory    : /home/ec2-user/anaconda3/envs/gluon/lib/python3.7/site-packages/mxnet\r\nNum GPUs     : 1\r\nCommit Hash   : 75a9e187d00a8b7ebc71412a02ed0e3ae489d91f\r\n----------System Info----------\r\nPlatform     : Linux-4.14.146-93.123.amzn1.x86_64-x86_64-with-glibc2.10\r\nsystem       : Linux\r\nnode         : ip-172-31-18-232\r\nrelease      : 4.14.146-93.123.amzn1.x86_64\r\nversion      : #1 SMP Tue Sep 24 00:45:23 UTC 2019\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                8\r\nOn-line CPU(s) list:   0-7\r\nThread(s) per core:    2\r\nCore(s) per socket:    4\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\nStepping:              1\r\nCPU MHz:               2705.098\r\nCPU max MHz:           3000.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              4600.12\r\nHypervisor vendor:     Xen\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              46080K\r\nNUMA node0 CPU(s):     0-7\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0021 sec, LOAD: 0.8024 sec.\r\nTiming for GluonNLP GitHub: https://github.com/dmlc/gluon-nlp, DNS: 0.0005 sec, LOAD: 0.5872 sec.\r\nTiming for GluonNLP: http://gluon-nlp.mxnet.io, DNS: 0.1223 sec, LOAD: 0.2127 sec.\r\nTiming for D2L: http://d2l.ai, DNS: 0.0146 sec, LOAD: 0.2927 sec.\r\nTiming for D2L (zh-cn): http://zh.d2l.ai, DNS: 0.0184 sec, LOAD: 0.3771 sec.\r\nTiming for FashionMNIST: https://repo.mxnet.io/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0817 sec, LOAD: 0.7324 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0146 sec, LOAD: 0.4340 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0143 sec, LOAD: 0.2452 sec.\r\n```\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/961/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/961/timeline","performed_via_github_app":null,"state_reason":null}