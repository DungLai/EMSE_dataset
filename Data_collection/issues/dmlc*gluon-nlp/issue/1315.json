{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1315","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1315/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1315/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1315/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/1315","id":685539324,"node_id":"MDU6SXNzdWU2ODU1MzkzMjQ=","number":1315,"title":"Bugs for run_electra.py at master branch","user":{"login":"ZiyueHuang","id":24650346,"node_id":"MDQ6VXNlcjI0NjUwMzQ2","avatar_url":"https://avatars.githubusercontent.com/u/24650346?v=4","gravatar_id":"","url":"https://api.github.com/users/ZiyueHuang","html_url":"https://github.com/ZiyueHuang","followers_url":"https://api.github.com/users/ZiyueHuang/followers","following_url":"https://api.github.com/users/ZiyueHuang/following{/other_user}","gists_url":"https://api.github.com/users/ZiyueHuang/gists{/gist_id}","starred_url":"https://api.github.com/users/ZiyueHuang/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ZiyueHuang/subscriptions","organizations_url":"https://api.github.com/users/ZiyueHuang/orgs","repos_url":"https://api.github.com/users/ZiyueHuang/repos","events_url":"https://api.github.com/users/ZiyueHuang/events{/privacy}","received_events_url":"https://api.github.com/users/ZiyueHuang/received_events","type":"User","site_admin":false},"labels":[{"id":890393501,"node_id":"MDU6TGFiZWw4OTAzOTM1MDE=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-08-25T14:35:13Z","updated_at":"2020-08-28T11:53:25Z","closed_at":"2020-08-28T11:53:25Z","author_association":"MEMBER","active_lock_reason":null,"body":"## Description\r\n### Bug for Horovod support\r\n\r\nAt https://github.com/dmlc/gluon-nlp/blob/master/scripts/pretraining/run_electra.py#L418, `num_samples_per_update` depends on the data batch, and thus could be different across the horovod processes (note that Horovod will launch a process for each GPU card), meaning that the parameters maintained in each horovod process (since we use `trainer.allreduce_grads()`) might diverge.\r\n\r\nWe can normalize the loss by batch_size on each worker before `trainer.allreduce_grads()`, to avoid syncing `num_samples_per_update` across all workers.\r\n\r\n\r\n### Bug for MLM loss\r\n\r\nIn the current implementation, the MLM loss actually doesn't take into account `masked_weights`.\r\n\r\nAt https://github.com/dmlc/gluon-nlp/blob/master/scripts/pretraining/run_electra.py#L383-L384, `masked_weights.reshape(-1)` should be replaced by `mx.np.expand_dims(masked_weights, axis=-1)`, please see the doc of `SoftmaxCELoss` at https://github.com/apache/incubator-mxnet/pull/19010/files or the example usage in bert at https://github.com/dmlc/gluon-nlp/blob/v0.10.x/scripts/bert/pretraining_utils.py#L416-L418\r\n\r\nNote that\r\n\r\n`mlm_scores`'s shape: (batch_size, num_masked_positions, vocab_size)\r\n`unmasked_tokens`'s shape: (batch_size, num_masked_positions)\r\n`masked_weights`'s shape: (batch_size, num_masked_positions)\r\n\r\nIf we comment out `mlm_loss_fn.hybridize()` and add two lines before/after https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/gluon/loss.py#L408: `print('loss.shape before weighting ', loss.shape, ' sample_weight.shape ', sample_weight.shape)` and `print('loss.shape after weighting ', loss.shape)`, running the current script run_electra.py we will get\r\n\r\n```\r\nloss.shape before weighting  (64, 19, 1)  sample_weight.shape  (1216,)\r\nloss.shape after weighting  (64, 19, 1216)\r\n```\r\nnote that 1216 = 64 x 19\r\n\r\n\r\ncc @sxjscience @ZheyuYe \r\n\r\n### Error Message\r\n(Paste the complete error message, including stack trace.)\r\n\r\n## To Reproduce\r\n(If you developed your own code, please provide a short script that reproduces the error. For existing examples, please provide link.)\r\n\r\n### Steps to reproduce\r\n(Paste the commands you ran that produced the error.)\r\n\r\n1.\r\n2.\r\n\r\n## What have you tried to solve it?\r\n\r\n1.\r\n2.\r\n\r\n## Environment\r\n\r\nWe recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\r\n```\r\ncurl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\r\n\r\n# paste outputs here\r\n```\r\n","closed_by":{"login":"ZiyueHuang","id":24650346,"node_id":"MDQ6VXNlcjI0NjUwMzQ2","avatar_url":"https://avatars.githubusercontent.com/u/24650346?v=4","gravatar_id":"","url":"https://api.github.com/users/ZiyueHuang","html_url":"https://github.com/ZiyueHuang","followers_url":"https://api.github.com/users/ZiyueHuang/followers","following_url":"https://api.github.com/users/ZiyueHuang/following{/other_user}","gists_url":"https://api.github.com/users/ZiyueHuang/gists{/gist_id}","starred_url":"https://api.github.com/users/ZiyueHuang/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ZiyueHuang/subscriptions","organizations_url":"https://api.github.com/users/ZiyueHuang/orgs","repos_url":"https://api.github.com/users/ZiyueHuang/repos","events_url":"https://api.github.com/users/ZiyueHuang/events{/privacy}","received_events_url":"https://api.github.com/users/ZiyueHuang/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1315/reactions","total_count":7,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":2,"rocket":3,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1315/timeline","performed_via_github_app":null,"state_reason":"completed"}