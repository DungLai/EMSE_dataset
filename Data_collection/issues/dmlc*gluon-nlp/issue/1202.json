{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1202","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1202/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1202/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1202/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/1202","id":598282538,"node_id":"MDU6SXNzdWU1OTgyODI1Mzg=","number":1202,"title":"Prediction on the fasttext text classification model trained on yelp review polarity dataset","user":{"login":"SamanwaySadhu","id":24360328,"node_id":"MDQ6VXNlcjI0MzYwMzI4","avatar_url":"https://avatars.githubusercontent.com/u/24360328?v=4","gravatar_id":"","url":"https://api.github.com/users/SamanwaySadhu","html_url":"https://github.com/SamanwaySadhu","followers_url":"https://api.github.com/users/SamanwaySadhu/followers","following_url":"https://api.github.com/users/SamanwaySadhu/following{/other_user}","gists_url":"https://api.github.com/users/SamanwaySadhu/gists{/gist_id}","starred_url":"https://api.github.com/users/SamanwaySadhu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SamanwaySadhu/subscriptions","organizations_url":"https://api.github.com/users/SamanwaySadhu/orgs","repos_url":"https://api.github.com/users/SamanwaySadhu/repos","events_url":"https://api.github.com/users/SamanwaySadhu/events{/privacy}","received_events_url":"https://api.github.com/users/SamanwaySadhu/received_events","type":"User","site_admin":false},"labels":[{"id":890393501,"node_id":"MDU6TGFiZWw4OTAzOTM1MDE=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-04-11T14:57:25Z","updated_at":"2020-07-19T21:47:43Z","closed_at":"2020-07-19T21:47:43Z","author_association":"NONE","active_lock_reason":null,"body":"## Description\r\nI am trying to run a prediction on the Fast-text Word N-gram model trained with Yelp review data set. I am getting this error message below. The rest of entire training process is working fine. I have run for only one epoch and a truncated version of the data-set for quicker reproduction purposes. Can't figure out how to solve it.\r\n\r\n### Error Message\r\nINFO:root:Ngrams range for the training run : 1\r\nINFO:root:Loading Training data\r\nINFO:root:Opening file yelp_review_polarity/train_m.csv for reading input\r\nINFO:root:Loading Test data\r\nINFO:root:Opening file yelp_review_polarity/test_m.csv for reading input\r\nINFO:root:Vocabulary size: 298608\r\nINFO:root:Training data converting to sequences...\r\nINFO:root:Done! Sequence conversion Time=4.39s, #Sentences=56294\r\nINFO:root:Done! Sequence conversion Time=2.81s, #Sentences=3749\r\nINFO:root:Encoding labels\r\nINFO:root:Label mapping:{'1': 0, '2': 1}\r\nINFO:root:Done! Preprocessing Time=0.39s, #Sentences=56294\r\nINFO:root:Done! Preprocessing Time=0.16s, #Sentences=3749\r\nINFO:root:Number of labels: 2\r\nINFO:root:Initializing network\r\nINFO:root:Running Training on ctx:gpu(0)\r\nINFO:root:Embedding Matrix Length:298608\r\nINFO:root:Number of output units in the last layer :1\r\nINFO:root:Network initialized\r\nINFO:root:Changing the loss function to sigmoid since its Binary Classification\r\nINFO:root:Loss function for training:SigmoidBinaryCrossEntropyLoss(batch_axis=0, w=None)\r\nINFO:root:Starting Training!\r\nINFO:root:Training on 56294 samples and testing on 3749 samples\r\nINFO:root:Number of batches for each epoch : 3518.375, Display cadence: 352\r\nINFO:root:Epoch : 0, Batches complete :0\r\nINFO:root:Epoch : 0, Batches complete :352\r\nINFO:root:Epoch : 0, Batches complete :704\r\nINFO:root:Epoch : 0, Batches complete :1056\r\nINFO:root:Epoch : 0, Batches complete :1408\r\nINFO:root:Epoch : 0, Batches complete :1760\r\nINFO:root:Epoch : 0, Batches complete :2112\r\nINFO:root:Epoch complete :0, Computing Accuracy\r\nINFO:root:Epochs completed : 0 Test Accuracy: 0.9007735396105628, Test Loss: 0.3058077375582877\r\nTraceback (most recent call last):\r\n  File \"fasttext_word_ngram.py\", line 424, in <module>\r\n    train(arguments)\r\n  File \"fasttext_word_ngram.py\", line 418, in train\r\n    logging.info(net(mx.nd.reshape(mx.nd.array(train_vocab[['This', 'movie', 'is', 'awful']], ctx=ctx)), mx.nd.array([4], ctx=ctx)).sigmoid())\r\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/gluon/block.py\", line 693, in __call__\r\n    out = self.forward(*args)\r\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/gluon/block.py\", line 1148, in forward\r\n    return self._call_cached_op(x, *args)\r\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/gluon/block.py\", line 1020, in _call_cached_op\r\n    out = self._cached_op(*cargs)\r\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py\", line 170, in __call__\r\n    ctypes.byref(out_stypes)))\r\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/base.py\", line 255, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: Error in operator fasttextclassificationmodel0_meanpoolinglayer0_sequencemask0: [16:12:08] include/mxnet/./tuple.h:220: Check failed: i >= 0 && i < ndim(): index = 1 must be in range [0, -1)\r\nStack trace:\r\n  [bt] (0) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x6b8b5b) [0x7fbc32edfb5b]\r\n  [bt] (1) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3f8c14b) [0x7fbc367b314b]\r\n  [bt] (2) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3f8da35) [0x7fbc367b4a35]\r\n  [bt] (3) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3a8feb0) [0x7fbc362b6eb0]\r\n  [bt] (4) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x382fe3c) [0x7fbc36056e3c]\r\n  [bt] (5) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x383367a) [0x7fbc3605a67a]\r\n  [bt] (6) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x386e5bf) [0x7fbc360955bf]\r\n  [bt] (7) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::CachedOp::SetForwardGraph(mxnet::CachedOp::GraphInfo*, bool, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&)+0x4ac) [0x7fbc3609870c]\r\n  [bt] (8) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::CachedOp::DynamicForward(mxnet::Context const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, bool)+0x108) [0x7fbc360aa508]\r\n\r\n## To Reproduce\r\nJust added this line at the end of the train function. It is inspired from the sentiment analysis tutorial where prediction was being done in a similar way.\r\n\r\nlogging.info(net(mx.nd.reshape(mx.nd.array(train_vocab[['This', 'movie', 'is', 'awful']], ctx=ctx), shape=(-1, 1)), mx.nd.array([4], ctx=ctx)).sigmoid())","closed_by":{"login":"szha","id":2626883,"node_id":"MDQ6VXNlcjI2MjY4ODM=","avatar_url":"https://avatars.githubusercontent.com/u/2626883?v=4","gravatar_id":"","url":"https://api.github.com/users/szha","html_url":"https://github.com/szha","followers_url":"https://api.github.com/users/szha/followers","following_url":"https://api.github.com/users/szha/following{/other_user}","gists_url":"https://api.github.com/users/szha/gists{/gist_id}","starred_url":"https://api.github.com/users/szha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/szha/subscriptions","organizations_url":"https://api.github.com/users/szha/orgs","repos_url":"https://api.github.com/users/szha/repos","events_url":"https://api.github.com/users/szha/events{/privacy}","received_events_url":"https://api.github.com/users/szha/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1202/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1202/timeline","performed_via_github_app":null,"state_reason":"completed"}