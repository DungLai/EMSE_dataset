{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1029","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1029/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1029/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1029/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/1029","id":530598525,"node_id":"MDU6SXNzdWU1MzA1OTg1MjU=","number":1029,"title":"Limitation of the current gluonnlp.data.dataset.transform()","user":{"login":"zburning","id":26197318,"node_id":"MDQ6VXNlcjI2MTk3MzE4","avatar_url":"https://avatars.githubusercontent.com/u/26197318?v=4","gravatar_id":"","url":"https://api.github.com/users/zburning","html_url":"https://github.com/zburning","followers_url":"https://api.github.com/users/zburning/followers","following_url":"https://api.github.com/users/zburning/following{/other_user}","gists_url":"https://api.github.com/users/zburning/gists{/gist_id}","starred_url":"https://api.github.com/users/zburning/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zburning/subscriptions","organizations_url":"https://api.github.com/users/zburning/orgs","repos_url":"https://api.github.com/users/zburning/repos","events_url":"https://api.github.com/users/zburning/events{/privacy}","received_events_url":"https://api.github.com/users/zburning/received_events","type":"User","site_admin":false},"labels":[{"id":890393503,"node_id":"MDU6TGFiZWw4OTAzOTM1MDM=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement","name":"enhancement","color":"135caf","default":true,"description":"New feature or request"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2019-11-30T16:16:20Z","updated_at":"2019-12-01T02:43:19Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"## Description\r\nConsider adding a flatten arguement to the nlp.data.dataset.transform()?\r\n\r\nThe current nlp.data.dataset.transform() applies a transform function fn on each example in the dataset.\r\n```\r\n    def __getitem__(self, idx):\r\n        item = self._data[idx]\r\n        if isinstance(item, tuple):\r\n            return self._fn(*item)\r\n        return self._fn(item) \r\n```\r\nSo that it assumes each item only be converted to one fn(item). But in some cases, for example, squad dataset, we would use the sliding window to get several doc spans. So for each example in dataset, we would have a number of transformed examples, e.g., fn(item) can be a list. Thus we may need to flatten it manually after we call call transform().\r\nSo I think maybe it could be better to have a flatten argument in transform() directly? For example:\r\n```\r\n    def transform(self, fn, lazy=True, flatten=False):\r\n        trans = _LazyTransformDataset(self, fn)\r\n        if lazy:\r\n            return trans\r\n        if flatten:\r\n            return SimpleDataset(list(itertools.chain.from_iterable([i for i in trans])))\r\n        return SimpleDataset([i for i in trans])\r\n```\r\n\r\n\r\n## References\r\n- list reference and related literature\r\n- list known implementations\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1029/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1029/timeline","performed_via_github_app":null,"state_reason":null}