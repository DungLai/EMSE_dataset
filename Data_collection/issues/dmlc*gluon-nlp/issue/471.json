{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/471","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/471/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/471/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/471/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/471","id":393025861,"node_id":"MDU6SXNzdWUzOTMwMjU4NjE=","number":471,"title":"[API] ConvolutionalEncoder : Some confusion about the ConvolutionalEncoder interface.","user":{"login":"vanewu","id":27672489,"node_id":"MDQ6VXNlcjI3NjcyNDg5","avatar_url":"https://avatars.githubusercontent.com/u/27672489?v=4","gravatar_id":"","url":"https://api.github.com/users/vanewu","html_url":"https://github.com/vanewu","followers_url":"https://api.github.com/users/vanewu/followers","following_url":"https://api.github.com/users/vanewu/following{/other_user}","gists_url":"https://api.github.com/users/vanewu/gists{/gist_id}","starred_url":"https://api.github.com/users/vanewu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vanewu/subscriptions","organizations_url":"https://api.github.com/users/vanewu/orgs","repos_url":"https://api.github.com/users/vanewu/repos","events_url":"https://api.github.com/users/vanewu/events{/privacy}","received_events_url":"https://api.github.com/users/vanewu/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2018-12-20T12:28:29Z","updated_at":"2018-12-26T13:35:02Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"This interface is very good, but there are two points that are confusing.\r\n First, this interface does not provide padding. Although the effect of padding may be small in one-dimensional convolution due to GlobalMaxPool1D. But acutally it may be a little different. If I have a specific demand that want to pad data, I need to pad the input 3D data independently. But the ndarray padding currently only supports 4d and 5d. I need to change the dimension, which adds some extra unnecessary operations. Maybe adding padding to the implementation of this interface will be easier to use. Also adding padding to this interface is easy because conv1d is used internally.\r\n```python\r\nseq.add(nn.Conv1D(in_channels=self._embed_size,\r\n                                      channels=num_filter,\r\n                                      kernel_size=ngram_size,\r\n                                      use_bias=True))\r\n```\r\nSecond, I think the input of the general convolution will be the 0th dimension of the batch, but the input of this interface is not. I have seen the implementation. it has internally performed the dimensional transformation. Is this necessary?\r\n```python\r\ninputs = F.transpose(inputs, axes=(1, 2, 0))\r\n``` \r\nMaybe this interface will be more intuitive when the batch is in the 0th dimension.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/471/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/471/timeline","performed_via_github_app":null,"state_reason":null}