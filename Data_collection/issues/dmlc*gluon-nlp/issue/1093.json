{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1093","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1093/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1093/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1093/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/1093","id":545517052,"node_id":"MDU6SXNzdWU1NDU1MTcwNTI=","number":1093,"title":"Add suffix support for bert tokenization for NER","user":{"login":"XINGXIAOYU","id":17694187,"node_id":"MDQ6VXNlcjE3Njk0MTg3","avatar_url":"https://avatars.githubusercontent.com/u/17694187?v=4","gravatar_id":"","url":"https://api.github.com/users/XINGXIAOYU","html_url":"https://github.com/XINGXIAOYU","followers_url":"https://api.github.com/users/XINGXIAOYU/followers","following_url":"https://api.github.com/users/XINGXIAOYU/following{/other_user}","gists_url":"https://api.github.com/users/XINGXIAOYU/gists{/gist_id}","starred_url":"https://api.github.com/users/XINGXIAOYU/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/XINGXIAOYU/subscriptions","organizations_url":"https://api.github.com/users/XINGXIAOYU/orgs","repos_url":"https://api.github.com/users/XINGXIAOYU/repos","events_url":"https://api.github.com/users/XINGXIAOYU/events{/privacy}","received_events_url":"https://api.github.com/users/XINGXIAOYU/received_events","type":"User","site_admin":false},"labels":[{"id":890393503,"node_id":"MDU6TGFiZWw4OTAzOTM1MDM=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement","name":"enhancement","color":"135caf","default":true,"description":"New feature or request"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-01-06T03:14:07Z","updated_at":"2020-01-06T03:47:05Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"## Description\r\nIn finetune_ner.py, I find that only the first token of the subword list is tagged and other pieces of subword are tagged as 'O'. Is that mean we only choose the feature of the prefix of the words? What about choosing the suffix feature of the words? \r\n```\r\ndef bert_tokenize_sentence(sentence, bert_tokenizer):\r\n    \"\"\"Apply BERT tokenizer on a tagged sentence to break words into sub-words.\r\n    This function assumes input tags are following IOBES, and outputs IOBES tags.\r\n    Parameters\r\n    ----------\r\n    sentence: List[TaggedToken]\r\n        List of tagged words\r\n    bert_tokenizer: nlp.data.BertTokenizer\r\n        BERT tokenizer\r\n    Returns\r\n    -------\r\n    List[TaggedToken]: list of annotated sub-word tokens\r\n    \"\"\"\r\n    ret = []\r\n    for token in sentence:\r\n        # break a word into sub-word tokens\r\n        sub_token_texts = bert_tokenizer(token.text)\r\n        # only the first token of a word is going to be tagged\r\n        ret.append(TaggedToken(text=sub_token_texts[0], tag=token.tag))\r\n        ret += [TaggedToken(text=sub_token_text, tag=NULL_TAG)\r\n                for sub_token_text in sub_token_texts[1:]]\r\n\r\n    return ret\r\n```\r\n## Reference\r\n- allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer(pretrained_model: str, use_starting_offsets: bool = False, do_lowercase: bool = True, never_lowercase: List[str] = None, max_pieces: int = 512, truncate_long_sequences: bool = True) [source code](https://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/wordpiece_indexer.py#L296-L367). \r\nWe can use the parameter 'use_starting_offsets' to choose the first wordpiece or the last wordpiece of the subwords.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1093/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1093/timeline","performed_via_github_app":null,"state_reason":null}