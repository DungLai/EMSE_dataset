{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1311","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1311/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1311/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1311/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/1311","id":684281013,"node_id":"MDU6SXNzdWU2ODQyODEwMTM=","number":1311,"title":"[Numpy] [Performance] Boolean masking + Wrap masked_softmax and masked_logsoftmax to mxnet operators","user":{"login":"sxjscience","id":5178350,"node_id":"MDQ6VXNlcjUxNzgzNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5178350?v=4","gravatar_id":"","url":"https://api.github.com/users/sxjscience","html_url":"https://github.com/sxjscience","followers_url":"https://api.github.com/users/sxjscience/followers","following_url":"https://api.github.com/users/sxjscience/following{/other_user}","gists_url":"https://api.github.com/users/sxjscience/gists{/gist_id}","starred_url":"https://api.github.com/users/sxjscience/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sxjscience/subscriptions","organizations_url":"https://api.github.com/users/sxjscience/orgs","repos_url":"https://api.github.com/users/sxjscience/repos","events_url":"https://api.github.com/users/sxjscience/events{/privacy}","received_events_url":"https://api.github.com/users/sxjscience/received_events","type":"User","site_admin":false},"labels":[{"id":890393503,"node_id":"MDU6TGFiZWw4OTAzOTM1MDM=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement","name":"enhancement","color":"135caf","default":true,"description":"New feature or request"},{"id":2278734280,"node_id":"MDU6TGFiZWwyMjc4NzM0Mjgw","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/performance","name":"performance","color":"e99695","default":false,"description":"Performance issues"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-08-23T23:57:58Z","updated_at":"2020-08-23T23:59:31Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Here, the mask for attention layers can actually have boolean type, which will be far-less computationally-heavy than float32 type. Previously, I haven't added the support due to some issues in the boolean support of the DeepNumpy interface in MXNet 2.0. However, we may try to fix it now.\r\n\r\nIn addition, we can directly add `masked_softmax` and `masked_logsoftmax` to npx operators.\r\n\r\nThe following is the list of functions that should be revised:\r\n\r\nhttps://github.com/dmlc/gluon-nlp/blob/210dd0ca9be36fe82643d28a7e495e9647b09d5f/src/gluonnlp/attention_cell.py#L33-L162\r\n\r\nhttps://github.com/dmlc/gluon-nlp/blob/210dd0ca9be36fe82643d28a7e495e9647b09d5f/src/gluonnlp/attention_cell.py#L248-L287\r\n\r\nhttps://github.com/dmlc/gluon-nlp/blob/210dd0ca9be36fe82643d28a7e495e9647b09d5f/src/gluonnlp/attention_cell.py#L291-L330\r\n\r\ncc @dmlc/gluon-nlp-committers ","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1311/reactions","total_count":2,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":2,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1311/timeline","performed_via_github_app":null,"state_reason":null}