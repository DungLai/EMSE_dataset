{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/680","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/680/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/680/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/680/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/680","id":437155883,"node_id":"MDU6SXNzdWU0MzcxNTU4ODM=","number":680,"title":"vocabulary set_embedding(glove) maps all OOV terms to the same vector if no lookup provided","user":{"login":"khui","id":5355226,"node_id":"MDQ6VXNlcjUzNTUyMjY=","avatar_url":"https://avatars.githubusercontent.com/u/5355226?v=4","gravatar_id":"","url":"https://api.github.com/users/khui","html_url":"https://github.com/khui","followers_url":"https://api.github.com/users/khui/followers","following_url":"https://api.github.com/users/khui/following{/other_user}","gists_url":"https://api.github.com/users/khui/gists{/gist_id}","starred_url":"https://api.github.com/users/khui/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/khui/subscriptions","organizations_url":"https://api.github.com/users/khui/orgs","repos_url":"https://api.github.com/users/khui/repos","events_url":"https://api.github.com/users/khui/events{/privacy}","received_events_url":"https://api.github.com/users/khui/received_events","type":"User","site_admin":false},"labels":[{"id":890393503,"node_id":"MDU6TGFiZWw4OTAzOTM1MDM=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement","name":"enhancement","color":"135caf","default":true,"description":"New feature or request"}],"state":"open","locked":false,"assignee":{"login":"leezu","id":946903,"node_id":"MDQ6VXNlcjk0NjkwMw==","avatar_url":"https://avatars.githubusercontent.com/u/946903?v=4","gravatar_id":"","url":"https://api.github.com/users/leezu","html_url":"https://github.com/leezu","followers_url":"https://api.github.com/users/leezu/followers","following_url":"https://api.github.com/users/leezu/following{/other_user}","gists_url":"https://api.github.com/users/leezu/gists{/gist_id}","starred_url":"https://api.github.com/users/leezu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leezu/subscriptions","organizations_url":"https://api.github.com/users/leezu/orgs","repos_url":"https://api.github.com/users/leezu/repos","events_url":"https://api.github.com/users/leezu/events{/privacy}","received_events_url":"https://api.github.com/users/leezu/received_events","type":"User","site_admin":false},"assignees":[{"login":"leezu","id":946903,"node_id":"MDQ6VXNlcjk0NjkwMw==","avatar_url":"https://avatars.githubusercontent.com/u/946903?v=4","gravatar_id":"","url":"https://api.github.com/users/leezu","html_url":"https://github.com/leezu","followers_url":"https://api.github.com/users/leezu/followers","following_url":"https://api.github.com/users/leezu/following{/other_user}","gists_url":"https://api.github.com/users/leezu/gists{/gist_id}","starred_url":"https://api.github.com/users/leezu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leezu/subscriptions","organizations_url":"https://api.github.com/users/leezu/orgs","repos_url":"https://api.github.com/users/leezu/repos","events_url":"https://api.github.com/users/leezu/events{/privacy}","received_events_url":"https://api.github.com/users/leezu/received_events","type":"User","site_admin":false}],"milestone":null,"comments":6,"created_at":"2019-04-25T11:46:37Z","updated_at":"2019-06-23T21:41:18Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"When attaching the pre-trained embedding to a built vocab, namely, `vocab.set_embedding(glove_em)`, by design, all of the vocabulary that did not present in the pre-trained embedding will be mapped to the `<'unk'>` using init_unknown_vec (default `nd.zeros`).\r\n\r\nThis is a bit awkward since the `<'unk'>` was defined in building vocabulary already (e.g., using a threshold of mininal term frequency), and one may expect all of these OOV terms are at least mapped to different random vectors instead of the same vector. \r\n\r\nOf course, when using FastText and enable the ngram or providing `unknown_lookup` could resolve it. However, as the default behavior, it is still a bit counter-converntion. \r\n\r\n```\r\ntext_data = \"Computing-Tabulating-Recording \\\\n affective-motivational \\\\n teacher-dealers\"\r\ncounter = gluonnlp.data.count_tokens(text_data)\r\nvocab = gluonnlp.Vocab(counter,  unknown_token='<unk>', min_freq=self.min_freq)\r\nem = gluonnlp.embedding.create('GloVe',\r\n                               unknown_token='<unk>',\r\n                               source='glove.840B.300d',\r\n                               allow_extend=True,\r\n                               init_unknown_vec=nd.random.uniform)\r\nvocab.set_embedding(em)\r\n```","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/680/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/680/timeline","performed_via_github_app":null,"state_reason":null}