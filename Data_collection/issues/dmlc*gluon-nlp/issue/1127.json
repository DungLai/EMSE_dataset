{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1127","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1127/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1127/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1127/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/1127","id":555238982,"node_id":"MDU6SXNzdWU1NTUyMzg5ODI=","number":1127,"title":"BERT: Cannot get the reported accuracy with the master branch","user":{"login":"TaoLv","id":22437510,"node_id":"MDQ6VXNlcjIyNDM3NTEw","avatar_url":"https://avatars.githubusercontent.com/u/22437510?v=4","gravatar_id":"","url":"https://api.github.com/users/TaoLv","html_url":"https://github.com/TaoLv","followers_url":"https://api.github.com/users/TaoLv/followers","following_url":"https://api.github.com/users/TaoLv/following{/other_user}","gists_url":"https://api.github.com/users/TaoLv/gists{/gist_id}","starred_url":"https://api.github.com/users/TaoLv/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/TaoLv/subscriptions","organizations_url":"https://api.github.com/users/TaoLv/orgs","repos_url":"https://api.github.com/users/TaoLv/repos","events_url":"https://api.github.com/users/TaoLv/events{/privacy}","received_events_url":"https://api.github.com/users/TaoLv/received_events","type":"User","site_admin":false},"labels":[{"id":890393501,"node_id":"MDU6TGFiZWw4OTAzOTM1MDE=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2020-01-26T14:50:30Z","updated_at":"2020-01-27T14:40:46Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Cannot the reported accuracy with the master branch of GluonNLP and a nightly build of MXNet.\r\n\r\nTake MRPC fine-tuning as an example:\r\n\r\n```\r\n(mxnet) [lvtao@mlt-gpu200 bert]$ python finetune_classifier.py --task_name MRPC --batch_size 32 --epochs 3 --gpu 0 --lr 2e-5\r\nINFO:root:22:47:22 Namespace(accumulate=None, batch_size=32, bert_dataset='book_corpus_wiki_en_uncased', bert_model='bert_12_768_12', dev_batch_size=8, dtype='float32', early_stop=None, epochs=3, epsilon=1e-06, gpu=0, log_interval=10, lr=2e-05, max_len=128, model_parameters=None, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, seed=2, task_name='MRPC', training_steps=None, warmup_ratio=0.1)\r\n[22:47:24] src/base.cc:51: Upgrade advisory: this mxnet has been built against cuda library version 9020, which is older than the oldest version tested by CI (10000).  Set MXNET_CUDA_LIB_CHECKING=0 to quiet this warning.\r\nINFO:root:22:47:28 processing dataset...\r\nINFO:root:22:47:30 Now we are doing BERT classification training on gpu(0)!\r\nINFO:root:22:47:30 training steps=343\r\nINFO:root:22:47:33 [Epoch 1 Batch 10/119] loss=0.6328, lr=0.0000053, metrics:accuracy:0.6844,f1:0.8112\r\nINFO:root:22:47:34 [Epoch 1 Batch 20/119] loss=0.6421, lr=0.0000112, metrics:accuracy:0.6693,f1:0.7937\r\nINFO:root:22:47:36 [Epoch 1 Batch 30/119] loss=0.6187, lr=0.0000171, metrics:accuracy:0.6786,f1:0.8026\r\nINFO:root:22:47:38 [Epoch 1 Batch 40/119] loss=0.5839, lr=0.0000197, metrics:accuracy:0.6881,f1:0.8085\r\nINFO:root:22:47:39 [Epoch 1 Batch 50/119] loss=0.6971, lr=0.0000190, metrics:accuracy:0.6719,f1:0.7961\r\nINFO:root:22:47:41 [Epoch 1 Batch 60/119] loss=0.6307, lr=0.0000184, metrics:accuracy:0.6696,f1:0.7929\r\nINFO:root:22:47:42 [Epoch 1 Batch 70/119] loss=0.6842, lr=0.0000177, metrics:accuracy:0.6565,f1:0.7792\r\nINFO:root:22:47:44 [Epoch 1 Batch 80/119] loss=0.6355, lr=0.0000171, metrics:accuracy:0.6540,f1:0.7765\r\nINFO:root:22:47:45 [Epoch 1 Batch 90/119] loss=0.6826, lr=0.0000164, metrics:accuracy:0.6540,f1:0.7782\r\nINFO:root:22:47:47 [Epoch 1 Batch 100/119] loss=0.6138, lr=0.0000158, metrics:accuracy:0.6595,f1:0.7838\r\nINFO:root:22:47:49 [Epoch 1 Batch 110/119] loss=0.6562, lr=0.0000151, metrics:accuracy:0.6583,f1:0.7840\r\nINFO:root:22:47:50 Now we are doing evaluation on dev with gpu(0).\r\nINFO:root:22:47:51 [Batch 10/51] loss=0.6115, metrics:accuracy:0.7000,f1:0.8235\r\nINFO:root:22:47:51 [Batch 20/51] loss=0.6306, metrics:accuracy:0.6875,f1:0.8148\r\nINFO:root:22:47:51 [Batch 30/51] loss=0.6021, metrics:accuracy:0.6958,f1:0.8206\r\nINFO:root:22:47:51 [Batch 40/51] loss=0.6307, metrics:accuracy:0.6906,f1:0.8170\r\nINFO:root:22:47:52 [Batch 50/51] loss=0.6401, metrics:accuracy:0.6850,f1:0.8131\r\nINFO:root:22:47:52 validation metrics:accuracy:0.6838,f1:0.8122\r\nINFO:root:22:47:52 Time cost=1.50s, throughput=272.63 samples/s\r\nINFO:root:22:47:56 params saved in: ./output_dir/model_bert_MRPC_0.params\r\nINFO:root:22:47:56 Time cost=26.15s\r\nINFO:root:22:47:58 [Epoch 2 Batch 10/119] loss=0.6394, lr=0.0000139, metrics:accuracy:0.6632,f1:0.7975\r\nINFO:root:22:48:00 [Epoch 2 Batch 20/119] loss=0.6355, lr=0.0000133, metrics:accuracy:0.6710,f1:0.8031\r\nINFO:root:22:48:01 [Epoch 2 Batch 30/119] loss=0.6387, lr=0.0000126, metrics:accuracy:0.6692,f1:0.8018\r\nINFO:root:22:48:03 [Epoch 2 Batch 40/119] loss=0.6460, lr=0.0000120, metrics:accuracy:0.6659,f1:0.7994\r\nINFO:root:22:48:04 [Epoch 2 Batch 50/119] loss=0.6451, lr=0.0000113, metrics:accuracy:0.6665,f1:0.7998\r\nINFO:root:22:48:06 [Epoch 2 Batch 60/119] loss=0.6128, lr=0.0000107, metrics:accuracy:0.6677,f1:0.8008\r\nINFO:root:22:48:08 [Epoch 2 Batch 70/119] loss=0.6269, lr=0.0000100, metrics:accuracy:0.6700,f1:0.8024\r\nINFO:root:22:48:09 [Epoch 2 Batch 80/119] loss=0.6391, lr=0.0000094, metrics:accuracy:0.6691,f1:0.8017\r\nINFO:root:22:48:11 [Epoch 2 Batch 90/119] loss=0.6051, lr=0.0000087, metrics:accuracy:0.6715,f1:0.8035\r\nINFO:root:22:48:12 [Epoch 2 Batch 100/119] loss=0.5598, lr=0.0000081, metrics:accuracy:0.6768,f1:0.8070\r\nINFO:root:22:48:14 [Epoch 2 Batch 110/119] loss=0.6328, lr=0.0000074, metrics:accuracy:0.6781,f1:0.8058\r\nINFO:root:22:48:15 Now we are doing evaluation on dev with gpu(0).\r\nINFO:root:22:48:16 [Batch 10/51] loss=0.5951, metrics:accuracy:0.7125,f1:0.8217\r\nINFO:root:22:48:16 [Batch 20/51] loss=0.6593, metrics:accuracy:0.6750,f1:0.7984\r\nINFO:root:22:48:16 [Batch 30/51] loss=0.6350, metrics:accuracy:0.6792,f1:0.8021\r\nINFO:root:22:48:16 [Batch 40/51] loss=0.6661, metrics:accuracy:0.6687,f1:0.7954\r\nINFO:root:22:48:16 [Batch 50/51] loss=0.6437, metrics:accuracy:0.6725,f1:0.7969\r\nINFO:root:22:48:16 validation metrics:accuracy:0.6691,f1:0.7939\r\nINFO:root:22:48:16 Time cost=1.21s, throughput=338.03 samples/s\r\nINFO:root:22:48:21 params saved in: ./output_dir/model_bert_MRPC_1.params\r\nINFO:root:22:48:21 Time cost=24.79s\r\nINFO:root:22:48:23 [Epoch 3 Batch 10/119] loss=0.6267, lr=0.0000062, metrics:accuracy:0.6869,f1:0.8056\r\nINFO:root:22:48:24 [Epoch 3 Batch 20/119] loss=0.5999, lr=0.0000056, metrics:accuracy:0.6923,f1:0.8068\r\nINFO:root:22:48:26 [Epoch 3 Batch 30/119] loss=0.5741, lr=0.0000049, metrics:accuracy:0.7023,f1:0.8085\r\nINFO:root:22:48:28 [Epoch 3 Batch 40/119] loss=0.5909, lr=0.0000043, metrics:accuracy:0.7073,f1:0.8122\r\nINFO:root:22:48:29 [Epoch 3 Batch 50/119] loss=0.5718, lr=0.0000036, metrics:accuracy:0.7042,f1:0.8101\r\nINFO:root:22:48:31 [Epoch 3 Batch 60/119] loss=0.5747, lr=0.0000030, metrics:accuracy:0.7084,f1:0.8130\r\nINFO:root:22:48:32 [Epoch 3 Batch 70/119] loss=0.6543, lr=0.0000023, metrics:accuracy:0.6932,f1:0.7982\r\nINFO:root:22:48:34 [Epoch 3 Batch 80/119] loss=0.5972, lr=0.0000017, metrics:accuracy:0.6906,f1:0.7954\r\nINFO:root:22:48:35 [Epoch 3 Batch 90/119] loss=0.5921, lr=0.0000010, metrics:accuracy:0.6917,f1:0.7971\r\nINFO:root:22:48:37 [Epoch 3 Batch 100/119] loss=0.5446, lr=0.0000004, metrics:accuracy:0.6964,f1:0.8009\r\nINFO:root:22:48:38 Finish training step: 343\r\nINFO:root:22:48:38 Now we are doing evaluation on dev with gpu(0).\r\nINFO:root:22:48:38 [Batch 10/51] loss=0.5878, metrics:accuracy:0.6875,f1:0.7934\r\nINFO:root:22:48:38 [Batch 20/51] loss=0.6297, metrics:accuracy:0.6562,f1:0.7755\r\nINFO:root:22:48:38 [Batch 30/51] loss=0.6211, metrics:accuracy:0.6583,f1:0.7784\r\nINFO:root:22:48:39 [Batch 40/51] loss=0.6200, metrics:accuracy:0.6594,f1:0.7789\r\nINFO:root:22:48:39 [Batch 50/51] loss=0.5931, metrics:accuracy:0.6675,f1:0.7837\r\nINFO:root:22:48:39 validation metrics:accuracy:0.6667,f1:0.7821\r\nINFO:root:22:48:39 Time cost=1.27s, throughput=321.60 samples/s\r\nINFO:root:22:48:43 params saved in: ./output_dir/model_bert_MRPC_2.params\r\nINFO:root:22:48:43 Time cost=22.36s\r\nINFO:root:22:48:47 Best model at epoch 0. Validation metrics:accuracy:0.6838,f1:0.8122\r\nINFO:root:22:48:47 Now we are doing testing on test with gpu(0).\r\nINFO:root:22:48:52 Time cost=4.64s, throughput=372.78 samples/s\r\n```\r\n\r\nGluonNLP is installed from source code. Commit id: aa663284c9c94c0792f3d0ac901e1af2ef81e1fb\r\nMXNet nightly build: mxnet-cu92 (1.6.0b20200118)","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1127/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1127/timeline","performed_via_github_app":null,"state_reason":null}