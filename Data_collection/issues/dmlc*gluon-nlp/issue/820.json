{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/820","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/820/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/820/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/820/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/820","id":465566245,"node_id":"MDU6SXNzdWU0NjU1NjYyNDU=","number":820,"title":"FixedBucketSampler causes excessive memory consumption","user":{"login":"rjk-git","id":44219470,"node_id":"MDQ6VXNlcjQ0MjE5NDcw","avatar_url":"https://avatars.githubusercontent.com/u/44219470?v=4","gravatar_id":"","url":"https://api.github.com/users/rjk-git","html_url":"https://github.com/rjk-git","followers_url":"https://api.github.com/users/rjk-git/followers","following_url":"https://api.github.com/users/rjk-git/following{/other_user}","gists_url":"https://api.github.com/users/rjk-git/gists{/gist_id}","starred_url":"https://api.github.com/users/rjk-git/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rjk-git/subscriptions","organizations_url":"https://api.github.com/users/rjk-git/orgs","repos_url":"https://api.github.com/users/rjk-git/repos","events_url":"https://api.github.com/users/rjk-git/events{/privacy}","received_events_url":"https://api.github.com/users/rjk-git/received_events","type":"User","site_admin":false},"labels":[{"id":890393501,"node_id":"MDU6TGFiZWw4OTAzOTM1MDE=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2019-07-09T04:43:53Z","updated_at":"2019-08-28T19:20:04Z","closed_at":"2019-08-28T19:20:04Z","author_association":"NONE","active_lock_reason":null,"body":"## Description\r\nI am having a problem with FixedBucketSampler. My language model uses a simple lstm, hidden_dim:300, num_layer:3. Batch_size: 32, max_seq_len: 100. However, the memory consumption will reach 15G after training 1000batch. In this process, the memory consumption has been increasing.\r\n\r\n### Error Message\r\nThere is an obvious rule: if the current batch has a length of 46 and the next batch is still 46, the memory will hardly increase. However, if the sentence length of the next batch is different, the memory consumption of less than or greater than 46 will continue to increase.\r\nThen I fixed the length of each batch of sentences into same length, and the memory consumption will be fixed at around 3G.\r\nI think that using batch data with different sentence lengths, the memory consumption is too large, is there a BUG.\r\n","closed_by":{"login":"szha","id":2626883,"node_id":"MDQ6VXNlcjI2MjY4ODM=","avatar_url":"https://avatars.githubusercontent.com/u/2626883?v=4","gravatar_id":"","url":"https://api.github.com/users/szha","html_url":"https://github.com/szha","followers_url":"https://api.github.com/users/szha/followers","following_url":"https://api.github.com/users/szha/following{/other_user}","gists_url":"https://api.github.com/users/szha/gists{/gist_id}","starred_url":"https://api.github.com/users/szha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/szha/subscriptions","organizations_url":"https://api.github.com/users/szha/orgs","repos_url":"https://api.github.com/users/szha/repos","events_url":"https://api.github.com/users/szha/events{/privacy}","received_events_url":"https://api.github.com/users/szha/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/820/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/820/timeline","performed_via_github_app":null,"state_reason":"completed"}