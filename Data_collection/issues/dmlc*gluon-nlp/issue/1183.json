{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1183","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1183/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1183/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1183/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/1183","id":580875824,"node_id":"MDU6SXNzdWU1ODA4NzU4MjQ=","number":1183,"title":"GluonNLP 0.9.x RoBERTa model return inconsistent encoded result comparing to Fairseq ","user":{"login":"kaonashi-tyc","id":11814502,"node_id":"MDQ6VXNlcjExODE0NTAy","avatar_url":"https://avatars.githubusercontent.com/u/11814502?v=4","gravatar_id":"","url":"https://api.github.com/users/kaonashi-tyc","html_url":"https://github.com/kaonashi-tyc","followers_url":"https://api.github.com/users/kaonashi-tyc/followers","following_url":"https://api.github.com/users/kaonashi-tyc/following{/other_user}","gists_url":"https://api.github.com/users/kaonashi-tyc/gists{/gist_id}","starred_url":"https://api.github.com/users/kaonashi-tyc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kaonashi-tyc/subscriptions","organizations_url":"https://api.github.com/users/kaonashi-tyc/orgs","repos_url":"https://api.github.com/users/kaonashi-tyc/repos","events_url":"https://api.github.com/users/kaonashi-tyc/events{/privacy}","received_events_url":"https://api.github.com/users/kaonashi-tyc/received_events","type":"User","site_admin":false},"labels":[{"id":890393501,"node_id":"MDU6TGFiZWw4OTAzOTM1MDE=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":{"login":"eric-haibin-lin","id":5545640,"node_id":"MDQ6VXNlcjU1NDU2NDA=","avatar_url":"https://avatars.githubusercontent.com/u/5545640?v=4","gravatar_id":"","url":"https://api.github.com/users/eric-haibin-lin","html_url":"https://github.com/eric-haibin-lin","followers_url":"https://api.github.com/users/eric-haibin-lin/followers","following_url":"https://api.github.com/users/eric-haibin-lin/following{/other_user}","gists_url":"https://api.github.com/users/eric-haibin-lin/gists{/gist_id}","starred_url":"https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eric-haibin-lin/subscriptions","organizations_url":"https://api.github.com/users/eric-haibin-lin/orgs","repos_url":"https://api.github.com/users/eric-haibin-lin/repos","events_url":"https://api.github.com/users/eric-haibin-lin/events{/privacy}","received_events_url":"https://api.github.com/users/eric-haibin-lin/received_events","type":"User","site_admin":false},"assignees":[{"login":"eric-haibin-lin","id":5545640,"node_id":"MDQ6VXNlcjU1NDU2NDA=","avatar_url":"https://avatars.githubusercontent.com/u/5545640?v=4","gravatar_id":"","url":"https://api.github.com/users/eric-haibin-lin","html_url":"https://github.com/eric-haibin-lin","followers_url":"https://api.github.com/users/eric-haibin-lin/followers","following_url":"https://api.github.com/users/eric-haibin-lin/following{/other_user}","gists_url":"https://api.github.com/users/eric-haibin-lin/gists{/gist_id}","starred_url":"https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eric-haibin-lin/subscriptions","organizations_url":"https://api.github.com/users/eric-haibin-lin/orgs","repos_url":"https://api.github.com/users/eric-haibin-lin/repos","events_url":"https://api.github.com/users/eric-haibin-lin/events{/privacy}","received_events_url":"https://api.github.com/users/eric-haibin-lin/received_events","type":"User","site_admin":false}],"milestone":null,"comments":22,"created_at":"2020-03-13T21:47:21Z","updated_at":"2020-09-04T21:19:16Z","closed_at":"2020-09-04T21:19:16Z","author_association":"NONE","active_lock_reason":null,"body":"## Description\r\nI am working on porting XLM-R model to gluonnlp (view this script here [convert_xlmr_model_to_gluon.py](https://gist.github.com/kaonashi-tyc/5f77b962c5be70395f4875f77b3f7149)). \r\n\r\nThe XLM-R model reuses the same RoBERTa model architecture from fairseq.\r\n\r\nWhen using gluonnlp 0.8.x, the converted model can match the fairseq reference implementation with a small error range within 5e-6, and the std-dev is small (< 8e-7)\r\n\r\nOnce updated gluonnlp to 0.9.x, the result no longer matches, and std-dev increases to 0.2+ ranges, which indicates drastically different output.\r\n\r\n### Error Message\r\n```\r\n*** Maximum errors for vector of size 3840:  rtol=0.001, atol=0.001\r\n\r\n  1: Error 1004.472290  Location of error: (0, 3, 152), a=1.01276851, b=-1.85498929\r\n  2: Error 704.275513  Location of error: (0, 4, 588), a=1.44983745, b=7.28419113\r\n  3: Error 647.055481  Location of error: (0, 3, 465), a=-0.56997168, b=0.21840204\r\n  4: Error 600.452820  Location of error: (0, 0, 588), a=1.60323822, b=5.51547194\r\n  5: Error 538.981934  Location of error: (0, 2, 749), a=-0.70366722, b=-0.10700922\r\n  6: Error 522.929871  Location of error: (0, 2, 465), a=-0.22267081, b=0.62938148\r\n  7: Error 508.802521  Location of error: (0, 3, 467), a=0.50823522, b=-0.00115502\r\n  8: Error 508.074951  Location of error: (0, 2, 459), a=-0.04906127, b=-1.13256359\r\n  9: Error 489.669586  Location of error: (0, 2, 152), a=0.31114388, b=-0.34982380\r\n 10: Error 481.314819  Location of error: (0, 2, 145), a=1.19826353, b=0.48399478\r\nTraceback (most recent call last):\r\n  File \"xlmr_conversion/convert_vocab.py\", line 198, in <module>\r\n    check_output('Hello world!')\r\n  File \"xlmr_conversion/convert_vocab.py\", line 192, in check_output\r\n    mx.test_utils.assert_almost_equal(mx_output.asnumpy(), torch_output, atol=1e-3, rtol=1e-3)\r\n  File \"/efs/users/tiayuche/mxnet16/lib/python3.6/site-packages/mxnet/test_utils.py\", line 627, in assert_almost_equal\r\n    raise AssertionError(msg)\r\nAssertionError:\r\nItems are not equal:\r\nError 1004.472290 exceeds tolerance rtol=1.000000e-03, atol=1.000000e-03 (mismatch at least 0.286458%).\r\nLocation of maximum error: (0, 3, 152), a=1.01276851, b=-1.85498929\r\n ACTUAL: array([[[ 0.09790944,  0.08255608,  0.01538194, ..., -0.20328012,\r\n          0.02295702,  0.06142968],\r\n        [-0.13235903,  0.02904704, -0.09925546, ..., -0.03289408,...\r\n DESIRED: array([[[ 0.28058335,  0.18484427,  0.09018373, ..., -0.2651089 ,\r\n          0.10111443, -0.05324648],\r\n        [-0.05585899,  0.07528387, -0.04672416, ...,  0.12345381,...\r\n\r\n```\r\n## To Reproduce\r\n\r\n### Steps to reproduce\r\n(Paste the commands you ran that produced the error.)\r\n\r\n1. download the xlm-r model artifacts from fairseq repo:\r\nhttps://github.com/pytorch/fairseq/tree/master/examples/xlmr\r\n\r\n2. Install both fairseq and gluonnlp and sentencepieces via pip\r\n\r\n3. run the following command\r\n\r\n`python convert_xlmr_model_to_gluon.py --ckpt_dir xlmr_ckpt/xlmr.base/ --verbose` \r\n\r\n## What have you tried to solve it?\r\n\r\nI have notified @eric-haibin-lin and identified the regression happens after this commit:\r\n\r\n184a0007bc4165d5fe080a58dd3ff9bb413203a6\r\n\r\nFurther investigation will be needed to pinpoint the exact change causing this bug.\r\n\r\n## Environment\r\n\r\nWe recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\r\n```\r\ncurl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\r\n\r\n----------Python Info----------\r\nVersion      : 3.6.6\r\nCompiler     : GCC 7.2.0\r\nBuild        : ('default', 'Jun 28 2018 17:14:51')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 20.0.2\r\nDirectory    : XXXXX\r\n----------MXNet Info-----------\r\nVersion      : 1.6.0\r\nDirectory    : XXXX\r\nNum GPUs     : 4\r\nCommit Hash   : 6eec9da55c5096079355d1f1a5fa58dcf35d6752\r\n----------System Info----------\r\nPlatform     : Linux-4.4.0-1102-aws-x86_64-with-debian-stretch-sid\r\nsystem       : Linux\r\nnode         : ip-172-31-21-222\r\nrelease      : 4.4.0-1102-aws\r\nversion      : #113-Ubuntu SMP Wed Jan 29 14:54:54 UTC 2020\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0011 sec, LOAD: 0.0248 sec.\r\nTiming for GluonNLP GitHub: https://github.com/dmlc/gluon-nlp, DNS: 0.0003 sec, LOAD: 0.0223 sec.\r\nTiming for GluonNLP: http://gluon-nlp.mxnet.io, DNS: 0.0004 sec, LOAD: 0.0200 sec.\r\nTiming for D2L: http://d2l.ai, DNS: 0.0003 sec, LOAD: 0.0035 sec.\r\nTiming for D2L (zh-cn): http://zh.d2l.ai, DNS: 0.0003 sec, LOAD: 0.0081 sec.\r\nTiming for FashionMNIST: https://repo.mxnet.io/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0005 sec, LOAD: 0.3333 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0004 sec, LOAD: 0.0586 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0003 sec, LOAD: 0.0333 sec.```\r\n","closed_by":{"login":"szha","id":2626883,"node_id":"MDQ6VXNlcjI2MjY4ODM=","avatar_url":"https://avatars.githubusercontent.com/u/2626883?v=4","gravatar_id":"","url":"https://api.github.com/users/szha","html_url":"https://github.com/szha","followers_url":"https://api.github.com/users/szha/followers","following_url":"https://api.github.com/users/szha/following{/other_user}","gists_url":"https://api.github.com/users/szha/gists{/gist_id}","starred_url":"https://api.github.com/users/szha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/szha/subscriptions","organizations_url":"https://api.github.com/users/szha/orgs","repos_url":"https://api.github.com/users/szha/repos","events_url":"https://api.github.com/users/szha/events{/privacy}","received_events_url":"https://api.github.com/users/szha/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1183/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1183/timeline","performed_via_github_app":null,"state_reason":"completed"}