{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1164","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1164/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1164/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1164/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/1164","id":567375789,"node_id":"MDU6SXNzdWU1NjczNzU3ODk=","number":1164,"title":"is there an easy way to implement personal gpt2 model","user":{"login":"carter54","id":26741594,"node_id":"MDQ6VXNlcjI2NzQxNTk0","avatar_url":"https://avatars.githubusercontent.com/u/26741594?v=4","gravatar_id":"","url":"https://api.github.com/users/carter54","html_url":"https://github.com/carter54","followers_url":"https://api.github.com/users/carter54/followers","following_url":"https://api.github.com/users/carter54/following{/other_user}","gists_url":"https://api.github.com/users/carter54/gists{/gist_id}","starred_url":"https://api.github.com/users/carter54/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/carter54/subscriptions","organizations_url":"https://api.github.com/users/carter54/orgs","repos_url":"https://api.github.com/users/carter54/repos","events_url":"https://api.github.com/users/carter54/events{/privacy}","received_events_url":"https://api.github.com/users/carter54/received_events","type":"User","site_admin":false},"labels":[{"id":890393503,"node_id":"MDU6TGFiZWw4OTAzOTM1MDM=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement","name":"enhancement","color":"135caf","default":true,"description":"New feature or request"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-02-19T07:41:53Z","updated_at":"2020-02-19T09:02:30Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"## Description\r\nthe sequence_sampling.py script dose not offer an method to import users' personal model (gpt 2 in my case).\r\nhttps://github.com/dmlc/gluon-nlp/blob/ef57ca08ee507902a9b2fbb4dbcc4ca110d84cd3/scripts/text_generation/sequence_sampling.py#L146\r\nhttps://github.com/dmlc/gluon-nlp/blob/ef57ca08ee507902a9b2fbb4dbcc4ca110d84cd3/scripts/text_generation/sequence_sampling.py#L147\r\nwill force download model, vocab, and bpe from s3 if they are not in cache.\r\n\r\nis it possible to set an input parameter of customer model path, which allow users to apply their own models?\r\n\r\nI have tried to modify following functions to make it work:\r\nhttps://github.com/dmlc/gluon-nlp/blob/ef57ca08ee507902a9b2fbb4dbcc4ca110d84cd3/src/gluonnlp/data/utils.py#L373\r\nhttps://github.com/dmlc/gluon-nlp/blob/ef57ca08ee507902a9b2fbb4dbcc4ca110d84cd3/src/gluonnlp/data/transforms.py#L1114\r\nunfortunately, I have to modify a mxnet gluon file model_store.py, as the model file is loaded by this function\r\nhttps://github.com/apache/incubator-mxnet/blob/a11a9f9a8a0d412e421a87263dad9a4cde076d11/python/mxnet/gluon/model_zoo/model_store.py#L75\r\n\r\n\r\n## References\r\n- list reference and related literature\r\nI used https://github.com/sxjscience/gluonnlp-gpt2 to transfer model from tensorflow ckpt to mxnet, thanks to @sxjscience .\r\nI notice the vocab size might be different when applying this transferred mxnet model in the gluonnlp.\r\n\r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1164/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1164/timeline","performed_via_github_app":null,"state_reason":null}