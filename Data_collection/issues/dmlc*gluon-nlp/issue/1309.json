{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1309","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1309/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1309/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1309/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/1309","id":683942133,"node_id":"MDU6SXNzdWU2ODM5NDIxMzM=","number":1309,"title":"[Numpy][Pretrained Model] Add functionality to compress the vocabulary or add new special tokens for fast knowledge transfer","user":{"login":"sxjscience","id":5178350,"node_id":"MDQ6VXNlcjUxNzgzNTA=","avatar_url":"https://avatars.githubusercontent.com/u/5178350?v=4","gravatar_id":"","url":"https://api.github.com/users/sxjscience","html_url":"https://github.com/sxjscience","followers_url":"https://api.github.com/users/sxjscience/followers","following_url":"https://api.github.com/users/sxjscience/following{/other_user}","gists_url":"https://api.github.com/users/sxjscience/gists{/gist_id}","starred_url":"https://api.github.com/users/sxjscience/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sxjscience/subscriptions","organizations_url":"https://api.github.com/users/sxjscience/orgs","repos_url":"https://api.github.com/users/sxjscience/repos","events_url":"https://api.github.com/users/sxjscience/events{/privacy}","received_events_url":"https://api.github.com/users/sxjscience/received_events","type":"User","site_admin":false},"labels":[{"id":890393503,"node_id":"MDU6TGFiZWw4OTAzOTM1MDM=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement","name":"enhancement","color":"135caf","default":true,"description":"New feature or request"},{"id":963101581,"node_id":"MDU6TGFiZWw5NjMxMDE1ODE=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/discussion","name":"discussion","color":"c5def5","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2020-08-22T06:36:13Z","updated_at":"2020-08-25T19:27:04Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"When applying pretrained models on real datasets, we often need to adapt the tokenizer and ensure that we can appropriately transfer the knowledge:\r\n\r\n- Case 1: Trim the vocabulary\r\n\r\n   For example, multilingual models such as XLMR have a tremendously large vocabulary size. Sometimes, you will just want to train a model that works for English and Spanish and not all the languages supported by XLMR. Here, we may trim the vocabulary to only keep the tokens that are related to English and Spanish.\r\n\r\n- Case 2: Add new tokens into the vocabulary\r\n\r\n    You may have some special tokens other than [CLS] and [SEP] that have special meanings in the downstream application and you'd like to add more reserved tokens to the existing tokenizer.\r\n\r\nThus, we should consider about how to support both use cases.\r\n\r\n@garima3292 Please correct me if I'm wrong here in describing the use-cases.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1309/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1309/timeline","performed_via_github_app":null,"state_reason":null}