{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/690","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/690/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/690/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/690/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/690","id":439803401,"node_id":"MDU6SXNzdWU0Mzk4MDM0MDE=","number":690,"title":"[MXNet] - [BERT]","user":{"login":"araitats","id":34896074,"node_id":"MDQ6VXNlcjM0ODk2MDc0","avatar_url":"https://avatars.githubusercontent.com/u/34896074?v=4","gravatar_id":"","url":"https://api.github.com/users/araitats","html_url":"https://github.com/araitats","followers_url":"https://api.github.com/users/araitats/followers","following_url":"https://api.github.com/users/araitats/following{/other_user}","gists_url":"https://api.github.com/users/araitats/gists{/gist_id}","starred_url":"https://api.github.com/users/araitats/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/araitats/subscriptions","organizations_url":"https://api.github.com/users/araitats/orgs","repos_url":"https://api.github.com/users/araitats/repos","events_url":"https://api.github.com/users/araitats/events{/privacy}","received_events_url":"https://api.github.com/users/araitats/received_events","type":"User","site_admin":false},"labels":[{"id":890393501,"node_id":"MDU6TGFiZWw4OTAzOTM1MDE=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":{"login":"eric-haibin-lin","id":5545640,"node_id":"MDQ6VXNlcjU1NDU2NDA=","avatar_url":"https://avatars.githubusercontent.com/u/5545640?v=4","gravatar_id":"","url":"https://api.github.com/users/eric-haibin-lin","html_url":"https://github.com/eric-haibin-lin","followers_url":"https://api.github.com/users/eric-haibin-lin/followers","following_url":"https://api.github.com/users/eric-haibin-lin/following{/other_user}","gists_url":"https://api.github.com/users/eric-haibin-lin/gists{/gist_id}","starred_url":"https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eric-haibin-lin/subscriptions","organizations_url":"https://api.github.com/users/eric-haibin-lin/orgs","repos_url":"https://api.github.com/users/eric-haibin-lin/repos","events_url":"https://api.github.com/users/eric-haibin-lin/events{/privacy}","received_events_url":"https://api.github.com/users/eric-haibin-lin/received_events","type":"User","site_admin":false},"assignees":[{"login":"eric-haibin-lin","id":5545640,"node_id":"MDQ6VXNlcjU1NDU2NDA=","avatar_url":"https://avatars.githubusercontent.com/u/5545640?v=4","gravatar_id":"","url":"https://api.github.com/users/eric-haibin-lin","html_url":"https://github.com/eric-haibin-lin","followers_url":"https://api.github.com/users/eric-haibin-lin/followers","following_url":"https://api.github.com/users/eric-haibin-lin/following{/other_user}","gists_url":"https://api.github.com/users/eric-haibin-lin/gists{/gist_id}","starred_url":"https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eric-haibin-lin/subscriptions","organizations_url":"https://api.github.com/users/eric-haibin-lin/orgs","repos_url":"https://api.github.com/users/eric-haibin-lin/repos","events_url":"https://api.github.com/users/eric-haibin-lin/events{/privacy}","received_events_url":"https://api.github.com/users/eric-haibin-lin/received_events","type":"User","site_admin":false}],"milestone":null,"comments":9,"created_at":"2019-05-02T21:48:45Z","updated_at":"2019-05-11T07:36:14Z","closed_at":"2019-05-03T17:40:06Z","author_association":"NONE","active_lock_reason":null,"body":"There is a problem with a custom BERT model training with the later version of MXNet 1.5.0 (observed with cu90). \r\nmlm_loss stops around 7.2X and nsp_acc stopps around 54. \r\nThe last mxnet-cu90 version is still viable is 1.5.0b20190425. \r\n1.5.0b20190426 onward has this issue. Thus, you cannot train a custom BERT model with the latest version of MXNet now. \r\n\r\nI assume there was a change in optimization between April 25th and 26th. \r\n\r\nI used the latest version of gluonnlp for the following test. I think it is not the problem with gluonnlp (0.6.0). \r\n(i.e. pip install https://github.com/dmlc/gluon-nlp/tarball/master ) \r\n\r\nWith mxnet-cu90==1.5.0b20190425 (This is working) \r\n```bash\r\n(mxnet_p36_updated_4) sh-4.2$ python run_pretraining.py --gpus 0,1,2,3,4,5,6,7 --batch_size 8 --lr 1e-3 --data \"out_mcg_test-big/part-001.npz\"  @--warmup_ratio 0.01 --num_steps 1000000 --log_interval=250 --data_eval \"out_mcg_test-big/part-001.npz\" --batch_size_eval 8 --ckpt_dir ckpt --ckpt_interval 25000 --accumulate 4 --num_buckets 10 --dtype float16 \r\nINFO:root:Namespace(accumulate=4, batch_size=8, batch_size_eval=8, by_token=False, ckpt_dir='ckpt', ckpt_interval=25000, data='out_mcg_test-big/part-001.npz', data_eval='out_mcg_test-big/part-001.npz', dataset_name='book_corpus_wiki_en_uncased',dtype='float16', eval_only=False, gpus='0,1,2,3,4,5,6,7', kvstore='device', log_interval=250, lr=0.001, model='bert_12_768_12', num_buckets=10, num_steps=1000000, pretrained=False, profile=False, seed=0, start_step=0, verbose=False, warmup_ratio=0.01) \r\nINFO:root:Using training data at out_mcg_test-big/part-001.npz \r\n[20:42:24] src/kvstore/././comm_tree.h:356: only 32 out of 56 GPU pairs are enabled direct access. It may affect the performance. You can set MXNET_ENABLE_GPU_P2P=0 to turn it off \r\n[20:42:24] src/kvstore/././comm_tree.h:365: .vvvv... \r\n[20:42:24] src/kvstore/././comm_tree.h:365: v.vv.v.. \r\n[20:42:24] src/kvstore/././comm_tree.h:365: vv.v..v. \r\n[20:42:24] src/kvstore/././comm_tree.h:365: vvv....v \r\n... \r\n[20:42:24] src/kvstore/./././gpu_topology.h:216: cudaDeviceGetP2PAttribute incorrect. Falling back to cudaDeviceEnablePeerAccess for topology detection \r\n[20:42:24] src/kvstore/././comm_tree.h:380: Using Kernighan-Lin to generate trees \r\n[20:42:24] src/kvstore/././comm_tree.h:391: Using Tree \r\n[20:42:25] src/kvstore/././comm_tree.h:488: Size 2 occurs 1 times \r\n[20:42:25] src/kvstore/././comm_tree.h:488: Size 768 occurs 114 times \r\n[20:42:25] src/kvstore/././comm_tree.h:488: Size 1536 occurs 2 times \r\n[20:42:25] src/kvstore/././comm_tree.h:488: Size 3072 occurs 12 times \r\n[20:42:25] src/kvstore/././comm_tree.h:488: Size 30522 occurs 1 times \r\n[20:42:25] src/kvstore/././comm_tree.h:488: Size 393216 occurs 1 times \r\n[20:42:25] src/kvstore/././comm_tree.h:488: Size 589824 occurs 50 times \r\n[20:42:25] src/kvstore/././comm_tree.h:488: Size 2359296 occurs 24 times \r\n[20:42:25] src/kvstore/././comm_tree.h:488: Size 23440896 occurs 1 times \r\nINFO:root:[step 249] mlm_loss=8.02087 mlm_acc=6.88167 nsp_loss=0.69021 nsp_acc=53.343 throughput=24.2K tks/s lr=0.0000249 time=315.28 \r\nINFO:root:[step 499] mlm_loss=6.85134 mlm_acc=11.51758 nsp_loss=0.65648 nsp_acc=60.298 throughput=57.7K tks/s lr=0.0000499 time=133.49 \r\nINFO:root:[step 749] mlm_loss=6.60548 mlm_acc=13.98383 nsp_loss=0.58539 nsp_acc=67.169 throughput=57.7K tks/s lr=0.0000749 time=133.54 \r\n```\r\n\r\nWith mxnet-cu90==1.5.0b20190426 (This is not working) \r\n```bash\r\n#(Same)# \r\nINFO:root:[step 249]    mlm_loss=nan    mlm_acc=4.56305 nsp_loss=nan    nsp_acc=54.454  throughput=23.7K tks/s  lr=0.0000249 time=321.78\r\nINFO:root:[step 499]    mlm_loss=7.27492        mlm_acc=5.76089 nsp_loss=0.68847        nsp_acc=54.719  throughput=57.4K tks/s     lr=0.0000499 time=134.22\r\nINFO:root:[step 749]    mlm_loss=7.26470        mlm_acc=5.82224 nsp_loss=0.68894        nsp_acc=54.428  throughput=57.3K tks/s     lr=0.0000749 time=134.40\r\n```","closed_by":{"login":"szha","id":2626883,"node_id":"MDQ6VXNlcjI2MjY4ODM=","avatar_url":"https://avatars.githubusercontent.com/u/2626883?v=4","gravatar_id":"","url":"https://api.github.com/users/szha","html_url":"https://github.com/szha","followers_url":"https://api.github.com/users/szha/followers","following_url":"https://api.github.com/users/szha/following{/other_user}","gists_url":"https://api.github.com/users/szha/gists{/gist_id}","starred_url":"https://api.github.com/users/szha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/szha/subscriptions","organizations_url":"https://api.github.com/users/szha/orgs","repos_url":"https://api.github.com/users/szha/repos","events_url":"https://api.github.com/users/szha/events{/privacy}","received_events_url":"https://api.github.com/users/szha/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/690/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":1},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/690/timeline","performed_via_github_app":null,"state_reason":"completed"}