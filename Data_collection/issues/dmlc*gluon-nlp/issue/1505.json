{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1505","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1505/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1505/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1505/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/1505","id":794397729,"node_id":"MDU6SXNzdWU3OTQzOTc3Mjk=","number":1505,"title":"Issues in ELECTRA-base pre-training and fine-tuning","user":{"login":"szha","id":2626883,"node_id":"MDQ6VXNlcjI2MjY4ODM=","avatar_url":"https://avatars.githubusercontent.com/u/2626883?v=4","gravatar_id":"","url":"https://api.github.com/users/szha","html_url":"https://github.com/szha","followers_url":"https://api.github.com/users/szha/followers","following_url":"https://api.github.com/users/szha/following{/other_user}","gists_url":"https://api.github.com/users/szha/gists{/gist_id}","starred_url":"https://api.github.com/users/szha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/szha/subscriptions","organizations_url":"https://api.github.com/users/szha/orgs","repos_url":"https://api.github.com/users/szha/repos","events_url":"https://api.github.com/users/szha/events{/privacy}","received_events_url":"https://api.github.com/users/szha/received_events","type":"User","site_admin":false},"labels":[{"id":890393501,"node_id":"MDU6TGFiZWw4OTAzOTM1MDE=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":890393503,"node_id":"MDU6TGFiZWw4OTAzOTM1MDM=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement","name":"enhancement","color":"135caf","default":true,"description":"New feature or request"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-01-26T16:57:17Z","updated_at":"2021-02-21T20:12:11Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"## Description\r\nAs part of #1413 I was running the ELECTRA-base model and found several issues along the way.\r\n\r\n- [x] dataloader KeyError and crash in pre-training #1525 \r\n<details><summary>dataloader KeyError error message</summary>\r\n\r\n``` \r\n[2]<stderr>:multiprocessing.pool.RemoteTraceback:\r\n[2]<stderr>:\"\"\"\r\n[2]<stderr>:Traceback (most recent call last):\r\n[2]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\r\n[2]<stderr>:    result = (True, func(*args, **kwds))\r\n[2]<stderr>:  File \"/home/ubuntu/gluon-nlp/src/gluonnlp/data/loading.py\", line 147, in _batch_worker_fn\r\n[2]<stderr>:    if len(dataset[0]) > 1:\r\n[2]<stderr>:  File \"<string>\", line 2, in __getitem__\r\n[2]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 772, in _callmethod\r\n[2]<stderr>:    raise convert_to_error(kind, result)\r\n[2]<stderr>:multiprocessing.managers.RemoteError:\r\n[2]<stderr>:---------------------------------------------------------------------------\r\n[2]<stderr>:Traceback (most recent call last):\r\n[2]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 235, in serve_client\r\n[2]<stderr>:    self.id_to_local_proxy_obj[ident]\r\n[2]<stderr>:KeyError: '7f9f048a0608'\r\n[2]<stderr>:\r\n[2]<stderr>:During handling of the above exception, another exception occurred:\r\n[2]<stderr>:\r\n[2]<stderr>:Traceback (most recent call last):\r\n[2]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 237, in serve_client\r\n[2]<stderr>:    raise ke\r\n[2]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 231, in serve_client\r\n[2]<stderr>:    obj, exposed, gettypeid = id_to_obj[ident]\r\n[2]<stderr>:KeyError: '7f9f048a0608'\r\n[2]<stderr>:---------------------------------------------------------------------------\r\n[2]<stderr>:\"\"\"\r\n[2]<stderr>:\r\n[2]<stderr>:The above exception was the direct cause of the following exception:\r\n[2]<stderr>:\r\n[2]<stderr>:Traceback (most recent call last):\r\n[2]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n[2]<stderr>:    \"__main__\", mod_spec)\r\n[2]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n[2]<stderr>:    exec(code, run_globals)\r\n[2]<stderr>:  File \"/home/ubuntu/gluon-nlp/scripts/pretraining/run_electra.py\", line 557, in <module>\r\n[2]<stderr>:    train(args)\r\n[2]<stderr>:  File \"/home/ubuntu/gluon-nlp/scripts/pretraining/run_electra.py\", line 362, in train\r\n[2]<stderr>:    sample_l = next(train_loop_dataloader)\r\n[2]<stderr>:  File \"/home/ubuntu/gluon-nlp/src/gluonnlp/utils/misc.py\", line 226, in repeat\r\n[2]<stderr>:    for sample in iterable:\r\n[2]<stderr>:  File \"/home/ubuntu/gluon-nlp/src/gluonnlp/data/loading.py\", line 252, in __next__\r\n[2]<stderr>:    batch, counter = ret.get()\r\n[2]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 644, in get\r\n[2]<stderr>:    raise self._value\r\n[2]<stderr>:multiprocessing.managers.RemoteError:\r\n[2]<stderr>:---------------------------------------------------------------------------\r\n[2]<stderr>:Traceback (most recent call last):\r\n[2]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 235, in serve_client\r\n[2]<stderr>:    self.id_to_local_proxy_obj[ident]\r\n[2]<stderr>:KeyError: '7f9f048a0608'\r\n[2]<stderr>:\r\n[2]<stderr>:During handling of the above exception, another exception occurred:\r\n[2]<stderr>:\r\n[2]<stderr>:Traceback (most recent call last):\r\n[2]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 237, in serve_client\r\n[2]<stderr>:    raise ke\r\n[2]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 231, in serve_client\r\n[2]<stderr>:    obj, exposed, gettypeid = id_to_obj[ident]\r\n[2]<stderr>:KeyError: '7f9f048a0608'\r\n[2]<stderr>:---------------------------------------------------------------------------\r\n[7]<stderr>:munmap_chunk(): invalid pointer\r\n[7]<stderr>:malloc_consolidate(): invalid chunk size\r\n[0]<stdout>:\r\n[0]<stdout>:Fatal Error: Segmentation fault\r\n[0]<stderr>:Stack trace:\r\n[0]<stdout>:\r\n[0]<stderr>:Stack trace:\r\n[0]<stdout>:Fatal Error: Segmentation fault\r\n[0]<stderr>:Stack trace:\r\n[0]<stdout>:\r\n[0]<stdout>:Fatal Error: Segmentation fault\r\n[0]<stderr>:  /usr/lib/x86_64-linux-gnu/libstdc++.so.6 ( operator new(unsigned long)               + 0x18  )  [0x7f68d1a42298]\r\n[0]<stderr>:  /home/ubuntu/.local/lib/python3.6/site-packages/horovod/mxnet/mpi_lib.cpython-36m-x86_64-linux-gnu.so ( std::vector<std::shared_ptr<horovod::common::Tensor>, std::allocator<std::shared_ptr<horovod::common::Tensor> > >::reserve(unsigned long)  + 0x78  )  [0x7f630422daa8]\r\n[0]<stderr>:  /home/ubuntu/.local/lib/python3.6/site-packages/horovod/mxnet/mpi_lib.cpython-36m-x86_64-linux-gnu.so ( horovod::mxnet::DoHorovodOperation(void*, void*, void*)  + 0x8c3 )  [0x7f63042273d3]\r\n[0]<stderr>:  /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so (                                           + 0x1f67619)  [0x7f6686402619]\r\n[0]<stderr>:  /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so ( mxnet::engine::ThreadedEngine::ExecuteOprBlock(mxnet::RunContext, mxnet::engine::OprBlock*)  + 0x10c )  [0x7f6686523dbc]\r\n[0]<stderr>:  /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so ( std::_Function_handler<void (std::shared_ptr<dmlc::ManualEvent>), mxnet::engine::ThreadedEnginePerDevice::Start()::{lambda(std::shared_ptr<dmlc::ManualEvent>)#1}>::_M_invoke(std::_Any_data const&, std::shared_ptr<dmlc::ManualEvent>&&)  + 0xd0  )  [0x7f6686526310]\r\n[0]<stderr>:  /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so ( std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::function<void (std::shared_ptr<dmlc::ManualEvent>)>, std::shared_ptr<dmlc::ManualEvent> > > >::_M_run()  + 0x32  )  [0x7f6686522fa2]\r\n[0]<stderr>:  /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so (                                           + 0x1226877f)  [0x7f669670377f]\r\n[0]<stderr>:  /lib/x86_64-linux-gnu/libpthread.so.0 (                                           + 0x76db)  [0x7f68d85a76db]\r\n[0]<stderr>:  /lib/x86_64-linux-gnu/libc.so.6 ( clone                                     + 0x3f  )  [0x7f68d88e071f]\r\n[5]<stderr>:double free or corruption (out)\r\n[6]<stderr>:double free or corruption (out)\r\n[4]<stderr>:double free or corruption (out)\r\n[3]<stderr>:Traceback (most recent call last):\r\n[3]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n[3]<stderr>:    \"__main__\", mod_spec)\r\n[3]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n[3]<stderr>:    exec(code, run_globals)\r\n[3]<stderr>:  File \"/home/ubuntu/gluon-nlp/scripts/pretraining/run_electra.py\", line 557, in <module>\r\n[3]<stderr>:    train(args)\r\n[3]<stderr>:  File \"/home/ubuntu/gluon-nlp/scripts/pretraining/run_electra.py\", line 418, in train\r\n[3]<stderr>:    params, args.max_grad_norm * num_workers)\r\n[3]<stderr>:  File \"/home/ubuntu/gluon-nlp/src/gluonnlp/utils/parameter.py\", line 237, in clip_grad_global_norm\r\n[3]<stderr>:    total_norm = grad_global_norm(parameters)\r\n[3]<stderr>:  File \"/home/ubuntu/gluon-nlp/src/gluonnlp/utils/parameter.py\", line 187, in grad_global_norm\r\n[3]<stderr>:    total_norm = float(total_norm)\r\n[3]<stderr>:  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/numpy/multiarray.py\", line 1225, in __float__\r\n[3]<stderr>:    return float(self.item())\r\n[3]<stderr>:  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/numpy/multiarray.py\", line 1264, in item\r\n[3]<stderr>:    return self.asnumpy().item(*args)\r\n[3]<stderr>:  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\", line 2610, in asnumpy\r\n[3]<stderr>:    ctypes.c_size_t(data.size)))\r\n[3]<stderr>:  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/base.py\", line 246, in check_call\r\n[3]<stderr>:    raise get_last_ffi_error()\r\n[3]<stderr>:mxnet.base.MXNetError: MXNetError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\n[1]<stderr>:Traceback (most recent call last):\r\n[1]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n[1]<stderr>:    \"__main__\", mod_spec)\r\n[1]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n[1]<stderr>:    exec(code, run_globals)\r\n[1]<stderr>:  File \"/home/ubuntu/gluon-nlp/scripts/pretraining/run_electra.py\", line 557, in <module>\r\n[1]<stderr>:    train(args)\r\n[1]<stderr>:  File \"/home/ubuntu/gluon-nlp/scripts/pretraining/run_electra.py\", line 418, in train\r\n[1]<stderr>:    params, args.max_grad_norm * num_workers)\r\n[1]<stderr>:  File \"/home/ubuntu/gluon-nlp/src/gluonnlp/utils/parameter.py\", line 237, in clip_grad_global_norm\r\n[1]<stderr>:    total_norm = grad_global_norm(parameters)\r\n[1]<stderr>:  File \"/home/ubuntu/gluon-nlp/src/gluonnlp/utils/parameter.py\", line 187, in grad_global_norm\r\n[1]<stderr>:    total_norm = float(total_norm)\r\n[1]<stderr>:  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/numpy/multiarray.py\", line 1225, in __float__\r\n[1]<stderr>:    return float(self.item())\r\n[1]<stderr>:  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/numpy/multiarray.py\", line 1264, in item\r\n[1]<stderr>:    return self.asnumpy().item(*args)\r\n[1]<stderr>:  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\", line 2610, in asnumpy\r\n[1]<stderr>:    ctypes.c_size_t(data.size)))\r\n[1]<stderr>:  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/base.py\", line 246, in check_call\r\n[1]<stderr>:    raise get_last_ffi_error()\r\n[1]<stderr>:mxnet.base.MXNetError: MXNetError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\n[3]<stdout>:\r\n[3]<stderr>:Stack trace:\r\n[3]<stdout>:Fatal Error: Segmentation fault\r\n[3]<stderr>:  /usr/lib/x86_64-linux-gnu/libstdc++.so.6 ( std::__exception_ptr::operator!=(std::__exception_ptr::exception_ptr const&, std::__exception_ptr::exception_ptr const&)  + 0x9   )  [0x7f322a46c9f9]\r\n[3]<stderr>:  /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so ( mxnet::engine::ThreadedEngine::WaitForAll()  + 0x111 )  [0x7f2fea318881]\r\n[3]<stderr>:  /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so ( MXNotifyShutdown                          + 0x40  )  [0x7f2fea202a60]\r\n[3]<stderr>:  /usr/lib/x86_64-linux-gnu/libffi.so.6 ( ffi_call_unix64                           + 0x4c  )  [0x7f323a399dae]\r\n[3]<stderr>:  /usr/lib/x86_64-linux-gnu/libffi.so.6 ( ffi_call                                  + 0x22f )  [0x7f323a39971f]\r\n[3]<stderr>:  /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so ( _ctypes_callproc                          + 0x4d3 )  [0x7f323a5ad7e3]\r\n[3]<stderr>:  /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so (                                           + 0x11c33)  [0x7f323a5adc33]\r\n[3]<stderr>:  python3                        ( _PyObject_FastCallKeywords                + 0x19c )  [0x5a9dac]\r\n[3]<stderr>:  python3                        (                                                   )  [0x50a433]\r\n[3]<stderr>:  python3                        ( _PyEval_EvalFrameDefault                  + 0x444 )  [0x50beb4]\r\n[3]<stderr>:  python3                        (                                                   )  [0x507be4]\r\n[3]<stderr>:  python3                        (                                                   )  [0x588c8b]\r\n[3]<stderr>:  python3                        ( PyObject_Call                             + 0x3e  )  [0x59fd0e]\r\n[3]<stderr>:  python3                        (                                                   )  [0x5de69d]\r\n[3]<stderr>:  python3                        ( Py_FinalizeEx                             + 0x24  )  [0x637fe4]\r\n[3]<stderr>:  python3                        ( Py_Main                                   + 0x395 )  [0x639085]\r\n[3]<stderr>:  python3                        ( main                                      + 0xe0  )  [0x4b0dc0]\r\n[3]<stderr>:  /lib/x86_64-linux-gnu/libc.so.6 ( __libc_start_main                         + 0xe7  )  [0x7f323c5ddbf7]\r\n[3]<stderr>:  python3                        ( _start                                    + 0x2a  )  [0x5b259a]\r\n[1]<stderr>:Stack trace:\r\n[1]<stdout>:\r\n[1]<stdout>:Fatal Error: Segmentation fault\r\n[1]<stderr>:  /usr/lib/x86_64-linux-gnu/libstdc++.so.6 ( std::__exception_ptr::operator!=(std::__exception_ptr::exception_ptr const&, std::__exception_ptr::exception_ptr const&)  + 0x9   )  [0x7f230268a9f9]\r\n[1]<stderr>:  /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so ( mxnet::engine::ThreadedEngine::WaitForAll()  + 0x111 )  [0x7f232a7c4881]\r\n[1]<stderr>:  /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so ( MXNotifyShutdown                          + 0x40  )  [0x7f232a6aea60]\r\n[1]<stderr>:  /usr/lib/x86_64-linux-gnu/libffi.so.6 ( ffi_call_unix64                           + 0x4c  )  [0x7f257a845dae]\r\n[1]<stderr>:  /usr/lib/x86_64-linux-gnu/libffi.so.6 ( ffi_call                                  + 0x22f )  [0x7f257a84571f]\r\n[1]<stderr>:  /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so ( _ctypes_callproc                          + 0x4d3 )  [0x7f257aa597e3]\r\n[1]<stderr>:  /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so (                                           + 0x11c33)  [0x7f257aa59c33]\r\n[1]<stderr>:  python3                        ( _PyObject_FastCallKeywords                + 0x19c )  [0x5a9dac]\r\n[1]<stderr>:  python3                        (                                                   )  [0x50a433]\r\n[1]<stderr>:  python3                        ( _PyEval_EvalFrameDefault                  + 0x444 )  [0x50beb4]\r\n[1]<stderr>:  python3                        (                                                   )  [0x507be4]\r\n[1]<stderr>:  python3                        (                                                   )  [0x588c8b]\r\n[1]<stderr>:  python3                        ( PyObject_Call                             + 0x3e  )  [0x59fd0e]\r\n[1]<stderr>:  python3                        (                                                   )  [0x5de69d]\r\n[1]<stderr>:  python3                        ( Py_FinalizeEx                             + 0x24  )  [0x637fe4]\r\n[1]<stderr>:  python3                        ( Py_Main                                   + 0x395 )  [0x639085]\r\n[1]<stderr>:  python3                        ( main                                      + 0xe0  )  [0x4b0dc0]\r\n[1]<stderr>:  /lib/x86_64-linux-gnu/libc.so.6 ( __libc_start_main                         + 0xe7  )  [0x7f257ca89bf7]\r\n[1]<stderr>:  python3                        ( _start                                    + 0x2a  )  [0x5b259a]\r\nProcess 2 exit with status code 1.\r\n[0]<stderr>:Segmentation fault (core dumped)\r\n[5]<stderr>:Aborted (core dumped)\r\n[6]<stderr>:Aborted (core dumped)\r\n[4]<stderr>:Aborted (core dumped)\r\n[1]<stderr>:Segmentation fault (core dumped)\r\nProcess 1 exit with status code 139.\r\n[3]<stderr>:Segmentation fault (core dumped)\r\nProcess 3 exit with status code 139.\r\n[7]<stderr>:Aborted (core dumped)\r\n```\r\n\r\n</details>\r\n\r\n- [ ] training hangs\r\n- [ ] ~The pre-training script can't resume from last checkpoint.~ #1526\r\n- [ ] SQuAD fine-tuning script can't load pre-trained model\r\n\r\n<details><summary>SQuAD parameter loading error message</summary>\r\n\r\n```\r\n% python3 scripts/question_answering/run_squad.py \\\r\n    --model_name google_electra_base \\\r\n    --data_dir squad \\\r\n    --backbone_path output/0300000.params \\\r\n    --output_dir output_finetune \\\r\n    --version 1.1 \\\r\n    --do_eval \\\r\n    --do_train \\\r\n    --batch_size 32 \\\r\n    --num_accumulated 1 \\\r\n    --gpus 0 \\\r\n    --epochs 2 \\\r\n    --lr 3e-4 \\\r\n    --layerwise_decay 0.8 \\\r\n    --warmup_ratio 0.1 \\\r\n    --max_saved_ckpt 6 \\\r\n    --all_evaluate \\\r\n    --wd 0 \\\r\n    --max_seq_length 128 \\\r\n    --max_grad_norm 0.1 \\\r\n\r\nAll Logs will be saved to output_finetune/finetune_squad1.1.log\r\n2021-01-26 16:14:25,942 - root - INFO - Namespace(adam_betas='(0.9, 0.999)', adam_epsilon=1e-06, all_evaluate=True, backbone_path='output/0300000.params', batch_size=32, classifier_dropout=0.1, comm_backend='device', data_dir='squad', do_eval=True, do_train=True, doc_stride=128, dtype='float32', end_top_n=5, epochs=2.0, eval_batch_size=16, eval_log_interval=10, gpus='0', layerwise_decay=0.8, log_interval=50, lr=0.0003, max_answer_length=30, max_grad_norm=0.1, max_query_length=64, max_saved_ckpt=6, max_seq_length=128, model_name='google_electra_base', n_best_size=20, num_accumulated=1, num_train_steps=None, optimizer='adamw', output_dir='output_finetune', overwrite_cache=False, param_checkpoint=None, pre_shuffle_seed=100, round_to=None, save_interval=None, seed=100, start_top_n=5, untunable_depth=-1, version='1.1', warmup_ratio=0.1, warmup_steps=None, wd=0.0)\r\n[16:14:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU\r\nTraceback (most recent call last):\r\n  File \"../question_answering/run_squad.py\", line 1007, in <module>\r\n    train(args)\r\n  File \"../question_answering/run_squad.py\", line 449, in train\r\n    args.backbone_path)\r\n  File \"../question_answering/run_squad.py\", line 407, in get_network\r\n    ctx=ctx_l, cast_dtype=True)\r\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/util.py\", line 299, in _with_np_shape\r\n    return func(*args, **kwargs)\r\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/util.py\", line 480, in _with_np_array\r\n    return func(*args, **kwargs)\r\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/gluon/block.py\", line 432, in load_parameters\r\n    self.load_dict(full_dict, ctx, allow_missing, ignore_extra, cast_dtype, dtype_source)\r\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/util.py\", line 299, in _with_np_shape\r\n    return func(*args, **kwargs)\r\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/util.py\", line 480, in _with_np_array\r\n    return func(*args, **kwargs)\r\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/gluon/block.py\", line 477, in load_dict\r\n    name, error_str, _brief_print_list(loaded.keys()))\r\nAssertionError: Parameter 'encoder.all_encoder_layers.0.attn_qkv.weight' is missing in 'file: output/0300000.params', which contains parameters: 'disc_backbone.embed_layer_norm.beta', 'disc_backbone.embed_layer_norm.gamma', 'disc_backbone.encoder.all_encoder_layers.0.attention_proj.bias', ..., 'generator.mlm_decoder.2.beta', 'generator.mlm_decoder.2.gamma', 'generator.mlm_decoder.3.bias', 'generator.mlm_decoder.3.weight'. Set allow_missing=True to ignore missing parameters.\r\n```\r\n\r\n</details>\r\n\r\n## To Reproduce\r\nFollow the steps in https://github.com/dmlc/gluon-nlp/blob/09f343564e4f735df52e212df87ca073a824e829/scripts/pretraining/README.md. See below for the exact commands I used.\r\n\r\n### Steps to reproduce\r\n\r\n1. Run ELECTRA-base pre-training\r\n```\r\nhorovodrun --verbose -np 8 -H localhost:8 python3 -m run_electra \\\r\n    --model_name google_electra_base \\\r\n    --data 'preprocessed_owt/*.npz' \\\r\n    --generator_units_scale 0.25 \\\r\n    --gpus 0,1,2,3,4,5,6,7 \\\r\n    --do_train \\\r\n    --do_eval \\\r\n    --output_dir output \\\r\n    --num_accumulated 1 \\\r\n    --batch_size 128 \\\r\n    --lr 5e-4 \\\r\n    --wd 0.01 \\\r\n    --max_seq_len 128 \\\r\n    --max_grad_norm 1 \\\r\n    --warmup_steps 10000 \\\r\n    --num_train_steps 1000000 \\\r\n    --log_interval 200 \\\r\n    --save_interval 50000 \\\r\n    --mask_prob 0.15 \\\r\n    --comm_backend horovod \\\r\n```\r\n2. Use ELECTRA-base pre-trained weights for SQuAD fine-tuning\r\n```\r\npython3 scripts/question_answering/run_squad.py \\\r\n    --model_name google_electra_base \\\r\n    --data_dir squad \\\r\n    --backbone_path output/0300000.params \\  # update parameter file name here\r\n    --output_dir output_finetune \\\r\n    --version 1.1 \\\r\n    --do_eval \\\r\n    --do_train \\\r\n    --batch_size 32 \\\r\n    --num_accumulated 1 \\\r\n    --gpus 0 \\\r\n    --epochs 2 \\\r\n    --lr 3e-4 \\\r\n    --layerwise_decay 0.8 \\\r\n    --warmup_ratio 0.1 \\\r\n    --max_saved_ckpt 6 \\\r\n    --all_evaluate \\\r\n    --wd 0 \\\r\n    --max_seq_length 128 \\\r\n    --max_grad_norm 0.1\r\n```\r\n\r\n## Environment\r\n\r\nI ran both scripts on p4dn.24xlarge with an environment bootstrapped by this [cloudformation template](https://s3.amazonaws.com/lausen-data/cf_template_p4d.yaml). Details on some important dependencies:\r\n- MXNet: I used https://repo.mxnet.io/dist/python/cu110/mxnet_cu110-2.0.0b20210117-py3-none-manylinux2014_x86_64.whl\r\n- Horovod: I used `HOROVOD_WITH_MXNET=1 HOROVOD_GPU_OPERATIONS=NCCL HOROVOD_WITH_GLOO=1 python3 -m pip install --no-cache-dir horovod` for Horovod 0.21.1.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1505/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/1505/timeline","performed_via_github_app":null,"state_reason":null}