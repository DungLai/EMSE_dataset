{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/982","repository_url":"https://api.github.com/repos/dmlc/gluon-nlp","labels_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/982/labels{/name}","comments_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/982/comments","events_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/982/events","html_url":"https://github.com/dmlc/gluon-nlp/issues/982","id":510382862,"node_id":"MDU6SXNzdWU1MTAzODI4NjI=","number":982,"title":"Multi GPU context not updated","user":{"login":"kristjanArumae","id":3398459,"node_id":"MDQ6VXNlcjMzOTg0NTk=","avatar_url":"https://avatars.githubusercontent.com/u/3398459?v=4","gravatar_id":"","url":"https://api.github.com/users/kristjanArumae","html_url":"https://github.com/kristjanArumae","followers_url":"https://api.github.com/users/kristjanArumae/followers","following_url":"https://api.github.com/users/kristjanArumae/following{/other_user}","gists_url":"https://api.github.com/users/kristjanArumae/gists{/gist_id}","starred_url":"https://api.github.com/users/kristjanArumae/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kristjanArumae/subscriptions","organizations_url":"https://api.github.com/users/kristjanArumae/orgs","repos_url":"https://api.github.com/users/kristjanArumae/repos","events_url":"https://api.github.com/users/kristjanArumae/events{/privacy}","received_events_url":"https://api.github.com/users/kristjanArumae/received_events","type":"User","site_admin":false},"labels":[{"id":890393501,"node_id":"MDU6TGFiZWw4OTAzOTM1MDE=","url":"https://api.github.com/repos/dmlc/gluon-nlp/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"open","locked":false,"assignee":{"login":"eric-haibin-lin","id":5545640,"node_id":"MDQ6VXNlcjU1NDU2NDA=","avatar_url":"https://avatars.githubusercontent.com/u/5545640?v=4","gravatar_id":"","url":"https://api.github.com/users/eric-haibin-lin","html_url":"https://github.com/eric-haibin-lin","followers_url":"https://api.github.com/users/eric-haibin-lin/followers","following_url":"https://api.github.com/users/eric-haibin-lin/following{/other_user}","gists_url":"https://api.github.com/users/eric-haibin-lin/gists{/gist_id}","starred_url":"https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eric-haibin-lin/subscriptions","organizations_url":"https://api.github.com/users/eric-haibin-lin/orgs","repos_url":"https://api.github.com/users/eric-haibin-lin/repos","events_url":"https://api.github.com/users/eric-haibin-lin/events{/privacy}","received_events_url":"https://api.github.com/users/eric-haibin-lin/received_events","type":"User","site_admin":false},"assignees":[{"login":"eric-haibin-lin","id":5545640,"node_id":"MDQ6VXNlcjU1NDU2NDA=","avatar_url":"https://avatars.githubusercontent.com/u/5545640?v=4","gravatar_id":"","url":"https://api.github.com/users/eric-haibin-lin","html_url":"https://github.com/eric-haibin-lin","followers_url":"https://api.github.com/users/eric-haibin-lin/followers","following_url":"https://api.github.com/users/eric-haibin-lin/following{/other_user}","gists_url":"https://api.github.com/users/eric-haibin-lin/gists{/gist_id}","starred_url":"https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eric-haibin-lin/subscriptions","organizations_url":"https://api.github.com/users/eric-haibin-lin/orgs","repos_url":"https://api.github.com/users/eric-haibin-lin/repos","events_url":"https://api.github.com/users/eric-haibin-lin/events{/privacy}","received_events_url":"https://api.github.com/users/eric-haibin-lin/received_events","type":"User","site_admin":false}],"milestone":null,"comments":6,"created_at":"2019-10-22T01:36:03Z","updated_at":"2020-06-11T06:29:26Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"## Description\r\nI've implemented multi-GPU support (which works fine).  But when I add the following:\r\n```\r\ntrainer.allreduce_grads()\r\nnlp.utils.clip_grad_global_norm(params, 1)\r\ntrainer.update(args.accumulate if args.accumulate else 1)\r\n```\r\n\r\nI get a warning which terminates the program.\r\n\r\nThe BERT specific training loop code I added is largely taken from here:\r\nhttps://github.com/dmlc/gluon-nlp/blob/master/scripts/bert/finetune_classifier.py\r\n\r\nI am not excluding any params from training, and when I switch back to single GPU this problem goes away.\r\n\r\n### Error Message\r\n```\r\nFile \"/home/code/src/train/train.py\", line 266, in <module>\r\n    train_model(args)\r\n  File \"/home/code/src/train/train.py\", line 194, in train_model\r\n    trainer.update(args.accumulate if args.accumulate else 1)\r\n  File \"/home/anaconda3/lib/python3.7/site-packages/mxnet/gluon/trainer.py\", line 397, in update\r\n    self._update(ignore_stale_grad)\r\n  File \"/home/anaconda3/lib/python3.7/site-packages/mxnet/gluon/trainer.py\", line 416, in _update\r\n    %(param.name, str(data.context)))\r\nUserWarning: Gradient of Parameter `bertencoder0_position_weight` on context gpu(5) has not been updated by backward since last `step`. This could mean a bug in your model that made it only use a subset of the Parameters (Blocks) for this iteration. If you are intentionally only using a subset, call step with ignore_stale_grad=True to suppress this warning and skip updating of Parameters with stale gradient\r\n```\r\n## What have you tried to solve it?\r\n\r\n1. Looked for the warning elsewhere found threads which did not solve the issue such as this one:\r\nhttps://github.com/zackchase/mxnet-the-straight-dope/issues/348\r\n\r\n## Environment\r\n\r\n----------Python Info----------\r\nVersion      : 3.7.3\r\nCompiler     : GCC 7.3.0\r\nBuild        : ('default', 'Mar 27 2019 22:11:17')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 19.1.1\r\nDirectory    : /home/anaconda3/lib/python3.7/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.5.1\r\nDirectory    : /home/anaconda3/lib/python3.7/site-packages/mxnet\r\nNum GPUs     : 8\r\nCommit Hash   : c9818480680f84daa6e281a974ab263691302ba8\r\n----------System Info----------\r\nPlatform     : Linux-4.4.0-1092-aws-x86_64-with-debian-stretch-sid\r\nsystem       : Linux\r\nnode         : ip-172-31-30-6\r\nrelease      : 4.4.0-1092-aws\r\nversion      : #103-Ubuntu SMP Tue Aug 27 10:21:48 UTC 2019\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                64\r\nOn-line CPU(s) list:   0-63\r\nThread(s) per core:    2\r\nCore(s) per socket:    16\r\nSocket(s):             2\r\nNUMA node(s):          2\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\nStepping:              1\r\nCPU MHz:               2699.984\r\nCPU max MHz:           3000.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              4600.07\r\nHypervisor vendor:     Xen\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              46080K\r\nNUMA node0 CPU(s):     0-15,32-47\r\nNUMA node1 CPU(s):     16-31,48-63\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq monitor est ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt ida\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/982/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dmlc/gluon-nlp/issues/982/timeline","performed_via_github_app":null,"state_reason":null}