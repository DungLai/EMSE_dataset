{"url":"https://api.github.com/repos/allenai/scispacy/issues/370","repository_url":"https://api.github.com/repos/allenai/scispacy","labels_url":"https://api.github.com/repos/allenai/scispacy/issues/370/labels{/name}","comments_url":"https://api.github.com/repos/allenai/scispacy/issues/370/comments","events_url":"https://api.github.com/repos/allenai/scispacy/issues/370/events","html_url":"https://github.com/allenai/scispacy/issues/370","id":927806027,"node_id":"MDU6SXNzdWU5Mjc4MDYwMjc=","number":370,"title":"Keep downloading files related to UMLS from amazon website everytime while entity linking","user":{"login":"yihahn","id":19813586,"node_id":"MDQ6VXNlcjE5ODEzNTg2","avatar_url":"https://avatars.githubusercontent.com/u/19813586?v=4","gravatar_id":"","url":"https://api.github.com/users/yihahn","html_url":"https://github.com/yihahn","followers_url":"https://api.github.com/users/yihahn/followers","following_url":"https://api.github.com/users/yihahn/following{/other_user}","gists_url":"https://api.github.com/users/yihahn/gists{/gist_id}","starred_url":"https://api.github.com/users/yihahn/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yihahn/subscriptions","organizations_url":"https://api.github.com/users/yihahn/orgs","repos_url":"https://api.github.com/users/yihahn/repos","events_url":"https://api.github.com/users/yihahn/events{/privacy}","received_events_url":"https://api.github.com/users/yihahn/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-06-23T02:51:19Z","updated_at":"2021-07-07T22:43:40Z","closed_at":"2021-07-07T22:43:39Z","author_association":"NONE","active_lock_reason":null,"body":"Hi, I tried to extract entities related to those in UMLS from the EHR data, and I used the Scispacy with en_ner_bc5cdr_md database. Although I ran the chunks of EHR data using by below function. It can iterate the 10-12 loop and then stopped by the below error : \r\n\r\n=========================================================================================\r\n```python\r\ngaierror                                  Traceback (most recent call last)\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/urllib3/connection.py in _new_conn(self)\r\n    169             conn = connection.create_connection(\r\n--> 170                 (self._dns_host, self.port), self.timeout, **extra_kw\r\n    171             )\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/urllib3/util/connection.py in create_connection(address, timeout, source_address, socket_options)\r\n     72 \r\n---> 73     for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\r\n     74         af, socktype, proto, canonname, sa = res\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/socket.py in getaddrinfo(host, port, family, type, proto, flags)\r\n    744     addrlist = []\r\n--> 745     for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\r\n    746         af, socktype, proto, canonname, sa = res\r\n\r\ngaierror: [Errno -2] Name or service not known\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nNewConnectionError                        Traceback (most recent call last)\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/urllib3/connectionpool.py in urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\r\n    705                 headers=headers,\r\n--> 706                 chunked=chunked,\r\n    707             )\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/urllib3/connectionpool.py in _make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)\r\n    381         try:\r\n--> 382             self._validate_conn(conn)\r\n    383         except (SocketTimeout, BaseSSLError) as e:\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/urllib3/connectionpool.py in _validate_conn(self, conn)\r\n   1009         if not getattr(conn, \"sock\", None):  # AppEngine might not have  `.sock`\r\n-> 1010             conn.connect()\r\n   1011 \r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/urllib3/connection.py in connect(self)\r\n    352         # Add certificate verification\r\n--> 353         conn = self._new_conn()\r\n    354         hostname = self.host\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/urllib3/connection.py in _new_conn(self)\r\n    181             raise NewConnectionError(\r\n--> 182                 self, \"Failed to establish a new connection: %s\" % e\r\n    183             )\r\n\r\nNewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7fbb483d36a0>: Failed to establish a new connection: [Errno -2] Name or service not known\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nMaxRetryError                             Traceback (most recent call last)\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/requests/adapters.py in send(self, request, stream, timeout, verify, cert, proxies)\r\n    448                     retries=self.max_retries,\r\n--> 449                     timeout=timeout\r\n    450                 )\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/urllib3/connectionpool.py in urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\r\n    755             retries = retries.increment(\r\n--> 756                 method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\r\n    757             )\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/urllib3/util/retry.py in increment(self, method, url, response, error, _pool, _stacktrace)\r\n    573         if new_retry.is_exhausted():\r\n--> 574             raise MaxRetryError(_pool, url, error or ResponseError(cause))\r\n    575 \r\n\r\nMaxRetryError: HTTPSConnectionPool(host='s3-us-west-2.amazonaws.com', port=443): Max retries exceeded with url: /ai2-s2-scispacy/data/umls_semantic_type_tree.tsv (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fbb483d36a0>: Failed to establish a new connection: [Errno -2] Name or service not known',))\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nConnectionError                           Traceback (most recent call last)\r\n<ipython-input-15-230f620b9f72> in <module>\r\n      4             df_ner_processed = extract_entity(arg_list[i])\r\n      5         else :\r\n----> 6             tmp = extract_entity(arg_list[i])\r\n      7             df_ner_processed = pd.concat([df_ner_processed, tmp], ignore_index=True)\r\n      8         arg_list_done.append(arg_list[i])\r\n\r\n<ipython-input-4-ba3e01ebd0e6> in extract_entity(patient_line_dates_map, out_folder, out_prefix)\r\n      9     #nlp.add_pipe(linker)\r\n     10     #os.environ[\"SCISPACY_CACHE\"]=\"/home/hahnyi/.scispacy\"\r\n---> 11     nlp.add_pipe(\"scispacy_linker\", config={\"resolve_abbreviations\": True, \"linker_name\": \"umls\"})\r\n     12     result = pd.DataFrame()\r\n     13     for i, patient_id in enumerate(patient_line_dates_map[0].keys()) :\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in add_pipe(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\r\n    776                 config=config,\r\n    777                 raw_config=raw_config,\r\n--> 778                 validate=validate,\r\n    779             )\r\n    780         pipe_index = self._get_pipe_index(before, after, first, last)\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in create_pipe(self, factory_name, name, config, raw_config, validate)\r\n    657         # We're calling the internal _fill here to avoid constructing the\r\n    658         # registered functions twice\r\n--> 659         resolved = registry.resolve(cfg, validate=validate)\r\n    660         filled = registry.fill({\"cfg\": cfg[factory_name]}, validate=validate)[\"cfg\"]\r\n    661         filled = Config(filled)\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/thinc/config.py in resolve(cls, config, schema, overrides, validate)\r\n    726     ) -> Dict[str, Any]:\r\n    727         resolved, _ = cls._make(\r\n--> 728             config, schema=schema, overrides=overrides, validate=validate, resolve=True\r\n    729         )\r\n    730         return resolved\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/thinc/config.py in _make(cls, config, schema, overrides, resolve, validate)\r\n    775             config = Config(orig_config).interpolate()\r\n    776         filled, _, resolved = cls._fill(\r\n--> 777             config, schema, validate=validate, overrides=overrides, resolve=resolve\r\n    778         )\r\n    779         filled = Config(filled, section_order=section_order)\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/thinc/config.py in _fill(cls, config, schema, validate, resolve, parent, overrides)\r\n    846                     # We don't want to try/except this and raise our own error\r\n    847                     # here, because we want the traceback if the function fails.\r\n--> 848                     getter_result = getter(*args, **kwargs)\r\n    849                 else:\r\n    850                     # We're not resolving and calling the function, so replace\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/scispacy/linking.py in __init__(self, nlp, name, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, linker_name)\r\n     83 \r\n     84         self.candidate_generator = candidate_generator or CandidateGenerator(\r\n---> 85             name=linker_name\r\n     86         )\r\n     87         self.resolve_abbreviations = resolve_abbreviations\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __init__(self, ann_index, tfidf_vectorizer, ann_concept_aliases_list, kb, verbose, ef_search, name)\r\n    230         )\r\n    231 \r\n--> 232         self.kb = kb or DEFAULT_KNOWLEDGE_BASES[name]()\r\n    233         self.verbose = verbose\r\n    234 \r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/scispacy/linking_utils.py in __init__(self, file_path, types_file_path)\r\n     90 \r\n     91         self.semantic_type_tree: UmlsSemanticTypeTree = construct_umls_tree_from_tsv(\r\n---> 92             types_file_path\r\n     93         )\r\n     94 \r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_semantic_type_tree.py in construct_umls_tree_from_tsv(filepath)\r\n     98 \r\n     99     node_stack: Deque[SemanticTypeNode] = deque()\r\n--> 100     for line in open(cached_path(filepath), \"r\"):\r\n    101         name, type_id, level = line.split(\"\\t\")\r\n    102         name = name.strip()\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/scispacy/file_cache.py in cached_path(url_or_filename, cache_dir)\r\n     34     if parsed.scheme in (\"http\", \"https\"):\r\n     35         # URL, so get it from the cache (downloading if necessary)\r\n---> 36         return get_from_cache(url_or_filename, cache_dir)\r\n     37     elif os.path.exists(url_or_filename):\r\n     38         # File, and it exists.\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/scispacy/file_cache.py in get_from_cache(url, cache_dir)\r\n    110     os.makedirs(cache_dir, exist_ok=True)\r\n    111 \r\n--> 112     response = requests.head(url, allow_redirects=True)\r\n    113     if response.status_code != 200:\r\n    114         raise IOError(\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/requests/api.py in head(url, **kwargs)\r\n    102 \r\n    103     kwargs.setdefault('allow_redirects', False)\r\n--> 104     return request('head', url, **kwargs)\r\n    105 \r\n    106 \r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/requests/api.py in request(method, url, **kwargs)\r\n     59     # cases, and look like a memory leak in others.\r\n     60     with sessions.Session() as session:\r\n---> 61         return session.request(method=method, url=url, **kwargs)\r\n     62 \r\n     63 \r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/requests/sessions.py in request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\r\n    540         }\r\n    541         send_kwargs.update(settings)\r\n--> 542         resp = self.send(prep, **send_kwargs)\r\n    543 \r\n    544         return resp\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/requests/sessions.py in send(self, request, **kwargs)\r\n    653 \r\n    654         # Send the request\r\n--> 655         r = adapter.send(request, **kwargs)\r\n    656 \r\n    657         # Total elapsed time of the request (approximately)\r\n\r\n~/anaconda3/envs/scispacy/lib/python3.6/site-packages/requests/adapters.py in send(self, request, stream, timeout, verify, cert, proxies)\r\n    514                 raise SSLError(e, request=request)\r\n    515 \r\n--> 516             raise ConnectionError(e, request=request)\r\n    517 \r\n    518         except ClosedPoolError as e:\r\n\r\nConnectionError: HTTPSConnectionPool(host='s3-us-west-2.amazonaws.com', port=443): Max retries exceeded with url: /ai2-s2-scispacy/data/umls_semantic_type_tree.tsv (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fbb483d36a0>: Failed to establish a new connection: [Errno -2] Name or service not known',))\r\n```\r\n===============================================================================\r\n\r\nI guess that the scispacy keep downloading several files related to UMLS such as  below ones, \r\n\r\n'21a1012c532c3a431d60895c509f5b4d45b0f8966c4178b892190a302b21836f.330707f4efe774134872b9f77f0e3208c1d30f50800b3b39a6b8ec21d9adf1b7.umls_semantic_type_tree.tsv\r\n21a1012c532c3a431d60895c509f5b4d45b0f8966c4178b892190a302b21836f.330707f4efe774134872b9f77f0e3208c1d30f50800b3b39a6b8ec21d9adf1b7.umls_semantic_type_tree.tsv.json\r\n2d16de7bdaeca09492930b4065e44c63c649377e583a60baedc48b21160e6ffe.d22e20f8a82d5590c728adb94b7cf2d9bc3c953bfb63e06e356fd8b13d7b4d77.tfidf_vectorizer.joblib\r\n2d16de7bdaeca09492930b4065e44c63c649377e583a60baedc48b21160e6ffe.d22e20f8a82d5590c728adb94b7cf2d9bc3c953bfb63e06e356fd8b13d7b4d77.tfidf_vectorizer.joblib.json\r\nb7aadedb8a0dc19e86aca4e866e8767a419889c39f92f96e9458ee264bc13783.d670f5df5e7ad62f30ba05df2f48cafc6058117f2e352385f289872ac8c95028.tfidf_vectors_sparse.npz\r\nb7aadedb8a0dc19e86aca4e866e8767a419889c39f92f96e9458ee264bc13783.d670f5df5e7ad62f30ba05df2f48cafc6058117f2e352385f289872ac8c95028.tfidf_vectors_sparse.npz.json\r\ncf6297e16bc34e731db62e18b99603d440223279d6574e101d610ab5c713b265.1b0c2eaa35a3a31246741feac4b0255581214437fb86cd941018283668d461b0.umls_2020_aa_cat0129.jsonl\r\ncf6297e16bc34e731db62e18b99603d440223279d6574e101d610ab5c713b265.1b0c2eaa35a3a31246741feac4b0255581214437fb86cd941018283668d461b0.umls_2020_aa_cat0129.jsonl.json\r\nd485a39692e39f93339abf6102c3336dda07d84d8ae46a03d55079b54cad1137.a65425f2cddfa1f741a17c18fc68797f5434547425e30bbe236dea0dcb7a9389.concept_aliases.json\r\nd485a39692e39f93339abf6102c3336dda07d84d8ae46a03d55079b54cad1137.a65425f2cddfa1f741a17c18fc68797f5434547425e30bbe236dea0dcb7a9389.concept_aliases.json.json\r\ndda67f3ef5951cfedf2de7de7b3561d45ce9e8ed92346cc196310a76b15fe0b6.fdebf628ed43f2d0fba4f250d97a57ddcb36b183308702481009f67c5d771465.nmslib_index.bin\r\ndda67f3ef5951cfedf2de7de7b3561d45ce9e8ed92346cc196310a76b15fe0b6.fdebf628ed43f2d0fba4f250d97a57ddcb36b183308702481009f67c5d771465.nmslib_index.bin.json'\r\n\r\nI think this is the issue of sha256 while downloading because Scispacy did not identify the prefix name of downloaded files in the .scispacy/datasets/ in user's home directory, so it endlessly tried to download the mandatory files for extracting entity of EHR. How can I fix this issue? \r\n\r\n=================================================================================================\r\n```python\r\ndef extract_entity(patient_dates_map):\r\n    nlp = spacy.load('en_ner_bc5cdr_md')\r\n    os.environ[\"SCISPACY_CACHE\"]=\"/home/hahnyi/.scispacy\"\r\n    nlp.add_pipe(\"scispacy_linker\", config={\"resolve_abbreviations\": True, \"linker_name\": \"umls\"})\r\n    for i, patient_id in enumerate(patient_dates_map[0].keys()) :\r\n     \r\n        dates_map = patient_dates_map[0][patient_id]\r\n        for line, trace in dates_map.items():\r\n            doc = nlp(line.lower())\r\n            for ent in doc.ents :\r\n                if ent.label_ == \"DISEASE\":\r\n                    if len(ent._.kb_ents) > 0:\r\n                        linked_ent = ent._.kb_ents[0]\r\n                    else:\r\n                        linked_ent = None\r\n\r\n                    ent_text = linked_ent[0] if linked_ent else ent.text\r\n```","closed_by":{"login":"dakinggg","id":43149077,"node_id":"MDQ6VXNlcjQzMTQ5MDc3","avatar_url":"https://avatars.githubusercontent.com/u/43149077?v=4","gravatar_id":"","url":"https://api.github.com/users/dakinggg","html_url":"https://github.com/dakinggg","followers_url":"https://api.github.com/users/dakinggg/followers","following_url":"https://api.github.com/users/dakinggg/following{/other_user}","gists_url":"https://api.github.com/users/dakinggg/gists{/gist_id}","starred_url":"https://api.github.com/users/dakinggg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakinggg/subscriptions","organizations_url":"https://api.github.com/users/dakinggg/orgs","repos_url":"https://api.github.com/users/dakinggg/repos","events_url":"https://api.github.com/users/dakinggg/events{/privacy}","received_events_url":"https://api.github.com/users/dakinggg/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/allenai/scispacy/issues/370/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/allenai/scispacy/issues/370/timeline","performed_via_github_app":null,"state_reason":"completed"}