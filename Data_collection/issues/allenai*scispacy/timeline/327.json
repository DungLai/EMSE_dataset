[{"url":"https://api.github.com/repos/allenai/scispacy/issues/comments/789184234","html_url":"https://github.com/allenai/scispacy/issues/327#issuecomment-789184234","issue_url":"https://api.github.com/repos/allenai/scispacy/issues/327","id":789184234,"node_id":"MDEyOklzc3VlQ29tbWVudDc4OTE4NDIzNA==","user":{"login":"dakinggg","id":43149077,"node_id":"MDQ6VXNlcjQzMTQ5MDc3","avatar_url":"https://avatars.githubusercontent.com/u/43149077?v=4","gravatar_id":"","url":"https://api.github.com/users/dakinggg","html_url":"https://github.com/dakinggg","followers_url":"https://api.github.com/users/dakinggg/followers","following_url":"https://api.github.com/users/dakinggg/following{/other_user}","gists_url":"https://api.github.com/users/dakinggg/gists{/gist_id}","starred_url":"https://api.github.com/users/dakinggg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakinggg/subscriptions","organizations_url":"https://api.github.com/users/dakinggg/orgs","repos_url":"https://api.github.com/users/dakinggg/repos","events_url":"https://api.github.com/users/dakinggg/events{/privacy}","received_events_url":"https://api.github.com/users/dakinggg/received_events","type":"User","site_admin":false},"created_at":"2021-03-02T20:15:29Z","updated_at":"2021-03-10T18:23:09Z","author_association":"COLLABORATOR","body":"You have a couple options that I know of to get different sentence segmentation. In general, nothing is going to be perfect. In particular, the default spacy sentence segmentation is based on the dependency parse and for sure can do things like the error you observed. FWIW, if you add a `.` at the end of the first example, it gets it right.\r\n\r\nOptions:\r\n1) Check out the pysbd-based sentence segmentation pipe here (https://github.com/allenai/scispacy/blob/5df54e468c649e465b98ff6d924fa910eb3cb50c/scispacy/custom_sentence_segmenter.py#L12). You can add it with from scispacy.custom_sentence_segmenter import pysbd_sentencizer; `nlp.add_pipe('pysbd_sentencizer', first=True)`\r\n2) You can use spacy's default rule based sentencizer by `nlp.add_pipe('sentencizer', first=True)`","reactions":{"url":"https://api.github.com/repos/allenai/scispacy/issues/comments/789184234/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"dakinggg","id":43149077,"node_id":"MDQ6VXNlcjQzMTQ5MDc3","avatar_url":"https://avatars.githubusercontent.com/u/43149077?v=4","gravatar_id":"","url":"https://api.github.com/users/dakinggg","html_url":"https://github.com/dakinggg","followers_url":"https://api.github.com/users/dakinggg/followers","following_url":"https://api.github.com/users/dakinggg/following{/other_user}","gists_url":"https://api.github.com/users/dakinggg/gists{/gist_id}","starred_url":"https://api.github.com/users/dakinggg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakinggg/subscriptions","organizations_url":"https://api.github.com/users/dakinggg/orgs","repos_url":"https://api.github.com/users/dakinggg/repos","events_url":"https://api.github.com/users/dakinggg/events{/privacy}","received_events_url":"https://api.github.com/users/dakinggg/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/allenai/scispacy/issues/comments/789382495","html_url":"https://github.com/allenai/scispacy/issues/327#issuecomment-789382495","issue_url":"https://api.github.com/repos/allenai/scispacy/issues/327","id":789382495,"node_id":"MDEyOklzc3VlQ29tbWVudDc4OTM4MjQ5NQ==","user":{"login":"Hui-zju","id":71915957,"node_id":"MDQ6VXNlcjcxOTE1OTU3","avatar_url":"https://avatars.githubusercontent.com/u/71915957?v=4","gravatar_id":"","url":"https://api.github.com/users/Hui-zju","html_url":"https://github.com/Hui-zju","followers_url":"https://api.github.com/users/Hui-zju/followers","following_url":"https://api.github.com/users/Hui-zju/following{/other_user}","gists_url":"https://api.github.com/users/Hui-zju/gists{/gist_id}","starred_url":"https://api.github.com/users/Hui-zju/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Hui-zju/subscriptions","organizations_url":"https://api.github.com/users/Hui-zju/orgs","repos_url":"https://api.github.com/users/Hui-zju/repos","events_url":"https://api.github.com/users/Hui-zju/events{/privacy}","received_events_url":"https://api.github.com/users/Hui-zju/received_events","type":"User","site_admin":false},"created_at":"2021-03-03T02:39:24Z","updated_at":"2021-03-03T02:39:24Z","author_association":"NONE","body":"Thanks for your reply! I will try with the options.","reactions":{"url":"https://api.github.com/repos/allenai/scispacy/issues/comments/789382495/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"Hui-zju","id":71915957,"node_id":"MDQ6VXNlcjcxOTE1OTU3","avatar_url":"https://avatars.githubusercontent.com/u/71915957?v=4","gravatar_id":"","url":"https://api.github.com/users/Hui-zju","html_url":"https://github.com/Hui-zju","followers_url":"https://api.github.com/users/Hui-zju/followers","following_url":"https://api.github.com/users/Hui-zju/following{/other_user}","gists_url":"https://api.github.com/users/Hui-zju/gists{/gist_id}","starred_url":"https://api.github.com/users/Hui-zju/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Hui-zju/subscriptions","organizations_url":"https://api.github.com/users/Hui-zju/orgs","repos_url":"https://api.github.com/users/Hui-zju/repos","events_url":"https://api.github.com/users/Hui-zju/events{/privacy}","received_events_url":"https://api.github.com/users/Hui-zju/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/allenai/scispacy/issues/comments/794625912","html_url":"https://github.com/allenai/scispacy/issues/327#issuecomment-794625912","issue_url":"https://api.github.com/repos/allenai/scispacy/issues/327","id":794625912,"node_id":"MDEyOklzc3VlQ29tbWVudDc5NDYyNTkxMg==","user":{"login":"SantoshGuptaML","id":57730245,"node_id":"MDQ6VXNlcjU3NzMwMjQ1","avatar_url":"https://avatars.githubusercontent.com/u/57730245?v=4","gravatar_id":"","url":"https://api.github.com/users/SantoshGuptaML","html_url":"https://github.com/SantoshGuptaML","followers_url":"https://api.github.com/users/SantoshGuptaML/followers","following_url":"https://api.github.com/users/SantoshGuptaML/following{/other_user}","gists_url":"https://api.github.com/users/SantoshGuptaML/gists{/gist_id}","starred_url":"https://api.github.com/users/SantoshGuptaML/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SantoshGuptaML/subscriptions","organizations_url":"https://api.github.com/users/SantoshGuptaML/orgs","repos_url":"https://api.github.com/users/SantoshGuptaML/repos","events_url":"https://api.github.com/users/SantoshGuptaML/events{/privacy}","received_events_url":"https://api.github.com/users/SantoshGuptaML/received_events","type":"User","site_admin":false},"created_at":"2021-03-09T23:56:35Z","updated_at":"2021-03-09T23:56:35Z","author_association":"NONE","body":"With \r\n\r\n```\r\nnlp = spacy.load('en_core_sci_sm')\r\nnlp.add_pipe('pysbd_sentencizer', first=True)\r\n```\r\n\r\nIs the scispacy model being used at all, or is it just pysbd being used?\r\n","reactions":{"url":"https://api.github.com/repos/allenai/scispacy/issues/comments/794625912/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"SantoshGuptaML","id":57730245,"node_id":"MDQ6VXNlcjU3NzMwMjQ1","avatar_url":"https://avatars.githubusercontent.com/u/57730245?v=4","gravatar_id":"","url":"https://api.github.com/users/SantoshGuptaML","html_url":"https://github.com/SantoshGuptaML","followers_url":"https://api.github.com/users/SantoshGuptaML/followers","following_url":"https://api.github.com/users/SantoshGuptaML/following{/other_user}","gists_url":"https://api.github.com/users/SantoshGuptaML/gists{/gist_id}","starred_url":"https://api.github.com/users/SantoshGuptaML/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SantoshGuptaML/subscriptions","organizations_url":"https://api.github.com/users/SantoshGuptaML/orgs","repos_url":"https://api.github.com/users/SantoshGuptaML/repos","events_url":"https://api.github.com/users/SantoshGuptaML/events{/privacy}","received_events_url":"https://api.github.com/users/SantoshGuptaML/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/allenai/scispacy/issues/comments/794674113","html_url":"https://github.com/allenai/scispacy/issues/327#issuecomment-794674113","issue_url":"https://api.github.com/repos/allenai/scispacy/issues/327","id":794674113,"node_id":"MDEyOklzc3VlQ29tbWVudDc5NDY3NDExMw==","user":{"login":"dakinggg","id":43149077,"node_id":"MDQ6VXNlcjQzMTQ5MDc3","avatar_url":"https://avatars.githubusercontent.com/u/43149077?v=4","gravatar_id":"","url":"https://api.github.com/users/dakinggg","html_url":"https://github.com/dakinggg","followers_url":"https://api.github.com/users/dakinggg/followers","following_url":"https://api.github.com/users/dakinggg/following{/other_user}","gists_url":"https://api.github.com/users/dakinggg/gists{/gist_id}","starred_url":"https://api.github.com/users/dakinggg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakinggg/subscriptions","organizations_url":"https://api.github.com/users/dakinggg/orgs","repos_url":"https://api.github.com/users/dakinggg/repos","events_url":"https://api.github.com/users/dakinggg/events{/privacy}","received_events_url":"https://api.github.com/users/dakinggg/received_events","type":"User","site_admin":false},"created_at":"2021-03-10T00:51:49Z","updated_at":"2021-03-10T00:51:49Z","author_association":"COLLABORATOR","body":"you can view the whole pipeline via `nlp.pipeline`. It is just adding the pysbd pipe for sentence segmentation.","reactions":{"url":"https://api.github.com/repos/allenai/scispacy/issues/comments/794674113/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"dakinggg","id":43149077,"node_id":"MDQ6VXNlcjQzMTQ5MDc3","avatar_url":"https://avatars.githubusercontent.com/u/43149077?v=4","gravatar_id":"","url":"https://api.github.com/users/dakinggg","html_url":"https://github.com/dakinggg","followers_url":"https://api.github.com/users/dakinggg/followers","following_url":"https://api.github.com/users/dakinggg/following{/other_user}","gists_url":"https://api.github.com/users/dakinggg/gists{/gist_id}","starred_url":"https://api.github.com/users/dakinggg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakinggg/subscriptions","organizations_url":"https://api.github.com/users/dakinggg/orgs","repos_url":"https://api.github.com/users/dakinggg/repos","events_url":"https://api.github.com/users/dakinggg/events{/privacy}","received_events_url":"https://api.github.com/users/dakinggg/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/allenai/scispacy/issues/comments/795142592","html_url":"https://github.com/allenai/scispacy/issues/327#issuecomment-795142592","issue_url":"https://api.github.com/repos/allenai/scispacy/issues/327","id":795142592,"node_id":"MDEyOklzc3VlQ29tbWVudDc5NTE0MjU5Mg==","user":{"login":"SantoshGuptaML","id":57730245,"node_id":"MDQ6VXNlcjU3NzMwMjQ1","avatar_url":"https://avatars.githubusercontent.com/u/57730245?v=4","gravatar_id":"","url":"https://api.github.com/users/SantoshGuptaML","html_url":"https://github.com/SantoshGuptaML","followers_url":"https://api.github.com/users/SantoshGuptaML/followers","following_url":"https://api.github.com/users/SantoshGuptaML/following{/other_user}","gists_url":"https://api.github.com/users/SantoshGuptaML/gists{/gist_id}","starred_url":"https://api.github.com/users/SantoshGuptaML/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SantoshGuptaML/subscriptions","organizations_url":"https://api.github.com/users/SantoshGuptaML/orgs","repos_url":"https://api.github.com/users/SantoshGuptaML/repos","events_url":"https://api.github.com/users/SantoshGuptaML/events{/privacy}","received_events_url":"https://api.github.com/users/SantoshGuptaML/received_events","type":"User","site_admin":false},"created_at":"2021-03-10T09:25:37Z","updated_at":"2021-03-10T09:27:21Z","author_association":"NONE","body":"for scispacy `pipeline` gives \r\n\r\n```\r\n[('attribute_ruler',\r\n  <spacy.pipeline.attributeruler.AttributeRuler at 0x7f1a5969e3c0>),\r\n ('sentencizer', <spacy.pipeline.sentencizer.Sentencizer at 0x7f1a59754640>)]\r\n```\r\n\r\nWhere as regular spacy gives\r\n\r\n```\r\n[('sentencizer', <spacy.pipeline.pipes.Sentencizer at 0x7f821ef95e50>)]\r\n```\r\n\r\nSo it looks like scispacy adds a custom attribute_ruler, but both scispacy and spacy use the same sentencizer? Does that sound right?\r\n\r\nscispacy gives much better results than spacy for abstracts. Here's an example. \r\n\r\nen_core_sci_md:\r\n\r\n```\r\nAbstract  Our goal is to learn task-independent representations of academic papers.\r\nInspired by the recent success of pretrained Transformer language models across various NLP tasks, we use the Transformer model architecture as basis of encoding the input paper.\r\nExisting LMs such as BERT, however, are primarily based on masked language modeling objective, only considering intra-document context and do not use any inter-document information.\r\nThis limits their ability to learn optimal document representations.\r\nTo learn high-quality documentlevel representations we propose using citations as an inter-document relatedness signal and formulate it as a triplet loss learning objective.\r\nWe then pretrain the model on a large corpus of citations using this objective, encouraging it to output representations that are more similar for papers that share a citation link than for those that do not.\r\nRepresentation learning is a critical ingredient for natural language processing systems.\r\nRecent Transformer language models like BERT learn powerful textual representations, but these models are targeted towards token- and sentence-level training objectives and do not leverage information on inter-document relatedness, which limits their document-level representation power.\r\nFor applications on scientific documents, such as classification and recommendation, the embeddings power strong performance on end tasks.\r\nWe propose SPECTER, a new method to generate document-level embedding of scientific documents based on pretraining a Transformer language model on a powerful signal of document-level relatedness: the citation graph.\r\nUnlike existing pretrained language models, SPECTER can be easily applied to downstream applications without task-specific fine-tuning.\r\nAdditionally, to encourage further research on document-level models, we introduce SCIDOCS, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation.\r\nWe show that SPECTER outperforms a variety of competitive baselines on the benchmark.\r\nAs the pace of scientific publication continues to increase, Natural Language Processing (NLP) tools that help users to search, discover and understand the scientific literature have become critical.\r\nIn recent years, substantial improvements in NLP tools have been brought about by pretrained neural language models (LMs) (Radford et al., 2018; Devlin et al., 2019; Yang et al., 2019).\r\nWhile such models are widely used for representing individual words ∗ Equal contribution 1 https://github.com/allenai/specter or sentences, extensions to whole-document embeddings are relatively underexplored.\r\nLikewise, methods that do use inter-document signals to produce whole-document embeddings (Tu et al., 2017; Chen et al., 2019) have yet to incorporate stateof-the-art pretrained LMs.\r\nHere, we study how to leverage the power of pretrained language models to learn embeddings for scientific documents.\r\nA paper’s title and abstract provide rich semantic content about the paper, but, as we show in this work, simply passing these textual fields to an “off-the-shelf” pretrained language model—even a state-of-the-art model tailored to scientific text like the recent SciBERT (Beltagy et al., 2019)—does not result in accurate paper representations.\r\nThe language modeling objectives used to pretrain the model do not lead it to output representations that are helpful for document-level tasks such as topic classification or recommendation.\r\nIn this paper, we introduce a new method for learning general-purpose vector representations of scientific documents.\r\nOur system, SPECTER, 2 incorporates inter-document context into the Transformer (Vaswani et al., 2017) language models (e.g., SciBERT (Beltagy et al., 2019)) to learn document representations that are effective across a wide-variety of downstream tasks, without the need for any task-specific fine-tuning of the pretrained language model.\r\nWe specifically use citations as a naturally occurring, inter-document incidental supervision signal indicating which documents are most related and formulate the signal into a triplet-loss pretraining objective.\r\nUnlike many prior works, at inference time, our model does not require any citation information.\r\nThis is critical for embedding new papers that have not yet been cited.\r\nIn experiments, we show that SPECTER’s representations substantially outperform the state\r\n```\r\n\r\nen_core_web_sm\r\n\r\n```\r\nAbstract  Our goal is to learn task-independent representations of academic papers.\r\nInspired by the recent success of pretrained Transformer language models across various NLP tasks, we use the Transformer model architecture as basis of encoding the input paper.\r\nExisting LMs such as BERT, however, are primarily based on masked language modeling objective, only considering intra-document context and do not use any inter-document information.\r\nThis limits their ability to learn optimal document representations.\r\nTo learn high-quality documentlevel representations we propose using citations as an inter-document relatedness signal and formulate it as a triplet loss learning objective.\r\nWe then pretrain the model on a large corpus of citations using this objective, encouraging it to output representations that are more similar for papers that share a citation link than for those that do not.\r\nRepresentation learning is a critical ingredient for natural language processing systems.\r\nRecent Transformer language models like BERT learn powerful textual representations, but these models are targeted towards token- and sentence-level training objectives and do not leverage information on inter-document relatedness, which limits their document-level representation power.\r\nFor applications on scientific documents, such as classification and recommendation, the embeddings power strong performance on end tasks.\r\nWe propose SPECTER, a new method to generate document-level embedding of scientific documents based on pretraining a Transformer language model on a powerful signal of document-level relatedness: the citation graph.\r\nUnlike existing pretrained language models, SPECTER can be easily applied to downstream applications without task-specific fine-tuning.\r\nAdditionally, to encourage further research on document-level models, we introduce SCIDOCS, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation.\r\nWe show that SPECTER outperforms a variety of competitive baselines on the benchmark.\r\nAs the pace of scientific publication continues to increase, Natural Language Processing (NLP) tools that help users to search, discover and understand the scientific literature have become critical.\r\nIn recent years, substantial improvements in NLP tools have been brought about by pretrained neural language models (LMs) (Radford et al.,\r\n2018; Devlin et al.,\r\n2019; Yang et al.,\r\n2019).\r\nWhile such models are widely used for representing individual words ∗ Equal contribution 1 https://github.com/allenai/specter or sentences, extensions to whole-document embeddings are relatively underexplored.\r\nLikewise, methods that do use inter-document signals to produce whole-document embeddings (Tu et al.,\r\n2017; Chen et al.,\r\n2019) have yet to incorporate stateof-the-art pretrained LMs.\r\nHere, we study how to leverage the power of pretrained language models to learn embeddings for scientific documents.\r\nA paper’s title and abstract provide rich semantic content about the paper, but, as we show in this work, simply passing these textual fields to an “off-the-shelf” pretrained language model—even a state-of-the-art model tailored to scientific text like the recent SciBERT (Beltagy et al.,\r\n2019)—does not result in accurate paper representations.\r\nThe language modeling objectives used to pretrain the model do not lead it to output representations that are helpful for document-level tasks such as topic classification or recommendation.\r\nIn this paper, we introduce a new method for learning general-purpose vector representations of scientific documents.\r\nOur system, SPECTER, 2 incorporates inter-document context into the Transformer (Vaswani et al.,\r\n2017) language models (e.g., SciBERT (Beltagy et al.,\r\n2019)) to learn document representations that are effective across a wide-variety of downstream tasks, without the need for any task-specific fine-tuning of the pretrained language model.\r\nWe specifically use citations as a naturally occurring, inter-document incidental supervision signal indicating which documents are most related and formulate the signal into a triplet-loss pretraining objective.\r\nUnlike many prior works, at inference time, our model does not require any citation information.\r\nThis is critical for embedding new papers that have not yet been cited.\r\nIn experiments, we show that SPECTER’s representations substantially outperform the state\r\n```\r\n\r\nI also tried the pysbd_sentencizer, but got an error getting it to work \r\n\r\n```\r\nimport spacy\r\nimport scispacy\r\nfrom scispacy.custom_sentence_segmentater import pysbd_sentencizer\r\nnlpSciMd = spacy.load(\"en_core_sci_md\", disable = ['ner', 'parser', 'tagger', 'lemmatizer', 'attributeruler', 'tok2vec'])\r\nnlpSciSm = spacy.load(\"en_core_sci_sm\", disable = ['ner', 'parser', 'tagger', 'lemmatizer', 'attributeruler', 'tok2vec'])\r\n# nlpSciLg = spacy.load(\"en_core_sci_lg\", disable = ['ner', 'parser', 'tagger', 'lemmatizer'])\r\nnlpSciMd.add_pipe('pysbd_sentencizer')\r\nnlpSciSm.add_pipe('pysbd_sentencizer')\r\n```\r\n\r\nerror\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n<ipython-input-3-45556ac5415d> in <module>()\r\n      1 import spacy\r\n      2 import scispacy\r\n----> 3 from scispacy.custom_sentence_segmentater import pysbd_sentencizer\r\n      4 nlpSciMd = spacy.load(\"en_core_sci_md\", disable = ['ner', 'parser', 'tagger', 'lemmatizer', 'attributeruler', 'tok2vec'])\r\n      5 nlpSciSm = spacy.load(\"en_core_sci_sm\", disable = ['ner', 'parser', 'tagger', 'lemmatizer', 'attributeruler', 'tok2vec'])\r\n\r\nModuleNotFoundError: No module named 'scispacy.custom_sentence_segmentater'\r\n```\r\n\r\nFor convenience, here are the colab notebooks where I tried to code\r\n\r\nscispacy\r\n\r\nhttps://colab.research.google.com/drive/1EleinjhYDaqU3OYb4u1odSItEY7-KP4U?usp=sharing\r\n\r\nspacy\r\n\r\nhttps://colab.research.google.com/drive/1UCh65W-yEYZzOhWDrqL_ACKSbjxWXbGI?usp=sharing\r\n\r\npysbd_sentencizer\r\n\r\nhttps://colab.research.google.com/drive/1jYetA7G4RdRHDGmXxl3ToSBBpzw6BE36?usp=sharing\r\n\r\nside note: in the first notebook you can see there's an error getting the small model to work. ","reactions":{"url":"https://api.github.com/repos/allenai/scispacy/issues/comments/795142592/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"SantoshGuptaML","id":57730245,"node_id":"MDQ6VXNlcjU3NzMwMjQ1","avatar_url":"https://avatars.githubusercontent.com/u/57730245?v=4","gravatar_id":"","url":"https://api.github.com/users/SantoshGuptaML","html_url":"https://github.com/SantoshGuptaML","followers_url":"https://api.github.com/users/SantoshGuptaML/followers","following_url":"https://api.github.com/users/SantoshGuptaML/following{/other_user}","gists_url":"https://api.github.com/users/SantoshGuptaML/gists{/gist_id}","starred_url":"https://api.github.com/users/SantoshGuptaML/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SantoshGuptaML/subscriptions","organizations_url":"https://api.github.com/users/SantoshGuptaML/orgs","repos_url":"https://api.github.com/users/SantoshGuptaML/repos","events_url":"https://api.github.com/users/SantoshGuptaML/events{/privacy}","received_events_url":"https://api.github.com/users/SantoshGuptaML/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/allenai/scispacy/issues/comments/795863175","html_url":"https://github.com/allenai/scispacy/issues/327#issuecomment-795863175","issue_url":"https://api.github.com/repos/allenai/scispacy/issues/327","id":795863175,"node_id":"MDEyOklzc3VlQ29tbWVudDc5NTg2MzE3NQ==","user":{"login":"dakinggg","id":43149077,"node_id":"MDQ6VXNlcjQzMTQ5MDc3","avatar_url":"https://avatars.githubusercontent.com/u/43149077?v=4","gravatar_id":"","url":"https://api.github.com/users/dakinggg","html_url":"https://github.com/dakinggg","followers_url":"https://api.github.com/users/dakinggg/followers","following_url":"https://api.github.com/users/dakinggg/following{/other_user}","gists_url":"https://api.github.com/users/dakinggg/gists{/gist_id}","starred_url":"https://api.github.com/users/dakinggg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakinggg/subscriptions","organizations_url":"https://api.github.com/users/dakinggg/orgs","repos_url":"https://api.github.com/users/dakinggg/repos","events_url":"https://api.github.com/users/dakinggg/events{/privacy}","received_events_url":"https://api.github.com/users/dakinggg/received_events","type":"User","site_admin":false},"created_at":"2021-03-10T18:22:56Z","updated_at":"2021-03-10T18:22:56Z","author_association":"COLLABORATOR","body":"If you disable everything and just add the sentencizer, you should end up with just the sentencizer, whether it is spacy or scispacy\r\n```\r\nIn [8]: nlp = spacy.load('en_core_sci_sm', disable=['tok2vec', 'tagger', 'attribute_ruler', 'lemmatizer', 'parser', 'ner'])\r\n\r\nIn [9]: nlp.pipeline\r\nOut[9]: []\r\n\r\nIn [10]: nlp.add_pipe('sentencizer')\r\nOut[10]: <spacy.pipeline.sentencizer.Sentencizer at 0x7faf4642b640>\r\n\r\nIn [11]: nlp.pipeline\r\nOut[11]: [('sentencizer', <spacy.pipeline.sentencizer.Sentencizer at 0x7faf4642b640>)]\r\n```\r\n\r\nAs for your error, it is just a typo. You need `from scispacy.custom_sentence_segmenter import pysbd_sentencizer`. Sorry about that. Fixed the typo above.","reactions":{"url":"https://api.github.com/repos/allenai/scispacy/issues/comments/795863175/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"dakinggg","id":43149077,"node_id":"MDQ6VXNlcjQzMTQ5MDc3","avatar_url":"https://avatars.githubusercontent.com/u/43149077?v=4","gravatar_id":"","url":"https://api.github.com/users/dakinggg","html_url":"https://github.com/dakinggg","followers_url":"https://api.github.com/users/dakinggg/followers","following_url":"https://api.github.com/users/dakinggg/following{/other_user}","gists_url":"https://api.github.com/users/dakinggg/gists{/gist_id}","starred_url":"https://api.github.com/users/dakinggg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakinggg/subscriptions","organizations_url":"https://api.github.com/users/dakinggg/orgs","repos_url":"https://api.github.com/users/dakinggg/repos","events_url":"https://api.github.com/users/dakinggg/events{/privacy}","received_events_url":"https://api.github.com/users/dakinggg/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/allenai/scispacy/issues/comments/803182548","html_url":"https://github.com/allenai/scispacy/issues/327#issuecomment-803182548","issue_url":"https://api.github.com/repos/allenai/scispacy/issues/327","id":803182548,"node_id":"MDEyOklzc3VlQ29tbWVudDgwMzE4MjU0OA==","user":{"login":"dakinggg","id":43149077,"node_id":"MDQ6VXNlcjQzMTQ5MDc3","avatar_url":"https://avatars.githubusercontent.com/u/43149077?v=4","gravatar_id":"","url":"https://api.github.com/users/dakinggg","html_url":"https://github.com/dakinggg","followers_url":"https://api.github.com/users/dakinggg/followers","following_url":"https://api.github.com/users/dakinggg/following{/other_user}","gists_url":"https://api.github.com/users/dakinggg/gists{/gist_id}","starred_url":"https://api.github.com/users/dakinggg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakinggg/subscriptions","organizations_url":"https://api.github.com/users/dakinggg/orgs","repos_url":"https://api.github.com/users/dakinggg/repos","events_url":"https://api.github.com/users/dakinggg/events{/privacy}","received_events_url":"https://api.github.com/users/dakinggg/received_events","type":"User","site_admin":false},"created_at":"2021-03-19T23:06:39Z","updated_at":"2021-03-19T23:06:39Z","author_association":"COLLABORATOR","body":"Closing due to inactivity. Please reopen if you are still having issues.","reactions":{"url":"https://api.github.com/repos/allenai/scispacy/issues/comments/803182548/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"dakinggg","id":43149077,"node_id":"MDQ6VXNlcjQzMTQ5MDc3","avatar_url":"https://avatars.githubusercontent.com/u/43149077?v=4","gravatar_id":"","url":"https://api.github.com/users/dakinggg","html_url":"https://github.com/dakinggg","followers_url":"https://api.github.com/users/dakinggg/followers","following_url":"https://api.github.com/users/dakinggg/following{/other_user}","gists_url":"https://api.github.com/users/dakinggg/gists{/gist_id}","starred_url":"https://api.github.com/users/dakinggg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakinggg/subscriptions","organizations_url":"https://api.github.com/users/dakinggg/orgs","repos_url":"https://api.github.com/users/dakinggg/repos","events_url":"https://api.github.com/users/dakinggg/events{/privacy}","received_events_url":"https://api.github.com/users/dakinggg/received_events","type":"User","site_admin":false}},{"id":4484653125,"node_id":"MDExOkNsb3NlZEV2ZW50NDQ4NDY1MzEyNQ==","url":"https://api.github.com/repos/allenai/scispacy/issues/events/4484653125","actor":{"login":"dakinggg","id":43149077,"node_id":"MDQ6VXNlcjQzMTQ5MDc3","avatar_url":"https://avatars.githubusercontent.com/u/43149077?v=4","gravatar_id":"","url":"https://api.github.com/users/dakinggg","html_url":"https://github.com/dakinggg","followers_url":"https://api.github.com/users/dakinggg/followers","following_url":"https://api.github.com/users/dakinggg/following{/other_user}","gists_url":"https://api.github.com/users/dakinggg/gists{/gist_id}","starred_url":"https://api.github.com/users/dakinggg/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dakinggg/subscriptions","organizations_url":"https://api.github.com/users/dakinggg/orgs","repos_url":"https://api.github.com/users/dakinggg/repos","events_url":"https://api.github.com/users/dakinggg/events{/privacy}","received_events_url":"https://api.github.com/users/dakinggg/received_events","type":"User","site_admin":false},"event":"closed","commit_id":null,"commit_url":null,"created_at":"2021-03-19T23:06:39Z","state_reason":null,"performed_via_github_app":null}]