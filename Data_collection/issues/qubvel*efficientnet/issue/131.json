{"url":"https://api.github.com/repos/qubvel/efficientnet/issues/131","repository_url":"https://api.github.com/repos/qubvel/efficientnet","labels_url":"https://api.github.com/repos/qubvel/efficientnet/issues/131/labels{/name}","comments_url":"https://api.github.com/repos/qubvel/efficientnet/issues/131/comments","events_url":"https://api.github.com/repos/qubvel/efficientnet/issues/131/events","html_url":"https://github.com/qubvel/efficientnet/issues/131","id":748103481,"node_id":"MDU6SXNzdWU3NDgxMDM0ODE=","number":131,"title":"preprocess_input function with Lambda layers","user":{"login":"dimitreOliveira","id":16668746,"node_id":"MDQ6VXNlcjE2NjY4NzQ2","avatar_url":"https://avatars.githubusercontent.com/u/16668746?v=4","gravatar_id":"","url":"https://api.github.com/users/dimitreOliveira","html_url":"https://github.com/dimitreOliveira","followers_url":"https://api.github.com/users/dimitreOliveira/followers","following_url":"https://api.github.com/users/dimitreOliveira/following{/other_user}","gists_url":"https://api.github.com/users/dimitreOliveira/gists{/gist_id}","starred_url":"https://api.github.com/users/dimitreOliveira/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dimitreOliveira/subscriptions","organizations_url":"https://api.github.com/users/dimitreOliveira/orgs","repos_url":"https://api.github.com/users/dimitreOliveira/repos","events_url":"https://api.github.com/users/dimitreOliveira/events{/privacy}","received_events_url":"https://api.github.com/users/dimitreOliveira/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-11-21T21:10:11Z","updated_at":"2020-11-21T21:10:11Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi, I am trying to use the `preprocess_input` function with a lambda layer like bellow\r\n```\r\ndef model_fn(input_shape, N_CLASSES):\r\n    img_adjust_layer = L.Lambda(efn.preprocess_input, input_shape=input_shape)    \r\n    \r\n    input_image = L.Input(shape=input_shape, name='input_image')\r\n    base_model = efn.EfficientNetB3(include_top=False, \r\n                                                          weights='noisy-student', \r\n                                                          pooling='avg')\r\n\r\n    model = tf.keras.Sequential([\r\n        input_image,\r\n        img_adjust_layer,\r\n        base_model,\r\n        L.Dense(N_CLASSES, activation='softmax')\r\n    ])\r\n    \r\n    return model\r\n```\r\n\r\n\r\nbut I am getting this error:\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n---> 60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n\r\nTypeError: An op outside of the function building code is being passed\r\na \"Graph\" tensor. It is possible to have Graph tensors\r\nleak out of the function building context by including a\r\ntf.init_scope in your function building code.\r\nFor example, the following function will fail:\r\n  @tf.function\r\n  def has_init_scope():\r\n    my_constant = tf.constant(1.)\r\n    with tf.init_scope():\r\n      added = my_constant * 2\r\nThe graph tensor has name: lambda/Const:0\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n_SymbolicException                        Traceback (most recent call last)\r\n<ipython-input-63-ff9daa93ccd9> in <module>\r\n      6 #                     class_weight=class_weight,\r\n      7                     epochs=EPOCHS,\r\n----> 8                     verbose=2).history\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n     64   def _method_wrapper(self, *args, **kwargs):\r\n     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n---> 66       return method(self, *args, **kwargs)\r\n     67 \r\n     68     # Running inside `run_distribute_coordinator` already.\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n    846                 batch_size=batch_size):\r\n    847               callbacks.on_train_batch_begin(step)\r\n--> 848               tmp_logs = train_function(iterator)\r\n    849               # Catch OutOfRangeError for Datasets of unknown size.\r\n    850               # This blocks until the batch has finished executing.\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    578         xla_context.Exit()\r\n    579     else:\r\n--> 580       result = self._call(*args, **kwds)\r\n    581 \r\n    582     if tracing_count == self._get_tracing_count():\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    642         # Lifting succeeded, so variables are initialized and we can run the\r\n    643         # stateless function.\r\n--> 644         return self._stateless_fn(*args, **kwds)\r\n    645     else:\r\n    646       canon_args, canon_kwds = \\\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   2418     with self._lock:\r\n   2419       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n-> 2420     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   2421 \r\n   2422   @property\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs)\r\n   1663          if isinstance(t, (ops.Tensor,\r\n   1664                            resource_variable_ops.BaseResourceVariable))),\r\n-> 1665         self.captured_inputs)\r\n   1666 \r\n   1667   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1744       # No tape is watching; skip to running the function.\r\n   1745       return self._build_call_outputs(self._inference_function.call(\r\n-> 1746           ctx, args, cancellation_manager=cancellation_manager))\r\n   1747     forward_backward = self._select_forward_and_backward_functions(\r\n   1748         args,\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    596               inputs=args,\r\n    597               attrs=attrs,\r\n--> 598               ctx=ctx)\r\n    599         else:\r\n    600           outputs = execute.execute_with_cancellation(\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     72       raise core._SymbolicException(\r\n     73           \"Inputs to eager execution function cannot be Keras symbolic \"\r\n---> 74           \"tensors, but found {}\".format(keras_symbolic_tensors))\r\n     75     raise e\r\n     76   # pylint: enable=protected-access\r\n\r\n_SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'lambda/Const:0' shape=(3,) dtype=float32>]\r\n```\r\n\r\nIf instead, I use the Keras `preprocess_input` like this, it works\r\n```\r\nimg_adjust_layer = L.Lambda(applications.resnet50.preprocess_input, input_shape=input_shape)\r\n```\r\n\r\nAny idea of what I might be missing?","closed_by":null,"reactions":{"url":"https://api.github.com/repos/qubvel/efficientnet/issues/131/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/qubvel/efficientnet/issues/131/timeline","performed_via_github_app":null,"state_reason":null}