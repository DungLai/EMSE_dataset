{"url":"https://api.github.com/repos/sniklaus/pytorch-pwc/issues/55","repository_url":"https://api.github.com/repos/sniklaus/pytorch-pwc","labels_url":"https://api.github.com/repos/sniklaus/pytorch-pwc/issues/55/labels{/name}","comments_url":"https://api.github.com/repos/sniklaus/pytorch-pwc/issues/55/comments","events_url":"https://api.github.com/repos/sniklaus/pytorch-pwc/issues/55/events","html_url":"https://github.com/sniklaus/pytorch-pwc/issues/55","id":1049128954,"node_id":"I_kwDOCGqm2c4-iG_6","number":55,"title":"Receiving a random error, CUDA_ERROR_ILLEGAL_ADDRESS","user":{"login":"Etienne66","id":52262160,"node_id":"MDQ6VXNlcjUyMjYyMTYw","avatar_url":"https://avatars.githubusercontent.com/u/52262160?v=4","gravatar_id":"","url":"https://api.github.com/users/Etienne66","html_url":"https://github.com/Etienne66","followers_url":"https://api.github.com/users/Etienne66/followers","following_url":"https://api.github.com/users/Etienne66/following{/other_user}","gists_url":"https://api.github.com/users/Etienne66/gists{/gist_id}","starred_url":"https://api.github.com/users/Etienne66/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Etienne66/subscriptions","organizations_url":"https://api.github.com/users/Etienne66/orgs","repos_url":"https://api.github.com/users/Etienne66/repos","events_url":"https://api.github.com/users/Etienne66/events{/privacy}","received_events_url":"https://api.github.com/users/Etienne66/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":9,"created_at":"2021-11-09T21:15:27Z","updated_at":"2022-04-19T20:54:45Z","closed_at":"2022-02-17T21:46:30Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Let me start by saying that I have already resolved this but it was related to your commit 85b59fa.\r\n\r\nThe original error which repeated multiple times:\r\n```python\r\nException ignored in: 'cupy.cuda.function.Module.__dealloc__'\r\nTraceback (most recent call last):\r\n  File \"cupy_backends\\cuda\\api\\driver.pyx\", line 260, in cupy_backends.cuda.api.driver.moduleUnload\r\n  File \"cupy_backends\\cuda\\api\\driver.pyx\", line 125, in cupy_backends.cuda.api.driver.check_status\r\ncupy_backends.cuda.api.driver.CUDADriverError: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n```\r\nI copied your move of the multiply by 20.0 to the `return` of the `forward` in the `Network` class. However I had also implemented `torch.utils.checkpoint`. I had missed that there was a layer in the `return` statement and it seems having the other layers checkpointed caused a random  memory error once that was manipulated by the multiplication.\r\n\r\nMy resolution was to put the multiply by 20.0 back where it was and then I moved the `self.netRefiner(objEstimate['tenFeat'])` out of the return and placed on the line above so that I could checkpoint it. This freed up even more GPU memory than I had before which only allowed a patch size of 576.\r\n\r\nIt took me 3 weeks to figure this out because it was taking a couple of days to run an epoch and sometimes the error didn't popup until it was almost done. It was very random. Plus I wasn't sure if it was this change or one of the updates I had done. Plus I just couldn't fathom that this could have caused a memory error. I still find it hard to believe but this was the last thing that I changed and it had worked fine for several epochs with checkpointing before I made that change.\r\n\r\nIn [my repository](https://github.com/Etienne66/CDVD-TSP/tree/MM-SSIM_Loss) your `run.py` is  under `code/model/flow_pwc.py` which I forked from [csbhr/CDVD-TSP](https://github.com/csbhr/CDVD-TSP)\r\n\r\nI'm using checkpoint so that I can increase the patch size to 720 pixels. Otherwise I can only run it at 256 pixels and I have a feeling in particular for the flow calculations from your model need a higher resolution. I'm not saving your model separately but I might update the code to do that in the future because it is being trained and I have a lot more frame pairs that are being used for training. Not sure if it will do any better of a job of training the `pytorch-PWC` model but I am curious what the differences would be in the end result. Plus a lot of the frames contain blur so I'm sure that makes the job of calculating flow much more difficult. In total I am using 29,844 frames for my training with random flip vertical and horizontal as well as a random 90 degree rotation. Most of the frames are 1280x720 but all are cropped to 720 with the cropped position being random.\r\n\r\nThanks for all of your work @sniklaus. After learning more about all of the work you have done in this model I have to admit that I am very impressed with your work as well as the original authors.","closed_by":{"login":"sniklaus","id":1238034,"node_id":"MDQ6VXNlcjEyMzgwMzQ=","avatar_url":"https://avatars.githubusercontent.com/u/1238034?v=4","gravatar_id":"","url":"https://api.github.com/users/sniklaus","html_url":"https://github.com/sniklaus","followers_url":"https://api.github.com/users/sniklaus/followers","following_url":"https://api.github.com/users/sniklaus/following{/other_user}","gists_url":"https://api.github.com/users/sniklaus/gists{/gist_id}","starred_url":"https://api.github.com/users/sniklaus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sniklaus/subscriptions","organizations_url":"https://api.github.com/users/sniklaus/orgs","repos_url":"https://api.github.com/users/sniklaus/repos","events_url":"https://api.github.com/users/sniklaus/events{/privacy}","received_events_url":"https://api.github.com/users/sniklaus/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/sniklaus/pytorch-pwc/issues/55/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/sniklaus/pytorch-pwc/issues/55/timeline","performed_via_github_app":null,"state_reason":"completed"}