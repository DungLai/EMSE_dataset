{"url":"https://api.github.com/repos/theislab/diffxpy/issues/217","repository_url":"https://api.github.com/repos/theislab/diffxpy","labels_url":"https://api.github.com/repos/theislab/diffxpy/issues/217/labels{/name}","comments_url":"https://api.github.com/repos/theislab/diffxpy/issues/217/comments","events_url":"https://api.github.com/repos/theislab/diffxpy/issues/217/events","html_url":"https://github.com/theislab/diffxpy/issues/217","id":1209885969,"node_id":"I_kwDOCFAGUM5IHWUR","number":217,"title":"RuntimeError: Cannot convert a sparse array to dense automatically. To manually densify, use the todense method.","user":{"login":"SimaDubnov","id":76960862,"node_id":"MDQ6VXNlcjc2OTYwODYy","avatar_url":"https://avatars.githubusercontent.com/u/76960862?v=4","gravatar_id":"","url":"https://api.github.com/users/SimaDubnov","html_url":"https://github.com/SimaDubnov","followers_url":"https://api.github.com/users/SimaDubnov/followers","following_url":"https://api.github.com/users/SimaDubnov/following{/other_user}","gists_url":"https://api.github.com/users/SimaDubnov/gists{/gist_id}","starred_url":"https://api.github.com/users/SimaDubnov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SimaDubnov/subscriptions","organizations_url":"https://api.github.com/users/SimaDubnov/orgs","repos_url":"https://api.github.com/users/SimaDubnov/repos","events_url":"https://api.github.com/users/SimaDubnov/events{/privacy}","received_events_url":"https://api.github.com/users/SimaDubnov/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2022-04-20T15:55:39Z","updated_at":"2022-11-28T16:49:48Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi!\r\nI get this error when running a very simple wald test. I saw that you solved the same problem two years ago but didn't publish how exactly. Could you please guide me here too?\r\n\r\nHere is the whole error:\r\n\r\nRuntimeError                              Traceback (most recent call last)\r\nInput In [26], in <cell line: 1>()\r\n----> 1 test=de.test.wald(data=data_Ast, formula_loc='~1 + AD', factor_loc_totest='AD')\r\n\r\nFile ~/.conda/envs/scRNAseq/lib/python3.10/site-packages/diffxpy/testing/tests.py:717, in wald(data, factor_loc_totest, coef_to_test, formula_loc, formula_scale, as_numeric, init_a, init_b, gene_names, sample_description, dmat_loc, dmat_scale, constraints_loc, constraints_scale, noise_model, size_factors, batch_size, backend, train_args, training_strategy, quick_scale, dtype, **kwargs)\r\n    714 col_indices = np.array([np.where(constraints_loc_temp[x, :] == 1)[0][0] for x in col_indices])\r\n    716 # Fit model.\r\n--> 717 model = _fit(\r\n    718     noise_model=noise_model,\r\n    719     data=data,\r\n    720     design_loc=design_loc,\r\n    721     design_scale=design_scale,\r\n    722     design_loc_names=design_loc_names,\r\n    723     design_scale_names=design_scale_names,\r\n    724     constraints_loc=constraints_loc,\r\n    725     constraints_scale=constraints_scale,\r\n    726     init_a=init_a,\r\n    727     init_b=init_b,\r\n    728     gene_names=gene_names,\r\n    729     size_factors=size_factors,\r\n    730     batch_size=batch_size,\r\n    731     backend=backend,\r\n    732     train_args=train_args,\r\n    733     training_strategy=training_strategy,\r\n    734     quick_scale=quick_scale,\r\n    735     dtype=dtype,\r\n    736     **kwargs,\r\n    737 )\r\n    739 # Prepare differential expression test.\r\n    740 de_test = DifferentialExpressionTestWald(\r\n    741     model_estim=model,\r\n    742     col_indices=col_indices,\r\n    743     noise_model=noise_model,\r\n    744     sample_description=sample_description\r\n    745 )\r\n\r\nFile ~/.conda/envs/scRNAseq/lib/python3.10/site-packages/diffxpy/testing/tests.py:222, in _fit(noise_model, data, design_loc, design_scale, design_loc_names, design_scale_names, constraints_loc, constraints_scale, init_model, init_a, init_b, gene_names, size_factors, batch_size, backend, training_strategy, quick_scale, train_args, close_session, dtype)\r\n    219 else:\r\n    220     raise ValueError('backend=\"%s\" not recognized.' % backend)\r\n--> 222 estim = Estimator(\r\n    223     input_data=input_data,\r\n    224     init_a=init_a,\r\n    225     init_b=init_b,\r\n    226     dtype=dtype,\r\n    227     **constructor_args\r\n    228 )\r\n    229 estim.initialize()\r\n    231 # Assemble backend specific key word arguments to training function:\r\n\r\nFile ~/.conda/envs/scRNAseq/lib/python3.10/site-packages/batchglm/train/numpy/glm_nb/estimator.py:59, in Estimator.__init__(self, input_data, init_a, init_b, batch_size, quick_scale, dtype, **kwargs)\r\n     19 def __init__(\r\n     20         self,\r\n     21         input_data: InputDataGLM,\r\n   (...)\r\n     27         **kwargs\r\n     28 ):\r\n     29     \"\"\"\r\n     30     Performs initialisation and creates a new estimator.\r\n     31 \r\n   (...)\r\n     57     :param dtype: Numerical precision.\r\n     58     \"\"\"\r\n---> 59     init_a, init_b, train_loc, train_scale = init_par(\r\n     60         input_data=input_data,\r\n     61         init_a=init_a,\r\n     62         init_b=init_b,\r\n     63         init_model=None\r\n     64     )\r\n     65     self._train_loc = train_loc\r\n     66     self._train_scale = train_scale\r\n\r\nFile ~/.conda/envs/scRNAseq/lib/python3.10/site-packages/batchglm/models/glm_nb/utils.py:120, in init_par(input_data, init_a, init_b, init_model)\r\n    117     init_a = \"standard\" if not one_hot else \"closed_form\"\r\n    119 if init_a.lower() == \"closed_form\":\r\n--> 120     groupwise_means, init_a, rmsd_a = closedform_nb_glm_logmu(\r\n    121         x=input_data.x,\r\n    122         design_loc=input_data.design_loc,\r\n    123         constraints_loc=input_data.constraints_loc,\r\n    124         size_factors=input_data.size_factors,\r\n    125         link_fn=lambda mu: np.log(mu+np.nextafter(0, 1, dtype=mu.dtype))\r\n    126     )\r\n    128     # train mu, if the closed-form solution is inaccurate\r\n    129     train_loc = not (np.all(np.abs(rmsd_a) < 1e-20) or rmsd_a.size == 0)\r\n\r\nFile ~/.conda/envs/scRNAseq/lib/python3.10/site-packages/batchglm/models/glm_nb/utils.py:30, in closedform_nb_glm_logmu(x, design_loc, constraints_loc, size_factors, link_fn, inv_link_fn)\r\n     10 def closedform_nb_glm_logmu(\r\n     11         x: Union[np.ndarray, scipy.sparse.csr_matrix],\r\n     12         design_loc: np.ndarray,\r\n   (...)\r\n     16         inv_link_fn=np.exp\r\n     17 ):\r\n     18     r\"\"\"\r\n     19     Calculates a closed-form solution for the `mu` parameters of negative-binomial GLMs.\r\n     20 \r\n   (...)\r\n     28     :return: tuple: (groupwise_means, mu, rmsd)\r\n     29     \"\"\"\r\n---> 30     return closedform_glm_mean(\r\n     31         x=x,\r\n     32         dmat=design_loc,\r\n     33         constraints=constraints_loc,\r\n     34         size_factors=size_factors,\r\n     35         link_fn=link_fn,\r\n     36         inv_link_fn=inv_link_fn\r\n     37     )\r\n\r\nFile ~/.conda/envs/scRNAseq/lib/python3.10/site-packages/batchglm/models/base_glm/utils.py:118, in closedform_glm_mean(x, dmat, constraints, size_factors, link_fn, inv_link_fn)\r\n    115     else:\r\n    116         return link_fn(groupwise_means)\r\n--> 118 linker_groupwise_means, mu, rmsd, rank, s = groupwise_solve_lm(\r\n    119     dmat=dmat,\r\n    120     apply_fun=apply_fun,\r\n    121     constraints=constraints\r\n    122 )\r\n    123 if inv_link_fn is not None:\r\n    124     return inv_link_fn(linker_groupwise_means), mu, rmsd\r\n\r\nFile ~/.conda/envs/scRNAseq/lib/python3.10/site-packages/batchglm/utils/linalg.py:93, in groupwise_solve_lm(dmat, apply_fun, constraints)\r\n     89     logger.error(\"model is not full rank!\")\r\n     91 # Get group-wise means in linker space based on group assignments\r\n     92 # based on unique rows of design matrix:\r\n---> 93 params = apply_fun(inverse_idx)\r\n     95 # Use least-squares solver to compute model parameterization\r\n     96 # accounting for dependent parameters, ie. degrees of freedom\r\n     97 # of the model which appear as groups in the design matrix\r\n   (...)\r\n    100 # <X, <theta, H> = means -> <X, theta>, H> = means -> lstsqs for theta\r\n    101 # (This is faster and more accurate than using matrix inversion.)\r\n    102 logger.debug(\" ** Solve lstsq problem\")\r\n\r\nFile ~/.conda/envs/scRNAseq/lib/python3.10/site-packages/batchglm/models/base_glm/utils.py:109, in closedform_glm_mean.<locals>.apply_fun(grouping)\r\n    108 def apply_fun(grouping):\r\n--> 109     groupwise_means = np.asarray(np.vstack([\r\n    110         np.mean(x[np.where(grouping == g)[0], :], axis=0)\r\n    111         for g in np.unique(grouping)\r\n    112     ]))\r\n    113     if link_fn is None:\r\n    114         return groupwise_means\r\n\r\nFile ~/.conda/envs/scRNAseq/lib/python3.10/site-packages/dask/array/core.py:1642, in Array.__array__(self, dtype, **kwargs)\r\n   1640     x = x.astype(dtype)\r\n   1641 if not isinstance(x, np.ndarray):\r\n-> 1642     x = np.array(x)\r\n   1643 return x\r\n\r\nFile ~/.conda/envs/scRNAseq/lib/python3.10/site-packages/sparse/_sparse_array.py:229, in SparseArray.__array__(self, *args, **kwargs)\r\n    226 from ._settings import AUTO_DENSIFY\r\n    228 if not AUTO_DENSIFY:\r\n--> 229     raise RuntimeError(\r\n    230         \"Cannot convert a sparse array to dense automatically. \"\r\n    231         \"To manually densify, use the todense method.\"\r\n    232     )\r\n    234 return np.asarray(self.todense(), *args, **kwargs)\r\n\r\nRuntimeError: Cannot convert a sparse array to dense automatically. To manually densify, use the todense method.\r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/theislab/diffxpy/issues/217/reactions","total_count":4,"+1":4,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/theislab/diffxpy/issues/217/timeline","performed_via_github_app":null,"state_reason":null}