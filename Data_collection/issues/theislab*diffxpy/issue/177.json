{"url":"https://api.github.com/repos/theislab/diffxpy/issues/177","repository_url":"https://api.github.com/repos/theislab/diffxpy","labels_url":"https://api.github.com/repos/theislab/diffxpy/issues/177/labels{/name}","comments_url":"https://api.github.com/repos/theislab/diffxpy/issues/177/comments","events_url":"https://api.github.com/repos/theislab/diffxpy/issues/177/events","html_url":"https://github.com/theislab/diffxpy/issues/177","id":682199917,"node_id":"MDU6SXNzdWU2ODIxOTk5MTc=","number":177,"title":"Error while running de.test.pairwise","user":{"login":"leonardosepulveda","id":26014718,"node_id":"MDQ6VXNlcjI2MDE0NzE4","avatar_url":"https://avatars.githubusercontent.com/u/26014718?v=4","gravatar_id":"","url":"https://api.github.com/users/leonardosepulveda","html_url":"https://github.com/leonardosepulveda","followers_url":"https://api.github.com/users/leonardosepulveda/followers","following_url":"https://api.github.com/users/leonardosepulveda/following{/other_user}","gists_url":"https://api.github.com/users/leonardosepulveda/gists{/gist_id}","starred_url":"https://api.github.com/users/leonardosepulveda/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leonardosepulveda/subscriptions","organizations_url":"https://api.github.com/users/leonardosepulveda/orgs","repos_url":"https://api.github.com/users/leonardosepulveda/repos","events_url":"https://api.github.com/users/leonardosepulveda/events{/privacy}","received_events_url":"https://api.github.com/users/leonardosepulveda/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-08-19T21:41:42Z","updated_at":"2020-08-19T22:33:14Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi, \r\n\r\nI downloaded diffxpy and batchglm as instructed. I tried to run the pairwise tutorial in https://nbviewer.jupyter.org/github/theislab/diffxpy_tutorials/blob/master/diffxpy_tutorials/test/multiple_tests_per_gene.ipynbnb\r\nWhen I run the following code:\r\n\r\n    test = de.test.pairwise(\r\n        data=exampleData,\r\n        grouping=\"batch\",\r\n        test=\"z-test\",\r\n        lazy=False,\r\n        noise_model=\"nb\"\r\n    )\r\n\r\n\r\nI get the following error:\r\n\r\n    ValueError                                Traceback (most recent call last)\r\n    <ipython-input-28-59b32f8f075b> in <module>\r\n          4     test=\"z-test\",\r\n          5     lazy=False,\r\n    ----> 6     noise_model=\"nb\"\r\n          7 )\r\n\r\n    ~/Software/diffxpy/diffxpy/testing/tests.py in pairwise(data, grouping, as_numeric, test, lazy, gene_names, sample_description, noise_model, size_factors, batch_size, backend, train_args, training_strategy, is_sig_zerovar, quick_scale, dtype, pval_correction, keep_full_test_objs, **kwargs)\r\n       1251             quick_scale=quick_scale,\r\n       1252             dtype=dtype,\r\n    -> 1253             **kwargs\r\n       1254         )\r\n       1255 \r\n    \r\n    ~/Software/diffxpy/diffxpy/testing/tests.py in _fit(noise_model, data, design_loc, design_scale, design_loc_names, design_scale_names, constraints_loc, constraints_scale, init_model, init_a, init_b, gene_names, size_factors, batch_size, backend, training_strategy, quick_scale, train_args, close_session, type)\r\n        188         chunk_size_genes=chunk_size_genes,\r\n        189         as_dask=backend.lower() in [\"numpy\"],\r\n    --> 190         cast_dtype=dtype\r\n        191     )\r\n        192 \r\n\r\n    ~/Software/batchglm/batchglm/models/base_glm/input.py in __init__(self, data, design_loc, design_loc_names, design_scale, design_scale_names, constraints_loc, constraints_scale, size_factors, observation_names, feature_names, chunk_size_cells, chunk_size_genes, as_dask, cast_dtype)\r\n         94         design_loc, design_loc_names = parse_design(\r\n         95             design_matrix=design_loc,\r\n    ---> 96             param_names=design_loc_names\r\n         97         )\r\n         98         design_scale, design_scale_names = parse_design(\r\n\r\n    ~/Software/batchglm/batchglm/models/base_glm/utils.py in parse_design(design_matrix, param_names)\r\n         39         params = None\r\n         40     else:\r\n    ---> 41         raise ValueError(\"type %s not recognized\" % type(design_matrix))\r\n         42 \r\n         43     if param_names is not None:\r\n\r\n    ValueError: type <class 'tuple'> not recognized\r\n\r\n\r\nFrom some of the other questions, I gather that Wald tests is better supported at the moment.  When I try\r\n\r\n    test = de.test.pairwise(\r\n        data=exampleData,\r\n        grouping=\"batch\",\r\n        test=\"wald\",\r\n        lazy=False,\r\n        noise_model=\"nb\"\r\n    )\r\n\r\nI get output but now I get a different error:\r\n\r\n    training location model: False\r\n    training scale model: True\r\n    iter   0: ll=747800.631759\r\n    iter   1: ll=747800.631759, converged: 0.00% (loc: 100.00%, scale update: False), in 0.00sec\r\n    iter   2: ll=736972.523377, converged: 19.00% (loc: 19.00%, scale update: True), in 0.50sec\r\n    iter   3: ll=736972.523377, converged: 19.00% (loc: 100.00%, scale update: False), in 0.00sec\r\n    iter   4: ll=736972.519056, converged: 38.00% (loc: 38.00%, scale update: True), in 0.46sec\r\n    iter   5: ll=736972.519056, converged: 38.00% (loc: 100.00%, scale update: False), in 0.00sec\r\n    iter   6: ll=735864.762600, converged: 47.00% (loc: 47.00%, scale update: True), in 0.35sec\r\n    iter   7: ll=735864.762600, converged: 47.00% (loc: 100.00%, scale update: False), in 0.00sec\r\n    iter   8: ll=735864.753847, converged: 55.00% (loc: 55.00%, scale update: True), in 0.35sec\r\n    iter   9: ll=735864.753847, converged: 55.00% (loc: 100.00%, scale update: False), in 0.00sec\r\n    iter  10: ll=733713.706344, converged: 72.00% (loc: 72.00%, scale update: True), in 0.34sec\r\n    iter  11: ll=733713.706344, converged: 72.00% (loc: 100.00%, scale update: False), in 0.00sec\r\n    iter  12: ll=733713.706046, converged: 84.00% (loc: 84.00%, scale update: True), in 0.34sec\r\n    iter  13: ll=733713.706046, converged: 84.00% (loc: 100.00%, scale update: False), in 0.00sec\r\n    iter  14: ll=733523.994672, converged: 88.00% (loc: 88.00%, scale update: True), in 0.23sec\r\n    iter  15: ll=733523.994672, converged: 88.00% (loc: 100.00%, scale update: False), in 0.00sec\r\n    iter  16: ll=733523.994641, converged: 94.00% (loc: 94.00%, scale update: True), in 0.22sec\r\n    iter  17: ll=733523.994641, converged: 94.00% (loc: 100.00%, scale update: False), in 0.00sec\r\n    iter  18: ll=733515.860695, converged: 95.00% (loc: 95.00%, scale update: True), in 0.22sec\r\n    iter  19: ll=733515.860695, converged: 95.00% (loc: 100.00%, scale update: False), in 0.00sec\r\n    iter  20: ll=733515.860695, converged: 100.00% (loc: 100.00%, scale update: True), in 0.21sec\r\n    training location model: False\r\n    training scale model: True\r\n    iter   0: ll=750874.499417\r\n    iter   1: ll=750874.499417, converged: 0.00% (loc: 100.00%, scale update: False), in 0.00sec\r\n    iter   2: ll=750870.272187, converged: 96.00% (loc: 96.00%, scale update: True), in 0.46sec\r\n    iter   3: ll=750870.272187, converged: 96.00% (loc: 100.00%, scale update: False), in 0.00sec\r\n    iter   4: ll=750870.272186, converged: 99.00% (loc: 99.00%, scale update: True), in 0.23sec\r\n    iter   5: ll=750870.272186, converged: 99.00% (loc: 100.00%, scale update: False), in 0.00sec\r\n    Fitting dispersion models: 0.00% in 0.00sec\r\n    ---------------------------------------------------------------------------\r\n    ValueError                                Traceback (most recent call last)\r\n    <ipython-input-29-4d6b6f291ef9> in <module>\r\n          4     test=\"wald\",\r\n          5     lazy=False,\r\n    ----> 6     noise_model=\"nb\"\r\n          7 )\r\n\r\n    ~/Software/diffxpy/diffxpy/testing/tests.py in pairwise(data, grouping, as_numeric, test, lazy, gene_names, sample_description, noise_model, size_factors, batch_size, backend, train_args, training_strategy, is_sig_zerovar, quick_scale, dtype, pval_correction, keep_full_test_objs, **kwargs)\r\n       1308                     is_sig_zerovar=is_sig_zerovar,\r\n       1309                     dtype=dtype,\r\n    -> 1310                     **kwargs\r\n       1311                 )\r\n       1312                 pvals[i, j] = de_test_temp.pval\r\n\r\n    ~/Software/diffxpy/diffxpy/testing/tests.py in two_sample(data, grouping, as_numeric, test, gene_names, sample_description, noise_model, size_factors, batch_size, backend, train_args, training_strategy, is_sig_zerovar, quick_scale, dtype, **kwargs)\r\n       1045             quick_scale=quick_scale,\r\n       1046             dtype=dtype,\r\n    -> 1047             **kwargs\r\n       1048         )\r\n       1049     elif test.lower() == 'lrt':\r\n\r\n    ~/Software/diffxpy/diffxpy/testing/tests.py in wald(data, factor_loc_totest, coef_to_test, formula_loc, formula_scale, as_numeric, init_a, init_b, gene_names, sample_description, dmat_loc, dmat_scale, constraints_loc, constraints_scale, noise_model, size_factors, batch_size, backend, train_args, training_strategy, quick_scale, dtype, **kwargs)\r\n        734         quick_scale=quick_scale,\r\n        735         dtype=dtype,\r\n    --> 736         **kwargs,\r\n        737     )\r\n        738 \r\n\r\n    ~/Software/diffxpy/diffxpy/testing/tests.py in _fit(noise_model, data, design_loc, design_scale, design_loc_names, design_scale_names, constraints_loc, constraints_scale, init_model, init_a, init_b, gene_names, size_factors, batch_size, backend, training_strategy, quick_scale, train_args, close_session, dtype)\r\n        242     estim.train_sequence(\r\n        243         training_strategy=training_strategy,\r\n    --> 244         **train_args\r\n        245     )\r\n        246 \r\n\r\n    ~/Software/batchglm/batchglm/models/base/estimator.py in train_sequence(self, training_strategy, **kwargs)\r\n        122                         (x, str(d[x]), str(kwargs[x]))\r\n        123                     )\r\n    --> 124             self.train(**d, **kwargs)\r\n        125             logger.debug(\"Training sequence #%d complete\", idx + 1)\r\n        126 \r\n\r\n    ~/Software/batchglm/batchglm/train/numpy/base_glm/estimator.py in train(self, max_steps, method_b, update_b_freq, ftol_b, lr_b, max_iter_b, nproc, **kwargs)\r\n        110                         lr=lr_b,\r\n        111                         max_iter=max_iter_b,\r\n    --> 112                         nproc=nproc\r\n        113                     )\r\n        114                     # Perform trial update.\r\n\r\n    ~/Software/batchglm/batchglm/train/numpy/base_glm/estimator.py in b_step(self, idx_update, method, ftol, lr, max_iter, nproc)\r\n        349                 ftol=ftol,\r\n        350                 max_iter=max_iter,\r\n    --> 351                 nproc=nproc\r\n        352             )\r\n        353 \r\n\r\n    ~/Software/batchglm/batchglm/train/numpy/base_glm/estimator.py in _b_step_loop(self, idx_update, method, max_iter, ftol, nproc)\r\n        521                         tol=ftol,\r\n        522                         brack=(lb_bracket, ub_bracket),\r\n    --> 523                         full_output=False\r\n        524                     )\r\n        525                 else:\r\n\r\n    ValueError: assignment destination is read-only\r\n\r\nLooking online it seems that this may be an error associated with some numpy versions. I tried updating numpy but that did not make a difference. Any ideas of what could be the issue?","closed_by":null,"reactions":{"url":"https://api.github.com/repos/theislab/diffxpy/issues/177/reactions","total_count":5,"+1":5,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/theislab/diffxpy/issues/177/timeline","performed_via_github_app":null,"state_reason":null}