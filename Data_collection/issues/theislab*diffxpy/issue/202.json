{"url":"https://api.github.com/repos/theislab/diffxpy/issues/202","repository_url":"https://api.github.com/repos/theislab/diffxpy","labels_url":"https://api.github.com/repos/theislab/diffxpy/issues/202/labels{/name}","comments_url":"https://api.github.com/repos/theislab/diffxpy/issues/202/comments","events_url":"https://api.github.com/repos/theislab/diffxpy/issues/202/events","html_url":"https://github.com/theislab/diffxpy/issues/202","id":936208224,"node_id":"MDU6SXNzdWU5MzYyMDgyMjQ=","number":202,"title":"TF1 InvalidArgumentError: Rank of input must be no greater than rank of output shape ","user":{"login":"Hrovatin","id":47607471,"node_id":"MDQ6VXNlcjQ3NjA3NDcx","avatar_url":"https://avatars.githubusercontent.com/u/47607471?v=4","gravatar_id":"","url":"https://api.github.com/users/Hrovatin","html_url":"https://github.com/Hrovatin","followers_url":"https://api.github.com/users/Hrovatin/followers","following_url":"https://api.github.com/users/Hrovatin/following{/other_user}","gists_url":"https://api.github.com/users/Hrovatin/gists{/gist_id}","starred_url":"https://api.github.com/users/Hrovatin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Hrovatin/subscriptions","organizations_url":"https://api.github.com/users/Hrovatin/orgs","repos_url":"https://api.github.com/users/Hrovatin/repos","events_url":"https://api.github.com/users/Hrovatin/events{/privacy}","received_events_url":"https://api.github.com/users/Hrovatin/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-03T08:48:17Z","updated_at":"2021-07-03T08:48:17Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I tried to run diffxpy with tf1 and normal noise. However, I get the below error.\r\n```\r\nimport diffxpy.api as de\r\nfrom anndata import AnnData\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n# Mock data\r\nadata=AnnData(np.random.randn(100,10),obs=pd.DataFrame(np.random.randn(100,1),columns=['a']))\r\n\r\n# DE test\r\nresult=de.test.continuous_1d(\r\n            data=adata,\r\n            continuous='a',\r\n            factor_loc_totest='a',\r\n            formula_loc='~1+a',\r\n            formula_scale='~1',\r\n            df = 3,\r\n            test = 'wald',\r\n            sample_description=adata.obs,\r\n            size_factors=abs(adata.X.sum(axis=1)),\r\n            backend='tf1',\r\n            noise_model='norm'\r\n    )\r\n\r\nWARNING:tensorflow:\r\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\n  * https://github.com/tensorflow/io (for I/O related ops)\r\nIf you depend on functionality not listed there, please file an issue.\r\n\r\n/home/icb/karin.hrovatin/miniconda3/envs/diffxpy_tf1/lib/python3.7/site-packages/batchglm/utils/linalg.py:107: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\r\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\r\n  params\r\n\r\nWARNING:tensorflow:Entity <bound method ReducableTensorsGLMALL.assemble_tensors of <batchglm.train.tf1.glm_norm.reducible_tensors.ReducibleTensors object at 0x7fcfc54937f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: LIVE_VARS_IN\r\nWARNING: Entity <bound method ReducableTensorsGLMALL.assemble_tensors of <batchglm.train.tf1.glm_norm.reducible_tensors.ReducibleTensors object at 0x7fcfc54937f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: LIVE_VARS_IN\r\nWARNING:tensorflow:Entity <bound method ReducableTensorsGLMALL.assemble_tensors of <batchglm.train.tf1.glm_norm.reducible_tensors.ReducibleTensors object at 0x7fcfc54e3b38>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: LIVE_VARS_IN\r\nWARNING: Entity <bound method ReducableTensorsGLMALL.assemble_tensors of <batchglm.train.tf1.glm_norm.reducible_tensors.ReducibleTensors object at 0x7fcfc54e3b38>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: LIVE_VARS_IN\r\nWARNING:tensorflow:Entity <bound method ReducableTensorsGLMALL.assemble_tensors of <batchglm.train.tf1.glm_norm.reducible_tensors.ReducibleTensors object at 0x7fcfc53d3710>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: LIVE_VARS_IN\r\nWARNING: Entity <bound method ReducableTensorsGLMALL.assemble_tensors of <batchglm.train.tf1.glm_norm.reducible_tensors.ReducibleTensors object at 0x7fcfc53d3710>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: LIVE_VARS_IN\r\nWARNING:tensorflow:Entity <bound method ReducableTensorsGLMALL.assemble_tensors of <batchglm.train.tf1.glm_norm.reducible_tensors.ReducibleTensors object at 0x7fcfc5353f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: LIVE_VARS_IN\r\nWARNING: Entity <bound method ReducableTensorsGLMALL.assemble_tensors of <batchglm.train.tf1.glm_norm.reducible_tensors.ReducibleTensors object at 0x7fcfc5353f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: LIVE_VARS_IN\r\nWARNING:tensorflow:From /home/icb/karin.hrovatin/miniconda3/envs/diffxpy_tf1/lib/python3.7/site-packages/batchglm/train/tf1/base_glm/estimator_graph.py:907: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\n\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n~/miniconda3/envs/diffxpy_tf1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py in _do_call(self, fn, *args)\r\n   1364     try:\r\n-> 1365       return fn(*args)\r\n   1366     except errors.OpError as e:\r\n\r\n~/miniconda3/envs/diffxpy_tf1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1349       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\r\n-> 1350                                       target_list, run_metadata)\r\n   1351 \r\n\r\n~/miniconda3/envs/diffxpy_tf1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1442                                             fetch_list, target_list,\r\n-> 1443                                             run_metadata)\r\n   1444 \r\n\r\nInvalidArgumentError: {{function_node __inference_Dataset_map_fetch_fn_372}} Rank of input (3) must be no greater than rank of output shape (2).\r\n\t [[{{node BroadcastTo}}]]\r\n\t [[full_data/reducible_tensors_eval_ll_jac/ReduceDataset]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-4-16f8030636fd> in <module>\r\n     10             size_factors=abs(adata.X.sum(axis=1)),\r\n     11             backend='tf1',\r\n---> 12             noise_model='norm'\r\n     13     )\r\n\r\n~/miniconda3/envs/diffxpy_tf1/lib/python3.7/site-packages/diffxpy/testing/tests.py in continuous_1d(data, continuous, factor_loc_totest, formula_loc, formula_scale, df, spline_basis, as_numeric, test, init_a, init_b, gene_names, sample_description, constraints_loc, constraints_scale, noise_model, size_factors, batch_size, backend, train_args, training_strategy, quick_scale, dtype, **kwargs)\r\n   2308             quick_scale=quick_scale,\r\n   2309             dtype=dtype,\r\n-> 2310             **kwargs\r\n   2311         )\r\n   2312         de_test = DifferentialExpressionTestWaldCont(\r\n\r\n~/miniconda3/envs/diffxpy_tf1/lib/python3.7/site-packages/diffxpy/testing/tests.py in wald(data, factor_loc_totest, coef_to_test, formula_loc, formula_scale, as_numeric, init_a, init_b, gene_names, sample_description, dmat_loc, dmat_scale, constraints_loc, constraints_scale, noise_model, size_factors, batch_size, backend, train_args, training_strategy, quick_scale, dtype, **kwargs)\r\n    738         quick_scale=quick_scale,\r\n    739         dtype=dtype,\r\n--> 740         **kwargs,\r\n    741     )\r\n    742 \r\n\r\n~/miniconda3/envs/diffxpy_tf1/lib/python3.7/site-packages/diffxpy/testing/tests.py in _fit(noise_model, data, design_loc, design_scale, design_loc_names, design_scale_names, constraints_loc, constraints_scale, init_model, init_a, init_b, gene_names, size_factors, batch_size, backend, training_strategy, quick_scale, train_args, close_session, dtype)\r\n    244     estim.train_sequence(\r\n    245         training_strategy=training_strategy,\r\n--> 246         **train_args\r\n    247     )\r\n    248 \r\n\r\n~/miniconda3/envs/diffxpy_tf1/lib/python3.7/site-packages/batchglm/models/base/estimator.py in train_sequence(self, training_strategy, **kwargs)\r\n    122                         (x, str(d[x]), str(kwargs[x]))\r\n    123                     )\r\n--> 124             self.train(**d, **kwargs)\r\n    125             logger.debug(\"Training sequence #%d complete\", idx + 1)\r\n    126 \r\n\r\n~/miniconda3/envs/diffxpy_tf1/lib/python3.7/site-packages/batchglm/train/tf1/base_glm_all/estimator.py in train(self, learning_rate, convergence_criteria, stopping_criteria, train_loc, train_scale, use_batching, optim_algo, *args, **kwargs)\r\n    315                 require_fim=require_fim,\r\n    316                 is_batched=use_batching,\r\n--> 317                 **kwargs\r\n    318             )\r\n    319 \r\n\r\n~/miniconda3/envs/diffxpy_tf1/lib/python3.7/site-packages/batchglm/train/tf1/base/estimator.py in _train(self, learning_rate, feed_dict, convergence_criteria, stopping_criteria, train_op, trustregion_mode, require_hessian, require_fim, is_batched, *args, **kwargs)\r\n    158                  self.model.model_vars.convergence_update),\r\n    159                 feed_dict={self.model.model_vars.convergence_status:\r\n--> 160                                np.repeat(False, repeats=self.model.model_vars.converged.shape[0])\r\n    161                            }\r\n    162             )\r\n\r\n~/miniconda3/envs/diffxpy_tf1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    954     try:\r\n    955       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 956                          run_metadata_ptr)\r\n    957       if run_metadata:\r\n    958         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n~/miniconda3/envs/diffxpy_tf1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1178     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1179       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1180                              feed_dict_tensor, options, run_metadata)\r\n   1181     else:\r\n   1182       results = []\r\n\r\n~/miniconda3/envs/diffxpy_tf1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1357     if handle is None:\r\n   1358       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1359                            run_metadata)\r\n   1360     else:\r\n   1361       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\n~/miniconda3/envs/diffxpy_tf1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py in _do_call(self, fn, *args)\r\n   1382                     '\\nsession_config.graph_options.rewrite_options.'\r\n   1383                     'disable_meta_optimizer = True')\r\n-> 1384       raise type(e)(node_def, op, message)\r\n   1385 \r\n   1386   def _extend_graph(self):\r\n\r\nInvalidArgumentError:  Rank of input (3) must be no greater than rank of output shape (2).\r\n\t [[{{node BroadcastTo}}]]\r\n\t [[full_data/reducible_tensors_eval_ll_jac/ReduceDataset]]\r\n\r\n```","closed_by":null,"reactions":{"url":"https://api.github.com/repos/theislab/diffxpy/issues/202/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/theislab/diffxpy/issues/202/timeline","performed_via_github_app":null,"state_reason":null}