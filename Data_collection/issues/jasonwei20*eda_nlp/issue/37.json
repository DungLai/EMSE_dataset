{"url":"https://api.github.com/repos/jasonwei20/eda_nlp/issues/37","repository_url":"https://api.github.com/repos/jasonwei20/eda_nlp","labels_url":"https://api.github.com/repos/jasonwei20/eda_nlp/issues/37/labels{/name}","comments_url":"https://api.github.com/repos/jasonwei20/eda_nlp/issues/37/comments","events_url":"https://api.github.com/repos/jasonwei20/eda_nlp/issues/37/events","html_url":"https://github.com/jasonwei20/eda_nlp/issues/37","id":1084391182,"node_id":"I_kwDOCbrFdc5Aon8O","number":37,"title":"Need Code for paper \"Good-Enough Example Extrapolation\"","user":{"login":"beyondguo","id":37113676,"node_id":"MDQ6VXNlcjM3MTEzNjc2","avatar_url":"https://avatars.githubusercontent.com/u/37113676?v=4","gravatar_id":"","url":"https://api.github.com/users/beyondguo","html_url":"https://github.com/beyondguo","followers_url":"https://api.github.com/users/beyondguo/followers","following_url":"https://api.github.com/users/beyondguo/following{/other_user}","gists_url":"https://api.github.com/users/beyondguo/gists{/gist_id}","starred_url":"https://api.github.com/users/beyondguo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/beyondguo/subscriptions","organizations_url":"https://api.github.com/users/beyondguo/orgs","repos_url":"https://api.github.com/users/beyondguo/repos","events_url":"https://api.github.com/users/beyondguo/events{/privacy}","received_events_url":"https://api.github.com/users/beyondguo/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-12-20T05:59:47Z","updated_at":"2021-12-20T05:59:47Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi Jason! \r\nSorry to interrupt you. I can't contact you via email. I have to try this place.\r\n\r\nI am very interested in your EMNLP paper \"**Good-Enough Example Extrapolation**\", which provides me lots of inspirations.\r\n\r\nWhen reading the paper, I have some questions :\r\n\r\n1. You mentioned that \" implement GE3 at this final max-pooled hidden layer, which has size 768. That is, the hidden-space augmentation method only updates classifier weights after the BERT encoder\", do you mean **the weights of transformer are frozen during training**? This is a very important detail when I reimplement your paper.\r\n2. GE3 needs to average the hidden vectors of all samples in the same class. So how to implement it in a mini-batch training? Or did you implement the GE3 in a two-stage way: First use BERT to get all vectors, and use GE3 for feature augmentation, then use a simple classifier to train on top of these features?\r\n2. Could you please provide the source code? I am new to this area and I really want to study this method by code.\r\n\r\nI would appreciate it if you could answer my questions and provide the source code. In fact, I am also quite interested in data augmentation and have cited your EDA and other works in my paper and working papers. I look forward to communicate with you! Thanks a lot.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/jasonwei20/eda_nlp/issues/37/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/jasonwei20/eda_nlp/issues/37/timeline","performed_via_github_app":null,"state_reason":null}