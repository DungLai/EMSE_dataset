{"url":"https://api.github.com/repos/google-research/google-research/issues/273","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/273/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/273/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/273/events","html_url":"https://github.com/google-research/google-research/issues/273","id":619748212,"node_id":"MDU6SXNzdWU2MTk3NDgyMTI=","number":273,"title":"TCC doesn't run with distributed training","user":{"login":"IdoWSC","id":30262079,"node_id":"MDQ6VXNlcjMwMjYyMDc5","avatar_url":"https://avatars.githubusercontent.com/u/30262079?v=4","gravatar_id":"","url":"https://api.github.com/users/IdoWSC","html_url":"https://github.com/IdoWSC","followers_url":"https://api.github.com/users/IdoWSC/followers","following_url":"https://api.github.com/users/IdoWSC/following{/other_user}","gists_url":"https://api.github.com/users/IdoWSC/gists{/gist_id}","starred_url":"https://api.github.com/users/IdoWSC/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/IdoWSC/subscriptions","organizations_url":"https://api.github.com/users/IdoWSC/orgs","repos_url":"https://api.github.com/users/IdoWSC/repos","events_url":"https://api.github.com/users/IdoWSC/events{/privacy}","received_events_url":"https://api.github.com/users/IdoWSC/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2020-05-17T16:38:01Z","updated_at":"2020-05-31T10:59:03Z","closed_at":"2020-05-31T10:59:03Z","author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\nI have a large data set and a bigger cnn for spatial encoder that I'm trying to train using the tcc alignment training. In order to get a long enough sequence length I'm trying to run it with distributed training on one machine with 2 GPUs .\r\n\r\nAlthough train.py runs with tf.distribute.MirroredStrategy() as a scope, the whole process runs only on one GPU. It's visible in 2 ways:\r\n\r\n1. nvidia-smi - only one GPU is fully utilized while the other one is on 0% (attached)\r\n![image](https://user-images.githubusercontent.com/30262079/82154160-b47de800-9874-11ea-9337-ffa24787d2b7.png)\r\n\r\n2. vector shape during run time - adding prints of tensors' shapes during train step reveals that the data and the tensors in one replica have actually the same shape as the full batch data and the data is paralelized.  \r\n\r\nIs there anything I'm doing wrong or is this really a bug?\r\n\r\nThanks!","closed_by":{"login":"IdoWSC","id":30262079,"node_id":"MDQ6VXNlcjMwMjYyMDc5","avatar_url":"https://avatars.githubusercontent.com/u/30262079?v=4","gravatar_id":"","url":"https://api.github.com/users/IdoWSC","html_url":"https://github.com/IdoWSC","followers_url":"https://api.github.com/users/IdoWSC/followers","following_url":"https://api.github.com/users/IdoWSC/following{/other_user}","gists_url":"https://api.github.com/users/IdoWSC/gists{/gist_id}","starred_url":"https://api.github.com/users/IdoWSC/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/IdoWSC/subscriptions","organizations_url":"https://api.github.com/users/IdoWSC/orgs","repos_url":"https://api.github.com/users/IdoWSC/repos","events_url":"https://api.github.com/users/IdoWSC/events{/privacy}","received_events_url":"https://api.github.com/users/IdoWSC/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/273/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/273/timeline","performed_via_github_app":null,"state_reason":"completed"}