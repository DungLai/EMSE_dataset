{"url":"https://api.github.com/repos/google-research/google-research/issues/904","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/904/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/904/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/904/events","html_url":"https://github.com/google-research/google-research/issues/904","id":1064410861,"node_id":"I_kwDOCQmIhc4_cZ7t","number":904,"title":"Temporal Fusion Transformers - Val Losses don't improve at all","user":{"login":"realiti4","id":43709619,"node_id":"MDQ6VXNlcjQzNzA5NjE5","avatar_url":"https://avatars.githubusercontent.com/u/43709619?v=4","gravatar_id":"","url":"https://api.github.com/users/realiti4","html_url":"https://github.com/realiti4","followers_url":"https://api.github.com/users/realiti4/followers","following_url":"https://api.github.com/users/realiti4/following{/other_user}","gists_url":"https://api.github.com/users/realiti4/gists{/gist_id}","starred_url":"https://api.github.com/users/realiti4/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/realiti4/subscriptions","organizations_url":"https://api.github.com/users/realiti4/orgs","repos_url":"https://api.github.com/users/realiti4/repos","events_url":"https://api.github.com/users/realiti4/events{/privacy}","received_events_url":"https://api.github.com/users/realiti4/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-11-26T12:13:46Z","updated_at":"2021-11-26T12:13:46Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I'm experimenting with the 4 dataset in the original paper. One thing that I noticed is that val losses usually gets it's best value in first couple of epochs and don't improve or stays the same. Is this normal? What is the point of training more than 2-3 epochs than? Also predefined eary calls usually stops the network between 10-20 epochs. The paper says that the model is trained for 6 hours on a V100 for electiricty dataset. Is there a reason why I am not seeing val loss improvements, or this is normal and that 6 hours training time is with hparam search included. I'd appreciate if you help me understand, thanks.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/904/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/904/timeline","performed_via_github_app":null,"state_reason":null}