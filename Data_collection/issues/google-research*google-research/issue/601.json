{"url":"https://api.github.com/repos/google-research/google-research/issues/601","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/601/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/601/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/601/events","html_url":"https://github.com/google-research/google-research/issues/601","id":821467802,"node_id":"MDU6SXNzdWU4MjE0Njc4MDI=","number":601,"title":"Example for best practice with Mic inputs for TFL Streaming (Just questions & requests)","user":{"login":"StuartIanNaylor","id":2593098,"node_id":"MDQ6VXNlcjI1OTMwOTg=","avatar_url":"https://avatars.githubusercontent.com/u/2593098?v=4","gravatar_id":"","url":"https://api.github.com/users/StuartIanNaylor","html_url":"https://github.com/StuartIanNaylor","followers_url":"https://api.github.com/users/StuartIanNaylor/followers","following_url":"https://api.github.com/users/StuartIanNaylor/following{/other_user}","gists_url":"https://api.github.com/users/StuartIanNaylor/gists{/gist_id}","starred_url":"https://api.github.com/users/StuartIanNaylor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/StuartIanNaylor/subscriptions","organizations_url":"https://api.github.com/users/StuartIanNaylor/orgs","repos_url":"https://api.github.com/users/StuartIanNaylor/repos","events_url":"https://api.github.com/users/StuartIanNaylor/events{/privacy}","received_events_url":"https://api.github.com/users/StuartIanNaylor/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-03-03T20:45:06Z","updated_at":"2021-05-14T07:34:44Z","closed_at":"2021-05-14T07:34:44Z","author_association":"NONE","active_lock_reason":null,"body":"Apols about my hacks but playing with the streaming CRNN I just used this to get something going.\r\nIs there any chance you guys could provide some basic best methods of mic input inference.\r\nAlso the 'envelope' of the classification whats the best way to process that rather than maybe a simple sum?\r\n\r\nShould you always reset the state after another classification detection?\r\n\r\n```\r\nimport sounddevice as sd\r\nimport numpy as np\r\nimport timeit\r\nimport tensorflow.compat.v1 as tf\r\n\r\n\r\n# Parameters\r\ndebug_time = 0\r\ndebug_acc = 0\r\nword_threshold = 10.0\r\nrec_duration = 0.020\r\nsample_rate = 16000\r\nnum_channels = 1\r\n\r\n# Load the TFLite model and allocate tensors.\r\ninterpreter = tf.lite.Interpreter(model_path=\"models2/crnn_state/tflite_stream_state_external/stream_state_external.tflite\")\r\ninterpreter.allocate_tensors()\r\n\r\n# Get input and output tensors.\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\nprint(input_details[0]['shape'])\r\ninputs = []\r\nfor s in range(len(input_details)):\r\n  inputs.append(np.zeros(input_details[s]['shape'], dtype=np.float32))\r\n    \r\ndef sd_callback(rec, frames, time, status):\r\n\r\n    \r\n    start = timeit.default_timer()\r\n    \r\n    # Notify if errors\r\n    if status:\r\n        print('Error:', status)\r\n    \r\n    rec = np.reshape(rec, (1, 320))\r\n    \r\n    # Make prediction from model\r\n    interpreter.set_tensor(input_details[0]['index'], rec.astype(np.float32))\r\n    # set input states (index 1...)\r\n    for s in range(1, len(input_details)):\r\n      interpreter.set_tensor(input_details[s]['index'], inputs[s])\r\n  \r\n    interpreter.invoke()\r\n    output_data = interpreter.get_tensor(output_details[0]['index'])\r\n    # get output states and set it back to input states\r\n    # which will be fed in the next inference cycle\r\n    for s in range(1, len(input_details)):\r\n      # The function `get_tensor()` returns a copy of the tensor data.\r\n      # Use `tensor()` in order to get a pointer to the tensor.\r\n      inputs[s] = interpreter.get_tensor(output_details[s]['index'])\r\n      \r\n    out_tflite_argmax = np.argmax(output_data)\r\n     \r\n    \r\n    if out_tflite_argmax == 2:\r\n        print('raspberry')\r\n        print(output_data[0][2])\r\n        \r\n\r\n    if debug_acc:\r\n        print(out_tflite_argmax)\r\n    \r\n    if debug_time:\r\n        print(timeit.default_timer() - start)\r\n\r\n# Start streaming from microphone\r\nwith sd.InputStream(channels=num_channels,\r\n                    samplerate=sample_rate,\r\n                    blocksize=int(sample_rate * rec_duration),\r\n                    callback=sd_callback):\r\n    while True:\r\n        pass\r\n```","closed_by":{"login":"StuartIanNaylor","id":2593098,"node_id":"MDQ6VXNlcjI1OTMwOTg=","avatar_url":"https://avatars.githubusercontent.com/u/2593098?v=4","gravatar_id":"","url":"https://api.github.com/users/StuartIanNaylor","html_url":"https://github.com/StuartIanNaylor","followers_url":"https://api.github.com/users/StuartIanNaylor/followers","following_url":"https://api.github.com/users/StuartIanNaylor/following{/other_user}","gists_url":"https://api.github.com/users/StuartIanNaylor/gists{/gist_id}","starred_url":"https://api.github.com/users/StuartIanNaylor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/StuartIanNaylor/subscriptions","organizations_url":"https://api.github.com/users/StuartIanNaylor/orgs","repos_url":"https://api.github.com/users/StuartIanNaylor/repos","events_url":"https://api.github.com/users/StuartIanNaylor/events{/privacy}","received_events_url":"https://api.github.com/users/StuartIanNaylor/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/601/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/601/timeline","performed_via_github_app":null,"state_reason":"completed"}