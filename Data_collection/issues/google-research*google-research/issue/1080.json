{"url":"https://api.github.com/repos/google-research/google-research/issues/1080","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/1080/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/1080/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/1080/events","html_url":"https://github.com/google-research/google-research/issues/1080","id":1221503198,"node_id":"I_kwDOCQmIhc5Izqje","number":1080,"title":"[VATT] Issues Loading Pretrianed Checkpoint","user":{"login":"Maddy12","id":14296217,"node_id":"MDQ6VXNlcjE0Mjk2MjE3","avatar_url":"https://avatars.githubusercontent.com/u/14296217?v=4","gravatar_id":"","url":"https://api.github.com/users/Maddy12","html_url":"https://github.com/Maddy12","followers_url":"https://api.github.com/users/Maddy12/followers","following_url":"https://api.github.com/users/Maddy12/following{/other_user}","gists_url":"https://api.github.com/users/Maddy12/gists{/gist_id}","starred_url":"https://api.github.com/users/Maddy12/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Maddy12/subscriptions","organizations_url":"https://api.github.com/users/Maddy12/orgs","repos_url":"https://api.github.com/users/Maddy12/repos","events_url":"https://api.github.com/users/Maddy12/events{/privacy}","received_events_url":"https://api.github.com/users/Maddy12/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2022-04-29T20:38:47Z","updated_at":"2022-05-06T02:10:17Z","closed_at":"2022-05-06T02:10:16Z","author_association":"NONE","active_lock_reason":null,"body":"Hello, I am trying to evaluate VATT on YouCook2 dataset for text-video retrieval. I am having errors trying to load a previous checkpoint among many other package issues with tensorflow v2.7, DMVR, and more (but will save that for another ticket). \r\n\r\nThe weights I am trying to load are for ut_fac and are stored in `weights/vatt` which I am passing as the param to `override_checkpoint`:\r\n\r\nThe link to data is: https://storage.cloud.google.com/tf_model_garden/vision/vatt/pretrain/ut_fac_medium/ckpt-500000.data-00000-of-00001\r\nThe link to index is: https://storage.cloud.google.com/tf_model_garden/vision/vatt/pretrain/ut_fac_medium/ckpt-500000.index\r\nThen I am passing the architecture as ut_fac.\r\n\r\nWhat I am calling:\r\n```\r\nWEIGHTS_DIR=weights/vatt\r\npython main.py --task=pretrain \\\r\n                    --mode=eval \\\r\n                    --model_dir=$WEIGHTS_DIR \\\r\n                    --model_arch=ut_fac \\\r\n                    --strategy_type=mirrored \\\r\n                     --override_checkpoint=$WEIGHTS_DIR\r\n```\r\n\r\nError: \r\n```\r\n022-04-28 16:53:59.807821: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /share/apps/anaconda3-2019.03-1/lib\r\n2022-04-28 16:53:59.807863: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\nI0428 16:53:59.813026 22875650352960 main.py:87] Model Parameters: {'checkpoint_path': 'weights/vatt',\r\n 'eval': {'input': {'audio_mixup': False,\r\n                    'audio_stride': 1,\r\n                    'batch_size': 8,\r\n                    'color_augment': True,\r\n                    'crop_resize_style': 'VGG',\r\n                    'frame_size': 224,\r\n                    'has_data': True,\r\n                    'linearize_vision': True,\r\n                    'max_area_ratio': 1.0,\r\n                    'max_aspect_ratio': 2.0,\r\n                    'max_num_words': 16,\r\n                    'mel_bins': 80,\r\n                    'min_area_ratio': 0.08,\r\n                    'min_aspect_ratio': 0.5,\r\n                    'min_resize': 224,\r\n                    'mixup_alpha': 10,\r\n                    'mixup_beta': 1,\r\n                    'multi_crop': False,\r\n                    'name': ('youcook2',),\r\n                    'num_augmentation': 1,\r\n                    'num_examples': 4096,\r\n                    'num_frames': 32,\r\n                    'num_windows_test': 4,\r\n                    'raw_audio': True,\r\n                    'scale_jitter': True,\r\n                    'space_to_depth': False,\r\n                    'split': 'test',\r\n                    'stft_length': 0.04267,\r\n                    'stft_step': 0.02134,\r\n                    'text_tokenizer': 'WordTokenizer',\r\n                    'video_stride': 2,\r\n                    'zero_centering_image': True}},\r\n 'mode': 'eval',\r\n 'model_config': {'backbone_config': {'name': 'unified_backbone',\r\n                                      'unified_backbone': 'ut_medium'},\r\n                  'head_config': {'bridge': ({'aud_to_vid_txt_kwargs': {'d_model': 512,\r\n                                                                        'modality': 'audio',\r\n                                                                        'name': 'audio_mlp_module'},\r\n                                              'bn_config': {'epsilon': 1e-05,\r\n                                                            'momentum': 0.9,\r\n                                                            'name': 'batch_norm',\r\n                                                            'scale': True},\r\n                                              'name': 'mlp_fac',\r\n                                              'txt_to_vid_aud_kwargs': {'d_model': 256,\r\n                                                                        'modality': 'text',\r\n                                                                        'name': 'text_mlp_module'},\r\n                                              'use_xreplica_bn': True,\r\n                                              'vid_to_aud_txt_kwargs': {'d_model': 512,\r\n                                                                        'modality': 'video',\r\n                                                                        'name': 'video_mlp_module'}},)},\r\n                  'loss_config': {'bridge': ({'aud_txt_weight': 0.0,\r\n                                              'loss_weight': 1.0,\r\n                                              'name': 'asymmetric_nce',\r\n                                              'temperature': 0.07,\r\n                                              'vid_aud_weight': 1.0,\r\n                                              'vid_txt_weight': 1.0},)},\r\n                  'model_name': 'uvatt_mlp_fac'},\r\n 'model_dir': 'weights/vatt',\r\n 'strategy_config': {'distribution_strategy': 'mirrored', 'tpu': None},\r\n 'task': 'Pretrain',\r\n 'train': {'gradient_clip_norm': 0.0,\r\n           'gradient_clip_norm_cls': None,\r\n           'input': {'audio_mixup': False,\r\n                     'audio_noise': 0.01,\r\n                     'audio_stride': 1,\r\n                     'batch_size': 8,\r\n                     'color_augment': True,\r\n                     'crop_resize_style': 'VGG',\r\n                     'frame_size': 224,\r\n                     'has_data': True,\r\n                     'linearize_vision': True,\r\n                     'max_area_ratio': 1.0,\r\n                     'max_aspect_ratio': 2.0,\r\n                     'max_context_sentences': 4,\r\n                     'max_num_words': 16,\r\n                     'mel_bins': 80,\r\n                     'min_area_ratio': 0.08,\r\n                     'min_aspect_ratio': 0.5,\r\n                     'min_resize': 224,\r\n                     'mixup_alpha': 10,\r\n                     'mixup_beta': 2,\r\n                     'name': 'howto100m+audioset',\r\n                     'num_examples': -1,\r\n                     'num_frames': 32,\r\n                     'raw_audio': True,\r\n                     'scale_jitter': True,\r\n                     'space_to_depth': False,\r\n                     'split': 'train',\r\n                     'stft_length': 0.04267,\r\n                     'stft_step': 0.02134,\r\n                     'text_tokenizer': 'WordTokenizer',\r\n                     'video_stride': 1,\r\n                     'zero_centering_image': True},\r\n           'iterations_per_loop': 50,\r\n           'max_checkpoints': 50,\r\n           'optimizer': {'beta_1': 0.9,\r\n                         'beta_2': 0.999,\r\n                         'epsilon': 1e-07,\r\n                         'learning_rate': {'learning_rate_base': 0.0001,\r\n                                           'learning_rate_levels': (0.0001,\r\n                                                                    5e-05),\r\n                                           'learning_rate_steps': (5000,\r\n                                                                   500000),\r\n                                           'total_steps': 500000,\r\n                                           'warmup_learning_rate': 0.0,\r\n                                           'warmup_steps': 5000},\r\n                         'name': 'Adam'},\r\n           'save_checkpoint_freq': 10000}}\r\n2022-04-28 16:53:59.814110: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nWARNING:tensorflow:Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:0\r\nW0428 16:53:59.815804 22875650352960 cross_device_ops.py:1382] Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:0\r\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\r\nI0428 16:53:59.829632 22875650352960 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\r\nI0428 16:54:00.367541 22875650352960 mlp_lib.py:122] Using Cross Replica BatchNorm in Relu-Dense-BN.\r\nI0428 16:54:00.374226 22875650352960 mlp_lib.py:122] Using Cross Replica BatchNorm in Relu-Dense-BN.\r\nI0428 16:54:00.376174 22875650352960 factory.py:123] Head stack mlp_fac created successfully.\r\nI0428 16:54:00.501415 22875650352960 factory.py:134] Unified backbone ut_medium created successfully.\r\nI0428 16:54:00.505504 22875650352960 factory.py:173] Entire MM model uvatt_mlp_fac created successfully.\r\nI0428 16:54:09.682963 22875650352960 pretrain.py:99] Language embedding weights word2vec restored successfully.\r\nI0428 16:54:09.692070 22875650352960 pretrain.py:130] Number of parameters in model: 182.653696 M.\r\nI0428 16:54:09.701606 22875650352960 base.py:446] Override checkpoint found. Restoring the model from the checkpoint at weights/vatt.\r\n2022-04-29 16:36:17.254240: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open weights/vatt: DATA_LOSS: file is too short to be an sstable: perhaps your file is in a different file format and you need to use a different restore operator?\r\nTraceback (most recent call last):\r\n  File \"/home/schiappa/.conda/envs/vatt_v2/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py\", line 96, in NewCheckpointReader\r\n    return CheckpointReader(compat.as_bytes(filepattern))\r\nRuntimeError: Unable to open table file weights/vatt: DATA_LOSS: file is too short to be an sstable: perhaps your file is in a different file format and you need to use a different restore operator?\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 110, in <module>\r\n    app.run(main)\r\n  File \"conda/envs/vatt_v2/lib/python3.8/site-packages/absl/app.py\", line 312, in run\r\n    _run_main(main, args)\r\n  File \".conda/envs/vatt_v2/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"main.py\", line 106, in main\r\n    return executor.run(mode=params.mode)\r\n  File \"models/vatt/experiments/base.py\", line 500, in run\r\n    self.evaluate()\r\n  File \"models/vatt/experiments/base.py\", line 450, in evaluate\r\n    checkpoint.restore(self.params.checkpoint_path).expect_partial().assert_existing_objects_matched()\r\n  File \".conda/envs/vatt_v2/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py\", line 2354, in restore\r\n    status = self.read(save_path, options=options)\r\n  File \".conda/envs/vatt_v2/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py\", line 2229, in read\r\n    result = self._saver.restore(save_path=save_path, options=options)\r\n  File \"/home/schiappa/.conda/envs/vatt_v2/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py\", line 1322, in restore\r\n    reader = py_checkpoint_reader.NewCheckpointReader(save_path)\r\n  File \"/home/schiappa/.conda/envs/vatt_v2/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py\", line 100, in NewCheckpointReader\r\n    error_translator(e)\r\n  File \"schiappa/.conda/envs/vatt_v2/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py\", line 44, in error_translator\r\n    raise errors_impl.DataLossError(None, None, error_message)\r\ntensorflow.python.framework.errors_impl.DataLossError: Unable to open table file weights/vatt: DATA_LOSS: file is too short to be an sstable: perhaps your file is in a different file format and you need to use a different restore operator?\r\n```\r\n\r\nI know it says to run in python3.7 but DMVR does not work for me otherwise.","closed_by":{"login":"Maddy12","id":14296217,"node_id":"MDQ6VXNlcjE0Mjk2MjE3","avatar_url":"https://avatars.githubusercontent.com/u/14296217?v=4","gravatar_id":"","url":"https://api.github.com/users/Maddy12","html_url":"https://github.com/Maddy12","followers_url":"https://api.github.com/users/Maddy12/followers","following_url":"https://api.github.com/users/Maddy12/following{/other_user}","gists_url":"https://api.github.com/users/Maddy12/gists{/gist_id}","starred_url":"https://api.github.com/users/Maddy12/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Maddy12/subscriptions","organizations_url":"https://api.github.com/users/Maddy12/orgs","repos_url":"https://api.github.com/users/Maddy12/repos","events_url":"https://api.github.com/users/Maddy12/events{/privacy}","received_events_url":"https://api.github.com/users/Maddy12/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/1080/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/1080/timeline","performed_via_github_app":null,"state_reason":"completed"}