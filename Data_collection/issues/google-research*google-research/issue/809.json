{"url":"https://api.github.com/repos/google-research/google-research/issues/809","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/809/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/809/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/809/events","html_url":"https://github.com/google-research/google-research/issues/809","id":987923534,"node_id":"MDU6SXNzdWU5ODc5MjM1MzQ=","number":809,"title":"error training svdf_resnet on custom data","user":{"login":"srewai","id":32038717,"node_id":"MDQ6VXNlcjMyMDM4NzE3","avatar_url":"https://avatars.githubusercontent.com/u/32038717?v=4","gravatar_id":"","url":"https://api.github.com/users/srewai","html_url":"https://github.com/srewai","followers_url":"https://api.github.com/users/srewai/followers","following_url":"https://api.github.com/users/srewai/following{/other_user}","gists_url":"https://api.github.com/users/srewai/gists{/gist_id}","starred_url":"https://api.github.com/users/srewai/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/srewai/subscriptions","organizations_url":"https://api.github.com/users/srewai/orgs","repos_url":"https://api.github.com/users/srewai/repos","events_url":"https://api.github.com/users/srewai/events{/privacy}","received_events_url":"https://api.github.com/users/srewai/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":31,"created_at":"2021-09-03T16:13:09Z","updated_at":"2022-01-06T09:59:00Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi @rybakov , \r\n\r\nI am trying to follow the steps for svdf_resnet [here for quantization](https://github.com/google-research/google-research/blob/master/kws_streaming/experiments/kws_experiments_30k_12_labels.md) with the below command on custom data. \r\n\r\nBelow is the command used:\r\n```\r\n$CMD_TRAIN \\\r\n--wanted_words 'srewai' \\\r\n--data_url '' \\\r\n--data_dir $DATA_PATH/ \\\r\n--train_dir $MODELS_PATH/svdf_resnet/ \\\r\n--mel_upper_edge_hertz 7600 \\\r\n--how_many_training_steps 20000,20000,20000,20000 \\\r\n--learning_rate 0.001,0.0005,0.0001,0.00002 \\\r\n--window_size_ms 40.0 \\\r\n--window_stride_ms 20.0 \\\r\n--mel_num_bins 80 \\\r\n--dct_num_features 40 \\\r\n--resample 0.15 \\\r\n--time_shift_ms 100 \\\r\n--feature_type 'mfcc_op' \\\r\n--fft_magnitude_squared 1 \\\r\n--preprocess 'raw' \\\r\n--train 1 \\\r\n--lr_schedule 'exp' \\\r\nsvdf_resnet \\\r\n--block1_memory_size '7' \\\r\n--block2_memory_size '7' \\\r\n--block3_memory_size '11,11' \\\r\n--block1_units1 '32' \\\r\n--block2_units1 '50' \\\r\n--block3_units1 '50,128' \\\r\n--blocks_pool '2,2,1' \\\r\n--use_batch_norm 1 \\\r\n--bn_scale 1 \\\r\n--activation 'relu' \\\r\n--svdf_dropout 0.0 \\\r\n--svdf_pad 1 \\\r\n--svdf_use_bias 0 \\\r\n--dropout1 0.0 \\\r\n--units2 '64' \\\r\n--flatten 0\r\n```\r\nThe model summary looks like this.\r\n```\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nW0903 18:00:45.072718 140373190989632 deprecation.py:347] From /srewai-venv/lib/python3.6/site-packages/keras/layers/normalization/batch_normalization.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nModel: \"model\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\ninput_1 (InputLayer)            [(100, 16000)]       0           []                               \r\n__________________________________________________________________________________________________\r\nspeech_features (SpeechFeature  (100, 49, 40)        0           ['input_1[0][0]']                \r\ns)                                                                                                \r\n__________________________________________________________________________________________________\r\ndense_1 (Dense)                 (100, 49, 32)        1280        ['speech_features[0][0]']        \r\n__________________________________________________________________________________________________\r\nsvdf_1_0 (Svdf)                 (100, 49, 32)        1632        ['speech_features[0][0]']        \r\n__________________________________________________________________________________________________\r\nbatch_normalization_1 (BatchNo  (100, 49, 32)        128         ['dense_1[0][0]']                \r\nrmalization)                                                                                      \r\n__________________________________________________________________________________________________\r\nadd (Add)                       (100, 49, 32)        0           ['svdf_1_0[0][0]',               \r\n                                                                  'batch_normalization_1[0][0]']  \r\n__________________________________________________________________________________________________\r\nactivation (Activation)         (100, 49, 32)        0           ['add[0][0]']                    \r\n__________________________________________________________________________________________________\r\nmax_pooling1d (MaxPooling1D)    (100, 24, 32)        0           ['activation[0][0]']             \r\n__________________________________________________________________________________________________\r\ndense_3 (Dense)                 (100, 24, 50)        1600        ['max_pooling1d[0][0]']          \r\n__________________________________________________________________________________________________\r\nsvdf_2_0 (Svdf)                 (100, 24, 50)        2150        ['max_pooling1d[0][0]']          \r\n__________________________________________________________________________________________________\r\nbatch_normalization_3 (BatchNo  (100, 24, 50)        200         ['dense_3[0][0]']                \r\nrmalization)                                                                                      \r\n__________________________________________________________________________________________________\r\nadd_1 (Add)                     (100, 24, 50)        0           ['svdf_2_0[0][0]',               \r\n                                                                  'batch_normalization_3[0][0]']  \r\n__________________________________________________________________________________________________\r\nactivation_1 (Activation)       (100, 24, 50)        0           ['add_1[0][0]']                  \r\n__________________________________________________________________________________________________\r\nmax_pooling1d_1 (MaxPooling1D)  (100, 11, 50)        0           ['activation_1[0][0]']           \r\n__________________________________________________________________________________________________\r\nsvdf_3_0 (Svdf)                 (100, 11, 50)        3250        ['max_pooling1d_1[0][0]']        \r\n__________________________________________________________________________________________________\r\ndense_6 (Dense)                 (100, 11, 128)       6400        ['max_pooling1d_1[0][0]']        \r\n__________________________________________________________________________________________________\r\nsvdf_3_1 (Svdf)                 (100, 11, 128)       8320        ['svdf_3_0[0][0]']               \r\n__________________________________________________________________________________________________\r\nbatch_normalization_6 (BatchNo  (100, 11, 128)       512         ['dense_6[0][0]']                \r\nrmalization)                                                                                      \r\n__________________________________________________________________________________________________\r\nadd_2 (Add)                     (100, 11, 128)       0           ['svdf_3_1[0][0]',               \r\n                                                                  'batch_normalization_6[0][0]']  \r\n__________________________________________________________________________________________________\r\nactivation_2 (Activation)       (100, 11, 128)       0           ['add_2[0][0]']                  \r\n__________________________________________________________________________________________________\r\nmax_pooling1d_2 (MaxPooling1D)  (100, 9, 128)        0           ['activation_2[0][0]']           \r\n__________________________________________________________________________________________________\r\nglobal_average_pooling1d (Glob  (100, 128)           0           ['max_pooling1d_2[0][0]']        \r\nalAveragePooling1D)                                                                               \r\n__________________________________________________________________________________________________\r\ndropout (Dropout)               (100, 128)           0           ['global_average_pooling1d[0][0]'\r\n                                                                 ]                                \r\n__________________________________________________________________________________________________\r\ndense_7 (Dense)                 (100, 64)            8256        ['dropout[0][0]']                \r\n__________________________________________________________________________________________________\r\ndense_8 (Dense)                 (100, 3)             195         ['dense_7[0][0]']                \r\n==================================================================================================\r\nTotal params: 33,923\r\nTrainable params: 32,983\r\nNon-trainable params: 940\r\n__________________________________________________________________________________________________\r\nI0903 18:00:45.455425 140373190989632 train.py:71] None\r\n```\r\n\r\nBut it fails at the time of converting into tflite stream. Here is the error:\r\n\r\n```\r\n2021-09-03 18:22:54.631382: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\r\n2021-09-03 18:22:54.634525: E tensorflow/core/grappler/grappler_item_builder.cc:669] Init node svdf_1_0/dense/kernel/Assign doesn't exist in graph\r\nI0903 18:22:54.659212 140426826090304 lite.py:1723] Using experimental converter: If you encountered a problem please file a bug. You can opt-out by setting experimental_new_converter=False\r\n2021-09-03 18:22:54.663914: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\r\n2021-09-03 18:22:54.663933: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\r\n2021-09-03 18:22:54.698313: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1855] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following flex op(s):\r\nFlex ops: FlexAudioSpectrogram, FlexMfcc\r\nDetails:\r\n\ttf.AudioSpectrogram(tensor<16000x1xf32>) -> (tensor<1x49x513xf32>) : {device = \"\", magnitude_squared = true, stride = 320 : i64, window_size = 640 : i64}\r\n\ttf.Mfcc(tensor<1x49x513xf32>, tensor<i32>) -> (tensor<1x49x40xf32>) : {dct_coefficient_count = 40 : i64, device = \"\", filterbank_channel_count = 80 : i64, lower_frequency_limit = 2.000000e+01 : f32, upper_frequency_limit = 7.600000e+03 : f32}\r\n\r\n******snipped****\r\n\r\nI0903 18:01:06.509099 140373190989632 test.py:510] tflite test accuracy, non stream model = 74.63% 200 out of 221\r\nI0903 18:01:06.552580 140373190989632 test.py:514] tflite Final test accuracy, non stream model = 75.11% (N=221)\r\nI0903 18:01:06.553761 140373190989632 model_train_eval.py:257] run TFlite streaming model accuracy evaluation\r\nW0903 18:01:07.091468 140373190989632 test.py:560] FAILED to convert to mode STREAM_EXTERNAL_STATE_INFERENCE, tflite: Negative dimension size caused by subtracting 3 from 1 for '{{node streaming/max_pooling1d/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 3, 1, 1], padding=\"VALID\", strides=[1, 2, 1, 1]](streaming/max_pooling1d/ExpandDims)' with input shapes: [1,1,1,32].\r\nI0903 18:01:07.091856 140373190989632 test.py:364] tflite stream model state external with reset_state 1\r\nI0903 18:01:07.342433 140373190989632 model_train_eval.py:282] FAILED to run TFLite streaming: Mmap of '7' at offset '0' failed with error '22'.\r\n\r\n```\r\nBelow is my environment :\r\n\r\n```\r\nPackage                       Version\r\n----------------------------- -------------------\r\nabsl-py                       0.13.0\r\nargon2-cffi                   21.1.0\r\nastunparse                    1.6.3\r\nasync-generator               1.10\r\nattrs                         21.2.0\r\nbackcall                      0.2.0\r\nbleach                        4.1.0\r\ncached-property               1.5.2\r\ncachetools                    4.2.2\r\ncertifi                       2021.5.30\r\ncffi                          1.14.6\r\ncharset-normalizer            2.0.4\r\ncycler                        0.10.0\r\ndataclasses                   0.8\r\ndecorator                     5.0.9\r\ndefusedxml                    0.7.1\r\ndm-tree                       0.1.6\r\nentrypoints                   0.3\r\nflatbuffers                   1.12\r\ngast                          0.4.0\r\ngoogle-auth                   1.35.0\r\ngoogle-auth-oauthlib          0.4.5\r\ngoogle-pasta                  0.2.0\r\ngraphviz                      0.17\r\ngrpcio                        1.39.0\r\nh5py                          3.1.0\r\nidna                          3.2\r\nimportlib-metadata            4.8.1\r\nipykernel                     5.5.5\r\nipython                       7.16.1\r\nipython-genutils              0.2.0\r\nipywidgets                    7.6.4\r\njedi                          0.18.0\r\nJinja2                        3.0.1\r\njsonschema                    3.2.0\r\njupyter                       1.0.0\r\njupyter-client                7.0.2\r\njupyter-console               6.4.0\r\njupyter-core                  4.7.1\r\njupyterlab-pygments           0.1.2\r\njupyterlab-widgets            1.0.1\r\nkeras-nightly                 2.7.0.dev2021083107\r\nKeras-Preprocessing           1.1.2\r\nkiwisolver                    1.3.1\r\nlibclang                      11.1.0\r\nMarkdown                      3.3.4\r\nMarkupSafe                    2.0.1\r\nmatplotlib                    3.3.4\r\nmistune                       0.8.4\r\nnbclient                      0.5.4\r\nnbconvert                     6.0.7\r\nnbformat                      5.1.3\r\nnest-asyncio                  1.5.1\r\nnotebook                      6.4.3\r\nnumpy                         1.19.5\r\noauthlib                      3.1.1\r\nopt-einsum                    3.3.0\r\npackaging                     21.0\r\npandocfilters                 1.4.3\r\nparso                         0.8.2\r\npexpect                       4.8.0\r\npickleshare                   0.7.5\r\nPillow                        8.3.1\r\npip                           21.2.4\r\nprometheus-client             0.11.0\r\nprompt-toolkit                3.0.20\r\nprotobuf                      3.17.3\r\nptyprocess                    0.7.0\r\npyasn1                        0.4.8\r\npyasn1-modules                0.2.8\r\npycparser                     2.20\r\npydot                         1.4.2\r\nPygments                      2.10.0\r\npyparsing                     2.4.7\r\npyrsistent                    0.18.0\r\npython-dateutil               2.8.2\r\npyzmq                         22.2.1\r\nqtconsole                     5.1.1\r\nQtPy                          1.10.0\r\nrequests                      2.26.0\r\nrequests-oauthlib             1.3.0\r\nrsa                           4.7.2\r\nscipy                         1.5.4\r\nSend2Trash                    1.8.0\r\nsetuptools                    57.4.0\r\nsix                           1.15.0\r\ntb-nightly                    2.6.0a20210806\r\ntensorboard-data-server       0.6.1\r\ntensorboard-plugin-wit        1.8.0\r\ntensorflow-addons             0.14.0\r\ntensorflow-model-optimization 0.6.0\r\ntermcolor                     1.1.0\r\nterminado                     0.11.1\r\ntestpath                      0.5.0\r\ntf-estimator-nightly          2.7.0.dev2021083108\r\ntf-nightly                    2.7.0.dev20210806\r\ntornado                       6.1\r\ntraitlets                     4.3.3\r\ntypeguard                     2.12.1\r\ntyping-extensions             3.7.4.3\r\nurllib3                       1.26.6\r\nwcwidth                       0.2.5\r\nwebencodings                  0.5.1\r\nWerkzeug                      2.0.1\r\nwheel                         0.37.0\r\nwidgetsnbextension            3.5.1\r\nwrapt                         1.12.1\r\nzipp                          3.5.0\r\n```\r\nThe data folder has 1-sec recordings as below:\r\n\r\n```\r\ndata folder:\r\n_background_noise_  bed  bird  cat  dog  happy  srewai  house  marvin   sheila  tree  wow\r\n ```\r\n\r\nPlease note that svdf works fine for me.\r\n\r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/809/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/809/timeline","performed_via_github_app":null,"state_reason":null}