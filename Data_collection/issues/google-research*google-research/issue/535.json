{"url":"https://api.github.com/repos/google-research/google-research/issues/535","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/535/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/535/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/535/events","html_url":"https://github.com/google-research/google-research/issues/535","id":790226111,"node_id":"MDU6SXNzdWU3OTAyMjYxMTE=","number":535,"title":"[T5X] RuntimeError with BF16 and multiple GPUs","user":{"login":"giacomofrisoni","id":24437838,"node_id":"MDQ6VXNlcjI0NDM3ODM4","avatar_url":"https://avatars.githubusercontent.com/u/24437838?v=4","gravatar_id":"","url":"https://api.github.com/users/giacomofrisoni","html_url":"https://github.com/giacomofrisoni","followers_url":"https://api.github.com/users/giacomofrisoni/followers","following_url":"https://api.github.com/users/giacomofrisoni/following{/other_user}","gists_url":"https://api.github.com/users/giacomofrisoni/gists{/gist_id}","starred_url":"https://api.github.com/users/giacomofrisoni/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/giacomofrisoni/subscriptions","organizations_url":"https://api.github.com/users/giacomofrisoni/orgs","repos_url":"https://api.github.com/users/giacomofrisoni/repos","events_url":"https://api.github.com/users/giacomofrisoni/events{/privacy}","received_events_url":"https://api.github.com/users/giacomofrisoni/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-20T18:45:35Z","updated_at":"2021-01-20T20:47:31Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi there,\r\n\r\nI really enjoyed the recent release of **T5X**.\r\nWhile having no problems running it on Colab (standard notebook with one GPU), I am facing some difficulties in running the code on one of my machines. Specifically, my configuration is Ubuntu 18.04, CUDA 11, CuDNN 7, with **two GPUs**  (TITAN Xp, 12GB each).\r\nThe GPUs are recognized by JAX, and the code runs correctly up to the `pmap` related to `p_train_epoch`.\r\n\r\nThe error is the following:\r\n`RuntimeError: Unimplemented: Requested AllReduce not implemented on GPU; replica_count: 2; operand_count: 131; IsCrossReplicaAllReduce: 1; NCCL support: 1; first operand array element-type: BF16`\r\n\r\nBy working with float32 the training is performed successfully. It appears an error related to using **jnp.float16** on **multi-GPUs**. Can you help me?\r\n\r\nHere the complete Traceback:\r\n```\r\nTraceback (most recent call last):\r\n  File \"ft_t5_small_super_glue.py\", line 84, in <module>\r\n    train(model_dir='t5x_data', config=fine_tuning_cfg)\r\n  File \"/workspace/linear_t5x/src/t5x_utils/training.py\", line 525, in train\r\n    jnp.array(0, dtype=jnp.int32), 1)\r\n  File \"/opt/conda/lib/python3.6/site-packages/jax/api.py\", line 1564, in f_pmapped\r\n    global_arg_shapes=tuple(global_arg_shapes_flat))\r\n  File \"/opt/conda/lib/python3.6/site-packages/jax/core.py\", line 1262, in bind\r\n    return call_bind(self, fun, *args, **params)\r\n  File \"/opt/conda/lib/python3.6/site-packages/jax/core.py\", line 1226, in call_bind\r\n    outs = primitive.process(top_trace, fun, tracers, params)\r\n  File \"/opt/conda/lib/python3.6/site-packages/jax/core.py\", line 1265, in process\r\n    return trace.process_map(self, fun, tracers, params)\r\n  File \"/opt/conda/lib/python3.6/site-packages/jax/core.py\", line 598, in process_call\r\n    return primitive.impl(f, *tracers, **params)\r\n  File \"/opt/conda/lib/python3.6/site-packages/jax/interpreters/pxla.py\", line 635, in xla_pmap_impl\r\n    *abstract_args)\r\n  File \"/opt/conda/lib/python3.6/site-packages/jax/linear_util.py\", line 251, in memoized_fun\r\n    ans = call(fun, *args)\r\n  File \"/opt/conda/lib/python3.6/site-packages/jax/interpreters/pxla.py\", line 892, in parallel_callable\r\n    compiled = xla.backend_compile(backend, built, compile_options)\r\n  File \"/opt/conda/lib/python3.6/site-packages/jax/interpreters/xla.py\", line 349, in backend_compile\r\n    return backend.compile(built_c, compile_options=options)\r\n```\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/535/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/535/timeline","performed_via_github_app":null,"state_reason":null}