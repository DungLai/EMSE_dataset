{"url":"https://api.github.com/repos/google-research/google-research/issues/565","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/565/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/565/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/565/events","html_url":"https://github.com/google-research/google-research/issues/565","id":803383056,"node_id":"MDU6SXNzdWU4MDMzODMwNTY=","number":565,"title":"interpretability_benchmark: clarification regarding feature importance estimates","user":{"login":"expectopatronum","id":2265475,"node_id":"MDQ6VXNlcjIyNjU0NzU=","avatar_url":"https://avatars.githubusercontent.com/u/2265475?v=4","gravatar_id":"","url":"https://api.github.com/users/expectopatronum","html_url":"https://github.com/expectopatronum","followers_url":"https://api.github.com/users/expectopatronum/followers","following_url":"https://api.github.com/users/expectopatronum/following{/other_user}","gists_url":"https://api.github.com/users/expectopatronum/gists{/gist_id}","starred_url":"https://api.github.com/users/expectopatronum/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/expectopatronum/subscriptions","organizations_url":"https://api.github.com/users/expectopatronum/orgs","repos_url":"https://api.github.com/users/expectopatronum/repos","events_url":"https://api.github.com/users/expectopatronum/events{/privacy}","received_events_url":"https://api.github.com/users/expectopatronum/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-02-08T09:40:28Z","updated_at":"2021-03-09T02:27:36Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi!\r\nThanks a lot for the great work! I am considering using ROAR in my own research but would like to clarify something first. In the paper and also in the README you mention that you use the estimated feature importance, and you write \r\n> A feature importance estimate is a ranking of the contribution of each input pixel to the model prediction for that image.\r\n\r\nFrom my own experiments with some of the methods, e.g. Integrated Gradients, I know that the attributions can also be negative. I couldn't find any hint how negative attributions are treated. I could imagine a few possible solutions, therefore I was wondering if you could clarify how it is done. Are the contributions ranked by their absolute value, are negative values ignored, are the contributions sorted from large positive to large negative values?\r\n\r\nThanks a lot for your time, I would really appreciate an answer!\r\nBest regards\r\nVerena  Haunschmid\r\n\r\ntagging: @sarahooker @doomie","closed_by":null,"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/565/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/565/timeline","performed_via_github_app":null,"state_reason":null}