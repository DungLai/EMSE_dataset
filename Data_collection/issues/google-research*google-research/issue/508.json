{"url":"https://api.github.com/repos/google-research/google-research/issues/508","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/508/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/508/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/508/events","html_url":"https://github.com/google-research/google-research/issues/508","id":775815636,"node_id":"MDU6SXNzdWU3NzU4MTU2MzY=","number":508,"title":"fast-attention: train well but predict badly","user":{"login":"2020zyc","id":7539692,"node_id":"MDQ6VXNlcjc1Mzk2OTI=","avatar_url":"https://avatars.githubusercontent.com/u/7539692?v=4","gravatar_id":"","url":"https://api.github.com/users/2020zyc","html_url":"https://github.com/2020zyc","followers_url":"https://api.github.com/users/2020zyc/followers","following_url":"https://api.github.com/users/2020zyc/following{/other_user}","gists_url":"https://api.github.com/users/2020zyc/gists{/gist_id}","starred_url":"https://api.github.com/users/2020zyc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/2020zyc/subscriptions","organizations_url":"https://api.github.com/users/2020zyc/orgs","repos_url":"https://api.github.com/users/2020zyc/repos","events_url":"https://api.github.com/users/2020zyc/events{/privacy}","received_events_url":"https://api.github.com/users/2020zyc/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2020-12-29T10:21:31Z","updated_at":"2021-02-04T07:47:27Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"1. I use the transformer model in models/official/nlp/transformer/transformer.py to train a seq2seq model, replacing the built-in keras attention with performer fast-attention(tensorflow version),  for example, the decoder stack is as follows\r\n![image](https://user-images.githubusercontent.com/7539692/103272848-d76e9e00-49f8-11eb-9594-b0f57114e67a.png)\r\n> It seams images can't be displayed: \r\n```\r\n    # DecoderStack\r\n    def build(self, input_shape):\r\n        \"\"\"Builds the decoder stack.\"\"\"\r\n        params = self.params\r\n        for _ in range(params[\"num_hidden_layers\"]):\r\n            if not params[\"use_fast_attn\"]:  # ==========set to True to use fast_attention=============\r\n                self_attention_layer = attention_layer.SelfAttention(\r\n                    params[\"hidden_size\"], params[\"num_heads\"],\r\n                    params[\"attention_dropout\"])\r\n                enc_dec_attention_layer = attention_layer.Attention(\r\n                    params[\"hidden_size\"], params[\"num_heads\"],\r\n                    params[\"attention_dropout\"])\r\n            else:\r\n                self_attention_layer = fast_attention.SelfAttention(  # ==========use fast_attention=============\r\n                    params[\"hidden_size\"], params[\"num_heads\"],\r\n                    params[\"attention_dropout\"],\r\n                    kernel_transformation=fast_attention.softmax_kernel_transformation,\r\n                    causal=True,\r\n                    projection_matrix_type=1,\r\n                    nb_random_features=nb_random_features,  # =============100(model hidden size is 512)============\r\n                )\r\n                enc_dec_attention_layer = fast_attention.Attention(  # ==========use fast_attention=============\r\n                    params[\"hidden_size\"], params[\"num_heads\"],\r\n                    params[\"attention_dropout\"],\r\n                    kernel_transformation=fast_attention.softmax_kernel_transformation,\r\n                    causal=False,\r\n                    projection_matrix_type=1,\r\n                    nb_random_features=nb_random_features,\r\n                )\r\n            feed_forward_network = ffn_layer.FeedForwardNetwork(\r\n                params[\"hidden_size\"], params[\"filter_size\"], params[\"relu_dropout\"])\r\n\r\n            self.layers.append([\r\n                PrePostProcessingWrapper(self_attention_layer, params),  # x->LNorm(x)->{layer(x)=y}->Dropout(y)->y+x\r\n                PrePostProcessingWrapper(enc_dec_attention_layer, params),\r\n                PrePostProcessingWrapper(feed_forward_network, params)\r\n            ])\r\n        self.output_normalization = tf.keras.layers.LayerNormalization(\r\n            epsilon=1e-6, dtype=\"float32\")\r\n        super(DecoderStack, self).build(input_shape)\r\n```\r\n\r\n2. The training stage is perfect, with good decoder outputs almost the same as the targets. An example is, if the target is **\"He is playing basktball in the basketball gym\"**, the output could be the same.\r\n\r\n3. But when doing inference, the decoder outputs are very bad. The output for the above example now is **\"He is playing is playing is playing is playing is playing </s>\"**, even more worse with **\"He He He He He He He He He He He He </s>\"**.\r\n\r\n4. I just change the mode from \"train\" to \"predict\", and use beam search. Whether setting beam_size=1 or not, the output is the same and bad.\r\n\r\n5. When doing inference, I check the **decoder attention output(layer0)** in \"fast_attention.py>Attention>call()\", the states between beams of an sample are almost the same in step 2. \r\n![image](https://user-images.githubusercontent.com/7539692/103276792-7b107c00-4a02-11eb-8604-f9f72ae47bee.png)\r\n![image](https://user-images.githubusercontent.com/7539692/103276588-ec9bfa80-4a01-11eb-9c57-c4edb4565d63.png)\r\n\r\n> It seams images can't be displayed: \r\n```      \r\n        if cache is not None:\r\n            # Combine cached keys and values with new keys and values.\r\n            if decode_loop_step is not None:\r\n                cache_k_shape = cache[\"k\"].shape.as_list()\r\n                indices = tf.reshape(\r\n                    tf.one_hot(decode_loop_step, cache_k_shape[1], dtype=key.dtype),\r\n                    [1, cache_k_shape[1], 1, 1])\r\n                key = cache[\"k\"] + key * indices\r\n                cache_v_shape = cache[\"v\"].shape.as_list()\r\n                indices = tf.reshape(\r\n                    tf.one_hot(decode_loop_step, cache_v_shape[1], dtype=value.dtype),\r\n                    [1, cache_v_shape[1], 1, 1])\r\n                value = cache[\"v\"] + value * indices\r\n        else:\r\n            key = tf.concat([tf.cast(cache[\"k\"], key.dtype), key], axis=1)\r\n            value = tf.concat([tf.cast(cache[\"v\"], value.dtype), value], axis=1)\r\n    \r\n            # Update cache\r\n            cache[\"k\"] = key\r\n            cache[\"v\"] = value\r\n\r\n        attention_output = favor_attention(query, key, value,\r\n                                           self.kernel_transformation, self.causal,\r\n                                           bias, projection_matrix)\r\n        \r\n        # the attention_output is: \r\n        attention_output = tf.Tensor(\r\n        [[-9.661879   2.9591107  1.3627272 ... -5.7556434 -4.247857   5.5499997]\r\n         [-9.661878   2.9591098  1.3627269 ... -5.7556424 -4.247855   5.55     ]\r\n         [-9.661879   2.9591098  1.3627272 ... -5.755643  -4.247857   5.5499997]\r\n         [-9.661878   2.9591103  1.3627266 ... -5.755642  -4.2478557  5.549999 ]\r\n         [-9.661879   2.9591098  1.3627272 ... -5.7556434 -4.247856   5.5499997]], shape=(5, 512), dtype=float32)\r\n```\r\n\r\n6. Using the raw code and the built-in keras attention, everying is good.","closed_by":{"login":"2020zyc","id":7539692,"node_id":"MDQ6VXNlcjc1Mzk2OTI=","avatar_url":"https://avatars.githubusercontent.com/u/7539692?v=4","gravatar_id":"","url":"https://api.github.com/users/2020zyc","html_url":"https://github.com/2020zyc","followers_url":"https://api.github.com/users/2020zyc/followers","following_url":"https://api.github.com/users/2020zyc/following{/other_user}","gists_url":"https://api.github.com/users/2020zyc/gists{/gist_id}","starred_url":"https://api.github.com/users/2020zyc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/2020zyc/subscriptions","organizations_url":"https://api.github.com/users/2020zyc/orgs","repos_url":"https://api.github.com/users/2020zyc/repos","events_url":"https://api.github.com/users/2020zyc/events{/privacy}","received_events_url":"https://api.github.com/users/2020zyc/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/508/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/508/timeline","performed_via_github_app":null,"state_reason":null}