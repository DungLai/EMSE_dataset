{"url":"https://api.github.com/repos/google-research/google-research/issues/801","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/801/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/801/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/801/events","html_url":"https://github.com/google-research/google-research/issues/801","id":981124401,"node_id":"MDU6SXNzdWU5ODExMjQ0MDE=","number":801,"title":"[TFT] Computing Validation Loss: Zero-Dimensional arrays cannot be concatenated","user":{"login":"Hinnerk8","id":88584787,"node_id":"MDQ6VXNlcjg4NTg0Nzg3","avatar_url":"https://avatars.githubusercontent.com/u/88584787?v=4","gravatar_id":"","url":"https://api.github.com/users/Hinnerk8","html_url":"https://github.com/Hinnerk8","followers_url":"https://api.github.com/users/Hinnerk8/followers","following_url":"https://api.github.com/users/Hinnerk8/following{/other_user}","gists_url":"https://api.github.com/users/Hinnerk8/gists{/gist_id}","starred_url":"https://api.github.com/users/Hinnerk8/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Hinnerk8/subscriptions","organizations_url":"https://api.github.com/users/Hinnerk8/orgs","repos_url":"https://api.github.com/users/Hinnerk8/repos","events_url":"https://api.github.com/users/Hinnerk8/events{/privacy}","received_events_url":"https://api.github.com/users/Hinnerk8/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-08-27T10:50:47Z","updated_at":"2021-09-07T16:58:50Z","closed_at":"2021-09-07T08:58:01Z","author_association":"NONE","active_lock_reason":null,"body":"Hey, \r\ni am trying to run the temporal fusion transformer network on my own data. \r\n\r\nThe test with the default datasets volatility and traffic worked out without any problem. \r\n\r\nWhen using my own dataset, i receive an error when the network starts computing the validation loss: \r\n\r\n`Done.\r\nComputing best validation loss\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Noah\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"C:\\Users\\Noah\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\Noah\\tft\\script_train_fixed_params.py\", line 238, in <module>\r\n    use_testing_mode=True)  # Change to false to use original default params\r\n  File \"C:\\Users\\Noah\\tft\\script_train_fixed_params.py\", line 151, in main\r\n    val_loss = model.evaluate(valid)\r\n  File \"C:\\Users\\Noah\\tft\\libs\\tft_model.py\", line 1189, in evaluate\r\n    raw_data = self._batch_data(data)\r\n  File \"C:\\Users\\Noah\\tft\\libs\\tft_model.py\", line 763, in _batch_data\r\n    data_map[k] = np.concatenate(data_map[k], axis=0)\r\n  File \"<__array_function__ internals>\", line 6, in concatenate\r\nValueError: zero-dimensional arrays cannot be concatenated`\r\n\r\nI followed the instruction of creating a new data-formatterclass for my experiment. I added column-definitions equal to those in traffic and volatility experiment: \r\n`_column_definition = [\r\n      ('id', DataTypes.REAL_VALUED, InputTypes.ID),\r\n      ('Minutengesamt', DataTypes.REAL_VALUED, InputTypes.TIME),\r\n      ('Gasmengenstrom', DataTypes.REAL_VALUED, InputTypes.TARGET),\r\n      ('Gesamtwasser', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\r\n      ('Gesamtschlamm', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\r\n      ('Tag', DataTypes.CATEGORICAL, InputTypes.KNOWN_INPUT),\r\n      ('Jahr', DataTypes.CATEGORICAL, InputTypes.KNOWN_INPUT),\r\n      ('Stunde', DataTypes.CATEGORICAL, InputTypes.KNOWN_INPUT),\r\n      ('Minute', DataTypes.CATEGORICAL, InputTypes.KNOWN_INPUT),\r\n      ('CatID', DataTypes.CATEGORICAL, InputTypes.STATIC_INPUT),\r\n  ]`\r\n\r\nAnd I am splitting my dataset: \r\n`def split_data(self, df, valid_boundary=26300, test_boundary=30700):\r\n    \"\"\"Splits data frame into training-validation-test data frames.\r\n\r\n    This also calibrates scaling object, and transforms data for each split.\r\n\r\n    Args:\r\n      df: Source data frame to split.\r\n      valid_boundary: Starting year for validation data\r\n      test_boundary: Starting year for test data\r\n\r\n    Returns:\r\n      Tuple of transformed (train, valid, test) data.\r\n    \"\"\"\r\n\r\n    print('Formatting train-valid-test splits.')\r\n\r\n    index = df['indall']\r\n    train = df.loc[index < valid_boundary]\r\n    valid = df.loc[(index >= valid_boundary) & (index < test_boundary)]\r\n    test = df.loc[(index >= test_boundary) & (index <= 34631)]`\r\n\r\nI did not change anything else in comparison to the volatility default experiment. \r\nMy complete dataset consists out of 35136 rows - so i left out the last lines, like in the volatility experiment it is performed. Although i dont understand so far, why this is done. \r\n\r\nCan somebody explain to me, what I would need to change and why those last lines are left out?\r\n\r\nThank you in advanced!\r\nHinnerk8\r\n\r\n\r\n","closed_by":{"login":"Hinnerk8","id":88584787,"node_id":"MDQ6VXNlcjg4NTg0Nzg3","avatar_url":"https://avatars.githubusercontent.com/u/88584787?v=4","gravatar_id":"","url":"https://api.github.com/users/Hinnerk8","html_url":"https://github.com/Hinnerk8","followers_url":"https://api.github.com/users/Hinnerk8/followers","following_url":"https://api.github.com/users/Hinnerk8/following{/other_user}","gists_url":"https://api.github.com/users/Hinnerk8/gists{/gist_id}","starred_url":"https://api.github.com/users/Hinnerk8/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Hinnerk8/subscriptions","organizations_url":"https://api.github.com/users/Hinnerk8/orgs","repos_url":"https://api.github.com/users/Hinnerk8/repos","events_url":"https://api.github.com/users/Hinnerk8/events{/privacy}","received_events_url":"https://api.github.com/users/Hinnerk8/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/801/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/801/timeline","performed_via_github_app":null,"state_reason":"completed"}