{"url":"https://api.github.com/repos/google-research/google-research/issues/880","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/880/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/880/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/880/events","html_url":"https://github.com/google-research/google-research/issues/880","id":1049929189,"node_id":"I_kwDOCQmIhc4-lKXl","number":880,"title":"[depth_and_motion_learning]  Unsupervised Monocular Depth and Motion Learning fails with NaN loss during training","user":{"login":"carloradice","id":24611784,"node_id":"MDQ6VXNlcjI0NjExNzg0","avatar_url":"https://avatars.githubusercontent.com/u/24611784?v=4","gravatar_id":"","url":"https://api.github.com/users/carloradice","html_url":"https://github.com/carloradice","followers_url":"https://api.github.com/users/carloradice/followers","following_url":"https://api.github.com/users/carloradice/following{/other_user}","gists_url":"https://api.github.com/users/carloradice/gists{/gist_id}","starred_url":"https://api.github.com/users/carloradice/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/carloradice/subscriptions","organizations_url":"https://api.github.com/users/carloradice/orgs","repos_url":"https://api.github.com/users/carloradice/repos","events_url":"https://api.github.com/users/carloradice/events{/privacy}","received_events_url":"https://api.github.com/users/carloradice/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-11-10T14:56:02Z","updated_at":"2021-11-24T15:35:31Z","closed_at":"2021-11-24T15:35:31Z","author_association":"NONE","active_lock_reason":null,"body":"Hi, I'm currently trying to resolve this problem when I run the training on GPU.\r\nI am using ubuntu 16.04.6 LTS and a conda environment with:\r\n- python 3.7\r\n- tensorflow 1.15\r\n- tensorflow-graphics 1.0.0\r\n- matplotlib 3.3.0\r\n- CUDA version 10.2\r\n\r\nMy GPU is a\r\n- NVIDIA GeForce GTX 1080 Ti\r\n\r\nI set the env variable  \r\n$LD_LIBRARY_PATH  to /usr/local/cuda-10.2/targets/x86_64-linux/lib\r\n$PATH to /usr/local/cuda-10.2/bin\r\n\r\nI read that there is a CUDA bug in version 10.0 in #162, but I get a similar error even with CUDA 10.2 .\r\nThe training starts ok but shortly after I get:\r\n- Model diverged with loss = NaN.\r\nand then\r\n- tensorflow.python.training.basic_session_run_hooks.NanLossDuringTrainingError: NaN loss during training\r\n\r\nThis error as far as I know, only happens when I run the training using the GPU.\r\n\r\n\r\nI really appreciate any help, thanks.\r\n","closed_by":{"login":"carloradice","id":24611784,"node_id":"MDQ6VXNlcjI0NjExNzg0","avatar_url":"https://avatars.githubusercontent.com/u/24611784?v=4","gravatar_id":"","url":"https://api.github.com/users/carloradice","html_url":"https://github.com/carloradice","followers_url":"https://api.github.com/users/carloradice/followers","following_url":"https://api.github.com/users/carloradice/following{/other_user}","gists_url":"https://api.github.com/users/carloradice/gists{/gist_id}","starred_url":"https://api.github.com/users/carloradice/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/carloradice/subscriptions","organizations_url":"https://api.github.com/users/carloradice/orgs","repos_url":"https://api.github.com/users/carloradice/repos","events_url":"https://api.github.com/users/carloradice/events{/privacy}","received_events_url":"https://api.github.com/users/carloradice/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/880/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/880/timeline","performed_via_github_app":null,"state_reason":"completed"}