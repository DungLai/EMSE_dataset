{"url":"https://api.github.com/repos/google-research/google-research/issues/393","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/393/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/393/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/393/events","html_url":"https://github.com/google-research/google-research/issues/393","id":702646073,"node_id":"MDU6SXNzdWU3MDI2NDYwNzM=","number":393,"title":"[uq-uncertainty] vanilla accuracy 20 news (even classes) unreachable","user":{"login":"Jordy-VL","id":16034009,"node_id":"MDQ6VXNlcjE2MDM0MDA5","avatar_url":"https://avatars.githubusercontent.com/u/16034009?v=4","gravatar_id":"","url":"https://api.github.com/users/Jordy-VL","html_url":"https://github.com/Jordy-VL","followers_url":"https://api.github.com/users/Jordy-VL/followers","following_url":"https://api.github.com/users/Jordy-VL/following{/other_user}","gists_url":"https://api.github.com/users/Jordy-VL/gists{/gist_id}","starred_url":"https://api.github.com/users/Jordy-VL/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Jordy-VL/subscriptions","organizations_url":"https://api.github.com/users/Jordy-VL/orgs","repos_url":"https://api.github.com/users/Jordy-VL/repos","events_url":"https://api.github.com/users/Jordy-VL/events{/privacy}","received_events_url":"https://api.github.com/users/Jordy-VL/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-09-16T10:26:27Z","updated_at":"2020-09-30T08:59:28Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"The appendix of the paper mentions reaching 95.5% accuracy for 20news with the detailed hyperparameter settings. \r\nWhatever I do, I can never exceed 40% accuracy on the in-distribution data [even data]. \r\nDid they mean AUC? \r\nOn all 20 classes I manage to reach 80% accuracy both with a textCNN and LSTM. \r\n\r\nI add in my Sacred config for comparison: \r\n```@ex.named_config\r\ndef ovadia_20news():\r\n    \"\"\"\r\n    %maxdoclen 250; max_vocabulary 30000\r\n    %The vanilla model uses a one-layer LSTM model of size 32 and a dense layer to predict the 10 class\r\n    % probabilities based on word embedding of size 128. A dropout rate of 0.1 is applied to both the LSTM\r\n    % layer and the dense layer for the Dropout model. The LL-SVI model replaces the last dense layer\r\n    % with a Bayesian layer, the ensemble model aggregates 10 vanilla models, and stochastic methods\r\n    % sample 5 predictions per example. The vanilla model accuracy for in-distribution test data is 0.955.\r\n    \"\"\"\r\n    identifier = \"20news\"\r\n    data_folder = os.path.join(DATAROOT, identifier)\r\n    out_folder = generate_out_folder(data_folder)\r\n    task = \"document_classification\"  # or regression\r\n    max_vocabulary = 30000  # 20news to 30K e.g.\r\n    composition = [\"word\"]\r\n\r\n    model = \"lstm\"\r\n    embed_dim = 128\r\n    projection_nodes = 32\r\n    dropout = 0.1\r\n    dropout_nonlinear = 0.1\r\n    embedding_dropout = 0\r\n    dropout_concrete = None\r\n    weight_decay = 0  # .0001  # triggers AdamW optimizer\r\n    max_document_len = 250\r\n\r\n    epochs = 48\r\n    optimizer = \"adam\"\r\n    clipnorm = 10\r\n    learning_rate = 0.001\r\n    steps_per_epoch = None  # could also be None\r\n\r\n    posterior_sampling = 10\r\n    use_aleatorics = False\r\n    multilabel = False\r\n    loss_fn = \"categorical_crossentropy\" if not use_aleatorics else \"attenuated_learned_loss\"\r\n    metrics = [\"accuracy\", \"mse\"] if not use_aleatorics else []\r\n    ood = ['comp.graphics', 'comp.sys.ibm.pc.hardware', 'comp.windows.x', 'rec.autos', 'rec.sport.baseball', 'sci.crypt', 'sci.med', 'soc.religion.christian', 'talk.politics.mideast', 'talk.religion.misc']\r\n```","closed_by":null,"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/393/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/393/timeline","performed_via_github_app":null,"state_reason":null}