{"url":"https://api.github.com/repos/google-research/google-research/issues/534","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/534/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/534/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/534/events","html_url":"https://github.com/google-research/google-research/issues/534","id":789736483,"node_id":"MDU6SXNzdWU3ODk3MzY0ODM=","number":534,"title":"Question about Meta Pseudo Labels gradient signal","user":{"login":"HansPinckaers","id":70747,"node_id":"MDQ6VXNlcjcwNzQ3","avatar_url":"https://avatars.githubusercontent.com/u/70747?v=4","gravatar_id":"","url":"https://api.github.com/users/HansPinckaers","html_url":"https://github.com/HansPinckaers","followers_url":"https://api.github.com/users/HansPinckaers/followers","following_url":"https://api.github.com/users/HansPinckaers/following{/other_user}","gists_url":"https://api.github.com/users/HansPinckaers/gists{/gist_id}","starred_url":"https://api.github.com/users/HansPinckaers/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HansPinckaers/subscriptions","organizations_url":"https://api.github.com/users/HansPinckaers/orgs","repos_url":"https://api.github.com/users/HansPinckaers/repos","events_url":"https://api.github.com/users/HansPinckaers/events{/privacy}","received_events_url":"https://api.github.com/users/HansPinckaers/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":32,"created_at":"2021-01-20T08:00:29Z","updated_at":"2022-03-18T02:58:40Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi there,\r\n\r\nI really enjoyed reading the paper by @hyhieu et al.! I don't have the resources to train the models, or even run the code, but I do have some questions about the code. Especially about the loss of the teacher model. If I'm understanding correctly, the final loss is defined here: \r\n\r\nhttps://github.com/google-research/google-research/blob/ec13eb6661a7b9500016cc6d7e3ab940c2dbf184/meta_pseudo_labels/training_utils.py#L494-L496\r\n\r\nI have a question about the MPL term. `cross_entropy['mpl'] * dot_product`.\r\n\r\n`dot_product` seems to be a scalar (like mentioned in the paper), without gradient computation:\r\n\r\nhttps://github.com/google-research/google-research/blob/ec13eb6661a7b9500016cc6d7e3ab940c2dbf184/meta_pseudo_labels/training_utils.py#L483\r\n\r\n`cross_entropy['mpl']` seems to be defined a few lines above:\r\nhttps://github.com/google-research/google-research/blob/ec13eb6661a7b9500016cc6d7e3ab940c2dbf184/meta_pseudo_labels/training_utils.py#L484-L487\r\n\r\nThis seems to be a cross-entropy where the logits and targets are the same (since `softmax_cross_entropy` also applies a softmax to the logits). This loss can be non-zero when the targets are not 'hard' (soft targets), however, I don't think there is any signal in that case? Since the logits and targets seem to be equal. \r\n\r\nMy question is — if I'm understanding the code correctly — if there is no signal and it's scaled by the `dot_product`, I do not know what the value is of this term in the optimization?\r\n\r\nThanks again for your work!\r\nHans\r\n\r\nP.S. small side question: in the paper, it is mentioned the method uses hard-targets, but I cannot find this in the code.\r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/534/reactions","total_count":6,"+1":6,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/534/timeline","performed_via_github_app":null,"state_reason":null}