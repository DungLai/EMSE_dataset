{"url":"https://api.github.com/repos/google-research/google-research/issues/1227","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/1227/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/1227/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/1227/events","html_url":"https://github.com/google-research/google-research/issues/1227","id":1329627087,"node_id":"I_kwDOCQmIhc5PQH_P","number":1227,"title":"MBPP split / README","user":{"login":"stadlerb","id":2452384,"node_id":"MDQ6VXNlcjI0NTIzODQ=","avatar_url":"https://avatars.githubusercontent.com/u/2452384?v=4","gravatar_id":"","url":"https://api.github.com/users/stadlerb","html_url":"https://github.com/stadlerb","followers_url":"https://api.github.com/users/stadlerb/followers","following_url":"https://api.github.com/users/stadlerb/following{/other_user}","gists_url":"https://api.github.com/users/stadlerb/gists{/gist_id}","starred_url":"https://api.github.com/users/stadlerb/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stadlerb/subscriptions","organizations_url":"https://api.github.com/users/stadlerb/orgs","repos_url":"https://api.github.com/users/stadlerb/repos","events_url":"https://api.github.com/users/stadlerb/events{/privacy}","received_events_url":"https://api.github.com/users/stadlerb/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2022-08-05T08:33:31Z","updated_at":"2022-08-18T19:05:46Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I noticed that the [MBPP dataset on the Hugging Face hub](https://huggingface.co/datasets/mbpp) only contains a single \"test\" split encompassing the whole dataset, instead of a train-test split. While writing an [issue](https://github.com/huggingface/datasets/issues/4795) to correct this, it became apparent that the splits used for the experiments of the [\"Program Synthesis with Large Language Models\" paper](https://arxiv.org/abs/2108.07732) were not completely clear, at least to me.\r\n\r\nThe paper mentions a four-way split of the full variant of MBPP in subsection 2.1:\r\n> In the experiments described later in the paper, we hold out 10 problems for **few-shot prompting**, another 500 as our **test** dataset (which is used to evaluate both few-shot inference and fine-tuned models), 374 problems for **fine-tuning**, and the rest for **validation**.\r\n\r\nThe paper doesn't explicitly state the task ID ranges of the splits, but the [README.md from this repo](https://github.com/google-research/google-research/blob/master/mbpp/README.md), which is referenced in the paper, does:\r\n> We specify a train and test split to use for evaluation. Specifically:\r\n> \r\n> * Task IDs 11-510 are used for evaluation.\r\n> * Task IDs 1-10 and 511-1000 are used for training and/or prompting. We typically used 1-10 for few-shot prompting, although you can feel free to use any of the training examples.\r\n\r\nI.e. compared to the paper, the few-shot, train and validation splits are combined into one split, with a soft suggestion of using the first ten for few-shot prompting.\r\n\r\nIt is not explicitly stated whether the 374 fine-tuning samples mentioned in the paper have Task ID 511 to 784 or 601 to 974 or whether they were randomly sampled from Task ID 511 to 974. The total number of samples is misstated as 1000 instead of 974.\r\n\r\nRegarding the edited variant of the dataset, the paper states the following:\r\n> For evaluations involving the edited dataset, we perform comparisons with 100 problems that appear in both the original and edited dataset, using the same held out 10 problems for few-shot prompting and 374 problems for fine-tuning. \r\n\r\nThe language here doesn't appear to be very precise, as among the 10 few-shot problems, those with Task ID 1, 5 and 10 are not part of the edited variant, and many from the task_id range from 511 to 974 are missing (e.g. Task ID 511 to 553).\r\nI suppose the idea the Task ID ranges for each split remain the same, even if some of the task_ids are not present, but I think this should be stated explicitly (if it is the case).\r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/1227/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/1227/timeline","performed_via_github_app":null,"state_reason":null}