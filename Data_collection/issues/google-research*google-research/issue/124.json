{"url":"https://api.github.com/repos/google-research/google-research/issues/124","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/124/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/124/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/124/events","html_url":"https://github.com/google-research/google-research/issues/124","id":521504712,"node_id":"MDU6SXNzdWU1MjE1MDQ3MTI=","number":124,"title":"[bam] bam/task_specific/classification/classification_tasks.py\", line 136, in featurize . self._distill_inputs[eid]) KeyError: 97","user":{"login":"vikotse","id":5728396,"node_id":"MDQ6VXNlcjU3MjgzOTY=","avatar_url":"https://avatars.githubusercontent.com/u/5728396?v=4","gravatar_id":"","url":"https://api.github.com/users/vikotse","html_url":"https://github.com/vikotse","followers_url":"https://api.github.com/users/vikotse/followers","following_url":"https://api.github.com/users/vikotse/following{/other_user}","gists_url":"https://api.github.com/users/vikotse/gists{/gist_id}","starred_url":"https://api.github.com/users/vikotse/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vikotse/subscriptions","organizations_url":"https://api.github.com/users/vikotse/orgs","repos_url":"https://api.github.com/users/vikotse/repos","events_url":"https://api.github.com/users/vikotse/events{/privacy}","received_events_url":"https://api.github.com/users/vikotse/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2019-11-12T11:53:14Z","updated_at":"2019-11-12T12:39:05Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I changed several config code position (includes `bert_dir` and `self.bert_config_file`) on `configure.Config`, so I can distill 12 layer teacher model's output to 3 layer student model by use another `bert_config_file`.\r\n\r\nI could train teacher model successfully.\r\nBut when I train the student model of distillation, error occurs.\r\n\r\ncommand for train teacher model:\r\n`python -m bam.run_classifier news-model-teacher $BAM_DIR '{\"debug\": false, \"task_names\": [\"news\"], \"pretrained_model_name\": \"chinese_L-12_H-768_A-12\", \"learning_rate\": 2e-5, \"num_train_epochs\": 3.0, \"distill\": false, \"max_seq_length\": 512, \"train_batch_size\": 4, \"save_checkpoints_steps\": 10000}'`\r\n\r\ncommand for train student model:\r\n`python -m bam.run_classifier news-model-student $BAM_DIR '{\"debug\": false, \"task_names\": [\"news\"], \"pretrained_model_name\": \"chinese_L-12_H-768_A-12\", \"learning_rate\": 2e-5, \"num_train_epochs\": 3.0, \"distill\": true, \"bert_config_file\": \"/home/work/repo/google-research-master/bam/bam_dir/pretrained_models/chinese_L-12_H-768_A-12/bert_config_3_layer.json\", \"teachers\": {\"news\": \"news-model-teacher\"}, \"max_seq_length\": 512, \"train_batch_size\": 4, \"save_checkpoints_steps\": 10000}'`\r\n\r\nerror message:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/work/anaconda2/envs/py3-tf.1.12/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/home/work/anaconda2/envs/py3-tf.1.12/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/data/repo/google-research-master/bam/run_classifier.py\", line 276, in <module>\r\n    tf.app.run()\r\n  File \"/home/work/anaconda2/envs/py3-tf.1.12/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run \r\n    _sys.exit(main(argv))\r\n  File \"/data/repo/google-research-master/bam/run_classifier.py\", line 253, in main\r\n    model_runner = ModelRunner(config, tasks)\r\n  File \"/data/repo/google-research-master/bam/run_classifier.py\", line 152, in __init__\r\n    sizes) = self._preprocessor.prepare_train()\r\n  File \"/data/repo/google-research-master/bam/data/preprocessing.py\", line 63, in prepare_train\r\n    return self._serialize_dataset(self._tasks, True, \"train\")\r\n  File \"/data/repo/google-research-master/bam/data/preprocessing.py\", line 108, in _serialize_dataset\r\n    self.serialize_examples(examples, is_training, tfrecords_path)\r\n  File \"/data/repo/google-research-master/bam/data/preprocessing.py\", line 127, in serialize_examples\r\n    tf_example = self._example_to_tf_example(example, is_training)\r\n  File \"/data/repo/google-research-master/bam/data/preprocessing.py\", line 136, in _example_to_tf_example\r\n    example, is_training))\r\n  File \"/data/repo/google-research-master/bam/task_specific/classification/classification_tasks.py\", line 136, in featurize\r\n    self._distill_inputs[eid])\r\nKeyError: 97\r\n```","closed_by":null,"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/124/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/124/timeline","performed_via_github_app":null,"state_reason":null}