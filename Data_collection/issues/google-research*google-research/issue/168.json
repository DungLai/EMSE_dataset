{"url":"https://api.github.com/repos/google-research/google-research/issues/168","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/168/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/168/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/168/events","html_url":"https://github.com/google-research/google-research/issues/168","id":533317240,"node_id":"MDU6SXNzdWU1MzMzMTcyNDA=","number":168,"title":"Rouge-L: Large differences to pyrouge/Rouge 1.5.5","user":{"login":"amarfurt","id":432593,"node_id":"MDQ6VXNlcjQzMjU5Mw==","avatar_url":"https://avatars.githubusercontent.com/u/432593?v=4","gravatar_id":"","url":"https://api.github.com/users/amarfurt","html_url":"https://github.com/amarfurt","followers_url":"https://api.github.com/users/amarfurt/followers","following_url":"https://api.github.com/users/amarfurt/following{/other_user}","gists_url":"https://api.github.com/users/amarfurt/gists{/gist_id}","starred_url":"https://api.github.com/users/amarfurt/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amarfurt/subscriptions","organizations_url":"https://api.github.com/users/amarfurt/orgs","repos_url":"https://api.github.com/users/amarfurt/repos","events_url":"https://api.github.com/users/amarfurt/events{/privacy}","received_events_url":"https://api.github.com/users/amarfurt/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2019-12-05T12:20:09Z","updated_at":"2019-12-12T11:05:24Z","closed_at":"2019-12-12T11:05:23Z","author_association":"NONE","active_lock_reason":null,"body":"I have evaluated the checkpoint of the paper [Text Summarization with Pretrained Encoders](https://arxiv.org/abs/1908.08345) with the pyrouge and the rouge-score packages. I observe rather large differences, especially for Rouge-L:\r\n\r\nWith pyrouge:\r\n```\r\nrouge_1_f_score      0.42164\r\nrouge_2_f_score      0.19486\r\nrouge_l_f_score      0.39156\r\n```\r\n\r\nWith rouge-score:\r\n```\r\nrouge_1_f_score      0.43707\r\nrouge_2_f_score      0.20137\r\nrouge_l_f_score      0.30160\r\n```\r\n\r\nMy procedure: The `validate` mode of the authors' code ([Github](https://github.com/nlpyang/PreSumm)) extracts candidate and reference summaries in text format. I then pass these to the authors' `test_rouge` function ([link](https://github.com/nlpyang/PreSumm/blob/ce8dc017fbef7c12b1b4bd764f0c3d20911ead5e/src/others/utils.py#L54)) (which to my understanding does no further processing except for preparing the file structure for pyrouge). For the rouge-score package I used the following code:\r\n```python\r\nscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\r\naggregator = BootstrapAggregator()\r\ncandidates = [line.strip() for line in open(candidates_path, encoding='utf-8')]\r\nreferences = [line.strip() for line in open(references_path, encoding='utf-8')]\r\nassert len(candidates) == len(references)\r\nfor i, (c, r) in enumerate(zip(candidates, references)):\r\n  aggregator.add_scores(scorer.score(r, c))\r\nresults = aggregator.aggregate()\r\n```\r\n\r\nThings I've checked:\r\n- There are no empty lines in candidate or reference summaries (after `.strip()`)\r\n- The other flags passed to pyrouge/Rouge-1.5.5 are equal \r\n- This behavior is consistent with different random seeds\r\n\r\n","closed_by":{"login":"amarfurt","id":432593,"node_id":"MDQ6VXNlcjQzMjU5Mw==","avatar_url":"https://avatars.githubusercontent.com/u/432593?v=4","gravatar_id":"","url":"https://api.github.com/users/amarfurt","html_url":"https://github.com/amarfurt","followers_url":"https://api.github.com/users/amarfurt/followers","following_url":"https://api.github.com/users/amarfurt/following{/other_user}","gists_url":"https://api.github.com/users/amarfurt/gists{/gist_id}","starred_url":"https://api.github.com/users/amarfurt/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amarfurt/subscriptions","organizations_url":"https://api.github.com/users/amarfurt/orgs","repos_url":"https://api.github.com/users/amarfurt/repos","events_url":"https://api.github.com/users/amarfurt/events{/privacy}","received_events_url":"https://api.github.com/users/amarfurt/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/168/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/168/timeline","performed_via_github_app":null,"state_reason":"completed"}