{"url":"https://api.github.com/repos/google-research/google-research/issues/773","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/773/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/773/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/773/events","html_url":"https://github.com/google-research/google-research/issues/773","id":956510500,"node_id":"MDU6SXNzdWU5NTY1MTA1MDA=","number":773,"title":"[Charformer] About the number of parameters of tall model.","user":{"login":"ogis-uno","id":1725331,"node_id":"MDQ6VXNlcjE3MjUzMzE=","avatar_url":"https://avatars.githubusercontent.com/u/1725331?v=4","gravatar_id":"","url":"https://api.github.com/users/ogis-uno","html_url":"https://github.com/ogis-uno","followers_url":"https://api.github.com/users/ogis-uno/followers","following_url":"https://api.github.com/users/ogis-uno/following{/other_user}","gists_url":"https://api.github.com/users/ogis-uno/gists{/gist_id}","starred_url":"https://api.github.com/users/ogis-uno/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ogis-uno/subscriptions","organizations_url":"https://api.github.com/users/ogis-uno/orgs","repos_url":"https://api.github.com/users/ogis-uno/repos","events_url":"https://api.github.com/users/ogis-uno/events{/privacy}","received_events_url":"https://api.github.com/users/ogis-uno/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-07-30T08:07:00Z","updated_at":"2021-08-02T04:01:52Z","closed_at":"2021-08-02T04:01:52Z","author_association":"NONE","active_lock_reason":null,"body":"Hi, \r\nI'm trying to run the charformer, and have some questions.\r\n\r\nAt first,  In \"Integration Steps\" in README.md,  I found a variable `self.num_gsw_layers` and I can't find any clue to set correct value.  what value shoud be set to `self.num_gsw_layers`? \r\nI used  `self.num_gsw_layers = 1` for now.\r\n\r\nThen I tried to run Chaformer_tall. the paper says,\r\n\r\n> Our small model follows the T5 small model size with 6 encoder layers and 6 decoder layers, hidden size d_model of 512, 8 heads, d_kv of 32 and d_ff of 2048. This corresponds to bi_v1_small.gin in the T5 codebase. \r\n>...\r\n> The tall model has 24 encoder layers and 6 decoder layers, while the remainder of its hyperparameters remain identical\r\nto the small model. \r\n\r\nSo, I included `bi_v1_small.gin` . and set `num_layers` to 24(encoder) and 6(decoder). My configuration is as follows,\r\n```\r\nimport charformer.lib.charformer_layers\r\ninclude 'models/bi_v1_small.gin'\r\n\r\nGradientSubwordLayerV2.key_value_size = %d_kv\r\nGradientSubwordLayerV2.num_heads = %num_heads\r\nGradientSubwordLayerV2.dropout_rate = %dropout_rate\r\nGradientSubwordLayerV2.downsample_query = 3.0\r\nGradientSubwordLayerV2.radius = 8\r\nGradientSubwordLayerV2.low_rank_features = 32\r\nGradientSubwordLayerV2.project_kv = False\r\nGradientSubwordLayerV2.use_ffn = False\r\nGradientSubwordLayerV2.local_gate = False\r\nGradientSubwordLayerV2.num_memory_slots = 0\r\nGradientSubwordLayerV2.local_attention = False\r\nGradientSubwordLayerV2.consider_chars_as_blocks = True\r\nGradientSubwordLayerV2.conv_type = \"conv1d\"\r\n\r\nencoder/Unitransformer.gradient_subwords = True\r\n\r\nmake_layer_stack.layer_stack_cls=@charformer_layers.CharformerLayerStack\r\n\r\nencoder/Unitransformer.gradient_subword_layer = @charformer_layers.GradientSubwordLayerV2\r\n\r\nencoder/transformer.make_layer_stack.num_layers = 24\r\ndecoder/transformer.make_layer_stack.num_layers = 6\r\n\r\nmesh_train_dataset_fn.pack = False\r\n```\r\n\r\nI ran charfomer with this configuration, and pick the number of parameters from the log messages.\r\n```\r\nINFO:tensorflow:Trainable Variables            count: 209     Total size: 102206464        Total slice_size: 102206464      \r\nINFO:tensorflow:All Variables                  count: 221     Total size: 102549376        Total slice_size: 102549376     \r\n```\r\n\r\nthe paper says chaformer_tall has 134M params, but I got 102,549,376. This is a big difference.   \r\nCould you tell me where this difference come from?\r\n\r\nMy environment.\r\n* Colab runtime with TPU.\r\n* tensorflow : 2.5.0\r\n* mesh-tensorflow : 0.1.19\r\n* t5 : 0.9.1\r\n* multilingual-t5 : 35f72315\r\n* byt5 : 069d3cbc\r\n* charformer(google-research) : 111c4ff4a\r\n* I borrowed \"byt5_wiki.ja\" task from byt5 for pre-training task.","closed_by":{"login":"ogis-uno","id":1725331,"node_id":"MDQ6VXNlcjE3MjUzMzE=","avatar_url":"https://avatars.githubusercontent.com/u/1725331?v=4","gravatar_id":"","url":"https://api.github.com/users/ogis-uno","html_url":"https://github.com/ogis-uno","followers_url":"https://api.github.com/users/ogis-uno/followers","following_url":"https://api.github.com/users/ogis-uno/following{/other_user}","gists_url":"https://api.github.com/users/ogis-uno/gists{/gist_id}","starred_url":"https://api.github.com/users/ogis-uno/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ogis-uno/subscriptions","organizations_url":"https://api.github.com/users/ogis-uno/orgs","repos_url":"https://api.github.com/users/ogis-uno/repos","events_url":"https://api.github.com/users/ogis-uno/events{/privacy}","received_events_url":"https://api.github.com/users/ogis-uno/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/773/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/773/timeline","performed_via_github_app":null,"state_reason":"completed"}