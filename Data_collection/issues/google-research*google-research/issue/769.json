{"url":"https://api.github.com/repos/google-research/google-research/issues/769","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/769/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/769/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/769/events","html_url":"https://github.com/google-research/google-research/issues/769","id":952818821,"node_id":"MDU6SXNzdWU5NTI4MTg4MjE=","number":769,"title":"[HITNet] Code stops running on Google colab after creating a 'Tensorflow device'","user":{"login":"Sarthak-22","id":63162679,"node_id":"MDQ6VXNlcjYzMTYyNjc5","avatar_url":"https://avatars.githubusercontent.com/u/63162679?v=4","gravatar_id":"","url":"https://api.github.com/users/Sarthak-22","html_url":"https://github.com/Sarthak-22","followers_url":"https://api.github.com/users/Sarthak-22/followers","following_url":"https://api.github.com/users/Sarthak-22/following{/other_user}","gists_url":"https://api.github.com/users/Sarthak-22/gists{/gist_id}","starred_url":"https://api.github.com/users/Sarthak-22/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Sarthak-22/subscriptions","organizations_url":"https://api.github.com/users/Sarthak-22/orgs","repos_url":"https://api.github.com/users/Sarthak-22/repos","events_url":"https://api.github.com/users/Sarthak-22/events{/privacy}","received_events_url":"https://api.github.com/users/Sarthak-22/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-26T11:50:08Z","updated_at":"2021-07-27T06:27:35Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I tried to run the code on Google Colab and this is the output that I got -\r\n```\r\n2021-07-26 11:24:31.361832: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\n2021-07-26 11:24:32.907777: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\r\n2021-07-26 11:24:32.970575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-07-26 11:24:32.971227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\r\ncoreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\r\n2021-07-26 11:24:32.971284: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\n2021-07-26 11:24:33.154572: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\r\n2021-07-26 11:24:33.154694: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\r\n2021-07-26 11:24:33.259957: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\r\n2021-07-26 11:24:33.312886: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\r\n2021-07-26 11:24:33.559715: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\r\n2021-07-26 11:24:33.617689: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\r\n2021-07-26 11:24:33.623997: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\r\n2021-07-26 11:24:33.624181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-07-26 11:24:33.624909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-07-26 11:24:33.627938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n2021-07-26 11:24:33.628872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-07-26 11:24:33.629559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\r\ncoreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\r\n2021-07-26 11:24:33.629649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-07-26 11:24:33.630282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-07-26 11:24:33.630836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n2021-07-26 11:24:33.632529: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\n2021-07-26 11:24:38.774730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-07-26 11:24:38.774779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \r\n2021-07-26 11:24:38.774795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \r\n2021-07-26 11:24:38.774971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-07-26 11:24:38.775604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-07-26 11:24:38.776196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-07-26 11:24:38.776739: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\r\n2021-07-26 11:24:38.776822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\r\n```\r\n\r\nThe code literally stops after the last execution. There are no errors thrown at all. What can be the solution to this?\r\n\r\nOn a side note, when will the pre-trained model for the paper be released? My work just requires inference results for images on pre-trained models so it would be great if the authors can release the pre-trained implementation anytime soon.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/769/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/769/timeline","performed_via_github_app":null,"state_reason":null}