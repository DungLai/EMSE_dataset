{"url":"https://api.github.com/repos/google-research/google-research/issues/251","repository_url":"https://api.github.com/repos/google-research/google-research","labels_url":"https://api.github.com/repos/google-research/google-research/issues/251/labels{/name}","comments_url":"https://api.github.com/repos/google-research/google-research/issues/251/comments","events_url":"https://api.github.com/repos/google-research/google-research/issues/251/events","html_url":"https://github.com/google-research/google-research/issues/251","id":611316225,"node_id":"MDU6SXNzdWU2MTEzMTYyMjU=","number":251,"title":"Example script for WT5 hangs","user":{"login":"poset","id":5651827,"node_id":"MDQ6VXNlcjU2NTE4Mjc=","avatar_url":"https://avatars.githubusercontent.com/u/5651827?v=4","gravatar_id":"","url":"https://api.github.com/users/poset","html_url":"https://github.com/poset","followers_url":"https://api.github.com/users/poset/followers","following_url":"https://api.github.com/users/poset/following{/other_user}","gists_url":"https://api.github.com/users/poset/gists{/gist_id}","starred_url":"https://api.github.com/users/poset/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/poset/subscriptions","organizations_url":"https://api.github.com/users/poset/orgs","repos_url":"https://api.github.com/users/poset/repos","events_url":"https://api.github.com/users/poset/events{/privacy}","received_events_url":"https://api.github.com/users/poset/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-05-03T02:25:01Z","updated_at":"2020-05-03T07:55:16Z","closed_at":"2020-05-03T07:55:16Z","author_association":"NONE","active_lock_reason":null,"body":"(EDIT: posted same issue in T5 main repo, which is probably a better fit. I'm okay with this being deleted, which I can't do.)\r\n\r\nThe example script for WT5 is hanging for me, and I'm not sure why. It can connect to my TPU and downloads/extracts a dataset, but then appears to do nothing after finishing the extraction (TPU shows 0.1% usage, no further prints).\r\n\r\nI set it to 2x4 tpu topology and set batch size to 2048 tokens.\r\n\r\nScript shown, then console output\r\n\r\n\r\n# Script based on provided script in  WT5 readme\r\n\r\n`export PROJECT=my-project-name\r\nexport ZONE=us-central1-b\r\nexport BUCKET=gs://my-bucket-name\r\nexport TPU=node-2\r\n\r\nctpu up   --name=$TPU   --project=$PROJECT  --zone=$ZONE   --tpu-size=v3-8   --tpu-only   --noconf \r\n\r\nTASK=movie_rationales_explanations_take1000_v010\r\nPRETRAINED_DIR=gs://t5-data/pretrained_models/small\r\nPRETRAINED_STEPS=1000000\r\nFINETUNE_STEPS=20000\r\nMODEL_DIR=\"${BUCKET}/${TASK}\"\r\n\r\nt5_mesh_transformer \\\r\n  --tpu=\"${TPU}\" \\\r\n  --gcp_project=\"${PROJECT}\" \\\r\n  --tpu_zone=\"${ZONE}\" \\\r\n  --model_dir=\"${MODEL_DIR}\" \\\r\n  --gin_file=\"dataset.gin\" \\\r\n  --gin_file=\"${PRETRAINED_DIR}/operative_config.gin\" \\\r\n  --gin_file=\"wt5/gin/sequence_lengths/movie_rationales_v010.gin\" \\\r\n  --gin_param=\"utils.tpu_mesh_shape.tpu_topology = '2x4'\" \\\r\n  --gin_param=\"MIXTURE_NAME = '${TASK}'\" \\\r\n  --gin_param=\"mesh_train_dataset_fn.use_cached=False\" \\\r\n  --gin_param=\"utils.run.save_checkpoints_steps=100\" \\\r\n  --gin_param=\"utils.run.batch_size=('tokens_per_batch', 16384)\" \\\r\n  --gin_param=\"utils.run.train_steps=$((PRETRAINED_STEPS+FINETUNE_STEPS))\" \\\r\n  --gin_param=\"utils.run.init_checkpoint='${PRETRAINED_DIR}/model.ckpt-${PRETRAINED_STEPS}'\" \\\r\n  --gin_param=\"utils.run.learning_rate_schedule=@learning_rate_schedules.constant_learning_rate\" \\\r\n  --gin_param=\"constant_learning_rate.learning_rate=1e-3\" \\\r\n  --t5_tfds_data_dir=\"${BUCKET}/t5-tfds\" \\\r\n  --module_import=\"wt5.tasks\" \\\r\n  --module_import=\"wt5.mixtures\" \\\r\n  --gin_location_prefix=\"wt5/wt5/gin/\"\r\n`\r\n# Console Output. \r\n(Note it shows no sign of any activity at the end, and doesn't return to bash)\r\n\r\n\r\n`:~/google-research/wt5$ ./testingWT5scriptGCP_TPU \r\n2020/05/03 02:05:37 TPU already running.\r\nOperation success; not ssh-ing to GCE VM due to --tpu-only flag.\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nnon-resource variables are not supported in the long term\r\nINFO:tensorflow:model_type=bitransformer\r\nI0503 02:05:43.398267 140562852878144 utils.py:1685] model_type=bitransformer\r\nINFO:tensorflow:mode=train\r\nI0503 02:05:43.398564 140562852878144 utils.py:1686] mode=train\r\nINFO:tensorflow:sequence_length={'inputs': 2048, 'targets': 512}\r\nI0503 02:05:43.398667 140562852878144 utils.py:1687] sequence_length={'inputs': 2048, 'targets': 512}\r\nINFO:tensorflow:batch_size=8\r\nI0503 02:05:43.398747 140562852878144 utils.py:1688] batch_size=8\r\nINFO:tensorflow:train_steps=1020000\r\nI0503 02:05:43.398822 140562852878144 utils.py:1689] train_steps=1020000\r\nINFO:tensorflow:mesh_shape=Shape[batch=16]\r\nI0503 02:05:43.398901 140562852878144 utils.py:1690] mesh_shape=Shape[batch=16]\r\nINFO:tensorflow:layout_rules=ensemble:ensemble,batch:batch,d_ff:model,heads:model,vocab:model,experts:batch\r\nI0503 02:05:43.398976 140562852878144 utils.py:1691] layout_rules=ensemble:ensemble,batch:batch,d_ff:model,heads:model,vocab:model,experts:batch\r\nINFO:tensorflow:Building TPUConfig with tpu_job_name=None\r\nI0503 02:05:43.403095 140562852878144 utils.py:1706] Building TPUConfig with tpu_job_name=None\r\nI0503 02:05:43.406050 140562852878144 discovery.py:280] URL being requested: GET https://www.googleapis.com/discovery/v1/apis/tpu/v1/rest\r\nI0503 02:05:43.441212 140562852878144 discovery.py:911] URL being requested: GET https://tpu.googleapis.com/v1/projects/t5-ignition/locations/us-central1-b/nodes/node-2?alt=json\r\nI0503 02:05:43.441443 140562852878144 transport.py:151] Attempting refresh to obtain initial access_token\r\nI0503 02:05:43.503969 140562852878144 discovery.py:280] URL being requested: GET https://www.googleapis.com/discovery/v1/apis/tpu/v1/rest\r\nI0503 02:05:43.534800 140562852878144 discovery.py:911] URL being requested: GET https://tpu.googleapis.com/v1/projects/t5-ignition/locations/us-central1-b/nodes/node-2?alt=json\r\nI0503 02:05:43.535020 140562852878144 transport.py:151] Attempting refresh to obtain initial access_token\r\nINFO:tensorflow:Using config: {'_model_dir': 'gs://t5-ignition-bucket/movie_rationales_explanations_take1000_v010', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\r\ncluster_def {\r\n  job {\r\n    name: \"worker\"\r\n    tasks {\r\n      key: 0\r\n      value: \"10.9.81.234:8470\"\r\n    }\r\n  }\r\n}\r\nisolate_session_state: true\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.9.81.234:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.9.81.234:8470', '_evaluation_master': 'grpc://10.9.81.234:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7fd6bce7b908>}\r\nI0503 02:05:43.584227 140562852878144 estimator.py:216] Using config: {'_model_dir': 'gs://t5-ignition-bucket/movie_rationales_explanations_take1000_v010', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\r\ncluster_def {\r\n  job {\r\n    name: \"worker\"\r\n    tasks {\r\n      key: 0\r\n      value: \"10.9.81.234:8470\"\r\n    }\r\n  }\r\n}\r\nisolate_session_state: true\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.9.81.234:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.9.81.234:8470', '_evaluation_master': 'grpc://10.9.81.234:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7fd6bce7b908>}\r\nINFO:tensorflow:_TPUContext: eval_on_tpu True\r\nI0503 02:05:43.584667 140562852878144 tpu_context.py:221] _TPUContext: eval_on_tpu True\r\nINFO:tensorflow:Querying Tensorflow master (grpc://10.9.81.234:8470) for TPU system metadata.\r\nI0503 02:05:43.709766 140562852878144 tpu_system_metadata.py:72] Querying Tensorflow master (grpc://10.9.81.234:8470) for TPU system metadata.\r\n2020-05-03 02:05:43.711139: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:373] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\r\nINFO:tensorflow:Initializing TPU system (master: grpc://10.9.81.234:8470) to fetch topology for model parallelism. This might take a while.\r\nI0503 02:05:43.716908 140562852878144 tpu_system_metadata.py:157] Initializing TPU system (master: grpc://10.9.81.234:8470) to fetch topology for model parallelism. This might take a while.\r\nINFO:tensorflow:Found TPU system:\r\nI0503 02:05:49.398839 140562852878144 tpu_system_metadata.py:140] Found TPU system:\r\nINFO:tensorflow:*** Num TPU Cores: 8\r\nI0503 02:05:49.399126 140562852878144 tpu_system_metadata.py:141] *** Num TPU Cores: 8\r\nINFO:tensorflow:*** Num TPU Workers: 1\r\nI0503 02:05:49.399248 140562852878144 tpu_system_metadata.py:142] *** Num TPU Workers: 1\r\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\r\nI0503 02:05:49.399342 140562852878144 tpu_system_metadata.py:144] *** Num TPU Cores Per Worker: 8\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 543705933573447767)\r\nI0503 02:05:49.399434 140562852878144 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 543705933573447767)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 9459511554632651815)\r\nI0503 02:05:49.399722 140562852878144 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 9459511554632651815)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10405845867630879762)\r\nI0503 02:05:49.399811 140562852878144 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10405845867630879762)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 1519635725069975015)\r\nI0503 02:05:49.399931 140562852878144 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 1519635725069975015)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 16532467575488418548)\r\nI0503 02:05:49.400012 140562852878144 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 16532467575488418548)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 9988226954971163265)\r\nI0503 02:05:49.400092 140562852878144 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 9988226954971163265)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 2095320529623114246)\r\nI0503 02:05:49.400168 140562852878144 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 2095320529623114246)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 5421484898729298314)\r\nI0503 02:05:49.400383 140562852878144 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 5421484898729298314)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 10057256119691496601)\r\nI0503 02:05:49.400545 140562852878144 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 10057256119691496601)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 9720856656554682660)\r\nI0503 02:05:49.400689 140562852878144 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 9720856656554682660)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 16735225736129679856)\r\nI0503 02:05:49.400792 140562852878144 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 16735225736129679856)\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nW0503 02:05:49.405328 140562852878144 deprecation.py:506] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nW0503 02:05:49.405760 140562852878144 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nINFO:tensorflow:Calling model_fn.\r\nI0503 02:05:49.412624 140562852878144 estimator.py:1151] Calling model_fn.\r\nI0503 02:05:49.850056 140562852878144 dataset_info.py:426] Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: movie_rationales/0.1.0\r\nI0503 02:05:49.879839 140562852878144 dataset_info.py:357] Load dataset info from /tmp/tmplb_43_hwtfds\r\nI0503 02:05:49.881754 140562852878144 dataset_info.py:397] Field info.description from disk and from code do not match. Keeping the one from code.\r\nI0503 02:05:49.881891 140562852878144 dataset_info.py:397] Field info.citation from disk and from code do not match. Keeping the one from code.\r\nI0503 02:05:50.003428 140562852878144 dataset_builder.py:333] Generating dataset movie_rationales (gs://t5-ignition-bucket/t5-tfds/movie_rationales/0.1.0)\r\nDownloading and preparing dataset movie_rationales/0.1.0 (download: 3.72 MiB, generated: Unknown size, total: 3.72 MiB) to gs://t5-ignition-bucket/t5-tfds/movie_rationales/0.1.0...\r\nDl Completed...: 0 url [00:00, ? url/s]          I0503 02:05:51.025692 140562852878144 download_manager.py:291] URL http://www.eraserbenchmark.com/zipped/movies.tar.gz already downloaded: reusing gs://t5-ignition-bucket/t5-tfds/downloads/eraserbenchmark.com_zipped_moviesZuGNTmyd-en1VEVysL_pKjlnP3Tsv8OFm0bO2y9bLe4.tar.gz.\r\nDl Completed...: 0 url [00:00, ? url/s] ? file/s]\r\nDl Size...: 0 MiB [00:00, ? `MiB/s]`\r\n\r\n","closed_by":{"login":"poset","id":5651827,"node_id":"MDQ6VXNlcjU2NTE4Mjc=","avatar_url":"https://avatars.githubusercontent.com/u/5651827?v=4","gravatar_id":"","url":"https://api.github.com/users/poset","html_url":"https://github.com/poset","followers_url":"https://api.github.com/users/poset/followers","following_url":"https://api.github.com/users/poset/following{/other_user}","gists_url":"https://api.github.com/users/poset/gists{/gist_id}","starred_url":"https://api.github.com/users/poset/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/poset/subscriptions","organizations_url":"https://api.github.com/users/poset/orgs","repos_url":"https://api.github.com/users/poset/repos","events_url":"https://api.github.com/users/poset/events{/privacy}","received_events_url":"https://api.github.com/users/poset/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/google-research/google-research/issues/251/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/google-research/issues/251/timeline","performed_via_github_app":null,"state_reason":"completed"}