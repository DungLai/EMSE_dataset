{"url":"https://api.github.com/repos/aimagelab/novelty-detection/issues/5","repository_url":"https://api.github.com/repos/aimagelab/novelty-detection","labels_url":"https://api.github.com/repos/aimagelab/novelty-detection/issues/5/labels{/name}","comments_url":"https://api.github.com/repos/aimagelab/novelty-detection/issues/5/comments","events_url":"https://api.github.com/repos/aimagelab/novelty-detection/issues/5/events","html_url":"https://github.com/aimagelab/novelty-detection/issues/5","id":469203460,"node_id":"MDU6SXNzdWU0NjkyMDM0NjA=","number":5,"title":"Loss exploding after few steps","user":{"login":"learnermaxRL","id":40789484,"node_id":"MDQ6VXNlcjQwNzg5NDg0","avatar_url":"https://avatars.githubusercontent.com/u/40789484?v=4","gravatar_id":"","url":"https://api.github.com/users/learnermaxRL","html_url":"https://github.com/learnermaxRL","followers_url":"https://api.github.com/users/learnermaxRL/followers","following_url":"https://api.github.com/users/learnermaxRL/following{/other_user}","gists_url":"https://api.github.com/users/learnermaxRL/gists{/gist_id}","starred_url":"https://api.github.com/users/learnermaxRL/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/learnermaxRL/subscriptions","organizations_url":"https://api.github.com/users/learnermaxRL/orgs","repos_url":"https://api.github.com/users/learnermaxRL/repos","events_url":"https://api.github.com/users/learnermaxRL/events{/privacy}","received_events_url":"https://api.github.com/users/learnermaxRL/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":22,"created_at":"2019-07-17T13:46:31Z","updated_at":"2019-07-19T07:09:27Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"`from functools import reduce\r\nfrom operator import mul\r\nfrom typing import Tuple\r\nimport numpy as np\r\nimport torch\r\nimport torchvision\r\nimport torch.nn as nn\r\nfrom models.loss_functions.lsaloss import LSALoss\r\nfrom models.base import BaseModule\r\nfrom models.blocks_2d import DownsampleBlock\r\nfrom models.blocks_2d import ResidualBlock\r\nfrom models.blocks_2d import UpsampleBlock\r\nfrom models.estimator_1D import Estimator1D\r\nimport cv2\r\n\r\nclass Encoder(BaseModule):\r\n    \"\"\"\r\n    CIFAR10 model encoder.\r\n    \"\"\"\r\n    def __init__(self, input_shape, code_length):\r\n        # type: (Tuple[int, int, int], int) -> None\r\n        \"\"\"\r\n        Class constructor:\r\n\r\n        :param input_shape: the shape of CIFAR10 samples.\r\n        :param code_length: the dimensionality of latent vectors.\r\n        \"\"\"\r\n        super(Encoder, self).__init__()\r\n\r\n        self.input_shape = input_shape\r\n        self.code_length = code_length\r\n\r\n        c, h, w = input_shape\r\n\r\n        print (c,h,w)\r\n\r\n        activation_fn = nn.LeakyReLU()\r\n\r\n        # Convolutional network\r\n        self.conv = nn.Sequential(\r\n            nn.Conv2d(in_channels=c, out_channels=32, kernel_size=3, bias=False),\r\n            activation_fn,\r\n            ResidualBlock(channel_in=32, channel_out=32, activation_fn=activation_fn),\r\n            DownsampleBlock(channel_in=32, channel_out=64, activation_fn=activation_fn),\r\n            DownsampleBlock(channel_in=64, channel_out=128, activation_fn=activation_fn),\r\n            DownsampleBlock(channel_in=128, channel_out=256, activation_fn=activation_fn),\r\n        )\r\n        self.deepest_shape = (256, h // 8, w // 8)\r\n\r\n        # FC network\r\n        self.fc = nn.Sequential(\r\n            nn.Linear(in_features=reduce(mul, self.deepest_shape), out_features=256),\r\n            nn.BatchNorm1d(num_features=256),\r\n            activation_fn,\r\n            nn.Linear(in_features=256, out_features=code_length),\r\n            nn.Sigmoid()\r\n        )\r\n\r\n    def forward(self, x):\r\n        # types: (torch.Tensor) -> torch.Tensor\r\n        \"\"\"\r\n        Forward propagation.\r\n\r\n        :param x: the input batch of images.\r\n        :return: the batch of latent vectors.\r\n        \"\"\"\r\n        h = x\r\n        print (type(h))\r\n        h = self.conv(h)\r\n        h = h.view(len(h), -1)\r\n        o = self.fc(h)\r\n\r\n        return o\r\n\r\n\r\nclass Decoder(BaseModule):\r\n    \"\"\"\r\n    CIFAR10 model decoder.\r\n    \"\"\"\r\n    def __init__(self, code_length, deepest_shape, output_shape):\r\n        # type: (int, Tuple[int, int, int], Tuple[int, int, int]) -> None\r\n        \"\"\"\r\n        Class constructor.\r\n\r\n        :param code_length: the dimensionality of latent vectors.\r\n        :param deepest_shape: the dimensionality of the encoder's deepest convolutional map.\r\n        :param output_shape: the shape of CIFAR10 samples.\r\n        \"\"\"\r\n        super(Decoder, self).__init__()\r\n\r\n        self.code_length = code_length\r\n        self.deepest_shape = deepest_shape\r\n        self.output_shape = output_shape\r\n\r\n        print (self.output_shape,\"--\")\r\n\r\n        activation_fn = nn.LeakyReLU()\r\n\r\n        # FC network\r\n        self.fc = nn.Sequential(\r\n            nn.Linear(in_features=code_length, out_features=256),\r\n            nn.BatchNorm1d(num_features=256),\r\n            activation_fn,\r\n            nn.Linear(in_features=256, out_features=reduce(mul, deepest_shape)),\r\n            nn.BatchNorm1d(num_features=reduce(mul, deepest_shape)),\r\n            activation_fn\r\n        )\r\n\r\n        # Convolutional network\r\n        self.conv = nn.Sequential(\r\n            UpsampleBlock(channel_in=256, channel_out=128, activation_fn=activation_fn),\r\n            UpsampleBlock(channel_in=128, channel_out=64, activation_fn=activation_fn),\r\n            UpsampleBlock(channel_in=64, channel_out=32, activation_fn=activation_fn),\r\n            ResidualBlock(channel_in=32, channel_out=32, activation_fn=activation_fn),\r\n            nn.Conv2d(in_channels=32, out_channels=3, kernel_size=1, bias=False)\r\n        )\r\n\r\n    def forward(self, x):\r\n        # types: (torch.Tensor) -> torch.Tensor\r\n        \"\"\"\r\n        Forward propagation.\r\n\r\n        :param x: the batch of latent vectors.\r\n        :return: the batch of reconstructions.\r\n        \"\"\"\r\n        h = x\r\n        h = self.fc(h)\r\n        h = h.view(len(h), *self.deepest_shape)\r\n        h = self.conv(h)\r\n        o = h\r\n\r\n        return o\r\n\r\n\r\nclass LSACIFAR10(BaseModule):\r\n    \"\"\"\r\n    LSA model for CIFAR10 one-class classification.\r\n    \"\"\"\r\n    def __init__(self,  input_shape, code_length, cpd_channels):\r\n        # type: (Tuple[int, int, int], int, int) -> None\r\n        \"\"\"\r\n        Class constructor.\r\n\r\n        :param input_shape: the shape of CIFAR10 samples.\r\n        :param code_length: the dimensionality of latent vectors.\r\n        :param cpd_channels: number of bins in which the multinomial works.\r\n        \"\"\"\r\n        super(LSACIFAR10, self).__init__()\r\n\r\n        self.input_shape = input_shape\r\n        self.code_length = code_length\r\n\r\n        # Build encoder\r\n        self.encoder = Encoder(\r\n            input_shape=input_shape,\r\n            code_length=code_length\r\n        )\r\n\r\n        # Build decoder\r\n        self.decoder = Decoder(\r\n            code_length=code_length,\r\n            deepest_shape=self.encoder.deepest_shape,\r\n            output_shape=input_shape\r\n        )\r\n\r\n        # Build estimator\r\n        self.estimator = Estimator1D(\r\n            code_length=code_length,\r\n            fm_list=[32, 32, 32, 32],\r\n            cpd_channels=cpd_channels\r\n        )\r\n\r\n    def forward(self, x):\r\n        # type: (torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]\r\n        \"\"\"\r\n        Forward propagation.\r\n\r\n        :param x: the input batch of images.\r\n        :return: a tuple of torch.Tensors holding reconstructions, latent vectors and CPD estimates.\r\n        \"\"\"\r\n        h = x\r\n\r\n        # Produce representations\r\n        z = self.encoder(h)\r\n\r\n        # Estimate CPDs with autoregression\r\n        z_dist = self.estimator(z)\r\n\r\n        # Reconstruct x\r\n        x_r = self.decoder(z)\r\n        # print (x_r.shape)\r\n        x_r = x_r.view(-1, *self.input_shape)\r\n\r\n        return x_r, z, z_dist\r\n\r\n\r\ndef load_dataset(data_path=\"/home/jbmai/Downloads/Defect Images-20190705T133320Z-001\"):\r\n    # data_path = 'data/train/'\r\n# torchvision.transforms.Grayscale(num_output_channels=1)\r\n    trainTransform  = torchvision.transforms.Compose([\r\n                                    torchvision.transforms.Resize(size=(128,128), interpolation=2),\r\n                                    torchvision.transforms.ToTensor(), \r\n                                    ])\r\n\r\n\r\n\r\n\r\n    train_dataset = torchvision.datasets.ImageFolder(\r\n        root=data_path,\r\n        transform=trainTransform)\r\n    \r\n\r\n    train_loader = torch.utils.data.DataLoader(\r\n        train_dataset,\r\n        batch_size=64,\r\n        num_workers=0,\r\n        shuffle=True\r\n    )\r\n    return train_loader\r\n\r\n\r\nnet = LSACIFAR10(input_shape=[3,128,128],code_length = 32,cpd_channels =100)\r\nlossFunction = LSALoss(cpd_channels=100)\r\noptimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\r\n\r\n\r\n\r\n\r\ntry:\r\n\r\n    checkpoint = torch.load(\"savedWeights/enc.pth\")\r\n    net.encoder.load_state_dict(checkpoint)\r\n\r\n    checkpoint = torch.load(\"savedWeights/est.pth\")\r\n    net.estimator.load_state_dict(checkpoint)\r\n\r\n    checkpoint = torch.load(\"savedWeights/dec.pth\")\r\n    net.decoder.load_state_dict(checkpoint)\r\n\r\n\r\nexcept Exception as e:\r\n    print (e)\r\n\r\n\r\nfor epoch in range(1000):  # loop over the dataset multiple times\r\n\r\n    running_loss = 0.0\r\n    d = load_dataset()\r\n    for i, (data,l) in enumerate(d):\r\n        # get the inputs; data is a list of [inputs, labels]\r\n        \r\n        # print (data.shape)\r\n\r\n        # zero the parameter gradients\r\n        optimizer.zero_grad()\r\n\r\n        # forward + backward + optimize\r\n        # print (data)\r\n        x_r,z,z_dist = net.forward(data)\r\n        # print (x_r.shape)\r\n        # print(data.shape)\r\n        loss = lossFunction(data,x_r,z,z_dist)\r\n        loss.backward()\r\n        optimizer.step()\r\n\r\n        # print statistics\r\n        running_loss += loss.item()\r\n        if i % 5 == 0:    # print every 2000 mini-batches\r\n            print('[%d, %5d] loss: %.3f' %\r\n                  (epoch + 1, i + 1, running_loss / 5))\r\n            running_loss = 0.0\r\n    if (epoch % 5)== 0 :\r\n        # print (\"--------------------{} epoch-----------\".format(epoch))\r\n        # net.encoder.eval()\r\n        # net.estimator.eval()\r\n        # net.decoder.eval()\r\n\r\n        # z = net.encoder(data)\r\n        # z_dist = net.estimator(z)\r\n        # x_r = net.decoder(z).permute(0,2,3,1).detach().numpy()\r\n        # out =x_r\r\n        # print (type(out))\r\n        # for i in range(out.shape[0]):\r\n        #     # print (out.shape)\r\n        #     # # out.permute(0,2,3,1)\r\n        #     # print (out.shape)\r\n        #     cv2.imwrite(\"constructedImages/outDec{}_{}.jpg\".format(epoch,i),out[i,:,:,:]*255)\r\n        #     # cv2.waitKey(0)\r\n           \r\n        #     # cv2.\r\n        # net.encoder.train()\r\n        # net.estimator.train()\r\n        # net.decoder.eval()\r\n        torch.save(net.encoder.state_dict(),(\"savedWeights/enc.pth\"))\r\n        torch.save(net.estimator.state_dict(),(\"savedWeights/est.pth\"))\r\n        torch.save(net.decoder.state_dict(),(\"savedWeights/dec.pth\"))\r\n\r\nprint('Finished Training')`\r\n\r\nOutput : \r\n\r\n<class 'torch.Tensor'>\r\n[1,     1] loss: 727109273.600\r\n<class 'torch.Tensor'>\r\n[2,     1] loss: 2495627954514337382531072.000\r\n\r\n\r\n\r\nHi can you help me rectify the issue.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/aimagelab/novelty-detection/issues/5/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/aimagelab/novelty-detection/issues/5/timeline","performed_via_github_app":null,"state_reason":null}