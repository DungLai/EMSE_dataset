{"url":"https://api.github.com/repos/JayYip/m3tl/issues/13","repository_url":"https://api.github.com/repos/JayYip/m3tl","labels_url":"https://api.github.com/repos/JayYip/m3tl/issues/13/labels{/name}","comments_url":"https://api.github.com/repos/JayYip/m3tl/issues/13/comments","events_url":"https://api.github.com/repos/JayYip/m3tl/issues/13/events","html_url":"https://github.com/JayYip/m3tl/issues/13","id":443311343,"node_id":"MDU6SXNzdWU0NDMzMTEzNDM=","number":13,"title":"[Question]OOM occurred when using larger batch_size, maybe data parallelism didn't work well","user":{"login":"haoyuhu","id":9149575,"node_id":"MDQ6VXNlcjkxNDk1NzU=","avatar_url":"https://avatars.githubusercontent.com/u/9149575?v=4","gravatar_id":"","url":"https://api.github.com/users/haoyuhu","html_url":"https://github.com/haoyuhu","followers_url":"https://api.github.com/users/haoyuhu/followers","following_url":"https://api.github.com/users/haoyuhu/following{/other_user}","gists_url":"https://api.github.com/users/haoyuhu/gists{/gist_id}","starred_url":"https://api.github.com/users/haoyuhu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/haoyuhu/subscriptions","organizations_url":"https://api.github.com/users/haoyuhu/orgs","repos_url":"https://api.github.com/users/haoyuhu/repos","events_url":"https://api.github.com/users/haoyuhu/events{/privacy}","received_events_url":"https://api.github.com/users/haoyuhu/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2019-05-13T10:03:01Z","updated_at":"2019-05-13T11:19:58Z","closed_at":"2019-05-13T11:19:58Z","author_association":"NONE","active_lock_reason":null,"body":"A lot of multi-gpu-related issues under this project have benefited me a lot.\r\n\r\nBased on the original code of [bert](https://github.com/google-research/bert), with batch_size of 24 and tensorflow of 1.13.1, I recently used the [**AdamWeightDecayOptimizer** in your project](https://github.com/JayYip/bert-multitask-learning/blob/master/src/optimizer.py) to successfully train a classifier with bert-large-uncased in 2 x Tesla P40, and the prediction looks fine.\r\n\r\nBut when I adjusted the batch_size to 32, I got the following **OOM error**. At this time I increased the number of GPUs to 3 but still OOM, I feel that MirroredSttrategy does not make **data parallelism** work. Then I reduced the number of GPUs to 1, the batch_size to 24, no OOM occurred. \r\n\r\nDo you have any clues to solve this problem pls? Thank you very much!\r\n\r\n---\r\nerror message:\r\n```\r\nWARNING:tensorflow:Efficient allreduce is not supported for IndexedSlices.\r\nINFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = hierarchical_copy, num_packs = 0, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\n...\r\nLimit:                 22654317364\r\nInUse:                 22621908992\r\nMaxInUse:              22621909760\r\nNumAllocs:                   13050\r\nMaxAllocSize:            247209984\r\n...\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[4096,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:1 by allocator GPU_1_bfc\r\n[[node replica_1/gradients/replica_1/bert/encoder/layer_20/intermediate/dense/Pow_grad/Pow (defined at /scripts/bert/custom_optimization.py:74) ]]\r\n```\r\n---\r\nmirrored strategy:\r\n```python\r\ndist_strategy = tf.contrib.distribute.MirroredStrategy(\r\n    cross_device_ops=AllReduceCrossDeviceOps('nccl'))\r\nlog_every_n_steps = 8\r\nrun_config = RunConfig(\r\n    train_distribute=dist_strategy,\r\n    eval_distribute=dist_strategy,\r\n    log_step_count_steps=log_every_n_steps,\r\n    model_dir=FLAGS.output_dir,\r\n    save_checkpoints_steps=FLAGS.save_checkpoints_steps)\r\nestimator = Estimator(\r\n    model_fn=model_fn,\r\n    params={},\r\n    config=run_config)\r\n...\r\ntrain_file = os.path.join(FLAGS.output_dir, \"train.tf_record\")\r\nfile_based_convert_examples_to_features(\r\n    train_examples, label_list, FLAGS.max_seq_length, tokenizer, train_file)\r\ntrain_input_fn = file_based_input_fn_builder(\r\n    input_file=train_file,\r\n    seq_length=FLAGS.max_seq_length,\r\n    is_training=True,\r\n    drop_remainder=True,\r\n    batch_size=FLAGS.train_batch_size)\r\nestimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\r\n```\r\n---\r\ncustom_optimization:\r\n```python\r\ndef create_optimizer(loss, init_lr, num_train_steps, num_warmup_steps):\r\n    \"\"\"Creates an optimizer training op.\"\"\"\r\n    global_step = tf.train.get_or_create_global_step()\r\n\r\n    learning_rate = tf.constant(value=init_lr, shape=[], dtype=tf.float32)\r\n\r\n    # Implements linear decay of the learning rate.\r\n    learning_rate = tf.train.polynomial_decay(\r\n        learning_rate,\r\n        global_step,\r\n        num_train_steps,\r\n        end_learning_rate=0.0,\r\n        power=1.0,\r\n        cycle=False)\r\n\r\n    # Implements linear warmup. I.e., if global_step < num_warmup_steps, the\r\n    # learning rate will be `global_step/num_warmup_steps * init_lr`.\r\n    if num_warmup_steps:\r\n        global_steps_int = tf.cast(global_step, tf.int32)\r\n        warmup_steps_int = tf.constant(num_warmup_steps, dtype=tf.int32)\r\n\r\n        global_steps_float = tf.cast(global_steps_int, tf.float32)\r\n        warmup_steps_float = tf.cast(warmup_steps_int, tf.float32)\r\n\r\n        warmup_percent_done = global_steps_float / warmup_steps_float\r\n        warmup_learning_rate = init_lr * warmup_percent_done\r\n\r\n        is_warmup = tf.cast(global_steps_int < warmup_steps_int, tf.float32)\r\n        learning_rate = (\r\n                (1.0 - is_warmup) * learning_rate + is_warmup * warmup_learning_rate)\r\n\r\n    # It is recommended that you use this optimizer for fine tuning, since this\r\n    # is how the model was trained (note that the Adam m/v variables are NOT\r\n    # loaded from init_checkpoint.)\r\n    optimizer = AdamWeightDecayOptimizer(\r\n        learning_rate=learning_rate,\r\n        weight_decay_rate=0.01,\r\n        beta_1=0.9,\r\n        beta_2=0.999,\r\n        epsilon=1e-6,\r\n        exclude_from_weight_decay=[\"LayerNorm\", \"layer_norm\", \"bias\"])\r\n\r\n    tvars = tf.trainable_variables()\r\n    grads = tf.gradients(loss, tvars)\r\n\r\n    # This is how the model was pre-trained.\r\n    (grads, _) = tf.clip_by_global_norm(grads, clip_norm=1.0)\r\n\r\n    train_op = optimizer.apply_gradients(\r\n        zip(grads, tvars), global_step=global_step)\r\n\r\n    # Normally the global step update is done inside of `apply_gradients`.\r\n    # However, `AdamWeightDecayOptimizer` doesn't do this. But if you use\r\n    # a different optimizer, you should probably take this line out.\r\n    new_global_step = global_step + 1\r\n    train_op = tf.group(train_op, [global_step.assign(new_global_step)])\r\n    return train_op\r\n\r\n\r\nclass AdamWeightDecayOptimizer(Optimizer):\r\n    \"\"\"A basic Adam optimizer that includes \"correct\" L2 weight decay.\"\"\"\r\n\r\n    def __init__(self,\r\n                 learning_rate,\r\n                 weight_decay_rate=0.0,\r\n                 beta_1=0.9,\r\n                 beta_2=0.999,\r\n                 epsilon=1e-6,\r\n                 exclude_from_weight_decay=None,\r\n                 name=\"AdamWeightDecayOptimizer\"):\r\n        \"\"\"Constructs a AdamWeightDecayOptimizer.\"\"\"\r\n        super(AdamWeightDecayOptimizer, self).__init__(False, name)\r\n\r\n        self.learning_rate = learning_rate\r\n        self.weight_decay_rate = weight_decay_rate\r\n        self.beta_1 = beta_1\r\n        self.beta_2 = beta_2\r\n        self.epsilon = epsilon\r\n        self.exclude_from_weight_decay = exclude_from_weight_decay\r\n\r\n    def _prepare(self):\r\n        self.learning_rate_t = ops.convert_to_tensor(\r\n            self.learning_rate, name='learning_rate')\r\n        self.weight_decay_rate_t = ops.convert_to_tensor(\r\n            self.weight_decay_rate, name='weight_decay_rate')\r\n        self.beta_1_t = ops.convert_to_tensor(self.beta_1, name='beta_1')\r\n        self.beta_2_t = ops.convert_to_tensor(self.beta_2, name='beta_2')\r\n        self.epsilon_t = ops.convert_to_tensor(self.epsilon, name='epsilon')\r\n\r\n    def _create_slots(self, var_list):\r\n        for v in var_list:\r\n            self._zeros_slot(v, 'm', self._name)\r\n            self._zeros_slot(v, 'v', self._name)\r\n\r\n    def _apply_dense(self, grad, var):\r\n        learning_rate_t = math_ops.cast(\r\n            self.learning_rate_t, var.dtype.base_dtype)\r\n        beta_1_t = math_ops.cast(self.beta_1_t, var.dtype.base_dtype)\r\n        beta_2_t = math_ops.cast(self.beta_2_t, var.dtype.base_dtype)\r\n        epsilon_t = math_ops.cast(self.epsilon_t, var.dtype.base_dtype)\r\n        weight_decay_rate_t = math_ops.cast(\r\n            self.weight_decay_rate_t, var.dtype.base_dtype)\r\n\r\n        m = self.get_slot(var, 'm')\r\n        v = self.get_slot(var, 'v')\r\n\r\n        # Standard Adam update.\r\n        next_m = (\r\n                tf.multiply(beta_1_t, m) +\r\n                tf.multiply(1.0 - beta_1_t, grad))\r\n        next_v = (\r\n                tf.multiply(beta_2_t, v) + tf.multiply(1.0 - beta_2_t,\r\n                                                       tf.square(grad)))\r\n\r\n        update = next_m / (tf.sqrt(next_v) + epsilon_t)\r\n\r\n        if self._do_use_weight_decay(var.name):\r\n            update += weight_decay_rate_t * var\r\n\r\n        update_with_lr = learning_rate_t * update\r\n\r\n        next_param = var - update_with_lr\r\n\r\n        return control_flow_ops.group(*[var.assign(next_param),\r\n                                        m.assign(next_m),\r\n                                        v.assign(next_v)])\r\n\r\n    def _resource_apply_dense(self, grad, var):\r\n        learning_rate_t = math_ops.cast(\r\n            self.learning_rate_t, var.dtype.base_dtype)\r\n        beta_1_t = math_ops.cast(self.beta_1_t, var.dtype.base_dtype)\r\n        beta_2_t = math_ops.cast(self.beta_2_t, var.dtype.base_dtype)\r\n        epsilon_t = math_ops.cast(self.epsilon_t, var.dtype.base_dtype)\r\n        weight_decay_rate_t = math_ops.cast(\r\n            self.weight_decay_rate_t, var.dtype.base_dtype)\r\n\r\n        m = self.get_slot(var, 'm')\r\n        v = self.get_slot(var, 'v')\r\n\r\n        # Standard Adam update.\r\n        next_m = (\r\n                tf.multiply(beta_1_t, m) +\r\n                tf.multiply(1.0 - beta_1_t, grad))\r\n        next_v = (\r\n                tf.multiply(beta_2_t, v) + tf.multiply(1.0 - beta_2_t,\r\n                                                       tf.square(grad)))\r\n\r\n        update = next_m / (tf.sqrt(next_v) + epsilon_t)\r\n\r\n        if self._do_use_weight_decay(var.name):\r\n            update += weight_decay_rate_t * var\r\n\r\n        update_with_lr = learning_rate_t * update\r\n\r\n        next_param = var - update_with_lr\r\n\r\n        return control_flow_ops.group(*[var.assign(next_param),\r\n                                        m.assign(next_m),\r\n                                        v.assign(next_v)])\r\n\r\n    def _apply_sparse_shared(self, grad, var, indices, scatter_add):\r\n        learning_rate_t = math_ops.cast(\r\n            self.learning_rate_t, var.dtype.base_dtype)\r\n        beta_1_t = math_ops.cast(self.beta_1_t, var.dtype.base_dtype)\r\n        beta_2_t = math_ops.cast(self.beta_2_t, var.dtype.base_dtype)\r\n        epsilon_t = math_ops.cast(self.epsilon_t, var.dtype.base_dtype)\r\n        weight_decay_rate_t = math_ops.cast(\r\n            self.weight_decay_rate_t, var.dtype.base_dtype)\r\n\r\n        m = self.get_slot(var, 'm')\r\n        v = self.get_slot(var, 'v')\r\n\r\n        m_t = state_ops.assign(m, m * beta_1_t,\r\n                               use_locking=self._use_locking)\r\n\r\n        m_scaled_g_values = grad * (1 - beta_1_t)\r\n        with ops.control_dependencies([m_t]):\r\n            m_t = scatter_add(m, indices, m_scaled_g_values)\r\n\r\n        v_scaled_g_values = (grad * grad) * (1 - beta_2_t)\r\n        v_t = state_ops.assign(v, v * beta_2_t, use_locking=self._use_locking)\r\n        with ops.control_dependencies([v_t]):\r\n            v_t = scatter_add(v, indices, v_scaled_g_values)\r\n\r\n        update = m_t / (math_ops.sqrt(v_t) + epsilon_t)\r\n\r\n        if self._do_use_weight_decay(var.name):\r\n            update += weight_decay_rate_t * var\r\n\r\n        update_with_lr = learning_rate_t * update\r\n\r\n        var_update = state_ops.assign_sub(var,\r\n                                          update_with_lr,\r\n                                          use_locking=self._use_locking)\r\n        return control_flow_ops.group(*[var_update, m_t, v_t])\r\n\r\n    def _apply_sparse(self, grad, var):\r\n        return self._apply_sparse_shared(\r\n            grad.values, var, grad.indices,\r\n            lambda x, i, v: state_ops.scatter_add(  # pylint: disable=g-long-lambda\r\n                x, i, v, use_locking=self._use_locking))\r\n\r\n    def _resource_scatter_add(self, x, i, v):\r\n        with ops.control_dependencies(\r\n                [resource_variable_ops.resource_scatter_add(\r\n                    x.handle, i, v)]):\r\n            return x.value()\r\n\r\n    def _resource_apply_sparse(self, grad, var, indices):\r\n        return self._apply_sparse_shared(\r\n            grad, var, indices, self._resource_scatter_add)\r\n\r\n    def _do_use_weight_decay(self, param_name):\r\n        \"\"\"Whether to use L2 weight decay for `param_name`.\"\"\"\r\n        if not self.weight_decay_rate:\r\n            return False\r\n        if self.exclude_from_weight_decay:\r\n            for r in self.exclude_from_weight_decay:\r\n                if re.search(r, param_name) is not None:\r\n                    return False\r\n        return True\r\n```\r\n---\r\nmodel_fn:\r\n```python\r\nis_training = (mode == tf.estimator.ModeKeys.TRAIN)\r\n\r\n(total_loss, per_example_loss, logits, probabilities) = create_model(\r\n    bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\r\n    num_labels, use_one_hot_embeddings)\r\n\r\ntvars = tf.trainable_variables()\r\ninitialized_variable_names = {}\r\nscaffold_fn = None\r\nif init_checkpoint:\r\n    (assignment_map, initialized_variable_names\r\n     ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\r\n    \r\n    tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\r\n\r\ntf.logging.info(\"**** Trainable Variables ****\")\r\nfor var in tvars:\r\n    init_string = \"\"\r\n    if var.name in initialized_variable_names:\r\n        init_string = \", *INIT_FROM_CKPT*\"\r\n    tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\r\n                    init_string)\r\n\r\nif mode == tf.estimator.ModeKeys.TRAIN:\r\n    train_op = custom_optimization.create_optimizer(\r\n        total_loss, learning_rate, num_train_steps, num_warmup_steps)\r\n    output_spec = tf.estimator.EstimatorSpec(\r\n        mode=mode,\r\n        loss=total_loss,\r\n        train_op=train_op,\r\n        scaffold=scaffold_fn)\r\n ...\r\n ```","closed_by":{"login":"haoyuhu","id":9149575,"node_id":"MDQ6VXNlcjkxNDk1NzU=","avatar_url":"https://avatars.githubusercontent.com/u/9149575?v=4","gravatar_id":"","url":"https://api.github.com/users/haoyuhu","html_url":"https://github.com/haoyuhu","followers_url":"https://api.github.com/users/haoyuhu/followers","following_url":"https://api.github.com/users/haoyuhu/following{/other_user}","gists_url":"https://api.github.com/users/haoyuhu/gists{/gist_id}","starred_url":"https://api.github.com/users/haoyuhu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/haoyuhu/subscriptions","organizations_url":"https://api.github.com/users/haoyuhu/orgs","repos_url":"https://api.github.com/users/haoyuhu/repos","events_url":"https://api.github.com/users/haoyuhu/events{/privacy}","received_events_url":"https://api.github.com/users/haoyuhu/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/JayYip/m3tl/issues/13/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/JayYip/m3tl/issues/13/timeline","performed_via_github_app":null,"state_reason":"completed"}