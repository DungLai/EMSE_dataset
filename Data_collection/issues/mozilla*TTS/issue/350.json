{"url":"https://api.github.com/repos/mozilla/TTS/issues/350","repository_url":"https://api.github.com/repos/mozilla/TTS","labels_url":"https://api.github.com/repos/mozilla/TTS/issues/350/labels{/name}","comments_url":"https://api.github.com/repos/mozilla/TTS/issues/350/comments","events_url":"https://api.github.com/repos/mozilla/TTS/issues/350/events","html_url":"https://github.com/mozilla/TTS/issues/350","id":562835319,"node_id":"MDU6SXNzdWU1NjI4MzUzMTk=","number":350,"title":"Error creating Test Sentence","user":{"login":"mausamsion","id":8238216,"node_id":"MDQ6VXNlcjgyMzgyMTY=","avatar_url":"https://avatars.githubusercontent.com/u/8238216?v=4","gravatar_id":"","url":"https://api.github.com/users/mausamsion","html_url":"https://github.com/mausamsion","followers_url":"https://api.github.com/users/mausamsion/followers","following_url":"https://api.github.com/users/mausamsion/following{/other_user}","gists_url":"https://api.github.com/users/mausamsion/gists{/gist_id}","starred_url":"https://api.github.com/users/mausamsion/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mausamsion/subscriptions","organizations_url":"https://api.github.com/users/mausamsion/orgs","repos_url":"https://api.github.com/users/mausamsion/repos","events_url":"https://api.github.com/users/mausamsion/events{/privacy}","received_events_url":"https://api.github.com/users/mausamsion/received_events","type":"User","site_admin":false},"labels":[{"id":813922298,"node_id":"MDU6TGFiZWw4MTM5MjIyOTg=","url":"https://api.github.com/repos/mozilla/TTS/labels/wontfix","name":"wontfix","color":"ffffff","default":true,"description":"This will not be worked on"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-02-10T21:21:19Z","updated_at":"2020-10-27T18:25:35Z","closed_at":"2020-04-17T23:58:08Z","author_association":"NONE","active_lock_reason":null,"body":"I am getting following RunTimeError in the validation phase; training continues normally although (with [Warning] mentioned in [#282](https://github.com/mozilla/TTS/issues/282). Also, this error started from Epoch-7.\r\n```\r\nEpoch 7/1000\r\n   | > Step:9/79  GlobalStep:570  PostnetLoss:0.98650  DecoderLoss:1.08368  StopLoss:1.76552  AlignScore:0.2073  GradNorm:1.97462  GradNormST:10.34477  AvgTextLen:20.9  AvgSpecLen:238.4  StepTime:0.55  LoaderTime:0.08  LR:0.000100\r\n   | > Step:19/79  GlobalStep:580  PostnetLoss:0.95169  DecoderLoss:1.06522  StopLoss:1.73338  AlignScore:0.2091  GradNorm:1.56169  GradNormST:5.89328  AvgTextLen:24.3  AvgSpecLen:268.7  StepTime:0.60  LoaderTime:0.01  LR:0.000100\r\n   | > Step:29/79  GlobalStep:590  PostnetLoss:0.94652  DecoderLoss:1.05271  StopLoss:1.65834  AlignScore:0.2185  GradNorm:0.82962  GradNormST:2.55707  AvgTextLen:27.3  AvgSpecLen:291.4  StepTime:0.79  LoaderTime:0.01  LR:0.000100\r\n   | > Step:39/79  GlobalStep:600  PostnetLoss:1.01864  DecoderLoss:1.07490  StopLoss:1.52232  AlignScore:0.1940  GradNorm:1.32182  GradNormST:14.46270  AvgTextLen:31.2  AvgSpecLen:322.9  StepTime:1.10  LoaderTime:0.01  LR:0.000100\r\n   | > Step:49/79  GlobalStep:610  PostnetLoss:0.97420  DecoderLoss:1.07130  StopLoss:1.73048  AlignScore:0.1663  GradNorm:2.26986  GradNormST:10.69967  AvgTextLen:37.3  AvgSpecLen:385.1  StepTime:1.37  LoaderTime:0.01  LR:0.000100\r\n   | > Step:59/79  GlobalStep:620  PostnetLoss:0.97626  DecoderLoss:1.10083  StopLoss:2.79588  AlignScore:0.1812  GradNorm:0.71479  GradNormST:73.75630  AvgTextLen:45.0  AvgSpecLen:468.2  StepTime:1.65  LoaderTime:0.02  LR:0.000100\r\n   | > Step:69/79  GlobalStep:630  PostnetLoss:1.00345  DecoderLoss:1.05590  StopLoss:1.46773  AlignScore:0.1687  GradNorm:3.34655  GradNormST:12.43859  AvgTextLen:56.4  AvgSpecLen:568.4  StepTime:2.71  LoaderTime:0.05  LR:0.000100\r\n   | > Step:79/79  GlobalStep:640  PostnetLoss:0.95168  DecoderLoss:1.04050  StopLoss:1.38745  AlignScore:0.1415  GradNorm:1.09425  GradNormST:6.16418  AvgTextLen:118.5  AvgSpecLen:1139.2  StepTime:1.41  LoaderTime:0.04  LR:0.000100\r\n   | > EPOCH END -- GlobalStep:640  AvgTotalLoss:0.98950  AvgPostnetLoss:1.07313  AvgDecoderLoss:1.75256  AvgStopLoss:0.19332  EpochTime:88.52  AvgStepTime:1.11  AvgLoaderTime:0.04\r\n[WARNING] NaN or Inf found in input tensor.\r\n[WARNING] NaN or Inf found in input tensor.\r\n\r\n > Validation\r\n   | > TotalLoss: 3.42646   PostnetLoss: 0.82252 - 0.82252  DecoderLoss:1.05244 - 1.05244 StopLoss: 1.56133 - 1.56133  AlignScore: 0.2179 : 0.2179\r\nwarning: audio amplitude out of range, auto clipped.\r\n | > Synthesizing test sentences\r\n !! Error creating Test Sentence - 0\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 484, in evaluate\r\n    style_wav=style_wav)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/utils/synthesis.py\", line 109, in synthesis\r\n    model, inputs, CONFIG, truncated, speaker_id, style_mel)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/utils/synthesis.py\", line 42, in run_model\r\n    inputs, speaker_ids=speaker_id)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/models/tacotron2.py\", line 62, in inference\r\n    encoder_outputs = self.encoder.inference(embedded_inputs)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/layers/tacotron2.py\", line 80, in inference\r\n    x = self.convolutions(x)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 100, in forward\r\n    input = module(input)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/layers/tacotron2.py\", line 27, in forward\r\n    output = self.net(x)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 100, in forward\r\n    input = module(input)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\", line 202, in forward\r\n    self.padding, self.dilation, self.groups)\r\nRuntimeError: Calculated padded input size per channel: (4). Kernel size: (5). Kernel size can't be greater than actual input size\r\n !! Error creating Test Sentence - 1\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 484, in evaluate\r\n    style_wav=style_wav)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/utils/synthesis.py\", line 109, in synthesis\r\n    model, inputs, CONFIG, truncated, speaker_id, style_mel)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/utils/synthesis.py\", line 42, in run_model\r\n    inputs, speaker_ids=speaker_id)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/models/tacotron2.py\", line 62, in inference\r\n    encoder_outputs = self.encoder.inference(embedded_inputs)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/layers/tacotron2.py\", line 80, in inference\r\n    x = self.convolutions(x)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 100, in forward\r\n    input = module(input)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/layers/tacotron2.py\", line 27, in forward\r\n    output = self.net(x)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 100, in forward\r\n    input = module(input)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\", line 202, in forward\r\n    self.padding, self.dilation, self.groups)\r\nRuntimeError: Calculated padded input size per channel: (4). Kernel size: (5). Kernel size can't be greater than actual input size\r\n !! Error creating Test Sentence - 2\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 484, in evaluate\r\n    style_wav=style_wav)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/utils/synthesis.py\", line 109, in synthesis\r\n    model, inputs, CONFIG, truncated, speaker_id, style_mel)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/utils/synthesis.py\", line 42, in run_model\r\n    inputs, speaker_ids=speaker_id)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/models/tacotron2.py\", line 62, in inference\r\n    encoder_outputs = self.encoder.inference(embedded_inputs)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/layers/tacotron2.py\", line 80, in inference\r\n    x = self.convolutions(x)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 100, in forward\r\n    input = module(input)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/layers/tacotron2.py\", line 27, in forward\r\n    output = self.net(x)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 100, in forward\r\n    input = module(input)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\", line 202, in forward\r\n    self.padding, self.dilation, self.groups)\r\nRuntimeError: Calculated padded input size per channel: (4). Kernel size: (5). Kernel size can't be greater than actual input size\r\n !! Error creating Test Sentence - 3\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 484, in evaluate\r\n    style_wav=style_wav)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/utils/synthesis.py\", line 109, in synthesis\r\n    model, inputs, CONFIG, truncated, speaker_id, style_mel)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/utils/synthesis.py\", line 42, in run_model\r\n    inputs, speaker_ids=speaker_id)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/models/tacotron2.py\", line 62, in inference\r\n    encoder_outputs = self.encoder.inference(embedded_inputs)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/layers/tacotron2.py\", line 80, in inference\r\n    x = self.convolutions(x)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 100, in forward\r\n    input = module(input)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/TTS/mozilla-tts/tts_namespace/TTS/layers/tacotron2.py\", line 27, in forward\r\n    output = self.net(x)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 100, in forward\r\n    input = module(input)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\", line 202, in forward\r\n    self.padding, self.dilation, self.groups)\r\nRuntimeError: Calculated padded input size per channel: (4). Kernel size: (5). Kernel size can't be greater than actual input size\r\n | > Training Loss: 0.98950   Validation Loss: 0.83471\r\n\r\n > BEST MODEL (0.83471) : /root/TTS/tacotron2_2_out/mozilla-no-loc-fattn-stopnet-sigmoid-loss_masking-February-10-2020_08+42PM-4212ff3/best_model.pth.tar\r\n > Number of outputs per iteration: 5\r\n```\r\n\r\nI am training Tacotron-2 for JSUT dataset and here is my config file:\r\n```\r\n{\r\n    \"run_name\": \"mozilla-no-loc-fattn-stopnet-sigmoid-loss_masking\",\r\n    \"run_description\": \"using forward attention, with original prenet, loss masking,separate stopnet, sigmoid. Compare this with 4817. Pytorch DPP\",\r\n\r\n    \"audio\":{\r\n        // Audio processing parameters\r\n        \"num_mels\": 80,         // size of the mel spec frame.\r\n        \"num_freq\": 1025,       // number of stft frequency levels. Size of the linear spectogram frame.\r\n        \"sample_rate\": 22050,   // DATASET-RELATED: wav sample-rate. If different than the original data, it is resampled.\r\n        \"frame_length_ms\": 50,  // stft window length in ms.\r\n        \"frame_shift_ms\": 12.5, // stft window hop-lengh in ms.\r\n        \"preemphasis\": 0.98,    // pre-emphasis to reduce spec noise and make it more structured. If 0.0, no -pre-emphasis.\r\n        \"min_level_db\": -100,   // normalization range\r\n        \"ref_level_db\": 25,     // reference level db, theoretically 20db is the sound of air.\r\n        \"power\": 1.5,           // value to sharpen wav signals after GL algorithm.\r\n        \"griffin_lim_iters\": 60,// #griffin-lim iterations. 30-60 is a good range. Larger the value, slower the generation.\r\n        // Normalization parameters\r\n        \"signal_norm\": true,    // normalize the spec values in range [0, 1]\r\n        \"symmetric_norm\": true, // move normalization to range [-1, 1]\r\n        \"max_norm\": 4,          // scale normalization to range [-max_norm, max_norm] or [0, max_norm]\r\n        \"clip_norm\": true,      // clip normalized values into the range.\r\n        \"mel_fmin\": 0.0,         // minimum freq level for mel-spec. ~50 for male and ~95 for female voices. Tune for dataset!!\r\n        \"mel_fmax\": 8000.0,        // maximum freq level for mel-spec. Tune for dataset!!\r\n        \"do_trim_silence\": true  // enable trimming of slience of audio as you load it. LJspeech (false), TWEB (false), Nancy (true)\r\n    },\r\n\r\n    \"distributed\":{\r\n        \"backend\": \"nccl\",\r\n        \"url\": \"tcp:\\/\\/localhost:54321\"\r\n    },\r\n\r\n    \"reinit_layers\": [],\r\n\r\n    \"model\": \"Tacotron2\",          // one of the model in models/\r\n    \"grad_clip\": 1,                // upper limit for gradients for clipping.\r\n    \"epochs\": 1000,                // total number of epochs to train.\r\n    \"lr\": 0.0001,                  // Initial learning rate. If Noam decay is active, maximum learning rate.\r\n    \"lr_decay\": false,             // if true, Noam learning rate decaying is applied through training.\r\n    \"warmup_steps\": 4000,          // Noam decay steps to increase the learning rate from 0 to \"lr\"\r\n    \"memory_size\": 5,              // ONLY TACOTRON - memory queue size used to queue network predictions to feed autoregressive connection. Useful if r < 5.\r\n    \"attention_norm\": \"softmax\",   // softmax or sigmoid. Suggested to use softmax for Tacotron2 and sigmoid for Tacotron.\r\n    \"prenet_type\": \"bn\",     // \"original\" or \"bn\".\r\n    \"prenet_dropout\": true,        // enable/disable dropout at prenet.\r\n    \"use_forward_attn\": true,      // enable/disable forward attention. In general, it aligns faster.\r\n    \"forward_attn_mask\": false,    // Apply forward attention mask af inference to prevent bad modes. Try it if your model does not align well.\r\n    \"transition_agent\": false,     // enable/disable transition agent of forward attention.\r\n    \"location_attn\": true,        // enable_disable location sensitive attention. It is enabled for TACOTRON by default.\r\n    \"loss_masking\": true,          // enable / disable loss masking against the sequence padding.\r\n    \"enable_eos_bos_chars\": false, // enable/disable beginning of sentence and end of sentence chars.\r\n    \"stopnet\": true,               // Train stopnet predicting the end of synthesis.\r\n    \"separate_stopnet\": true,      // Train stopnet seperately if 'stopnet==true'. It prevents stopnet loss to influence the rest of the model. It causes a better model, but it trains SLOWER.\r\n    \"tb_model_param_stats\": true,     // true, plots param stats per layer on tensorboard. Might be memory consuming, but good for debugging.\r\n\r\n    \"windowing\": false,             // Enables attention windowing. Used only in eval mode.\r\n    \"forward_attn_masking\": false,  // Enable forward attention masking which improves attention stability. Use it if network does not work as you like when it is off.\r\n\r\n    \"batch_size\": 32,       // Batch size for training. Lower values than 32 might cause hard to learn attention.\r\n    \"eval_batch_size\":16,\r\n    \"r\": 5,                 // Number of frames to predict for step.\r\n    \"gradual_training\": null,\r\n    \"wd\": 0.000001,         // Weight decay weight.\r\n    \"checkpoint\": true,     // If true, it saves checkpoints per \"save_step\"\r\n    \"save_step\": 1000,      // Number of training steps expected to save traning stats and checkpoints.\r\n    \"print_step\": 10,       // Number of steps to log traning on console.\r\n    \"batch_group_size\": 0,  //Number of batches to shuffle after bucketing.\r\n\r\n    \"run_eval\": true,\r\n    \"test_delay_epochs\": 5,  //Until attention is aligned, testing only wastes computation time.\r\n    \"test_sentences_file\": null,  // set a file to load sentences to be used for testing. If it is null then we use default english sentences.\r\n    //\"data_path\": \"/media/erogol/data_ssd/Data/Mozilla/\",  // DATASET-RELATED: can overwritten from command argument\r\n    //\"meta_file_train\": \"metadata_train.txt\",      // DATASET-RELATED: metafile for training dataloader.\r\n    //\"meta_file_val\": \"metadata_val.txt\",    // DATASET-RELATED: metafile for evaluation dataloader.\r\n    //\"dataset\": \"mozilla\",      // DATASET-RELATED: one of TTS.dataset.preprocessors depending on your target dataset. Use \"tts_cache\" for pre-computed dataset by extract_features.py\r\n    \"min_seq_len\": 6,       // DATASET-RELATED: minimum text length to use in training\r\n    \"max_seq_len\": 196,     // DATASET-RELATED: maximum text length\r\n    \"output_path\": \"/root/TTS/tacotron2_2_out/\",      // DATASET-RELATED: output path for all training outputs.\r\n    \"num_loader_workers\": 4,        // number of training data loader processes. Don't set it too big. 4-8 are good values.\r\n    \"num_val_loader_workers\": 4,    // number of evaluation data loader processes.\r\n    \"phoneme_cache_path\": \"mozilla_us_phonemes\",  // phoneme computation is slow, therefore, it caches results in the given folder.\r\n    \"use_phonemes\": false,           // use phonemes instead of raw characters. It is suggested for better pronounciation.\r\n    \"phoneme_language\": \"en-us\",     // depending on your target language, pick one from  https://github.com/bootphon/phonemizer#languages\r\n    \"text_cleaner\": \"jsut_precleaned\",\r\n    \"use_speaker_embedding\": false, // whether to use additional embeddings for separate speakers\r\n\r\n    \"datasets\":\r\n        [\r\n            {\r\n                \"name\": \"jsut\",\r\n                \"path\": \"/root/TTS/jsut_ver1.1/\",\r\n                \"meta_file_train\": \"metadata_train.csv\",\r\n                \"meta_file_val\": \"metadata_val.csv\"\r\n            }\r\n        ]\r\n}\r\n```\r\n\r\nH/W, S/W specs:\r\nUsing docker with cuda 10.1, ubuntu 18.04 LTS and distributed training with 3 Nvidia 1080 GPUs.\r\n\r\nAny help is really appreciated.\r\nThanks!","closed_by":{"login":"stale[bot]","id":26384082,"node_id":"MDM6Qm90MjYzODQwODI=","avatar_url":"https://avatars.githubusercontent.com/in/1724?v=4","gravatar_id":"","url":"https://api.github.com/users/stale%5Bbot%5D","html_url":"https://github.com/apps/stale","followers_url":"https://api.github.com/users/stale%5Bbot%5D/followers","following_url":"https://api.github.com/users/stale%5Bbot%5D/following{/other_user}","gists_url":"https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}","starred_url":"https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stale%5Bbot%5D/subscriptions","organizations_url":"https://api.github.com/users/stale%5Bbot%5D/orgs","repos_url":"https://api.github.com/users/stale%5Bbot%5D/repos","events_url":"https://api.github.com/users/stale%5Bbot%5D/events{/privacy}","received_events_url":"https://api.github.com/users/stale%5Bbot%5D/received_events","type":"Bot","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mozilla/TTS/issues/350/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mozilla/TTS/issues/350/timeline","performed_via_github_app":null,"state_reason":"completed"}