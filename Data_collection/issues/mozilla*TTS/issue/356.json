{"url":"https://api.github.com/repos/mozilla/TTS/issues/356","repository_url":"https://api.github.com/repos/mozilla/TTS","labels_url":"https://api.github.com/repos/mozilla/TTS/issues/356/labels{/name}","comments_url":"https://api.github.com/repos/mozilla/TTS/issues/356/comments","events_url":"https://api.github.com/repos/mozilla/TTS/issues/356/events","html_url":"https://github.com/mozilla/TTS/issues/356","id":567068902,"node_id":"MDU6SXNzdWU1NjcwNjg5MDI=","number":356,"title":"Running compute_embeddings.py fails with \"TypeError: type object argument after ** must be a mapping, not str\"","user":{"login":"thorstenMueller","id":9558265,"node_id":"MDQ6VXNlcjk1NTgyNjU=","avatar_url":"https://avatars.githubusercontent.com/u/9558265?v=4","gravatar_id":"","url":"https://api.github.com/users/thorstenMueller","html_url":"https://github.com/thorstenMueller","followers_url":"https://api.github.com/users/thorstenMueller/followers","following_url":"https://api.github.com/users/thorstenMueller/following{/other_user}","gists_url":"https://api.github.com/users/thorstenMueller/gists{/gist_id}","starred_url":"https://api.github.com/users/thorstenMueller/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/thorstenMueller/subscriptions","organizations_url":"https://api.github.com/users/thorstenMueller/orgs","repos_url":"https://api.github.com/users/thorstenMueller/repos","events_url":"https://api.github.com/users/thorstenMueller/events{/privacy}","received_events_url":"https://api.github.com/users/thorstenMueller/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-02-18T18:11:51Z","updated_at":"2021-06-19T10:17:55Z","closed_at":"2020-02-19T19:45:46Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Hello dear community.\r\n\r\nThanks to the great support by @nmstoker i try to run compute_embeddings.py (master branch) on a ljspeech dataset in a venv environment:\r\n\r\n> python3 ./compute_embeddings.py __path__/best_model.pth.tar __path__/speaker_encoder/config.json __path__/LJSpeech-1.1 __path__/output\r\n\r\nThe process fails directly with following error:\r\n\r\n```\r\n > Setting up Audio Processor...\r\n | > sample_rate:22050\r\n | > num_mels:80\r\n | > min_level_db:-100\r\n | > frame_shift_ms:12.5\r\n | > frame_length_ms:50\r\n | > ref_level_db:20\r\n | > num_freq:1025\r\n | > power:1.5\r\n | > preemphasis:0.98\r\n | > griffin_lim_iters:60\r\n | > signal_norm:True\r\n | > symmetric_norm:True\r\n | > mel_fmin:0\r\n | > mel_fmax:8000.0\r\n | > max_norm:4.0\r\n | > clip_norm:True\r\n | > do_trim_silence:True\r\n | > sound_norm:False\r\n | > n_fft:2048\r\n | > hop_length:275\r\n | > win_length:1100\r\nTraceback (most recent call last):\r\n  File \"./compute_embeddings.py\", line 76, in <module>\r\n    model = SpeakerEncoder(**c.model)\r\nTypeError: type object argument after ** must be a mapping, not str\r\n```\r\n\r\n**dataset and config source**\r\n- LJSpeech dataset: https://keithito.com/LJ-Speech-Dataset/\r\n- Model and config.json (from released models): https://drive.google.com/drive/folders/10ymOlWHutqTtfDYhIbHULn2IKDKP0O9m\r\n\r\nSplit metadata.csv (even it shouldn't be needed for compute embeddings):\r\n```\r\nshuf metadata.csv > metadata_shuf.csv\r\nhead -n 12000 metadata_shuf.csv > metadata_train.csv\r\ntail -n 1100 metadata_shuf.csv > metadata_val.csv\r\n```\r\n\r\n**config.json:**\r\n```\r\n{\r\n\"github_branch\":\"* dev\",\r\n\"restore_path\":\"/home/thorsten/___dev/tts/datasets/mozilla-pretrained-ljspeech/best_model.pth.tar\",\r\n\"github_branch\":\"* dev\",\r\n    \"model\": \"Tacotron2\",          // one of the model in models/\r\n    \"run_name\": \"ljspeech-bn\",\r\n    \"run_description\": \"tacotron2 basline finetuned with BN prenet\",\r\n\r\n    // AUDIO PARAMETERS\r\n    \"audio\":{\r\n        // Audio processing parameters\r\n        \"num_mels\": 80,         // size of the mel spec frame.\r\n        \"num_freq\": 1025,       // number of stft frequency levels. Size of the linear spectogram frame.\r\n        \"sample_rate\": 22050,   // DATASET-RELATED: wav sample-rate. If different than the original data, it is resampled.\r\n        \"frame_length_ms\": 50,  // stft window length in ms.\r\n        \"frame_shift_ms\": 12.5, // stft window hop-lengh in ms.\r\n        \"preemphasis\": 0.98,    // pre-emphasis to reduce spec noise and make it more structured. If 0.0, no -pre-emphasis.\r\n        \"min_level_db\": -100,   // normalization range\r\n        \"ref_level_db\": 20,     // reference level db, theoretically 20db is the sound of air.\r\n        \"power\": 1.5,           // value to sharpen wav signals after GL algorithm.\r\n        \"griffin_lim_iters\": 60,// #griffin-lim iterations. 30-60 is a good range. Larger the value, slower the generation.\r\n        // Normalization parameters\r\n        \"signal_norm\": true,    // normalize the spec values in range [0, 1]\r\n        \"symmetric_norm\": true, // move normalization to range [-1, 1]\r\n        \"max_norm\": 4,          // scale normalization to range [-max_norm, max_norm] or [0, max_norm]\r\n        \"clip_norm\": true,      // clip normalized values into the range.\r\n        \"mel_fmin\": 0.0,         // minimum freq level for mel-spec. ~50 for male and ~95 for female voices. Tune for dataset!!\r\n        \"mel_fmax\": 8000.0,        // maximum freq level for mel-spec. Tune for dataset!!\r\n        \"do_trim_silence\": true  // enable trimming of slience of audio as you load it. LJspeech (false), TWEB (false), Nancy (true)\r\n    },\r\n\r\n    // DISTRIBUTED TRAINING\r\n    \"distributed\":{\r\n        \"backend\": \"nccl\",\r\n        \"url\": \"tcp:\\/\\/localhost:54321\"\r\n    },\r\n\r\n    \"reinit_layers\": [],    // give a list of layer names to restore from the given checkpoint. If not defined, it reloads all heuristically matching layers.\r\n\r\n    // TRAINING\r\n    \"batch_size\": 32,       // Batch size for training. Lower values than 32 might cause hard to learn attention. It is overwritten by 'gradual_training'.\r\n    \"eval_batch_size\":16,\r\n    \"r\": 7,                 // Number of decoder frames to predict per iteration. Set the initial values if gradual training is enabled.\r\n    \"gradual_training\": [[0, 7, 64], [1, 5, 64], [50000, 3, 32], [130000, 2, 16], [290000, 1, 32]], // ONLY TACOTRON - set gradual training steps [first_step, r, batch_size]. If it is null, gradual training is disabled.\r\n    \"loss_masking\": true,         // enable / disable loss masking against the sequence padding.\r\n\r\n    // VALIDATION\r\n    \"run_eval\": true,\r\n    \"test_delay_epochs\": 10,  //Until attention is aligned, testing only wastes computation time.\r\n    \"test_sentences_file\": null,  // set a file to load sentences to be used for testing. If it is null then we use default english sentences.\r\n\r\n    // OPTIMIZER\r\n    \"grad_clip\": 1,                // upper limit for gradients for clipping.\r\n    \"epochs\": 1000,                // total number of epochs to train.\r\n    \"lr\": 0.0001,                  // Initial learning rate. If Noam decay is active, maximum learning rate.\r\n    \"lr_decay\": false,             // if true, Noam learning rate decaying is applied through training.\r\n    \"wd\": 0.000001,         // Weight decay weight.\r\n    \"warmup_steps\": 4000,          // Noam decay steps to increase the learning rate from 0 to \"lr\"\r\n\r\n    // TACOTRON PRENET\r\n    \"memory_size\": -1,              // ONLY TACOTRON - size of the memory queue used fro storing last decoder predictions for auto-regression. If < 0, memory queue is disabled and decoder only uses the last prediction frame.\r\n    \"prenet_type\": \"bn\",     // \"original\" or \"bn\".\r\n    \"prenet_dropout\": false,        // enable/disable dropout at prenet.\r\n\r\n    // ATTENTION\r\n    \"attention_type\": \"original\",  // 'original' or 'graves'\r\n    \"attention_heads\": 5,          // number of attention heads (only for 'graves')\r\n    \"attention_norm\": \"sigmoid\",   // softmax or sigmoid. Suggested to use softmax for Tacotron2 and sigmoid for Tacotron.\r\n    \"windowing\": false,            // Enables attention windowing. Used only in eval mode.\r\n    \"use_forward_attn\": false,      // if it uses forward attention. In general, it aligns faster.\r\n    \"forward_attn_mask\": false,    // Additional masking forcing monotonicity only in eval mode.\r\n    \"transition_agent\": false,     // enable/disable transition agent of forward attention.\r\n    \"location_attn\": true,        // enable_disable location sensitive attention. It is enabled for TACOTRON by default.\r\n    \"bidirectional_decoder\": false,  // use https://arxiv.org/abs/1907.09006. Use it, if attention does not work well with your dataset.\r\n\r\n    // STOPNET\r\n    \"stopnet\": true,               // Train stopnet predicting the end of synthesis.\r\n    \"separate_stopnet\": true,     // Train stopnet seperately if 'stopnet==true'. It prevents stopnet loss to influence the rest of the model. It causes a better model, but it trains SLOWER.\r\n\r\n    // TENSORBOARD and LOGGING\r\n    \"print_step\": 25,       // Number of steps to log traning on console.\r\n    \"save_step\": 10000,      // Number of training steps expected to save traninpg stats and checkpoints.\r\n    \"checkpoint\": true,     // If true, it saves checkpoints per \"save_step\"\r\n    \"tb_model_param_stats\": false,     // true, plots param stats per layer on tensorboard. Might be memory consuming, but good for debugging.\r\n\r\n    // DATA LOADING\r\n    \"text_cleaner\": \"phoneme_cleaners\",\r\n    \"enable_eos_bos_chars\": false, // enable/disable beginning of sentence and end of sentence chars.\r\n    \"num_loader_workers\": 4,        // number of training data loader processes. Don't set it too big. 4-8 are good values.\r\n    \"num_val_loader_workers\": 4,    // number of evaluation data loader processes.\r\n    \"batch_group_size\": 0,  //Number of batches to shuffle after bucketing.\r\n    \"min_seq_len\": 6,       // DATASET-RELATED: minimum text length to use in training\r\n    \"max_seq_len\": 150,     // DATASET-RELATED: maximum text length\r\n\r\n    // PATHS\r\n    \"output_path\": \"/home/thorsten/___dev/tts/datasets/mozilla-pretrained-ljspeech/keep/\",      // DATASET-RELATED: output path for all training outputs.\r\n\r\n    // PHONEMES\r\n    \"phoneme_cache_path\": \"ljspeech_ph_cache\",  // phoneme computation is slow, therefore, it caches results in the given folder.\r\n    \"use_phonemes\": true,           // use phonemes instead of raw characters. It is suggested for better pronounciation.\r\n    \"phoneme_language\": \"en-us\",     // depending on your target language, pick one from  https://github.com/bootphon/phonemizer#languages\r\n    // MULTI-SPEAKER and GST\r\n    \"use_speaker_embedding\": false,     // use speaker embedding to enable multi-speaker learning.\r\n    \"style_wav_for_test\": null,          // path to style wav file to be used in TacotronGST inference.\r\n    \"use_gst\": false,       // TACOTRON ONLY: use global style tokens\r\n\r\n    // DATASETS\r\n    \"datasets\":   // List of datasets. They all merged and they get different speaker_ids.\r\n        [\r\n            {\r\n                \"name\": \"ljspeech\",\r\n                //\"path\": \"/data/ro/shared/data/keithito/LJSpeech-1.1/\",\r\n                \"path\": \"/home/thorsten/___dev/tts/datasets/mozilla-pretrained-ljspeech/LJSpeech-1.1/\",\r\n                //\"path\": \"/home/erogol/Data/LJSpeech-1.1\",\r\n                \"meta_file_train\": \"metadata_train.csv\",\r\n                \"meta_file_val\": \"metadata_val.csv\"\r\n            }\r\n        ]\r\n\r\n}\r\n```\r\n\r\n**General information:**\r\n- Ubuntu 18.04.4 LTS\r\n- Venv Environment\r\n- Python 3.6.9\r\n- Pip3 version 9.0.1\r\n\r\n**Output from pip3 list:**\r\n```\r\nDEPRECATION: The default format will switch to columns in the future. You can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.\r\nabsl-py (0.9.0)\r\nattrdict (2.0.1)\r\nattrs (19.3.0)\r\naudioread (2.1.8)\r\nbokeh (1.4.0)\r\ncachetools (4.0.0)\r\ncertifi (2019.11.28)\r\ncffi (1.14.0)\r\nchardet (3.0.4)\r\nClick (7.0)\r\nclldutils (3.5.0)\r\ncolorlog (4.1.0)\r\ncsvw (1.7.0)\r\ncycler (0.10.0)\r\ndecorator (4.4.1)\r\nFlask (1.1.1)\r\ngoogle-auth (1.11.2)\r\ngoogle-auth-oauthlib (0.4.1)\r\ngrpcio (1.27.2)\r\nidna (2.8)\r\nisodate (0.6.0)\r\nitsdangerous (1.1.0)\r\nJinja2 (2.11.1)\r\njoblib (0.14.1)\r\nkiwisolver (1.1.0)\r\nlibrosa (0.7.2)\r\nllvmlite (0.31.0)\r\nMarkdown (3.2.1)\r\nMarkupSafe (1.1.1)\r\nmatplotlib (3.1.3)\r\nnumba (0.48.0)\r\nnumpy (1.18.1)\r\noauthlib (3.1.0)\r\npackaging (20.1)\r\nphonemizer (2.1)\r\nPillow (7.0.0)\r\npip (9.0.1)\r\npkg-resources (0.0.0)\r\nprotobuf (3.11.3)\r\npyasn1 (0.4.8)\r\npyasn1-modules (0.2.8)\r\npycparser (2.19)\r\npyparsing (2.4.6)\r\npython-dateutil (2.8.1)\r\nPyYAML (5.3)\r\nregex (2020.1.8)\r\nrequests (2.22.0)\r\nrequests-oauthlib (1.3.0)\r\nresampy (0.2.2)\r\nrfc3986 (1.3.2)\r\nrsa (4.0)\r\nscikit-learn (0.22.1)\r\nscipy (1.4.1)\r\nsegments (2.1.3)\r\nsetuptools (45.2.0)\r\nsix (1.14.0)\r\nSoundFile (0.10.3.post1)\r\ntabulate (0.8.6)\r\ntensorboard (2.1.0)\r\ntensorboardX (2.0)\r\ntorch (1.4.0)\r\ntornado (6.0.3)\r\ntqdm (4.42.1)\r\ntts (1.1)\r\nUnidecode (1.1.1)\r\nuritemplate (3.0.1)\r\nurllib3 (1.25.8)\r\nWerkzeug (1.0.0)\r\nwheel (0.34.2)\r\n```\r\n","closed_by":{"login":"thorstenMueller","id":9558265,"node_id":"MDQ6VXNlcjk1NTgyNjU=","avatar_url":"https://avatars.githubusercontent.com/u/9558265?v=4","gravatar_id":"","url":"https://api.github.com/users/thorstenMueller","html_url":"https://github.com/thorstenMueller","followers_url":"https://api.github.com/users/thorstenMueller/followers","following_url":"https://api.github.com/users/thorstenMueller/following{/other_user}","gists_url":"https://api.github.com/users/thorstenMueller/gists{/gist_id}","starred_url":"https://api.github.com/users/thorstenMueller/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/thorstenMueller/subscriptions","organizations_url":"https://api.github.com/users/thorstenMueller/orgs","repos_url":"https://api.github.com/users/thorstenMueller/repos","events_url":"https://api.github.com/users/thorstenMueller/events{/privacy}","received_events_url":"https://api.github.com/users/thorstenMueller/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mozilla/TTS/issues/356/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mozilla/TTS/issues/356/timeline","performed_via_github_app":null,"state_reason":"completed"}