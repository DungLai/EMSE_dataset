{"url":"https://api.github.com/repos/mozilla/TTS/issues/383","repository_url":"https://api.github.com/repos/mozilla/TTS","labels_url":"https://api.github.com/repos/mozilla/TTS/issues/383/labels{/name}","comments_url":"https://api.github.com/repos/mozilla/TTS/issues/383/comments","events_url":"https://api.github.com/repos/mozilla/TTS/issues/383/events","html_url":"https://github.com/mozilla/TTS/issues/383","id":580030282,"node_id":"MDU6SXNzdWU1ODAwMzAyODI=","number":383,"title":"pth.tar to ONNX","user":{"login":"anasvaf","id":23378874,"node_id":"MDQ6VXNlcjIzMzc4ODc0","avatar_url":"https://avatars.githubusercontent.com/u/23378874?v=4","gravatar_id":"","url":"https://api.github.com/users/anasvaf","html_url":"https://github.com/anasvaf","followers_url":"https://api.github.com/users/anasvaf/followers","following_url":"https://api.github.com/users/anasvaf/following{/other_user}","gists_url":"https://api.github.com/users/anasvaf/gists{/gist_id}","starred_url":"https://api.github.com/users/anasvaf/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/anasvaf/subscriptions","organizations_url":"https://api.github.com/users/anasvaf/orgs","repos_url":"https://api.github.com/users/anasvaf/repos","events_url":"https://api.github.com/users/anasvaf/events{/privacy}","received_events_url":"https://api.github.com/users/anasvaf/received_events","type":"User","site_admin":false},"labels":[{"id":813922298,"node_id":"MDU6TGFiZWw4MTM5MjIyOTg=","url":"https://api.github.com/repos/mozilla/TTS/labels/wontfix","name":"wontfix","color":"ffffff","default":true,"description":"This will not be worked on"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-03-12T15:42:59Z","updated_at":"2021-01-08T06:16:17Z","closed_at":"2020-05-18T21:25:24Z","author_association":"NONE","active_lock_reason":null,"body":"Hello,\r\n\r\nI am trying to convert the .pth.tar checkpoint to a .onnx file. I understand that this issue has been discussed a lot in the past but I could not find a final answer regarding the conversion.\r\n\r\nSince the torch.onnx.export point to the forward definition of tacotron-2, we have the inputs as follows:\r\n_text, text_length, mel_specs_\r\n\r\nI am trying to create my dummy input with the following code:\r\n```\r\nimport torch.onnx\r\nfrom torch.autograd import Variable\r\n\r\ntext_inputs = Variable(torch.randn(64, 163, device='cuda'))\r\ntext_lengths = Variable(torch.randn(64, device='cuda'))\r\nmels = Variable(torch.randn(64, 80, 851, device='cuda'))\r\n\r\ndummy_input = (text_inputs, text_lengths, mels)\r\n# dummy_input = Variable(torch.randn(30, 128, 257, 80, 2)) \r\nonnx_filename = \"tts.onnx\"\r\ntorch.onnx.export(model, dummy_input, onnx_filename)\r\n```\r\n\r\nHowever, I am getting the following error:\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-9-fd3bcec9057b> in <module>\r\n      6 # dummy_input = Variable(torch.randn(30, 128, 257, 80, 2))\r\n      7 onnx_filename = \"tts.onnx\"\r\n----> 8 torch.onnx.export(model, dummy_input, onnx_filename)\r\n\r\nc:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\onnx\\__init__.py in export(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs)\r\n    146                         operator_export_type, opset_version, _retain_param_name,\r\n    147                         do_constant_folding, example_outputs,\r\n--> 148                         strip_doc_string, dynamic_axes, keep_initializers_as_inputs)\r\n    149 \r\n    150 \r\n\r\nc:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\onnx\\utils.py in export(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs)\r\n     64             _retain_param_name=_retain_param_name, do_constant_folding=do_constant_folding,\r\n     65             example_outputs=example_outputs, strip_doc_string=strip_doc_string,\r\n---> 66             dynamic_axes=dynamic_axes, keep_initializers_as_inputs=keep_initializers_as_inputs)\r\n     67 \r\n     68 \r\n\r\nc:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\onnx\\utils.py in _export(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, propagate, opset_version, _retain_param_name, do_constant_folding, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size)\r\n    414                                                         example_outputs, propagate,\r\n    415                                                         _retain_param_name, do_constant_folding,\r\n--> 416                                                         fixed_batch_size=fixed_batch_size)\r\n    417 \r\n    418         # TODO: Don't allocate a in-memory string for the protobuf\r\n\r\nc:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\onnx\\utils.py in _model_to_graph(model, args, verbose, training, input_names, output_names, operator_export_type, example_outputs, propagate, _retain_param_name, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size)\r\n    277             model.graph, tuple(in_vars), False, propagate)\r\n    278     else:\r\n--> 279         graph, torch_out = _trace_and_get_graph_from_model(model, args, training)\r\n    280         state_dict = _unique_state_dict(model)\r\n    281         params = list(state_dict.values())\r\n\r\nc:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\onnx\\utils.py in _trace_and_get_graph_from_model(model, args, training)\r\n    234     # training mode was.)\r\n    235     with set_training(model, training):\r\n--> 236         trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(model, args, _force_outplace=True, _return_inputs_states=True)\r\n    237         warn_on_static_input_change(inputs_states)\r\n    238 \r\n\r\nc:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\jit\\__init__.py in _get_trace_graph(f, args, kwargs, _force_outplace, return_inputs, _return_inputs_states)\r\n    275     if not isinstance(args, tuple):\r\n    276         args = (args,)\r\n--> 277     outs = ONNXTracedModule(f, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\r\n    278     return outs\r\n    279 \r\n\r\nc:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py in __call__(self, *input, **kwargs)\r\n    530             result = self._slow_forward(*input, **kwargs)\r\n    531         else:\r\n--> 532             result = self.forward(*input, **kwargs)\r\n    533         for hook in self._forward_hooks.values():\r\n    534             hook_result = hook(self, input, result)\r\n\r\nc:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\jit\\__init__.py in forward(self, *args)\r\n    358             in_vars + module_state,\r\n    359             _create_interpreter_name_lookup_fn(),\r\n--> 360             self._force_outplace,\r\n    361         )\r\n    362 \r\n\r\nc:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\jit\\__init__.py in wrapper(*args)\r\n    345             if self._return_inputs_states:\r\n    346                 inputs_states.append(_unflatten(args[:len(in_vars)], in_desc))\r\n--> 347             outs.append(self.inner(*trace_inputs))\r\n    348             if self._return_inputs_states:\r\n    349                 inputs_states[0] = (inputs_states[0], trace_inputs)\r\n\r\nc:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py in __call__(self, *input, **kwargs)\r\n    528                 input = result\r\n    529         if torch._C._get_tracing_state():\r\n--> 530             result = self._slow_forward(*input, **kwargs)\r\n    531         else:\r\n    532             result = self.forward(*input, **kwargs)\r\n\r\nc:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py in _slow_forward(self, *input, **kwargs)\r\n    514                 recording_scopes = False\r\n    515         try:\r\n--> 516             result = self.forward(*input, **kwargs)\r\n    517         finally:\r\n    518             if recording_scopes:\r\n\r\nD:\\tts\\TTS\\models\\tacotron2.py in forward(self, text, text_lengths, mel_specs)\r\n     29     def forward(self, text, text_lengths, mel_specs=None):\r\n     30         # compute mask for padding\r\n---> 31         mask = sequence_mask(text_lengths).to(text.device)\r\n     32         embedded_inputs = self.embedding(text).transpose(1, 2)\r\n     33         encoder_outputs = self.encoder(embedded_inputs, text_lengths)\r\n\r\nD:\\tts\\TTS\\utils\\generic_utils.py in sequence_mask(sequence_length, max_len)\r\n    205     batch_size = sequence_length.size(0)\r\n    206     seq_range = torch.arange(0, max_len).long()\r\n--> 207     seq_range_expand = seq_range.unsqueeze(0).expand(batch_size, max_len)\r\n    208     if sequence_length.is_cuda:\r\n    209         seq_range_expand = seq_range_expand.cuda()\r\n\r\nRuntimeError: The expanded size of the tensor (1) must match the existing size (2) at non-singleton dimension 1.  Target sizes: [64, 1].  Tensor sizes: [1, 2]\r\n```\r\n\r\nDoes anyone have any idea with this issue? My onnx version is 1.6.0 and the PyTorch version is 1.4.0 with CUDA 10.1.\r\n\r\nThank you in advance.\r\n\r\nBest,\r\nTasos","closed_by":{"login":"stale[bot]","id":26384082,"node_id":"MDM6Qm90MjYzODQwODI=","avatar_url":"https://avatars.githubusercontent.com/in/1724?v=4","gravatar_id":"","url":"https://api.github.com/users/stale%5Bbot%5D","html_url":"https://github.com/apps/stale","followers_url":"https://api.github.com/users/stale%5Bbot%5D/followers","following_url":"https://api.github.com/users/stale%5Bbot%5D/following{/other_user}","gists_url":"https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}","starred_url":"https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stale%5Bbot%5D/subscriptions","organizations_url":"https://api.github.com/users/stale%5Bbot%5D/orgs","repos_url":"https://api.github.com/users/stale%5Bbot%5D/repos","events_url":"https://api.github.com/users/stale%5Bbot%5D/events{/privacy}","received_events_url":"https://api.github.com/users/stale%5Bbot%5D/received_events","type":"Bot","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mozilla/TTS/issues/383/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mozilla/TTS/issues/383/timeline","performed_via_github_app":null,"state_reason":"completed"}