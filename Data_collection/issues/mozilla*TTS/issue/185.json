{"url":"https://api.github.com/repos/mozilla/TTS/issues/185","repository_url":"https://api.github.com/repos/mozilla/TTS","labels_url":"https://api.github.com/repos/mozilla/TTS/issues/185/labels{/name}","comments_url":"https://api.github.com/repos/mozilla/TTS/issues/185/comments","events_url":"https://api.github.com/repos/mozilla/TTS/issues/185/events","html_url":"https://github.com/mozilla/TTS/issues/185","id":438747688,"node_id":"MDU6SXNzdWU0Mzg3NDc2ODg=","number":185,"title":"export model PyTorch -> ONNX model -> Tensorflow?","user":{"login":"MuruganR96","id":35978784,"node_id":"MDQ6VXNlcjM1OTc4Nzg0","avatar_url":"https://avatars.githubusercontent.com/u/35978784?v=4","gravatar_id":"","url":"https://api.github.com/users/MuruganR96","html_url":"https://github.com/MuruganR96","followers_url":"https://api.github.com/users/MuruganR96/followers","following_url":"https://api.github.com/users/MuruganR96/following{/other_user}","gists_url":"https://api.github.com/users/MuruganR96/gists{/gist_id}","starred_url":"https://api.github.com/users/MuruganR96/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MuruganR96/subscriptions","organizations_url":"https://api.github.com/users/MuruganR96/orgs","repos_url":"https://api.github.com/users/MuruganR96/repos","events_url":"https://api.github.com/users/MuruganR96/events{/privacy}","received_events_url":"https://api.github.com/users/MuruganR96/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2019-04-30T12:16:10Z","updated_at":"2019-05-02T04:02:22Z","closed_at":"2019-04-30T21:54:43Z","author_association":"NONE","active_lock_reason":null,"body":"sir i tried to convert TTS PyTorch Pretrained model to Tensorflow by using ONNX open source platform. \r\n\r\ni tried but i got some issues, doubts. i can share that in our repo.\r\n\r\n```\r\nimport sys\r\nsys.path.insert(0, \"/home/admin1/speech_recognition/text2speech/new_one\")\r\nimport io\r\nimport torch \r\nimport time\r\nimport numpy as np\r\nfrom collections import OrderedDict\r\nfrom matplotlib import pylab as plt\r\nfrom torch.autograd import Variable\r\nimport torch.onnx\r\nimport librosa\r\nimport librosa.display\r\n\r\nfrom TTS.models.tacotron import Tacotron \r\nfrom TTS.layers import *\r\nfrom TTS.utils.data import *\r\nfrom TTS.utils.audio import AudioProcessor\r\nfrom TTS.utils.generic_utils import load_config\r\nfrom TTS.utils.text import text_to_sequence\r\nfrom TTS.utils.synthesis import synthesis\r\nfrom TTS.utils.visual import visualize\r\nfrom utils.text.symbols import symbols, phonemes\r\n\r\nROOT_PATH = '/home/admin1/speech_recognition/text2speech/new_one/TTS/queue-February-16-2019_03+16AM-90f0cd6/'\r\nMODEL_PATH = ROOT_PATH + 'best_model.pth.tar'\r\nCONFIG_PATH = ROOT_PATH + '/config.json'\r\nOUT_FOLDER = ROOT_PATH + '/test'\r\nCONFIG = load_config(CONFIG_PATH)\r\nuse_cuda = True\r\n\r\nCONFIG.audio[\"preemphasis\"] = 0.97\r\nap = AudioProcessor(**CONFIG.audio)       \r\n\r\ncp = torch.load(MODEL_PATH)\r\n\r\nprint(cp['step'])\r\nnum_chars = len(phonemes) if CONFIG.use_phonemes else len(symbols)\r\nmodel = Tacotron(num_chars, CONFIG.embedding_size, CONFIG.audio['num_freq'], CONFIG.audio['num_mels'], CONFIG.r, attn_windowing=False)\r\nmodel.load_state_dict(cp['model'])\r\nmodel.eval()\r\n\r\nx = Variable(torch.randn(61, 256, 1025, 80, 2)) \r\ny = x.long()\r\ny = y.cuda() #dummy input\r\ntorch.onnx.export(model, y, \"tts.onnx\")\r\n```\r\nwe have to pass one input variable (dummy variable) with the correct shape. \r\n\r\nin this place i was struggled lot sir.\r\n\r\ni have a doubt.\r\n1) what is our input variable shape? \r\ne.g [1,2] is shape of the input variable(text). \r\n(or )\r\ntactorn five dimentional arguments.\r\ne.g (61, 256, 1025, 80, 2)\r\n\r\nsir i was created issue in PyTorch.\r\nhttps://github.com/pytorch/pytorch/issues/19951#issue-438647251\r\n\r\ni asked this issue about ONNX community also sir.\r\nhttps://github.com/onnx/onnx/issues/1956#issuecomment-487817663\r\n\r\n\r\nsir. i will show you my error logs.:)\r\n\r\nGPU.\r\n```\r\n\r\nTraceback (most recent call last):\r\n  File \"export_model.py\", line 48, in <module>\r\n    torch.onnx.export(model, y, \"tts.onnx\")\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 27, in export\r\n    return utils.export(*args, **kwargs)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/onnx/utils.py\", line 104, in export\r\n    operator_export_type=operator_export_type)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/onnx/utils.py\", line 281, in _export\r\n    example_outputs, propagate)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/onnx/utils.py\", line 224, in _model_to_graph\r\n    graph, torch_out = _trace_and_get_graph_from_model(model, args, training)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/onnx/utils.py\", line 192, in _trace_and_get_graph_from_model\r\n    trace, torch_out = torch.jit.get_trace_graph(model, args, _force_outplace=True)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/jit/__init__.py\", line 197, in get_trace_graph\r\n    return LegacyTracedModule(f, _force_outplace)(*args, **kwargs)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/jit/__init__.py\", line 252, in forward\r\n    out = self.inner(*trace_inputs)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 487, in __call__\r\n    result = self._slow_forward(*input, **kwargs)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in _slow_forward\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/TTS/models/tacotron.py\", line 35, in forward\r\n    inputs = self.embedding(characters)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 487, in __call__\r\n    result = self._slow_forward(*input, **kwargs)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in _slow_forward\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/nn/modules/sparse.py\", line 118, in forward\r\n    self.norm_type, self.scale_grad_by_freq, self.sparse)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/nn/functional.py\", line 1454, in embedding\r\n    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\r\nRuntimeError: Expected object of backend CPU but got backend CUDA for argument #3 'index'\r\n```\r\nCPU only.\r\n```\r\nTraceback (most recent call last):\r\n  File \"export_model.py\", line 48, in <module>\r\n    torch.onnx.export(model, y, \"tts.onnx\")\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 27, in export\r\n    return utils.export(*args, **kwargs)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/onnx/utils.py\", line 104, in export\r\n    operator_export_type=operator_export_type)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/onnx/utils.py\", line 281, in _export\r\n    example_outputs, propagate)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/onnx/utils.py\", line 224, in _model_to_graph\r\n    graph, torch_out = _trace_and_get_graph_from_model(model, args, training)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/onnx/utils.py\", line 192, in _trace_and_get_graph_from_model\r\n    trace, torch_out = torch.jit.get_trace_graph(model, args, _force_outplace=True)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/jit/__init__.py\", line 197, in get_trace_graph\r\n    return LegacyTracedModule(f, _force_outplace)(*args, **kwargs)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/jit/__init__.py\", line 252, in forward\r\n    out = self.inner(*trace_inputs)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 487, in __call__\r\n    result = self._slow_forward(*input, **kwargs)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in _slow_forward\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/TTS/models/tacotron.py\", line 35, in forward\r\n    inputs = self.embedding(characters)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 487, in __call__\r\n    result = self._slow_forward(*input, **kwargs)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in _slow_forward\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/nn/modules/sparse.py\", line 118, in forward\r\n    self.norm_type, self.scale_grad_by_freq, self.sparse)\r\n  File \"/home/admin1/speech_recognition/text2speech/new_one/env/lib/python3.6/site-packages/torch/nn/functional.py\", line 1454, in embedding\r\n    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\r\nRuntimeError: $ Torch: not enough memory: you tried to allocate 2442GB. Buy new RAM! at /pytorch/aten/src/TH/THGeneral.cpp:201\r\n\r\n```\r\ni was passed huge dimensional input variable for our TTS. that is why memory allocation error occurred.\r\n\r\ni don't know full model architecture.\r\nsir Please help me to improve this thought. export model pytorch to tensorflow.\r\n\r\nsir Please give some suggestion about input from the architecture. \r\n\r\nThank you so much TTS Team.:)","closed_by":{"login":"erogol","id":1402048,"node_id":"MDQ6VXNlcjE0MDIwNDg=","avatar_url":"https://avatars.githubusercontent.com/u/1402048?v=4","gravatar_id":"","url":"https://api.github.com/users/erogol","html_url":"https://github.com/erogol","followers_url":"https://api.github.com/users/erogol/followers","following_url":"https://api.github.com/users/erogol/following{/other_user}","gists_url":"https://api.github.com/users/erogol/gists{/gist_id}","starred_url":"https://api.github.com/users/erogol/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/erogol/subscriptions","organizations_url":"https://api.github.com/users/erogol/orgs","repos_url":"https://api.github.com/users/erogol/repos","events_url":"https://api.github.com/users/erogol/events{/privacy}","received_events_url":"https://api.github.com/users/erogol/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mozilla/TTS/issues/185/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mozilla/TTS/issues/185/timeline","performed_via_github_app":null,"state_reason":"completed"}