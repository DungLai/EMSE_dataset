{"url":"https://api.github.com/repos/mozilla/TTS/issues/101","repository_url":"https://api.github.com/repos/mozilla/TTS","labels_url":"https://api.github.com/repos/mozilla/TTS/issues/101/labels{/name}","comments_url":"https://api.github.com/repos/mozilla/TTS/issues/101/comments","events_url":"https://api.github.com/repos/mozilla/TTS/issues/101/events","html_url":"https://github.com/mozilla/TTS/issues/101","id":400798611,"node_id":"MDU6SXNzdWU0MDA3OTg2MTE=","number":101,"title":"Convert pth.tar to ONNX","user":{"login":"PegAldernine","id":46821488,"node_id":"MDQ6VXNlcjQ2ODIxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/46821488?v=4","gravatar_id":"","url":"https://api.github.com/users/PegAldernine","html_url":"https://github.com/PegAldernine","followers_url":"https://api.github.com/users/PegAldernine/followers","following_url":"https://api.github.com/users/PegAldernine/following{/other_user}","gists_url":"https://api.github.com/users/PegAldernine/gists{/gist_id}","starred_url":"https://api.github.com/users/PegAldernine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/PegAldernine/subscriptions","organizations_url":"https://api.github.com/users/PegAldernine/orgs","repos_url":"https://api.github.com/users/PegAldernine/repos","events_url":"https://api.github.com/users/PegAldernine/events{/privacy}","received_events_url":"https://api.github.com/users/PegAldernine/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2019-01-18T16:31:56Z","updated_at":"2019-03-31T02:26:48Z","closed_at":"2019-02-15T09:37:59Z","author_association":"NONE","active_lock_reason":null,"body":"Hi, I am trying to convert the trained model from torch into ONNX.\r\nThe conversion script target to run this function \"torch.onnx.export\". Most of the forward functions seems to run (when I call onnx.export) except the \"forward\" for \"Decoder\" from layer.tacotron.\r\nQuestions:\r\n1. Can this model be converted to onnx? (Do you know is some layers are not currently supported?)\r\n2. Do you know what am I doing wrong in the conversion script? (code and warnings/error below)\r\n3. Is there an already converted model to onnx and if so from where can I download it?\r\nThanks in advance!\r\n\r\n**Script:**\r\n\r\nimport torch\r\nimport torch.onnx\r\nfrom models.tacotron import Tacotron\r\nfrom layers.tacotron import Prenet\r\n\r\ndevice_cuda = torch.device(\"cuda:0\")\r\nmodel = Tacotron().to(device_cuda)\r\nstate_dict = torch.load(\"F:/TTS_mozilla/TTS-master/best_model_v1.pth.tar\")\r\njust_model_dict = state_dict[\"model\"]\r\nmodel.load_state_dict(just_model_dict)\r\ndummy_input = torch.randint(0, 24, (8, 128)).long().to(device_cuda)\r\ntorch.onnx.export(model, dummy_input, \"onnx_model_name.onnx\", verbose=True)\r\n\r\n**Warnings:**\r\n\r\n | > Number of characters : 149\r\nF:\\TTS_mozilla\\TTS-master\\layers\\tacotron.py:217: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  if x.size(-1) == self.in_features:\r\nF:\\TTS_mozilla\\TTS-master\\layers\\tacotron.py:227: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert x.size(1) == self.conv_bank_features * len(self.conv1d_banks)\r\nF:\\TTS_mozilla\\TTS-master\\layers\\tacotron.py:234: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator add_. This might cause the trace to be incorrect, because all other views that also reference this data will not not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.\r\n  x += inputs\r\nF:\\TTS_mozilla\\TTS-master\\layers\\tacotron.py:396: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  initial_memory = inputs.data.new(B, self.memory_dim * self.r).zero_()\r\nF:\\TTS_mozilla\\TTS-master\\layers\\tacotron.py:401: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  attention_rnn_hidden = inputs.data.new(B, 256).zero_()\r\nF:\\TTS_mozilla\\TTS-master\\layers\\tacotron.py:404: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  for _ in range(len(self.decoder_rnns))\r\nF:\\TTS_mozilla\\TTS-master\\layers\\tacotron.py:406: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  current_context_vec = inputs.data.new(B, self.in_features).zero_()\r\nF:\\TTS_mozilla\\TTS-master\\layers\\tacotron.py:408: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  attention = inputs.data.new(B, T).zero_()\r\nF:\\TTS_mozilla\\TTS-master\\layers\\tacotron.py:409: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  attention_cum = inputs.data.new(B, T).zero_()\r\n\r\n**Error:**\r\n\r\nTraceback (most recent call last):\r\n  File \"_convert2onnx.py\", line 14, in <module>\r\n    torch.onnx.export(model, dummy_input, \"onnx_model_name.onnx\", verbose=True)\r\n  File \"C:\\anaconda\\envs\\tts_env\\lib\\site-packages\\torch\\onnx\\__init__.py\", line 27, in export\r\n    return utils.export(*args, **kwargs)\r\n  File \"C:\\anaconda\\envs\\tts_env\\lib\\site-packages\\torch\\onnx\\utils.py\", line 104, in export\r\n    operator_export_type=operator_export_type)\r\n  File \"C:\\anaconda\\envs\\tts_env\\lib\\site-packages\\torch\\onnx\\utils.py\", line 281, in _export\r\n    example_outputs, propagate)\r\n  File \"C:\\anaconda\\envs\\tts_env\\lib\\site-packages\\torch\\onnx\\utils.py\", line 224, in _model_to_graph\r\n    graph, torch_out = _trace_and_get_graph_from_model(model, args, training)\r\n  File \"C:\\anaconda\\envs\\tts_env\\lib\\site-packages\\torch\\onnx\\utils.py\", line 192, in _trace_and_get_graph_from_model\r\n    trace, torch_out = torch.jit.get_trace_graph(model, args, _force_outplace=True)\r\n  File \"C:\\anaconda\\envs\\tts_env\\lib\\site-packages\\torch\\jit\\__init__.py\", line 196, in get_trace_graph\r\n    return LegacyTracedModule(f, _force_outplace)(*args, **kwargs)\r\n  File \"C:\\anaconda\\envs\\tts_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 491, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"C:\\anaconda\\envs\\tts_env\\lib\\site-packages\\torch\\jit\\__init__.py\", line 251, in forward\r\n    out = self.inner(*trace_inputs)\r\n  File \"C:\\anaconda\\envs\\tts_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 489, in __call__\r\n    result = self._slow_forward(*input, **kwargs)\r\n  File \"C:\\anaconda\\envs\\tts_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 478, in _slow_forward\r\n    result = self.forward(*input, **kwargs)\r\n  File \"F:\\TTS_mozilla\\TTS-master\\models\\tacotron.py\", line 37, in forward\r\n    encoder_outputs, mel_specs, mask)\r\n  File \"C:\\anaconda\\envs\\tts_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 489, in __call__\r\n    result = self._slow_forward(*input, **kwargs)\r\n  File \"C:\\anaconda\\envs\\tts_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 478, in _slow_forward\r\n    result = self.forward(*input, **kwargs)\r\n  **File \"F:\\TTS_mozilla\\TTS-master\\layers\\tacotron.py\", line 438, in forward**\r\n    inputs, attention_cat, mask, t)\r\n  File \"C:\\anaconda\\envs\\tts_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 489, in __call__\r\n    result = self._slow_forward(*input, **kwargs)\r\n  File \"C:\\anaconda\\envs\\tts_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 465, in _slow_forward\r\n    input_vars = tuple(torch.autograd.function._iter_tensors(input))\r\n  File \"C:\\anaconda\\envs\\tts_env\\lib\\site-packages\\torch\\autograd\\function.py\", line 284, in _iter\r\n    for var in _iter(o):\r\n  File \"C:\\anaconda\\envs\\tts_env\\lib\\site-packages\\torch\\autograd\\function.py\", line 293, in _iter\r\n    if condition_msg else \"\"))\r\nValueError: Auto nesting doesn't know how to process an input object of type int. Accepted types: Tensors, or lists/tuples of them\r\n","closed_by":{"login":"erogol","id":1402048,"node_id":"MDQ6VXNlcjE0MDIwNDg=","avatar_url":"https://avatars.githubusercontent.com/u/1402048?v=4","gravatar_id":"","url":"https://api.github.com/users/erogol","html_url":"https://github.com/erogol","followers_url":"https://api.github.com/users/erogol/followers","following_url":"https://api.github.com/users/erogol/following{/other_user}","gists_url":"https://api.github.com/users/erogol/gists{/gist_id}","starred_url":"https://api.github.com/users/erogol/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/erogol/subscriptions","organizations_url":"https://api.github.com/users/erogol/orgs","repos_url":"https://api.github.com/users/erogol/repos","events_url":"https://api.github.com/users/erogol/events{/privacy}","received_events_url":"https://api.github.com/users/erogol/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mozilla/TTS/issues/101/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":1},"timeline_url":"https://api.github.com/repos/mozilla/TTS/issues/101/timeline","performed_via_github_app":null,"state_reason":"completed"}