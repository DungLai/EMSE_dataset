{"url":"https://api.github.com/repos/mozilla/TTS/issues/180","repository_url":"https://api.github.com/repos/mozilla/TTS","labels_url":"https://api.github.com/repos/mozilla/TTS/issues/180/labels{/name}","comments_url":"https://api.github.com/repos/mozilla/TTS/issues/180/comments","events_url":"https://api.github.com/repos/mozilla/TTS/issues/180/events","html_url":"https://github.com/mozilla/TTS/issues/180","id":438024671,"node_id":"MDU6SXNzdWU0MzgwMjQ2NzE=","number":180,"title":"RuntimeError: CUDA out of memory while distribute training ","user":{"login":"PPGGG","id":11624203,"node_id":"MDQ6VXNlcjExNjI0MjAz","avatar_url":"https://avatars.githubusercontent.com/u/11624203?v=4","gravatar_id":"","url":"https://api.github.com/users/PPGGG","html_url":"https://github.com/PPGGG","followers_url":"https://api.github.com/users/PPGGG/followers","following_url":"https://api.github.com/users/PPGGG/following{/other_user}","gists_url":"https://api.github.com/users/PPGGG/gists{/gist_id}","starred_url":"https://api.github.com/users/PPGGG/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/PPGGG/subscriptions","organizations_url":"https://api.github.com/users/PPGGG/orgs","repos_url":"https://api.github.com/users/PPGGG/repos","events_url":"https://api.github.com/users/PPGGG/events{/privacy}","received_events_url":"https://api.github.com/users/PPGGG/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2019-04-28T07:27:50Z","updated_at":"2019-04-29T07:59:50Z","closed_at":"2019-04-28T12:36:31Z","author_association":"NONE","active_lock_reason":null,"body":"I would like to train `TTS` with batch size 32 while using `distributed.py`, which was trained on 3 `2080Ti` GPU. But it still output `RuntimeError: CUDA out of memory`.\r\n\r\nHere's my `config.json`\r\n\r\n```\r\n{\r\n    \"model_name\": \"queue\",\r\n    \"model_description\": \"Queue memory and change lower r incrementatlly\",\r\n\r\n    \"audio\":{\r\n        // Audio processing parameters\r\n        \"num_mels\": 80,         // size of the mel spec frame.\r\n        \"num_freq\": 1025,       // number of stft frequency levels. Size of the linear spectogram frame.\r\n        \"sample_rate\": 22050,   // wav sample-rate. If different than the original data, it is resampled.\r\n        \"frame_length_ms\": 50,  // stft window length in ms.\r\n        \"frame_shift_ms\": 12.5, // stft window hop-lengh in ms.\r\n        \"preemphasis\": 0.97,    // pre-emphasis to reduce spec noise and make it more structured. If 0.0, no -pre-emphasis.\r\n        \"min_level_db\": -100,   // normalization range\r\n        \"ref_level_db\": 20,     // reference level db, theoretically 20db is the sound of air.\r\n        \"power\": 1.5,           // value to sharpen wav signals after GL algorithm.\r\n        \"griffin_lim_iters\": 60,// #griffin-lim iterations. 30-60 is a good range. Larger the value, slower the generation.\r\n        // Normalization parameters\r\n        \"signal_norm\": true,    // normalize the spec values in range [0, 1]\r\n        \"symmetric_norm\": false, // move normalization to range [-1, 1]\r\n        \"max_norm\": 1,          // scale normalization to range [-max_norm, max_norm] or [0, max_norm]\r\n        \"clip_norm\": true,      // clip normalized values into the range.\r\n        \"mel_fmin\": 40,         // minimum freq level for mel-spec. ~50 for male and ~95 for female voices. Tune for dataset!!\r\n        \"mel_fmax\": 3600,        // maximum freq level for mel-spec. Tune for dataset!!\r\n        \"do_trim_silence\": true  // enable trimming of slience of audio as you load it. LJspeech (false), TWEB (false), Nancy (true)\r\n    },\r\n\r\n    \"distributed\":{\r\n        \"backend\": \"nccl\",\r\n        \"url\": \"tcp:\\/\\/localhost:54321\"\r\n    },\r\n\r\n    \"embedding_size\": 256,  // Character embedding vector length. You don't need to change it in general.\r\n    \"text_cleaner\": \"basic_cleaners\",\r\n    \"epochs\": 10000,         // total number of epochs to train.\r\n    \"lr\": 0.0001,            // Initial learning rate. If Noam decay is active, maximum learning rate.\r\n    \"lr_decay\": false,      // if true, Noam learning rate decaying is applied through training.\r\n    \"loss_weight\": 0.0,     // loss weight to emphasize lower frequencies. Lower frequencies are in general more important for speech signals.\r\n    \"warmup_steps\": 4000,   // Noam decay steps to increase the learning rate from 0 to \"lr\"\r\n    \"windowing\": false,      // Enables attention windowing. Used only in eval mode.\r\n    \"memory_size\": 5,       // memory queue size used to queue network predictions to feed autoregressive connection. Useful if r < 5.\r\n\r\n    \"batch_size\": 32,       // Batch size for training. Lower values than 32 might cause hard to learn attention.\r\n    \"eval_batch_size\":16,\r\n    \"r\": 2,                 // Number of frames to predict for step.\r\n    \"wd\": 0.00001,          // Weight decay weight.\r\n    \"checkpoint\": true,     // If true, it saves checkpoints per \"save_step\"\r\n    \"save_step\": 5000,      // Number of training steps expected to save traning stats and checkpoints.\r\n    \"print_step\": 50,       // Number of steps to log traning on console.\r\n    \"tb_model_param_stats\": false,     // true, plots param stats per layer on tensorboard. Might be memory consuming, but good for debugging.\r\n    \"batch_group_size\": 8,  //Number of batches to shuffle after bucketing.  \r\n\r\n...\r\n}\r\n```","closed_by":{"login":"erogol","id":1402048,"node_id":"MDQ6VXNlcjE0MDIwNDg=","avatar_url":"https://avatars.githubusercontent.com/u/1402048?v=4","gravatar_id":"","url":"https://api.github.com/users/erogol","html_url":"https://github.com/erogol","followers_url":"https://api.github.com/users/erogol/followers","following_url":"https://api.github.com/users/erogol/following{/other_user}","gists_url":"https://api.github.com/users/erogol/gists{/gist_id}","starred_url":"https://api.github.com/users/erogol/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/erogol/subscriptions","organizations_url":"https://api.github.com/users/erogol/orgs","repos_url":"https://api.github.com/users/erogol/repos","events_url":"https://api.github.com/users/erogol/events{/privacy}","received_events_url":"https://api.github.com/users/erogol/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mozilla/TTS/issues/180/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mozilla/TTS/issues/180/timeline","performed_via_github_app":null,"state_reason":"completed"}