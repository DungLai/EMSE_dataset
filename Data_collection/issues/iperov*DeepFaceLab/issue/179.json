{"url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/179","repository_url":"https://api.github.com/repos/iperov/DeepFaceLab","labels_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/179/labels{/name}","comments_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/179/comments","events_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/179/events","html_url":"https://github.com/iperov/DeepFaceLab/issues/179","id":416522601,"node_id":"MDU6SXNzdWU0MTY1MjI2MDE=","number":179,"title":"I pressed \"Enter\" but the training didn`t stopped and nothing was saved","user":{"login":"xdx3000","id":8912020,"node_id":"MDQ6VXNlcjg5MTIwMjA=","avatar_url":"https://avatars.githubusercontent.com/u/8912020?v=4","gravatar_id":"","url":"https://api.github.com/users/xdx3000","html_url":"https://github.com/xdx3000","followers_url":"https://api.github.com/users/xdx3000/followers","following_url":"https://api.github.com/users/xdx3000/following{/other_user}","gists_url":"https://api.github.com/users/xdx3000/gists{/gist_id}","starred_url":"https://api.github.com/users/xdx3000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xdx3000/subscriptions","organizations_url":"https://api.github.com/users/xdx3000/orgs","repos_url":"https://api.github.com/users/xdx3000/repos","events_url":"https://api.github.com/users/xdx3000/events{/privacy}","received_events_url":"https://api.github.com/users/xdx3000/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2019-03-03T14:35:51Z","updated_at":"2021-02-24T15:00:32Z","closed_at":"2019-03-03T14:41:59Z","author_association":"NONE","active_lock_reason":null,"body":"The training did worked, the loss was decreasing, but when I pressed \"Enter\", the training didn`t stopped and nothing is saved\r\n\r\nthe output was below:\r\n\r\npython main.py train --training-data-src-dir workspace\\faceA --training-data-dst-dir workspace\\faceB --model-dir workspace\\model --no-preview --model H64\r\n\r\n>Running trainer.\r\nLoading model...\r\nModel first run. Enter model options as default for each run.\r\nWrite preview history? (y/n ?:help skip:n/default) :\r\nn\r\nTarget epoch (skip:unlimited/default) :\r\n0\r\nBatch_size (?:help skip:0/default) :\r\n0\r\nFeed faces to network sorted by yaw? (y/n ?:help skip:n) :\r\nn\r\nFlip faces randomly? (y/n ?:help skip:y) :\r\ny\r\nSrc face scale modifier % ( -30...30, ?:help skip:0) :\r\n0\r\nUse lightweight autoencoder? (y/n, ?:help skip:n) : y\r\nUse pixel loss? (y/n, ?:help skip: n/default ) :\r\nn\r\nE:\\Anaconda3\\envs\\faceswap\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n2019-03-03 22:28:36.477112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties:\r\nname: GeForce GTX 750 Ti major: 5 minor: 0 memoryClockRate(GHz): 1.189\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 2.00GiB freeMemory: 1.89GiB\r\n2019-03-03 22:28:36.492712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2019-03-03 22:28:37.459913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-03-03 22:28:37.459913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0\r\n2019-03-03 22:28:37.459913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N\r\n2019-03-03 22:28:37.475513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1642 MB memory) ->\r\n physical GPU (device: 0, name: GeForce GTX 750 Ti, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\nUsing TensorFlow backend.\r\nLoading: 100%|##################################################################################################################################| 242/242 [00:00<00:00, 620.51it/s]\r\nLoading: 100%|##################################################################################################################################| 118/118 [00:00<00:00, 756.41it/s]\r\n===== Model summary =====\r\n== Model name: H64\r\n==\r\n== Current epoch: 0\r\n==\r\n== Model options:\r\n== |== batch_size : 4\r\n== |== sort_by_yaw : False\r\n== |== random_flip : True\r\n== |== lighter_ae : True\r\n== |== pixel_loss : False\r\n== Running on:\r\n== |== [0 : GeForce GTX 750 Ti]\r\n==\r\n== WARNING: You are using 2GB GPU. Result quality may be significantly decreased.\r\n== If training does not start, close all programs and try again.\r\n== Also you can disable Windows Aero Desktop to get extra free VRAM.\r\n==\r\n=========================\r\nSaving...\r\nStarting. Press \"Enter\" to stop training and save model.\r\n2019-03-03 22:28:49.879535: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.61GiB. The caller indicates that thi\r\ns is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-03-03 22:28:49.926335: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.15GiB. The caller indicates that thi\r\ns is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-03-03 22:28:49.941935: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.15GiB. The caller indicates that thi\r\ns is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-03-03 22:28:49.957535: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.15GiB. The caller indicates that thi\r\ns is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-03-03 22:28:49.973135: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.15GiB. The caller indicates that thi\r\ns is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-03-03 22:28:50.035536: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.08GiB. The caller indicates that thi\r\ns is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-03-03 22:28:50.082336: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.08GiB. The caller indicates that thi\r\ns is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-03-03 22:28:50.097936: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.08GiB. The caller indicates that thi\r\ns is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-03-03 22:28:50.160336: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.08GiB. The caller indicates that thi\r\ns is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-03-03 22:28:50.222736: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.05GiB. The caller indicates that thi\r\ns is not a failure, but may mean that there could be performance gains if more memory were available.\r\nTraining [#000706][0390ms] loss_src:1.636 loss_dst:1.237","closed_by":{"login":"xdx3000","id":8912020,"node_id":"MDQ6VXNlcjg5MTIwMjA=","avatar_url":"https://avatars.githubusercontent.com/u/8912020?v=4","gravatar_id":"","url":"https://api.github.com/users/xdx3000","html_url":"https://github.com/xdx3000","followers_url":"https://api.github.com/users/xdx3000/followers","following_url":"https://api.github.com/users/xdx3000/following{/other_user}","gists_url":"https://api.github.com/users/xdx3000/gists{/gist_id}","starred_url":"https://api.github.com/users/xdx3000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xdx3000/subscriptions","organizations_url":"https://api.github.com/users/xdx3000/orgs","repos_url":"https://api.github.com/users/xdx3000/repos","events_url":"https://api.github.com/users/xdx3000/events{/privacy}","received_events_url":"https://api.github.com/users/xdx3000/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/179/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/179/timeline","performed_via_github_app":null,"state_reason":"completed"}