{"url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/582","repository_url":"https://api.github.com/repos/iperov/DeepFaceLab","labels_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/582/labels{/name}","comments_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/582/comments","events_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/582/events","html_url":"https://github.com/iperov/DeepFaceLab/issues/582","id":555264795,"node_id":"MDU6SXNzdWU1NTUyNjQ3OTU=","number":582,"title":"Extractor slower than it can be","user":{"login":"blanuk","id":50863475,"node_id":"MDQ6VXNlcjUwODYzNDc1","avatar_url":"https://avatars.githubusercontent.com/u/50863475?v=4","gravatar_id":"","url":"https://api.github.com/users/blanuk","html_url":"https://github.com/blanuk","followers_url":"https://api.github.com/users/blanuk/followers","following_url":"https://api.github.com/users/blanuk/following{/other_user}","gists_url":"https://api.github.com/users/blanuk/gists{/gist_id}","starred_url":"https://api.github.com/users/blanuk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/blanuk/subscriptions","organizations_url":"https://api.github.com/users/blanuk/orgs","repos_url":"https://api.github.com/users/blanuk/repos","events_url":"https://api.github.com/users/blanuk/events{/privacy}","received_events_url":"https://api.github.com/users/blanuk/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2020-01-26T18:04:44Z","updated_at":"2020-01-27T13:24:33Z","closed_at":"2020-01-27T09:37:35Z","author_association":"NONE","active_lock_reason":null,"body":"On the newest DFL Version, the Extractor only use half of the usable VRAM.\r\nI can start 2 Instances multigpu of extracting at the same time and this way, it nearly doubles the speed of extraction.\r\nIs it possible to just double the workers in the code? If yes, where?\r\nas u can see, it works fine with the double of load :)\r\n![two](https://user-images.githubusercontent.com/50863475/73139474-9b0b2300-406e-11ea-92ca-e826e982026b.jpg)\r\n\r\nAnother try: 3 Instances on the Titan and 2 Instances on the 2080ti:\r\nit uses for each Instance 5GB VRAM. so, 2080ti is full, works with about 60-70% CUDA load and the RTX ises 15GB and have a load of 80-90%\r\n\r\n","closed_by":{"login":"iperov","id":8076202,"node_id":"MDQ6VXNlcjgwNzYyMDI=","avatar_url":"https://avatars.githubusercontent.com/u/8076202?v=4","gravatar_id":"","url":"https://api.github.com/users/iperov","html_url":"https://github.com/iperov","followers_url":"https://api.github.com/users/iperov/followers","following_url":"https://api.github.com/users/iperov/following{/other_user}","gists_url":"https://api.github.com/users/iperov/gists{/gist_id}","starred_url":"https://api.github.com/users/iperov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/iperov/subscriptions","organizations_url":"https://api.github.com/users/iperov/orgs","repos_url":"https://api.github.com/users/iperov/repos","events_url":"https://api.github.com/users/iperov/events{/privacy}","received_events_url":"https://api.github.com/users/iperov/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/582/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/582/timeline","performed_via_github_app":null,"state_reason":"completed"}