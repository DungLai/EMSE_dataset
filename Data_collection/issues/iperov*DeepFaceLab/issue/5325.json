{"url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/5325","repository_url":"https://api.github.com/repos/iperov/DeepFaceLab","labels_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/5325/labels{/name}","comments_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/5325/comments","events_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/5325/events","html_url":"https://github.com/iperov/DeepFaceLab/issues/5325","id":878812919,"node_id":"MDU6SXNzdWU4Nzg4MTI5MTk=","number":5325,"title":"Dynamic yaw / pitch range selection - only train on relevant SRC data based on yaw/pitch range of DST","user":{"login":"IUsedToBeAPygmy","id":35959558,"node_id":"MDQ6VXNlcjM1OTU5NTU4","avatar_url":"https://avatars.githubusercontent.com/u/35959558?v=4","gravatar_id":"","url":"https://api.github.com/users/IUsedToBeAPygmy","html_url":"https://github.com/IUsedToBeAPygmy","followers_url":"https://api.github.com/users/IUsedToBeAPygmy/followers","following_url":"https://api.github.com/users/IUsedToBeAPygmy/following{/other_user}","gists_url":"https://api.github.com/users/IUsedToBeAPygmy/gists{/gist_id}","starred_url":"https://api.github.com/users/IUsedToBeAPygmy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/IUsedToBeAPygmy/subscriptions","organizations_url":"https://api.github.com/users/IUsedToBeAPygmy/orgs","repos_url":"https://api.github.com/users/IUsedToBeAPygmy/repos","events_url":"https://api.github.com/users/IUsedToBeAPygmy/events{/privacy}","received_events_url":"https://api.github.com/users/IUsedToBeAPygmy/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-05-07T11:22:13Z","updated_at":"2021-05-07T11:22:13Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi Iperov,\r\nwould it be possible to implement dynamic yaw / pitch range selection for source material?\r\nMeaning the DST dataset would be analyzed to get the min/max yaw and pitch range of the DST video, and to then only train on source data within that range?\r\n\r\nThat would avoid training on \"unused\" source data; for example when having a DST video that's just looking straight into the camera, it would be useless to train on SRC data that was shot from the side.\r\n\r\nThis way the network would be able to focus on relevant data only.\r\nIt would also make it easier to keep one src dataset that can be used for multiple different DST runs.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/5325/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/5325/timeline","performed_via_github_app":null,"state_reason":null}