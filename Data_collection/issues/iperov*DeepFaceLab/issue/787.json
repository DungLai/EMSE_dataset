{"url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/787","repository_url":"https://api.github.com/repos/iperov/DeepFaceLab","labels_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/787/labels{/name}","comments_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/787/comments","events_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/787/events","html_url":"https://github.com/iperov/DeepFaceLab/issues/787","id":639374732,"node_id":"MDU6SXNzdWU2MzkzNzQ3MzI=","number":787,"title":"Cannot train (RTX PROBLEM)","user":{"login":"HappiestCow22","id":66987400,"node_id":"MDQ6VXNlcjY2OTg3NDAw","avatar_url":"https://avatars.githubusercontent.com/u/66987400?v=4","gravatar_id":"","url":"https://api.github.com/users/HappiestCow22","html_url":"https://github.com/HappiestCow22","followers_url":"https://api.github.com/users/HappiestCow22/followers","following_url":"https://api.github.com/users/HappiestCow22/following{/other_user}","gists_url":"https://api.github.com/users/HappiestCow22/gists{/gist_id}","starred_url":"https://api.github.com/users/HappiestCow22/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HappiestCow22/subscriptions","organizations_url":"https://api.github.com/users/HappiestCow22/orgs","repos_url":"https://api.github.com/users/HappiestCow22/repos","events_url":"https://api.github.com/users/HappiestCow22/events{/privacy}","received_events_url":"https://api.github.com/users/HappiestCow22/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2020-06-16T05:11:12Z","updated_at":"2022-02-23T23:33:42Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Cannot Train for longer than 5 minutes.\r\n\r\nThe training CMD prompt window will stop updating the iteration count and the training window will not update when clicking P. (ENTER does nothing either. Closing the CMD prompt will unload VRAM and not save the model)\r\nThe training completely ends without an error message or anything.\r\n\r\n\r\nI have a 2080TI and i'd like to mention that I had the same problem on a 2080 non ti. **My theory is it has something to do with the RTX cuda drivers packaged with DFL.**\r\n\r\nOlder versions of DFL(the RTX specific branch) that still used the original SAE model can still train, (I have a 2.5mil iteration model that had almost no issues the entire training life)\r\n\r\n**This is an issue that was introduced as soon as SAEHD was added months ago.** When SAEHD and SAE were able to be picked between, i always had to stay with SAE because SAEHD would crash every time.\r\nI have tried models with super low resolution and params and I have the same issue. Its not related to oom errors.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/787/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/787/timeline","performed_via_github_app":null,"state_reason":null}