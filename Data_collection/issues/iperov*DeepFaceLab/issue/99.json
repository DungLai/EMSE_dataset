{"url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/99","repository_url":"https://api.github.com/repos/iperov/DeepFaceLab","labels_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/99/labels{/name}","comments_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/99/comments","events_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/99/events","html_url":"https://github.com/iperov/DeepFaceLab/issues/99","id":395961899,"node_id":"MDU6SXNzdWUzOTU5NjE4OTk=","number":99,"title":"Multi GPU load vs batch size and speed","user":{"login":"titanrw","id":26033165,"node_id":"MDQ6VXNlcjI2MDMzMTY1","avatar_url":"https://avatars.githubusercontent.com/u/26033165?v=4","gravatar_id":"","url":"https://api.github.com/users/titanrw","html_url":"https://github.com/titanrw","followers_url":"https://api.github.com/users/titanrw/followers","following_url":"https://api.github.com/users/titanrw/following{/other_user}","gists_url":"https://api.github.com/users/titanrw/gists{/gist_id}","starred_url":"https://api.github.com/users/titanrw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/titanrw/subscriptions","organizations_url":"https://api.github.com/users/titanrw/orgs","repos_url":"https://api.github.com/users/titanrw/repos","events_url":"https://api.github.com/users/titanrw/events{/privacy}","received_events_url":"https://api.github.com/users/titanrw/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":true,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2019-01-04T15:20:11Z","updated_at":"2019-03-20T10:32:56Z","closed_at":"2019-01-04T19:00:59Z","author_association":"NONE","active_lock_reason":"resolved","body":"Hi.\r\n\r\nI just started playing with DeepFaceLab.  I have 2x 980ti's.\r\n\r\nThe thing I've noticed is that the gpu load is very 'spiky' when using both cards, causing quite annoying power spikes, which cause lights to flicker throughout part of the house.  Kinda makes sense as power draw goes from as low as 200w to as high as 1,000w multiple times per second.  Here's a gpu load graph training H128 on default batch size of 8:\r\n\r\n[https://i.imgur.com/rKZNxLs.png](https://i.imgur.com/rKZNxLs.png)\r\n\r\nGPU2 is especially spiky\r\n\r\nI tried upping the batch size to 16 and get this:\r\n\r\n[https://i.imgur.com/T63Vkgc.png](https://i.imgur.com/T63Vkgc.png)\r\n\r\nGPU2 isn't quite as spiky, but it's still varying load quite a bit, still causing flickering lights.\r\n\r\nAre there any settings that could be changed to smooth out the gpu usage in multi gpu mode, and therefore the power draw?\r\n\r\nAs a comparison, limiting training to a single gpu sees much more consistent load on the gpu:\r\n\r\n[https://i.imgur.com/vV5YTq4.png](https://i.imgur.com/vV5YTq4.png)\r\n\r\nAnother question about batch size.  Is the ms per epoch related to batch size?  For example, I'm getting about 500ms per epoch at batch size 8, but 750ms at batch size 16.  Is 8 therefore better because it's faster per epoch, or is 16 better because the batch size doubled, and double the work is being done in only 50% more time? \r\n\r\nThanks in advance. ","closed_by":{"login":"iperov","id":8076202,"node_id":"MDQ6VXNlcjgwNzYyMDI=","avatar_url":"https://avatars.githubusercontent.com/u/8076202?v=4","gravatar_id":"","url":"https://api.github.com/users/iperov","html_url":"https://github.com/iperov","followers_url":"https://api.github.com/users/iperov/followers","following_url":"https://api.github.com/users/iperov/following{/other_user}","gists_url":"https://api.github.com/users/iperov/gists{/gist_id}","starred_url":"https://api.github.com/users/iperov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/iperov/subscriptions","organizations_url":"https://api.github.com/users/iperov/orgs","repos_url":"https://api.github.com/users/iperov/repos","events_url":"https://api.github.com/users/iperov/events{/privacy}","received_events_url":"https://api.github.com/users/iperov/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/99/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/iperov/DeepFaceLab/issues/99/timeline","performed_via_github_app":null,"state_reason":"completed"}