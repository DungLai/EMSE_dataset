{"url":"https://api.github.com/repos/HLTCHKUST/Mem2Seq/issues/33","repository_url":"https://api.github.com/repos/HLTCHKUST/Mem2Seq","labels_url":"https://api.github.com/repos/HLTCHKUST/Mem2Seq/issues/33/labels{/name}","comments_url":"https://api.github.com/repos/HLTCHKUST/Mem2Seq/issues/33/comments","events_url":"https://api.github.com/repos/HLTCHKUST/Mem2Seq/issues/33/events","html_url":"https://github.com/HLTCHKUST/Mem2Seq/issues/33","id":1423314910,"node_id":"I_kwDOB8oMxM5U1g_e","number":33,"title":"Project dependencies may have API risk issues","user":{"login":"PyDeps","id":109138844,"node_id":"U_kgDOBoFTnA","avatar_url":"https://avatars.githubusercontent.com/u/109138844?v=4","gravatar_id":"","url":"https://api.github.com/users/PyDeps","html_url":"https://github.com/PyDeps","followers_url":"https://api.github.com/users/PyDeps/followers","following_url":"https://api.github.com/users/PyDeps/following{/other_user}","gists_url":"https://api.github.com/users/PyDeps/gists{/gist_id}","starred_url":"https://api.github.com/users/PyDeps/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/PyDeps/subscriptions","organizations_url":"https://api.github.com/users/PyDeps/orgs","repos_url":"https://api.github.com/users/PyDeps/repos","events_url":"https://api.github.com/users/PyDeps/events{/privacy}","received_events_url":"https://api.github.com/users/PyDeps/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-10-26T01:47:45Z","updated_at":"2022-10-26T01:47:45Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi, In **Mem2Seq**, inappropriate dependency versioning constraints can cause risks.\r\n\r\nBelow are the dependencies and version constraints that the project is using\r\n\r\n```\r\ncycler==0.10.0\r\njoblib==0.14.1\r\nkiwisolver==1.1.0\r\nmatplotlib==3.2.1\r\nnltk==3.4.5\r\nnumpy==1.18.2\r\npandas==1.0.3\r\npyparsing==2.4.6\r\npython-dateutil==2.8.1\r\npytz==2019.3\r\nscikit-learn==0.22.2.post1\r\nscipy==1.4.1\r\nseaborn==0.10.0\r\nsix==1.14.0\r\nsklearn==0.0\r\ntorch==1.1.0\r\ntqdm==4.43.0\r\n```\r\n\r\nThe version constraint **==** will introduce the risk of dependency conflicts because the scope of dependencies is too strict.\r\nThe version constraint **No Upper Bound** and **\\*** will introduce the risk of the missing API Error because the latest version of the dependencies may remove some APIs.\r\n\r\nAfter further analysis, in this project,\r\nThe version constraint of dependency **numpy** can be changed to *>=1.8.0,<=1.23.0rc3*.\r\n\r\nThe above modification suggestions can reduce the dependency conflicts as much as possible, \r\nand introduce the latest version as much as possible without calling Error in the projects.\r\n\r\nThe invocation of the current project includes all the following methods.\r\n\r\n<details><summary>The calling methods from the numpy</summary>\r\n <pre>char.isdigit\r\n</pre>\r\n</details>\r\n<details><summary>The calling methods from the all methods</summary>\r\n <pre>gete_s.Variable.transpose\r\ninput_batches.size\r\ntorch.bmm.transpose\r\nzip\r\ngate.append\r\nargparse.ArgumentParser.add_argument\r\nself.LuongAttnDecoderRNN.super.__init__\r\nself.concat.cuda\r\nembed_A.torch.sum.squeeze.size\r\nsuper\r\ntarget_gate.float\r\nitem.lower.replace\r\ntorch.sum\r\nlengths.max.sequences.len.torch.ones.long\r\ntorch.nn.functional.log_softmax\r\nLuongAttnDecoderRNN\r\ncorrect.lstrip.rstrip.lstrip\r\ntorch.nn.functional.tanh\r\nset\r\njoin.find\r\ni.story.append\r\nargs.globals\r\nstory.contiguous\r\ntoppi.view.Variable.input_batches.torch.gather.transpose\r\nread_langs\r\nall_decoder_outputs_ptr.transpose.contiguous\r\nargs.globals.evaluate\r\nPtrDecoderRNN\r\nstr\r\nnumpy.zeros\r\nself.preprocess\r\nlengths.max.sequences.len.torch.zeros.long\r\nself.add_module\r\ntorch.autograd.Variable\r\nh0_encoder.cuda.cuda\r\nID.append\r\nself.evaluate_batch\r\ntoppi.view\r\nself.decoder.train\r\nel.replace.tokenizer.join.replace.lower\r\ncorrect.lstrip.rstrip\r\nst.lstrip.rstrip.lstrip\r\nself.PtrDecoderRNN.super.__init__\r\ntorch.nn.utils.clip_grad_norm\r\nlogging.info\r\ntqdm.set_description\r\nchar.isdigit\r\nst.lstrip.rstrip.split\r\nast.literal_eval\r\nself.decoder_optimizer.step\r\ntorch.nn.GRU\r\nsequence_length.data.max\r\nself.from_whichs.append\r\nsix.moves.urllib.request.urlretrieve\r\nsequence_length.size\r\ninput.size\r\nmax_len.torch.arange.long\r\nargparse.ArgumentParser.parse_args\r\nself.compute_prf\r\nkb_arr.append\r\ntorch.nn.utils.rnn.pad_packed_sequence\r\nhop.self.C\r\nhidden.squeeze\r\ntrg_seqs.Variable.transpose\r\ndecoder_ptr.data.topk\r\nd.pop\r\ngete_s.cuda.cuda\r\ntorch.LongTensor\r\ntempfile.NamedTemporaryFile.write\r\nAttrProxy\r\ntorch.nn.MSELoss\r\nself.EncoderMemNN.super.__init__\r\ne.keys\r\nmax_len.sequences.len.torch.zeros.long\r\ncontext.squeeze.word_embedded.torch.cat.unsqueeze\r\nenergy.transpose.transpose\r\ncontext.squeeze.squeeze\r\nentity_replace\r\nself.embedding_dropout.cuda\r\ntorch.autograd.Variable.float\r\ntorch.nn.functional.softmax\r\nday.el.split.rstrip\r\nself.W\r\ntorch.nn.functional.sigmoid\r\nd.split\r\nreferences.join.encode\r\nmasked_cross_entropy.item\r\nline.strip.replace\r\nself.encoder.cuda\r\nnltk.wordpunct_tokenize\r\nget_type_dict.keys\r\ntorch.nn.Softmax\r\ntorch.Tensor\r\ntorch.optim.Adam\r\nline.strip.strip\r\nlogits.size\r\nk.item.lower\r\nself.index_word\r\nday.el.split.split\r\nk.item.lower.replace\r\nentity.type_dict.append\r\nVanillaDecoderRNN\r\nentity_nav.append\r\nutils.until_temp.entityList.append\r\nutils.measures.wer\r\nos.path.abspath\r\nself.decoder\r\nel.keys\r\nind_seqs.cuda.cuda\r\nos.path.dirname\r\nencoder_outputs.transpose.transpose\r\ntorch.Tensor.split\r\np.replace\r\ncorrect.lstrip\r\nself.concat\r\nitem.keys\r\ntqdm.tqdm.set_description\r\nglobals\r\nencoder_outputs.data.shape.self.v.repeat.unsqueeze\r\ntarget_batches.transpose.contiguous\r\nself.VanillaSeqToSeq.super.__init__\r\nos.path.exists\r\nsent_new.append\r\ntorch.gather\r\ndict\r\ni.top_ptr_i.item\r\nembed_A.torch.sum.squeeze.view\r\nhypotheses.join.encode\r\nline.replace.replace\r\ntorch.nn.Parameter\r\nself.C.unsqueeze\r\nself.W1\r\nseq_range.unsqueeze.expand\r\ntorch.nn.functional.sigmoid.squeeze\r\nstory.contiguous.view\r\nos.path.join\r\nenumerate\r\ninput_batches.transpose\r\nencoder_outputs.transpose.size\r\ntqdm.tqdm\r\nall_decoder_outputs_gate.cuda.cuda\r\ncandid_all.append\r\nunicodedata.category\r\ncontext.split\r\nself.softmax\r\ns.re.sub.strip.lower\r\nself.decoder.ptrMemDecoder\r\nsrc_seqs.Variable.transpose\r\nlast_hidden.unsqueeze\r\ninput_batches.transpose.self.encoder.unsqueeze\r\nr_index.append\r\ntorch.Tensor.append\r\nembed_C.torch.sum.squeeze\r\nunicode_to_ascii\r\nsequence_length.unsqueeze.expand_as\r\ntqdm\r\nint\r\nself.U\r\ncandid2candDL.keys\r\ntorch.save\r\njoin\r\nself.gru\r\nfloat\r\nentity_list.append\r\nos.makedirs\r\nmax_len.sequences.len.torch.ones.long\r\nmask.float.sum\r\nembed_A.torch.sum.squeeze\r\ngenerate_memory\r\nre.sub\r\na.long.size\r\nargs.globals.print_loss\r\nargs.globals.train_batch\r\ntorch.bmm\r\nline.split.replace\r\nopen\r\na.cuda.long\r\ntarget.size\r\ntorch.utils.data.DataLoader\r\nhidden.squeeze.unsqueeze\r\ntorch.gather.squeeze\r\nref.append\r\nall_decoder_outputs_vocab.cuda.transpose\r\ntorch.nn.utils.rnn.pack_padded_sequence\r\nbleu_out.decode.decode\r\nhyp.append\r\nlength.torch.LongTensor.Variable.cuda\r\ntarget_batches.transpose\r\nself.decoder.parameters\r\nDecoderMemNN\r\ntorch.zeros\r\nnumpy.random.binomial\r\nmax\r\nself.encoder\r\nsum\r\nos.chmod\r\nconv_seqs.Variable.transpose\r\nline.replace.split\r\nget_type_dict\r\nprepare_data_seq\r\nentity_cal.append\r\nprob_.unsqueeze.expand_as\r\nr.split\r\nseq_range_expand.cuda.cuda\r\ntorch.nn.Linear\r\nself.embedding_dim.bsz.torch.zeros.Variable.cuda\r\nmath.sqrt\r\nstory.size\r\nself.encoder_optimizer.step\r\nEncoderRNN\r\ntopi.view\r\ntorch.rand\r\ntorch.cat\r\nutils.until_temp.entityList\r\nprint\r\ntorch.nn.functional.softmax.bmm\r\nall_decoder_outputs_ptr.cuda.cuda\r\nrange\r\nself.W.cuda\r\ndecoder_input.cuda.cuda\r\njson.load.keys\r\nos.cpu_count\r\nfrom_which.append\r\nself.encoder_optimizer.zero_grad\r\nmax_len.s_t.repeat.transpose\r\ntorch.utils.data.append\r\nconv_seqs.cuda.cuda\r\nself.dropout\r\ntoppi.squeeze\r\nself.W1.cuda\r\nrnn_output.squeeze.squeeze\r\nEncoderMemNN\r\nx.str.lower\r\nre.search\r\ntempfile.NamedTemporaryFile.close\r\nmap\r\nnltk.tokenize.word_tokenize\r\nlogging.basicConfig\r\nself.U.cuda\r\nglobal_temp.append\r\nLang.index_words\r\nself.preprocess_gate\r\nnumpy.uint8.h.len.r.len.numpy.zeros.reshape\r\nself.PTRUNK.super.__init__\r\nsrc_seqs.cuda.cuda\r\nself.out.cuda\r\nself.DecoderMemNN.super.__init__\r\nget_seq\r\nbool\r\nidx.token_array.isdigit\r\ncleaner\r\ntemp.append\r\nentityList\r\nself.decoder.load_memory\r\nembedded.view.view\r\nsequence_mask.float\r\nmerge\r\nst.lstrip.rstrip\r\nany\r\ns.lower.strip\r\nlast_hidden.unsqueeze.repeat\r\neng.lower\r\ngetattr\r\ni.data_dev.dialog_acc_dict.append\r\nnew_token_array.pop\r\ni.d.str.lower\r\nself.get_state.unsqueeze\r\nself.EncoderRNN.super.__init__\r\nself.v.data.normal_\r\nhidden.unsqueeze.repeat\r\nslot.el.replace.tokenizer.join.lower\r\ntorch.nn.Embedding\r\ncandidates.append\r\nvars\r\nnumpy.float32\r\ns.re.sub.strip\r\nloss.backward\r\nself.get_state\r\nDataset\r\nembed_C.torch.sum.squeeze.size\r\nu.unsqueeze.expand_as\r\nst.lstrip\r\nself.criterion\r\na.long.transpose\r\ny_seq.append\r\nself.C\r\nself.encoder.parameters\r\ni.topvi.item\r\ntarget.view\r\nsequence_mask\r\nunicodedata.normalize\r\nx_seq.append\r\nutils.measures.moses_multi_bleu\r\nptr_seq.append\r\ntorch.load\r\ntorch.gather.view\r\ndecoder_vacab.data.topk\r\nself.encoder.train\r\njson.load\r\nel.replace\r\nsequence_length.unsqueeze\r\nsent.split\r\nentity.append\r\ndialog_acc_dict.keys\r\np.append\r\nMEM_TOKEN_SIZE.lengths.max.sequences.len.torch.ones.long\r\nself.preprocess.append\r\nself.LuongSeqToSeq.super.__init__\r\ntrg_seqs.cuda.cuda\r\nall_decoder_outputs_vocab.cuda.cuda\r\nmodel.scheduler.step\r\nhidden.squeeze.append\r\nself.embedding.cuda\r\nself.dropout.cuda\r\nglobal_rp.keys\r\nmasked_cross_entropy\r\nprob.unsqueeze.expand_as\r\nsubprocess.check_output\r\nc0_encoder.cuda.cuda\r\nlist\r\ntopvi.squeeze\r\nptr_index.append\r\nformat\r\nnumpy.array\r\nself.embedding_dropout\r\nelm.split\r\nself.v.repeat\r\nsentence.split\r\ntorch.arange\r\nall_decoder_outputs_vocab.transpose.contiguous\r\ndecoded_words.append\r\nself.VanillaDecoderRNN.super.__init__\r\ntempfile.NamedTemporaryFile.flush\r\njoin.replace\r\ntarget_index.transpose.contiguous\r\nself.preprocess_inde\r\nself.out.squeeze\r\nself.save_model\r\np.e.str.lower.replace\r\nline.replace.strip\r\nargparse.ArgumentParser\r\nC.weight.data.normal_\r\nday.el.split.rstrip.replace\r\nmin\r\nall_decoder_outputs_ptr.cuda.transpose\r\nself.v.size\r\nrandom.random\r\nentity_wet.append\r\nslot.el.replace\r\nget_type_dict.append\r\nlen.append\r\nload_candidates\r\ntarget_index.transpose\r\ndict.items\r\nel.replace.tokenizer.join.replace\r\np.e.str.lower\r\nlist.append\r\nself.m_story.append\r\nnew_token_array.append\r\nprob_.unsqueeze.expand_as.unsqueeze\r\ni.toppi.item\r\nfre.lower\r\nDecoderrMemNN\r\ntemp_gen.append\r\ntorch.ones\r\ntorch.nn.Dropout\r\nos.path.realpath\r\njoin.lstrip\r\ntorch.utils.data.sort\r\ntempfile.NamedTemporaryFile\r\nself.decoder_optimizer.zero_grad\r\nself.lstm.cuda\r\nline.split.split\r\nday.el.split\r\nbleu_out.re.search.group\r\na.bmm.squeeze\r\nself.softmax.unsqueeze\r\na.cuda.cuda\r\nnumpy.transpose\r\nself.v.cuda\r\nloss.item\r\nel_key.el.tokenizer.join.lower\r\nembed_C.torch.sum.squeeze.view\r\nnumpy.ones\r\nlogits.view\r\nlen\r\ntorch.optim.lr_scheduler.ReduceLROnPlateau\r\ninput_seq.size\r\ngate_seq.append\r\nline.strip.split\r\nitem.lower\r\na.long.contiguous\r\np.str.replace\r\nself.out\r\nmax_len.torch.arange.long.unsqueeze\r\nself.decoder.cuda\r\ninput_batches.self.encoder.unsqueeze\r\nnumpy.size\r\ncandid2DL\r\nnames.keys\r\nind_seqs.Variable.transpose\r\nself.embedding\r\nlength.float.sum\r\nhidden.squeeze.size\r\ntorch.nn.LSTM\r\nstory.size.story.contiguous.view.long\r\nself.lstm\r\nLang\r\njoin.split\r\nself.DecoderrMemNN.super.__init__\r\nself.Mem2Seq.super.__init__\r\n</pre>\r\n</details>\r\n\r\n@developer\r\nCould please help me check this issue?\r\nMay I pull a request to fix it?\r\nThank you very much.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/HLTCHKUST/Mem2Seq/issues/33/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/HLTCHKUST/Mem2Seq/issues/33/timeline","performed_via_github_app":null,"state_reason":null}