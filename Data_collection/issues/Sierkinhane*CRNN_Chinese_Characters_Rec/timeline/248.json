[{"url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/comments/716249013","html_url":"https://github.com/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/248#issuecomment-716249013","issue_url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/248","id":716249013,"node_id":"MDEyOklzc3VlQ29tbWVudDcxNjI0OTAxMw==","user":{"login":"jasnei","id":52853052,"node_id":"MDQ6VXNlcjUyODUzMDUy","avatar_url":"https://avatars.githubusercontent.com/u/52853052?v=4","gravatar_id":"","url":"https://api.github.com/users/jasnei","html_url":"https://github.com/jasnei","followers_url":"https://api.github.com/users/jasnei/followers","following_url":"https://api.github.com/users/jasnei/following{/other_user}","gists_url":"https://api.github.com/users/jasnei/gists{/gist_id}","starred_url":"https://api.github.com/users/jasnei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasnei/subscriptions","organizations_url":"https://api.github.com/users/jasnei/orgs","repos_url":"https://api.github.com/users/jasnei/repos","events_url":"https://api.github.com/users/jasnei/events{/privacy}","received_events_url":"https://api.github.com/users/jasnei/received_events","type":"User","site_admin":false},"created_at":"2020-10-26T01:06:14Z","updated_at":"2020-10-26T02:07:36Z","author_association":"NONE","body":"@whwme\r\n这个是在瓶颈出现在读数据上面，可以改变一下读数据的方式，可以快1倍以上的速度，我16G内存，4G显示，Batch_size, 128，一个epoch大概 5000秒，看作者的，200张图像/s，我没有用prefecter技术之前大概是320张图像/s。用了之后750张/s。如果内存够大，你可以把batch_size 增大。\r\n\r\n![QQ浏览器截图20201026085903](https://user-images.githubusercontent.com/52853052/97124080-a9a37980-1769-11eb-89d5-6e40c813f79a.png)\r\n修改lib/core/function.py\r\n整个文件都修改了。\r\n代码如下：\r\n`\r\n\"\"\"\r\n利用了prefetcher技术，连计算的同时也在读取数据\r\n虽然现在GPU利用率比之前还低，但处理速度，比之前快了一倍\r\n缺点：内存占用比之前多一倍\r\n\"\"\"\r\n\r\nfrom  __future__ import  absolute_import\r\nimport time\r\nimport lib.utils.utils as utils\r\nimport torch\r\n\r\n\r\nclass AverageMeter(object):\r\n\r\n    \"\"\"Computes and stores the average and current value\"\"\"\r\n    def __init__(self):\r\n        self.val = 0\r\n        self.avg = 0\r\n        self.sum = 0\r\n        self.count = 0\r\n        self.reset()\r\n\r\n    def reset(self):\r\n        self.val = 0\r\n        self.avg = 0\r\n        self.sum = 0\r\n        self.count = 0\r\n\r\n    def update(self, val, n=1):\r\n        self.val = val\r\n        self.sum += val * n\r\n        self.count += n\r\n        self.avg = self.sum / self.count\r\n\r\nclass data_prefetcher():\r\n\r\n    def __init__(self, loader):\r\n        self.loader = iter(loader)\r\n        self.stream = torch.cuda.Stream()\r\n        # 在数据处理里已经做了标准化了，所以这里不再需要做了\r\n        # self.mean = torch.tensor([0.485 * 255, 0.456 * 255, 0.406 * 255]).cuda().view(1,3,1,1)\r\n        # self.std = torch.tensor([0.229 * 255, 0.224 * 255, 0.225 * 255]).cuda().view(1,3,1,1)\r\n\r\n        # self.mean = torch.tensor([0.485 * 255, 0.456 * 255, 0.406 * 255]).cuda().view(1,3,1,1)\r\n        # self.std = torch.tensor([0.229 * 255, 0.224 * 255, 0.225 * 255]).cuda().view(1,3,1,1)\r\n        # With Amp, it isn't necessary to manually convert data to half.\r\n        # if args.fp16:\r\n        #     self.mean = self.mean.half()\r\n        #     self.std = self.std.half()\r\n        self.preload()\r\n\r\n    def preload(self):\r\n        try:\r\n            self.next_input, self.next_target = next(self.loader)\r\n        except StopIteration:\r\n            self.next_input = None\r\n            self.next_target = None\r\n            return\r\n        with torch.cuda.stream(self.stream):\r\n            self.next_input = self.next_input.cuda(non_blocking=True)\r\n            self.next_target = self.next_target.cuda(non_blocking=True)\r\n            # With Amp, it isn't necessary to manually convert data to half.\r\n            # if args.fp16:\r\n            #     self.next_input = self.next_input.half()\r\n            # else:\r\n            self.next_input = self.next_input.float()\r\n            # self.next_input = self.next_input.sub_(self.mean).div_(self.std)\r\n            \r\n    def next(self):\r\n        torch.cuda.current_stream().wait_stream(self.stream)\r\n        input = self.next_input\r\n        target = self.next_target\r\n        self.preload()\r\n        return input, target\r\n        \r\n        \r\ndef train(config, train_loader, dataset, converter, model, criterion, optimizer, device, epoch, writer_dict=None, output_dict=None):\r\n\r\n    batch_time = AverageMeter()\r\n    data_time = AverageMeter()\r\n    losses = AverageMeter()\r\n\r\n    model.train()\r\n\r\n    end = time.time()\r\n    \r\n    prefetcher = data_prefetcher(train_loader)\r\n    inp, idx = prefetcher.next()\r\n\r\n    i = 0\r\n    while inp is not None:\r\n        i += 1\r\n        # measure data time\r\n        data_time.update(time.time() - end)\r\n        \r\n        labels = utils.get_batch_label(dataset, idx)\r\n        inp = inp.to(device)\r\n\r\n        # inference\r\n        preds = model(inp)\r\n\r\n        # compute loss\r\n        batch_size = inp.size(0)\r\n        # print(batch_size, len(labels))\r\n        text, length = converter.encode(labels)                    # length = 一个batch中的总字符长度, text = 一个batch中的字符所对应的下标\r\n        preds_size = torch.IntTensor([preds.size(0)] * batch_size) # timestep * batchsize\r\n        loss = criterion(preds, text, preds_size, length)\r\n\r\n        optimizer.zero_grad()\r\n        loss.backward()\r\n        optimizer.step()\r\n\r\n        losses.update(loss.item(), inp.size(0))\r\n\r\n        batch_time.update(time.time()-end)\r\n        if i % config.PRINT_FREQ == 0:\r\n            msg = 'Epoch: [{0}][{1}/{2}]\\t' \\\r\n                  'Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\\t' \\\r\n                  'Speed {speed:.1f} samples/s\\t' \\\r\n                  'Data {data_time.val:.3f}s ({data_time.avg:.3f}s)\\t' \\\r\n                  'Loss {loss.val:.5f} ({loss.avg:.5f})\\t'.format(\r\n                      epoch, i, len(train_loader), batch_time=batch_time,\r\n                      speed=inp.size(0)/batch_time.val,\r\n                      data_time=data_time, loss=losses)\r\n            print(msg)\r\n\r\n            if writer_dict:\r\n                writer = writer_dict['writer']\r\n                global_steps = writer_dict['train_global_steps']\r\n                writer.add_scalar('train_loss', losses.avg, global_steps)\r\n                writer_dict['train_global_steps'] = global_steps + 1\r\n\r\n        end = time.time()\r\n        \r\n        inp, idx = prefetcher.next()\r\n\r\n\r\ndef validate(config, val_loader, dataset, converter, model, criterion, device, epoch, writer_dict, output_dict):\r\n\r\n    losses = AverageMeter()\r\n    model.eval()\r\n\r\n    n_correct = 0\r\n    with torch.no_grad():\r\n        for i, (inp, idx) in enumerate(val_loader):\r\n\r\n            labels = utils.get_batch_label(dataset, idx)\r\n            inp = inp.to(device)\r\n\r\n            # inference\r\n            preds = model(inp)\r\n\r\n            # compute loss\r\n            batch_size = inp.size(0)\r\n            text, length = converter.encode(labels)\r\n            preds_size = torch.IntTensor([preds.size(0)] * batch_size)\r\n            loss = criterion(preds, text, preds_size, length)\r\n\r\n            losses.update(loss.item(), inp.size(0))\r\n\r\n            _, preds = preds.max(2)\r\n            preds = preds.transpose(1, 0).contiguous().view(-1)\r\n            sim_preds = converter.decode(preds.data, preds_size.data, raw=False)\r\n            for pred, target in zip(sim_preds, labels):\r\n                if pred == target:\r\n                    n_correct += 1\r\n\r\n            if (i + 1) % config.PRINT_FREQ == 0:\r\n                print('Epoch: [{0}][{1}/{2}]'.format(epoch, i, len(val_loader)))\r\n\r\n            if i == config.TEST.NUM_TEST_BATCH:\r\n                break\r\n\r\n    raw_preds = converter.decode(preds.data, preds_size.data, raw=True)[:config.TEST.NUM_TEST_DISP]\r\n    for raw_pred, pred, gt in zip(raw_preds, sim_preds, labels):\r\n        print('%-20s => %-20s, gt: %-20s' % (raw_pred, pred, gt))\r\n\r\n    num_test_sample = config.TEST.NUM_TEST_BATCH * config.TEST.BATCH_SIZE_PER_GPU\r\n    if num_test_sample > len(dataset):\r\n        num_test_sample = len(dataset)\r\n\r\n    print(\"[#correct:{} / #total:{}]\".format(n_correct, num_test_sample))\r\n    accuracy = n_correct / float(num_test_sample)\r\n    print('Test loss: {:.4f}, accuray: {:.4f}'.format(losses.avg, accuracy))\r\n\r\n    if writer_dict:\r\n        writer = writer_dict['writer']\r\n        global_steps = writer_dict['valid_global_steps']\r\n        writer.add_scalar('valid_acc', accuracy, global_steps)\r\n        writer_dict['valid_global_steps'] = global_steps + 1\r\n\r\n    return accuracy\r\n`\r\n","reactions":{"url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/comments/716249013/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"jasnei","id":52853052,"node_id":"MDQ6VXNlcjUyODUzMDUy","avatar_url":"https://avatars.githubusercontent.com/u/52853052?v=4","gravatar_id":"","url":"https://api.github.com/users/jasnei","html_url":"https://github.com/jasnei","followers_url":"https://api.github.com/users/jasnei/followers","following_url":"https://api.github.com/users/jasnei/following{/other_user}","gists_url":"https://api.github.com/users/jasnei/gists{/gist_id}","starred_url":"https://api.github.com/users/jasnei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasnei/subscriptions","organizations_url":"https://api.github.com/users/jasnei/orgs","repos_url":"https://api.github.com/users/jasnei/repos","events_url":"https://api.github.com/users/jasnei/events{/privacy}","received_events_url":"https://api.github.com/users/jasnei/received_events","type":"User","site_admin":false}},{"id":3918526878,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MzkxODUyNjg3OA==","url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/events/3918526878","actor":{"login":"whwme","id":61930311,"node_id":"MDQ6VXNlcjYxOTMwMzEx","avatar_url":"https://avatars.githubusercontent.com/u/61930311?v=4","gravatar_id":"","url":"https://api.github.com/users/whwme","html_url":"https://github.com/whwme","followers_url":"https://api.github.com/users/whwme/followers","following_url":"https://api.github.com/users/whwme/following{/other_user}","gists_url":"https://api.github.com/users/whwme/gists{/gist_id}","starred_url":"https://api.github.com/users/whwme/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/whwme/subscriptions","organizations_url":"https://api.github.com/users/whwme/orgs","repos_url":"https://api.github.com/users/whwme/repos","events_url":"https://api.github.com/users/whwme/events{/privacy}","received_events_url":"https://api.github.com/users/whwme/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2020-10-26T01:52:55Z","performed_via_github_app":null},{"id":3918526882,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDM5MTg1MjY4ODI=","url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/events/3918526882","actor":{"login":"whwme","id":61930311,"node_id":"MDQ6VXNlcjYxOTMwMzEx","avatar_url":"https://avatars.githubusercontent.com/u/61930311?v=4","gravatar_id":"","url":"https://api.github.com/users/whwme","html_url":"https://github.com/whwme","followers_url":"https://api.github.com/users/whwme/followers","following_url":"https://api.github.com/users/whwme/following{/other_user}","gists_url":"https://api.github.com/users/whwme/gists{/gist_id}","starred_url":"https://api.github.com/users/whwme/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/whwme/subscriptions","organizations_url":"https://api.github.com/users/whwme/orgs","repos_url":"https://api.github.com/users/whwme/repos","events_url":"https://api.github.com/users/whwme/events{/privacy}","received_events_url":"https://api.github.com/users/whwme/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2020-10-26T01:52:55Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/comments/726581250","html_url":"https://github.com/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/248#issuecomment-726581250","issue_url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/248","id":726581250,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNjU4MTI1MA==","user":{"login":"Donaghys","id":49194956,"node_id":"MDQ6VXNlcjQ5MTk0OTU2","avatar_url":"https://avatars.githubusercontent.com/u/49194956?v=4","gravatar_id":"","url":"https://api.github.com/users/Donaghys","html_url":"https://github.com/Donaghys","followers_url":"https://api.github.com/users/Donaghys/followers","following_url":"https://api.github.com/users/Donaghys/following{/other_user}","gists_url":"https://api.github.com/users/Donaghys/gists{/gist_id}","starred_url":"https://api.github.com/users/Donaghys/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Donaghys/subscriptions","organizations_url":"https://api.github.com/users/Donaghys/orgs","repos_url":"https://api.github.com/users/Donaghys/repos","events_url":"https://api.github.com/users/Donaghys/events{/privacy}","received_events_url":"https://api.github.com/users/Donaghys/received_events","type":"User","site_admin":false},"created_at":"2020-11-13T07:47:59Z","updated_at":"2020-11-13T07:47:59Z","author_association":"NONE","body":"> @whwme\r\n> 这个是在瓶颈出现在读数据上面，可以改变一下读数据的方式，可以快1倍以上的速度，我16G内存，4G显示，Batch_size, 128，一个epoch大概 5000秒，看作者的，200张图像/s，我没有用prefecter技术之前大概是320张图像/s。用了之后750张/s。如果内存够大，你可以把batch_size 增大。\r\n> \r\n> ![QQ浏览器截图20201026085903](https://user-images.githubusercontent.com/52853052/97124080-a9a37980-1769-11eb-89d5-6e40c813f79a.png)\r\n> 修改lib/core/function.py\r\n> 整个文件都修改了。\r\n> 代码如下：\r\n> `\r\n> \"\"\"\r\n> 利用了prefetcher技术，连计算的同时也在读取数据\r\n> 虽然现在GPU利用率比之前还低，但处理速度，比之前快了一倍\r\n> 缺点：内存占用比之前多一倍\r\n> \"\"\"\r\n> \r\n> from **future** import absolute_import\r\n> import time\r\n> import lib.utils.utils as utils\r\n> import torch\r\n> \r\n> class AverageMeter(object):\r\n> \r\n> ```\r\n> \"\"\"Computes and stores the average and current value\"\"\"\r\n> def __init__(self):\r\n>     self.val = 0\r\n>     self.avg = 0\r\n>     self.sum = 0\r\n>     self.count = 0\r\n>     self.reset()\r\n> \r\n> def reset(self):\r\n>     self.val = 0\r\n>     self.avg = 0\r\n>     self.sum = 0\r\n>     self.count = 0\r\n> \r\n> def update(self, val, n=1):\r\n>     self.val = val\r\n>     self.sum += val * n\r\n>     self.count += n\r\n>     self.avg = self.sum / self.count\r\n> ```\r\n> \r\n> class data_prefetcher():\r\n> \r\n> ```\r\n> def __init__(self, loader):\r\n>     self.loader = iter(loader)\r\n>     self.stream = torch.cuda.Stream()\r\n>     # 在数据处理里已经做了标准化了，所以这里不再需要做了\r\n>     # self.mean = torch.tensor([0.485 * 255, 0.456 * 255, 0.406 * 255]).cuda().view(1,3,1,1)\r\n>     # self.std = torch.tensor([0.229 * 255, 0.224 * 255, 0.225 * 255]).cuda().view(1,3,1,1)\r\n> \r\n>     # self.mean = torch.tensor([0.485 * 255, 0.456 * 255, 0.406 * 255]).cuda().view(1,3,1,1)\r\n>     # self.std = torch.tensor([0.229 * 255, 0.224 * 255, 0.225 * 255]).cuda().view(1,3,1,1)\r\n>     # With Amp, it isn't necessary to manually convert data to half.\r\n>     # if args.fp16:\r\n>     #     self.mean = self.mean.half()\r\n>     #     self.std = self.std.half()\r\n>     self.preload()\r\n> \r\n> def preload(self):\r\n>     try:\r\n>         self.next_input, self.next_target = next(self.loader)\r\n>     except StopIteration:\r\n>         self.next_input = None\r\n>         self.next_target = None\r\n>         return\r\n>     with torch.cuda.stream(self.stream):\r\n>         self.next_input = self.next_input.cuda(non_blocking=True)\r\n>         self.next_target = self.next_target.cuda(non_blocking=True)\r\n>         # With Amp, it isn't necessary to manually convert data to half.\r\n>         # if args.fp16:\r\n>         #     self.next_input = self.next_input.half()\r\n>         # else:\r\n>         self.next_input = self.next_input.float()\r\n>         # self.next_input = self.next_input.sub_(self.mean).div_(self.std)\r\n>         \r\n> def next(self):\r\n>     torch.cuda.current_stream().wait_stream(self.stream)\r\n>     input = self.next_input\r\n>     target = self.next_target\r\n>     self.preload()\r\n>     return input, target\r\n> ```\r\n> \r\n> def train(config, train_loader, dataset, converter, model, criterion, optimizer, device, epoch, writer_dict=None, output_dict=None):\r\n> \r\n> ```\r\n> batch_time = AverageMeter()\r\n> data_time = AverageMeter()\r\n> losses = AverageMeter()\r\n> \r\n> model.train()\r\n> \r\n> end = time.time()\r\n> \r\n> prefetcher = data_prefetcher(train_loader)\r\n> inp, idx = prefetcher.next()\r\n> \r\n> i = 0\r\n> while inp is not None:\r\n>     i += 1\r\n>     # measure data time\r\n>     data_time.update(time.time() - end)\r\n>     \r\n>     labels = utils.get_batch_label(dataset, idx)\r\n>     inp = inp.to(device)\r\n> \r\n>     # inference\r\n>     preds = model(inp)\r\n> \r\n>     # compute loss\r\n>     batch_size = inp.size(0)\r\n>     # print(batch_size, len(labels))\r\n>     text, length = converter.encode(labels)                    # length = 一个batch中的总字符长度, text = 一个batch中的字符所对应的下标\r\n>     preds_size = torch.IntTensor([preds.size(0)] * batch_size) # timestep * batchsize\r\n>     loss = criterion(preds, text, preds_size, length)\r\n> \r\n>     optimizer.zero_grad()\r\n>     loss.backward()\r\n>     optimizer.step()\r\n> \r\n>     losses.update(loss.item(), inp.size(0))\r\n> \r\n>     batch_time.update(time.time()-end)\r\n>     if i % config.PRINT_FREQ == 0:\r\n>         msg = 'Epoch: [{0}][{1}/{2}]\\t' \\\r\n>               'Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\\t' \\\r\n>               'Speed {speed:.1f} samples/s\\t' \\\r\n>               'Data {data_time.val:.3f}s ({data_time.avg:.3f}s)\\t' \\\r\n>               'Loss {loss.val:.5f} ({loss.avg:.5f})\\t'.format(\r\n>                   epoch, i, len(train_loader), batch_time=batch_time,\r\n>                   speed=inp.size(0)/batch_time.val,\r\n>                   data_time=data_time, loss=losses)\r\n>         print(msg)\r\n> \r\n>         if writer_dict:\r\n>             writer = writer_dict['writer']\r\n>             global_steps = writer_dict['train_global_steps']\r\n>             writer.add_scalar('train_loss', losses.avg, global_steps)\r\n>             writer_dict['train_global_steps'] = global_steps + 1\r\n> \r\n>     end = time.time()\r\n>     \r\n>     inp, idx = prefetcher.next()\r\n> ```\r\n> \r\n> def validate(config, val_loader, dataset, converter, model, criterion, device, epoch, writer_dict, output_dict):\r\n> \r\n> ```\r\n> losses = AverageMeter()\r\n> model.eval()\r\n> \r\n> n_correct = 0\r\n> with torch.no_grad():\r\n>     for i, (inp, idx) in enumerate(val_loader):\r\n> \r\n>         labels = utils.get_batch_label(dataset, idx)\r\n>         inp = inp.to(device)\r\n> \r\n>         # inference\r\n>         preds = model(inp)\r\n> \r\n>         # compute loss\r\n>         batch_size = inp.size(0)\r\n>         text, length = converter.encode(labels)\r\n>         preds_size = torch.IntTensor([preds.size(0)] * batch_size)\r\n>         loss = criterion(preds, text, preds_size, length)\r\n> \r\n>         losses.update(loss.item(), inp.size(0))\r\n> \r\n>         _, preds = preds.max(2)\r\n>         preds = preds.transpose(1, 0).contiguous().view(-1)\r\n>         sim_preds = converter.decode(preds.data, preds_size.data, raw=False)\r\n>         for pred, target in zip(sim_preds, labels):\r\n>             if pred == target:\r\n>                 n_correct += 1\r\n> \r\n>         if (i + 1) % config.PRINT_FREQ == 0:\r\n>             print('Epoch: [{0}][{1}/{2}]'.format(epoch, i, len(val_loader)))\r\n> \r\n>         if i == config.TEST.NUM_TEST_BATCH:\r\n>             break\r\n> \r\n> raw_preds = converter.decode(preds.data, preds_size.data, raw=True)[:config.TEST.NUM_TEST_DISP]\r\n> for raw_pred, pred, gt in zip(raw_preds, sim_preds, labels):\r\n>     print('%-20s => %-20s, gt: %-20s' % (raw_pred, pred, gt))\r\n> \r\n> num_test_sample = config.TEST.NUM_TEST_BATCH * config.TEST.BATCH_SIZE_PER_GPU\r\n> if num_test_sample > len(dataset):\r\n>     num_test_sample = len(dataset)\r\n> \r\n> print(\"[#correct:{} / #total:{}]\".format(n_correct, num_test_sample))\r\n> accuracy = n_correct / float(num_test_sample)\r\n> print('Test loss: {:.4f}, accuray: {:.4f}'.format(losses.avg, accuracy))\r\n> \r\n> if writer_dict:\r\n>     writer = writer_dict['writer']\r\n>     global_steps = writer_dict['valid_global_steps']\r\n>     writer.add_scalar('valid_acc', accuracy, global_steps)\r\n>     writer_dict['valid_global_steps'] = global_steps + 1\r\n> \r\n> return accuracy\r\n> ```\r\n> \r\n> `\r\n\r\n您好，请问这样子会不会影响最终模型的效果？","reactions":{"url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/comments/726581250/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"Donaghys","id":49194956,"node_id":"MDQ6VXNlcjQ5MTk0OTU2","avatar_url":"https://avatars.githubusercontent.com/u/49194956?v=4","gravatar_id":"","url":"https://api.github.com/users/Donaghys","html_url":"https://github.com/Donaghys","followers_url":"https://api.github.com/users/Donaghys/followers","following_url":"https://api.github.com/users/Donaghys/following{/other_user}","gists_url":"https://api.github.com/users/Donaghys/gists{/gist_id}","starred_url":"https://api.github.com/users/Donaghys/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Donaghys/subscriptions","organizations_url":"https://api.github.com/users/Donaghys/orgs","repos_url":"https://api.github.com/users/Donaghys/repos","events_url":"https://api.github.com/users/Donaghys/events{/privacy}","received_events_url":"https://api.github.com/users/Donaghys/received_events","type":"User","site_admin":false}},{"id":3992222019,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50Mzk5MjIyMjAxOQ==","url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/events/3992222019","actor":{"login":"whwme","id":61930311,"node_id":"MDQ6VXNlcjYxOTMwMzEx","avatar_url":"https://avatars.githubusercontent.com/u/61930311?v=4","gravatar_id":"","url":"https://api.github.com/users/whwme","html_url":"https://github.com/whwme","followers_url":"https://api.github.com/users/whwme/followers","following_url":"https://api.github.com/users/whwme/following{/other_user}","gists_url":"https://api.github.com/users/whwme/gists{/gist_id}","starred_url":"https://api.github.com/users/whwme/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/whwme/subscriptions","organizations_url":"https://api.github.com/users/whwme/orgs","repos_url":"https://api.github.com/users/whwme/repos","events_url":"https://api.github.com/users/whwme/events{/privacy}","received_events_url":"https://api.github.com/users/whwme/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2020-11-13T07:47:59Z","performed_via_github_app":null},{"id":3992222021,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDM5OTIyMjIwMjE=","url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/events/3992222021","actor":{"login":"whwme","id":61930311,"node_id":"MDQ6VXNlcjYxOTMwMzEx","avatar_url":"https://avatars.githubusercontent.com/u/61930311?v=4","gravatar_id":"","url":"https://api.github.com/users/whwme","html_url":"https://github.com/whwme","followers_url":"https://api.github.com/users/whwme/followers","following_url":"https://api.github.com/users/whwme/following{/other_user}","gists_url":"https://api.github.com/users/whwme/gists{/gist_id}","starred_url":"https://api.github.com/users/whwme/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/whwme/subscriptions","organizations_url":"https://api.github.com/users/whwme/orgs","repos_url":"https://api.github.com/users/whwme/repos","events_url":"https://api.github.com/users/whwme/events{/privacy}","received_events_url":"https://api.github.com/users/whwme/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2020-11-13T07:47:59Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/comments/727144071","html_url":"https://github.com/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/248#issuecomment-727144071","issue_url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/248","id":727144071,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNzE0NDA3MQ==","user":{"login":"Donaghys","id":49194956,"node_id":"MDQ6VXNlcjQ5MTk0OTU2","avatar_url":"https://avatars.githubusercontent.com/u/49194956?v=4","gravatar_id":"","url":"https://api.github.com/users/Donaghys","html_url":"https://github.com/Donaghys","followers_url":"https://api.github.com/users/Donaghys/followers","following_url":"https://api.github.com/users/Donaghys/following{/other_user}","gists_url":"https://api.github.com/users/Donaghys/gists{/gist_id}","starred_url":"https://api.github.com/users/Donaghys/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Donaghys/subscriptions","organizations_url":"https://api.github.com/users/Donaghys/orgs","repos_url":"https://api.github.com/users/Donaghys/repos","events_url":"https://api.github.com/users/Donaghys/events{/privacy}","received_events_url":"https://api.github.com/users/Donaghys/received_events","type":"User","site_admin":false},"created_at":"2020-11-14T04:44:34Z","updated_at":"2020-11-14T04:44:34Z","author_association":"NONE","body":"![image](https://user-images.githubusercontent.com/49194956/99139807-ee3e7880-2676-11eb-9d81-1ee1e5c83011.png)\r\n速度是快了不少，但是loss降不下去，平时最终在0.0005收敛，现在在0.6就收敛了，有好的解决办法吗？","reactions":{"url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/comments/727144071/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"Donaghys","id":49194956,"node_id":"MDQ6VXNlcjQ5MTk0OTU2","avatar_url":"https://avatars.githubusercontent.com/u/49194956?v=4","gravatar_id":"","url":"https://api.github.com/users/Donaghys","html_url":"https://github.com/Donaghys","followers_url":"https://api.github.com/users/Donaghys/followers","following_url":"https://api.github.com/users/Donaghys/following{/other_user}","gists_url":"https://api.github.com/users/Donaghys/gists{/gist_id}","starred_url":"https://api.github.com/users/Donaghys/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Donaghys/subscriptions","organizations_url":"https://api.github.com/users/Donaghys/orgs","repos_url":"https://api.github.com/users/Donaghys/repos","events_url":"https://api.github.com/users/Donaghys/events{/privacy}","received_events_url":"https://api.github.com/users/Donaghys/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/comments/727161532","html_url":"https://github.com/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/248#issuecomment-727161532","issue_url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/248","id":727161532,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNzE2MTUzMg==","user":{"login":"jasnei","id":52853052,"node_id":"MDQ6VXNlcjUyODUzMDUy","avatar_url":"https://avatars.githubusercontent.com/u/52853052?v=4","gravatar_id":"","url":"https://api.github.com/users/jasnei","html_url":"https://github.com/jasnei","followers_url":"https://api.github.com/users/jasnei/followers","following_url":"https://api.github.com/users/jasnei/following{/other_user}","gists_url":"https://api.github.com/users/jasnei/gists{/gist_id}","starred_url":"https://api.github.com/users/jasnei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasnei/subscriptions","organizations_url":"https://api.github.com/users/jasnei/orgs","repos_url":"https://api.github.com/users/jasnei/repos","events_url":"https://api.github.com/users/jasnei/events{/privacy}","received_events_url":"https://api.github.com/users/jasnei/received_events","type":"User","site_admin":false},"created_at":"2020-11-14T07:40:09Z","updated_at":"2020-11-14T07:43:12Z","author_association":"NONE","body":"这个不会影响模型的，这只是dataloader会快一点。你可以测试一下准确率看看效果。这个跟原来的没有什么区别，区别是是加了prefecter技术，读数据时候快点。应该不影响到loss还有准确率的。你可以对比一下两个模型的效果。","reactions":{"url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/comments/727161532/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"jasnei","id":52853052,"node_id":"MDQ6VXNlcjUyODUzMDUy","avatar_url":"https://avatars.githubusercontent.com/u/52853052?v=4","gravatar_id":"","url":"https://api.github.com/users/jasnei","html_url":"https://github.com/jasnei","followers_url":"https://api.github.com/users/jasnei/followers","following_url":"https://api.github.com/users/jasnei/following{/other_user}","gists_url":"https://api.github.com/users/jasnei/gists{/gist_id}","starred_url":"https://api.github.com/users/jasnei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jasnei/subscriptions","organizations_url":"https://api.github.com/users/jasnei/orgs","repos_url":"https://api.github.com/users/jasnei/repos","events_url":"https://api.github.com/users/jasnei/events{/privacy}","received_events_url":"https://api.github.com/users/jasnei/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/comments/727162478","html_url":"https://github.com/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/248#issuecomment-727162478","issue_url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/248","id":727162478,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNzE2MjQ3OA==","user":{"login":"Donaghys","id":49194956,"node_id":"MDQ6VXNlcjQ5MTk0OTU2","avatar_url":"https://avatars.githubusercontent.com/u/49194956?v=4","gravatar_id":"","url":"https://api.github.com/users/Donaghys","html_url":"https://github.com/Donaghys","followers_url":"https://api.github.com/users/Donaghys/followers","following_url":"https://api.github.com/users/Donaghys/following{/other_user}","gists_url":"https://api.github.com/users/Donaghys/gists{/gist_id}","starred_url":"https://api.github.com/users/Donaghys/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Donaghys/subscriptions","organizations_url":"https://api.github.com/users/Donaghys/orgs","repos_url":"https://api.github.com/users/Donaghys/repos","events_url":"https://api.github.com/users/Donaghys/events{/privacy}","received_events_url":"https://api.github.com/users/Donaghys/received_events","type":"User","site_admin":false},"created_at":"2020-11-14T07:50:09Z","updated_at":"2020-11-14T07:50:09Z","author_association":"NONE","body":"> 这个不会影响模型的，这只是dataloader会快一点。你可以测试一下准确率看看效果。\r\n感谢您的工作，同样使用作者提供的预训练模型finetune，如果我不使用prefecter，我的数据一个bs后就可以到2.多，只需要2-3个epoch就可以下降到很低，大约在0.005左右，验证集有90%以上的准确率，但是速度在500/s张左右，加入这个prefecter后，速度到了3100/s，但是这个损失就下降的很慢，现在已经30个epoch了，损失依然是0.6，曲线如刚才发的样子，我现在怀疑网络已经收敛了~，但是除了这个dataloader以外，我没有对代码做任何修改，我很困惑，希望得到您的指点~","reactions":{"url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/comments/727162478/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"Donaghys","id":49194956,"node_id":"MDQ6VXNlcjQ5MTk0OTU2","avatar_url":"https://avatars.githubusercontent.com/u/49194956?v=4","gravatar_id":"","url":"https://api.github.com/users/Donaghys","html_url":"https://github.com/Donaghys","followers_url":"https://api.github.com/users/Donaghys/followers","following_url":"https://api.github.com/users/Donaghys/following{/other_user}","gists_url":"https://api.github.com/users/Donaghys/gists{/gist_id}","starred_url":"https://api.github.com/users/Donaghys/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Donaghys/subscriptions","organizations_url":"https://api.github.com/users/Donaghys/orgs","repos_url":"https://api.github.com/users/Donaghys/repos","events_url":"https://api.github.com/users/Donaghys/events{/privacy}","received_events_url":"https://api.github.com/users/Donaghys/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/comments/727520499","html_url":"https://github.com/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/248#issuecomment-727520499","issue_url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/248","id":727520499,"node_id":"MDEyOklzc3VlQ29tbWVudDcyNzUyMDQ5OQ==","user":{"login":"Donaghys","id":49194956,"node_id":"MDQ6VXNlcjQ5MTk0OTU2","avatar_url":"https://avatars.githubusercontent.com/u/49194956?v=4","gravatar_id":"","url":"https://api.github.com/users/Donaghys","html_url":"https://github.com/Donaghys","followers_url":"https://api.github.com/users/Donaghys/followers","following_url":"https://api.github.com/users/Donaghys/following{/other_user}","gists_url":"https://api.github.com/users/Donaghys/gists{/gist_id}","starred_url":"https://api.github.com/users/Donaghys/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Donaghys/subscriptions","organizations_url":"https://api.github.com/users/Donaghys/orgs","repos_url":"https://api.github.com/users/Donaghys/repos","events_url":"https://api.github.com/users/Donaghys/events{/privacy}","received_events_url":"https://api.github.com/users/Donaghys/received_events","type":"User","site_admin":false},"created_at":"2020-11-15T05:58:42Z","updated_at":"2020-11-15T05:58:42Z","author_association":"NONE","body":"> 这个不会影响模型的，这只是dataloader会快一点。你可以测试一下准确率看看效果。这个跟原来的没有什么区别，区别是是加了prefecter技术，读数据时候快点。应该不影响到loss还有准确率的。你可以对比一下两个模型的效果。\r\n主要还是mode(inp),以前是cpu做预测，您这是gpu做预测~，两者会不会有差距呢？\r\n","reactions":{"url":"https://api.github.com/repos/Sierkinhane/CRNN_Chinese_Characters_Rec/issues/comments/727520499/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"Donaghys","id":49194956,"node_id":"MDQ6VXNlcjQ5MTk0OTU2","avatar_url":"https://avatars.githubusercontent.com/u/49194956?v=4","gravatar_id":"","url":"https://api.github.com/users/Donaghys","html_url":"https://github.com/Donaghys","followers_url":"https://api.github.com/users/Donaghys/followers","following_url":"https://api.github.com/users/Donaghys/following{/other_user}","gists_url":"https://api.github.com/users/Donaghys/gists{/gist_id}","starred_url":"https://api.github.com/users/Donaghys/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Donaghys/subscriptions","organizations_url":"https://api.github.com/users/Donaghys/orgs","repos_url":"https://api.github.com/users/Donaghys/repos","events_url":"https://api.github.com/users/Donaghys/events{/privacy}","received_events_url":"https://api.github.com/users/Donaghys/received_events","type":"User","site_admin":false}}]