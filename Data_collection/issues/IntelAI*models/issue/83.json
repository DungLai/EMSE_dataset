{"url":"https://api.github.com/repos/IntelAI/models/issues/83","repository_url":"https://api.github.com/repos/IntelAI/models","labels_url":"https://api.github.com/repos/IntelAI/models/issues/83/labels{/name}","comments_url":"https://api.github.com/repos/IntelAI/models/issues/83/comments","events_url":"https://api.github.com/repos/IntelAI/models/issues/83/events","html_url":"https://github.com/IntelAI/models/issues/83","id":921459713,"node_id":"MDU6SXNzdWU5MjE0NTk3MTM=","number":83,"title":"How to evaluate the performance number of Bert-Large training","user":{"login":"zhixingheyi-tian","id":41657774,"node_id":"MDQ6VXNlcjQxNjU3Nzc0","avatar_url":"https://avatars.githubusercontent.com/u/41657774?v=4","gravatar_id":"","url":"https://api.github.com/users/zhixingheyi-tian","html_url":"https://github.com/zhixingheyi-tian","followers_url":"https://api.github.com/users/zhixingheyi-tian/followers","following_url":"https://api.github.com/users/zhixingheyi-tian/following{/other_user}","gists_url":"https://api.github.com/users/zhixingheyi-tian/gists{/gist_id}","starred_url":"https://api.github.com/users/zhixingheyi-tian/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhixingheyi-tian/subscriptions","organizations_url":"https://api.github.com/users/zhixingheyi-tian/orgs","repos_url":"https://api.github.com/users/zhixingheyi-tian/repos","events_url":"https://api.github.com/users/zhixingheyi-tian/events{/privacy}","received_events_url":"https://api.github.com/users/zhixingheyi-tian/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-06-15T14:27:23Z","updated_at":"2021-06-15T17:22:40Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I encountered some confusion when I followed the guide--https://github.com/IntelAI/models/tree/master/benchmarks/language_modeling/tensorflow/bert_large to run training workload.\r\n\r\nRunning command:\r\n\r\n```\r\nnohup python ./launch_benchmark.py \\\r\n    --model-name=bert_large \\\r\n    --precision=fp32 \\\r\n    --mode=training \\\r\n    --framework=tensorflow \\\r\n    --batch-size=24 --mpi_num_processes=2 \\\r\n    --benchmark-only \\\r\n    --docker-image intel/intel-optimized-tensorflow:2.3.0 \\\r\n    --volume $BERT_LARGE_DIR:$BERT_LARGE_DIR \\\r\n    --volume $SQUAD_DIR:$SQUAD_DIR \\\r\n    --data-location=$BERT_LARGE_DIR \\\r\n    --num-intra-threads=26 \\\r\n    --num-inter-threads=1 \\\r\n-- train-option=SQuAD  DEBIAN_FRONTEND=noninteractive   config_file=$BERT_LARGE_DIR/bert_config.json init_checkpoint=$BERT_LARGE_DIR/bert_model.ckpt     vocab_file=$BERT_LARGE_DIR/vocab.txt train_file=$SQUAD_DIR/train-v1.1.json     predict_file=$SQUAD_DIR/dev-v1.1.json      do-train=True learning-rate=1.5e-5   max-seq-length=384     do_predict=True warmup-steps=0     num_train_epochs=2     doc_stride=128      do_lower_case=False     experimental-gelu=False     mpi_workers_sync_gradients=True >> training-0609 &\r\n\r\n```\r\nResult:\r\n\r\n```\r\nINFO:tensorflow:Writing nbest to: /workspace/benchmarks/common/tensorflow/logs/nbest_predictions.json\r\nI0610 01:09:58.730417 140427424720704 run_squad.py:798] Writing nbest to: /workspace/benchmarks/common/tensorflow/logs/nbest_predictions.json\r\nINFO:tensorflow:Processing example: 9000\r\nI0610 01:13:27.192351 140160153200448 run_squad.py:1363] Processing example: 9000\r\nINFO:tensorflow:Processing example: 10000\r\nI0610 01:17:27.623694 140160153200448 run_squad.py:1363] Processing example: 10000\r\nINFO:tensorflow:prediction_loop marked as finished\r\nI0610 01:20:36.625470 140160153200448 error_handling.py:115] prediction_loop marked as finished\r\nINFO:tensorflow:prediction_loop marked as finished\r\nI0610 01:20:36.625671 140160153200448 error_handling.py:115] prediction_loop marked as finished\r\nINFO:tensorflow:Writing predictions to: /workspace/benchmarks/common/tensorflow/logs/1/predictions.json\r\nI0610 01:20:36.625791 140160153200448 run_squad.py:797] Writing predictions to: /workspace/benchmarks/common/tensorflow/logs/1/predictions.json\r\nINFO:tensorflow:Writing nbest to: /workspace/benchmarks/common/tensorflow/logs/1/nbest_predictions.json\r\nI0610 01:20:36.625833 140160153200448 run_squad.py:798] Writing nbest to: /workspace/benchmarks/common/tensorflow/logs/1/nbest_predictions.json\r\n\r\n```\r\nI didn’t see the “throughput((num_processed_examples-threshod_examples)/Elapsedtime)” information like inference workload  from the training log. I also read the script code: models/models/language_modeling/tensorflow/bert_large/training/fp32/run_squad.py, I have not found about “throughput”. But the ./models/models/language_modeling/tensorflow/bert_large/inference/run_squad.py used by inference has code about ” throughput((num_processed_examples-threshod_examples)/Elapsedtime)”.\r\n\r\n\r\nSo how  to evaluate the performance number of Bert-Large training. There is neither \"throughput\" nor \"Elapsedtime\" in the log and running script?\r\n\r\n\r\n@ashahba @dmsuehir \r\n\r\nThanks","closed_by":null,"reactions":{"url":"https://api.github.com/repos/IntelAI/models/issues/83/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/IntelAI/models/issues/83/timeline","performed_via_github_app":null,"state_reason":null}