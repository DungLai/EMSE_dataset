{"url":"https://api.github.com/repos/IntelAI/models/issues/98","repository_url":"https://api.github.com/repos/IntelAI/models","labels_url":"https://api.github.com/repos/IntelAI/models/issues/98/labels{/name}","comments_url":"https://api.github.com/repos/IntelAI/models/issues/98/comments","events_url":"https://api.github.com/repos/IntelAI/models/issues/98/events","html_url":"https://github.com/IntelAI/models/issues/98","id":1180579523,"node_id":"I_kwDOCTQkLM5GXjbD","number":98,"title":"Query: Parallel_batches support for CNN and NLP model","user":{"login":"avinashcpandey","id":3540503,"node_id":"MDQ6VXNlcjM1NDA1MDM=","avatar_url":"https://avatars.githubusercontent.com/u/3540503?v=4","gravatar_id":"","url":"https://api.github.com/users/avinashcpandey","html_url":"https://github.com/avinashcpandey","followers_url":"https://api.github.com/users/avinashcpandey/followers","following_url":"https://api.github.com/users/avinashcpandey/following{/other_user}","gists_url":"https://api.github.com/users/avinashcpandey/gists{/gist_id}","starred_url":"https://api.github.com/users/avinashcpandey/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/avinashcpandey/subscriptions","organizations_url":"https://api.github.com/users/avinashcpandey/orgs","repos_url":"https://api.github.com/users/avinashcpandey/repos","events_url":"https://api.github.com/users/avinashcpandey/events{/privacy}","received_events_url":"https://api.github.com/users/avinashcpandey/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-03-25T09:56:47Z","updated_at":"2022-03-25T09:56:47Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I see WideDeep has parallel batch support where no. of input samples can be broken into N chunks and run parallely. \r\n\r\nEg. if we are giving parallel_batchess 28, inter=28 intra and num_threads=1 for CSL single socket. \r\nBenchmark will launch 28 graph  execution parallely  and each will work on provided BS. Please correct me here.\r\n\r\nThis is the reference I followed.\r\nhttps://github.com/IntelAI/models/blob/master/benchmarks/recommendation/tensorflow/wide_deep_large_ds/inference/fp32/Advanced.md\r\n\r\nNow I want to do the same for CNN model (eg. inceptionV3) \r\nFor example Given BS is 280, and given parallel batches is 28. Then 28 graph execution will be created where each graph execution will work on 10 images.\r\n\r\nIs this supported? If yes, how can I use it?\r\nIf No, Is it there in plan?\r\n\r\nI want to do the same for BERT also.\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/IntelAI/models/issues/98/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/IntelAI/models/issues/98/timeline","performed_via_github_app":null,"state_reason":null}