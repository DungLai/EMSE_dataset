{"url":"https://api.github.com/repos/quark0/darts/issues/16","repository_url":"https://api.github.com/repos/quark0/darts","labels_url":"https://api.github.com/repos/quark0/darts/issues/16/labels{/name}","comments_url":"https://api.github.com/repos/quark0/darts/issues/16/comments","events_url":"https://api.github.com/repos/quark0/darts/issues/16/events","html_url":"https://github.com/quark0/darts/issues/16","id":340809654,"node_id":"MDU6SXNzdWUzNDA4MDk2NTQ=","number":16,"title":"Out of memory trying to run CIFAR example","user":{"login":"AlexMikhalev","id":50685,"node_id":"MDQ6VXNlcjUwNjg1","avatar_url":"https://avatars.githubusercontent.com/u/50685?v=4","gravatar_id":"","url":"https://api.github.com/users/AlexMikhalev","html_url":"https://github.com/AlexMikhalev","followers_url":"https://api.github.com/users/AlexMikhalev/followers","following_url":"https://api.github.com/users/AlexMikhalev/following{/other_user}","gists_url":"https://api.github.com/users/AlexMikhalev/gists{/gist_id}","starred_url":"https://api.github.com/users/AlexMikhalev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AlexMikhalev/subscriptions","organizations_url":"https://api.github.com/users/AlexMikhalev/orgs","repos_url":"https://api.github.com/users/AlexMikhalev/repos","events_url":"https://api.github.com/users/AlexMikhalev/events{/privacy}","received_events_url":"https://api.github.com/users/AlexMikhalev/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":8,"created_at":"2018-07-12T21:45:35Z","updated_at":"2018-07-20T14:15:18Z","closed_at":"2018-07-17T04:58:31Z","author_association":"NONE","active_lock_reason":null,"body":"I am tring to run CIFAR example using pyro docker image, but I have cuda out of memory error:\r\n\r\n\r\n`pyromancer@6d7a480a66c9:~/workspace/shared/darts/cnn$ python train_search.py --unrolled\r\nExperiment dir : search-EXP-20180712-214257\r\n07/12 09:42:57 PM gpu device = 0\r\n07/12 09:42:57 PM args = Namespace(arch_learning_rate=0.0003, arch_weight_decay=0.001, batch_size=64, cutout=False, cutout_length=16, data='../data', drop_path_prob=0.3, epochs=50, gpu=0, grad_clip=5, init_channels=16, layers=8, learning_rate=0.025, learning_rate_min=0.001, model_path='saved_models', momentum=0.9, report_freq=50, save='search-EXP-20180712-214257', seed=2, train_portion=0.5, unrolled=True, weight_decay=0.0003)\r\n07/12 09:43:00 PM param size = 1.930618MB\r\nFiles already downloaded and verified\r\nFiles already downloaded and verified\r\n07/12 09:43:01 PM epoch 0 lr 2.500000e-02\r\n07/12 09:43:01 PM genotype = Genotype(normal=[('avg_pool_3x3', 0), ('dil_conv_5x5', 1), ('dil_conv_3x3', 1), ('dil_conv_5x5', 2), ('max_pool_3x3', 1), ('avg_pool_3x3', 0), ('dil_conv_5x5', 1), ('avg_pool_3x3', 0)], normal_concat=range(2, 6), reduce=[('avg_pool_3x3', 1), ('avg_pool_3x3', 0), ('sep_conv_3x3', 1), ('dil_conv_5x5', 2), ('sep_conv_3x3', 2), ('avg_pool_3x3', 3), ('max_pool_3x3', 4), ('dil_conv_5x5', 0)], reduce_concat=range(2, 6))\r\ntensor([[ 0.1249,  0.1249,  0.1252,  0.1251,  0.1250,  0.1250,  0.1250,\r\n          0.1249],\r\n        [ 0.1250,  0.1248,  0.1251,  0.1250,  0.1250,  0.1250,  0.1251,\r\n          0.1251],\r\n        [ 0.1250,  0.1250,  0.1250,  0.1250,  0.1250,  0.1250,  0.1251,\r\n          0.1249],\r\n        [ 0.1249,  0.1249,  0.1249,  0.1250,  0.1249,  0.1250,  0.1253,\r\n          0.1251],\r\n        [ 0.1249,  0.1251,  0.1251,  0.1250,  0.1249,  0.1249,  0.1249,\r\n          0.1251],\r\n        [ 0.1250,  0.1250,  0.1252,  0.1251,  0.1249,  0.1249,  0.1250,\r\n          0.1249],\r\n        [ 0.1249,  0.1253,  0.1250,  0.1248,  0.1248,  0.1251,  0.1251,\r\n          0.1250],\r\n        [ 0.1249,  0.1251,  0.1251,  0.1252,  0.1250,  0.1248,  0.1250,\r\n          0.1249],\r\n        [ 0.1251,  0.1250,  0.1250,  0.1250,  0.1249,  0.1251,  0.1249,\r\n          0.1250],\r\n        [ 0.1249,  0.1248,  0.1252,  0.1247,  0.1251,  0.1249,  0.1252,\r\n          0.1251],\r\n        [ 0.1249,  0.1249,  0.1251,  0.1250,  0.1248,  0.1250,  0.1249,\r\n          0.1254],\r\n        [ 0.1251,  0.1250,  0.1250,  0.1250,  0.1252,  0.1250,  0.1249,\r\n          0.1250],\r\n        [ 0.1251,  0.1249,  0.1250,  0.1250,  0.1251,  0.1249,  0.1250,\r\n          0.1251],\r\n        [ 0.1251,  0.1252,  0.1251,  0.1247,  0.1252,  0.1249,  0.1249,\r\n          0.1250]], device='cuda:0')\r\ntensor([[ 0.1251,  0.1251,  0.1251,  0.1250,  0.1247,  0.1250,  0.1251,\r\n          0.1250],\r\n        [ 0.1250,  0.1249,  0.1251,  0.1250,  0.1250,  0.1248,  0.1251,\r\n          0.1248],\r\n        [ 0.1252,  0.1251,  0.1250,  0.1250,  0.1249,  0.1249,  0.1250,\r\n          0.1250],\r\n        [ 0.1248,  0.1249,  0.1250,  0.1249,  0.1252,  0.1250,  0.1251,\r\n          0.1251],\r\n        [ 0.1252,  0.1249,  0.1250,  0.1250,  0.1250,  0.1249,  0.1250,\r\n          0.1251],\r\n        [ 0.1249,  0.1251,  0.1250,  0.1250,  0.1250,  0.1251,  0.1250,\r\n          0.1249],\r\n        [ 0.1249,  0.1249,  0.1251,  0.1251,  0.1246,  0.1251,  0.1251,\r\n          0.1251],\r\n        [ 0.1250,  0.1247,  0.1250,  0.1251,  0.1252,  0.1250,  0.1250,\r\n          0.1250],\r\n        [ 0.1252,  0.1249,  0.1252,  0.1247,  0.1249,  0.1251,  0.1250,\r\n          0.1250],\r\n        [ 0.1248,  0.1251,  0.1251,  0.1249,  0.1249,  0.1249,  0.1251,\r\n          0.1252],\r\n        [ 0.1249,  0.1250,  0.1250,  0.1251,  0.1251,  0.1251,  0.1249,\r\n          0.1249],\r\n        [ 0.1250,  0.1249,  0.1249,  0.1252,  0.1250,  0.1250,  0.1251,\r\n          0.1250],\r\n        [ 0.1249,  0.1251,  0.1249,  0.1251,  0.1252,  0.1250,  0.1248,\r\n          0.1250],\r\n        [ 0.1251,  0.1253,  0.1249,  0.1250,  0.1248,  0.1249,  0.1248,\r\n          0.1251]], device='cuda:0')\r\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/THC/generic/THCStorage.cu line=58 error=2 : out of memory\r\nTraceback (most recent call last):\r\n  File \"train_search.py\", line 200, in <module>\r\n    main() \r\n  File \"train_search.py\", line 124, in main\r\n    train_acc, train_obj, arch_grad_norm = train(train_queue, search_queue, model, architect, criterion, optimizer, lr)\r\n  File \"train_search.py\", line 152, in train\r\n    arch_grad_norm = architect.step(input, target, input_search, target_search, lr, optimizer, unrolled=args.unrolled)\r\n  File \"/home/pyromancer/workspace/shared/darts/cnn/architect.py\", line 37, in step\r\n    input_train, target_train, input_valid, target_valid, eta, network_optimizer)\r\n  File \"/home/pyromancer/workspace/shared/darts/cnn/architect.py\", line 53, in _backward_step_unrolled\r\n    model_unrolled = self._compute_unrolled_model(input_train, target_train, eta, network_optimizer)\r\n  File \"/home/pyromancer/workspace/shared/darts/cnn/architect.py\", line 23, in _compute_unrolled_model\r\n    loss = self.model._loss(input, target)\r\n  File \"/home/pyromancer/workspace/shared/darts/cnn/model_search.py\", line 110, in _loss\r\n    logits = self(input)\r\n  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/pyromancer/workspace/shared/darts/cnn/model_search.py\", line 104, in forward\r\n    s0, s1 = s1, cell(s0, s1, weights)\r\n  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/pyromancer/workspace/shared/darts/cnn/model_search.py\", line 54, in forward\r\n    s = sum(self._ops[offset+j](h, weights[offset+j]) for j, h in enumerate(states))\r\n  File \"/home/pyromancer/workspace/shared/darts/cnn/model_search.py\", line 54, in <genexpr>\r\n    s = sum(self._ops[offset+j](h, weights[offset+j]) for j, h in enumerate(states))\r\n  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/pyromancer/workspace/shared/darts/cnn/model_search.py\", line 22, in forward\r\n    return sum(w * op(x) for w, op in zip(weights, self._ops))\r\n  File \"/home/pyromancer/workspace/shared/darts/cnn/model_search.py\", line 22, in <genexpr>\r\n    return sum(w * op(x) for w, op in zip(weights, self._ops))\r\nRuntimeError: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/THC/generic/THCStorage.cu:58`\r\n\r\nCard is GeForce GTX 1080  8119MiB  on ubuntu linux box. \r\n","closed_by":{"login":"quark0","id":4343626,"node_id":"MDQ6VXNlcjQzNDM2MjY=","avatar_url":"https://avatars.githubusercontent.com/u/4343626?v=4","gravatar_id":"","url":"https://api.github.com/users/quark0","html_url":"https://github.com/quark0","followers_url":"https://api.github.com/users/quark0/followers","following_url":"https://api.github.com/users/quark0/following{/other_user}","gists_url":"https://api.github.com/users/quark0/gists{/gist_id}","starred_url":"https://api.github.com/users/quark0/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/quark0/subscriptions","organizations_url":"https://api.github.com/users/quark0/orgs","repos_url":"https://api.github.com/users/quark0/repos","events_url":"https://api.github.com/users/quark0/events{/privacy}","received_events_url":"https://api.github.com/users/quark0/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/quark0/darts/issues/16/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/quark0/darts/issues/16/timeline","performed_via_github_app":null,"state_reason":"completed"}