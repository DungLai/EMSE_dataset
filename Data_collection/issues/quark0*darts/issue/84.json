{"url":"https://api.github.com/repos/quark0/darts/issues/84","repository_url":"https://api.github.com/repos/quark0/darts","labels_url":"https://api.github.com/repos/quark0/darts/issues/84/labels{/name}","comments_url":"https://api.github.com/repos/quark0/darts/issues/84/comments","events_url":"https://api.github.com/repos/quark0/darts/issues/84/events","html_url":"https://github.com/quark0/darts/issues/84","id":434233172,"node_id":"MDU6SXNzdWU0MzQyMzMxNzI=","number":84,"title":"A bug on FactorizedReduce in operations.py?","user":{"login":"Dav-Jay","id":11131378,"node_id":"MDQ6VXNlcjExMTMxMzc4","avatar_url":"https://avatars.githubusercontent.com/u/11131378?v=4","gravatar_id":"","url":"https://api.github.com/users/Dav-Jay","html_url":"https://github.com/Dav-Jay","followers_url":"https://api.github.com/users/Dav-Jay/followers","following_url":"https://api.github.com/users/Dav-Jay/following{/other_user}","gists_url":"https://api.github.com/users/Dav-Jay/gists{/gist_id}","starred_url":"https://api.github.com/users/Dav-Jay/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Dav-Jay/subscriptions","organizations_url":"https://api.github.com/users/Dav-Jay/orgs","repos_url":"https://api.github.com/users/Dav-Jay/repos","events_url":"https://api.github.com/users/Dav-Jay/events{/privacy}","received_events_url":"https://api.github.com/users/Dav-Jay/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2019-04-17T11:31:49Z","updated_at":"2020-01-17T12:02:04Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I wonder whether there is a bug in [this line](https://github.com/quark0/darts/blob/f276dd346a09ae3160f8e3aca5c7b193fda1da37/cnn/operations.py#L102) in the `FactorizedReduce` function:\r\n\r\n`out = torch.cat([self.conv_1(x), self.conv_2(x[:,:,1:,1:])], dim=1)`\r\n\r\n**NOTE: in above line, the input for `conv_2` is a sliced one of `x`**\r\n\r\nTherefore, it is definite that in some cases the outputs of `conv_1` and `conv_2` would have different shapes  in the 3rd and 4th dimension, which causes error in `torch.cat` since the concatenated tensors should have exactly the same shape.\r\n\r\nI'm surprised that it seems no one ever came into this problem. ","closed_by":null,"reactions":{"url":"https://api.github.com/repos/quark0/darts/issues/84/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/quark0/darts/issues/84/timeline","performed_via_github_app":null,"state_reason":null}