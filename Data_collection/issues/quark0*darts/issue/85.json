{"url":"https://api.github.com/repos/quark0/darts/issues/85","repository_url":"https://api.github.com/repos/quark0/darts","labels_url":"https://api.github.com/repos/quark0/darts/issues/85/labels{/name}","comments_url":"https://api.github.com/repos/quark0/darts/issues/85/comments","events_url":"https://api.github.com/repos/quark0/darts/issues/85/events","html_url":"https://github.com/quark0/darts/issues/85","id":434804268,"node_id":"MDU6SXNzdWU0MzQ4MDQyNjg=","number":85,"title":"It seems the global moving average is used as opposed to what the original paper instructed","user":{"login":"bombs-kim","id":11001573,"node_id":"MDQ6VXNlcjExMDAxNTcz","avatar_url":"https://avatars.githubusercontent.com/u/11001573?v=4","gravatar_id":"","url":"https://api.github.com/users/bombs-kim","html_url":"https://github.com/bombs-kim","followers_url":"https://api.github.com/users/bombs-kim/followers","following_url":"https://api.github.com/users/bombs-kim/following{/other_user}","gists_url":"https://api.github.com/users/bombs-kim/gists{/gist_id}","starred_url":"https://api.github.com/users/bombs-kim/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bombs-kim/subscriptions","organizations_url":"https://api.github.com/users/bombs-kim/orgs","repos_url":"https://api.github.com/users/bombs-kim/repos","events_url":"https://api.github.com/users/bombs-kim/events{/privacy}","received_events_url":"https://api.github.com/users/bombs-kim/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2019-04-18T14:37:08Z","updated_at":"2019-04-18T14:42:19Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"According to the original paper\r\n1. (In architecture search) we always use batch-specific statistics for batch normalization rather than the global moving average.\r\n2. Learnable affine parameters in all batch normalizations are disabled during the search process\r\n\r\nThe second statement holds true in this implementation, but I couldn't find related code for the first statement. According to my observation, all batch normalizations use global moving average.\r\nFor example, one batch norm layer has this form,\r\n```BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False)```\r\n\r\nI think momentum (or decay in fact) should be set to 1 in the above to be consistent with the paper.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/quark0/darts/issues/85/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/quark0/darts/issues/85/timeline","performed_via_github_app":null,"state_reason":null}