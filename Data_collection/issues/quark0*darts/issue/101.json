{"url":"https://api.github.com/repos/quark0/darts/issues/101","repository_url":"https://api.github.com/repos/quark0/darts","labels_url":"https://api.github.com/repos/quark0/darts/issues/101/labels{/name}","comments_url":"https://api.github.com/repos/quark0/darts/issues/101/comments","events_url":"https://api.github.com/repos/quark0/darts/issues/101/events","html_url":"https://github.com/quark0/darts/issues/101","id":469053988,"node_id":"MDU6SXNzdWU0NjkwNTM5ODg=","number":101,"title":"Doubt about the effectiveness of the method","user":{"login":"twangnh","id":18298163,"node_id":"MDQ6VXNlcjE4Mjk4MTYz","avatar_url":"https://avatars.githubusercontent.com/u/18298163?v=4","gravatar_id":"","url":"https://api.github.com/users/twangnh","html_url":"https://github.com/twangnh","followers_url":"https://api.github.com/users/twangnh/followers","following_url":"https://api.github.com/users/twangnh/following{/other_user}","gists_url":"https://api.github.com/users/twangnh/gists{/gist_id}","starred_url":"https://api.github.com/users/twangnh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/twangnh/subscriptions","organizations_url":"https://api.github.com/users/twangnh/orgs","repos_url":"https://api.github.com/users/twangnh/repos","events_url":"https://api.github.com/users/twangnh/events{/privacy}","received_events_url":"https://api.github.com/users/twangnh/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":28,"created_at":"2019-07-17T08:22:42Z","updated_at":"2021-01-18T01:58:43Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi, thanks for sharing the work. We have performed a rigorous evaluation for the framework on the cifar-10 setting with this code base, for each setting we run the experiments independently 8 times and average the results(the accuracy of searched archs retrained on whole training set). \r\n![image](https://user-images.githubusercontent.com/18298163/61357955-dcdf3380-a8ab-11e9-8e8d-9fa65a834428.png)\r\n\r\n`first-order` is simple baseline of alternatively optimize weight parameters and architecture parameters, `lookahead` is to peform a step of fake weight update before calculating gradients of architecture parameters, `Random` is random baseline without search, the curve of `orig arch diff epochs` is the default method of second order with different epochs. `paper` is the reported results in the paper.\r\n\r\nHowever the confusion are, 1, simple alternating optimization of first order baseline gets similar results to second order with much smaller model size and it actually performs more than two times faster than second order method, however first order is theoretically too much deviated from the formulation of searching objective:  \r\n![image](https://user-images.githubusercontent.com/18298163/61359261-8f17fa80-a8ae-11e9-9088-305c75be3c24.png)\r\nSo maybe we are not even doing architecture search, but just eliminated some bad design choices that is easy to get rid of?\r\n2, increasing training epochs  leading to wrose results after some points, which is really counter-intuitive as searching longer should at least gets as good results as less epochs.\r\nCould you please give some advice on the issue? Thank you very much.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/quark0/darts/issues/101/reactions","total_count":13,"+1":6,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":5,"eyes":2},"timeline_url":"https://api.github.com/repos/quark0/darts/issues/101/timeline","performed_via_github_app":null,"state_reason":null}