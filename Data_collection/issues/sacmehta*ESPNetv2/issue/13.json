{"url":"https://api.github.com/repos/sacmehta/ESPNetv2/issues/13","repository_url":"https://api.github.com/repos/sacmehta/ESPNetv2","labels_url":"https://api.github.com/repos/sacmehta/ESPNetv2/issues/13/labels{/name}","comments_url":"https://api.github.com/repos/sacmehta/ESPNetv2/issues/13/comments","events_url":"https://api.github.com/repos/sacmehta/ESPNetv2/issues/13/events","html_url":"https://github.com/sacmehta/ESPNetv2/issues/13","id":412221340,"node_id":"MDU6SXNzdWU0MTIyMjEzNDA=","number":13,"title":"How to train own dataset?","user":{"login":"pentaris","id":20432143,"node_id":"MDQ6VXNlcjIwNDMyMTQz","avatar_url":"https://avatars.githubusercontent.com/u/20432143?v=4","gravatar_id":"","url":"https://api.github.com/users/pentaris","html_url":"https://github.com/pentaris","followers_url":"https://api.github.com/users/pentaris/followers","following_url":"https://api.github.com/users/pentaris/following{/other_user}","gists_url":"https://api.github.com/users/pentaris/gists{/gist_id}","starred_url":"https://api.github.com/users/pentaris/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pentaris/subscriptions","organizations_url":"https://api.github.com/users/pentaris/orgs","repos_url":"https://api.github.com/users/pentaris/repos","events_url":"https://api.github.com/users/pentaris/events{/privacy}","received_events_url":"https://api.github.com/users/pentaris/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2019-02-20T02:59:57Z","updated_at":"2019-03-28T21:02:29Z","closed_at":"2019-02-26T03:58:01Z","author_association":"NONE","active_lock_reason":null,"body":"Hello, I'm a student studying machine running.\r\n\r\nI found ESPNet v2 after looking for a network of real time semantic segmentation processing on TX2.\r\n\r\nI don't have the cityscapes dataset, so I want to do training with own dataset.\r\n\r\nI'm a beginner about machine running.\r\n\r\nCould you provide a tutorial that trains to own dataset?\r\n\r\n Thank you in advance.","closed_by":{"login":"pentaris","id":20432143,"node_id":"MDQ6VXNlcjIwNDMyMTQz","avatar_url":"https://avatars.githubusercontent.com/u/20432143?v=4","gravatar_id":"","url":"https://api.github.com/users/pentaris","html_url":"https://github.com/pentaris","followers_url":"https://api.github.com/users/pentaris/followers","following_url":"https://api.github.com/users/pentaris/following{/other_user}","gists_url":"https://api.github.com/users/pentaris/gists{/gist_id}","starred_url":"https://api.github.com/users/pentaris/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pentaris/subscriptions","organizations_url":"https://api.github.com/users/pentaris/orgs","repos_url":"https://api.github.com/users/pentaris/repos","events_url":"https://api.github.com/users/pentaris/events{/privacy}","received_events_url":"https://api.github.com/users/pentaris/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/sacmehta/ESPNetv2/issues/13/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/sacmehta/ESPNetv2/issues/13/timeline","performed_via_github_app":null,"state_reason":"completed"}