{"url":"https://api.github.com/repos/microsoft/human-pose-estimation.pytorch/issues/145","repository_url":"https://api.github.com/repos/microsoft/human-pose-estimation.pytorch","labels_url":"https://api.github.com/repos/microsoft/human-pose-estimation.pytorch/issues/145/labels{/name}","comments_url":"https://api.github.com/repos/microsoft/human-pose-estimation.pytorch/issues/145/comments","events_url":"https://api.github.com/repos/microsoft/human-pose-estimation.pytorch/issues/145/events","html_url":"https://github.com/microsoft/human-pose-estimation.pytorch/issues/145","id":623210016,"node_id":"MDU6SXNzdWU2MjMyMTAwMTY=","number":145,"title":"image input channels issue","user":{"login":"taeyeop-lee","id":50736858,"node_id":"MDQ6VXNlcjUwNzM2ODU4","avatar_url":"https://avatars.githubusercontent.com/u/50736858?v=4","gravatar_id":"","url":"https://api.github.com/users/taeyeop-lee","html_url":"https://github.com/taeyeop-lee","followers_url":"https://api.github.com/users/taeyeop-lee/followers","following_url":"https://api.github.com/users/taeyeop-lee/following{/other_user}","gists_url":"https://api.github.com/users/taeyeop-lee/gists{/gist_id}","starred_url":"https://api.github.com/users/taeyeop-lee/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/taeyeop-lee/subscriptions","organizations_url":"https://api.github.com/users/taeyeop-lee/orgs","repos_url":"https://api.github.com/users/taeyeop-lee/repos","events_url":"https://api.github.com/users/taeyeop-lee/events{/privacy}","received_events_url":"https://api.github.com/users/taeyeop-lee/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-05-22T13:35:39Z","updated_at":"2021-12-25T15:49:09Z","closed_at":"2020-05-25T05:56:27Z","author_association":"NONE","active_lock_reason":null,"body":"Can I ask why the input channel issue?? \r\n**RuntimeError: weight of size [64, 3, 7, 7], expected input[32, 256, 192, 3] to have 3 channels, but got 256 channels instead**\r\n\r\n```\r\n(simple) user@user:/sdata1/workspace/simple-pose$ python pose_estimation/train.py     --cfg experiments/coco/resnet50/256x192_d256x3_adam_lr1e-3.yaml\r\n/sdata1/workspace/simple-pose/pose_estimation/../lib/core/config.py:161: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\n  exp_config = edict(yaml.load(f))\r\n=> creating output/coco/pose_resnet_50/256x192_d256x3_adam_lr1e-3\r\n=> creating log/coco/pose_resnet_50/256x192_d256x3_adam_lr1e-3_2020-05-22-22-31\r\nNamespace(cfg='experiments/coco/resnet50/256x192_d256x3_adam_lr1e-3.yaml', frequent=100, gpus=None, workers=None)\r\n{'CUDNN': {'BENCHMARK': True, 'DETERMINISTIC': False, 'ENABLED': True},\r\n 'DATASET': {'DATASET': 'coco',\r\n             'DATA_FORMAT': 'jpg',\r\n             'FLIP': True,\r\n             'HYBRID_JOINTS_TYPE': '',\r\n             'ROOT': './data/coco/',\r\n             'ROT_FACTOR': 40,\r\n             'SCALE_FACTOR': 0.3,\r\n             'SELECT_DATA': False,\r\n             'TEST_SET': 'val2017',\r\n             'TRAIN_SET': 'train2017'},\r\n 'DATA_DIR': '',\r\n 'DEBUG': {'DEBUG': True,\r\n           'SAVE_BATCH_IMAGES_GT': True,\r\n           'SAVE_BATCH_IMAGES_PRED': True,\r\n           'SAVE_HEATMAPS_GT': True,\r\n           'SAVE_HEATMAPS_PRED': True},\r\n 'GPUS': '0',\r\n 'LOG_DIR': 'log',\r\n 'LOSS': {'USE_TARGET_WEIGHT': True},\r\n 'MODEL': {'EXTRA': {'DECONV_WITH_BIAS': False,\r\n                     'FINAL_CONV_KERNEL': 1,\r\n                     'HEATMAP_SIZE': array([48, 64]),\r\n                     'NUM_DECONV_FILTERS': [256, 256, 256],\r\n                     'NUM_DECONV_KERNELS': [4, 4, 4],\r\n                     'NUM_DECONV_LAYERS': 3,\r\n                     'NUM_LAYERS': 50,\r\n                     'SIGMA': 2,\r\n                     'TARGET_TYPE': 'gaussian'},\r\n           'IMAGE_SIZE': array([192, 256]),\r\n           'INIT_WEIGHTS': True,\r\n           'NAME': 'pose_resnet',\r\n           'NUM_JOINTS': 17,\r\n           'PRETRAINED': 'models/pytorch/imagenet/resnet50-19c8e357.pth',\r\n           'STYLE': 'pytorch'},\r\n 'OUTPUT_DIR': 'output',\r\n 'PRINT_FREQ': 100,\r\n 'TEST': {'BATCH_SIZE': 1,\r\n          'BBOX_THRE': 1.0,\r\n          'COCO_BBOX_FILE': 'data/coco/person_detection_results/COCO_val2017_detections_AP_H_56_person.json',\r\n          'FLIP_TEST': False,\r\n          'IMAGE_THRE': 0.0,\r\n          'IN_VIS_THRE': 0.2,\r\n          'MODEL_FILE': '',\r\n          'NMS_THRE': 1.0,\r\n          'OKS_THRE': 0.9,\r\n          'POST_PROCESS': True,\r\n          'SHIFT_HEATMAP': True,\r\n          'USE_GT_BBOX': True},\r\n 'TRAIN': {'BATCH_SIZE': 32,\r\n           'BEGIN_EPOCH': 0,\r\n           'CHECKPOINT': '',\r\n           'END_EPOCH': 140,\r\n           'GAMMA1': 0.99,\r\n           'GAMMA2': 0.0,\r\n           'LR': 0.001,\r\n           'LR_FACTOR': 0.1,\r\n           'LR_STEP': [90, 120],\r\n           'MOMENTUM': 0.9,\r\n           'NESTEROV': False,\r\n           'OPTIMIZER': 'adam',\r\n           'RESUME': False,\r\n           'SHUFFLE': True,\r\n           'WD': 0.0001},\r\n 'WORKERS': 4}\r\n=> init deconv weights from normal distribution\r\n=> init 0.weight as normal(0, 0.001)\r\n=> init 0.bias as 0\r\n=> init 1.weight as 1\r\n=> init 1.bias as 0\r\n=> init 3.weight as normal(0, 0.001)\r\n=> init 3.bias as 0\r\n=> init 4.weight as 1\r\n=> init 4.bias as 0\r\n=> init 6.weight as normal(0, 0.001)\r\n=> init 6.bias as 0\r\n=> init 7.weight as 1\r\n=> init 7.bias as 0\r\n=> init final conv weights from normal distribution\r\n=> init 8.weight as normal(0, 0.001)\r\n=> init 8.bias as 0\r\n=> loading pretrained model models/pytorch/imagenet/resnet50-19c8e357.pth\r\n/home/user/anaconda3/envs/simple/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\r\n  warnings.warn(warning.format(ret))\r\nloading annotations into memory...\r\nDone (t=7.44s)\r\ncreating index...\r\nindex created!\r\n=> classes: ['__background__', 'person']\r\n=> num_images: 118287\r\n=> load 149813 samples\r\nloading annotations into memory...\r\nDone (t=0.22s)\r\ncreating index...\r\nindex created!\r\n=> classes: ['__background__', 'person']\r\n=> num_images: 5000\r\n=> load 6352 samples\r\nTraceback (most recent call last):\r\n  File \"pose_estimation/train.py\", line 206, in <module>\r\n    main()\r\n  File \"pose_estimation/train.py\", line 174, in main\r\n    final_output_dir, tb_log_dir, writer_dict)\r\n  File \"/sdata1/workspace/simple-pose/pose_estimation/../lib/core/function.py\", line 45, in train\r\n    output = model(input)\r\n  File \"/home/user/anaconda3/envs/simple/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/user/anaconda3/envs/simple/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 121, in forward\r\n    return self.module(*inputs[0], **kwargs[0])\r\n  File \"/home/user/anaconda3/envs/simple/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/sdata1/workspace/simple-pose/pose_estimation/../lib/models/pose_resnet.py\", line 235, in forward\r\n    x = self.conv1(x)\r\n  File \"/home/user/anaconda3/envs/simple/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/user/anaconda3/envs/simple/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 301, in forward\r\n    self.padding, self.dilation, self.groups)\r\nRuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[32, 256, 192, 3] to have 3 channels, but got 256 channels instead\r\n```","closed_by":{"login":"taeyeop-lee","id":50736858,"node_id":"MDQ6VXNlcjUwNzM2ODU4","avatar_url":"https://avatars.githubusercontent.com/u/50736858?v=4","gravatar_id":"","url":"https://api.github.com/users/taeyeop-lee","html_url":"https://github.com/taeyeop-lee","followers_url":"https://api.github.com/users/taeyeop-lee/followers","following_url":"https://api.github.com/users/taeyeop-lee/following{/other_user}","gists_url":"https://api.github.com/users/taeyeop-lee/gists{/gist_id}","starred_url":"https://api.github.com/users/taeyeop-lee/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/taeyeop-lee/subscriptions","organizations_url":"https://api.github.com/users/taeyeop-lee/orgs","repos_url":"https://api.github.com/users/taeyeop-lee/repos","events_url":"https://api.github.com/users/taeyeop-lee/events{/privacy}","received_events_url":"https://api.github.com/users/taeyeop-lee/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/microsoft/human-pose-estimation.pytorch/issues/145/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/microsoft/human-pose-estimation.pytorch/issues/145/timeline","performed_via_github_app":null,"state_reason":"completed"}