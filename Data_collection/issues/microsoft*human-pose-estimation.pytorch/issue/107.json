{"url":"https://api.github.com/repos/microsoft/human-pose-estimation.pytorch/issues/107","repository_url":"https://api.github.com/repos/microsoft/human-pose-estimation.pytorch","labels_url":"https://api.github.com/repos/microsoft/human-pose-estimation.pytorch/issues/107/labels{/name}","comments_url":"https://api.github.com/repos/microsoft/human-pose-estimation.pytorch/issues/107/comments","events_url":"https://api.github.com/repos/microsoft/human-pose-estimation.pytorch/issues/107/events","html_url":"https://github.com/microsoft/human-pose-estimation.pytorch/issues/107","id":431853902,"node_id":"MDU6SXNzdWU0MzE4NTM5MDI=","number":107,"title":"out of memory when train and valid","user":{"login":"YuZijian","id":17141809,"node_id":"MDQ6VXNlcjE3MTQxODA5","avatar_url":"https://avatars.githubusercontent.com/u/17141809?v=4","gravatar_id":"","url":"https://api.github.com/users/YuZijian","html_url":"https://github.com/YuZijian","followers_url":"https://api.github.com/users/YuZijian/followers","following_url":"https://api.github.com/users/YuZijian/following{/other_user}","gists_url":"https://api.github.com/users/YuZijian/gists{/gist_id}","starred_url":"https://api.github.com/users/YuZijian/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/YuZijian/subscriptions","organizations_url":"https://api.github.com/users/YuZijian/orgs","repos_url":"https://api.github.com/users/YuZijian/repos","events_url":"https://api.github.com/users/YuZijian/events{/privacy}","received_events_url":"https://api.github.com/users/YuZijian/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2019-04-11T06:38:50Z","updated_at":"2019-04-11T08:09:44Z","closed_at":"2019-04-11T08:09:44Z","author_association":"NONE","active_lock_reason":null,"body":"I meet OOM problem both train and valid,  I decrease the batch size but it still happen, the problems seems happen when load pretrained models.  the log of valid mpii dataset with resnet50 model is below. I can't find where the problem is.\r\n\r\n=> creating output/mpii/pose_resnet_50/256x256_d256x3_adam_lr1e-3\r\n=> creating log/mpii/pose_resnet_50/256x256_d256x3_adam_lr1e-3_2019-04-11-14-26\r\nNamespace(cfg='experiments/mpii/resnet50/256x256_d256x3_adam_lr1e-3.yaml', coco_                                                                                                             bbox_file=None, flip_test=True, frequent=100, gpus=None, model_file='models/pyto                                                                                                             rch/pose_mpii/pose_resnet_50_256x256.pth.tar', post_process=False, shift_heatmap                                                                                                             =False, use_detect_bbox=False, workers=None)\r\n{'CUDNN': {'BENCHMARK': True, 'DETERMINISTIC': False, 'ENABLED': True},\r\n 'DATASET': {'DATASET': 'mpii',\r\n             'DATA_FORMAT': 'jpg',\r\n             'FLIP': True,\r\n             'HYBRID_JOINTS_TYPE': '',\r\n             'ROOT': 'data/mpii/',\r\n             'ROT_FACTOR': 30,\r\n             'SCALE_FACTOR': 0.25,\r\n             'SELECT_DATA': False,\r\n             'TEST_SET': 'valid',\r\n             'TRAIN_SET': 'train'},\r\n 'DATA_DIR': '',\r\n 'DEBUG': {'DEBUG': False,\r\n           'SAVE_BATCH_IMAGES_GT': True,\r\n           'SAVE_BATCH_IMAGES_PRED': True,\r\n           'SAVE_HEATMAPS_GT': True,\r\n           'SAVE_HEATMAPS_PRED': True},\r\n 'GPUS': '8',\r\n 'LOG_DIR': 'log',\r\n 'LOSS': {'USE_TARGET_WEIGHT': True},\r\n 'MODEL': {'EXTRA': {'DECONV_WITH_BIAS': False,\r\n                     'FINAL_CONV_KERNEL': 1,\r\n                     'HEATMAP_SIZE': array([64, 64]),\r\n                     'NUM_DECONV_FILTERS': [256, 256, 256],\r\n                     'NUM_DECONV_KERNELS': [4, 4, 4],\r\n                     'NUM_DECONV_LAYERS': 3,\r\n                     'NUM_LAYERS': 50,\r\n                     'SIGMA': 2,\r\n                     'TARGET_TYPE': 'gaussian'},\r\n           'IMAGE_SIZE': array([256, 256]),\r\n           'INIT_WEIGHTS': True,\r\n           'NAME': 'pose_resnet',\r\n           'NUM_JOINTS': 16,\r\n           'PRETRAINED': 'models/pytorch/imagenet/resnet50-19c8e357.pth',\r\n           'STYLE': 'pytorch'},\r\n 'OUTPUT_DIR': 'output',\r\n 'PRINT_FREQ': 100,\r\n 'TEST': {'BATCH_SIZE': 32,\r\n          'BBOX_THRE': 1.0,\r\n          'COCO_BBOX_FILE': '',\r\n          'FLIP_TEST': True,\r\n          'IMAGE_THRE': 0.0,\r\n          'IN_VIS_THRE': 0.0,\r\n          'MODEL_FILE': 'models/pytorch/pose_mpii/pose_resnet_50_256x256.pth.tar                                                                                                             ',\r\n          'NMS_THRE': 1.0,\r\n          'OKS_THRE': 0.5,\r\n          'POST_PROCESS': True,\r\n          'SHIFT_HEATMAP': True,\r\n          'USE_GT_BBOX': False},\r\n 'TRAIN': {'BATCH_SIZE': 32,\r\n           'BEGIN_EPOCH': 0,\r\n           'CHECKPOINT': '',\r\n           'END_EPOCH': 140,\r\n           'GAMMA1': 0.99,\r\n           'GAMMA2': 0.0,\r\n           'LR': 0.001,\r\n           'LR_FACTOR': 0.1,\r\n           'LR_STEP': [90, 120],\r\n           'MOMENTUM': 0.9,\r\n           'NESTEROV': False,\r\n           'OPTIMIZER': 'adam',\r\n           'RESUME': False,\r\n           'SHUFFLE': True,\r\n           'WD': 0.0001},\r\n 'WORKERS': 4}\r\n=> loading model from models/pytorch/pose_mpii/pose_resnet_50_256x256.pth.tar\r\nTraceback (most recent call last):\r\n  File \"pose_estimation/valid.py\", line 165, in <module>\r\n    main()\r\n  File \"pose_estimation/valid.py\", line 123, in main\r\n    model.load_state_dict(torch.load(config.TEST.MODEL_FILE))\r\n  File \"/home1/yuzijian19/voice/lib/python3.6/site-packages/torch/serialization.py\", line 367, in load\r\n    return _load(f, map_location, pickle_module)\r\n  File \"/home1/yuzijian19/voice/lib/python3.6/site-packages/torch/serialization.py\", line 538, in _load\r\n    result = unpickler.load()\r\n  File \"/home1/yuzijian19/voice/lib/python3.6/site-packages/torch/serialization.py\", line 504, in persistent_load\r\n    data_type(size), location)\r\n  File \"/home1/yuzijian19/voice/lib/python3.6/site-packages/torch/serialization.py\", line 113, in default_restore_location\r\n    result = fn(storage, location)\r\n  File \"/home1/yuzijian19/voice/lib/python3.6/site-packages/torch/serialization.py\", line 95, in _cuda_deserialize\r\n    return obj.cuda(device)\r\n  File \"/home1/yuzijian19/voice/lib/python3.6/site-packages/torch/_utils.py\", line 76, in _cuda\r\n    return new_type(self.size()).copy_(self, non_blocking)\r\n  File \"/home1/yuzijian19/voice/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 496, in _lazy_new\r\n    return super(_CudaBase, cls).__new__(cls, *args, **kwargs)\r\nRuntimeError: CUDA error: out of memory","closed_by":{"login":"leoxiaobin","id":5362509,"node_id":"MDQ6VXNlcjUzNjI1MDk=","avatar_url":"https://avatars.githubusercontent.com/u/5362509?v=4","gravatar_id":"","url":"https://api.github.com/users/leoxiaobin","html_url":"https://github.com/leoxiaobin","followers_url":"https://api.github.com/users/leoxiaobin/followers","following_url":"https://api.github.com/users/leoxiaobin/following{/other_user}","gists_url":"https://api.github.com/users/leoxiaobin/gists{/gist_id}","starred_url":"https://api.github.com/users/leoxiaobin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/leoxiaobin/subscriptions","organizations_url":"https://api.github.com/users/leoxiaobin/orgs","repos_url":"https://api.github.com/users/leoxiaobin/repos","events_url":"https://api.github.com/users/leoxiaobin/events{/privacy}","received_events_url":"https://api.github.com/users/leoxiaobin/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/microsoft/human-pose-estimation.pytorch/issues/107/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/microsoft/human-pose-estimation.pytorch/issues/107/timeline","performed_via_github_app":null,"state_reason":"completed"}