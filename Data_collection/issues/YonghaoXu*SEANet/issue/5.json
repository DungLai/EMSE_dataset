{"url":"https://api.github.com/repos/YonghaoXu/SEANet/issues/5","repository_url":"https://api.github.com/repos/YonghaoXu/SEANet","labels_url":"https://api.github.com/repos/YonghaoXu/SEANet/issues/5/labels{/name}","comments_url":"https://api.github.com/repos/YonghaoXu/SEANet/issues/5/comments","events_url":"https://api.github.com/repos/YonghaoXu/SEANet/issues/5/events","html_url":"https://github.com/YonghaoXu/SEANet/issues/5","id":720062296,"node_id":"MDU6SXNzdWU3MjAwNjIyOTY=","number":5,"title":"the attention mechanism","user":{"login":"Lufei-github","id":47933628,"node_id":"MDQ6VXNlcjQ3OTMzNjI4","avatar_url":"https://avatars.githubusercontent.com/u/47933628?v=4","gravatar_id":"","url":"https://api.github.com/users/Lufei-github","html_url":"https://github.com/Lufei-github","followers_url":"https://api.github.com/users/Lufei-github/followers","following_url":"https://api.github.com/users/Lufei-github/following{/other_user}","gists_url":"https://api.github.com/users/Lufei-github/gists{/gist_id}","starred_url":"https://api.github.com/users/Lufei-github/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Lufei-github/subscriptions","organizations_url":"https://api.github.com/users/Lufei-github/orgs","repos_url":"https://api.github.com/users/Lufei-github/repos","events_url":"https://api.github.com/users/Lufei-github/events{/privacy}","received_events_url":"https://api.github.com/users/Lufei-github/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-10-13T09:44:24Z","updated_at":"2020-10-14T03:19:43Z","closed_at":"2020-10-14T03:19:43Z","author_association":"NONE","active_lock_reason":null,"body":"You says \"different regions in the images usually correspond to different levels of domain gap\",I agree with you definitely!\r\n\r\nThen you says \"we introduce the attention mechanism into the proposed framework to generate attention-aware features\".\r\n\r\nAfter reading your paper and the code. I know you design an attention module in the segmentation network, and you use avgpool, UpsamplingBilinear2d, interpolation, aconv, sigmoid to build this module and get a mask, if the mask bigger than threshold 0.3(for example),then got 1,otherwise got 0.Then you obtain a M, You multiply M and consistency loss to selectively calculate the consistency loss.\r\n\r\nBut now I have a small question about the attention module. Why mask bigger than 0.3, then we focus on this pixel, and smaller than 0.3, then we ignore this pixel? Why your attention module can focus larger levels of domain gap and ignore smaller levels of domain gap? How do you make sure M can filter out the insignificant pixelï¼Ÿ","closed_by":{"login":"Lufei-github","id":47933628,"node_id":"MDQ6VXNlcjQ3OTMzNjI4","avatar_url":"https://avatars.githubusercontent.com/u/47933628?v=4","gravatar_id":"","url":"https://api.github.com/users/Lufei-github","html_url":"https://github.com/Lufei-github","followers_url":"https://api.github.com/users/Lufei-github/followers","following_url":"https://api.github.com/users/Lufei-github/following{/other_user}","gists_url":"https://api.github.com/users/Lufei-github/gists{/gist_id}","starred_url":"https://api.github.com/users/Lufei-github/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Lufei-github/subscriptions","organizations_url":"https://api.github.com/users/Lufei-github/orgs","repos_url":"https://api.github.com/users/Lufei-github/repos","events_url":"https://api.github.com/users/Lufei-github/events{/privacy}","received_events_url":"https://api.github.com/users/Lufei-github/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/YonghaoXu/SEANet/issues/5/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/YonghaoXu/SEANet/issues/5/timeline","performed_via_github_app":null,"state_reason":"completed"}