{"url":"https://api.github.com/repos/netrack/keras-metrics/issues/44","repository_url":"https://api.github.com/repos/netrack/keras-metrics","labels_url":"https://api.github.com/repos/netrack/keras-metrics/issues/44/labels{/name}","comments_url":"https://api.github.com/repos/netrack/keras-metrics/issues/44/comments","events_url":"https://api.github.com/repos/netrack/keras-metrics/issues/44/events","html_url":"https://github.com/netrack/keras-metrics/issues/44","id":487262578,"node_id":"MDU6SXNzdWU0ODcyNjI1Nzg=","number":44,"title":"Non-Sensical Print Values For Metrics","user":{"login":"onurdanaci","id":51238902,"node_id":"MDQ6VXNlcjUxMjM4OTAy","avatar_url":"https://avatars.githubusercontent.com/u/51238902?v=4","gravatar_id":"","url":"https://api.github.com/users/onurdanaci","html_url":"https://github.com/onurdanaci","followers_url":"https://api.github.com/users/onurdanaci/followers","following_url":"https://api.github.com/users/onurdanaci/following{/other_user}","gists_url":"https://api.github.com/users/onurdanaci/gists{/gist_id}","starred_url":"https://api.github.com/users/onurdanaci/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/onurdanaci/subscriptions","organizations_url":"https://api.github.com/users/onurdanaci/orgs","repos_url":"https://api.github.com/users/onurdanaci/repos","events_url":"https://api.github.com/users/onurdanaci/events{/privacy}","received_events_url":"https://api.github.com/users/onurdanaci/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2019-08-30T03:05:27Z","updated_at":"2019-09-02T08:57:24Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\nWhile training a binary classifier with binary_crossentropy output layer, and binary labels in Keras (TF - GPU backend) using your keras_metrics package, I've been getting lots of f1-score values printed as: 0.0000e+00\r\n\r\nIt wasn't making any sense as I was seeing a drop in loss, and an increase in accuracy (either/both for train/val). I decided to dig it up, and started printing everything available in keras_metrics.\r\n\r\nRealized I am getting all the metrics from keras_metrics printed as 0.0000e+00 !\r\n\r\nI get true positive, true negatives, false positives, false negatives, precision, recall, f1-score (each is binary like binary_recall etc), all of them printed as 0.0000e+00.\r\n\r\nThere must either be a bug, or a catastrophic division or something propagating.\r\n\r\nI have the following module versions:\r\n\r\nsklearn '0.21.3'\r\ntensorflow gpu '0.21.3'\r\nkeras '2.2.4'\r\nnumpy '1.16.4'\r\nscipy '1.3.1'\r\npandas '0.25.0'\r\nkeras_metrics '1.1.0'\r\n\r\nDo you know what may be the issue? It stopped my progress big time, before I even realize.\r\n\r\nBest,\r\nOnur\r\n\r\n\r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/netrack/keras-metrics/issues/44/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/netrack/keras-metrics/issues/44/timeline","performed_via_github_app":null,"state_reason":null}