{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/695","repository_url":"https://api.github.com/repos/PaddlePaddle/ERNIE","labels_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/695/labels{/name}","comments_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/695/comments","events_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/695/events","html_url":"https://github.com/PaddlePaddle/ERNIE/issues/695","id":916036120,"node_id":"MDU6SXNzdWU5MTYwMzYxMjA=","number":695,"title":"ernie-gen SQuAD finetuning error","user":{"login":"cberrioa","id":57407760,"node_id":"MDQ6VXNlcjU3NDA3NzYw","avatar_url":"https://avatars.githubusercontent.com/u/57407760?v=4","gravatar_id":"","url":"https://api.github.com/users/cberrioa","html_url":"https://github.com/cberrioa","followers_url":"https://api.github.com/users/cberrioa/followers","following_url":"https://api.github.com/users/cberrioa/following{/other_user}","gists_url":"https://api.github.com/users/cberrioa/gists{/gist_id}","starred_url":"https://api.github.com/users/cberrioa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cberrioa/subscriptions","organizations_url":"https://api.github.com/users/cberrioa/orgs","repos_url":"https://api.github.com/users/cberrioa/repos","events_url":"https://api.github.com/users/cberrioa/events{/privacy}","received_events_url":"https://api.github.com/users/cberrioa/received_events","type":"User","site_admin":false},"labels":[{"id":1256169225,"node_id":"MDU6TGFiZWwxMjU2MTY5MjI1","url":"https://api.github.com/repos/PaddlePaddle/ERNIE/labels/wontfix","name":"wontfix","color":"ffffff","default":true,"description":"This will not be worked on"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-06-09T10:17:34Z","updated_at":"2021-10-20T02:27:27Z","closed_at":"2021-10-20T02:27:27Z","author_association":"NONE","active_lock_reason":null,"body":"Hi, I'm having some problems while trying to finetune ernie-gen on SQuAD. Here are the logs:\r\n\r\n```\r\n-----------  Configuration Arguments -----------\r\nattention_probs_dropout_prob: -1.0\r\nbatch_size: 1\r\nbeam_size: 1\r\ncheckpoints: ./checkpoints\r\ncontinuous_position: True\r\ndecr_every_n_nan_or_inf: 2\r\ndecr_ratio: 0.8\r\ndev_set: ./datasets/squad_qg//dev.tsv\r\ndo_decode: True\r\ndo_lower_case: True\r\ndo_pred: False\r\ndo_test: False\r\ndo_train: True\r\ndo_val: False\r\nepoch: 10\r\nernie_config_path: ernie_gen_base/ernie_config.json\r\neval_mertrics: Bleu_4,METEOR,ROUGE_L\r\neval_script: bash ./eval/tasks/squad_qg/eval.sh\r\nhidden_dropout_prob: 0.1\r\nin_tokens: False\r\nincr_every_n_steps: 100\r\nincr_ratio: 2.0\r\ninit_checkpoint: None\r\ninit_loss_scaling: 128.0\r\ninit_pretraining_params: ernie_gen_base/params\r\nis_distributed: True\r\nlabel_smooth: 0.1\r\nlearning_rate: 2.5e-05\r\nlength_penalty: 1.0\r\nlr_scheduler: linear_warmup_decay\r\nmax_dec_len: 48\r\nmax_seq_len: 400\r\nmax_dec_len: 48\r\nmax_seq_len: 400\r\nmax_src_len: 400\r\nmax_tgt_len: 96\r\nnoise_prob: 0.7\r\nnum_iteration_per_drop_scope: 1\r\npred_batch_size: 0\r\npred_set: ./datasets/squad_qg//pred.tsv\r\nrandom_noise: True\r\nrandom_seed: 93001\r\nrole_type_size: 0\r\nsave_and_valid_by_epoch: True\r\nsave_steps: 10000\r\nskip_steps: 10\r\nsrc_do_lower_case: True\r\nsrc_tokenizer: FullTokenizer\r\nsrc_vocab_path: None\r\nstream_job: None\r\ntask_type: normal\r\ntest_set: ./datasets/squad_qg//test.tsv\r\ntgt_type_id: 3\r\ntokenized_input: True\r\ntokenizer: FullTokenizer\r\ntrain_set: ./datasets/squad_qg//train.tsv\r\nturn_type_size: 0\r\nuse_cuda: True\r\nuse_dynamic_loss_scaling: False\r\nuse_fast_executor: True\r\nuse_fp16: False\r\nuse_multi_gpu_test: True\r\nvalidation_steps: 1000\r\nverbose: True\r\nvocab_path: ernie_gen_base/vocab.txt\r\nwarmup_proportion: 0.1\r\nweight_decay: 0.01\r\nweight_sharing: True\r\n------------------------------------------------\r\nattention_probs_dropout_prob: 0.1\r\nhidden_act: gelu\r\nhidden_dropout_prob: 0.1\r\nhidden_size: 768\r\ninitializer_range: 0.02\r\nintermediate_size: 3072\r\nmax_position_embeddings: 1024\r\nnum_attention_heads: 12\r\nnum_hidden_layers: 12\r\ntype_vocab_size: 4\r\nvocab_size: 30522\r\n------------------------------------------------\r\nDevice count: 1, gpu_id: 0\r\nNum train examples: 75722\r\nMax train steps: 757220\r\nNum warmup steps: 75722\r\nTheoretical memory usage in training: 10074.366 - 10554.098 MB\r\nargs.is_distributed: True\r\nworker_endpoints:['172.16.173.123:6170'] trainers_num:1 current_endpoint:172.16.173.123:6170               trainer_id:0\r\n\r\n\r\nAPI is deprecated since 2.0.0 Please use FleetAPI instead.\r\nWIKI: https://github.com/PaddlePaddle/Fleet/blob/develop/markdown_doc/transpiler\r\n\r\n\r\n\r\n\r\nW0609 12:27:54.821136 19909 device_context.cc:237] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 11.3, Runtime API Version: 10.0\r\nW0609 12:27:54.823410 19909 device_context.cc:245] device: 0, cuDNN Version: 7.6.\r\nI0609 12:27:55.246949 19909 rpc_client.h:107] init rpc client with trainer_id 0\r\nLoad pretraining parameters from ernie_gen_base/params.\r\nI0609 12:27:56.123220 19909 parallel_executor.cc:440] The Program will be executed on CUDA using ParallelExecutor, 1 cards are used, so 1 programs are executed in parallel.\r\nI0609 12:27:56.197180 19909 build_strategy.cc:365] SeqOnlyAllReduceOps:0, num_trainers:1\r\nI0609 12:27:56.563462 19909 parallel_executor.cc:307] Inplace strategy is enabled, when build_strategy.enable_inplace = True\r\nI0609 12:27:56.644340 19909 parallel_executor.cc:375] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 1\r\n/home/test/anaconda3/lib/python3.6/site-packages/paddle/fluid/executor.py:789: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"./run_seq2seq.py\", line 313, in <module>\r\n    main(args)\r\n  File \"./run_seq2seq.py\", line 264, in main\r\n    train_exe.run(fetch_list=[])\r\n  File \"/home/test/anaconda3/lib/python3.6/site-packages/paddle/fluid/parallel_executor.py\", line 302, in run\r\n    return_numpy=return_numpy)\r\n  File \"/home/test/anaconda3/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 790, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/test/anaconda3/lib/python3.6/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/home/test/anaconda3/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 785, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/test/anaconda3/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 850, in _run_impl\r\n    return_numpy=return_numpy)\r\n  File \"/home/test/anaconda3/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 684, in _run_parallel\r\n    tensors = exe.run(fetch_var_names)._move_to_list()\r\npaddle.fluid.core_avx.EnforceNotMet:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::framework::Tensor::mutable_data(paddle::platform::Place const&, paddle::framework::proto::VarType_Type, unsigned long)\r\n3   paddle::operators::ElementwiseAddKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n4   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::ElementwiseAddKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::ElementwiseAddKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::ElementwiseAddKernel<paddle::platform::CUDADeviceContext, int>, paddle::operators::ElementwiseAddKernel<paddle::platform::CUDADeviceContext, long>, paddle::operators::ElementwiseAddKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n6   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n7   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n8   paddle::framework::details::ComputationOpHandle::RunImpl()\r\n9   paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*)\r\n10  paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp(paddle::framework::details::OpHandleBase*, std::shared_ptr<paddle::framework::BlockingQueue<unsigned long> > const&, unsigned long*)\r\n11  std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&)\r\n12  std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n13  ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/test/anaconda3/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/test/anaconda3/lib/python3.6/site-packages/paddle/fluid/layers/math_op_patch.py\", line 243, in __impl__\r\n    attrs={'axis': axis})\r\n  File \"/home/test/ERNIE/ernie-gen/model/ernie.py\", line 139, in _gen_input\r\n    emb_out = emb_out + emb if emb_out else emb\r\n  File \"/home/test/ERNIE/ernie-gen/model/ernie.py\", line 139, in _gen_input\r\n    emb_out = emb_out + emb if emb_out else emb\r\n  File \"/home/test/ERNIE/ernie-gen/model/ernie.py\", line 173, in encode\r\n    query_emb_out, n_head_query_attn_mask = self._gen_input(emb_ids[1], input_mask[1])\r\n  File \"/home/test/ERNIE/ernie-gen/model/ernie.py\", line 228, in _build_model\r\n    self._enc_out = self.encode(emb_ids, input_mask, gather_idx, remove_query=False)\r\n  File \"/home/test/ERNIE/ernie-gen/model/ernie.py\", line 128, in __init__\r\n    self._build_model(emb_ids, input_mask, gather_idx)\r\n  File \"/home/test/ERNIE/ernie-gen/finetune/seq2seq.py\", line 159, in create_model\r\n    task_type=self.task_type)\r\n  File \"./run_seq2seq.py\", line 125, in main\r\n    train_pyreader, graph_vars = ernie_gen.create_model()\r\n  File \"./run_seq2seq.py\", line 313, in <module>\r\n    main(args)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: When calling this method, the Tensor's numel must be equal or larger than zero. Please check Tensor::dims, or Tensor::Resize has been called first. The Tensor's shape is [-1, 12, 768] now\r\n  [Hint: Expected numel() >= 0, but received numel():-9216 < 0:0.] at (/paddle/paddle/fluid/framework/tensor.cc:45)\r\n  [operator < elementwise_add > error]\r\nterminate called without an active exception\r\nW0609 12:27:57.065218 19984 init.cc:209] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0609 12:27:57.065241 19984 init.cc:211] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\r\nW0609 12:27:57.065248 19984 init.cc:214] The detail failure signal is:\r\n\r\nW0609 12:27:57.065258 19984 init.cc:217] *** Aborted at 1623241677 (unix time) try \"date -d @1623241677\" if you are using GNU date ***\r\nW0609 12:27:57.067502 19984 init.cc:217] PC: @                0x0 (unknown)\r\nW0609 12:27:57.067590 19984 init.cc:217] *** SIGABRT (@0x3e800004dc5) received by PID 19909 (TID 0x7fc601ed4700) from PID 19909; stack trace: ***\r\nW0609 12:27:57.069734 19984 init.cc:217]     @     0x7fc73321f890 (unknown)\r\nW0609 12:27:57.071744 19984 init.cc:217]     @     0x7fc732e5ae97 gsignal\r\nW0609 12:27:57.073776 19984 init.cc:217]     @     0x7fc732e5c801 abort\r\nW0609 12:27:57.075096 19984 init.cc:217]     @     0x7fc709a82892 __gnu_cxx::__verbose_terminate_handler()\r\nW0609 12:27:57.076014 19984 init.cc:217]     @     0x7fc709a80f69 __cxxabiv1::__terminate()\r\nW0609 12:27:57.077248 19984 init.cc:217]     @     0x7fc709a80fab std::terminate()\r\nW0609 12:27:57.078239 19984 init.cc:217]     @     0x7fc709a80c7c __gxx_personality_v0\r\nW0609 12:27:57.079216 19984 init.cc:217]     @     0x7fc71957abc8 _Unwind_ForcedUnwind_Phase2\r\nW0609 12:27:57.080211 19984 init.cc:217]     @     0x7fc71957aeae _Unwind_ForcedUnwind\r\nW0609 12:27:57.081902 19984 init.cc:217]     @     0x7fc73321df10 __GI___pthread_unwind\r\nW0609 12:27:57.083508 19984 init.cc:217]     @     0x7fc733215ae5 __pthread_exit\r\nW0609 12:27:57.084079 19984 init.cc:217]     @     0x562d02a8fa09 PyThread_exit_thread\r\nW0609 12:27:57.084221 19984 init.cc:217]     @     0x562d02929d12 PyEval_RestoreThread.cold.739\r\nW0609 12:27:57.086426 19984 init.cc:217]     @     0x7fc6de79a889 pybind11::gil_scoped_release::~gil_scoped_release()\r\nW0609 12:27:57.086639 19984 init.cc:217]     @     0x7fc6de7470e4 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL22pybind11_init_core_avxERNS_6moduleEEUlRNS2_9operators6reader22LoDTensorBlockingQueueERKSt6vectorINS2_9framework9LoDTensorESaISC_EEE60_bIS9_SG_EINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNESY_\r\nW0609 12:27:57.088801 19984 init.cc:217]     @     0x7fc6de7b8c41 pybind11::cpp_function::dispatcher()\r\nW0609 12:27:57.089345 19984 init.cc:217]     @     0x562d029d8c54 _PyCFunction_FastCallDict\r\nW0609 12:27:57.089700 19984 init.cc:217]     @     0x562d02a60c0e call_function\r\nW0609 12:27:57.090265 19984 init.cc:217]     @     0x562d02a8375a _PyEval_EvalFrameDefault\r\nW0609 12:27:57.090816 19984 init.cc:217]     @     0x562d02a5bd58 PyEval_EvalCodeEx\r\nW0609 12:27:57.091143 19984 init.cc:217]     @     0x562d02a5c8e6 function_call\r\nW0609 12:27:57.091691 19984 init.cc:217]     @     0x562d029d8a5e PyObject_Call\r\nW0609 12:27:57.092248 19984 init.cc:217]     @     0x562d02a84e37 _PyEval_EvalFrameDefault\r\nW0609 12:27:57.092581 19984 init.cc:217]     @     0x562d02a5ac5b fast_function\r\nW0609 12:27:57.092916 19984 init.cc:217]     @     0x562d02a60b95 call_function\r\nW0609 12:27:57.093463 19984 init.cc:217]     @     0x562d02a8375a _PyEval_EvalFrameDefault\r\nW0609 12:27:57.093794 19984 init.cc:217]     @     0x562d02a5ac5b fast_function\r\nW0609 12:27:57.094127 19984 init.cc:217]     @     0x562d02a60b95 call_function\r\nW0609 12:27:57.094672 19984 init.cc:217]     @     0x562d02a8375a _PyEval_EvalFrameDefault\r\nW0609 12:27:57.095175 19984 init.cc:217]     @     0x562d02a5b2db _PyFunction_FastCallDict\r\nW0609 12:27:57.095664 19984 init.cc:217]     @     0x562d029d901f _PyObject_FastCallDict\r\nW0609 12:27:57.096171 19984 init.cc:217]     @     0x562d029ddaa3 _PyObject_Call_Prepend\r\nW0609 12:27:57.096171 19984 init.cc:217]     @     0x562d029ddaa3 _PyObject_Call_Prepend\r\n```\r\n\r\nI don't know what's going on, I've tried with different paddle versions (until version 2.0.2, version 2.1.0 give me some errors). At the begining I though that maybe it was some GPU memory problems (I only have one GPU with ~12GB), but I reduced the batch size to 1 and max_seq_len, max_src_len to 400, and now the theorical memory in usage in training is 10074.366 - 10554.098 MB. I've tried to predict with the pretrained ernie-gen, and it works, but, as it is supposed, the predictions are not fine. I appreciate your help.","closed_by":{"login":"stale[bot]","id":26384082,"node_id":"MDM6Qm90MjYzODQwODI=","avatar_url":"https://avatars.githubusercontent.com/in/1724?v=4","gravatar_id":"","url":"https://api.github.com/users/stale%5Bbot%5D","html_url":"https://github.com/apps/stale","followers_url":"https://api.github.com/users/stale%5Bbot%5D/followers","following_url":"https://api.github.com/users/stale%5Bbot%5D/following{/other_user}","gists_url":"https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}","starred_url":"https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stale%5Bbot%5D/subscriptions","organizations_url":"https://api.github.com/users/stale%5Bbot%5D/orgs","repos_url":"https://api.github.com/users/stale%5Bbot%5D/repos","events_url":"https://api.github.com/users/stale%5Bbot%5D/events{/privacy}","received_events_url":"https://api.github.com/users/stale%5Bbot%5D/received_events","type":"Bot","site_admin":false},"reactions":{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/695/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/695/timeline","performed_via_github_app":null,"state_reason":"completed"}