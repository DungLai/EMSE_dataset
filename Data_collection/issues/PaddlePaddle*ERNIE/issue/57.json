{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/57","repository_url":"https://api.github.com/repos/PaddlePaddle/ERNIE","labels_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/57/labels{/name}","comments_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/57/comments","events_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/57/events","html_url":"https://github.com/PaddlePaddle/ERNIE/issues/57","id":423610422,"node_id":"MDU6SXNzdWU0MjM2MTA0MjI=","number":57,"title":"能否给出一个preprocess 文件","user":{"login":"zhaolulul","id":40298785,"node_id":"MDQ6VXNlcjQwMjk4Nzg1","avatar_url":"https://avatars.githubusercontent.com/u/40298785?v=4","gravatar_id":"","url":"https://api.github.com/users/zhaolulul","html_url":"https://github.com/zhaolulul","followers_url":"https://api.github.com/users/zhaolulul/followers","following_url":"https://api.github.com/users/zhaolulul/following{/other_user}","gists_url":"https://api.github.com/users/zhaolulul/gists{/gist_id}","starred_url":"https://api.github.com/users/zhaolulul/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhaolulul/subscriptions","organizations_url":"https://api.github.com/users/zhaolulul/orgs","repos_url":"https://api.github.com/users/zhaolulul/repos","events_url":"https://api.github.com/users/zhaolulul/events{/privacy}","received_events_url":"https://api.github.com/users/zhaolulul/received_events","type":"User","site_admin":false},"labels":[{"id":1256169225,"node_id":"MDU6TGFiZWwxMjU2MTY5MjI1","url":"https://api.github.com/repos/PaddlePaddle/ERNIE/labels/wontfix","name":"wontfix","color":"ffffff","default":true,"description":"This will not be worked on"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2019-03-21T08:11:07Z","updated_at":"2020-05-28T13:52:36Z","closed_at":"2020-05-28T13:52:36Z","author_association":"NONE","active_lock_reason":null,"body":" 因为想试一下你们预训练的模型  我在处理我自己的数据过程中 不知道你们（ 利用百度内部词法分析工具对句对数据进行字、词、实体等不同粒度的切分，然后基于 tokenization.py 中的 CharTokenizer 对切分后的数据进行 token 化处理，得到明文的 token 序列及切分边界，）用的什么词法分析工具 是否方便公开 ","closed_by":{"login":"stale[bot]","id":26384082,"node_id":"MDM6Qm90MjYzODQwODI=","avatar_url":"https://avatars.githubusercontent.com/in/1724?v=4","gravatar_id":"","url":"https://api.github.com/users/stale%5Bbot%5D","html_url":"https://github.com/apps/stale","followers_url":"https://api.github.com/users/stale%5Bbot%5D/followers","following_url":"https://api.github.com/users/stale%5Bbot%5D/following{/other_user}","gists_url":"https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}","starred_url":"https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stale%5Bbot%5D/subscriptions","organizations_url":"https://api.github.com/users/stale%5Bbot%5D/orgs","repos_url":"https://api.github.com/users/stale%5Bbot%5D/repos","events_url":"https://api.github.com/users/stale%5Bbot%5D/events{/privacy}","received_events_url":"https://api.github.com/users/stale%5Bbot%5D/received_events","type":"Bot","site_admin":false},"reactions":{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/57/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/57/timeline","performed_via_github_app":null,"state_reason":"completed"}