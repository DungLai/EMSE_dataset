{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/54","repository_url":"https://api.github.com/repos/PaddlePaddle/ERNIE","labels_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/54/labels{/name}","comments_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/54/comments","events_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/54/events","html_url":"https://github.com/PaddlePaddle/ERNIE/issues/54","id":423601445,"node_id":"MDU6SXNzdWU0MjM2MDE0NDU=","number":54,"title":"16G显存，batch size = 2，fintune句子对分类，好像都会爆显存，这是为什么啊 ","user":{"login":"randomtutu","id":25904625,"node_id":"MDQ6VXNlcjI1OTA0NjI1","avatar_url":"https://avatars.githubusercontent.com/u/25904625?v=4","gravatar_id":"","url":"https://api.github.com/users/randomtutu","html_url":"https://github.com/randomtutu","followers_url":"https://api.github.com/users/randomtutu/followers","following_url":"https://api.github.com/users/randomtutu/following{/other_user}","gists_url":"https://api.github.com/users/randomtutu/gists{/gist_id}","starred_url":"https://api.github.com/users/randomtutu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/randomtutu/subscriptions","organizations_url":"https://api.github.com/users/randomtutu/orgs","repos_url":"https://api.github.com/users/randomtutu/repos","events_url":"https://api.github.com/users/randomtutu/events{/privacy}","received_events_url":"https://api.github.com/users/randomtutu/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2019-03-21T07:35:15Z","updated_at":"2019-03-21T13:21:57Z","closed_at":"2019-03-21T13:21:57Z","author_association":"NONE","active_lock_reason":null,"body":"-----------  Configuration Arguments -----------\r\nbatch_size: 2\r\ncheckpoints: ./checkpoints\r\ndev_set: /home/wb-wzft515778/LARK/ERNIE/data//lcqmc/test.tsv\r\ndo_lower_case: True\r\ndo_test: True\r\ndo_train: True\r\ndo_val: True\r\nepoch: 3\r\nernie_config_path: config/ernie_config.json\r\nin_tokens: False\r\ninit_checkpoint: None\r\ninit_pretraining_params: /home/wb-wzft515778/LARK/ERNIE/ckpt//params\r\nlabel_map_config: None\r\nlearning_rate: 2e-05\r\nloss_scaling: 1.0\r\nlr_scheduler: linear_warmup_decay\r\nmax_seq_len: 16\r\nmetrics: True\r\nnum_iteration_per_drop_scope: 1\r\nnum_labels: 2\r\nrandom_seed: 1\r\nsave_steps: 1000\r\nskip_steps: 10\r\ntest_set: /home/wb-wzft515778/LARK/ERNIE/data//lcqmc/test.tsv\r\ntrain_set: /home/wb-wzft515778/LARK/ERNIE/data//lcqmc/train.tsv\r\nuse_cuda: True\r\nuse_fast_executor: False\r\nuse_fp16: False\r\nvalidation_steps: 100\r\nverbose: True\r\nvocab_path: config/vocab.txt\r\nwarmup_proportion: 0.0\r\nweight_decay: 0.0\r\n------------------------------------------------\r\nattention_probs_dropout_prob: 0.1\r\nhidden_act: relu\r\nhidden_dropout_prob: 0.1\r\nhidden_size: 768\r\ninitializer_range: 0.02\r\nmax_position_embeddings: 513\r\nnum_attention_heads: 12\r\nnum_hidden_layers: 12\r\ntype_vocab_size: 2\r\nvocab_size: 18000\r\n------------------------------------------------\r\nDevice count: 1\r\nNum train examples: 102477\r\nMax train steps: 153715\r\nNum warmup steps: 0\r\nTheoretical memory usage in training: 2102.707 - 2202.836 MB\r\nW0321 17:00:02.179066 66953 device_context.cc:263] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 9.2, Runtime API Version: 9.0\r\nW0321 17:00:02.179129 66953 device_context.cc:271] device: 0, cuDNN Version: 7.0.\r\nTraceback (most recent call last):\r\n  File \"run_classifier.py\", line 283, in <module>\r\n    main(args)\r\n  File \"run_classifier.py\", line 141, in main\r\n    exe.run(startup_prog)\r\n  File \"/home/wb-wzft515778/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 525, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/wb-wzft515778/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 591, in _run\r\n    exe.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Invoke operator fill_constant error.\r\nPython Callstacks:\r\n  File \"/home/wb-wzft515778/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1382, in _prepend_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/wb-wzft515778/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/initializer.py\", line 167, in __call__\r\n    stop_gradient=True)\r\n  File \"/home/wb-wzft515778/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1198, in create_var\r\n    kwargs['initializer'](var, self)\r\n  File \"/home/wb-wzft515778/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/layer_helper.py\", line 402, in set_variable_initializer\r\n    initializer=initializer)\r\n  File \"/home/wb-wzft515778/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/layers/tensor.py\", line 137, in create_global_var\r\n    value=float(value), force_cpu=force_cpu))\r\n  File \"/home/wb-wzft515778/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/optimizer.py\", line 92, in _create_global_learning_rate\r\n    persistable=True)\r\n  File \"/home/wb-wzft515778/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/optimizer.py\", line 224, in _create_optimization_pass\r\n    self._create_global_learning_rate()\r\n  File \"/home/wb-wzft515778/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/optimizer.py\", line 350, in apply_gradients\r\n    optimize_ops = self._create_optimization_pass(params_grads)\r\n  File \"/home/wb-wzft515778/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/optimizer.py\", line 405, in minimize\r\n    optimize_ops = self.apply_gradients(params_grads)\r\n  File \"/home/wb-wzft515778/LARK/ERNIE/optimization.py\", line 127, in optimization\r\n    _, param_grads = optimizer.minimize(loss)\r\n  File \"run_classifier.py\", line 108, in main\r\n    loss_scaling=args.loss_scaling)\r\n  File \"run_classifier.py\", line 283, in <module>\r\n    main(args)\r\nC++ Callstacks:\r\nEnforce failed. Expected allocating <= available, but received allocating:14920696472 > available:14265745152.\r\nInsufficient GPU memory to allocation. at [/paddle/paddle/fluid/platform/gpu_info.cc:216]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f76e04d190dp void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 365\r\n1       0x7f76e04d1c57p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7f76e1f9baf8p paddle::platform::GpuMaxChunkSize() + 744\r\n3       0x7f76e1f922a9p\r\n4       0x7f779ab35bb9p\r\n5       0x7f76e1f91a7dp paddle::memory::legacy::GetGPUBuddyAllocator(int) + 109\r\n6       0x7f76e1f92767p void* paddle::memory::legacy::Alloc<paddle::platform::CUDAPlace>(paddle::platform::CUDAPlace const&, unsigned long) + 39\r\n7       0x7f76e1f92e35p paddle::memory::allocation::LegacyAllocator::AllocateImpl(unsigned long, paddle::memory::allocation::Allocator::Attr) + 389\r\n8       0x7f76e1f9513bp paddle::memory::allocation::Allocator::Allocate(unsigned long, paddle::memory::allocation::Allocator::Attr) + 27\r\n9       0x7f76e1f868e3p paddle::memory::allocation::AllocatorFacade::Alloc(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long, paddle::memory::allocation::Allocator::Attr) + 435\r\n10      0x7f76e1f86a01p paddle::memory::allocation::AllocatorFacade::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long, paddle::memory::allocation::Allocator::Attr) + 33\r\n11      0x7f76e1c48540p paddle::memory::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long, paddle::memory::allocation::Allocator::Attr) + 48\r\n12      0x7f76e1f43576p paddle::framework::Tensor::mutable_data(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, paddle::framework::proto::VarType_Type, paddle::memory::allocation::Allocator::Attr, unsigned long) + 150\r\n13      0x7f76e095fc01p paddle::operators::FillConstantKernel<float>::Compute(paddle::framework::ExecutionContext const&) const + 497\r\n14      0x7f76e0962c23p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::FillConstantKernel<float>, paddle::operators::FillConstantKernel<double>, paddle::operators::FillConstantKernel<long>, paddle::operators::FillConstantKernel<int>, paddle::operators::FillConstantKernel<paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n15      0x7f76e1ee5f23p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 659\r\n16      0x7f76e1ee3795p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 341\r\n17      0x7f76e05edf1ap paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 218\r\n18      0x7f76e05eff15p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 261\r\n19      0x7f76e04b5a7bp\r\n20      0x7f76e04fc79ep\r\n21      0x7f779b07e744p _PyCFunction_FastCallDict + 340\r\n22      0x7f779b10557ep\r\n23      0x7f779b12a38ap _PyEval_EvalFrameDefault + 778\r\n24      0x7f779b0fe8e4p\r\n25      0x7f779b0ff771p\r\n26      0x7f779b105505p\r\n27      0x7f779b12b147p _PyEval_EvalFrameDefault + 4295\r\n28      0x7f779b0fe8e4p\r\n29      0x7f779b0ff771p\r\n30      0x7f779b105505p\r\n31      0x7f779b12a38ap _PyEval_EvalFrameDefault + 778\r\n32      0x7f779b0ff53bp\r\n33      0x7f779b105505p\r\n34      0x7f779b12a38ap _PyEval_EvalFrameDefault + 778\r\n35      0x7f779b100289p PyEval_EvalCodeEx + 809\r\n36      0x7f779b10101cp PyEval_EvalCode + 28\r\n37      0x7f779b1833c4p\r\n38      0x7f779b1837c1p PyRun_FileExFlags + 161\r\n39      0x7f779b1839c3p PyRun_SimpleFileExFlags + 451\r\n40      0x7f779b1874b3p Py_Main + 1555\r\n41      0x7f779b05002ep main + 238\r\n42      0x7f779a781401p __libc_start_main + 241\r\n43      0x7f779b130e0ep\r\n","closed_by":{"login":"tianxin1860","id":6829601,"node_id":"MDQ6VXNlcjY4Mjk2MDE=","avatar_url":"https://avatars.githubusercontent.com/u/6829601?v=4","gravatar_id":"","url":"https://api.github.com/users/tianxin1860","html_url":"https://github.com/tianxin1860","followers_url":"https://api.github.com/users/tianxin1860/followers","following_url":"https://api.github.com/users/tianxin1860/following{/other_user}","gists_url":"https://api.github.com/users/tianxin1860/gists{/gist_id}","starred_url":"https://api.github.com/users/tianxin1860/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tianxin1860/subscriptions","organizations_url":"https://api.github.com/users/tianxin1860/orgs","repos_url":"https://api.github.com/users/tianxin1860/repos","events_url":"https://api.github.com/users/tianxin1860/events{/privacy}","received_events_url":"https://api.github.com/users/tianxin1860/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/54/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/54/timeline","performed_via_github_app":null,"state_reason":"completed"}