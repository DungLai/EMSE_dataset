[{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/comments/514880504","html_url":"https://github.com/PaddlePaddle/ERNIE/issues/224#issuecomment-514880504","issue_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/224","id":514880504,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDg4MDUwNA==","user":{"login":"tianxin1860","id":6829601,"node_id":"MDQ6VXNlcjY4Mjk2MDE=","avatar_url":"https://avatars.githubusercontent.com/u/6829601?v=4","gravatar_id":"","url":"https://api.github.com/users/tianxin1860","html_url":"https://github.com/tianxin1860","followers_url":"https://api.github.com/users/tianxin1860/followers","following_url":"https://api.github.com/users/tianxin1860/following{/other_user}","gists_url":"https://api.github.com/users/tianxin1860/gists{/gist_id}","starred_url":"https://api.github.com/users/tianxin1860/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tianxin1860/subscriptions","organizations_url":"https://api.github.com/users/tianxin1860/orgs","repos_url":"https://api.github.com/users/tianxin1860/repos","events_url":"https://api.github.com/users/tianxin1860/events{/privacy}","received_events_url":"https://api.github.com/users/tianxin1860/received_events","type":"User","site_admin":false},"created_at":"2019-07-25T03:26:31Z","updated_at":"2019-07-25T03:26:31Z","author_association":"COLLABORATOR","body":"> 在ERNIE自定义数据进行预训练中，首先要对数据作预处理，生成与demo数据一样的格式，README文件中说“然后基于 tokenization.py 中的 CharTokenizer 对切分后的数据进行 token 化处理，得到明文的 token 序列及切分边界”、“其中 seg_labels 表示分词边界信息: 0表示词首、1表示非词首、-1为占位符, 其对应的词为 CLS 或者 SEP”，请问这里的切分边界信息seg_labels怎么获取？在tokenization.py文件中没有找到相应的处理函数。\r\n\r\n根据分词后的结果提取 seg_labels 的逻辑比较容易实现，具体逻辑如 readme 所述:  `0表示词首、1表示非词首、-1为占位符, 其对应的词为 CLS 或者 SEP”`，相应代码逻辑可以自己添加；","reactions":{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/comments/514880504/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"tianxin1860","id":6829601,"node_id":"MDQ6VXNlcjY4Mjk2MDE=","avatar_url":"https://avatars.githubusercontent.com/u/6829601?v=4","gravatar_id":"","url":"https://api.github.com/users/tianxin1860","html_url":"https://github.com/tianxin1860","followers_url":"https://api.github.com/users/tianxin1860/followers","following_url":"https://api.github.com/users/tianxin1860/following{/other_user}","gists_url":"https://api.github.com/users/tianxin1860/gists{/gist_id}","starred_url":"https://api.github.com/users/tianxin1860/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tianxin1860/subscriptions","organizations_url":"https://api.github.com/users/tianxin1860/orgs","repos_url":"https://api.github.com/users/tianxin1860/repos","events_url":"https://api.github.com/users/tianxin1860/events{/privacy}","received_events_url":"https://api.github.com/users/tianxin1860/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/comments/514901015","html_url":"https://github.com/PaddlePaddle/ERNIE/issues/224#issuecomment-514901015","issue_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/224","id":514901015,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDkwMTAxNQ==","user":{"login":"Bodhi-Tree","id":18651447,"node_id":"MDQ6VXNlcjE4NjUxNDQ3","avatar_url":"https://avatars.githubusercontent.com/u/18651447?v=4","gravatar_id":"","url":"https://api.github.com/users/Bodhi-Tree","html_url":"https://github.com/Bodhi-Tree","followers_url":"https://api.github.com/users/Bodhi-Tree/followers","following_url":"https://api.github.com/users/Bodhi-Tree/following{/other_user}","gists_url":"https://api.github.com/users/Bodhi-Tree/gists{/gist_id}","starred_url":"https://api.github.com/users/Bodhi-Tree/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Bodhi-Tree/subscriptions","organizations_url":"https://api.github.com/users/Bodhi-Tree/orgs","repos_url":"https://api.github.com/users/Bodhi-Tree/repos","events_url":"https://api.github.com/users/Bodhi-Tree/events{/privacy}","received_events_url":"https://api.github.com/users/Bodhi-Tree/received_events","type":"User","site_admin":false},"created_at":"2019-07-25T05:23:41Z","updated_at":"2019-07-25T05:23:41Z","author_association":"NONE","body":"> > 在ERNIE自定义数据进行预训练中，首先要对数据作预处理，生成与demo数据一样的格式，README文件中说“然后基于 tokenization.py 中的 CharTokenizer 对切分后的数据进行 token 化处理，得到明文的 token 序列及切分边界”、“其中 seg_labels 表示分词边界信息: 0表示词首、1表示非词首、-1为占位符, 其对应的词为 CLS 或者 SEP”，请问这里的切分边界信息seg_labels怎么获取？在tokenization.py文件中没有找到相应的处理函数。\r\n> \r\n> 根据分词后的结果提取 seg_labels 的逻辑比较容易实现，具体逻辑如 readme 所述: `0表示词首、1表示非词首、-1为占位符, 其对应的词为 CLS 或者 SEP”`，相应代码逻辑可以自己添加；\r\n\r\n按我的理解，“北京是中国首都”这句话，通过BasicTokenizer处理后得到\"北京 是 中国 首都\"，然后通过WordpieceTokenizer处理得到“北 京 是 中 国 首 都”，那么“北”是词首0，“京”是非词首1，“是”是词首0，“中”是词首0，“国”是非词首1，“首”是词首0，“都”是非词首1，所以，其seg_labels就是[0 1 0 0 1 0 1]，是这样理解的么？","reactions":{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/comments/514901015/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"Bodhi-Tree","id":18651447,"node_id":"MDQ6VXNlcjE4NjUxNDQ3","avatar_url":"https://avatars.githubusercontent.com/u/18651447?v=4","gravatar_id":"","url":"https://api.github.com/users/Bodhi-Tree","html_url":"https://github.com/Bodhi-Tree","followers_url":"https://api.github.com/users/Bodhi-Tree/followers","following_url":"https://api.github.com/users/Bodhi-Tree/following{/other_user}","gists_url":"https://api.github.com/users/Bodhi-Tree/gists{/gist_id}","starred_url":"https://api.github.com/users/Bodhi-Tree/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Bodhi-Tree/subscriptions","organizations_url":"https://api.github.com/users/Bodhi-Tree/orgs","repos_url":"https://api.github.com/users/Bodhi-Tree/repos","events_url":"https://api.github.com/users/Bodhi-Tree/events{/privacy}","received_events_url":"https://api.github.com/users/Bodhi-Tree/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/comments/514917712","html_url":"https://github.com/PaddlePaddle/ERNIE/issues/224#issuecomment-514917712","issue_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/224","id":514917712,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDkxNzcxMg==","user":{"login":"tianxin1860","id":6829601,"node_id":"MDQ6VXNlcjY4Mjk2MDE=","avatar_url":"https://avatars.githubusercontent.com/u/6829601?v=4","gravatar_id":"","url":"https://api.github.com/users/tianxin1860","html_url":"https://github.com/tianxin1860","followers_url":"https://api.github.com/users/tianxin1860/followers","following_url":"https://api.github.com/users/tianxin1860/following{/other_user}","gists_url":"https://api.github.com/users/tianxin1860/gists{/gist_id}","starred_url":"https://api.github.com/users/tianxin1860/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tianxin1860/subscriptions","organizations_url":"https://api.github.com/users/tianxin1860/orgs","repos_url":"https://api.github.com/users/tianxin1860/repos","events_url":"https://api.github.com/users/tianxin1860/events{/privacy}","received_events_url":"https://api.github.com/users/tianxin1860/received_events","type":"User","site_admin":false},"created_at":"2019-07-25T06:39:37Z","updated_at":"2019-07-25T06:39:37Z","author_association":"COLLABORATOR","body":"> > > 在ERNIE自定义数据进行预训练中，首先要对数据作预处理，生成与demo数据一样的格式，README文件中说“然后基于 tokenization.py 中的 CharTokenizer 对切分后的数据进行 token 化处理，得到明文的 token 序列及切分边界”、“其中 seg_labels 表示分词边界信息: 0表示词首、1表示非词首、-1为占位符, 其对应的词为 CLS 或者 SEP”，请问这里的切分边界信息seg_labels怎么获取？在tokenization.py文件中没有找到相应的处理函数。\r\n> > \r\n> > \r\n> > 根据分词后的结果提取 seg_labels 的逻辑比较容易实现，具体逻辑如 readme 所述: `0表示词首、1表示非词首、-1为占位符, 其对应的词为 CLS 或者 SEP”`，相应代码逻辑可以自己添加；\r\n> \r\n> 按我的理解，“北京是中国首都”这句话，通过BasicTokenizer处理后得到\"北京 是 中国 首都\"，然后通过WordpieceTokenizer处理得到“北 京 是 中 国 首 都”，那么“北”是词首0，“京”是非词首1，“是”是词首0，“中”是词首0，“国”是非词首1，“首”是词首0，“都”是非词首1，所以，其seg_labels就是[0 1 0 0 1 0 1]，是这样理解的么？\r\n\r\n对 seg_labels 的理解是正确的，BasicTokenizer 和 WordpieceTokenizer 的处理逻辑建议看一下源码;","reactions":{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/comments/514917712/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"tianxin1860","id":6829601,"node_id":"MDQ6VXNlcjY4Mjk2MDE=","avatar_url":"https://avatars.githubusercontent.com/u/6829601?v=4","gravatar_id":"","url":"https://api.github.com/users/tianxin1860","html_url":"https://github.com/tianxin1860","followers_url":"https://api.github.com/users/tianxin1860/followers","following_url":"https://api.github.com/users/tianxin1860/following{/other_user}","gists_url":"https://api.github.com/users/tianxin1860/gists{/gist_id}","starred_url":"https://api.github.com/users/tianxin1860/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tianxin1860/subscriptions","organizations_url":"https://api.github.com/users/tianxin1860/orgs","repos_url":"https://api.github.com/users/tianxin1860/repos","events_url":"https://api.github.com/users/tianxin1860/events{/privacy}","received_events_url":"https://api.github.com/users/tianxin1860/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/comments/514932173","html_url":"https://github.com/PaddlePaddle/ERNIE/issues/224#issuecomment-514932173","issue_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/224","id":514932173,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDkzMjE3Mw==","user":{"login":"Bodhi-Tree","id":18651447,"node_id":"MDQ6VXNlcjE4NjUxNDQ3","avatar_url":"https://avatars.githubusercontent.com/u/18651447?v=4","gravatar_id":"","url":"https://api.github.com/users/Bodhi-Tree","html_url":"https://github.com/Bodhi-Tree","followers_url":"https://api.github.com/users/Bodhi-Tree/followers","following_url":"https://api.github.com/users/Bodhi-Tree/following{/other_user}","gists_url":"https://api.github.com/users/Bodhi-Tree/gists{/gist_id}","starred_url":"https://api.github.com/users/Bodhi-Tree/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Bodhi-Tree/subscriptions","organizations_url":"https://api.github.com/users/Bodhi-Tree/orgs","repos_url":"https://api.github.com/users/Bodhi-Tree/repos","events_url":"https://api.github.com/users/Bodhi-Tree/events{/privacy}","received_events_url":"https://api.github.com/users/Bodhi-Tree/received_events","type":"User","site_admin":false},"created_at":"2019-07-25T07:33:09Z","updated_at":"2019-07-25T07:33:09Z","author_association":"NONE","body":"> > > > 在ERNIE自定义数据进行预训练中，首先要对数据作预处理，生成与demo数据一样的格式，README文件中说“然后基于 tokenization.py 中的 CharTokenizer 对切分后的数据进行 token 化处理，得到明文的 token 序列及切分边界”、“其中 seg_labels 表示分词边界信息: 0表示词首、1表示非词首、-1为占位符, 其对应的词为 CLS 或者 SEP”，请问这里的切分边界信息seg_labels怎么获取？在tokenization.py文件中没有找到相应的处理函数。\r\n> > > \r\n> > > \r\n> > > 根据分词后的结果提取 seg_labels 的逻辑比较容易实现，具体逻辑如 readme 所述: `0表示词首、1表示非词首、-1为占位符, 其对应的词为 CLS 或者 SEP”`，相应代码逻辑可以自己添加；\r\n> > \r\n> > \r\n> > 按我的理解，“北京是中国首都”这句话，通过BasicTokenizer处理后得到\"北京 是 中国 首都\"，然后通过WordpieceTokenizer处理得到“北 京 是 中 国 首 都”，那么“北”是词首0，“京”是非词首1，“是”是词首0，“中”是词首0，“国”是非词首1，“首”是词首0，“都”是非词首1，所以，其seg_labels就是[0 1 0 0 1 0 1]，是这样理解的么？\r\n> \r\n> 对 seg_labels 的理解是正确的，BasicTokenizer 和 WordpieceTokenizer 的处理逻辑建议看一下源码;\r\n\r\n我看了一下，BasicTokenizer直接就把“北京是中国首都”这句话切成了“北 京 是 中 国 首 都”这样一个一个的字符，请问怎么先按词粒度切割呢，不然难以得到它的切分边界信息，有什么推荐的切词工具么？","reactions":{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/comments/514932173/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"Bodhi-Tree","id":18651447,"node_id":"MDQ6VXNlcjE4NjUxNDQ3","avatar_url":"https://avatars.githubusercontent.com/u/18651447?v=4","gravatar_id":"","url":"https://api.github.com/users/Bodhi-Tree","html_url":"https://github.com/Bodhi-Tree","followers_url":"https://api.github.com/users/Bodhi-Tree/followers","following_url":"https://api.github.com/users/Bodhi-Tree/following{/other_user}","gists_url":"https://api.github.com/users/Bodhi-Tree/gists{/gist_id}","starred_url":"https://api.github.com/users/Bodhi-Tree/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Bodhi-Tree/subscriptions","organizations_url":"https://api.github.com/users/Bodhi-Tree/orgs","repos_url":"https://api.github.com/users/Bodhi-Tree/repos","events_url":"https://api.github.com/users/Bodhi-Tree/events{/privacy}","received_events_url":"https://api.github.com/users/Bodhi-Tree/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/comments/514958734","html_url":"https://github.com/PaddlePaddle/ERNIE/issues/224#issuecomment-514958734","issue_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/224","id":514958734,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNDk1ODczNA==","user":{"login":"tianxin1860","id":6829601,"node_id":"MDQ6VXNlcjY4Mjk2MDE=","avatar_url":"https://avatars.githubusercontent.com/u/6829601?v=4","gravatar_id":"","url":"https://api.github.com/users/tianxin1860","html_url":"https://github.com/tianxin1860","followers_url":"https://api.github.com/users/tianxin1860/followers","following_url":"https://api.github.com/users/tianxin1860/following{/other_user}","gists_url":"https://api.github.com/users/tianxin1860/gists{/gist_id}","starred_url":"https://api.github.com/users/tianxin1860/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tianxin1860/subscriptions","organizations_url":"https://api.github.com/users/tianxin1860/orgs","repos_url":"https://api.github.com/users/tianxin1860/repos","events_url":"https://api.github.com/users/tianxin1860/events{/privacy}","received_events_url":"https://api.github.com/users/tianxin1860/received_events","type":"User","site_admin":false},"created_at":"2019-07-25T08:53:43Z","updated_at":"2019-07-25T08:53:43Z","author_association":"COLLABORATOR","body":"> > > > > 在ERNIE自定义数据进行预训练中，首先要对数据作预处理，生成与demo数据一样的格式，README文件中说“然后基于 tokenization.py 中的 CharTokenizer 对切分后的数据进行 token 化处理，得到明文的 token 序列及切分边界”、“其中 seg_labels 表示分词边界信息: 0表示词首、1表示非词首、-1为占位符, 其对应的词为 CLS 或者 SEP”，请问这里的切分边界信息seg_labels怎么获取？在tokenization.py文件中没有找到相应的处理函数。\r\n> > > > \r\n> > > > \r\n> > > > 根据分词后的结果提取 seg_labels 的逻辑比较容易实现，具体逻辑如 readme 所述: `0表示词首、1表示非词首、-1为占位符, 其对应的词为 CLS 或者 SEP”`，相应代码逻辑可以自己添加；\r\n> > > \r\n> > > \r\n> > > 按我的理解，“北京是中国首都”这句话，通过BasicTokenizer处理后得到\"北京 是 中国 首都\"，然后通过WordpieceTokenizer处理得到“北 京 是 中 国 首 都”，那么“北”是词首0，“京”是非词首1，“是”是词首0，“中”是词首0，“国”是非词首1，“首”是词首0，“都”是非词首1，所以，其seg_labels就是[0 1 0 0 1 0 1]，是这样理解的么？\r\n> > \r\n> > \r\n> > 对 seg_labels 的理解是正确的，BasicTokenizer 和 WordpieceTokenizer 的处理逻辑建议看一下源码;\r\n> \r\n> 我看了一下，BasicTokenizer直接就把“北京是中国首都”这句话切成了“北 京 是 中 国 首 都”这样一个一个的字符，请问怎么先按词粒度切割呢，不然难以得到它的切分边界信息，有什么推荐的切词工具么？\r\n\r\n我们基于百度内部分词工具做切分，分词工具涉及一些内部代码库依赖，没有开源;  可以使用开源工具 [LAC](https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/lexical_analysis) 切词;","reactions":{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/comments/514958734/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"tianxin1860","id":6829601,"node_id":"MDQ6VXNlcjY4Mjk2MDE=","avatar_url":"https://avatars.githubusercontent.com/u/6829601?v=4","gravatar_id":"","url":"https://api.github.com/users/tianxin1860","html_url":"https://github.com/tianxin1860","followers_url":"https://api.github.com/users/tianxin1860/followers","following_url":"https://api.github.com/users/tianxin1860/following{/other_user}","gists_url":"https://api.github.com/users/tianxin1860/gists{/gist_id}","starred_url":"https://api.github.com/users/tianxin1860/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tianxin1860/subscriptions","organizations_url":"https://api.github.com/users/tianxin1860/orgs","repos_url":"https://api.github.com/users/tianxin1860/repos","events_url":"https://api.github.com/users/tianxin1860/events{/privacy}","received_events_url":"https://api.github.com/users/tianxin1860/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/comments/599447303","html_url":"https://github.com/PaddlePaddle/ERNIE/issues/224#issuecomment-599447303","issue_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/224","id":599447303,"node_id":"MDEyOklzc3VlQ29tbWVudDU5OTQ0NzMwMw==","user":{"login":"jfkey","id":19853150,"node_id":"MDQ6VXNlcjE5ODUzMTUw","avatar_url":"https://avatars.githubusercontent.com/u/19853150?v=4","gravatar_id":"","url":"https://api.github.com/users/jfkey","html_url":"https://github.com/jfkey","followers_url":"https://api.github.com/users/jfkey/followers","following_url":"https://api.github.com/users/jfkey/following{/other_user}","gists_url":"https://api.github.com/users/jfkey/gists{/gist_id}","starred_url":"https://api.github.com/users/jfkey/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jfkey/subscriptions","organizations_url":"https://api.github.com/users/jfkey/orgs","repos_url":"https://api.github.com/users/jfkey/repos","events_url":"https://api.github.com/users/jfkey/events{/privacy}","received_events_url":"https://api.github.com/users/jfkey/received_events","type":"User","site_admin":false},"created_at":"2020-03-16T10:02:13Z","updated_at":"2020-03-16T10:02:13Z","author_association":"NONE","body":"> > 在ERNIE自定义数据进行预训练中，首先要对数据作预处理，生成与demo数据一样的格式，README文件中说“然后基于 tokenization.py 中的 CharTokenizer 对切分后的数据进行 token 化处理，得到明文的 token 序列及切分边界”、“其中 seg_labels 表示分词边界信息: 0表示词首、1表示非词首、-1为占位符, 其对应的词为 CLS 或者 SEP”，请问这里的切分边界信息seg_labels怎么获取？在tokenization.py文件中没有找到相应的处理函数。\r\n> \r\n> 根据分词后的结果提取 seg_labels 的逻辑比较容易实现，具体逻辑如 readme 所述: `0表示词首、1表示非词首、-1为占位符, 其对应的词为 CLS 或者 SEP”`，相应代码逻辑可以自己添加；\r\n\r\n 请问你们提到的seg_labels是什么？是sentence reordering task任务中的对segments进行排序的classes么？","reactions":{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/comments/599447303/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"jfkey","id":19853150,"node_id":"MDQ6VXNlcjE5ODUzMTUw","avatar_url":"https://avatars.githubusercontent.com/u/19853150?v=4","gravatar_id":"","url":"https://api.github.com/users/jfkey","html_url":"https://github.com/jfkey","followers_url":"https://api.github.com/users/jfkey/followers","following_url":"https://api.github.com/users/jfkey/following{/other_user}","gists_url":"https://api.github.com/users/jfkey/gists{/gist_id}","starred_url":"https://api.github.com/users/jfkey/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jfkey/subscriptions","organizations_url":"https://api.github.com/users/jfkey/orgs","repos_url":"https://api.github.com/users/jfkey/repos","events_url":"https://api.github.com/users/jfkey/events{/privacy}","received_events_url":"https://api.github.com/users/jfkey/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/comments/631980168","html_url":"https://github.com/PaddlePaddle/ERNIE/issues/224#issuecomment-631980168","issue_url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/224","id":631980168,"node_id":"MDEyOklzc3VlQ29tbWVudDYzMTk4MDE2OA==","user":{"login":"stale[bot]","id":26384082,"node_id":"MDM6Qm90MjYzODQwODI=","avatar_url":"https://avatars.githubusercontent.com/in/1724?v=4","gravatar_id":"","url":"https://api.github.com/users/stale%5Bbot%5D","html_url":"https://github.com/apps/stale","followers_url":"https://api.github.com/users/stale%5Bbot%5D/followers","following_url":"https://api.github.com/users/stale%5Bbot%5D/following{/other_user}","gists_url":"https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}","starred_url":"https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stale%5Bbot%5D/subscriptions","organizations_url":"https://api.github.com/users/stale%5Bbot%5D/orgs","repos_url":"https://api.github.com/users/stale%5Bbot%5D/repos","events_url":"https://api.github.com/users/stale%5Bbot%5D/events{/privacy}","received_events_url":"https://api.github.com/users/stale%5Bbot%5D/received_events","type":"Bot","site_admin":false},"created_at":"2020-05-21T09:17:55Z","updated_at":"2020-05-21T09:17:55Z","author_association":"NONE","body":"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Feel free to reopen it. Thank you for your contributions.\n","reactions":{"url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/comments/631980168/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"stale[bot]","id":26384082,"node_id":"MDM6Qm90MjYzODQwODI=","avatar_url":"https://avatars.githubusercontent.com/in/1724?v=4","gravatar_id":"","url":"https://api.github.com/users/stale%5Bbot%5D","html_url":"https://github.com/apps/stale","followers_url":"https://api.github.com/users/stale%5Bbot%5D/followers","following_url":"https://api.github.com/users/stale%5Bbot%5D/following{/other_user}","gists_url":"https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}","starred_url":"https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stale%5Bbot%5D/subscriptions","organizations_url":"https://api.github.com/users/stale%5Bbot%5D/orgs","repos_url":"https://api.github.com/users/stale%5Bbot%5D/repos","events_url":"https://api.github.com/users/stale%5Bbot%5D/events{/privacy}","received_events_url":"https://api.github.com/users/stale%5Bbot%5D/received_events","type":"Bot","site_admin":false}},{"id":3359920083,"node_id":"MDEyOkxhYmVsZWRFdmVudDMzNTk5MjAwODM=","url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/events/3359920083","actor":{"login":"stale[bot]","id":26384082,"node_id":"MDM6Qm90MjYzODQwODI=","avatar_url":"https://avatars.githubusercontent.com/in/1724?v=4","gravatar_id":"","url":"https://api.github.com/users/stale%5Bbot%5D","html_url":"https://github.com/apps/stale","followers_url":"https://api.github.com/users/stale%5Bbot%5D/followers","following_url":"https://api.github.com/users/stale%5Bbot%5D/following{/other_user}","gists_url":"https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}","starred_url":"https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stale%5Bbot%5D/subscriptions","organizations_url":"https://api.github.com/users/stale%5Bbot%5D/orgs","repos_url":"https://api.github.com/users/stale%5Bbot%5D/repos","events_url":"https://api.github.com/users/stale%5Bbot%5D/events{/privacy}","received_events_url":"https://api.github.com/users/stale%5Bbot%5D/received_events","type":"Bot","site_admin":false},"event":"labeled","commit_id":null,"commit_url":null,"created_at":"2020-05-21T09:18:25Z","label":{"name":"wontfix","color":"ffffff"},"performed_via_github_app":null},{"id":3382017180,"node_id":"MDExOkNsb3NlZEV2ZW50MzM4MjAxNzE4MA==","url":"https://api.github.com/repos/PaddlePaddle/ERNIE/issues/events/3382017180","actor":{"login":"stale[bot]","id":26384082,"node_id":"MDM6Qm90MjYzODQwODI=","avatar_url":"https://avatars.githubusercontent.com/in/1724?v=4","gravatar_id":"","url":"https://api.github.com/users/stale%5Bbot%5D","html_url":"https://github.com/apps/stale","followers_url":"https://api.github.com/users/stale%5Bbot%5D/followers","following_url":"https://api.github.com/users/stale%5Bbot%5D/following{/other_user}","gists_url":"https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}","starred_url":"https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stale%5Bbot%5D/subscriptions","organizations_url":"https://api.github.com/users/stale%5Bbot%5D/orgs","repos_url":"https://api.github.com/users/stale%5Bbot%5D/repos","events_url":"https://api.github.com/users/stale%5Bbot%5D/events{/privacy}","received_events_url":"https://api.github.com/users/stale%5Bbot%5D/received_events","type":"Bot","site_admin":false},"event":"closed","commit_id":null,"commit_url":null,"created_at":"2020-05-28T09:53:05Z","state_reason":null,"performed_via_github_app":null}]