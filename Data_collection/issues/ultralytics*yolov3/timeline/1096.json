[{"id":3272222733,"node_id":"MDEyOkxhYmVsZWRFdmVudDMyNzIyMjI3MzM=","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/3272222733","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"event":"labeled","commit_id":null,"commit_url":null,"created_at":"2020-04-25T19:33:45Z","label":{"name":"enhancement","color":"a2eeef"},"performed_via_github_app":null},{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/619435070","html_url":"https://github.com/ultralytics/yolov3/issues/1096#issuecomment-619435070","issue_url":"https://api.github.com/repos/ultralytics/yolov3/issues/1096","id":619435070,"node_id":"MDEyOklzc3VlQ29tbWVudDYxOTQzNTA3MA==","user":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false},"created_at":"2020-04-25T20:18:12Z","updated_at":"2020-04-25T20:18:12Z","author_association":"MEMBER","body":"@jveitchmichaelis these images are mainly intended for validating your labels, as many custom dataset users incorrectly format their data. One thing we are doing is trying to use tensorboard more extensively in the new repo. \r\n\r\nYes, I understand that some of these features may be very useful, and we may want to look at implementing them. One thing that comes to mind though is that anecdotal results partway through training from an incomplete model would seem to me to invite a great deal of questions and uncertainty and issue raising from (particularly inexperienced) users who do not like how their boxes look in epoch 30 out of 300 and want answers about FPs, poor regressions etc. We already get inundated with issues about people trying to shortcut training and not liking their results (i.e. training 10 epochs and then asking why mAP is low).\r\n\r\nAnother point is simply size considerations. The images are currently pngs because of a matplotlib bug from a few months ago, but this has been cleared up and can now be reverted to jpgs. Even at jpg compression, each individual image is 1.3MB currently, so it is not feasable to save a seperate image per epoch, nor to accumulate these on tensorboard every epoch, which would balloon one's tb file to over a GB for full training. Do you know if there's a way to simply display the most recent image in tensorboard without actually saving and growing the tb file?\r\n\r\nAnd speed is also a factor. Plotting takes several seconds for 1 image, so small datasets would experience a significant slowdown in overall training time.\r\n\r\nAbout the dataloader, we did use pytorch transforms initially, but they were extremely slow compared to the current implementation. This may have changed in the intervening time, if you have profiling results comparing that would be very useful!","reactions":{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/619435070/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false}},{"id":3272254505,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MzI3MjI1NDUwNQ==","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/3272254505","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2020-04-25T20:18:12Z","performed_via_github_app":null},{"id":3272254506,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDMyNzIyNTQ1MDY=","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/3272254506","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2020-04-25T20:18:12Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/619437703","html_url":"https://github.com/ultralytics/yolov3/issues/1096#issuecomment-619437703","issue_url":"https://api.github.com/repos/ultralytics/yolov3/issues/1096","id":619437703,"node_id":"MDEyOklzc3VlQ29tbWVudDYxOTQzNzcwMw==","user":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false},"created_at":"2020-04-25T20:39:05Z","updated_at":"2020-04-25T20:39:48Z","author_association":"MEMBER","body":"@jveitchmichaelis BTW, in terms of dataloading, our speed constraint now is simply the loading of the images from the hard drive / SSD, i.e. the line below. For smaller models this may dominate the total training time even beyond model forward and backward passes. We have a --cache option for training which caches smaller datasets into RAM to significantly speed up training, but this is not feasable for larger datasets. \r\n\r\nhttps://github.com/ultralytics/yolov3/blob/3554ab07fbedc05d91d9e6907b96a62512d931d5/utils/datasets.py#L506\r\n\r\nWe've had requests for a dali implementation to address this. I think on the dataloader side this might have the biggest impact of all on speed of coco training.\r\nhttps://docs.nvidia.com/deeplearning/sdk/dali-developer-guide/docs/examples/pytorch/pytorch-basic_example.html\r\n\r\nIn regards to the training images, if you can compact your code to the most minimal implementation as a plot function at the end of utils/utils.py we can review a PR there. Tensorboard functionality would be a plus also, but again being very attentive to profiling speed and file size considerations.","reactions":{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/619437703/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false}},{"id":3272268915,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MzI3MjI2ODkxNQ==","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/3272268915","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2020-04-25T20:39:05Z","performed_via_github_app":null},{"id":3272268916,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDMyNzIyNjg5MTY=","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/3272268916","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2020-04-25T20:39:05Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/619440412","html_url":"https://github.com/ultralytics/yolov3/issues/1096#issuecomment-619440412","issue_url":"https://api.github.com/repos/ultralytics/yolov3/issues/1096","id":619440412,"node_id":"MDEyOklzc3VlQ29tbWVudDYxOTQ0MDQxMg==","user":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"created_at":"2020-04-25T21:03:21Z","updated_at":"2020-04-25T21:55:16Z","author_association":"CONTRIBUTOR","body":"Will do - thought it would be best to opening a discussion here first. It seemed like a simple fix, but actually brought up a lot of architecture questions...\r\n\r\nDealing with user queries is an interesting issue. Plotting images every val step is the default behaviour in the Tensorflow object detection api, for example, which is why I decided to add it here, but it only plots a single random image afaik. Not sure you get round that aside from improving documentation and referring people to that. There is always going to be a balance between making an automatic system that does everything, but that gives you little insight, and a more flexible system that can be confusing or let you shoot yourself in the foot. If you look at the extreme end of this, Google's AutoML gives excellent results but is almost totally opaque to the user.\r\n\r\nSize I can see might be a problem. The mitigation for this is plot less, or fewer images (or small figure), or not at all, and it would make sense if this were optional.  I work with predominantly non-RGB data and this is also the case with satellite imagery. SSD read speed dominates over the forward/backward pass at some point for that, and throwing more cores usually helps to buffer up data (provided your SSD can cope). That said, I think worrying about a second or two of plotting speed when an epoch takes 5-10 minutes seems like premature optimisation. I can do some benchmarking there.\r\n\r\nI know if you publish to tensorboard with the same global step, it just adds the image to a sequence rather than overwriting it. Not sure there's a way around that.\r\n\r\nI suspect a large speed component is I/O storing and reading the figure from disk.  You could probably throw away matplotlib and plot the images into an array directly with OpenCV or Numpy primitives. You'd just need to annotate them separately and then cat them into a grid.\r\n\r\nDALI looks fun, though I'd be curious to see if your constraint is IO or the augmentation speed. \r\n\r\nPyTorch uses PIL which isn't great so not surprised it's slow. I can do some testing, though Albumentations already has benchmarks against built-in implementations. I think this is partly why a lot of Kagglers use it https://github.com/albumentations-team/albumentations#benchmarking-results\r\n\r\nBtw In terms of dataloading, I would expect you'd get a tiny boost in performance if you perform normalisation outside the training loop, since the work will be dispatched to the dataloader threads. Perhaps not if you're IO bound though.","reactions":{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/619440412/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/619448480","html_url":"https://github.com/ultralytics/yolov3/issues/1096#issuecomment-619448480","issue_url":"https://api.github.com/repos/ultralytics/yolov3/issues/1096","id":619448480,"node_id":"MDEyOklzc3VlQ29tbWVudDYxOTQ0ODQ4MA==","user":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false},"created_at":"2020-04-25T22:23:20Z","updated_at":"2020-04-25T22:23:20Z","author_association":"MEMBER","body":"@jveitchmichaelis yes, lots of factors. Albumentations looks interesting, though of course we are wary about adding more dependencies. We don't have the time to test it out for ourselves, but if you can demonstrate improvements over https://github.com/ultralytics/yolov3#speed in before and after tests we'd be happy to do a PR.\r\n\r\nFor the images I suppose the best intermediate solution to simply plot predictions_latest.jpg instead of naming per batch, then they are automatically written (not sure about tb but that's extra anyway).","reactions":{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/619448480/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false}},{"id":3272337067,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MzI3MjMzNzA2Nw==","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/3272337067","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2020-04-25T22:23:20Z","performed_via_github_app":null},{"id":3272337068,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDMyNzIzMzcwNjg=","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/3272337068","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2020-04-25T22:23:20Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/619456820","html_url":"https://github.com/ultralytics/yolov3/issues/1096#issuecomment-619456820","issue_url":"https://api.github.com/repos/ultralytics/yolov3/issues/1096","id":619456820,"node_id":"MDEyOklzc3VlQ29tbWVudDYxOTQ1NjgyMA==","user":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false},"created_at":"2020-04-25T23:58:38Z","updated_at":"2020-04-25T23:58:38Z","author_association":"MEMBER","body":"@jveitchmichaelis ah also, about one of your points, we used to normalize inside the dataloader, we moved it out because it seems the RAM-GPU info transfer speed is a severe bottleneck, so this way we only need to send images to the GPU as uint8 (i.e. 4x less data transfer).\r\n\r\nWe had our hopes up this would make some sort of significant impact, but in practice training speeds remained unchanged.","reactions":{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/619456820/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false}},{"id":3272390135,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MzI3MjM5MDEzNQ==","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/3272390135","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2020-04-25T23:58:38Z","performed_via_github_app":null},{"id":3272390136,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDMyNzIzOTAxMzY=","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/3272390136","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2020-04-25T23:58:38Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/619898956","html_url":"https://github.com/ultralytics/yolov3/issues/1096#issuecomment-619898956","issue_url":"https://api.github.com/repos/ultralytics/yolov3/issues/1096","id":619898956,"node_id":"MDEyOklzc3VlQ29tbWVudDYxOTg5ODk1Ng==","user":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"created_at":"2020-04-27T10:46:10Z","updated_at":"2020-04-27T10:49:09Z","author_association":"CONTRIBUTOR","body":"Ok I'll take a look at this today. I'll try an OpenCV solution, I would think it's almost certainly going to be faster.\r\n\r\nAlso on augmentation, I'll run some benchmarks against:\r\n\r\n```\r\n# Augment imagespace\r\n            if not self.mosaic:\r\n                img, labels = random_affine(img, labels,\r\n                                            degrees=hyp['degrees'],\r\n                                            translate=hyp['translate'],\r\n                                            scale=hyp['scale'],\r\n                                            shear=hyp['shear'])\r\n\r\n            # Augment colorspace\r\n            augment_hsv(img, hgain=hyp['hsv_h'], sgain=hyp['hsv_s'], vgain=hyp['hsv_v'])\r\n```\r\n\r\nSo currently it's just HSV and random affine that you're running? Cutout is currently commented. I'll try and get it set up in GCP, I have some credits which need burning. Should only need to run for a few epochs I think.\r\n\r\n> We had our hopes up this would make some sort of significant impact, but in practice training speeds remained unchanged.\r\n\r\nInteresting on the normalisation front. So you expected an improvement from moving everything to the dataloder and there wasn't? Or the other way around?\r\n\r\nI guess this is also easy to benchmark, since if I'm testing Albumentations I can move everything into the same composition pipeline.","reactions":{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/619898956/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/620117934","html_url":"https://github.com/ultralytics/yolov3/issues/1096#issuecomment-620117934","issue_url":"https://api.github.com/repos/ultralytics/yolov3/issues/1096","id":620117934,"node_id":"MDEyOklzc3VlQ29tbWVudDYyMDExNzkzNA==","user":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false},"created_at":"2020-04-27T17:14:07Z","updated_at":"2020-04-27T17:14:07Z","author_association":"MEMBER","body":"@jveitchmichaelis ah yes, I could never get cutout to produce better training results. Every experiment I ran it hurt the mAP a bit.\r\n\r\nThe current augmentation is:\r\n\r\n- **color space** using augment_hsv(). Would multi-ch just skip this function then?\r\n- **image space** using fliplr, flipud, rotate, translate, scale, shear\r\n\r\nThe image space transformations are done on a mosaic of 4 images, i.e. four 640x640 images are grouped into a 1280x1280 square, then random_affine() is applied to the 1280x1280 image, with an argument to remove 320 pixels of border, to produce a resultant 640x640 mosaicd augmented image that goes into the batch. Importantly the border removal is specified by the last argument and is also taken care of by random_affine()\r\n\r\nhttps://github.com/ultralytics/yolov3/blob/18702c96084557d020cccf11fc77d8db2e44c073/utils/datasets.py#L587-L593","reactions":{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/620117934/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false}},{"id":3276780425,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MzI3Njc4MDQyNQ==","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/3276780425","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2020-04-27T17:14:07Z","performed_via_github_app":null},{"id":3276780432,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDMyNzY3ODA0MzI=","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/3276780432","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2020-04-27T17:14:07Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/620681969","html_url":"https://github.com/ultralytics/yolov3/issues/1096#issuecomment-620681969","issue_url":"https://api.github.com/repos/ultralytics/yolov3/issues/1096","id":620681969,"node_id":"MDEyOklzc3VlQ29tbWVudDYyMDY4MTk2OQ==","user":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"created_at":"2020-04-28T15:35:03Z","updated_at":"2020-04-28T15:35:46Z","author_association":"CONTRIBUTOR","body":"Doing some simple benchmarks, I found that Albumentations' HSV augmentation is about twice as fast. Their implementation:\r\n\r\n```\r\ndef _shift_hsv_uint8(img, hue_shift, sat_shift, val_shift):\r\n    dtype = img.dtype\r\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\r\n    hue, sat, val = cv2.split(img)\r\n\r\n    lut_hue = np.arange(0, 256, dtype=np.int16)\r\n    lut_hue = np.mod(lut_hue + hue_shift, 180).astype(dtype)\r\n\r\n    lut_sat = np.arange(0, 256, dtype=np.int16)\r\n    lut_sat = np.clip(lut_sat + sat_shift, 0, 255).astype(dtype)\r\n\r\n    lut_val = np.arange(0, 256, dtype=np.int16)\r\n    lut_val = np.clip(lut_val + val_shift, 0, 255).astype(dtype)\r\n\r\n    hue = cv2.LUT(hue, lut_hue)\r\n    sat = cv2.LUT(sat, lut_sat)\r\n    val = cv2.LUT(val, lut_val)\r\n\r\n    img = cv2.merge((hue, sat, val)).astype(dtype)\r\n    img = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\r\n    return img\r\n```\r\n\r\nvs\r\n\r\n```\r\ndef augment_hsv(img, hgain=0.5, sgain=0.5, vgain=0.5):\r\n    x = np.random.uniform(-1, 1, 3) * [hgain, sgain, vgain] + 1  # random gains\r\n    img_hsv = (cv2.cvtColor(img, cv2.COLOR_BGR2HSV) * x).clip(None, 255).astype(np.uint8)\r\n    np.clip(img_hsv[:, :, 0], None, 179, out=img_hsv[:, :, 0])  # inplace hue clip (0 - 179 deg)\r\n    cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR, dst=img) \r\n```\r\n\r\nTheirs takes about 8ms on full resolution Zidane vs 19ms for the one here. It would need a bit of modification to figure out what the gains should convert to since it's additive not multiplicative.\r\n\r\nAffine warping is the same - they implement the affine transform in the same way using `cv2.warpAffine` and in fact they don't provide the option for shearing (though there are more options for other types of warp). There are some minor differences about how translation is handled, but the timings are almost identical.\r\n\r\nI didn't test speed for bounding box transforms yet as I expected that would be minimal compared to image ops. I also didn't check vertical/horizontal flip because I assume you're not going to beat `np.flipud`/`fliplr`.\r\n\r\nInitial conclusion is probably to update the hsv augmenter (and test it). Otherwise it's potentially something to look into in the future to see if extra augmentation helps, as there's a richer variety of stuff to choose from (and for custom data that might be useful). Intermediate (best?) solution would be to provide an example to users on how to write a custom dataloader with their own augmentation pipeline.","reactions":{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/620681969/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/620688870","html_url":"https://github.com/ultralytics/yolov3/issues/1096#issuecomment-620688870","issue_url":"https://api.github.com/repos/ultralytics/yolov3/issues/1096","id":620688870,"node_id":"MDEyOklzc3VlQ29tbWVudDYyMDY4ODg3MA==","user":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"created_at":"2020-04-28T15:46:13Z","updated_at":"2020-04-28T15:49:25Z","author_association":"CONTRIBUTOR","body":"On flipping:\r\n\r\n```\r\ndef vflip(img):\r\n    return np.ascontiguousarray(img[::-1, ...])\r\n\r\n\r\ndef hflip(img):\r\n    return np.ascontiguousarray(img[:, ::-1, ...])\r\n\r\n%timeit vflip(np.random.randint(low=0, high=255, size=(640,512,3)))\r\n%timeit np.flipud(np.random.randint(low=0, high=255, size=(640,512,3)))\r\n%timeit cv2.flip(np.random.randint(low=0, high=255, size=(640,512,3)), 0) #vflip\r\n\r\n%timeit hflip(np.random.randint(low=0, high=255, size=(640,512,3)))\r\n%timeit np.fliplr(np.random.randint(low=0, high=255, size=(640,512,3)))\r\n%timeit cv2.flip(np.random.randint(low=0, high=255, size=(640,512,3)), 1) #hflip\r\n\r\n3.69 ms ± 22.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\r\n2.71 ms ± 143 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) # Numpy\r\n4.02 ms ± 32.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\r\n4.51 ms ± 190 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\r\n3.02 ms ± 1.13 ms per loop (mean ± std. dev. of 7 runs, 100 loops each) # Numpy\r\n4.26 ms ± 133 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\r\n```\r\n\r\nDefinitely seems an advantage to using Numpy over OpenCV here, but should check this further. I think this is only used in webcam loading atm.","reactions":{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/620688870/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/620729050","html_url":"https://github.com/ultralytics/yolov3/issues/1096#issuecomment-620729050","issue_url":"https://api.github.com/repos/ultralytics/yolov3/issues/1096","id":620729050,"node_id":"MDEyOklzc3VlQ29tbWVudDYyMDcyOTA1MA==","user":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false},"created_at":"2020-04-28T16:52:31Z","updated_at":"2020-04-28T16:57:31Z","author_association":"MEMBER","body":"@jveitchmichaelis ah your HSV speedup is huge! That's great news. We should definitely implement their version then.\r\n\r\nAbout the flips, I see the contiguous call there. This can be very slow sometimes, which is why I only call it once at the very end, but in general contiguous data will provide overall speedup through all the later operations, so it is beneficial. Hflip and vflip are definitely booleans that should be added to the hyps in train.py as well.\r\n\r\nA wider question I have is do you have profiling capability with GPU? I used a macbook pro with 1080ti eGPU in the past, but lost that capability last year after a macos update, so now I just develop on cpu, and push to GCP for actual training. This means I've lost my profiling capability though, which I used to do with Spyder line profiler training a few batches with @profile decorators for example before the dataloader functions in datasets.py.\r\n\r\nEDIT: Now that I think about it, profiling all the datasets.py functions should be fine without GPU... as no data in the file ever makes its way to a cuda device. Hmm ok I'll give it a shot today to see where the bottlenecks are.\r\n\r\nEDIT2: I see their HSV function completely avoids indexing operations, very nice. Indexing can be extremely slow in general, this probably explains the speedup compared to our in-house function.","reactions":{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/620729050/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false}},{"id":3281236450,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MzI4MTIzNjQ1MA==","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/3281236450","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2020-04-28T16:52:31Z","performed_via_github_app":null},{"id":3281236452,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDMyODEyMzY0NTI=","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/3281236452","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2020-04-28T16:52:32Z","performed_via_github_app":null},{"id":3281236460,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MzI4MTIzNjQ2MA==","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/3281236460","actor":{"login":"Profile","id":19148526,"node_id":"MDQ6VXNlcjE5MTQ4NTI2","avatar_url":"https://avatars.githubusercontent.com/u/19148526?v=4","gravatar_id":"","url":"https://api.github.com/users/Profile","html_url":"https://github.com/Profile","followers_url":"https://api.github.com/users/Profile/followers","following_url":"https://api.github.com/users/Profile/following{/other_user}","gists_url":"https://api.github.com/users/Profile/gists{/gist_id}","starred_url":"https://api.github.com/users/Profile/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Profile/subscriptions","organizations_url":"https://api.github.com/users/Profile/orgs","repos_url":"https://api.github.com/users/Profile/repos","events_url":"https://api.github.com/users/Profile/events{/privacy}","received_events_url":"https://api.github.com/users/Profile/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2020-04-28T16:52:32Z","performed_via_github_app":null},{"id":3281236465,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDMyODEyMzY0NjU=","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/3281236465","actor":{"login":"Profile","id":19148526,"node_id":"MDQ6VXNlcjE5MTQ4NTI2","avatar_url":"https://avatars.githubusercontent.com/u/19148526?v=4","gravatar_id":"","url":"https://api.github.com/users/Profile","html_url":"https://github.com/Profile","followers_url":"https://api.github.com/users/Profile/followers","following_url":"https://api.github.com/users/Profile/following{/other_user}","gists_url":"https://api.github.com/users/Profile/gists{/gist_id}","starred_url":"https://api.github.com/users/Profile/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Profile/subscriptions","organizations_url":"https://api.github.com/users/Profile/orgs","repos_url":"https://api.github.com/users/Profile/repos","events_url":"https://api.github.com/users/Profile/events{/privacy}","received_events_url":"https://api.github.com/users/Profile/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2020-04-28T16:52:32Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/620737120","html_url":"https://github.com/ultralytics/yolov3/issues/1096#issuecomment-620737120","issue_url":"https://api.github.com/repos/ultralytics/yolov3/issues/1096","id":620737120,"node_id":"MDEyOklzc3VlQ29tbWVudDYyMDczNzEyMA==","user":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"created_at":"2020-04-28T17:07:36Z","updated_at":"2020-04-28T17:12:17Z","author_association":"CONTRIBUTOR","body":"I have an Intel 6700K + 1080ti here (we also have a Ryzen 3900X with 2x2070s in the office), so if you have some specific stuff you'd like to profile I can give it a go. I just ran the tests in a notebook on some random numpy arrays + the sample images so my numbers are definitely CPU. Maybe this is where DALI might help?\r\n\r\nI also tried caching the lookup tables to save allocating the `arange`s every time, but I don't think it made an enormous amount of difference - within the error of %timeit anyway.","reactions":{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/620737120/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/620759757","html_url":"https://github.com/ultralytics/yolov3/issues/1096#issuecomment-620759757","issue_url":"https://api.github.com/repos/ultralytics/yolov3/issues/1096","id":620759757,"node_id":"MDEyOklzc3VlQ29tbWVudDYyMDc1OTc1Nw==","user":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false},"created_at":"2020-04-28T17:51:03Z","updated_at":"2020-04-28T17:51:03Z","author_association":"MEMBER","body":"@jveitchmichaelis ok I did some lineprofiling in datasets.py. Back to my old game. This is for 16 epochs of coco64.data at img size 640, so about 1000 images total. Sorry for the long message, we can delete this later.\r\n\r\n\r\n```\r\nCaching labels:   0%|          | 0/64 [00:00<?, ?it/s]\r\nCaching labels (63 found, 1 missing, 0 empty, 0 duplicate, for 64 images): 100%|██████████| 64/64 [00:00<00:00, 3017.01it/s]\r\n\r\nCaching labels:   0%|          | 0/64 [00:00<?, ?it/s]\r\nCaching labels (63 found, 1 missing, 0 empty, 0 duplicate, for 64 images): 100%|██████████| 64/64 [00:00<00:00, 3307.00it/s]\r\n\r\nApex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\r\nNamespace(adam=False, batch_size=16, bucket='', cache_images=False, cfg='cfg/yolov3-spp.cfg', data='data/coco64.data', device='', epochs=16, evolve=False, img_size=[320, 640], multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/yolov3-spp-ultralytics.pt')\r\nUsing CPU\r\n\r\nStart Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\r\nModel Summary: 225 layers, 6.29987e+07 parameters, 6.29987e+07 gradients, 118.0 GFLOPS\r\nImage sizes 320 - 640 train, 640 test\r\nUsing 0 dataloader workers\r\nStarting training for 16 epochs...\r\n\r\nWrote profile results to /Users/glennjocher/.spyder-py3/lineprofiler.results\r\nTimer unit: 1e-06 s\r\n\r\nTotal time: 0.039052 s\r\nFile: /Users/glennjocher/PycharmProjects/yolov3/utils/datasets.py\r\nFunction: __init__ at line 259\r\n\r\nLine #      Hits         Time  Per Hit   % Time  Line Contents\r\n==============================================================\r\n   259                                               @profile\r\n   260                                               def __init__(self, path, img_size=416, batch_size=16, augment=False, hyp=None, rect=False, image_weights=False,\r\n   261                                                            cache_labels=True, cache_images=False, single_cls=False):\r\n   262         2        107.0     53.5      0.3          path = str(Path(path))  # os-agnostic\r\n   263         2         54.0     27.0      0.1          assert os.path.isfile(path), 'File not found %s. See %s' % (path, help_url)\r\n   264         2        133.0     66.5      0.3          with open(path, 'r') as f:\r\n   265         2        643.0    321.5      1.6              self.img_files = [x.replace('/', os.sep) for x in f.read().splitlines()  # os-agnostic\r\n   266                                                                         if os.path.splitext(x)[-1].lower() in img_formats]\r\n   267                                           \r\n   268         2          6.0      3.0      0.0          n = len(self.img_files)\r\n   269         2          5.0      2.5      0.0          assert n > 0, 'No images found in %s. See %s' % (path, help_url)\r\n   270         2         72.0     36.0      0.2          bi = np.floor(np.arange(n) / batch_size).astype(np.int)  # batch index\r\n   271         2         12.0      6.0      0.0          nb = bi[-1] + 1  # number of batches\r\n   272                                           \r\n   273         2          8.0      4.0      0.0          self.n = n\r\n   274         2          5.0      2.5      0.0          self.batch = bi  # batch index of image\r\n   275         2          5.0      2.5      0.0          self.img_size = img_size\r\n   276         2          5.0      2.5      0.0          self.augment = augment\r\n   277         2          5.0      2.5      0.0          self.hyp = hyp\r\n   278         2          6.0      3.0      0.0          self.image_weights = image_weights\r\n   279         2          7.0      3.5      0.0          self.rect = False if image_weights else rect\r\n   280         2          6.0      3.0      0.0          self.mosaic = self.augment and not self.rect  # load 4 images at a time into a mosaic (only during training)\r\n   281                                           \r\n   282                                                   # Define labels\r\n   283         2          6.0      3.0      0.0          self.label_files = [x.replace('images', 'labels').replace(os.path.splitext(x)[-1], '.txt')\r\n   284         2        592.0    296.0      1.5                              for x in self.img_files]\r\n   285                                           \r\n   286                                                   # Rectangular Training  https://github.com/ultralytics/yolov3/issues/232\r\n   287         2          5.0      2.5      0.0          if self.rect:\r\n   288                                                       # Read image shapes (wh)\r\n   289         1          2.0      2.0      0.0              sp = path.replace('.txt', '.shapes')  # shapefile path\r\n   290         1          2.0      2.0      0.0              try:\r\n   291         1         43.0     43.0      0.1                  with open(sp, 'r') as f:  # read existing shapefile\r\n   292         1         48.0     48.0      0.1                      s = [x.split() for x in f.read().splitlines()]\r\n   293         1         15.0     15.0      0.0                      assert len(s) == n, 'Shapefile out of sync'\r\n   294                                                       except:\r\n   295                                                           s = [exif_size(Image.open(f)) for f in tqdm(self.img_files, desc='Reading image shapes')]\r\n   296                                                           np.savetxt(sp, s, fmt='%g')  # overwrites existing (if any)\r\n   297                                           \r\n   298                                                       # Sort by aspect ratio\r\n   299         1         50.0     50.0      0.1              s = np.array(s, dtype=np.float64)\r\n   300         1         11.0     11.0      0.0              ar = s[:, 1] / s[:, 0]  # aspect ratio\r\n   301         1         17.0     17.0      0.0              i = ar.argsort()\r\n   302         1         29.0     29.0      0.1              self.img_files = [self.img_files[i] for i in i]\r\n   303         1         24.0     24.0      0.1              self.label_files = [self.label_files[i] for i in i]\r\n   304         1         15.0     15.0      0.0              self.shapes = s[i]  # wh\r\n   305         1          3.0      3.0      0.0              ar = ar[i]\r\n   306                                           \r\n   307                                                       # Set training image shapes\r\n   308         1          7.0      7.0      0.0              shapes = [[1, 1]] * nb\r\n   309         5         14.0      2.8      0.0              for i in range(nb):\r\n   310         4         31.0      7.8      0.1                  ari = ar[bi == i]\r\n   311         4         62.0     15.5      0.2                  mini, maxi = ari.min(), ari.max()\r\n   312         4         13.0      3.2      0.0                  if maxi < 1:\r\n   313         2          5.0      2.5      0.0                      shapes[i] = [maxi, 1]\r\n   314         2          5.0      2.5      0.0                  elif mini > 1:\r\n   315         1          3.0      3.0      0.0                      shapes[i] = [1, 1 / mini]\r\n   316                                           \r\n   317         1         26.0     26.0      0.1              self.batch_shapes = np.ceil(np.array(shapes) * img_size / 64.).astype(np.int) * 64\r\n   318                                           \r\n   319                                                   # Preload labels (required for weighted CE training)\r\n   320         2          8.0      4.0      0.0          self.imgs = [None] * n\r\n   321         2          6.0      3.0      0.0          self.labels = [None] * n\r\n   322         2          4.0      2.0      0.0          if cache_labels or image_weights:  # cache labels for faster training\r\n   323         2         10.0      5.0      0.0              self.labels = [np.zeros((0, 5))] * n\r\n   324         2          4.0      2.0      0.0              extract_bounding_boxes = False\r\n   325         2          5.0      2.5      0.0              create_datasubset = False\r\n   326         2       2132.0   1066.0      5.5              pbar = tqdm(self.label_files, desc='Caching labels')\r\n   327         2          7.0      3.5      0.0              nm, nf, ne, ns, nd = 0, 0, 0, 0, 0  # number missing, found, empty, datasubset, duplicate\r\n   328       130       1603.0     12.3      4.1              for i, file in enumerate(pbar):\r\n   329       128        278.0      2.2      0.7                  try:\r\n   330       128       5922.0     46.3     15.2                      with open(file, 'r') as f:\r\n   331       126       5998.0     47.6     15.4                          l = np.array([x.split() for x in f.read().splitlines()], dtype=np.float32)\r\n   332         2          5.0      2.5      0.0                  except:\r\n   333         2          4.0      2.0      0.0                      nm += 1  # print('missing labels for image %s' % self.img_files[i])  # file missing\r\n   334         2          6.0      3.0      0.0                      continue\r\n   335                                           \r\n   336       126        375.0      3.0      1.0                  if l.shape[0]:\r\n   337       126        317.0      2.5      0.8                      assert l.shape[1] == 5, '> 5 label columns: %s' % file\r\n   338       126       1914.0     15.2      4.9                      assert (l >= 0).all(), 'negative labels: %s' % file\r\n   339       126       1691.0     13.4      4.3                      assert (l[:, 1:] <= 1).all(), 'non-normalized or out of bounds coordinate labels: %s' % file\r\n   340       126      14170.0    112.5     36.3                      if np.unique(l, axis=0).shape[0] < l.shape[0]:  # duplicate rows\r\n   341                                                                   nd += 1  # print('WARNING: duplicate rows in %s' % self.label_files[i])  # duplicate rows\r\n   342       126        329.0      2.6      0.8                      if single_cls:\r\n   343                                                                   l[:, 0] = 0  # force dataset into single-class mode\r\n   344       126        321.0      2.5      0.8                      self.labels[i] = l\r\n   345       126        288.0      2.3      0.7                      nf += 1  # file found\r\n   346                                           \r\n   347                                                               # Create subdataset (a smaller dataset)\r\n   348       126        290.0      2.3      0.7                      if create_datasubset and ns < 1E4:\r\n   349                                                                   if ns == 0:\r\n   350                                                                       create_folder(path='./datasubset')\r\n   351                                                                       os.makedirs('./datasubset/images')\r\n   352                                                                   exclude_classes = 43\r\n   353                                                                   if exclude_classes not in l[:, 0]:\r\n   354                                                                       ns += 1\r\n   355                                                                       # shutil.copy(src=self.img_files[i], dst='./datasubset/images/')  # copy image\r\n   356                                                                       with open('./datasubset/images.txt', 'a') as f:\r\n   357                                                                           f.write(self.img_files[i] + '\\n')\r\n   358                                           \r\n   359                                                               # Extract object detection boxes for a second stage classifier\r\n   360       126        304.0      2.4      0.8                      if extract_bounding_boxes:\r\n   361                                                                   p = Path(self.img_files[i])\r\n   362                                                                   img = cv2.imread(str(p))\r\n   363                                                                   h, w = img.shape[:2]\r\n   364                                                                   for j, x in enumerate(l):\r\n   365                                                                       f = '%s%sclassifier%s%g_%g_%s' % (p.parent.parent, os.sep, os.sep, x[0], j, p.name)\r\n   366                                                                       if not os.path.exists(Path(f).parent):\r\n   367                                                                           os.makedirs(Path(f).parent)  # make new output folder\r\n   368                                           \r\n   369                                                                       b = x[1:] * [w, h, w, h]  # box\r\n   370                                                                       b[2:] = b[2:].max()  # rectangle to square\r\n   371                                                                       b[2:] = b[2:] * 1.3 + 30  # pad\r\n   372                                                                       b = xywh2xyxy(b.reshape(-1, 4)).ravel().astype(np.int)\r\n   373                                           \r\n   374                                                                       b[[0, 2]] = np.clip(b[[0, 2]], 0, w)  # clip boxes outside of image\r\n   375                                                                       b[[1, 3]] = np.clip(b[[1, 3]], 0, h)\r\n   376                                                                       assert cv2.imwrite(f, img[b[1]:b[3], b[0]:b[2]]), 'Failure extracting classifier boxes'\r\n   377                                                           else:\r\n   378                                                               ne += 1  # print('empty labels for image %s' % self.img_files[i])  # file empty\r\n   379                                                               # os.system(\"rm '%s' '%s'\" % (self.img_files[i], self.label_files[i]))  # remove\r\n   380                                           \r\n   381       126        271.0      2.2      0.7                  pbar.desc = 'Caching labels (%g found, %g missing, %g empty, %g duplicate, for %g images)' % (\r\n   382       126        662.0      5.3      1.7                      nf, nm, ne, nd, n)\r\n   383         2          7.0      3.5      0.0              assert nf > 0, 'No labels found in %s. See %s' % (os.path.dirname(file) + os.sep, help_url)\r\n   384                                           \r\n   385                                                   # Cache images into memory for faster training (WARNING: large datasets may exceed system RAM)\r\n   386         2          5.0      2.5      0.0          if cache_images:  # if training\r\n   387                                                       gb = 0  # Gigabytes of cached images\r\n   388                                                       pbar = tqdm(range(len(self.img_files)), desc='Caching images')\r\n   389                                                       self.img_hw0, self.img_hw = [None] * n, [None] * n\r\n   390                                                       for i in pbar:  # max 10k images\r\n   391                                                           self.imgs[i], self.img_hw0[i], self.img_hw[i] = load_image(self, i)  # img, hw_original, hw_resized\r\n   392                                                           gb += self.imgs[i].nbytes\r\n   393                                                           pbar.desc = 'Caching images (%.1fGB)' % (gb / 1E9)\r\n   394                                           \r\n   395                                                   # Detect corrupted images https://medium.com/joelthchao/programmatically-detect-corrupted-image-8c1b2006c3d3\r\n   396         2          4.0      2.0      0.0          detect_corrupted_images = False\r\n   397         2          5.0      2.5      0.0          if detect_corrupted_images:\r\n   398                                                       from skimage import io  # conda install -c conda-forge scikit-image\r\n   399                                                       for file in tqdm(self.img_files, desc='Detecting corrupted images'):\r\n   400                                                           try:\r\n   401                                                               _ = io.imread(file)\r\n   402                                                           except:\r\n   403                                                               print('Corrupted image detected: %s' % file)\r\n\r\nTotal time: 39.4643 s\r\nFile: /Users/glennjocher/PycharmProjects/yolov3/utils/datasets.py\r\nFunction: __getitem__ at line 414\r\n\r\nLine #      Hits         Time  Per Hit   % Time  Line Contents\r\n==============================================================\r\n   414                                               @profile\r\n   415                                               def __getitem__(self, index):\r\n   416      1024        992.0      1.0      0.0          if self.image_weights:\r\n   417                                                       index = self.indices[index]\r\n   418                                           \r\n   419      1024        770.0      0.8      0.0          hyp = self.hyp\r\n   420      1024        783.0      0.8      0.0          if self.mosaic:\r\n   421                                                       # Load mosaic\r\n   422      1024   24187640.0  23620.7     61.3              img, labels = load_mosaic(self, index)\r\n   423      1024        882.0      0.9      0.0              shapes = None\r\n   424                                           \r\n   425                                                   else:\r\n   426                                                       # Load image\r\n   427                                                       img, (h0, w0), (h, w) = load_image(self, index)\r\n   428                                           \r\n   429                                                       # Letterbox\r\n   430                                                       shape = self.batch_shapes[self.batch[index]] if self.rect else self.img_size  # final letterboxed shape\r\n   431                                                       img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment)\r\n   432                                                       shapes = (h0, w0), ((h / h0, w / w0), pad)  # for COCO mAP rescaling\r\n   433                                           \r\n   434                                                       # Load labels\r\n   435                                                       labels = []\r\n   436                                                       x = self.labels[index]\r\n   437                                                       if x is not None and x.size > 0:\r\n   438                                                           # Normalized xywh to pixel xyxy format\r\n   439                                                           labels = x.copy()\r\n   440                                                           labels[:, 1] = ratio[0] * w * (x[:, 1] - x[:, 3] / 2) + pad[0]  # pad width\r\n   441                                                           labels[:, 2] = ratio[1] * h * (x[:, 2] - x[:, 4] / 2) + pad[1]  # pad height\r\n   442                                                           labels[:, 3] = ratio[0] * w * (x[:, 1] + x[:, 3] / 2) + pad[0]\r\n   443                                                           labels[:, 4] = ratio[1] * h * (x[:, 2] + x[:, 4] / 2) + pad[1]\r\n   444                                           \r\n   445      1024       1119.0      1.1      0.0          if self.augment:\r\n   446                                                       # Augment imagespace\r\n   447      1024        744.0      0.7      0.0              if not self.mosaic:\r\n   448                                                           img, labels = random_affine(img, labels,\r\n   449                                                                                       degrees=hyp['degrees'],\r\n   450                                                                                       translate=hyp['translate'],\r\n   451                                                                                       scale=hyp['scale'],\r\n   452                                                                                       shear=hyp['shear'])\r\n   453                                           \r\n   454                                                       # Augment colorspace\r\n   455      1024   14598738.0  14256.6     37.0              augment_hsv(img, hgain=hyp['hsv_h'], sgain=hyp['hsv_s'], vgain=hyp['hsv_v'])\r\n   456                                           \r\n   457                                                       # Apply cutouts\r\n   458                                                       # if random.random() < 0.9:\r\n   459                                                       #     labels = cutout(img, labels)\r\n   460                                           \r\n   461      1024       1708.0      1.7      0.0          nL = len(labels)  # number of labels\r\n   462      1024        847.0      0.8      0.0          if nL:\r\n   463                                                       # convert xyxy to xywh\r\n   464      1019      50403.0     49.5      0.1              labels[:, 1:5] = xyxy2xywh(labels[:, 1:5])\r\n   465                                           \r\n   466                                                       # Normalize coordinates 0 - 1\r\n   467      1019      22027.0     21.6      0.1              labels[:, [2, 4]] /= img.shape[0]  # height\r\n   468      1019      10981.0     10.8      0.0              labels[:, [1, 3]] /= img.shape[1]  # width\r\n   469                                           \r\n   470      1024       1429.0      1.4      0.0          if self.augment:\r\n   471                                                       # random left-right flip\r\n   472      1024        671.0      0.7      0.0              lr_flip = True\r\n   473      1024       2369.0      2.3      0.0              if lr_flip and random.random() < 0.5:\r\n   474       506       4135.0      8.2      0.0                  img = np.fliplr(img)\r\n   475       506        353.0      0.7      0.0                  if nL:\r\n   476       503       2398.0      4.8      0.0                      labels[:, 1] = 1 - labels[:, 1]\r\n   477                                           \r\n   478                                                       # random up-down flip\r\n   479      1024        618.0      0.6      0.0              ud_flip = False\r\n   480      1024        634.0      0.6      0.0              if ud_flip and random.random() < 0.5:\r\n   481                                                           img = np.flipud(img)\r\n   482                                                           if nL:\r\n   483                                                               labels[:, 2] = 1 - labels[:, 2]\r\n   484                                           \r\n   485      1024      31981.0     31.2      0.1          labels_out = torch.zeros((nL, 6))\r\n   486      1024        838.0      0.8      0.0          if nL:\r\n   487      1019      39957.0     39.2      0.1              labels_out[:, 1:] = torch.from_numpy(labels)\r\n   488                                           \r\n   489                                                   # Convert\r\n   490      1024       4148.0      4.1      0.0          img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\r\n   491      1024     489124.0    477.7      1.2          img = np.ascontiguousarray(img)\r\n   492                                           \r\n   493      1024       8059.0      7.9      0.0          return torch.from_numpy(img), labels_out, self.img_files[index], shapes\r\n\r\nTotal time: 20.0311 s\r\nFile: /Users/glennjocher/PycharmProjects/yolov3/utils/datasets.py\r\nFunction: load_image at line 502\r\n\r\nLine #      Hits         Time  Per Hit   % Time  Line Contents\r\n==============================================================\r\n   502                                           @profile\r\n   503                                           def load_image(self, index):\r\n   504                                               # loads 1 image from dataset, returns img, original hw, resized hw\r\n   505      4096       4031.0      1.0      0.0      img = self.imgs[index]\r\n   506      4096       1970.0      0.5      0.0      if img is None:  # not cached\r\n   507      4096       2916.0      0.7      0.0          img_path = self.img_files[index]\r\n   508      4096   19327841.0   4718.7     96.5          img = cv2.imread(img_path)  # BGR\r\n   509      4096       6204.0      1.5      0.0          assert img is not None, 'Image Not Found ' + img_path\r\n   510      4096       7073.0      1.7      0.0          h0, w0 = img.shape[:2]  # orig hw\r\n   511      4096      10713.0      2.6      0.1          r = self.img_size / max(h0, w0)  # resize image to img_size\r\n   512      4096       4143.0      1.0      0.0          if r < 1 or (self.augment and r != 1):  # always resize down, only resize up if training with augmentation\r\n   513       702        655.0      0.9      0.0              interp = cv2.INTER_AREA if r < 1 and not self.augment else cv2.INTER_LINEAR\r\n   514       702     661470.0    942.3      3.3              img = cv2.resize(img, (int(w0 * r), int(h0 * r)), interpolation=interp)\r\n   515      4096       4106.0      1.0      0.0          return img, (h0, w0), img.shape[:2]  # img, hw_original, hw_resized\r\n   516                                               else:\r\n   517                                                   return self.imgs[index], self.img_hw0[index], self.img_hw[index]  # img, hw_original, hw_resized\r\n\r\nTotal time: 14.505 s\r\nFile: /Users/glennjocher/PycharmProjects/yolov3/utils/datasets.py\r\nFunction: augment_hsv at line 519\r\n\r\nLine #      Hits         Time  Per Hit   % Time  Line Contents\r\n==============================================================\r\n   519                                           @profile\r\n   520                                           def augment_hsv(img, hgain=0.5, sgain=0.5, vgain=0.5):\r\n   521      1024      21550.0     21.0      0.1      x = np.random.uniform(-1, 1, 3) * [hgain, sgain, vgain] + 1  # random gains\r\n   522      1024   12402276.0  12111.6     85.5      img_hsv = (cv2.cvtColor(img, cv2.COLOR_BGR2HSV) * x).clip(None, 255).astype(np.uint8)\r\n   523      1024     335501.0    327.6      2.3      np.clip(img_hsv[:, :, 0], None, 179, out=img_hsv[:, :, 0])  # inplace hue clip (0 - 179 deg)\r\n   524      1024    1745712.0   1704.8     12.0      cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR, dst=img)  # no return needed\r\n\r\nTotal time: 24.0236 s\r\nFile: /Users/glennjocher/PycharmProjects/yolov3/utils/datasets.py\r\nFunction: load_mosaic at line 531\r\n\r\nLine #      Hits         Time  Per Hit   % Time  Line Contents\r\n==============================================================\r\n   531                                           @profile\r\n   532                                           def load_mosaic(self, index):\r\n   533                                               # loads images in a mosaic\r\n   534                                           \r\n   535      1024       1102.0      1.1      0.0      labels4 = []\r\n   536      1024       1078.0      1.1      0.0      s = self.img_size\r\n   537      1024      10111.0      9.9      0.0      xc, yc = [int(random.uniform(s * 0.5, s * 1.5)) for _ in range(2)]  # mosaic center x, y\r\n   538      1024      22212.0     21.7      0.1      indices = [index] + [random.randint(0, len(self.labels) - 1) for _ in range(3)]  # 3 additional image indices\r\n   539      5120       7778.0      1.5      0.0      for i, index in enumerate(indices):\r\n   540                                                   # Load image\r\n   541      4096   20106198.0   4908.7     83.7          img, _, (h, w) = load_image(self, index)\r\n   542                                           \r\n   543                                                   # place img in img4\r\n   544      4096       4202.0      1.0      0.0          if i == 0:  # top left\r\n   545      1024     316638.0    309.2      1.3              img4 = np.full((s * 2, s * 2, img.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles\r\n   546      1024       3165.0      3.1      0.0              x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymax (large image)\r\n   547      1024       1456.0      1.4      0.0              x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymax (small image)\r\n   548      3072       2804.0      0.9      0.0          elif i == 1:  # top right\r\n   549      1024       2684.0      2.6      0.0              x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc\r\n   550      1024       1622.0      1.6      0.0              x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h\r\n   551      2048       1785.0      0.9      0.0          elif i == 2:  # bottom left\r\n   552      1024       2675.0      2.6      0.0              x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)\r\n   553      1024       1825.0      1.8      0.0              x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, max(xc, w), min(y2a - y1a, h)\r\n   554      1024        909.0      0.9      0.0          elif i == 3:  # bottom right\r\n   555      1024       2560.0      2.5      0.0              x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)\r\n   556      1024       1788.0      1.7      0.0              x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)\r\n   557                                           \r\n   558      4096     320291.0     78.2      1.3          img4[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  # img4[ymin:ymax, xmin:xmax]\r\n   559      4096       4612.0      1.1      0.0          padw = x1a - x1b\r\n   560      4096       3669.0      0.9      0.0          padh = y1a - y1b\r\n   561                                           \r\n   562                                                   # Load labels\r\n   563      4096       7042.0      1.7      0.0          label_path = self.label_files[index]\r\n   564      4096      68768.0     16.8      0.3          if os.path.isfile(label_path):\r\n   565      4027       5609.0      1.4      0.0              x = self.labels[index]\r\n   566      4027       3988.0      1.0      0.0              if x is None:  # labels not preloaded\r\n   567                                                           with open(label_path, 'r') as f:\r\n   568                                                               x = np.array([x.split() for x in f.read().splitlines()], dtype=np.float32)\r\n   569                                           \r\n   570      4027       5652.0      1.4      0.0              if x.size > 0:\r\n   571                                                           # Normalized xywh to pixel xyxy format\r\n   572      4027      11452.0      2.8      0.0                  labels = x.copy()\r\n   573      4027      82746.0     20.5      0.3                  labels[:, 1] = w * (x[:, 1] - x[:, 3] / 2) + padw\r\n   574      4027      31467.0      7.8      0.1                  labels[:, 2] = h * (x[:, 2] - x[:, 4] / 2) + padh\r\n   575      4027      28048.0      7.0      0.1                  labels[:, 3] = w * (x[:, 1] + x[:, 3] / 2) + padw\r\n   576      4027      26623.0      6.6      0.1                  labels[:, 4] = h * (x[:, 2] + x[:, 4] / 2) + padh\r\n   577                                                       else:\r\n   578                                                           labels = np.zeros((0, 5), dtype=np.float32)\r\n   579      4027       6306.0      1.6      0.0              labels4.append(labels)\r\n   580                                           \r\n   581                                               # Concat/clip labels\r\n   582      1024       1616.0      1.6      0.0      if len(labels4):\r\n   583      1024      11568.0     11.3      0.0          labels4 = np.concatenate(labels4, 0)\r\n   584                                                   # np.clip(labels4[:, 1:] - s / 2, 0, s, out=labels4[:, 1:])  # use with center crop\r\n   585      1024      66430.0     64.9      0.3          np.clip(labels4[:, 1:], 0, 2 * s, out=labels4[:, 1:])  # use with random_affine\r\n   586                                           \r\n   587                                               # Augment\r\n   588                                               # img4 = img4[s // 2: int(s * 1.5), s // 2:int(s * 1.5)]  # center crop (WARNING, requires box pruning)\r\n   589      1024       1263.0      1.2      0.0      img4, labels4 = random_affine(img4, labels4,\r\n   590      1024       1976.0      1.9      0.0                                    degrees=self.hyp['degrees'] * 1,\r\n   591      1024       1127.0      1.1      0.0                                    translate=self.hyp['translate'] * 1,\r\n   592      1024       1016.0      1.0      0.0                                    scale=self.hyp['scale'] * 1,\r\n   593      1024       1006.0      1.0      0.0                                    shear=self.hyp['shear'] * 1,\r\n   594      1024    2837772.0   2771.3     11.8                                    border=-s // 2)  # border to remove\r\n   595                                           \r\n   596      1024        976.0      1.0      0.0      return img4, labels4\r\n\r\nTotal time: 0 s\r\nFile: /Users/glennjocher/PycharmProjects/yolov3/utils/datasets.py\r\nFunction: letterbox at line 598\r\n\r\nLine #      Hits         Time  Per Hit   % Time  Line Contents\r\n==============================================================\r\n   598                                           @profile\r\n   599                                           def letterbox(img, new_shape=(416, 416), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True):\r\n   600                                               # Resize image to a 32-pixel-multiple rectangle https://github.com/ultralytics/yolov3/issues/232\r\n   601                                               shape = img.shape[:2]  # current shape [height, width]\r\n   602                                               if isinstance(new_shape, int):\r\n   603                                                   new_shape = (new_shape, new_shape)\r\n   604                                           \r\n   605                                               # Scale ratio (new / old)\r\n   606                                               r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\r\n   607                                               if not scaleup:  # only scale down, do not scale up (for better test mAP)\r\n   608                                                   r = min(r, 1.0)\r\n   609                                           \r\n   610                                               # Compute padding\r\n   611                                               ratio = r, r  # width, height ratios\r\n   612                                               new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\r\n   613                                               dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\r\n   614                                               if auto:  # minimum rectangle\r\n   615                                                   dw, dh = np.mod(dw, 64), np.mod(dh, 64)  # wh padding\r\n   616                                               elif scaleFill:  # stretch\r\n   617                                                   dw, dh = 0.0, 0.0\r\n   618                                                   new_unpad = new_shape\r\n   619                                                   ratio = new_shape[0] / shape[1], new_shape[1] / shape[0]  # width, height ratios\r\n   620                                           \r\n   621                                               dw /= 2  # divide padding into 2 sides\r\n   622                                               dh /= 2\r\n   623                                           \r\n   624                                               if shape[::-1] != new_unpad:  # resize\r\n   625                                                   img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\r\n   626                                               top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\r\n   627                                               left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\r\n   628                                               img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\r\n   629                                               return img, ratio, (dw, dh)\r\n\r\nTotal time: 2.77499 s\r\nFile: /Users/glennjocher/PycharmProjects/yolov3/utils/datasets.py\r\nFunction: random_affine at line 631\r\n\r\nLine #      Hits         Time  Per Hit   % Time  Line Contents\r\n==============================================================\r\n   631                                           @profile\r\n   632                                           def random_affine(img, targets=(), degrees=10, translate=.1, scale=.1, shear=10, border=0):\r\n   633                                               # torchvision.transforms.RandomAffine(degrees=(-10, 10), translate=(.1, .1), scale=(.9, 1.1), shear=(-10, 10))\r\n   634                                               # https://medium.com/uruvideo/dataset-augmentation-with-random-homographies-a8f4b44830d4\r\n   635                                           \r\n   636      1024        923.0      0.9      0.0      if targets is None:  # targets = [cls, xyxy]\r\n   637                                                   targets = []\r\n   638      1024       1483.0      1.4      0.1      height = img.shape[0] + border * 2\r\n   639      1024        948.0      0.9      0.0      width = img.shape[1] + border * 2\r\n   640                                           \r\n   641                                               # Rotation and Scale\r\n   642      1024      11823.0     11.5      0.4      R = np.eye(3)\r\n   643      1024       4167.0      4.1      0.2      a = random.uniform(-degrees, degrees)\r\n   644                                               # a += random.choice([-180, -90, 0, 90])  # add 90deg rotations to small rotations\r\n   645      1024       1777.0      1.7      0.1      s = random.uniform(1 - scale, 1 + scale)\r\n   646      1024      11052.0     10.8      0.4      R[:2] = cv2.getRotationMatrix2D(angle=a, center=(img.shape[1] / 2, img.shape[0] / 2), scale=s)\r\n   647                                           \r\n   648                                               # Translation\r\n   649      1024       5681.0      5.5      0.2      T = np.eye(3)\r\n   650      1024       2525.0      2.5      0.1      T[0, 2] = random.uniform(-translate, translate) * img.shape[0] + border  # x translation (pixels)\r\n   651      1024       1617.0      1.6      0.1      T[1, 2] = random.uniform(-translate, translate) * img.shape[1] + border  # y translation (pixels)\r\n   652                                           \r\n   653                                               # Shear\r\n   654      1024       4268.0      4.2      0.2      S = np.eye(3)\r\n   655      1024       3381.0      3.3      0.1      S[0, 1] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # x shear (deg)\r\n   656      1024       1663.0      1.6      0.1      S[1, 0] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # y shear (deg)\r\n   657                                           \r\n   658                                               # Combined rotation matrix\r\n   659      1024      21452.0     20.9      0.8      M = S @ T @ R  # ORDER IS IMPORTANT HERE!!\r\n   660      1024        953.0      0.9      0.0      if (border != 0) or (M != np.eye(3)).any():  # image changed\r\n   661      1024    2464487.0   2406.7     88.8          img = cv2.warpAffine(img, M[:2], dsize=(width, height), flags=cv2.INTER_LINEAR, borderValue=(114, 114, 114))\r\n   662                                           \r\n   663                                               # Transform label coordinates\r\n   664      1024       1843.0      1.8      0.1      n = len(targets)\r\n   665      1024        846.0      0.8      0.0      if n:\r\n   666                                                   # warp points\r\n   667      1024      14153.0     13.8      0.5          xy = np.ones((n * 4, 3))\r\n   668      1024      20811.0     20.3      0.7          xy[:, :2] = targets[:, [1, 2, 3, 4, 1, 4, 3, 2]].reshape(n * 4, 2)  # x1y1, x2y2, x1y2, x2y1\r\n   669      1024      14404.0     14.1      0.5          xy = (xy @ M.T)[:, :2].reshape(n, 8)\r\n   670                                           \r\n   671                                                   # create new boxes\r\n   672      1024       6902.0      6.7      0.2          x = xy[:, [0, 2, 4, 6]]\r\n   673      1024       4465.0      4.4      0.2          y = xy[:, [1, 3, 5, 7]]\r\n   674      1024      33448.0     32.7      1.2          xy = np.concatenate((x.min(1), y.min(1), x.max(1), y.max(1))).reshape(4, n).T\r\n   675                                           \r\n   676                                                   # # apply angle-based reduction of bounding boxes\r\n   677                                                   # radians = a * math.pi / 180\r\n   678                                                   # reduction = max(abs(math.sin(radians)), abs(math.cos(radians))) ** 0.5\r\n   679                                                   # x = (xy[:, 2] + xy[:, 0]) / 2\r\n   680                                                   # y = (xy[:, 3] + xy[:, 1]) / 2\r\n   681                                                   # w = (xy[:, 2] - xy[:, 0]) * reduction\r\n   682                                                   # h = (xy[:, 3] - xy[:, 1]) * reduction\r\n   683                                                   # xy = np.concatenate((x - w / 2, y - h / 2, x + w / 2, y + h / 2)).reshape(4, n).T\r\n   684                                           \r\n   685                                                   # reject warped points outside of image\r\n   686      1024      56307.0     55.0      2.0          xy[:, [0, 2]] = xy[:, [0, 2]].clip(0, width)\r\n   687      1024      37507.0     36.6      1.4          xy[:, [1, 3]] = xy[:, [1, 3]].clip(0, height)\r\n   688      1024       4126.0      4.0      0.1          w = xy[:, 2] - xy[:, 0]\r\n   689      1024       1941.0      1.9      0.1          h = xy[:, 3] - xy[:, 1]\r\n   690      1024       1842.0      1.8      0.1          area = w * h\r\n   691      1024       6666.0      6.5      0.2          area0 = (targets[:, 3] - targets[:, 1]) * (targets[:, 4] - targets[:, 2])\r\n   692      1024       7517.0      7.3      0.3          ar = np.maximum(w / (h + 1e-16), h / (w + 1e-16))  # aspect ratio\r\n   693      1024      13891.0     13.6      0.5          i = (w > 4) & (h > 4) & (area / (area0 + 1e-16) > 0.2) & (ar < 10)\r\n   694                                           \r\n   695      1024       4649.0      4.5      0.2          targets = targets[i]\r\n   696      1024       4707.0      4.6      0.2          targets[:, 1:5] = xy[i]\r\n   697                                           \r\n   698      1024        769.0      0.8      0.0      return img, targets\r\n```","reactions":{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/620759757/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false}},{"id":3281460463,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MzI4MTQ2MDQ2Mw==","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/3281460463","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2020-04-28T17:51:03Z","performed_via_github_app":null},{"id":3281460468,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDMyODE0NjA0Njg=","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/3281460468","actor":{"login":"jveitchmichaelis","id":3159591,"node_id":"MDQ6VXNlcjMxNTk1OTE=","avatar_url":"https://avatars.githubusercontent.com/u/3159591?v=4","gravatar_id":"","url":"https://api.github.com/users/jveitchmichaelis","html_url":"https://github.com/jveitchmichaelis","followers_url":"https://api.github.com/users/jveitchmichaelis/followers","following_url":"https://api.github.com/users/jveitchmichaelis/following{/other_user}","gists_url":"https://api.github.com/users/jveitchmichaelis/gists{/gist_id}","starred_url":"https://api.github.com/users/jveitchmichaelis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jveitchmichaelis/subscriptions","organizations_url":"https://api.github.com/users/jveitchmichaelis/orgs","repos_url":"https://api.github.com/users/jveitchmichaelis/repos","events_url":"https://api.github.com/users/jveitchmichaelis/events{/privacy}","received_events_url":"https://api.github.com/users/jveitchmichaelis/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2020-04-28T17:51:03Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/620773116","html_url":"https://github.com/ultralytics/yolov3/issues/1096#issuecomment-620773116","issue_url":"https://api.github.com/repos/ultralytics/yolov3/issues/1096","id":620773116,"node_id":"MDEyOklzc3VlQ29tbWVudDYyMDc3MzExNg==","user":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false},"created_at":"2020-04-28T18:16:33Z","updated_at":"2020-04-28T18:16:33Z","author_association":"MEMBER","body":"@jveitchmichaelis 15f1343dfc203968b4c048ce7a6c5bd7e2387b13 cleans up the code a bit. I'll try your HSV augment now in the profiler. Ah, awesome, I see a big speedup as well. Load mosaic is about 10% faster now after the commit, though it might just be random effect. \r\n<img width=\"885\" alt=\"Screen Shot 2020-04-28 at 11 13 48 AM\" src=\"https://user-images.githubusercontent.com/26833433/80522408-647cc700-8941-11ea-9102-4d62acc92081.png\">\r\n\r\nOk, so to implement this hsv fix, we can adopt their code, but it looks like their code accepts fixed hsv gains, so we need to use part of the existing function that generates these randomly from the hyps, which is super fast.\r\n<img width=\"829\" alt=\"Screen Shot 2020-04-28 at 10 43 06 AM\" src=\"https://user-images.githubusercontent.com/26833433/80522578-a9086280-8941-11ea-9c84-0bd3fd6ebd46.png\">\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/620773116/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false}}]