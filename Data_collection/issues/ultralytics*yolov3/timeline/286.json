[{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/493664009","html_url":"https://github.com/ultralytics/yolov3/issues/286#issuecomment-493664009","issue_url":"https://api.github.com/repos/ultralytics/yolov3/issues/286","id":493664009,"node_id":"MDEyOklzc3VlQ29tbWVudDQ5MzY2NDAwOQ==","user":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false},"created_at":"2019-05-18T09:49:50Z","updated_at":"2019-05-18T09:49:56Z","author_association":"MEMBER","body":"The counts here are tabulated seperately for bias and batchnorm layers, which are not mentioned in the figure above.","reactions":{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/493664009/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/493667709","html_url":"https://github.com/ultralytics/yolov3/issues/286#issuecomment-493667709","issue_url":"https://api.github.com/repos/ultralytics/yolov3/issues/286","id":493667709,"node_id":"MDEyOklzc3VlQ29tbWVudDQ5MzY2NzcwOQ==","user":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false},"created_at":"2019-05-18T10:49:50Z","updated_at":"2019-05-18T10:49:50Z","author_association":"MEMBER","body":"The PyTorch layer numbers are on the left here, and the darknet layer numbers are in the name column.\r\n\r\n```bash\r\nlayer                                     name  gradient   parameters                shape         mu      sigma\r\n    0                          0.conv_0.weight      True          864        [32, 3, 3, 3]   -0.00339     0.0648\r\n    1                    0.batch_norm_0.weight      True           32                 [32]      0.987       1.07\r\n    2                      0.batch_norm_0.bias      True           32                 [32]     -0.698       2.07\r\n    3                          1.conv_1.weight      True        18432       [64, 32, 3, 3]   0.000298     0.0177\r\n    4                    1.batch_norm_1.weight      True           64                 [64]       0.88      0.389\r\n    5                      1.batch_norm_1.bias      True           64                 [64]     -0.409       1.01\r\n    6                          2.conv_2.weight      True         2048       [32, 64, 1, 1]   -0.00301     0.0306\r\n    7                    2.batch_norm_2.weight      True           32                 [32]      0.895      0.327\r\n    8                      2.batch_norm_2.bias      True           32                 [32]      -0.37      0.752\r\n    9                          3.conv_3.weight      True        18432       [64, 32, 3, 3]  -0.000943     0.0163\r\n   10                    3.batch_norm_3.weight      True           64                 [64]      0.912      0.923\r\n   11                      3.batch_norm_3.bias      True           64                 [64]     -0.477      0.534\r\n   12                          5.conv_5.weight      True        73728      [128, 64, 3, 3]  -0.000371     0.0137\r\n   13                    5.batch_norm_5.weight      True          128                [128]       1.03      0.338\r\n   14                      5.batch_norm_5.bias      True          128                [128]    -0.0887      0.888\r\n   15                          6.conv_6.weight      True         8192      [64, 128, 1, 1]   0.000322     0.0126\r\n   16                    6.batch_norm_6.weight      True           64                 [64]      0.571      0.218\r\n   17                      6.batch_norm_6.bias      True           64                 [64]     -0.397      0.829\r\n   18                          7.conv_7.weight      True        73728      [128, 64, 3, 3]  -0.000418    0.00752\r\n   19                    7.batch_norm_7.weight      True          128                [128]      0.429      0.456\r\n   20                      7.batch_norm_7.bias      True          128                [128]     -0.362      0.552\r\n   21                          9.conv_9.weight      True         8192      [64, 128, 1, 1]   -0.00196     0.0213\r\n   22                    9.batch_norm_9.weight      True           64                 [64]      0.902      0.308\r\n   23                      9.batch_norm_9.bias      True           64                 [64]     -0.392      0.442\r\n   24                        10.conv_10.weight      True        73728      [128, 64, 3, 3]  -0.000514     0.0108\r\n   25                  10.batch_norm_10.weight      True          128                [128]       0.94      0.629\r\n   26                    10.batch_norm_10.bias      True          128                [128]     -0.571      0.423\r\n   27                        12.conv_12.weight      True       294912     [256, 128, 3, 3]  -0.000328     0.0101\r\n   28                  12.batch_norm_12.weight      True          256                [256]      0.965      0.348\r\n   29                    12.batch_norm_12.bias      True          256                [256]       -0.1      0.741\r\n   30                        13.conv_13.weight      True        32768     [128, 256, 1, 1]  -3.11e-05    0.00793\r\n   31                  13.batch_norm_13.weight      True          128                [128]      0.683      0.297\r\n   32                    13.batch_norm_13.bias      True          128                [128]     -0.352        0.6\r\n   33                        14.conv_14.weight      True       294912     [256, 128, 3, 3]  -0.000135    0.00368\r\n   34                  14.batch_norm_14.weight      True          256                [256]       0.23      0.348\r\n   35                    14.batch_norm_14.bias      True          256                [256]     -0.464      0.328\r\n   36                        16.conv_16.weight      True        32768     [128, 256, 1, 1]  -0.000212       0.01\r\n   37                  16.batch_norm_16.weight      True          128                [128]      0.876      0.206\r\n   38                    16.batch_norm_16.bias      True          128                [128]     -0.337      0.307\r\n   39                        17.conv_17.weight      True       294912     [256, 128, 3, 3]  -0.000162    0.00487\r\n   40                  17.batch_norm_17.weight      True          256                [256]      0.412      0.301\r\n   41                    17.batch_norm_17.bias      True          256                [256]      -0.45       0.28\r\n   42                        19.conv_19.weight      True        32768     [128, 256, 1, 1]   -0.00077     0.0119\r\n   43                  19.batch_norm_19.weight      True          128                [128]      0.835      0.192\r\n   44                    19.batch_norm_19.bias      True          128                [128]     -0.408      0.375\r\n   45                        20.conv_20.weight      True       294912     [256, 128, 3, 3]  -0.000226    0.00547\r\n   46                  20.batch_norm_20.weight      True          256                [256]      0.533      0.402\r\n   47                    20.batch_norm_20.bias      True          256                [256]     -0.575       0.25\r\n   48                        22.conv_22.weight      True        32768     [128, 256, 1, 1]  -0.000538     0.0117\r\n   49                  22.batch_norm_22.weight      True          128                [128]      0.879      0.163\r\n   50                    22.batch_norm_22.bias      True          128                [128]     -0.364      0.308\r\n   51                        23.conv_23.weight      True       294912     [256, 128, 3, 3]   -0.00019    0.00565\r\n   52                  23.batch_norm_23.weight      True          256                [256]      0.544      0.402\r\n   53                    23.batch_norm_23.bias      True          256                [256]     -0.624      0.249\r\n   54                        25.conv_25.weight      True        32768     [128, 256, 1, 1]  -0.000797     0.0129\r\n   55                  25.batch_norm_25.weight      True          128                [128]      0.826      0.161\r\n   56                    25.batch_norm_25.bias      True          128                [128]     -0.446      0.346\r\n   57                        26.conv_26.weight      True       294912     [256, 128, 3, 3]  -0.000427      0.006\r\n   58                  26.batch_norm_26.weight      True          256                [256]      0.725      0.392\r\n   59                    26.batch_norm_26.bias      True          256                [256]     -0.744      0.257\r\n   60                        28.conv_28.weight      True        32768     [128, 256, 1, 1]  -0.000794     0.0131\r\n   61                  28.batch_norm_28.weight      True          128                [128]      0.831      0.143\r\n   62                    28.batch_norm_28.bias      True          128                [128]     -0.416      0.383\r\n   63                        29.conv_29.weight      True       294912     [256, 128, 3, 3]  -0.000323    0.00593\r\n   64                  29.batch_norm_29.weight      True          256                [256]      0.754      0.478\r\n   65                    29.batch_norm_29.bias      True          256                [256]      -0.73      0.276\r\n   66                        31.conv_31.weight      True        32768     [128, 256, 1, 1]   -0.00116     0.0142\r\n   67                  31.batch_norm_31.weight      True          128                [128]      0.768      0.159\r\n   68                    31.batch_norm_31.bias      True          128                [128]     -0.546      0.368\r\n   69                        32.conv_32.weight      True       294912     [256, 128, 3, 3]  -0.000317    0.00606\r\n   70                  32.batch_norm_32.weight      True          256                [256]      0.842      0.468\r\n   71                    32.batch_norm_32.bias      True          256                [256]     -0.711      0.225\r\n   72                        34.conv_34.weight      True        32768     [128, 256, 1, 1]   -0.00119     0.0127\r\n   73                  34.batch_norm_34.weight      True          128                [128]      0.866      0.113\r\n   74                    34.batch_norm_34.bias      True          128                [128]     -0.294      0.423\r\n   75                        35.conv_35.weight      True       294912     [256, 128, 3, 3]  -0.000133    0.00557\r\n   76                  35.batch_norm_35.weight      True          256                [256]      0.843      0.581\r\n   77                    35.batch_norm_35.bias      True          256                [256]     -0.672      0.218\r\n   78                        37.conv_37.weight      True  1.17965e+06     [512, 256, 3, 3]  -0.000165    0.00683\r\n   79                  37.batch_norm_37.weight      True          512                [512]       1.12      0.293\r\n   80                    37.batch_norm_37.bias      True          512                [512]     -0.727      0.579\r\n   81                        38.conv_38.weight      True       131072     [256, 512, 1, 1]  -0.000107    0.00573\r\n   82                  38.batch_norm_38.weight      True          256                [256]      0.942      0.149\r\n   83                    38.batch_norm_38.bias      True          256                [256]    -0.0305      0.316\r\n   84                        39.conv_39.weight      True  1.17965e+06     [512, 256, 3, 3]  -4.88e-05    0.00244\r\n   85                  39.batch_norm_39.weight      True          512                [512]      0.232      0.392\r\n   86                    39.batch_norm_39.bias      True          512                [512]     -0.543      0.206\r\n   87                        41.conv_41.weight      True       131072     [256, 512, 1, 1]  -0.000329     0.0062\r\n   88                  41.batch_norm_41.weight      True          256                [256]      0.887      0.175\r\n   89                    41.batch_norm_41.bias      True          256                [256]     -0.312       0.32\r\n   90                        42.conv_42.weight      True  1.17965e+06     [512, 256, 3, 3]  -5.83e-05     0.0032\r\n   91                  42.batch_norm_42.weight      True          512                [512]      0.446       0.39\r\n   92                    42.batch_norm_42.bias      True          512                [512]     -0.591      0.229\r\n   93                        44.conv_44.weight      True       131072     [256, 512, 1, 1]  -0.000549    0.00837\r\n   94                  44.batch_norm_44.weight      True          256                [256]      0.703      0.127\r\n   95                    44.batch_norm_44.bias      True          256                [256]     -0.666      0.288\r\n   96                        45.conv_45.weight      True  1.17965e+06     [512, 256, 3, 3]  -0.000209      0.004\r\n   97                  45.batch_norm_45.weight      True          512                [512]      0.539      0.343\r\n   98                    45.batch_norm_45.bias      True          512                [512]     -0.599      0.217\r\n   99                        47.conv_47.weight      True       131072     [256, 512, 1, 1]   -0.00087    0.00907\r\n  100                  47.batch_norm_47.weight      True          256                [256]      0.741      0.143\r\n  101                    47.batch_norm_47.bias      True          256                [256]     -0.576      0.373\r\n  102                        48.conv_48.weight      True  1.17965e+06     [512, 256, 3, 3]  -0.000128    0.00413\r\n  103                  48.batch_norm_48.weight      True          512                [512]      0.591      0.286\r\n  104                    48.batch_norm_48.bias      True          512                [512]     -0.698      0.197\r\n  105                        50.conv_50.weight      True       131072     [256, 512, 1, 1]  -0.000895    0.00897\r\n  106                  50.batch_norm_50.weight      True          256                [256]      0.747      0.123\r\n  107                    50.batch_norm_50.bias      True          256                [256]     -0.608      0.281\r\n  108                        51.conv_51.weight      True  1.17965e+06     [512, 256, 3, 3]  -0.000171    0.00397\r\n  109                  51.batch_norm_51.weight      True          512                [512]      0.611      0.379\r\n  110                    51.batch_norm_51.bias      True          512                [512]     -0.727      0.212\r\n  111                        53.conv_53.weight      True       131072     [256, 512, 1, 1]  -0.000844    0.00956\r\n  112                  53.batch_norm_53.weight      True          256                [256]      0.658      0.103\r\n  113                    53.batch_norm_53.bias      True          256                [256]     -0.729      0.244\r\n  114                        54.conv_54.weight      True  1.17965e+06     [512, 256, 3, 3]  -0.000186    0.00426\r\n  115                  54.batch_norm_54.weight      True          512                [512]      0.695      0.326\r\n  116                    54.batch_norm_54.bias      True          512                [512]     -0.698      0.196\r\n  117                        56.conv_56.weight      True       131072     [256, 512, 1, 1]  -0.000739     0.0082\r\n  118                  56.batch_norm_56.weight      True          256                [256]      0.911     0.0725\r\n  119                    56.batch_norm_56.bias      True          256                [256]     -0.373      0.176\r\n  120                        57.conv_57.weight      True  1.17965e+06     [512, 256, 3, 3]  -0.000133    0.00355\r\n  121                  57.batch_norm_57.weight      True          512                [512]      0.603      0.454\r\n  122                    57.batch_norm_57.bias      True          512                [512]     -0.679      0.189\r\n  123                        59.conv_59.weight      True       131072     [256, 512, 1, 1]   -0.00104     0.0104\r\n  124                  59.batch_norm_59.weight      True          256                [256]      0.731     0.0927\r\n  125                    59.batch_norm_59.bias      True          256                [256]     -0.631      0.275\r\n  126                        60.conv_60.weight      True  1.17965e+06     [512, 256, 3, 3]  -5.31e-05    0.00411\r\n  127                  60.batch_norm_60.weight      True          512                [512]      0.765       0.36\r\n  128                    60.batch_norm_60.bias      True          512                [512]     -0.653       0.17\r\n  129                        62.conv_62.weight      True  4.71859e+06    [1024, 512, 3, 3]  -0.000182    0.00485\r\n  130                  62.batch_norm_62.weight      True         1024               [1024]      0.969      0.258\r\n  131                    62.batch_norm_62.bias      True         1024               [1024]     -0.968      0.393\r\n  132                        63.conv_63.weight      True       524288    [512, 1024, 1, 1]  -0.000384    0.00566\r\n  133                  63.batch_norm_63.weight      True          512                [512]      0.821      0.216\r\n  134                    63.batch_norm_63.bias      True          512                [512]      -0.43      0.337\r\n  135                        64.conv_64.weight      True  4.71859e+06    [1024, 512, 3, 3]  -8.66e-05    0.00278\r\n  136                  64.batch_norm_64.weight      True         1024               [1024]      0.386      0.303\r\n  137                    64.batch_norm_64.bias      True         1024               [1024]     -0.449      0.211\r\n  138                        66.conv_66.weight      True       524288    [512, 1024, 1, 1]  -0.000645    0.00721\r\n  139                  66.batch_norm_66.weight      True          512                [512]      0.659      0.112\r\n  140                    66.batch_norm_66.bias      True          512                [512]     -0.743      0.276\r\n  141                        67.conv_67.weight      True  4.71859e+06    [1024, 512, 3, 3]  -7.31e-05    0.00334\r\n  142                  67.batch_norm_67.weight      True         1024               [1024]       0.51      0.289\r\n  143                    67.batch_norm_67.bias      True         1024               [1024]     -0.586      0.196\r\n  144                        69.conv_69.weight      True       524288    [512, 1024, 1, 1]  -0.000693    0.00694\r\n  145                  69.batch_norm_69.weight      True          512                [512]      0.708        0.1\r\n  146                    69.batch_norm_69.bias      True          512                [512]     -0.684      0.254\r\n  147                        70.conv_70.weight      True  4.71859e+06    [1024, 512, 3, 3]  -7.92e-05    0.00305\r\n  148                  70.batch_norm_70.weight      True         1024               [1024]        0.5      0.373\r\n  149                    70.batch_norm_70.bias      True         1024               [1024]     -0.622      0.214\r\n  150                        72.conv_72.weight      True       524288    [512, 1024, 1, 1]  -0.000817    0.00957\r\n  151                  72.batch_norm_72.weight      True          512                [512]       0.67      0.111\r\n  152                    72.batch_norm_72.bias      True          512                [512]     -0.857      0.347\r\n  153                        73.conv_73.weight      True  4.71859e+06    [1024, 512, 3, 3]  -6.56e-05    0.00375\r\n  154                  73.batch_norm_73.weight      True         1024               [1024]      0.848      0.295\r\n  155                    73.batch_norm_73.bias      True         1024               [1024]      -0.82      0.289\r\n  156                        75.conv_75.weight      True       524288    [512, 1024, 1, 1]   2.47e-05      0.018\r\n  157                  75.batch_norm_75.weight      True          512                [512]      0.516      0.288\r\n  158                    75.batch_norm_75.bias      True          512                [512]          0          0\r\n  159                        76.conv_76.weight      True  4.71859e+06    [1024, 512, 3, 3]    2.8e-06     0.0085\r\n  160                  76.batch_norm_76.weight      True         1024               [1024]      0.511       0.29\r\n  161                    76.batch_norm_76.bias      True         1024               [1024]          0          0\r\n  162                        77.conv_77.weight      True       524288    [512, 1024, 1, 1]  -4.85e-05      0.018\r\n  163                  77.batch_norm_77.weight      True          512                [512]      0.495      0.289\r\n  164                    77.batch_norm_77.bias      True          512                [512]          0          0\r\n  165                        84.conv_84.weight      True  1.04858e+06    [512, 2048, 1, 1]  -7.37e-06     0.0128\r\n  166                  84.batch_norm_84.weight      True          512                [512]      0.494      0.295\r\n  167                    84.batch_norm_84.bias      True          512                [512]          0          0\r\n  168                        85.conv_85.weight      True  4.71859e+06    [1024, 512, 3, 3]   2.85e-07    0.00851\r\n  169                  85.batch_norm_85.weight      True         1024               [1024]      0.503      0.289\r\n  170                    85.batch_norm_85.bias      True         1024               [1024]          0          0\r\n  171                        86.conv_86.weight      True       524288    [512, 1024, 1, 1]    9.5e-06     0.0181\r\n  172                  86.batch_norm_86.weight      True          512                [512]      0.502      0.288\r\n  173                    86.batch_norm_86.bias      True          512                [512]          0          0\r\n  174                        87.conv_87.weight      True  4.71859e+06    [1024, 512, 3, 3]  -4.67e-06     0.0085\r\n  175                  87.batch_norm_87.weight      True         1024               [1024]      0.483      0.281\r\n  176                    87.batch_norm_87.bias      True         1024               [1024]          0          0\r\n  177                        88.conv_88.weight      True       261120    [255, 1024, 1, 1]   2.81e-05      0.018\r\n  178                          88.conv_88.bias      True          255                [255]    0.00152     0.0178\r\n  179                        91.conv_91.weight      True       131072     [256, 512, 1, 1]  -0.000111     0.0255\r\n  180                  91.batch_norm_91.weight      True          256                [256]      0.483      0.292\r\n  181                    91.batch_norm_91.bias      True          256                [256]          0          0\r\n  182                        94.conv_94.weight      True       196608     [256, 768, 1, 1]  -5.67e-05     0.0209\r\n  183                  94.batch_norm_94.weight      True          256                [256]      0.526      0.287\r\n  184                    94.batch_norm_94.bias      True          256                [256]          0          0\r\n  185                        95.conv_95.weight      True  1.17965e+06     [512, 256, 3, 3]   5.19e-06      0.012\r\n  186                  95.batch_norm_95.weight      True          512                [512]      0.496      0.297\r\n  187                    95.batch_norm_95.bias      True          512                [512]          0          0\r\n  188                        96.conv_96.weight      True       131072     [256, 512, 1, 1]  -8.48e-05     0.0255\r\n  189                  96.batch_norm_96.weight      True          256                [256]      0.512      0.297\r\n  190                    96.batch_norm_96.bias      True          256                [256]          0          0\r\n  191                        97.conv_97.weight      True  1.17965e+06     [512, 256, 3, 3]  -6.41e-06      0.012\r\n  192                  97.batch_norm_97.weight      True          512                [512]      0.485       0.29\r\n  193                    97.batch_norm_97.bias      True          512                [512]          0          0\r\n  194                        98.conv_98.weight      True       131072     [256, 512, 1, 1]   6.35e-05     0.0255\r\n  195                  98.batch_norm_98.weight      True          256                [256]      0.457      0.294\r\n  196                    98.batch_norm_98.bias      True          256                [256]          0          0\r\n  197                        99.conv_99.weight      True  1.17965e+06     [512, 256, 3, 3]   4.49e-06      0.012\r\n  198                  99.batch_norm_99.weight      True          512                [512]      0.516      0.289\r\n  199                    99.batch_norm_99.bias      True          512                [512]          0          0\r\n  200                      100.conv_100.weight      True       130560     [255, 512, 1, 1]   6.23e-05     0.0255\r\n  201                        100.conv_100.bias      True          255                [255]     0.0015     0.0249\r\n  202                      103.conv_103.weight      True        32768     [128, 256, 1, 1]   0.000166     0.0362\r\n  203                103.batch_norm_103.weight      True          128                [128]      0.511      0.272\r\n  204                  103.batch_norm_103.bias      True          128                [128]          0          0\r\n  205                      106.conv_106.weight      True        49152     [128, 384, 1, 1]   0.000104     0.0295\r\n  206                106.batch_norm_106.weight      True          128                [128]      0.513      0.286\r\n  207                  106.batch_norm_106.bias      True          128                [128]          0          0\r\n  208                      107.conv_107.weight      True       294912     [256, 128, 3, 3]   3.11e-05      0.017\r\n  209                107.batch_norm_107.weight      True          256                [256]      0.501      0.289\r\n  210                  107.batch_norm_107.bias      True          256                [256]          0          0\r\n  211                      108.conv_108.weight      True        32768     [128, 256, 1, 1]   6.87e-05     0.0361\r\n  212                108.batch_norm_108.weight      True          128                [128]      0.483      0.294\r\n  213                  108.batch_norm_108.bias      True          128                [128]          0          0\r\n  214                      109.conv_109.weight      True       294912     [256, 128, 3, 3]   2.05e-05      0.017\r\n  215                109.batch_norm_109.weight      True          256                [256]      0.523      0.291\r\n  216                  109.batch_norm_109.bias      True          256                [256]          0          0\r\n  217                      110.conv_110.weight      True        32768     [128, 256, 1, 1]  -0.000212     0.0362\r\n  218                110.batch_norm_110.weight      True          128                [128]      0.508      0.296\r\n  219                  110.batch_norm_110.bias      True          128                [128]          0          0\r\n  220                      111.conv_111.weight      True       294912     [256, 128, 3, 3]   1.69e-05      0.017\r\n  221                111.batch_norm_111.weight      True          256                [256]      0.491      0.281\r\n  222                  111.batch_norm_111.bias      True          256                [256]          0          0\r\n  223                      112.conv_112.weight      True        65280     [255, 256, 1, 1]   0.000119     0.0362\r\n  224                        112.conv_112.bias      True          255                [255]  -0.000773     0.0356\r\nModel Summary: 225 layers, 6.29987e+07 parameters, 6.29987e+07 gradients\r\n```","reactions":{"url":"https://api.github.com/repos/ultralytics/yolov3/issues/comments/493667709/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false}},{"id":2355776960,"node_id":"MDExOkNsb3NlZEV2ZW50MjM1NTc3Njk2MA==","url":"https://api.github.com/repos/ultralytics/yolov3/issues/events/2355776960","actor":{"login":"glenn-jocher","id":26833433,"node_id":"MDQ6VXNlcjI2ODMzNDMz","avatar_url":"https://avatars.githubusercontent.com/u/26833433?v=4","gravatar_id":"","url":"https://api.github.com/users/glenn-jocher","html_url":"https://github.com/glenn-jocher","followers_url":"https://api.github.com/users/glenn-jocher/followers","following_url":"https://api.github.com/users/glenn-jocher/following{/other_user}","gists_url":"https://api.github.com/users/glenn-jocher/gists{/gist_id}","starred_url":"https://api.github.com/users/glenn-jocher/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/glenn-jocher/subscriptions","organizations_url":"https://api.github.com/users/glenn-jocher/orgs","repos_url":"https://api.github.com/users/glenn-jocher/repos","events_url":"https://api.github.com/users/glenn-jocher/events{/privacy}","received_events_url":"https://api.github.com/users/glenn-jocher/received_events","type":"User","site_admin":false},"event":"closed","commit_id":null,"commit_url":null,"created_at":"2019-05-21T11:03:19Z","state_reason":null,"performed_via_github_app":null}]