{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/178","repository_url":"https://api.github.com/repos/sksq96/pytorch-summary","labels_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/178/labels{/name}","comments_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/178/comments","events_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/178/events","html_url":"https://github.com/sksq96/pytorch-summary/issues/178","id":1048417401,"node_id":"I_kwDOB8pl4c4-fZR5","number":178,"title":"Dividing model over multiple gpus in pytorch.","user":{"login":"sreenithakasarapu","id":62122163,"node_id":"MDQ6VXNlcjYyMTIyMTYz","avatar_url":"https://avatars.githubusercontent.com/u/62122163?v=4","gravatar_id":"","url":"https://api.github.com/users/sreenithakasarapu","html_url":"https://github.com/sreenithakasarapu","followers_url":"https://api.github.com/users/sreenithakasarapu/followers","following_url":"https://api.github.com/users/sreenithakasarapu/following{/other_user}","gists_url":"https://api.github.com/users/sreenithakasarapu/gists{/gist_id}","starred_url":"https://api.github.com/users/sreenithakasarapu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sreenithakasarapu/subscriptions","organizations_url":"https://api.github.com/users/sreenithakasarapu/orgs","repos_url":"https://api.github.com/users/sreenithakasarapu/repos","events_url":"https://api.github.com/users/sreenithakasarapu/events{/privacy}","received_events_url":"https://api.github.com/users/sreenithakasarapu/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-11-09T10:08:58Z","updated_at":"2022-02-23T21:17:09Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"\r\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0! (when checking arugment for argument target in method wrapper_nll_loss_forward)\r\n\r\n\r\nfrom torchvision.models.resnet import ResNet, Bottleneck\r\nimport torch.nn as nn\r\nnum_classes = 2\r\n\r\n\r\nclass CNN(ResNet):\r\n    def __init__(self, *args, **kwargs):\r\n        super(CNN, self).__init__(\r\n            Bottleneck, [3, 4, 6, 3], num_classes=num_classes, *args, **kwargs)\r\n\r\n        self.seq1 = nn.Sequential(\r\n            self.conv1,\r\n            self.bn1,\r\n            self.relu,\r\n            self.maxpool,\r\n\r\n            self.layer1,\r\n            self.layer2\r\n        ).to('cuda:0')\r\n\r\n        self.seq2 = nn.Sequential(\r\n            self.layer3,\r\n            self.layer4,\r\n            self.avgpool,\r\n        ).to('cuda:1')\r\n        \r\n        \r\n\r\n        self.fc.to('cuda:1')\r\n\r\n    def forward(self, x):\r\n        x = self.seq2(self.seq1(x).to('cuda:1'))\r\n        return self.fc(x.view(x.size(0), -1))\r\n\r\nfrom torch.autograd import Variable\r\nnum_epochs = 10\r\ndef train(num_epochs, cnn, loaders):\r\n    \r\n    cnn.train()\r\n        \r\n    # Train the model\r\n    total_step = len(loaders['train'])\r\n        \r\n    for epoch in range(num_epochs):\r\n        for i, (images, labels) in enumerate(loaders['train']):\r\n            \r\n            # gives batch data, normalize x when iterate train_loader\r\n            b_x =  Variable(images).to('cuda:0')    # batch x\r\n            b_y = Variable(labels).to('cuda:0')   # batch y\r\n            output = cnn(images.to('cuda:0'))  \r\n            \r\n            loss = loss_func(output, b_y).to('cuda:1')  \r\n            \r\n            print(loss)\r\n            \r\n            # clear gradients for this training step   \r\n            optimizer.zero_grad()           \r\n            \r\n            # backpropagation, compute gradients \r\n            loss.backward()    \r\n            # apply gradients             \r\n            optimizer.step()                \r\n            \r\n            if (i+1) % 100 == 0:\r\n                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\r\n                pass\r\n        \r\n            pass\r\n    \r\n    \r\n        pass\r\ntrain(num_epochs, cnn, loaders)","closed_by":null,"reactions":{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/178/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/178/timeline","performed_via_github_app":null,"state_reason":null}