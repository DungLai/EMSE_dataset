{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/138","repository_url":"https://api.github.com/repos/sksq96/pytorch-summary","labels_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/138/labels{/name}","comments_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/138/comments","events_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/138/events","html_url":"https://github.com/sksq96/pytorch-summary/issues/138","id":652916881,"node_id":"MDU6SXNzdWU2NTI5MTY4ODE=","number":138,"title":"Error occured When module output is List or OrderedDict","user":{"login":"BriFuture","id":7582298,"node_id":"MDQ6VXNlcjc1ODIyOTg=","avatar_url":"https://avatars.githubusercontent.com/u/7582298?v=4","gravatar_id":"","url":"https://api.github.com/users/BriFuture","html_url":"https://github.com/BriFuture","followers_url":"https://api.github.com/users/BriFuture/followers","following_url":"https://api.github.com/users/BriFuture/following{/other_user}","gists_url":"https://api.github.com/users/BriFuture/gists{/gist_id}","starred_url":"https://api.github.com/users/BriFuture/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/BriFuture/subscriptions","organizations_url":"https://api.github.com/users/BriFuture/orgs","repos_url":"https://api.github.com/users/BriFuture/repos","events_url":"https://api.github.com/users/BriFuture/events{/privacy}","received_events_url":"https://api.github.com/users/BriFuture/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-07-08T03:58:52Z","updated_at":"2020-07-08T03:58:52Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Version: torchsummary 1.5.1\r\n\r\nWhen custom neuron network contains \r\n1. nn.Module such as `torchvision.ops.feature_pyramid_network.LeastLevelMaxPool`  which returns a **list** from `forward` \r\n2. or ModuleDict sucha as `torchvision.models._utils.IntermediateLayerGetter` which returns a **OrderedDict** from `forward` \r\n\r\nError occured such as **List** has no attribute `size` or **OrderedDict** has no attribute `size`.\r\n\r\nCould these two types be added into the hook function?\r\n\r\nI modified the hook funciton as follows to avoid **List** or **OrderedDict**  object causing the error:\r\n```py\r\n        def hook(module, input, output):\r\n            class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\r\n            module_idx = len(summary)\r\n\r\n            m_key = \"%s-%i\" % (class_name, module_idx + 1)\r\n            summary[m_key] = OrderedDict()\r\n\r\n            try:\r\n                summary[m_key][\"input_shape\"] = list(input[0].size())\r\n            except:\r\n                summary[m_key][\"input_shape\"] = list((0, 0, 0))\r\n            summary[m_key][\"input_shape\"][0] = batch_size\r\n                \r\n            if isinstance(output, (list, tuple)):\r\n                try:\r\n                    summary[m_key][\"output_shape\"] = [\r\n                        [-1] + list(o.size())[1:] for o in output\r\n                    ]\r\n                except:\r\n                    summary[m_key][\"output_shape\"] = [\r\n                        [-1, 0, 0, 0] for o in output\r\n                    ]\r\n            elif isinstance(output, (OrderedDict,)):\r\n                summary[m_key][\"output_shape\"] = [\r\n                    [-1] + list(o.size())[1:] for _, o in output.items()\r\n                ]\r\n            else:\r\n                summary[m_key][\"output_shape\"] = list(output.size())\r\n                summary[m_key][\"output_shape\"][0] = batch_size\r\n\r\n            params = 0\r\n            if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\r\n                params += torch.prod(torch.LongTensor(list(module.weight.size())))\r\n                summary[m_key][\"trainable\"] = module.weight.requires_grad\r\n            if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\r\n                params += torch.prod(torch.LongTensor(list(module.bias.size())))\r\n            summary[m_key][\"nb_params\"] = params\r\n\r\n        if (\r\n            not isinstance(module, nn.Sequential)\r\n            and not isinstance(module, nn.ModuleList)\r\n            and not (module == model)\r\n        ):\r\n            hooks.append(module.register_forward_hook(hook))\r\n\r\n```\r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/138/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/138/timeline","performed_via_github_app":null,"state_reason":null}