{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/143","repository_url":"https://api.github.com/repos/sksq96/pytorch-summary","labels_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/143/labels{/name}","comments_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/143/comments","events_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/143/events","html_url":"https://github.com/sksq96/pytorch-summary/issues/143","id":682395581,"node_id":"MDU6SXNzdWU2ODIzOTU1ODE=","number":143,"title":"LSTM cannot be used","user":{"login":"z-a-f","id":4216323,"node_id":"MDQ6VXNlcjQyMTYzMjM=","avatar_url":"https://avatars.githubusercontent.com/u/4216323?v=4","gravatar_id":"","url":"https://api.github.com/users/z-a-f","html_url":"https://github.com/z-a-f","followers_url":"https://api.github.com/users/z-a-f/followers","following_url":"https://api.github.com/users/z-a-f/following{/other_user}","gists_url":"https://api.github.com/users/z-a-f/gists{/gist_id}","starred_url":"https://api.github.com/users/z-a-f/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/z-a-f/subscriptions","organizations_url":"https://api.github.com/users/z-a-f/orgs","repos_url":"https://api.github.com/users/z-a-f/repos","events_url":"https://api.github.com/users/z-a-f/events{/privacy}","received_events_url":"https://api.github.com/users/z-a-f/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-08-20T04:08:03Z","updated_at":"2020-08-20T04:08:03Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"If a model has an LSTM, this fails. I guess this is related to #130.\r\n\r\nMinimum failing example:\r\n\r\n```python\r\nclass Model(nn.Module):\r\n    def __init__(self):\r\n        super(Model, self).__init__()\r\n        self.lstm = nn.LSTM(5, 5)\r\n        \r\n    def forward(self, x):\r\n        return self.lstm(x)\r\n    \r\nmodel = Model()\r\nsummary(model, (3, 5), device='cpu')\r\n```\r\n\r\nthrows an error:\r\n\r\n```console\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-87-26dd936cf377> in <module>\r\n      8 \r\n      9 model = Model()\r\n---> 10 summary(model, (3, 5), device='cpu')\r\n\r\n~/miniconda3/envs/pytorch-dev/lib/python3.6/site-packages/torchsummary/torchsummary.py in summary(model, input_size, batch_size, device)\r\n     70     # make a forward pass\r\n     71     # print(x.shape)\r\n---> 72     model(*x)\r\n     73 \r\n     74     # remove these hooks\r\n\r\n~/Git/pytorch-dev/pytorch/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\r\n    725             result = self._slow_forward(*input, **kwargs)\r\n    726         else:\r\n--> 727             result = self.forward(*input, **kwargs)\r\n    728         for hook in itertools.chain(\r\n    729                 _global_forward_hooks.values(),\r\n\r\n<ipython-input-87-26dd936cf377> in forward(self, x)\r\n      5 \r\n      6     def forward(self, x):\r\n----> 7         return self.lstm(x)\r\n      8 \r\n      9 model = Model()\r\n\r\n~/Git/pytorch-dev/pytorch/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\r\n    729                 _global_forward_hooks.values(),\r\n    730                 self._forward_hooks.values()):\r\n--> 731             hook_result = hook(self, input, result)\r\n    732             if hook_result is not None:\r\n    733                 result = hook_result\r\n\r\n~/miniconda3/envs/pytorch-dev/lib/python3.6/site-packages/torchsummary/torchsummary.py in hook(module, input, output)\r\n     21             if isinstance(output, (list, tuple)):\r\n     22                 summary[m_key][\"output_shape\"] = [\r\n---> 23                     [-1] + list(o.size())[1:] for o in output\r\n     24                 ]\r\n     25             else:\r\n\r\n~/miniconda3/envs/pytorch-dev/lib/python3.6/site-packages/torchsummary/torchsummary.py in <listcomp>(.0)\r\n     21             if isinstance(output, (list, tuple)):\r\n     22                 summary[m_key][\"output_shape\"] = [\r\n---> 23                     [-1] + list(o.size())[1:] for o in output\r\n     24                 ]\r\n     25             else:\r\n\r\nAttributeError: 'tuple' object has no attribute 'size'\r\n```","closed_by":null,"reactions":{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/143/reactions","total_count":3,"+1":3,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/143/timeline","performed_via_github_app":null,"state_reason":null}