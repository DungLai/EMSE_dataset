{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/77","repository_url":"https://api.github.com/repos/sksq96/pytorch-summary","labels_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/77/labels{/name}","comments_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/77/comments","events_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/77/events","html_url":"https://github.com/sksq96/pytorch-summary/issues/77","id":461315666,"node_id":"MDU6SXNzdWU0NjEzMTU2NjY=","number":77,"title":"input in Long type","user":{"login":"sungjchi","id":36436717,"node_id":"MDQ6VXNlcjM2NDM2NzE3","avatar_url":"https://avatars.githubusercontent.com/u/36436717?v=4","gravatar_id":"","url":"https://api.github.com/users/sungjchi","html_url":"https://github.com/sungjchi","followers_url":"https://api.github.com/users/sungjchi/followers","following_url":"https://api.github.com/users/sungjchi/following{/other_user}","gists_url":"https://api.github.com/users/sungjchi/gists{/gist_id}","starred_url":"https://api.github.com/users/sungjchi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sungjchi/subscriptions","organizations_url":"https://api.github.com/users/sungjchi/orgs","repos_url":"https://api.github.com/users/sungjchi/repos","events_url":"https://api.github.com/users/sungjchi/events{/privacy}","received_events_url":"https://api.github.com/users/sungjchi/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2019-06-27T05:03:14Z","updated_at":"2022-02-17T06:11:47Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"My model has an input in Long dtype which is passed to an torch.nn.Embedding layer. Since all the input data are created in torch.FloatTensor type, it creates runtime error when these inputs are passed to an embedding layer. Should there be an argument to choose which data type to pass to inputs?\r\n\r\nIn the code below, the third input is passed through an embedding layer and thus cause a runtime error.\r\n\r\n`(Pdb) summary(m,[(170,),(800,80),(170,),(800,)])`\r\n`*** RuntimeError: Expected tensor for argument #1 'indices' to have scalar type Long; but got CUDAType instead (while checking arguments for embedding)\r\n`","closed_by":null,"reactions":{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/77/reactions","total_count":4,"+1":4,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/77/timeline","performed_via_github_app":null,"state_reason":null}