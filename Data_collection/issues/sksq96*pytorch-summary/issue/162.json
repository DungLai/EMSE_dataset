{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/162","repository_url":"https://api.github.com/repos/sksq96/pytorch-summary","labels_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/162/labels{/name}","comments_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/162/comments","events_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/162/events","html_url":"https://github.com/sksq96/pytorch-summary/issues/162","id":801755642,"node_id":"MDU6SXNzdWU4MDE3NTU2NDI=","number":162,"title":"Cannot get the summary","user":{"login":"GuoQuanhao","id":49911294,"node_id":"MDQ6VXNlcjQ5OTExMjk0","avatar_url":"https://avatars.githubusercontent.com/u/49911294?v=4","gravatar_id":"","url":"https://api.github.com/users/GuoQuanhao","html_url":"https://github.com/GuoQuanhao","followers_url":"https://api.github.com/users/GuoQuanhao/followers","following_url":"https://api.github.com/users/GuoQuanhao/following{/other_user}","gists_url":"https://api.github.com/users/GuoQuanhao/gists{/gist_id}","starred_url":"https://api.github.com/users/GuoQuanhao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/GuoQuanhao/subscriptions","organizations_url":"https://api.github.com/users/GuoQuanhao/orgs","repos_url":"https://api.github.com/users/GuoQuanhao/repos","events_url":"https://api.github.com/users/GuoQuanhao/events{/privacy}","received_events_url":"https://api.github.com/users/GuoQuanhao/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-02-05T01:09:45Z","updated_at":"2021-03-02T12:27:33Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"platform: win10\r\nversion: 1.6.0\r\n\r\n# net.py\r\n```python\r\nimport time\r\nimport torch\r\nimport torch.nn as nn\r\nimport torchvision.models._utils as _utils\r\nimport torchvision.models as models\r\nimport torch.nn.functional as F\r\nfrom torch.autograd import Variable\r\nfrom torchsummary import summary\r\n\r\ndef conv_bn(inp, oup, stride = 1, leaky = 0):\r\n    return nn.Sequential(\r\n        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\r\n        nn.BatchNorm2d(oup),\r\n        nn.LeakyReLU(negative_slope=leaky, inplace=True)\r\n    )\r\n\r\ndef conv_bn_no_relu(inp, oup, stride):\r\n    return nn.Sequential(\r\n        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\r\n        nn.BatchNorm2d(oup),\r\n    )\r\n\r\ndef conv_bn1X1(inp, oup, stride, leaky=0):\r\n    return nn.Sequential(\r\n        nn.Conv2d(inp, oup, 1, stride, padding=0, bias=False),\r\n        nn.BatchNorm2d(oup),\r\n        nn.LeakyReLU(negative_slope=leaky, inplace=True)\r\n    )\r\n\r\ndef conv_dw(inp, oup, stride, leaky=0.1):\r\n    return nn.Sequential(\r\n        nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\r\n        nn.BatchNorm2d(inp),\r\n        nn.LeakyReLU(negative_slope= leaky,inplace=True),\r\n\r\n        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\r\n        nn.BatchNorm2d(oup),\r\n        nn.LeakyReLU(negative_slope= leaky,inplace=True),\r\n    )\r\n\r\nclass SSH(nn.Module):\r\n    def __init__(self, in_channel, out_channel):\r\n        super(SSH, self).__init__()\r\n        assert out_channel % 4 == 0\r\n        leaky = 0\r\n        if (out_channel <= 64):\r\n            leaky = 0.1\r\n        self.conv3X3 = conv_bn_no_relu(in_channel, out_channel//2, stride=1)\r\n\r\n        self.conv5X5_1 = conv_bn(in_channel, out_channel//4, stride=1, leaky = leaky)\r\n        self.conv5X5_2 = conv_bn_no_relu(out_channel//4, out_channel//4, stride=1)\r\n\r\n        self.conv7X7_2 = conv_bn(out_channel//4, out_channel//4, stride=1, leaky = leaky)\r\n        self.conv7x7_3 = conv_bn_no_relu(out_channel//4, out_channel//4, stride=1)\r\n\r\n    def forward(self, input):\r\n        conv3X3 = self.conv3X3(input)\r\n\r\n        conv5X5_1 = self.conv5X5_1(input)\r\n        conv5X5 = self.conv5X5_2(conv5X5_1)\r\n\r\n        conv7X7_2 = self.conv7X7_2(conv5X5_1)\r\n        conv7X7 = self.conv7x7_3(conv7X7_2)\r\n\r\n        out = torch.cat([conv3X3, conv5X5, conv7X7], dim=1)\r\n        out = F.relu(out)\r\n        return out\r\n\r\nclass FPN(nn.Module):\r\n    def __init__(self,in_channels_list,out_channels):\r\n        super(FPN,self).__init__()\r\n        leaky = 0\r\n        if (out_channels <= 64):\r\n            leaky = 0.1\r\n        self.output1 = conv_bn1X1(in_channels_list[0], out_channels, stride = 1, leaky = leaky)\r\n        self.output2 = conv_bn1X1(in_channels_list[1], out_channels, stride = 1, leaky = leaky)\r\n        self.output3 = conv_bn1X1(in_channels_list[2], out_channels, stride = 1, leaky = leaky)\r\n\r\n        self.merge1 = conv_bn(out_channels, out_channels, leaky = leaky)\r\n        self.merge2 = conv_bn(out_channels, out_channels, leaky = leaky)\r\n\r\n    def forward(self, input):\r\n        # names = list(input.keys())\r\n        input = list(input.values())\r\n\r\n        output1 = self.output1(input[0])\r\n        output2 = self.output2(input[1])\r\n        output3 = self.output3(input[2])\r\n\r\n        up3 = F.interpolate(output3, size=[output2.size(2), output2.size(3)], mode=\"nearest\")\r\n        output2 = output2 + up3\r\n        output2 = self.merge2(output2)\r\n\r\n        up2 = F.interpolate(output2, size=[output1.size(2), output1.size(3)], mode=\"nearest\")\r\n        output1 = output1 + up2\r\n        output1 = self.merge1(output1)\r\n\r\n        out = [output1, output2, output3]\r\n        return out\r\n\r\n\r\n\r\nclass MobileNetV1(nn.Module):\r\n    def __init__(self):\r\n        super(MobileNetV1, self).__init__()\r\n        self.stage1 = nn.Sequential(\r\n            conv_bn(3, 8, 2, leaky = 0.1),    # 3\r\n            conv_dw(8, 16, 1),   # 7\r\n            conv_dw(16, 32, 2),  # 11\r\n            conv_dw(32, 32, 1),  # 19\r\n            conv_dw(32, 64, 2),  # 27\r\n            conv_dw(64, 64, 1),  # 43\r\n        )\r\n        self.stage2 = nn.Sequential(\r\n            conv_dw(64, 128, 2),  # 43 + 16 = 59\r\n            conv_dw(128, 128, 1), # 59 + 32 = 91\r\n            conv_dw(128, 128, 1), # 91 + 32 = 123\r\n            conv_dw(128, 128, 1), # 123 + 32 = 155\r\n            conv_dw(128, 128, 1), # 155 + 32 = 187\r\n            conv_dw(128, 128, 1), # 187 + 32 = 219\r\n        )\r\n        self.stage3 = nn.Sequential(\r\n            conv_dw(128, 256, 2), # 219 +3 2 = 241\r\n            conv_dw(256, 256, 1), # 241 + 64 = 301\r\n        )\r\n        self.avg = nn.AdaptiveAvgPool2d((1,1))\r\n        self.fc = nn.Linear(256, 1000)\r\n\r\n    def forward(self, x):\r\n        x = self.stage1(x)\r\n        x = self.stage2(x)\r\n        x = self.stage3(x)\r\n        x = self.avg(x)\r\n        # x = self.model(x)\r\n        x = x.view(-1, 256)\r\n        x = self.fc(x)\r\n        return x\r\n\r\nif __name__=='__main__':\r\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n    net = MobileNetV1().to(device)\r\n    summary(net, input_size=(3, 640, 640))\r\n```\r\n# retinaface.py\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nimport torchvision.models.detection.backbone_utils as backbone_utils\r\nimport torchvision.models._utils as _utils\r\nimport torch.nn.functional as F\r\nfrom collections import OrderedDict\r\nfrom torchsummary import summary\r\n'''\r\nfrom models.net import MobileNetV1 as MobileNetV1\r\nfrom models.net import FPN as FPN\r\nfrom models.net import SSH as SSH\r\n'''\r\nfrom net import MobileNetV1 as MobileNetV1\r\nfrom net import FPN as FPN\r\nfrom net import SSH as SSH\r\n\r\n\r\n\r\nclass ClassHead(nn.Module):\r\n    def __init__(self,inchannels=512,num_anchors=3):\r\n        super(ClassHead,self).__init__()\r\n        self.num_anchors = num_anchors\r\n        self.conv1x1 = nn.Conv2d(inchannels,self.num_anchors*2,kernel_size=(1,1),stride=1,padding=0)\r\n\r\n    def forward(self,x):\r\n        out = self.conv1x1(x)\r\n        out = out.permute(0,2,3,1).contiguous()\r\n        \r\n        return out.view(out.shape[0], -1, 2)\r\n\r\nclass BboxHead(nn.Module):\r\n    def __init__(self,inchannels=512,num_anchors=3):\r\n        super(BboxHead,self).__init__()\r\n        self.conv1x1 = nn.Conv2d(inchannels,num_anchors*4,kernel_size=(1,1),stride=1,padding=0)\r\n\r\n    def forward(self,x):\r\n        out = self.conv1x1(x)\r\n        out = out.permute(0,2,3,1).contiguous()\r\n\r\n        return out.view(out.shape[0], -1, 4)\r\n\r\nclass LandmarkHead(nn.Module):\r\n    def __init__(self,inchannels=512,num_anchors=3):\r\n        super(LandmarkHead,self).__init__()\r\n        self.conv1x1 = nn.Conv2d(inchannels,num_anchors*10,kernel_size=(1,1),stride=1,padding=0)\r\n\r\n    def forward(self,x):\r\n        out = self.conv1x1(x)\r\n        out = out.permute(0,2,3,1).contiguous()\r\n\r\n        return out.view(out.shape[0], -1, 10)\r\n\r\nclass RetinaFace(nn.Module):\r\n    def __init__(self, cfg = None, phase = 'train'):\r\n        \"\"\"\r\n        :param cfg:  Network related settings.\r\n        :param phase: train or test.\r\n        \"\"\"\r\n        super(RetinaFace,self).__init__()\r\n        self.phase = phase\r\n        backbone = None\r\n        if cfg['name'] == 'mobilenet0.25':\r\n            backbone = MobileNetV1()\r\n            if cfg['pretrain']:\r\n                checkpoint = torch.load(\"./weights/mobilenetV1X0.25_pretrain.tar\", map_location=torch.device('cpu'))\r\n                from collections import OrderedDict\r\n                new_state_dict = OrderedDict()\r\n                for k, v in checkpoint['state_dict'].items():\r\n                    name = k[7:]  # remove module.\r\n                    new_state_dict[name] = v\r\n                # load params\r\n                backbone.load_state_dict(new_state_dict)\r\n        elif cfg['name'] == 'Resnet50':\r\n            import torchvision.models as models\r\n            backbone = models.resnet50(pretrained=cfg['pretrain'])\r\n\r\n        self.body = _utils.IntermediateLayerGetter(backbone, cfg['return_layers'])\r\n        in_channels_stage2 = cfg['in_channel']\r\n        in_channels_list = [\r\n            in_channels_stage2 * 2,\r\n            in_channels_stage2 * 4,\r\n            in_channels_stage2 * 8,\r\n        ]\r\n        out_channels = cfg['out_channel']\r\n        self.fpn = FPN(in_channels_list,out_channels)\r\n        self.ssh1 = SSH(out_channels, out_channels)\r\n        self.ssh2 = SSH(out_channels, out_channels)\r\n        self.ssh3 = SSH(out_channels, out_channels)\r\n\r\n        self.ClassHead = self._make_class_head(fpn_num=3, inchannels=cfg['out_channel'])\r\n        self.BboxHead = self._make_bbox_head(fpn_num=3, inchannels=cfg['out_channel'])\r\n        self.LandmarkHead = self._make_landmark_head(fpn_num=3, inchannels=cfg['out_channel'])\r\n\r\n    def _make_class_head(self,fpn_num=3,inchannels=64,anchor_num=2):\r\n        classhead = nn.ModuleList()\r\n        for i in range(fpn_num):\r\n            classhead.append(ClassHead(inchannels,anchor_num))\r\n        return classhead\r\n    \r\n    def _make_bbox_head(self,fpn_num=3,inchannels=64,anchor_num=2):\r\n        bboxhead = nn.ModuleList()\r\n        for i in range(fpn_num):\r\n            bboxhead.append(BboxHead(inchannels,anchor_num))\r\n        return bboxhead\r\n\r\n    def _make_landmark_head(self,fpn_num=3,inchannels=64,anchor_num=2):\r\n        landmarkhead = nn.ModuleList()\r\n        for i in range(fpn_num):\r\n            landmarkhead.append(LandmarkHead(inchannels,anchor_num))\r\n        return landmarkhead\r\n\r\n    def forward(self,inputs):\r\n        out = self.body(inputs)\r\n\r\n        # FPN\r\n        fpn = self.fpn(out)\r\n\r\n        # SSH\r\n        feature1 = self.ssh1(fpn[0])\r\n        feature2 = self.ssh2(fpn[1])\r\n        feature3 = self.ssh3(fpn[2])\r\n        features = [feature1, feature2, feature3]\r\n\r\n        bbox_regressions = torch.cat([self.BboxHead[i](feature) for i, feature in enumerate(features)], dim=1)\r\n        classifications = torch.cat([self.ClassHead[i](feature) for i, feature in enumerate(features)],dim=1)\r\n        ldm_regressions = torch.cat([self.LandmarkHead[i](feature) for i, feature in enumerate(features)], dim=1)\r\n\r\n        if self.phase == 'train':\r\n            output = (bbox_regressions, classifications, ldm_regressions)\r\n        else:\r\n            output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\r\n        return output\r\n\r\n\r\nif __name__=='__main__':\r\n    cfg_mnet = {\r\n    'name': 'mobilenet0.25',\r\n    'min_sizes': [[16, 32], [64, 128], [256, 512]],\r\n    'steps': [8, 16, 32],\r\n    'variance': [0.1, 0.2],\r\n    'clip': False,\r\n    'loc_weight': 2.0,\r\n    'gpu_train': True,\r\n    'batch_size': 1,\r\n    'ngpu': 1,\r\n    'epoch': 250,\r\n    'decay1': 190,\r\n    'decay2': 220,\r\n    'image_size': 320,\r\n    'pretrain': True,\r\n    'return_layers': {'stage1': 1, 'stage2': 2, 'stage3': 3},\r\n    'in_channel': 32,\r\n    'out_channel': 64\r\n    }\r\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n    net = RetinaFace(cfg=cfg_mnet).to(device)\r\n    net.eval()\r\n    #print(net)\r\n    summary(net, input_size=(3, 640, 640))\r\nwhen I use python retinaface.py, I get the following error\r\n```\r\n```\r\nTraceback (most recent call last):\r\n  File \".\\models\\retinaface.py\", line 159, in <module>\r\n    summary(net, input_size=(3, 640, 640))\r\n  File \"E:\\Anaconda3\\envs\\pytorch1.6.0\\lib\\site-packages\\torchsummary\\torchsummary.py\", line 72, in summary\r\n    model(*x)\r\n  File \"E:\\Anaconda3\\envs\\pytorch1.6.0\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \".\\models\\retinaface.py\", line 113, in forward\r\n    out = self.body(inputs)\r\n  File \"E:\\Anaconda3\\envs\\pytorch1.6.0\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 726, in _call_impl\r\n    hook_result = hook(self, input, result)\r\n  File \"E:\\Anaconda3\\envs\\pytorch1.6.0\\lib\\site-packages\\torchsummary\\torchsummary.py\", line 26, in hook\r\n    summary[m_key][\"output_shape\"] = list(output.size())\r\nAttributeError: 'collections.OrderedDict' object has no attribute 'size'\r\n```\r\nso, how can I get the summary","closed_by":null,"reactions":{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/162/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/162/timeline","performed_via_github_app":null,"state_reason":null}