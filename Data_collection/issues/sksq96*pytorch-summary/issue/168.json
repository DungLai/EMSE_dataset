{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/168","repository_url":"https://api.github.com/repos/sksq96/pytorch-summary","labels_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/168/labels{/name}","comments_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/168/comments","events_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/168/events","html_url":"https://github.com/sksq96/pytorch-summary/issues/168","id":830313061,"node_id":"MDU6SXNzdWU4MzAzMTMwNjE=","number":168,"title":"Why do I get '2' as batch size?","user":{"login":"Flock1","id":15093420,"node_id":"MDQ6VXNlcjE1MDkzNDIw","avatar_url":"https://avatars.githubusercontent.com/u/15093420?v=4","gravatar_id":"","url":"https://api.github.com/users/Flock1","html_url":"https://github.com/Flock1","followers_url":"https://api.github.com/users/Flock1/followers","following_url":"https://api.github.com/users/Flock1/following{/other_user}","gists_url":"https://api.github.com/users/Flock1/gists{/gist_id}","starred_url":"https://api.github.com/users/Flock1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Flock1/subscriptions","organizations_url":"https://api.github.com/users/Flock1/orgs","repos_url":"https://api.github.com/users/Flock1/repos","events_url":"https://api.github.com/users/Flock1/events{/privacy}","received_events_url":"https://api.github.com/users/Flock1/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2021-03-12T17:22:44Z","updated_at":"2021-04-21T12:42:45Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hey,\r\n\r\nThis is a really great tool to visualize the model. However, I was trying to see how my decoder is working in the VAE and the input to the VAE is the latent space (dim = `(2,2)`). However, when I get the output, I see an extra `2` there. Like this:\r\n`summary(decoder, (2,2))`\r\nOutput is:\r\n```\r\nDECODER\r\ntorch.Size([2, 2, 2])\r\n```\r\nMy decoder is initialized like this:\r\n```\r\nclass Decoder(nn.Module):\r\n    def __init__(self):\r\n        super(Decoder, self).__init__()\r\n        c = capacity\r\n        self.fc = nn.Linear(in_features=latent_dims, out_features=c*2*7*7)\r\n        self.conv2 = nn.ConvTranspose2d(in_channels=c*2, out_channels=c, kernel_size=4, stride=2, padding=1)\r\n        self.conv1 = nn.ConvTranspose2d(in_channels=c, out_channels=1, kernel_size=4, stride=2, padding=1)\r\n        self.adapt = nn.AdaptiveMaxPool1d(input_len)\r\n\r\n        \r\n    def forward(self, x):\r\n        print(\"DECODER\")\r\n        print(x.shape) #1\r\n        x = self.fc(x)\r\n        x = x.reshape(-1,x.shape[0], x.shape[1])\r\n        x = self.adapt(x)\r\n        x = x.view(x.size(0), capacity*2, axis_transfer, axis_transfer) # unflatten batch of feature vectors to a batch of multi-channel feature maps\r\n        x = F.relu(self.conv2(x))\r\n        x = torch.sigmoid(self.conv1(x)) # last layer before output is sigmoid, since we are using BCE as reconstruction loss\r\n        return x\r\n```\r\n\r\nDo let me know. ","closed_by":null,"reactions":{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/168/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/168/timeline","performed_via_github_app":null,"state_reason":null}