{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/177","repository_url":"https://api.github.com/repos/sksq96/pytorch-summary","labels_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/177/labels{/name}","comments_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/177/comments","events_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/177/events","html_url":"https://github.com/sksq96/pytorch-summary/issues/177","id":1005361812,"node_id":"I_kwDOB8pl4c477JqU","number":177,"title":"About the input_size of summary","user":{"login":"UnBuen","id":37174252,"node_id":"MDQ6VXNlcjM3MTc0MjUy","avatar_url":"https://avatars.githubusercontent.com/u/37174252?v=4","gravatar_id":"","url":"https://api.github.com/users/UnBuen","html_url":"https://github.com/UnBuen","followers_url":"https://api.github.com/users/UnBuen/followers","following_url":"https://api.github.com/users/UnBuen/following{/other_user}","gists_url":"https://api.github.com/users/UnBuen/gists{/gist_id}","starred_url":"https://api.github.com/users/UnBuen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnBuen/subscriptions","organizations_url":"https://api.github.com/users/UnBuen/orgs","repos_url":"https://api.github.com/users/UnBuen/repos","events_url":"https://api.github.com/users/UnBuen/events{/privacy}","received_events_url":"https://api.github.com/users/UnBuen/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-23T12:18:12Z","updated_at":"2021-09-23T12:18:12Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"When i use summary(model, input_size), There is a problem about the parameter 'input_size\", in general, input_size = (C, H, W), but for graph datasets, there are nodes and labels and edges. \r\nSo it can't work. \r\n\r\nI donâ€™t even need to use summary to print the size of each layer of the network, I only need to print the model structure. \r\n\r\nCode address: https://github.com/debadyuti23/GraphCovidNet, If needed, I can provide a processed dataset.\r\n\r\n![image](https://user-images.githubusercontent.com/37174252/134504439-b429c724-3a92-4551-b7cb-9e58cef17358.png)\r\n![image](https://user-images.githubusercontent.com/37174252/134504451-08c5bb95-4dcd-4143-8d7e-fb1b84efb5b6.png)\r\n\r\nPlease help me again. It may be due to my limited level. I tried many times but failed to solve this problem.\r\n\r\nmodel.py is as follows: \r\n```\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nimport torch_geometric.nn as pyg_nn\r\nimport torch\r\nclass GNNStack(nn.Module):\r\n    def __init__(self, input_dim, hidden_dim, output_dim, task='node'):\r\n        super(GNNStack, self).__init__()\r\n        self.task = task\r\n        self.convs = nn.ModuleList()\r\n        self.convs.append(self.build_conv_model(input_dim, hidden_dim))\r\n        self.lns = nn.ModuleList()\r\n        self.lns.append(nn.LayerNorm(hidden_dim))\r\n        self.lns.append(nn.LayerNorm(hidden_dim))\r\n        for l in range(2):\r\n            self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))\r\n\r\n        # post-message-passing\r\n        self.post_mp = nn.Sequential(\r\n            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.5),\r\n            nn.Linear(hidden_dim, output_dim))\r\n        if not (self.task == 'node' or self.task == 'graph'):\r\n            raise RuntimeError('Unknown task.')\r\n\r\n        self.dropout = 0.5\r\n        self.num_layers = 3\r\n\r\n    def build_conv_model(self, input_dim, hidden_dim):\r\n        # refer to pytorch geometric nn module for different implementation of GNNs.\r\n        if self.task == 'node':\r\n            return pyg_nn.GCNConv(input_dim, hidden_dim)\r\n        else:\r\n            return pyg_nn.GINConv(nn.Sequential(nn.Linear(input_dim, hidden_dim),\r\n                                                nn.ReLU(), nn.Linear(hidden_dim, hidden_dim)))\r\n\r\n    def forward(self, data):\r\n\r\n        x, edge_index, batch = data.x, data.edge_index, data.batch\r\n\r\n        # print(\"data:{}\".format(data))\r\n        \"\"\"\r\n            data:Batch(batch=[7127], edge_index=[2, 37816], x=[7127, 3], y=[1])\r\n            data:Batch(batch=[2469], edge_index=[2, 12144], x=[2469, 3], y=[1])\r\n            data:Batch(batch=[4846], edge_index=[2, 27550], x=[4846, 3], y=[1])\r\n            data:Batch(batch=[4955], edge_index=[2, 19078], x=[4955, 3], y=[1])\r\n            data:Batch(batch=[8360], edge_index=[2, 48258], x=[8360, 3], y=[1])\r\n            ......\r\n        \"\"\"\r\n        # print(\"data.num_node_features:\", data.num_node_features)    # 3\r\n        # num_node_features\r\n        if data.num_node_features == 0:\r\n            x = torch.ones(data.num_nodes, 1)\r\n\r\n        for i in range(self.num_layers):    # num_layers = 3\r\n            x = self.convs[i](x, edge_index)\r\n            emb = x\r\n            x = F.relu(x)\r\n            x = F.dropout(x, p=self.dropout, training=self.training)\r\n            if not i == self.num_layers - 1:\r\n                x = self.lns[i](x)\r\n\r\n        if self.task == 'graph':\r\n            x = pyg_nn.global_mean_pool(x, batch)\r\n\r\n        x = self.post_mp(x)\r\n\r\n        return emb, F.log_softmax(x, dim=1), F.softmax(x, dim=1)\r\n\r\n    def loss(self, pred, label):\r\n        return F.nll_loss(pred, label)\r\n`\r\n```","closed_by":null,"reactions":{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/177/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/177/timeline","performed_via_github_app":null,"state_reason":null}