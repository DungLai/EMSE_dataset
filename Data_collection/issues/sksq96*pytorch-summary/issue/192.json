{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/192","repository_url":"https://api.github.com/repos/sksq96/pytorch-summary","labels_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/192/labels{/name}","comments_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/192/comments","events_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/192/events","html_url":"https://github.com/sksq96/pytorch-summary/issues/192","id":1449609415,"node_id":"I_kwDOB8pl4c5WZ0jH","number":192,"title":"Failing in the input stage Using Encoder and Decoder Model Architecture (DONUT model)","user":{"login":"swapnil-lader","id":110459485,"node_id":"U_kgDOBpV6XQ","avatar_url":"https://avatars.githubusercontent.com/u/110459485?v=4","gravatar_id":"","url":"https://api.github.com/users/swapnil-lader","html_url":"https://github.com/swapnil-lader","followers_url":"https://api.github.com/users/swapnil-lader/followers","following_url":"https://api.github.com/users/swapnil-lader/following{/other_user}","gists_url":"https://api.github.com/users/swapnil-lader/gists{/gist_id}","starred_url":"https://api.github.com/users/swapnil-lader/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/swapnil-lader/subscriptions","organizations_url":"https://api.github.com/users/swapnil-lader/orgs","repos_url":"https://api.github.com/users/swapnil-lader/repos","events_url":"https://api.github.com/users/swapnil-lader/events{/privacy}","received_events_url":"https://api.github.com/users/swapnil-lader/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-11-15T11:14:40Z","updated_at":"2022-11-15T11:37:10Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I am trying to get a model summary of the donut model but am unable to define the input for the torch summary.\r\n###########################################################\r\nimport argparse\r\nimport gradio as gr\r\nimport torch\r\nfrom PIL import Image\r\nfrom donut.donut.model import DonutModel\r\nfrom torchvision import models\r\nfrom torchsummary import summary\r\n\r\ndef demo_process_vqa(input_img, question):\r\n    global pretrained_model, task_prompt, task_name\r\n    # pretrained_model = './donut/result/train_docvqa/20220912_103244'\r\n    # task_name = \"docvqa\"\r\n    # task_prompt = \"<s_pdf-donut>\"\r\n    input_img = Image.fromarray(input_img)\r\n    user_prompt = task_prompt.replace(\"{user_input}\", question)\r\n    print(user_prompt)\r\n    output = pretrained_model.inference(input_img, prompt=user_prompt)[\"predictions\"][0]\r\n    print('inf_out',output)\r\n    return output\r\n\r\ndef demo_process(input_img):\r\n    global pretrained_model, task_prompt, task_name\r\n    input_img = Image.fromarray(input_img)\r\n    output = pretrained_model.inference(image=input_img, prompt=task_prompt)[\"predictions\"][0]\r\n    return output\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument(\"--task\", type=str, default=\"docvqa\")\r\nparser.add_argument(\"--pretrained_path\", type=str, default=\"train_docvqa_for_all_atts/donut/result/train_docvqa/20220915_125713\")\r\nargs, left_argv = parser.parse_known_args()\r\n\r\ntask_name = args.task\r\nif \"docvqa\" == task_name:\r\n    task_prompt = \"<s_taco_eiko_pdf_donut>{user_input}</s_question><s_answer>\"\r\nelse:  # rvlcdip, cord, ...\r\n    task_prompt = f\"<s_{task_name}>\"\r\n\r\npretrained_model = DonutModel.from_pretrained(args.pretrained_path)\r\n\r\n\r\nif torch.cuda.is_available():\r\n    # pretrained_model.half()\r\n    device = torch.device(\"cuda\")\r\n    pretrained_model.to(device)\r\nelse:\r\n    pretrained_model.encoder.to(torch.bfloat16)\r\n\r\nsummary(pretrained_model, [(1, 3, 1280 , 960), (1, 21),(1, 21)])\r\n\r\nThe shape of the encoder and decoder is as follows.\r\nEncoder : torch.Size([1, 3, 1280, 960]) \r\nDecode : torch.Size([1, 21])\r\n\r\n##Model forward architecture looks like this \r\n\r\n        encoder_outputs = self.encoder(image_tensors)\r\n        decoder_outputs = self.decoder(\r\n            input_ids=decoder_input_ids,\r\n            encoder_hidden_states=encoder_outputs,\r\n            labels=decoder_labels,\r\n        )\r\n        return decoder_outputs\r\n\r\nCan you please guide how to pass down the model input in summary?\r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/192/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/192/timeline","performed_via_github_app":null,"state_reason":null}