{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/185","repository_url":"https://api.github.com/repos/sksq96/pytorch-summary","labels_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/185/labels{/name}","comments_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/185/comments","events_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/185/events","html_url":"https://github.com/sksq96/pytorch-summary/issues/185","id":1194572510,"node_id":"I_kwDOB8pl4c5HM7re","number":185,"title":"AttributeError: ‘NoneType’ object has no attribute ‘size’ ","user":{"login":"Aidenfaustine","id":82608348,"node_id":"MDQ6VXNlcjgyNjA4MzQ4","avatar_url":"https://avatars.githubusercontent.com/u/82608348?v=4","gravatar_id":"","url":"https://api.github.com/users/Aidenfaustine","html_url":"https://github.com/Aidenfaustine","followers_url":"https://api.github.com/users/Aidenfaustine/followers","following_url":"https://api.github.com/users/Aidenfaustine/following{/other_user}","gists_url":"https://api.github.com/users/Aidenfaustine/gists{/gist_id}","starred_url":"https://api.github.com/users/Aidenfaustine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Aidenfaustine/subscriptions","organizations_url":"https://api.github.com/users/Aidenfaustine/orgs","repos_url":"https://api.github.com/users/Aidenfaustine/repos","events_url":"https://api.github.com/users/Aidenfaustine/events{/privacy}","received_events_url":"https://api.github.com/users/Aidenfaustine/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2022-04-06T12:52:11Z","updated_at":"2022-09-30T05:34:55Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"hello. when i use torch summary. it reports some issues about:\r\n\r\nFile “F:\\Anaconda3\\lib\\site-packages\\torchsummary\\torchsummary.py”, line 23, in\r\n[-1] + list(o.size())[1:] for o in output\r\nAttributeError: ‘NoneType’ object has no attribute ‘size’\r\n\r\nhere is my model structure.\r\nCommonsenseGRUModel(\r\n(linear_in): Linear(in_features=1024, out_features=300, bias=True)\r\n(norm1a): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\r\n(norm1b): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\r\n(norm1c): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\r\n(norm1d): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\r\n(norm3a): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n(norm3b): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n(norm3c): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n(norm3d): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n(dropout): Dropout(p=0.5, inplace=False)\r\n(dropout_rec): Dropout(p=False, inplace=False)\r\n(cs_rnn_f): CommonsenseRNN(\r\n(dropout): Dropout(p=False, inplace=False)\r\n(dialogue_cell): CommonsenseRNNCell(\r\n(g_cell): GRUCell(600, 150)\r\n(p_cell): GRUCell(918, 150)\r\n(r_cell): GRUCell(1218, 150)\r\n(i_cell): GRUCell(918, 150)\r\n(e_cell): GRUCell(750, 450)\r\n(dropout): Dropout(p=False, inplace=False)\r\n(dropout1): Dropout(p=False, inplace=False)\r\n(dropout2): Dropout(p=False, inplace=False)\r\n(dropout3): Dropout(p=False, inplace=False)\r\n(dropout4): Dropout(p=False, inplace=False)\r\n(dropout5): Dropout(p=False, inplace=False)\r\n(attention): SimpleAttention(\r\n(scalar): Linear(in_features=150, out_features=1, bias=False)\r\n)\r\n)\r\n)\r\n(cs_rnn_r): CommonsenseRNN(\r\n(dropout): Dropout(p=False, inplace=False)\r\n(dialogue_cell): CommonsenseRNNCell(\r\n(g_cell): GRUCell(600, 150)\r\n(p_cell): GRUCell(918, 150)\r\n(r_cell): GRUCell(1218, 150)\r\n(i_cell): GRUCell(918, 150)\r\n(e_cell): GRUCell(750, 450)\r\n(dropout): Dropout(p=False, inplace=False)\r\n(dropout1): Dropout(p=False, inplace=False)\r\n(dropout2): Dropout(p=False, inplace=False)\r\n(dropout3): Dropout(p=False, inplace=False)\r\n(dropout4): Dropout(p=False, inplace=False)\r\n(dropout5): Dropout(p=False, inplace=False)\r\n(attention): SimpleAttention(\r\n(scalar): Linear(in_features=150, out_features=1, bias=False)\r\n)\r\n)\r\n)\r\n(sense_gru): GRU(768, 384, bidirectional=True)\r\n(matchatt): MatchingAttention(\r\n(transform): Linear(in_features=900, out_features=900, bias=True)\r\n)\r\n(linear): Linear(in_features=900, out_features=300, bias=True)\r\n(smax_fc): Linear(in_features=300, out_features=7, bias=True)\r\n)\r\n\r\nhere is about using summary.\r\ninput_size = [( 14,1, 1024), (14, 1, 1024), (14, 1, 1024), (14, 1, 1024), (14, 1, 768), (14, 1, 768), (14, 1, 768),(14, 1, 768), (14, 1, 768), (14, 1, 9), (1, 14)]\r\nfrom torchsummary import summary\r\nmodel_summary = summary(model,input_size = input_size)\r\nprint(model_summary)\r\n\r\nCould you please give me some detailed suggestions about how to fix it?\r\nThanks, best wishes","closed_by":null,"reactions":{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/185/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/185/timeline","performed_via_github_app":null,"state_reason":null}