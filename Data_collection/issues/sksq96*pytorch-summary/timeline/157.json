[{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/comments/1023336779","html_url":"https://github.com/sksq96/pytorch-summary/issues/157#issuecomment-1023336779","issue_url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/157","id":1023336779,"node_id":"IC_kwDOB8pl4c48_uFL","user":{"login":"gugarosa","id":4120639,"node_id":"MDQ6VXNlcjQxMjA2Mzk=","avatar_url":"https://avatars.githubusercontent.com/u/4120639?v=4","gravatar_id":"","url":"https://api.github.com/users/gugarosa","html_url":"https://github.com/gugarosa","followers_url":"https://api.github.com/users/gugarosa/followers","following_url":"https://api.github.com/users/gugarosa/following{/other_user}","gists_url":"https://api.github.com/users/gugarosa/gists{/gist_id}","starred_url":"https://api.github.com/users/gugarosa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gugarosa/subscriptions","organizations_url":"https://api.github.com/users/gugarosa/orgs","repos_url":"https://api.github.com/users/gugarosa/repos","events_url":"https://api.github.com/users/gugarosa/events{/privacy}","received_events_url":"https://api.github.com/users/gugarosa/received_events","type":"User","site_admin":false},"created_at":"2022-01-27T15:30:41Z","updated_at":"2022-01-27T15:31:08Z","author_association":"NONE","body":"These are some messy modifications but it should hold for your BERT case:\r\n\r\n```import torch\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\n\r\nfrom collections import OrderedDict\r\nimport numpy as np\r\n\r\n\r\ndef summary(model, input_size, batch_size=-1, device=\"cuda\"):\r\n\r\n    def register_hook(module):\r\n\r\n        def hook(module, input, output):\r\n            class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\r\n            module_idx = len(summary)\r\n\r\n            m_key = \"%s-%i\" % (class_name, module_idx + 1)\r\n            summary[m_key] = OrderedDict()\r\n            if len(input) > 0:\r\n                summary[m_key][\"input_shape\"] = list(input[0].size() if input[0] is not None else None)\r\n                summary[m_key][\"input_shape\"][0] = batch_size\r\n            if isinstance(output, (list, tuple)):\r\n                summary[m_key][\"output_shape\"] = [\r\n                    [-1] + list(o.size())[1:] if o is not None else None for o in output\r\n                ]\r\n            else:\r\n                summary[m_key][\"output_shape\"] = list(output[0].size())\r\n                summary[m_key][\"output_shape\"][0] = batch_size\r\n\r\n            params = 0\r\n            if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\r\n                params += torch.prod(torch.LongTensor(list(module.weight.size())))\r\n                summary[m_key][\"trainable\"] = module.weight.requires_grad\r\n            if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\r\n                params += torch.prod(torch.LongTensor(list(module.bias.size())))\r\n            summary[m_key][\"nb_params\"] = params\r\n\r\n        if (\r\n            not isinstance(module, nn.Sequential)\r\n            and not isinstance(module, nn.ModuleList)\r\n            and not (module == model)\r\n        ):\r\n            hooks.append(module.register_forward_hook(hook))\r\n\r\n    device = device.lower()\r\n    assert device in [\r\n        \"cuda\",\r\n        \"cpu\",\r\n    ], \"Input device is not valid, please specify 'cuda' or 'cpu'\"\r\n\r\n    if device == \"cuda\" and torch.cuda.is_available():\r\n        dtype = torch.cuda.LongTensor\r\n    else:\r\n        dtype = torch.LongTensor\r\n\r\n    # multiple inputs to the network\r\n    if isinstance(input_size, tuple):\r\n        input_size = [input_size]\r\n\r\n    # batch_size of 2 for batchnorm\r\n    x = [torch.rand(2, *in_size).type(dtype) for in_size in input_size]\r\n    # print(type(x[0]))\r\n\r\n    # create properties\r\n    summary = OrderedDict()\r\n    hooks = []\r\n\r\n    # register hook\r\n    model.apply(register_hook)\r\n\r\n    # make a forward pass\r\n    # print(x.shape)\r\n    model(*x)\r\n\r\n    # remove these hooks\r\n    for h in hooks:\r\n        h.remove()\r\n\r\n    print(\"----------------------------------------------------------------\")\r\n    line_new = \"{:>20}  {:>25} {:>15}\".format(\"Layer (type)\", \"Output Shape\", \"Param #\")\r\n    print(line_new)\r\n    print(\"================================================================\")\r\n    total_params = 0\r\n    total_output = 0\r\n    trainable_params = 0\r\n    for layer in summary:\r\n        # input_shape, output_shape, trainable, nb_params\r\n        line_new = \"{:>20}  {:>25} {:>15}\".format(\r\n            layer,\r\n            str(summary[layer][\"output_shape\"]),\r\n            \"{0:,}\".format(summary[layer][\"nb_params\"]),\r\n        )\r\n        total_params += summary[layer][\"nb_params\"]\r\n        print(summary[layer][\"output_shape\"])\r\n        total_output += np.prod(summary[layer][\"output_shape\"][0] if summary[layer][\"output_shape\"][0] is not None else 1)\r\n        if \"trainable\" in summary[layer]:\r\n            if summary[layer][\"trainable\"] == True:\r\n                trainable_params += summary[layer][\"nb_params\"]\r\n        print(line_new)\r\n\r\n    # assume 4 bytes/number (float on cuda).\r\n    total_input_size = abs(np.prod(input_size) * batch_size * 4. / (1024 ** 2.))\r\n    total_output_size = abs(2. * total_output * 4. / (1024 ** 2.))  # x2 for gradients\r\n    total_params_size = abs(total_params.numpy() * 4. / (1024 ** 2.))\r\n    total_size = total_params_size + total_output_size + total_input_size\r\n\r\n    print(\"================================================================\")\r\n    print(\"Total params: {0:,}\".format(total_params))\r\n    print(\"Trainable params: {0:,}\".format(trainable_params))\r\n    print(\"Non-trainable params: {0:,}\".format(total_params - trainable_params))\r\n    print(\"----------------------------------------------------------------\")\r\n    print(\"Input size (MB): %0.2f\" % total_input_size)\r\n    print(\"Forward/backward pass size (MB): %0.2f\" % total_output_size)\r\n    print(\"Params size (MB): %0.2f\" % total_params_size)\r\n    print(\"Estimated Total Size (MB): %0.2f\" % total_size)\r\n    print(\"----------------------------------------------------------------\")\r\n    # return summary\r\n```\r\n\r\nBoth total number of parameters should match with the following:\r\n```\r\nsummary(model, (64, ))\r\nprint(sum(p.numel() for p in model.parameters()))\r\n```","reactions":{"url":"https://api.github.com/repos/sksq96/pytorch-summary/issues/comments/1023336779/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"gugarosa","id":4120639,"node_id":"MDQ6VXNlcjQxMjA2Mzk=","avatar_url":"https://avatars.githubusercontent.com/u/4120639?v=4","gravatar_id":"","url":"https://api.github.com/users/gugarosa","html_url":"https://github.com/gugarosa","followers_url":"https://api.github.com/users/gugarosa/followers","following_url":"https://api.github.com/users/gugarosa/following{/other_user}","gists_url":"https://api.github.com/users/gugarosa/gists{/gist_id}","starred_url":"https://api.github.com/users/gugarosa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gugarosa/subscriptions","organizations_url":"https://api.github.com/users/gugarosa/orgs","repos_url":"https://api.github.com/users/gugarosa/repos","events_url":"https://api.github.com/users/gugarosa/events{/privacy}","received_events_url":"https://api.github.com/users/gugarosa/received_events","type":"User","site_admin":false}}]