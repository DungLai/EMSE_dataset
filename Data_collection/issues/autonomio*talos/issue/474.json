{"url":"https://api.github.com/repos/autonomio/talos/issues/474","repository_url":"https://api.github.com/repos/autonomio/talos","labels_url":"https://api.github.com/repos/autonomio/talos/issues/474/labels{/name}","comments_url":"https://api.github.com/repos/autonomio/talos/issues/474/comments","events_url":"https://api.github.com/repos/autonomio/talos/issues/474/events","html_url":"https://github.com/autonomio/talos/issues/474","id":568813642,"node_id":"MDU6SXNzdWU1Njg4MTM2NDI=","number":474,"title":"KeyError: 'loss' in Talos.Scan","user":{"login":"SamBelkacem","id":33413333,"node_id":"MDQ6VXNlcjMzNDEzMzMz","avatar_url":"https://avatars.githubusercontent.com/u/33413333?v=4","gravatar_id":"","url":"https://api.github.com/users/SamBelkacem","html_url":"https://github.com/SamBelkacem","followers_url":"https://api.github.com/users/SamBelkacem/followers","following_url":"https://api.github.com/users/SamBelkacem/following{/other_user}","gists_url":"https://api.github.com/users/SamBelkacem/gists{/gist_id}","starred_url":"https://api.github.com/users/SamBelkacem/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SamBelkacem/subscriptions","organizations_url":"https://api.github.com/users/SamBelkacem/orgs","repos_url":"https://api.github.com/users/SamBelkacem/repos","events_url":"https://api.github.com/users/SamBelkacem/events{/privacy}","received_events_url":"https://api.github.com/users/SamBelkacem/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-02-21T08:39:30Z","updated_at":"2020-11-09T16:14:24Z","closed_at":"2020-11-09T16:14:24Z","author_association":"NONE","active_lock_reason":null,"body":"ta.version : 0.6.7\r\n\r\nI'm using Talos and Google colab TPU to run hyperparameter tuning of a Keras model.\r\n\r\n**Function to create and compile the Keras model**\r\n\r\n```\r\ndef create_model(x_train, y_train, x_val, y_val, params):\r\n    # Specify a distributed strategy to use TPU\r\n    resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\n    tf.contrib.distribute.initialize_tpu_system(resolver)\r\n    strategy = tf.contrib.distribute.TPUStrategy(resolver)\r\n\r\n    # Use the distributed strategy to create and compile a Keras model\r\n    with strategy.scope():\r\n      deep_model = Sequential()\r\n      deep_model.add(Dense(16, input_shape=(16,), activation=tf.nn.relu, name=\"relu\"))\r\n      deep_model.add(Dense(1, activation=tf.nn.sigmoid, name=\"sigmoid\"))\r\n      optimizer = SGD(lr=params['learn_rate'], momentum=params['momentum'])\r\n      deep_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\r\n  \r\n    # Convert data type to use TPU  \r\n    x_train = x_train.astype('float32')\r\n    x_val = x_val.astype('float32')\r\n    y_train = y_train.astype('int32')\r\n    y_val = y_val.astype('int32')\r\n\r\n    # Fit the Keras model on the dataset\r\n    steps_per_epoch = int(np.ceil(x_train.shape[0] / params['batch_size'])) - 1\r\n    out = deep_model.fit(x_train, y_train, batch_size=params['batch_size'], epochs=params['epochs'], validation_data=[x_val, y_val], verbose=0, steps_per_epoch=steps_per_epoch)\r\n\r\n    # Return the history output and the Keras model\r\n    return out, deep_model\r\n```\r\n\r\n**The parameter distributions**\r\n\r\n```\r\np = {'batch_size': [512, 1024],\r\n        'epochs': [10],\r\n        'learn_rate': [0.1, 0.2, 0.3],\r\n        'momentum': [0.2, 0.4, 0.6]} \r\n```\r\n\r\n**Scan the best hyperparameters of the Keras model**\r\n\r\n`scan_results = ta.Scan(x_train, y_train, params=p, model=create_model, experiment_name='exp', x_val=x_val, y_val=y_val, fraction_limit=0.2, seed=69420)`\r\n\r\nI'm facing the following error in `scan_results`:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-7-e7e73cb16155> in <module>()\r\n     27 \r\n     28     # Scan the best hyperparameters of the Keras model\r\n---> 29     scan_results = ta.Scan(x_train, y_train, params=p, model=create_model, experiment_name='exp', x_val=x_val, y_val=y_val, fraction_limit=0.2, seed=69420)\r\n     30 \r\n\r\n4 frames\r\n/usr/local/lib/python3.6/dist-packages/talos/scan/Scan.py in __init__(self, x, y, params, model, experiment_name, x_val, y_val, val_split, random_method, seed, performance_target, fraction_limit, round_limit, time_limit, boolean_limit, reduction_method, reduction_interval, reduction_window, reduction_threshold, reduction_metric, minimize_loss, disable_progress_bar, print_params, clear_session, save_weights)\r\n    194         # start runtime\r\n    195         from .scan_run import scan_run\r\n--> 196         scan_run(self)\r\n\r\n/usr/local/lib/python3.6/dist-packages/talos/scan/scan_run.py in scan_run(self)\r\n     24         # otherwise proceed with next permutation\r\n     25         from .scan_round import scan_round\r\n---> 26         self = scan_round(self)\r\n     27         self.pbar.update(1)\r\n     28 \r\n\r\n/usr/local/lib/python3.6/dist-packages/talos/scan/scan_round.py in scan_round(self)\r\n     22     # handle logging of results\r\n     23     from ..logging.logging_run import logging_run\r\n---> 24     self = logging_run(self, round_start, start, self.model_history)\r\n     25 \r\n     26     # apply reductions\r\n\r\n/usr/local/lib/python3.6/dist-packages/talos/logging/logging_run.py in logging_run(self, round_start, start, model_history)\r\n     31     # create log and other stats\r\n     32     from ..metrics.entropy import epoch_entropy\r\n---> 33     self.epoch_entropy.append(epoch_entropy(self, model_history.history))\r\n     34 \r\n     35     # get round results to the results table and save it\r\n\r\n/usr/local/lib/python3.6/dist-packages/talos/metrics/entropy.py in epoch_entropy(self, history)\r\n     28         # make sure that the length of the arrays are same\r\n     29         for i in range(len(self._metric_keys)):\r\n---> 30             if len(history[self._metric_keys[i]]) == len(history[self._val_keys[i]]):\r\n     31                 mode = 'kl_divergence'\r\n     32             else:\r\n\r\nKeyError: 'loss'\r\n```","closed_by":{"login":"mikkokotila","id":7943188,"node_id":"MDQ6VXNlcjc5NDMxODg=","avatar_url":"https://avatars.githubusercontent.com/u/7943188?v=4","gravatar_id":"","url":"https://api.github.com/users/mikkokotila","html_url":"https://github.com/mikkokotila","followers_url":"https://api.github.com/users/mikkokotila/followers","following_url":"https://api.github.com/users/mikkokotila/following{/other_user}","gists_url":"https://api.github.com/users/mikkokotila/gists{/gist_id}","starred_url":"https://api.github.com/users/mikkokotila/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mikkokotila/subscriptions","organizations_url":"https://api.github.com/users/mikkokotila/orgs","repos_url":"https://api.github.com/users/mikkokotila/repos","events_url":"https://api.github.com/users/mikkokotila/events{/privacy}","received_events_url":"https://api.github.com/users/mikkokotila/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/autonomio/talos/issues/474/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/autonomio/talos/issues/474/timeline","performed_via_github_app":null,"state_reason":"completed"}