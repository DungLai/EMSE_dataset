{"url":"https://api.github.com/repos/autonomio/talos/issues/335","repository_url":"https://api.github.com/repos/autonomio/talos","labels_url":"https://api.github.com/repos/autonomio/talos/issues/335/labels{/name}","comments_url":"https://api.github.com/repos/autonomio/talos/issues/335/comments","events_url":"https://api.github.com/repos/autonomio/talos/issues/335/events","html_url":"https://github.com/autonomio/talos/issues/335","id":460665108,"node_id":"MDU6SXNzdWU0NjA2NjUxMDg=","number":335,"title":"ValueError: Length mismatch: Expected axis has 21 elements, new values have 11 elements","user":{"login":"bjtho08","id":885853,"node_id":"MDQ6VXNlcjg4NTg1Mw==","avatar_url":"https://avatars.githubusercontent.com/u/885853?v=4","gravatar_id":"","url":"https://api.github.com/users/bjtho08","html_url":"https://github.com/bjtho08","followers_url":"https://api.github.com/users/bjtho08/followers","following_url":"https://api.github.com/users/bjtho08/following{/other_user}","gists_url":"https://api.github.com/users/bjtho08/gists{/gist_id}","starred_url":"https://api.github.com/users/bjtho08/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bjtho08/subscriptions","organizations_url":"https://api.github.com/users/bjtho08/orgs","repos_url":"https://api.github.com/users/bjtho08/repos","events_url":"https://api.github.com/users/bjtho08/events{/privacy}","received_events_url":"https://api.github.com/users/bjtho08/received_events","type":"User","site_admin":false},"labels":[{"id":1006326921,"node_id":"MDU6TGFiZWwxMDA2MzI2OTIx","url":"https://api.github.com/repos/autonomio/talos/labels/topic:%20documentation","name":"topic: documentation","color":"ffffff","default":false,"description":"better doc strings or comments needed"},{"id":1040763409,"node_id":"MDU6TGFiZWwxMDQwNzYzNDA5","url":"https://api.github.com/repos/autonomio/talos/labels/user%20support","name":"user support","color":"59db8b","default":false,"description":"nothing is wrong with Talos"}],"state":"closed","locked":false,"assignee":{"login":"mikkokotila","id":7943188,"node_id":"MDQ6VXNlcjc5NDMxODg=","avatar_url":"https://avatars.githubusercontent.com/u/7943188?v=4","gravatar_id":"","url":"https://api.github.com/users/mikkokotila","html_url":"https://github.com/mikkokotila","followers_url":"https://api.github.com/users/mikkokotila/followers","following_url":"https://api.github.com/users/mikkokotila/following{/other_user}","gists_url":"https://api.github.com/users/mikkokotila/gists{/gist_id}","starred_url":"https://api.github.com/users/mikkokotila/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mikkokotila/subscriptions","organizations_url":"https://api.github.com/users/mikkokotila/orgs","repos_url":"https://api.github.com/users/mikkokotila/repos","events_url":"https://api.github.com/users/mikkokotila/events{/privacy}","received_events_url":"https://api.github.com/users/mikkokotila/received_events","type":"User","site_admin":false},"assignees":[{"login":"mikkokotila","id":7943188,"node_id":"MDQ6VXNlcjc5NDMxODg=","avatar_url":"https://avatars.githubusercontent.com/u/7943188?v=4","gravatar_id":"","url":"https://api.github.com/users/mikkokotila","html_url":"https://github.com/mikkokotila","followers_url":"https://api.github.com/users/mikkokotila/followers","following_url":"https://api.github.com/users/mikkokotila/following{/other_user}","gists_url":"https://api.github.com/users/mikkokotila/gists{/gist_id}","starred_url":"https://api.github.com/users/mikkokotila/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mikkokotila/subscriptions","organizations_url":"https://api.github.com/users/mikkokotila/orgs","repos_url":"https://api.github.com/users/mikkokotila/repos","events_url":"https://api.github.com/users/mikkokotila/events{/privacy}","received_events_url":"https://api.github.com/users/mikkokotila/received_events","type":"User","site_admin":false}],"milestone":null,"comments":17,"created_at":"2019-06-25T22:02:01Z","updated_at":"2019-07-22T07:35:25Z","closed_at":"2019-07-02T11:01:16Z","author_association":"NONE","active_lock_reason":null,"body":"# Bug description\r\nTalos fails upon completion of all rounds in parameter search because of a mismatch between axis and new values.\r\n\r\n\r\n- [x] I'm up-to-date with the latest release:\r\n- [x] I've confirmed that my Keras model works outside of Talos.\r\n\r\n## Output of shape for x and y\r\nX.shape = (16, 208, 208, 3)\r\nY.shape = (16, 208, 208, 10)\r\n\r\n## Talos params dictionary\r\n```python\r\np = {\r\n    \"dropout\": [0],\r\n    \"decay\": [0.0],\r\n    \"lr\": [1e-4],\r\n    \"sigma_noise\": [0],\r\n    #\"pretrain\": [2, 0],\r\n    #\"class_weights\": [False, True],\r\n    \"loss_func\": [tversky_loss]\r\n}\r\n```\r\n## The Keras model wired for Talos\r\n```python\r\ndef talos_presets(weight_path, cls_wgts, static_params, train_generator, val_generator):\r\n    \"\"\"Initialize a talos model object for hyper-parameter search\r\n\r\n    :param weight_path: Path to the base weight folder\r\n    :type weight_path: str\r\n    :param cls_wgts: A list containing the weights applied to each class,\r\n        or None\r\n    :type cls_wgts: None, or List of floats\r\n    :param params: Dictionary of fixed parameters in the model\r\n    :type params: Dict\r\n    :param train_generator: Generator function for training data\r\n    :type train_generator: Class\r\n    :param train_generator: Generator function for validation data\r\n    :type train_generator: Class\r\n    \"\"\"\r\n    def talos_model(x, y, val_x, val_y, params):\r\n        \"\"\"Talos model setup\r\n\r\n        :param x: Dummy input needed for talos framework\r\n        :type x: Array-like\r\n        :param y: Dummy input needed for talos framework\r\n        :type y: Array-like\r\n        :param val_x: Dummy input needed for talos framework\r\n        :type val_x: Array-like\r\n        :param val_y: Dummy input needed for talos framework\r\n        :type val_y: Array-like\r\n        :param params: Hyperparameters supplied by talos\r\n        :type params: Dict\r\n        \"\"\"\r\n        # Dummy inputs\r\n        _ = x, y, val_x, val_y\r\n        params.update(static_params)\r\n        if params[\"loss_func\"] == \"cat_CE\":\r\n            loss_func = categorical_crossentropy\r\n        elif params[\"loss_func\"] == \"cat_FL\":\r\n            cat_focal_loss = categorical_focal_loss()\r\n            loss_func = cat_focal_loss\r\n        elif hasattr(params[\"loss_func\"], '__call__'):\r\n            loss_func = params[\"loss_func\"]\r\n        else:\r\n            raise NameError(\"Wrong loss function name\")\r\n        # mse, mae, binary_crossentropy, jaccard2_loss, categorical_crossentropy,\r\n        # tversky_loss, categorical_focal_loss\r\n        if params[\"class_weights\"] is False:\r\n            class_weights = [1 if k != 12 else 0 for k in cls_wgts.keys()]\r\n        else:\r\n            class_weights = ([v for v in cls_wgts.values()],)\r\n        try:\r\n            loss_name = params[\"loss_func\"].__name__\r\n        except AttributeError:\r\n            loss_name = params[\"loss_func\"].__str__()\r\n        model_base_path = osp.join(\r\n            weight_path,\r\n            params[\"today_str\"],\r\n            \"{}-{}epochs-bs_{}\".format(\r\n                loss_name,\r\n                str(params[\"nb_epoch\"]),\r\n                str(params[\"batch_size\"]),\r\n            ))\r\n\r\n        if not os.path.exists(model_base_path):\r\n            os.makedirs(model_base_path, exist_ok=True)\r\n\r\n        modelpath = osp.join(\r\n            model_base_path,\r\n            \"talos_U-net_model-\"\r\n            + \"decay_{}-drop_{}-weights_{}-pretrain_{}-sigma_{}.h5\".format(\r\n                params[\"decay\"],\r\n                params[\"dropout\"],\r\n                params[\"class_weights\"],\r\n                params[\"pretrain\"],\r\n                params[\"sigma_noise\"],\r\n            ),\r\n        )\r\n        log_path = (\r\n            \"./logs/\"\r\n            + \"{}/lossfunc_{}/decay_{}-drop_{}-weights_{}-pretrain_{}-sigma_{}/\".format(\r\n                params[\"today_str\"],\r\n                loss_name,\r\n                params[\"decay\"],\r\n                params[\"dropout\"],\r\n                params[\"class_weights\"],\r\n                params[\"pretrain\"],\r\n                params[\"sigma_noise\"],\r\n            )\r\n        )\r\n\r\n        if params[\"pretrain\"] != 0:\r\n            print(\r\n                \"starting with frozen layers\\nclass weights: {}\".format(class_weights)\r\n            )\r\n            model = u_net(\r\n                params[\"shape\"],\r\n                int(params[\"nb_filters_0\"]),\r\n                sigma_noise=params[\"sigma_noise\"],\r\n                depth=4,\r\n                dropout=params[\"dropout\"],\r\n                output_channels=params[\"num_cls\"],\r\n                batchnorm=params[\"batchnorm\"],\r\n                pretrain=params[\"pretrain\"],\r\n            )\r\n            model.compile(\r\n                loss=loss_func,\r\n                optimizer=Adam(lr=params[\"lr\"], decay=params[\"decay\"]),\r\n                metrics=[\"acc\"],\r\n            )\r\n\r\n            history = model.fit_generator(\r\n                generator=train_generator,\r\n                epochs=10,\r\n                validation_data=val_generator,\r\n                use_multiprocessing=True,\r\n                workers=30,\r\n                class_weight=class_weights,\r\n                verbose=params[\"verbose\"],\r\n            )\r\n\r\n            pretrain_layers = [\r\n                \"block{}_conv{}\".format(block, layer)\r\n                for block in range(1, params[\"pretrain\"] + 1)\r\n                for layer in range(1, 3)\r\n            ]\r\n            for n in pretrain_layers:\r\n                model.get_layer(name=n).trainable = True\r\n            print(\"layers unfrozen\\n\")\r\n\r\n            model.compile(\r\n                loss=loss_func,\r\n                optimizer=Adam(lr=params[\"lr\"], decay=params[\"decay\"]),\r\n                metrics=[\"acc\"],\r\n            )\r\n\r\n            history = model.fit_generator(\r\n                generator=train_generator,\r\n                epochs=params[\"nb_epoch\"],\r\n                validation_data=val_generator,\r\n                use_multiprocessing=True,\r\n                workers=30,\r\n                class_weight=class_weights,\r\n                verbose=params[\"verbose\"],\r\n                callbacks=[\r\n                    TQDMNotebookCallback(\r\n                        metric_format=\"{name}: {value:0.4f}\",\r\n                        leave_inner=True,\r\n                        leave_outer=True,\r\n                    ),\r\n                    TensorBoard(\r\n                        log_dir=log_path,\r\n                        histogram_freq=0,\r\n                        batch_size=params[\"batch_size\"],\r\n                        write_graph=True,\r\n                        write_grads=False,\r\n                        write_images=True,\r\n                        embeddings_freq=0,\r\n                        update_freq=\"epoch\",\r\n                    ),\r\n                    EarlyStopping(\r\n                        monitor=\"loss\",\r\n                        min_delta=0.0001,\r\n                        patience=10,\r\n                        verbose=0,\r\n                        mode=\"auto\",\r\n                    ),\r\n                    ReduceLROnPlateau(\r\n                        monitor=\"loss\", factor=0.1, patience=3, min_lr=1e-7, verbose=1\r\n                    ),\r\n                    PatchedModelCheckpoint(\r\n                        modelpath, verbose=0, monitor=\"loss\", save_best_only=True\r\n                    ),\r\n                ],\r\n            )\r\n        else:\r\n            print(\"No layers frozen at start\\nclass weights: {}\".format(class_weights))\r\n            model = u_net(\r\n                params[\"shape\"],\r\n                int(params[\"nb_filters_0\"]),\r\n                sigma_noise=params[\"sigma_noise\"],\r\n                depth=4,\r\n                dropout=params[\"dropout\"],\r\n                output_channels=params[\"num_cls\"],\r\n                batchnorm=params[\"batchnorm\"],\r\n                pretrain=params[\"pretrain\"],\r\n            )\r\n\r\n            model.compile(\r\n                loss=loss_func,\r\n                optimizer=Adam(lr=params[\"lr\"], decay=params[\"decay\"]),\r\n                metrics=[\"acc\"],\r\n            )\r\n\r\n            history = model.fit_generator(\r\n                generator=train_generator,\r\n                epochs=params[\"nb_epoch\"],\r\n                validation_data=val_generator,\r\n                use_multiprocessing=True,\r\n                workers=30,\r\n                class_weight=class_weights,\r\n                verbose=params[\"verbose\"],\r\n                callbacks=[\r\n                    TQDMNotebookCallback(\r\n                        metric_format=\"{name}: {value:0.4f}\",\r\n                        leave_inner=True,\r\n                        leave_outer=True,\r\n                    ),\r\n                    TensorBoard(\r\n                        log_dir=log_path,\r\n                        histogram_freq=0,\r\n                        batch_size=params[\"batch_size\"],\r\n                        write_graph=True,\r\n                        write_grads=False,\r\n                        write_images=True,\r\n                        embeddings_freq=0,\r\n                        update_freq=\"epoch\",\r\n                    ),\r\n                    EarlyStopping(\r\n                        monitor=\"loss\",\r\n                        min_delta=0.0001,\r\n                        patience=10,\r\n                        verbose=0,\r\n                        mode=\"auto\",\r\n                    ),\r\n                    ReduceLROnPlateau(\r\n                        monitor=\"loss\", factor=0.1, patience=3, min_lr=1e-7, verbose=1\r\n                    ),\r\n                    PatchedModelCheckpoint(\r\n                        modelpath, verbose=0, monitor=\"loss\", save_best_only=True\r\n                    ),\r\n                ],\r\n            )\r\n        return history, model\r\n    return talos_model\r\n```\r\n\r\n# Traceback\r\n```python\r\n-------------------------------------------------------------------------\r\n100%|██████████| 1/1 [1:43:42<00:00, 6222.81s/it]\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-70-acd959206821> in <module>()\r\n     83     # functional_model=True,\r\n     84     # grid_downsample=0.1,\r\n---> 85     params=p,\r\n     86 )\r\n     87 \r\n\r\n~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/talos/scan/Scan.py in __init__(self, x, y, params, model, experiment_name, x_val, y_val, val_split, random_method, performance_target, fraction_limit, round_limit, time_limit, boolean_limit, reduction_method, reduction_interval, reduction_window, reduction_threshold, reduction_metric, minimize_loss, seed, clear_session, disable_progress_bar, print_params, debug)\r\n    170         # input parameters section ends\r\n    171 \r\n--> 172         self.runtime()\r\n    173 \r\n    174     def runtime(self):\r\n\r\n~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/talos/scan/Scan.py in runtime(self)\r\n    175 \r\n    176         from .scan_run import scan_run\r\n--> 177         self = scan_run(self)\r\n\r\n~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/talos/scan/scan_run.py in scan_run(self)\r\n     32     # finish\r\n     33     from ..logging.logging_finish import logging_finish\r\n---> 34     self = logging_finish(self)\r\n     35 \r\n     36     from .scan_finish import scan_finish\r\n\r\n~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/talos/logging/logging_finish.py in logging_finish(self)\r\n      4 \r\n      5     # save the results\r\n----> 6     self = result_todf(self)\r\n      7 \r\n      8     return self\r\n\r\n~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/talos/logging/results.py in result_todf(self)\r\n     46     cols = self.result[0]\r\n     47     self.result = pd.DataFrame(self.result[1:])\r\n---> 48     self.result.columns = cols\r\n     49 \r\n     50     return self\r\n\r\n~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/pandas/core/generic.py in __setattr__(self, name, value)\r\n   4383         try:\r\n   4384             object.__getattribute__(self, name)\r\n-> 4385             return object.__setattr__(self, name, value)\r\n   4386         except AttributeError:\r\n   4387             pass\r\n\r\npandas/_libs/properties.pyx in pandas._libs.properties.AxisProperty.__set__()\r\n\r\n~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/pandas/core/generic.py in _set_axis(self, axis, labels)\r\n    643 \r\n    644     def _set_axis(self, axis, labels):\r\n--> 645         self._data.set_axis(axis, labels)\r\n    646         self._clear_item_cache()\r\n    647 \r\n\r\n~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/pandas/core/internals.py in set_axis(self, axis, new_labels)\r\n   3321             raise ValueError(\r\n   3322                 'Length mismatch: Expected axis has {old} elements, new '\r\n-> 3323                 'values have {new} elements'.format(old=old_len, new=new_len))\r\n   3324 \r\n   3325         self.axes[axis] = new_labels\r\n\r\nValueError: Length mismatch: Expected axis has 21 elements, new values have 11 elements\r\n```","closed_by":{"login":"bjtho08","id":885853,"node_id":"MDQ6VXNlcjg4NTg1Mw==","avatar_url":"https://avatars.githubusercontent.com/u/885853?v=4","gravatar_id":"","url":"https://api.github.com/users/bjtho08","html_url":"https://github.com/bjtho08","followers_url":"https://api.github.com/users/bjtho08/followers","following_url":"https://api.github.com/users/bjtho08/following{/other_user}","gists_url":"https://api.github.com/users/bjtho08/gists{/gist_id}","starred_url":"https://api.github.com/users/bjtho08/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bjtho08/subscriptions","organizations_url":"https://api.github.com/users/bjtho08/orgs","repos_url":"https://api.github.com/users/bjtho08/repos","events_url":"https://api.github.com/users/bjtho08/events{/privacy}","received_events_url":"https://api.github.com/users/bjtho08/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/autonomio/talos/issues/335/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/autonomio/talos/issues/335/timeline","performed_via_github_app":null,"state_reason":"completed"}