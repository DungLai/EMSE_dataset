{"url":"https://api.github.com/repos/autonomio/talos/issues/300","repository_url":"https://api.github.com/repos/autonomio/talos","labels_url":"https://api.github.com/repos/autonomio/talos/issues/300/labels{/name}","comments_url":"https://api.github.com/repos/autonomio/talos/issues/300/comments","events_url":"https://api.github.com/repos/autonomio/talos/issues/300/events","html_url":"https://github.com/autonomio/talos/issues/300","id":440611479,"node_id":"MDU6SXNzdWU0NDA2MTE0Nzk=","number":300,"title":"Using multi_gpu on auto-encoder model","user":{"login":"aaronfderybel","id":43145159,"node_id":"MDQ6VXNlcjQzMTQ1MTU5","avatar_url":"https://avatars.githubusercontent.com/u/43145159?v=4","gravatar_id":"","url":"https://api.github.com/users/aaronfderybel","html_url":"https://github.com/aaronfderybel","followers_url":"https://api.github.com/users/aaronfderybel/followers","following_url":"https://api.github.com/users/aaronfderybel/following{/other_user}","gists_url":"https://api.github.com/users/aaronfderybel/gists{/gist_id}","starred_url":"https://api.github.com/users/aaronfderybel/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aaronfderybel/subscriptions","organizations_url":"https://api.github.com/users/aaronfderybel/orgs","repos_url":"https://api.github.com/users/aaronfderybel/repos","events_url":"https://api.github.com/users/aaronfderybel/events{/privacy}","received_events_url":"https://api.github.com/users/aaronfderybel/received_events","type":"User","site_admin":false},"labels":[{"id":994489876,"node_id":"MDU6TGFiZWw5OTQ0ODk4NzY=","url":"https://api.github.com/repos/autonomio/talos/labels/investigation","name":"investigation","color":"d3d3d3","default":false,"description":"gathering information"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2019-05-06T09:22:16Z","updated_at":"2019-05-14T07:51:15Z","closed_at":"2019-05-14T07:51:15Z","author_association":"NONE","active_lock_reason":null,"body":"Thanks so much for coming here to raise an issue. Please take a moment to 'check' the below boxes:\r\n\r\n- [x ] I'm up-to-date with the latest release:\r\n    \r\n      pip install -U talos\r\n\r\n- [x ] I've confirmed that my Keras model works outside of Talos.\r\n   \r\nCurrently facing a weird/critical bug When running the script below and setting hyperpar to:\r\n```python\r\n    hyperpar = {'opt':[adam, SGD],\\\r\n              'lr': (10**(-3),1,100),\\\r\n              'n_layer':[2],\\\r\n              'loss_func':['mse','binary_crossentropy'],\r\n              'scan_number':[number]\r\n              }\r\n```\r\nI pass the dictionary to the build model function ...\r\n\r\n```python\r\n     def build(self, hyperpar):\r\n        amt = self.col_amt\r\n        window_size = self.generator.window_size\r\n        n_layer = hyperpar[\"n_layer\"]\r\n        # input and first layer\r\n        inputs = Input(batch_shape=(None, window_size, amt))\r\n        encoded = LSTM(amt, return_sequences=True, activation='relu')(inputs)\r\n\r\n        # stacking encoding layers\r\n        for i in range(1, n_layer):\r\n            encoded = LSTM(amt - i, return_sequences=True, activation='relu')(encoded)\r\n        encoded = LSTM(amt - n_layer, activation='relu')(encoded)\r\n\r\n        decoded = RepeatVector(window_size)(encoded)\r\n        # stacking decoding layers\r\n        for i in range(1, n_layer):\r\n            decoded = LSTM(amt - n_layer + i, return_sequences=True, activation='relu')(decoded)\r\n        decoded = LSTM(amt, return_sequences=True, activation='softmax')(decoded)\r\n\r\n        model = Model(inputs, decoded)\r\n        #for talos multi-gpu usage\r\n        model = multi_gpu(model, gpus=[0,1])\r\n\r\n        model.compile(optimizer= hyperpar['opt'](lr=hyperpar['lr']),\\\r\n                      loss=hyperpar['loss_func'])\r\n        model.summary()\r\n\r\n        return model\r\n```\r\n\r\nwhen I use `multi_gpu(..)` I receive the following output for `model.summary()`:\r\n![image](https://user-images.githubusercontent.com/43145159/57216669-ce91b300-6ff0-11e9-86c4-ede7108ab77b.png)\r\n\r\nHowever my model uses LSTM and when removing the `multi_gpu(..)` I receive following expected output:\r\n![image](https://user-images.githubusercontent.com/43145159/57216787-27614b80-6ff1-11e9-83df-63a0afe5f7b0.png)\r\n\r\n\r\nThe model trains and gives output. didn't check if it gives exactly same results. \r\nIn short Should I be worried ? Are these Lambda layers, custom layers created by talos for multi_gpu processing or is some nasty bug going on ?\r\n\r\nThanks in advance,\r\nAaron De Rybel","closed_by":{"login":"mikkokotila","id":7943188,"node_id":"MDQ6VXNlcjc5NDMxODg=","avatar_url":"https://avatars.githubusercontent.com/u/7943188?v=4","gravatar_id":"","url":"https://api.github.com/users/mikkokotila","html_url":"https://github.com/mikkokotila","followers_url":"https://api.github.com/users/mikkokotila/followers","following_url":"https://api.github.com/users/mikkokotila/following{/other_user}","gists_url":"https://api.github.com/users/mikkokotila/gists{/gist_id}","starred_url":"https://api.github.com/users/mikkokotila/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mikkokotila/subscriptions","organizations_url":"https://api.github.com/users/mikkokotila/orgs","repos_url":"https://api.github.com/users/mikkokotila/repos","events_url":"https://api.github.com/users/mikkokotila/events{/privacy}","received_events_url":"https://api.github.com/users/mikkokotila/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/autonomio/talos/issues/300/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/autonomio/talos/issues/300/timeline","performed_via_github_app":null,"state_reason":"completed"}