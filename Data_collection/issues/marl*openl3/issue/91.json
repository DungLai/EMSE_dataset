{"url":"https://api.github.com/repos/marl/openl3/issues/91","repository_url":"https://api.github.com/repos/marl/openl3","labels_url":"https://api.github.com/repos/marl/openl3/issues/91/labels{/name}","comments_url":"https://api.github.com/repos/marl/openl3/issues/91/comments","events_url":"https://api.github.com/repos/marl/openl3/issues/91/events","html_url":"https://github.com/marl/openl3/issues/91","id":1306808565,"node_id":"I_kwDOCSWbMs5N5FD1","number":91,"title":"Example of fine-tuning the audio sub-network.","user":{"login":"mattiacampana","id":1859476,"node_id":"MDQ6VXNlcjE4NTk0NzY=","avatar_url":"https://avatars.githubusercontent.com/u/1859476?v=4","gravatar_id":"","url":"https://api.github.com/users/mattiacampana","html_url":"https://github.com/mattiacampana","followers_url":"https://api.github.com/users/mattiacampana/followers","following_url":"https://api.github.com/users/mattiacampana/following{/other_user}","gists_url":"https://api.github.com/users/mattiacampana/gists{/gist_id}","starred_url":"https://api.github.com/users/mattiacampana/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mattiacampana/subscriptions","organizations_url":"https://api.github.com/users/mattiacampana/orgs","repos_url":"https://api.github.com/users/mattiacampana/repos","events_url":"https://api.github.com/users/mattiacampana/events{/privacy}","received_events_url":"https://api.github.com/users/mattiacampana/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-07-16T13:33:32Z","updated_at":"2022-07-16T13:33:32Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I want to perform the fine-tuning of the audio subnetwork to fit my audio classification problem.\r\nTo this aim, I plan to use the `_construct_linear_audio_network`, `_construct_mel128_audio_network`, and `_construct_mel256_audio_network` functions to load the pre-trained Keras model and then append one or more fully-connected layers to perform the classification.\r\n\r\nHowever, I don't understand the Input shape of such models. According to the `models.py`, the input shape is `input_shape = (1, asr * audio_window_dur)`, where `asr= 48000` and `audio_window_dur=1`; what's `asr` and why it has that value? Can you please provide an example of using the Keras model from the `.wav` file?\r\n\r\nI really appreciate any help you can provide.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/marl/openl3/issues/91/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/marl/openl3/issues/91/timeline","performed_via_github_app":null,"state_reason":null}