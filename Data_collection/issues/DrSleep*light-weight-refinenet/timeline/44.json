[{"url":"https://api.github.com/repos/DrSleep/light-weight-refinenet/issues/comments/520247402","html_url":"https://github.com/DrSleep/light-weight-refinenet/issues/44#issuecomment-520247402","issue_url":"https://api.github.com/repos/DrSleep/light-weight-refinenet/issues/44","id":520247402,"node_id":"MDEyOklzc3VlQ29tbWVudDUyMDI0NzQwMg==","user":{"login":"DrSleep","id":7841432,"node_id":"MDQ6VXNlcjc4NDE0MzI=","avatar_url":"https://avatars.githubusercontent.com/u/7841432?v=4","gravatar_id":"","url":"https://api.github.com/users/DrSleep","html_url":"https://github.com/DrSleep","followers_url":"https://api.github.com/users/DrSleep/followers","following_url":"https://api.github.com/users/DrSleep/following{/other_user}","gists_url":"https://api.github.com/users/DrSleep/gists{/gist_id}","starred_url":"https://api.github.com/users/DrSleep/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DrSleep/subscriptions","organizations_url":"https://api.github.com/users/DrSleep/orgs","repos_url":"https://api.github.com/users/DrSleep/repos","events_url":"https://api.github.com/users/DrSleep/events{/privacy}","received_events_url":"https://api.github.com/users/DrSleep/received_events","type":"User","site_admin":false},"created_at":"2019-08-11T17:52:06Z","updated_at":"2019-08-11T17:52:06Z","author_association":"OWNER","body":"what commands did you run and what changes did you make to the code?","reactions":{"url":"https://api.github.com/repos/DrSleep/light-weight-refinenet/issues/comments/520247402/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"DrSleep","id":7841432,"node_id":"MDQ6VXNlcjc4NDE0MzI=","avatar_url":"https://avatars.githubusercontent.com/u/7841432?v=4","gravatar_id":"","url":"https://api.github.com/users/DrSleep","html_url":"https://github.com/DrSleep","followers_url":"https://api.github.com/users/DrSleep/followers","following_url":"https://api.github.com/users/DrSleep/following{/other_user}","gists_url":"https://api.github.com/users/DrSleep/gists{/gist_id}","starred_url":"https://api.github.com/users/DrSleep/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DrSleep/subscriptions","organizations_url":"https://api.github.com/users/DrSleep/orgs","repos_url":"https://api.github.com/users/DrSleep/repos","events_url":"https://api.github.com/users/DrSleep/events{/privacy}","received_events_url":"https://api.github.com/users/DrSleep/received_events","type":"User","site_admin":false}},{"id":2582186383,"node_id":"MDExOkNsb3NlZEV2ZW50MjU4MjE4NjM4Mw==","url":"https://api.github.com/repos/DrSleep/light-weight-refinenet/issues/events/2582186383","actor":{"login":"DrSleep","id":7841432,"node_id":"MDQ6VXNlcjc4NDE0MzI=","avatar_url":"https://avatars.githubusercontent.com/u/7841432?v=4","gravatar_id":"","url":"https://api.github.com/users/DrSleep","html_url":"https://github.com/DrSleep","followers_url":"https://api.github.com/users/DrSleep/followers","following_url":"https://api.github.com/users/DrSleep/following{/other_user}","gists_url":"https://api.github.com/users/DrSleep/gists{/gist_id}","starred_url":"https://api.github.com/users/DrSleep/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DrSleep/subscriptions","organizations_url":"https://api.github.com/users/DrSleep/orgs","repos_url":"https://api.github.com/users/DrSleep/repos","events_url":"https://api.github.com/users/DrSleep/events{/privacy}","received_events_url":"https://api.github.com/users/DrSleep/received_events","type":"User","site_admin":false},"event":"closed","commit_id":null,"commit_url":null,"created_at":"2019-08-25T23:10:41Z","state_reason":null,"performed_via_github_app":null},{"url":"https://api.github.com/repos/DrSleep/light-weight-refinenet/issues/comments/524691006","html_url":"https://github.com/DrSleep/light-weight-refinenet/issues/44#issuecomment-524691006","issue_url":"https://api.github.com/repos/DrSleep/light-weight-refinenet/issues/44","id":524691006,"node_id":"MDEyOklzc3VlQ29tbWVudDUyNDY5MTAwNg==","user":{"login":"electronicYH","id":11705091,"node_id":"MDQ6VXNlcjExNzA1MDkx","avatar_url":"https://avatars.githubusercontent.com/u/11705091?v=4","gravatar_id":"","url":"https://api.github.com/users/electronicYH","html_url":"https://github.com/electronicYH","followers_url":"https://api.github.com/users/electronicYH/followers","following_url":"https://api.github.com/users/electronicYH/following{/other_user}","gists_url":"https://api.github.com/users/electronicYH/gists{/gist_id}","starred_url":"https://api.github.com/users/electronicYH/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/electronicYH/subscriptions","organizations_url":"https://api.github.com/users/electronicYH/orgs","repos_url":"https://api.github.com/users/electronicYH/repos","events_url":"https://api.github.com/users/electronicYH/events{/privacy}","received_events_url":"https://api.github.com/users/electronicYH/received_events","type":"User","site_admin":false},"created_at":"2019-08-26T02:18:27Z","updated_at":"2019-08-26T02:18:27Z","author_association":"NONE","body":"the command in nyu.sh is : \r\n#!/bin/sh\r\nPYTHONPATH=$(pwd):$PYTHONPATH python src/train.py \\\r\n    --enc 50 #--evaluate true\r\n\r\nand the train.py is : \r\n\"\"\"RefineNet-LightWeight\r\n\r\nRefineNet-LigthWeight PyTorch for non-commercial purposes\r\n\r\nCopyright (c) 2018, Vladimir Nekrasov (vladimir.nekrasov@adelaide.edu.au)\r\nAll rights reserved.\r\n\r\nRedistribution and use in source and binary forms, with or without\r\nmodification, are permitted provided that the following conditions are met:\r\n\r\n* Redistributions of source code must retain the above copyright notice, this\r\n  list of conditions and the following disclaimer.\r\n\r\n* Redistributions in binary form must reproduce the above copyright notice,\r\n  this list of conditions and the following disclaimer in the documentation\r\n  and/or other materials provided with the distribution.\r\n\r\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\r\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\r\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\r\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\r\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\r\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\r\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\r\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\r\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\r\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\r\n\"\"\"\r\n\r\n# general libs\r\nimport argparse\r\nimport logging\r\nimport os\r\nimport random\r\nimport re\r\nimport sys\r\nimport time\r\n\r\n# misc\r\nimport cv2\r\nimport numpy as np\r\n\r\n# pytorch libs\r\nimport torch\r\nimport torch.nn as nn\r\n\r\n# custom libs\r\nfrom config import *\r\nfrom miou_utils import compute_iu, fast_cm\r\nfrom util import *\r\n\r\ndef get_arguments():\r\n    \"\"\"Parse all the arguments provided from the CLI.\r\n\r\n    Returns:\r\n      A list of parsed arguments.\r\n    \"\"\"\r\n    parser = argparse.ArgumentParser(description=\"Full Pipeline Training\")\r\n\r\n    # Dataset\r\n    parser.add_argument(\"--train-dir\", type=str, default=TRAIN_DIR,\r\n                        help=\"Path to the training set directory.\")\r\n    parser.add_argument(\"--val-dir\", type=str, default=VAL_DIR,\r\n                        help=\"Path to the validation set directory.\")\r\n    parser.add_argument(\"--train-list\", type=str, nargs='+', default=TRAIN_LIST,\r\n                        help=\"Path to the training set list.\")\r\n    parser.add_argument(\"--val-list\", type=str, nargs='+', default=VAL_LIST,\r\n                        help=\"Path to the validation set list.\")\r\n    parser.add_argument(\"--shorter-side\", type=int, nargs='+', default=SHORTER_SIDE,\r\n                        help=\"Shorter side transformation.\")\r\n    parser.add_argument(\"--crop-size\", type=int, nargs='+', default=CROP_SIZE,\r\n                        help=\"Crop size for training,\")\r\n    parser.add_argument(\"--normalise-params\", type=list, default=NORMALISE_PARAMS,\r\n                        help=\"Normalisation parameters [scale, mean, std],\")\r\n    parser.add_argument(\"--batch-size\", type=int, nargs='+', default=BATCH_SIZE,\r\n                        help=\"Batch size to train the segmenter model.\")\r\n    parser.add_argument(\"--num-workers\", type=int, default=NUM_WORKERS,\r\n                        help=\"Number of workers for pytorch's dataloader.\")\r\n    parser.add_argument(\"--num-classes\", type=int, nargs='+', default=NUM_CLASSES,\r\n                        help=\"Number of output classes for each task.\")\r\n    parser.add_argument(\"--low-scale\", type=float, nargs='+', default=LOW_SCALE,\r\n                        help=\"Lower bound for random scale\")\r\n    parser.add_argument(\"--high-scale\", type=float, nargs='+', default=HIGH_SCALE,\r\n                        help=\"Upper bound for random scale\")\r\n    parser.add_argument(\"--ignore-label\", type=int, default=IGNORE_LABEL,\r\n                        help=\"Label to ignore during training\")\r\n\r\n    # Encoder\r\n    parser.add_argument(\"--enc\", type=str, default=ENC,\r\n                        help=\"Encoder net type.\")\r\n    parser.add_argument(\"--enc-pretrained\", type=bool, default=ENC_PRETRAINED,\r\n                        help='Whether to init with imagenet weights.')\r\n    # General\r\n    parser.add_argument(\"--evaluate\", type=bool, default=EVALUATE,\r\n                        help='If true, only validate segmentation.')\r\n    parser.add_argument(\"--freeze-bn\", type=bool, nargs='+', default=FREEZE_BN,\r\n                        help='Whether to keep batch norm statistics intact.')\r\n    parser.add_argument(\"--num-segm-epochs\", type=int, nargs='+', default=NUM_SEGM_EPOCHS,\r\n                        help='Number of epochs to train for segmentation network.')\r\n    parser.add_argument(\"--print-every\", type=int, default=PRINT_EVERY,\r\n                        help='Print information every often.')\r\n    parser.add_argument(\"--random-seed\", type=int, default=RANDOM_SEED,\r\n                        help='Seed to provide (near-)reproducibility.')\r\n    parser.add_argument(\"--snapshot-dir\", type=str, default=SNAPSHOT_DIR,\r\n                        help=\"Path to directory for storing checkpoints.\")\r\n    parser.add_argument(\"--ckpt-path\", type=str, default=CKPT_PATH,\r\n                        help=\"Path to the checkpoint file.\")\r\n    parser.add_argument(\"--val-every\", nargs='+', type=int, default=VAL_EVERY,\r\n                        help=\"How often to validate current architecture.\")\r\n\r\n    # Optimisers\r\n    parser.add_argument(\"--lr-enc\", type=float, nargs='+', default=LR_ENC,\r\n                        help=\"Learning rate for encoder.\")\r\n    parser.add_argument(\"--lr-dec\", type=float, nargs='+', default=LR_DEC,\r\n                        help=\"Learning rate for decoder.\")\r\n    parser.add_argument(\"--mom-enc\", type=float, nargs='+', default=MOM_ENC,\r\n                        help=\"Momentum for encoder.\")\r\n    parser.add_argument(\"--mom-dec\", type=float, nargs='+', default=MOM_DEC,\r\n                        help=\"Momentum for decoder.\")\r\n    parser.add_argument(\"--wd-enc\", type=float, nargs='+', default=WD_ENC,\r\n                        help=\"Weight decay for encoder.\")\r\n    parser.add_argument(\"--wd-dec\", type=float, nargs='+', default=WD_DEC,\r\n                        help=\"Weight decay for decoder.\")\r\n    parser.add_argument(\"--optim-dec\", type=str, default=OPTIM_DEC,\r\n                        help=\"Optimiser algorithm for decoder.\")\r\n    return parser.parse_args()\r\n\r\ndef create_segmenter(\r\n    net, pretrained, num_classes\r\n    ):\r\n    \"\"\"Create Encoder; for now only ResNet [50,101,152]\"\"\"\r\n    from models.resnet import rf_lw50, rf_lw101, rf_lw152\r\n    if str(net) == '50':\r\n        return rf_lw50(num_classes, imagenet=pretrained)\r\n    elif str(net) == '101':\r\n        return rf_lw101(num_classes, imagenet=pretrained)\r\n    elif str(net) == '152':\r\n        return rf_lw152(num_classes, imagenet=pretrained)\r\n    else:\r\n        raise ValueError(\"{} is not supported\".format(str(net)))\r\n\r\ndef create_loaders(\r\n    train_dir, val_dir, train_list, val_list,\r\n    shorter_side, crop_size, low_scale, high_scale,\r\n    normalise_params, batch_size, num_workers, ignore_label\r\n    ):\r\n    \"\"\"\r\n    Args:\r\n      train_dir (str) : path to the root directory of the training set.\r\n      val_dir (str) : path to the root directory of the validation set.\r\n      train_list (str) : path to the training list.\r\n      val_list (str) : path to the validation list.\r\n      shorter_side (int) : parameter of the shorter_side resize transformation.\r\n      crop_size (int) : square crop to apply during the training.\r\n      low_scale (float) : lowest scale ratio for augmentations.\r\n      high_scale (float) : highest scale ratio for augmentations.\r\n      normalise_params (list / tuple) : img_scale, img_mean, img_std.\r\n      batch_size (int) : training batch size.\r\n      num_workers (int) : number of workers to parallelise data loading operations.\r\n      ignore_label (int) : label to pad segmentation masks with\r\n\r\n    Returns:\r\n      train_loader, val loader\r\n\r\n    \"\"\"\r\n    # Torch libraries\r\n    from torchvision import transforms\r\n    from torch.utils.data import DataLoader, random_split\r\n    # Custom libraries\r\n    from datasets import NYUDataset as Dataset\r\n    from datasets import Pad, RandomCrop, RandomMirror, ResizeShorterScale, ToTensor, Normalise\r\n\r\n    ## Transformations during training ##\r\n    composed_trn = transforms.Compose([#ResizeShorterScale(shorter_side, low_scale, high_scale),\r\n                                    #Pad(crop_size, [105.57, 104.295 , 107.61], ignore_label),\r\n                                    #RandomMirror(),\r\n                                    #RandomCrop(crop_size),\r\n                                    Normalise(*normalise_params),\r\n                                    ToTensor()])\r\n                                    #Pad(crop_size, [105.57, 104.295 , 107.61], ignore_label),\r\n\r\n    composed_val = transforms.Compose([Normalise(*normalise_params),\r\n                                    ToTensor()])\r\n    ## Training and validation sets ##\r\n    trainset = Dataset(data_file=train_list,\r\n                       data_dir=train_dir,\r\n                       transform_trn=composed_trn,\r\n                       transform_val=composed_val)\r\n\r\n    valset = Dataset(data_file=val_list,\r\n                         data_dir=val_dir,\r\n                         transform_trn=None,\r\n                         transform_val=composed_val)\r\n    logger.info(\" Created train set = {} examples, val set = {} examples\"\r\n                .format(len(trainset), len(valset)))\r\n    ## Training and validation loaders ##\r\n    train_loader = DataLoader(trainset,\r\n                              batch_size=batch_size,\r\n                              shuffle=True,\r\n                              num_workers=num_workers,\r\n                              pin_memory=True,\r\n                              drop_last=True)\r\n    val_loader = DataLoader(valset,\r\n                            batch_size=1,\r\n                            shuffle=False,\r\n                            num_workers=num_workers,\r\n                            pin_memory=True)\r\n    return train_loader, val_loader\r\n\r\ndef create_optimisers(\r\n    lr_enc, lr_dec,\r\n    mom_enc, mom_dec,\r\n    wd_enc, wd_dec,\r\n    param_enc, param_dec,\r\n    optim_dec\r\n    ):\r\n    \"\"\"Create optimisers for encoder, decoder and controller\"\"\"\r\n    optim_enc = torch.optim.SGD(param_enc, lr=lr_enc, momentum=mom_enc,\r\n                                weight_decay=wd_enc)\r\n    if optim_dec == 'sgd':\r\n        optim_dec = torch.optim.SGD(param_dec, lr=lr_dec,\r\n                                    momentum=mom_dec, weight_decay=wd_dec)\r\n    elif optim_dec == 'adam':\r\n        optim_dec = torch.optim.Adam(param_dec, lr=lr_dec, weight_decay=wd_dec, eps=1e-3)\r\n    return optim_enc, optim_dec\r\n\r\ndef load_ckpt(\r\n    ckpt_path, ckpt_dict\r\n    ):\r\n    best_val = epoch_start = 0\r\n    if os.path.exists(args.ckpt_path):\r\n        ckpt = torch.load(ckpt_path)\r\n        for (k, v) in ckpt_dict.items():\r\n            if k in ckpt:\r\n                v.load_state_dict(ckpt[k])\r\n        best_val = ckpt.get('best_val', 0)\r\n        epoch_start = ckpt.get('epoch_start', 0)\r\n        logger.info(\" Found checkpoint at {} with best_val {:.4f} at epoch {}\".\r\n            format(\r\n                ckpt_path, best_val, epoch_start\r\n            ))\r\n    return best_val, epoch_start\r\n\r\ndef train_segmenter(\r\n    segmenter, train_loader, optim_enc, optim_dec,\r\n    epoch, segm_crit, freeze_bn\r\n    ):\r\n    \"\"\"Training segmenter\r\n\r\n    Args:\r\n      segmenter (nn.Module) : segmentation network\r\n      train_loader (DataLoader) : training data iterator\r\n      optim_enc (optim) : optimiser for encoder\r\n      optim_dec (optim) : optimiser for decoder\r\n      epoch (int) : current epoch\r\n      segm_crit (nn.Loss) : segmentation criterion\r\n      freeze_bn (bool) : whether to keep BN params intact\r\n\r\n    \"\"\"\r\n    train_loader.dataset.set_stage('train')\r\n    segmenter.train()\r\n    if freeze_bn:\r\n        for m in segmenter.modules():\r\n            if isinstance(m, nn.BatchNorm2d):\r\n                m.eval()\r\n    batch_time = AverageMeter()\r\n    losses = AverageMeter()\r\n    for i, sample in enumerate(train_loader):\r\n        start = time.time()\r\n        input = sample['image'].cuda()\r\n        target = sample['mask'].cuda()\r\n        input_var = torch.autograd.Variable(input).float()\r\n        target_var = torch.autograd.Variable(target).long()\r\n        # Compute output\r\n        output = segmenter(input_var)\r\n        output = nn.functional.interpolate(output, size=target_var.size()[1:], mode='bilinear', align_corners=False)\r\n        soft_output = nn.LogSoftmax()(output)\r\n        # Compute loss and backpropagate\r\n        loss = segm_crit(soft_output, target_var)\r\n        optim_enc.zero_grad()\r\n        optim_dec.zero_grad()\r\n        loss.backward()\r\n        optim_enc.step()\r\n        optim_dec.step()\r\n        losses.update(loss.item())\r\n        batch_time.update(time.time() - start)\r\n        if i % args.print_every == 0:\r\n            logger.info(' Train epoch: {} [{}/{}]\\t'\r\n                        'Avg. Loss: {:.3f}\\t'\r\n                        'Avg. Time: {:.3f}'.format(\r\n                            epoch, i, len(train_loader),\r\n                            losses.avg, batch_time.avg\r\n                        ))\r\n\r\ndef validate(\r\n    segmenter, val_loader, epoch, num_classes=-1\r\n    ):\r\n    \"\"\"Validate segmenter\r\n\r\n    Args:\r\n      segmenter (nn.Module) : segmentation network\r\n      val_loader (DataLoader) : training data iterator\r\n      epoch (int) : current epoch\r\n      num_classes (int) : number of classes to consider\r\n\r\n    Returns:\r\n      Mean IoU (float)\r\n    \"\"\"\r\n    val_loader.dataset.set_stage('val')\r\n    segmenter.eval()\r\n    cm = np.zeros((num_classes, num_classes), dtype=int)\r\n    with torch.no_grad():\r\n        for i, sample in enumerate(val_loader):\r\n            start = time.time()\r\n            input = sample['image']\r\n            target = sample['mask']\r\n            input_var = torch.autograd.Variable(input).float().cuda()\r\n            # Compute output\r\n            output = segmenter(input_var)\r\n            output = cv2.resize(output[0, :num_classes].data.cpu().numpy().transpose(1, 2, 0),\r\n                                target.size()[1:][::-1],\r\n                                interpolation=cv2.INTER_CUBIC).argmax(axis=2).astype(np.uint8)\r\n            \r\n            #cv2.imshow('output',50*output)\r\n            #cv2.waitKey()\r\n            cv2.imwrite(str(i)+'.jpg',output)\r\n            # Compute IoU\r\n            gt = target[0].data.cpu().numpy().astype(np.uint8)\r\n            gt_idx = gt < num_classes # Ignore every class index larger than the number of classes\r\n            cm += fast_cm(output[gt_idx], gt[gt_idx], num_classes)\r\n\r\n            if i % args.print_every == 0:\r\n                logger.info(' Val epoch: {} [{}/{}]\\t'\r\n                            'Mean IoU: {:.3f}'.format(\r\n                                epoch, i, len(val_loader),\r\n                                compute_iu(cm).mean()\r\n                            ))\r\n\r\n    ious = compute_iu(cm)\r\n    logger.info(\" IoUs: {}\".format(ious))\r\n    miou = np.mean(ious)\r\n    logger.info(' Val epoch: {}\\tMean IoU: {:.3f}'.format(\r\n                                epoch, miou))\r\n    return miou\r\n\r\ndef main():\r\n    global args, logger\r\n    args = get_arguments()\r\n    logger = logging.getLogger(__name__)\r\n    ## Add args ##\r\n    args.num_stages = len(args.num_classes)\r\n    ## Set random seeds ##\r\n    torch.backends.cudnn.deterministic = True\r\n    torch.manual_seed(args.random_seed)\r\n    if torch.cuda.is_available():\r\n        torch.cuda.manual_seed_all(args.random_seed)\r\n    np.random.seed(args.random_seed)\r\n    random.seed(args.random_seed)\r\n    ## Generate Segmenter ##\r\n    segmenter = nn.DataParallel(\r\n        create_segmenter(args.enc, args.enc_pretrained, args.num_classes[0])\r\n        ).cuda()\r\n    logger.info(\" Loaded Segmenter {}, ImageNet-Pre-Trained={}, #PARAMS={:3.2f}M\"\r\n                .format(args.enc, args.enc_pretrained, compute_params(segmenter) / 1e6))\r\n    ## Restore if any ##\r\n    best_val, epoch_start = load_ckpt(args.ckpt_path, {'segmenter' : segmenter})\r\n    ## Criterion ##\r\n    segm_crit = nn.NLLLoss2d(ignore_index=args.ignore_label).cuda()\r\n\r\n    ## Saver ##\r\n    saver = Saver(args=vars(args),\r\n                  ckpt_dir=args.snapshot_dir,\r\n                  best_val=best_val,\r\n                  condition=lambda x, y: x > y)  # keep checkpoint with the best validation score\r\n\r\n    logger.info(\" Training Process Starts\")\r\n    for task_idx in range(args.num_stages):\r\n        start = time.time()\r\n        torch.cuda.empty_cache()\r\n        ## Create dataloaders ##\r\n        train_loader, val_loader = create_loaders(args.train_dir,\r\n                                                  args.val_dir,\r\n                                                  args.train_list[task_idx],\r\n                                                  args.val_list[task_idx],\r\n                                                  args.shorter_side[task_idx],\r\n                                                  args.crop_size[task_idx],\r\n                                                  args.low_scale[task_idx],\r\n                                                  args.high_scale[task_idx],\r\n                                                  args.normalise_params,\r\n                                                  args.batch_size[task_idx],\r\n                                                  args.num_workers,\r\n                                                  args.ignore_label)\r\n        if args.evaluate:\r\n            return validate(segmenter, val_loader, 0, num_classes=args.num_classes[task_idx])\r\n\r\n        logger.info(\" Training Stage {}\".format(str(task_idx)))\r\n        ## Optimisers ##\r\n        enc_params = []\r\n        dec_params = []\r\n        for k,v in segmenter.named_parameters():\r\n            if bool(re.match(\".*conv1.*|.*bn1.*|.*layer.*\", k)):\r\n                enc_params.append(v)\r\n                logger.info(\" Enc. parameter: {}\".format(k))\r\n            else:\r\n                dec_params.append(v)\r\n                logger.info(\" Dec. parameter: {}\".format(k))\r\n        optim_enc, optim_dec = create_optimisers(args.lr_enc[task_idx], args.lr_dec[task_idx],\r\n                                                 args.mom_enc[task_idx], args.mom_dec[task_idx],\r\n                                                 args.wd_enc[task_idx], args.wd_dec[task_idx],\r\n                                                 enc_params, dec_params, args.optim_dec)\r\n        for epoch in range(args.num_segm_epochs[task_idx]):\r\n            train_segmenter(segmenter, train_loader,\r\n                            optim_enc, optim_dec,\r\n                            epoch_start, segm_crit,\r\n                            args.freeze_bn[task_idx])\r\n            if (epoch + 1) % (args.val_every[task_idx]) == 0:\r\n                miou = validate(segmenter, val_loader, epoch_start, args.num_classes[task_idx])\r\n                saver.save(\r\n                    miou,\r\n                    {'segmenter' : segmenter.state_dict(),\r\n                     'epoch_start' : epoch_start}, logger\r\n                     )\r\n            epoch_start += 1\r\n        logger.info(\"Stage {} finished, time spent {:.3f}min\".format(\r\n            task_idx, (time.time() - start) / 60.))\r\n    logger.info(\"All stages are now finished. Best Val is {:.3f}\".format(\r\n        saver.best_val))\r\n\r\nif __name__ == '__main__':\r\n    logging.basicConfig(level=logging.INFO)\r\n    main()","reactions":{"url":"https://api.github.com/repos/DrSleep/light-weight-refinenet/issues/comments/524691006/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"electronicYH","id":11705091,"node_id":"MDQ6VXNlcjExNzA1MDkx","avatar_url":"https://avatars.githubusercontent.com/u/11705091?v=4","gravatar_id":"","url":"https://api.github.com/users/electronicYH","html_url":"https://github.com/electronicYH","followers_url":"https://api.github.com/users/electronicYH/followers","following_url":"https://api.github.com/users/electronicYH/following{/other_user}","gists_url":"https://api.github.com/users/electronicYH/gists{/gist_id}","starred_url":"https://api.github.com/users/electronicYH/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/electronicYH/subscriptions","organizations_url":"https://api.github.com/users/electronicYH/orgs","repos_url":"https://api.github.com/users/electronicYH/repos","events_url":"https://api.github.com/users/electronicYH/events{/privacy}","received_events_url":"https://api.github.com/users/electronicYH/received_events","type":"User","site_admin":false}}]