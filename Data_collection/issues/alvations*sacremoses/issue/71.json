{"url":"https://api.github.com/repos/alvations/sacremoses/issues/71","repository_url":"https://api.github.com/repos/alvations/sacremoses","labels_url":"https://api.github.com/repos/alvations/sacremoses/issues/71/labels{/name}","comments_url":"https://api.github.com/repos/alvations/sacremoses/issues/71/comments","events_url":"https://api.github.com/repos/alvations/sacremoses/issues/71/events","html_url":"https://github.com/alvations/sacremoses/issues/71","id":501789320,"node_id":"MDU6SXNzdWU1MDE3ODkzMjA=","number":71,"title":"detokenization does not add a space between Chinese/Japanese characters and non-CJK characters","user":{"login":"brandonherzog","id":13034948,"node_id":"MDQ6VXNlcjEzMDM0OTQ4","avatar_url":"https://avatars.githubusercontent.com/u/13034948?v=4","gravatar_id":"","url":"https://api.github.com/users/brandonherzog","html_url":"https://github.com/brandonherzog","followers_url":"https://api.github.com/users/brandonherzog/followers","following_url":"https://api.github.com/users/brandonherzog/following{/other_user}","gists_url":"https://api.github.com/users/brandonherzog/gists{/gist_id}","starred_url":"https://api.github.com/users/brandonherzog/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/brandonherzog/subscriptions","organizations_url":"https://api.github.com/users/brandonherzog/orgs","repos_url":"https://api.github.com/users/brandonherzog/repos","events_url":"https://api.github.com/users/brandonherzog/events{/privacy}","received_events_url":"https://api.github.com/users/brandonherzog/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2019-10-03T00:24:07Z","updated_at":"2019-10-03T01:21:38Z","closed_at":"2019-10-03T01:21:38Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"The original Moses perl scripts add a space between tokens that do not end with a CJK character and tokens that do:\r\nhttps://github.com/moses-smt/mosesdecoder/blob/555829a771cd897bb807f495a95737953a7ca9a3/scripts/tokenizer/detokenizer.perl#L109-L115\r\n\r\nThe current Python port only adds a space if a token starts with a CJK character and does not end with a CJK character:\r\nhttps://github.com/alvations/sacremoses/blob/4d994b8781f6c10600d34413679e1a1acdb53cb5/sacremoses/tokenize.py#L692-L696\r\n\r\nThis seems like a mistake and I would expect the original behavior to be replicated.\r\n\r\n```\r\ndetokenizer = MosesDetokenizer()\r\ntext = detokenizer.detokenize(['Japan', 'is', '日', '本', 'in', 'Japanese', '.'])\r\nassert text == 'Japan is 日本 in Japanese.'\r\n# it actually will currently return 'Japan is日本 in Japanese.' with no space before 日\r\n```","closed_by":{"login":"alvations","id":1050316,"node_id":"MDQ6VXNlcjEwNTAzMTY=","avatar_url":"https://avatars.githubusercontent.com/u/1050316?v=4","gravatar_id":"","url":"https://api.github.com/users/alvations","html_url":"https://github.com/alvations","followers_url":"https://api.github.com/users/alvations/followers","following_url":"https://api.github.com/users/alvations/following{/other_user}","gists_url":"https://api.github.com/users/alvations/gists{/gist_id}","starred_url":"https://api.github.com/users/alvations/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alvations/subscriptions","organizations_url":"https://api.github.com/users/alvations/orgs","repos_url":"https://api.github.com/users/alvations/repos","events_url":"https://api.github.com/users/alvations/events{/privacy}","received_events_url":"https://api.github.com/users/alvations/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/alvations/sacremoses/issues/71/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/alvations/sacremoses/issues/71/timeline","performed_via_github_app":null,"state_reason":"completed"}