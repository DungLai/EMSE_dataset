{"url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/121","repository_url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai","labels_url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/121/labels{/name}","comments_url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/121/comments","events_url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/121/events","html_url":"https://github.com/huggingface/transfer-learning-conv-ai/issues/121","id":1301079407,"node_id":"I_kwDOCwz_ac5NjOVv","number":121,"title":"Batchwise padding dataset","user":{"login":"engmrgh","id":43805623,"node_id":"MDQ6VXNlcjQzODA1NjIz","avatar_url":"https://avatars.githubusercontent.com/u/43805623?v=4","gravatar_id":"","url":"https://api.github.com/users/engmrgh","html_url":"https://github.com/engmrgh","followers_url":"https://api.github.com/users/engmrgh/followers","following_url":"https://api.github.com/users/engmrgh/following{/other_user}","gists_url":"https://api.github.com/users/engmrgh/gists{/gist_id}","starred_url":"https://api.github.com/users/engmrgh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/engmrgh/subscriptions","organizations_url":"https://api.github.com/users/engmrgh/orgs","repos_url":"https://api.github.com/users/engmrgh/repos","events_url":"https://api.github.com/users/engmrgh/events{/privacy}","received_events_url":"https://api.github.com/users/engmrgh/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-07-11T18:38:10Z","updated_at":"2022-07-11T18:38:10Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hello \r\nI'm pretty new to Pytorch so sorry if this question was so simple. Because of memory limits, I can't pad my dataset as a whole. So I was wondering what is the simplest way to move the `pad_dataset` function into the training process, I mean how can I pad the dataset in a batch? For ease of reference, I added the `pad_dataset` below. \r\nThanks.\r\n\r\n```\r\ndef pad_dataset(dataset, padding=0):\r\n    \"\"\" Pad the dataset. This could be optimized by defining a Dataset class and padding at the batch level, but this is simpler. \"\"\"\r\n    max_l = max(len(x) for x in dataset[\"input_ids\"])\r\n    for name in PADDED_INPUTS:\r\n        dataset[name] = [x + [padding if name != \"lm_labels\" else -100] * (max_l - len(x)) for x in dataset[name]]\r\n    return dataset\r\n```","closed_by":null,"reactions":{"url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/121/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/121/timeline","performed_via_github_app":null,"state_reason":null}