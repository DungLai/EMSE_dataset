{"url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/13","repository_url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai","labels_url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/13/labels{/name}","comments_url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/13/comments","events_url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/13/events","html_url":"https://github.com/huggingface/transfer-learning-conv-ai/issues/13","id":453437066,"node_id":"MDU6SXNzdWU0NTM0MzcwNjY=","number":13,"title":"README vs Defaults: Which training parameters lead to Hits@1 over 79","user":{"login":"starlightwy","id":35663080,"node_id":"MDQ6VXNlcjM1NjYzMDgw","avatar_url":"https://avatars.githubusercontent.com/u/35663080?v=4","gravatar_id":"","url":"https://api.github.com/users/starlightwy","html_url":"https://github.com/starlightwy","followers_url":"https://api.github.com/users/starlightwy/followers","following_url":"https://api.github.com/users/starlightwy/following{/other_user}","gists_url":"https://api.github.com/users/starlightwy/gists{/gist_id}","starred_url":"https://api.github.com/users/starlightwy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/starlightwy/subscriptions","organizations_url":"https://api.github.com/users/starlightwy/orgs","repos_url":"https://api.github.com/users/starlightwy/repos","events_url":"https://api.github.com/users/starlightwy/events{/privacy}","received_events_url":"https://api.github.com/users/starlightwy/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2019-06-07T10:08:05Z","updated_at":"2019-10-03T20:27:30Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi team thank you very much for the great work and the clean code! I got some problem while running the code and was wondering if you could give me some help :-)\r\n\r\n1. I just got an error while I'm trying to evaluate the F1 score with convai_evaluation.py:\r\n\r\n> Traceback (most recent call last):\r\n  File \"../convai_evaluation.py\", line 239, in <module>\r\n    eval_fct(opt)\r\n  File \"/home/wang/PycharmProjects/transfer-learning-conv-ai/ParlAI/projects/convai2/eval_f1.py\", line 27, in eval_f1\r\n    report = eval_model(opt, print_parser)\r\n  File \"/home/wang/PycharmProjects/transfer-learning-conv-ai/ParlAI/parlai/scripts/eval_model.py\", line 84, in eval_model\r\n    world.parley()\r\n  File \"/home/wang/PycharmProjects/transfer-learning-conv-ai/ParlAI/parlai/core/worlds.py\", line 275, in parley\r\n    acts[1] = agents[1].act()\r\n  File \"/home/wang/PycharmProjects/transfer-learning-conv-ai/convai_evaluation.py\", line 156, in act\r\n    out_ids, _ = sample_sequence(self.persona, self.history, self.tokenizer, self.model_checkpoint, self.args)\r\n  File \"/home/wang/PycharmProjects/transfer-learning-conv-ai/interact.py\", line 74, in sample_sequence\r\n    logits = top_filtering(logits, top_k=args.top_k, top_p=args.top_p)\r\nAttributeError: 'AttrDict' object has no attribute 'top_p'\r\n\r\nThen I tried to add an top_p argument but then got:\r\n\r\n> Traceback (most recent call last):\r\n  File \"../convai_evaluation.py\", line 239, in <module>\r\n    eval_fct(opt)\r\n  File \"/home/wang/PycharmProjects/transfer-learning-conv-ai/ParlAI/projects/convai2/eval_f1.py\", line 27, in eval_f1\r\n    report = eval_model(opt, print_parser)\r\n  File \"/home/wang/PycharmProjects/transfer-learning-conv-ai/ParlAI/parlai/scripts/eval_model.py\", line 84, in eval_model\r\n    world.parley()\r\n  File \"/home/wang/PycharmProjects/transfer-learning-conv-ai/ParlAI/parlai/core/worlds.py\", line 275, in parley\r\n    acts[1] = agents[1].act()\r\n  File \"/home/wang/PycharmProjects/transfer-learning-conv-ai/convai_evaluation.py\", line 156, in act\r\n    out_ids, _ = sample_sequence(self.persona, self.history, self.tokenizer, self.model_checkpoint, self.args)\r\nValueError: too many values to unpack (expected 2)\r\n\r\nI changed this line (line 151 in the original script convai_evaluation.py) from \r\n`out_ids, _ = sample_sequence(self.persona, self.history, self.tokenizer, self.model_checkpoint, self.args)`\r\ninto\r\n`out_ids = sample_sequence(self.persona, self.history, self.tokenizer, self.model_checkpoint, self.args)`\r\nand it works. \r\n\r\nCould you please tell me if it's a bug here or if I ran and changed the code in a wrong way? In the table of `Running ConvAI2 evaluation scripts` in readme, the default parameters are the same as the one in `Using the interaction script` part, which look different from the defined parameters in evaluation script.\r\n\r\n2. In the `Using the training script part` it was said `\"This model should give a Hits@1 over 79, perplexity of 20.5 and F1 of 16.5 using the convai2 evaluation script (see below).\"` I was wondering if this result is based on the model which is trained by the default parameters or the parameters which are given in your example (see below)?\r\n\r\n> python -m torch.distributed.launch --nproc_per_node=8 ./train.py --gradient_accumulation_steps=4 --lm_coef=2.0 --max_history=2 --n_epochs=1 --num_candidates=4 --personality_permutations=2 --train_batch_size=2 --valid_batch_size=2\r\n\r\nI trained two models, the first one based on the default parameters and the second one based on the parameters in this example. But the first one gave better result which is correspond to \"Hits@1 over 79, perplexity of 20.5 and F1 of 16.5\". So I'm curious about that.\r\n\r\nThank you very much in advance!","closed_by":null,"reactions":{"url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/13/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/13/timeline","performed_via_github_app":null,"state_reason":null}