{"url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/82","repository_url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai","labels_url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/82/labels{/name}","comments_url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/82/comments","events_url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/82/events","html_url":"https://github.com/huggingface/transfer-learning-conv-ai/issues/82","id":646020373,"node_id":"MDU6SXNzdWU2NDYwMjAzNzM=","number":82,"title":"Difference in fine-tuned models linked in README and used in interact.py script","user":{"login":"AmanTiwari1503","id":31160025,"node_id":"MDQ6VXNlcjMxMTYwMDI1","avatar_url":"https://avatars.githubusercontent.com/u/31160025?v=4","gravatar_id":"","url":"https://api.github.com/users/AmanTiwari1503","html_url":"https://github.com/AmanTiwari1503","followers_url":"https://api.github.com/users/AmanTiwari1503/followers","following_url":"https://api.github.com/users/AmanTiwari1503/following{/other_user}","gists_url":"https://api.github.com/users/AmanTiwari1503/gists{/gist_id}","starred_url":"https://api.github.com/users/AmanTiwari1503/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AmanTiwari1503/subscriptions","organizations_url":"https://api.github.com/users/AmanTiwari1503/orgs","repos_url":"https://api.github.com/users/AmanTiwari1503/repos","events_url":"https://api.github.com/users/AmanTiwari1503/events{/privacy}","received_events_url":"https://api.github.com/users/AmanTiwari1503/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-06-26T05:35:15Z","updated_at":"2022-02-08T11:26:21Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"The pre-trained and fine-tuned model, given in the README of the repo under the 'Pretrained model' heading (linked [here](https://s3.amazonaws.com/models.huggingface.co/transfer-learning-chatbot/finetuned_chatbot_gpt.tar.gz)) is different from what gets used when we run `python interact.py`. <br>In the script utils.py, the link for the fine_tuned model has been given in the script as [https://s3.amazonaws.com/models.huggingface.co/transfer-learning-chatbot/gpt_personachat_cache.tar.gz](https://s3.amazonaws.com/models.huggingface.co/transfer-learning-chatbot/gpt_personachat_cache.tar.gz).\r\n<br> Are these two different models because when I tried to run the earlier fine-tuned model which was linked with the repo as a model-checkpoint with interact.py, following error was obtained - <br>\r\nCommand used - `python3 ./interact.py --model_checkpoint='./finetuned_chatbot_gpt'`<br>\r\nError:\r\nTraceback (most recent call last):\r\n  File \"./interact.py\", line 155, in <module>\r\n    run()\r\n  File \"./interact.py\", line 128, in run\r\n    model = model_class.from_pretrained(args.model_checkpoint)\r\n  File \"/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\", line 558, in from_pretrained\r\n    model.__class__.__name__, \"\\n\\t\".join(error_msgs)\r\nRuntimeError: Error(s) in loading state_dict for OpenAIGPTLMHeadModel:\r\n\tsize mismatch for transformer.tokens_embed.weight: copying a param with shape torch.Size([40483, 768]) from checkpoint, the shape in current model is torch.Size([40478, 768]).<br>\r\nWhile just running `python3 interact.py`, the result was fine.\r\nKindly see to this issue","closed_by":null,"reactions":{"url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/82/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/huggingface/transfer-learning-conv-ai/issues/82/timeline","performed_via_github_app":null,"state_reason":null}