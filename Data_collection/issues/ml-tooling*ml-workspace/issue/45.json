{"url":"https://api.github.com/repos/ml-tooling/ml-workspace/issues/45","repository_url":"https://api.github.com/repos/ml-tooling/ml-workspace","labels_url":"https://api.github.com/repos/ml-tooling/ml-workspace/issues/45/labels{/name}","comments_url":"https://api.github.com/repos/ml-tooling/ml-workspace/issues/45/comments","events_url":"https://api.github.com/repos/ml-tooling/ml-workspace/issues/45/events","html_url":"https://github.com/ml-tooling/ml-workspace/issues/45","id":641434658,"node_id":"MDU6SXNzdWU2NDE0MzQ2NTg=","number":45,"title":"zeppelin in spark flavor is broken","user":{"login":"kundeng","id":89032,"node_id":"MDQ6VXNlcjg5MDMy","avatar_url":"https://avatars.githubusercontent.com/u/89032?v=4","gravatar_id":"","url":"https://api.github.com/users/kundeng","html_url":"https://github.com/kundeng","followers_url":"https://api.github.com/users/kundeng/followers","following_url":"https://api.github.com/users/kundeng/following{/other_user}","gists_url":"https://api.github.com/users/kundeng/gists{/gist_id}","starred_url":"https://api.github.com/users/kundeng/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kundeng/subscriptions","organizations_url":"https://api.github.com/users/kundeng/orgs","repos_url":"https://api.github.com/users/kundeng/repos","events_url":"https://api.github.com/users/kundeng/events{/privacy}","received_events_url":"https://api.github.com/users/kundeng/received_events","type":"User","site_admin":false},"labels":[{"id":1379266800,"node_id":"MDU6TGFiZWwxMzc5MjY2ODAw","url":"https://api.github.com/repos/ml-tooling/ml-workspace/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working as expected"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-06-18T17:40:03Z","updated_at":"2020-12-12T21:01:54Z","closed_at":"2020-12-12T21:01:54Z","author_association":"NONE","active_lock_reason":null,"body":"<!--\r\nThanks for reporting a bug 🙌 ❤️\r\n\r\nBefore opening a new issue, please make sure that we do not have any duplicates already open. You can ensure this by searching the issue list for this repository. If there is a duplicate, please close your issue and add a comment to the existing issue instead.\r\n\r\nAlso, be sure to check our documentation first: https://github.com/ml-tooling/ml-workspace\r\n-->\r\n\r\n**Describe the bug:**\r\nimported an example zeppelin notebook from stock zeppelin docker image for testing spark \r\n\r\n\r\n<!-- Describe your issue, but please be descriptive! Thanks again 🙌 ❤️ -->\r\nI got this:\r\njava.lang.IllegalArgumentException: Unsupported class file major version 55\r\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166)\r\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148)\r\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136)\r\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237)\r\n\tat org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49)\r\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517)\r\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500)\r\n\tat scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)\r\n\tat scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134)\r\n\tat scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134)\r\n\tat scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)\r\n\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)\r\n\tat scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134)\r\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)\r\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500)\r\n\tat org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175)\r\n\tat org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238)\r\n\tat org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631)\r\n\tat org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355)\r\n\tat org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307)\r\n\tat org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306)\r\n\tat scala.collection.immutable.List.foreach(List.scala:392)\r\n\tat org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:306)\r\n\tat org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:162)\r\n\tat org.apache.spark.SparkContext.clean(SparkContext.scala:2326)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1.apply(RDD.scala:850)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1.apply(RDD.scala:849)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.mapPartitionsWithIndex(RDD.scala:849)\r\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec$$anonfun$doExecute$1.apply(HashAggregateExec.scala:102)\r\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec$$anonfun$doExecute$1.apply(HashAggregateExec.scala:95)\r\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\r\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.doExecute(HashAggregateExec.scala:95)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.liftedTree1$1(WholeStageCodegenExec.scala:606)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:600)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\r\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)\r\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:151)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:136)\r\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat org.apache.zeppelin.spark.SparkZeppelinContext.showData(SparkZeppelinContext.java:108)\r\n\tat org.apache.zeppelin.spark.SparkSqlInterpreter.interpret(SparkSqlInterpreter.java:136)\r\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:103)\r\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:632)\r\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\r\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:140)\r\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\n**Expected behaviour:**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n<!-- include screenshots, logs, code or other info to help explain your problem -->\r\nSo it seems that some java version mismatch is going on.  \r\n<!-- \r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n-->\r\n\r\n**Technical details:**\r\n\r\n- Workspace version <!-- run `echo $WORKSPACE_VERSION` inside the workspace -->: \r\n- Docker version <!-- run `docker version` on host machine -->: \r\n- Host Machine OS (Windows/Linux/Mac): \r\n- Command used to start the workspace <!-- e.g. `docker run mltooling/ml-workspace:latest` -->:\r\n- Browser (Chrome/Firefox/Safari):\r\n\r\n**Possible Fix:**\r\n\r\n<!--- Not obligatory, but suggest a fix or reason for the bug -->\r\n\r\n**Additional context:**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n","closed_by":{"login":"LukasMasuch","id":2852129,"node_id":"MDQ6VXNlcjI4NTIxMjk=","avatar_url":"https://avatars.githubusercontent.com/u/2852129?v=4","gravatar_id":"","url":"https://api.github.com/users/LukasMasuch","html_url":"https://github.com/LukasMasuch","followers_url":"https://api.github.com/users/LukasMasuch/followers","following_url":"https://api.github.com/users/LukasMasuch/following{/other_user}","gists_url":"https://api.github.com/users/LukasMasuch/gists{/gist_id}","starred_url":"https://api.github.com/users/LukasMasuch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/LukasMasuch/subscriptions","organizations_url":"https://api.github.com/users/LukasMasuch/orgs","repos_url":"https://api.github.com/users/LukasMasuch/repos","events_url":"https://api.github.com/users/LukasMasuch/events{/privacy}","received_events_url":"https://api.github.com/users/LukasMasuch/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/ml-tooling/ml-workspace/issues/45/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ml-tooling/ml-workspace/issues/45/timeline","performed_via_github_app":null,"state_reason":"completed"}