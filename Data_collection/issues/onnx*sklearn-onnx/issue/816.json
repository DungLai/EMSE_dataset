{"url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/816","repository_url":"https://api.github.com/repos/onnx/sklearn-onnx","labels_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/816/labels{/name}","comments_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/816/comments","events_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/816/events","html_url":"https://github.com/onnx/sklearn-onnx/issues/816","id":1115096323,"node_id":"I_kwDOCa0gS85CdwUD","number":816,"title":"Converted ONNX model throws ShapeInferenceError","user":{"login":"PratsBhatt","id":15447437,"node_id":"MDQ6VXNlcjE1NDQ3NDM3","avatar_url":"https://avatars.githubusercontent.com/u/15447437?v=4","gravatar_id":"","url":"https://api.github.com/users/PratsBhatt","html_url":"https://github.com/PratsBhatt","followers_url":"https://api.github.com/users/PratsBhatt/followers","following_url":"https://api.github.com/users/PratsBhatt/following{/other_user}","gists_url":"https://api.github.com/users/PratsBhatt/gists{/gist_id}","starred_url":"https://api.github.com/users/PratsBhatt/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/PratsBhatt/subscriptions","organizations_url":"https://api.github.com/users/PratsBhatt/orgs","repos_url":"https://api.github.com/users/PratsBhatt/repos","events_url":"https://api.github.com/users/PratsBhatt/events{/privacy}","received_events_url":"https://api.github.com/users/PratsBhatt/received_events","type":"User","site_admin":false},"labels":[{"id":2673847808,"node_id":"MDU6TGFiZWwyNjczODQ3ODA4","url":"https://api.github.com/repos/onnx/sklearn-onnx/labels/pending%20user%20response","name":"pending user response","color":"2465AA","default":false,"description":""}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2022-01-26T14:42:28Z","updated_at":"2022-11-24T13:07:44Z","closed_at":"2022-11-24T13:07:44Z","author_association":"NONE","active_lock_reason":null,"body":"Hello Community,\r\n\r\nI followed the tutorial from the documentation found on your website - https://onnx.ai/sklearn-onnx/\r\n\r\nI basically copied and ran it on google colab. There was no issues while converting, but when I tried using Ã¬nfershape` on the model, it throws error.\r\n\r\nAfter running the following code on the converted ONNX model.\r\n```\r\ninferred_model = onnx.shape_inference.infer_shapes(model)\r\nprint(inferred_model.graph.value_info)\r\n```\r\n\r\nError:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nInferenceError                            Traceback (most recent call last)\r\n<ipython-input-18-90349dccf945> in <module>()\r\n----> 1 inferred_model = onnx.shape_inference.infer_shapes(model)\r\n      2 print(inferred_model.graph.value_info)\r\n\r\n/usr/local/lib/python3.7/dist-packages/onnx/shape_inference.py in infer_shapes(model, check_type, strict_mode, data_prop)\r\n     40     if isinstance(model, (ModelProto, binary_type)):\r\n     41         model_str = model if isinstance(model, binary_type) else model.SerializeToString()\r\n---> 42         inferred_model_str = C.infer_shapes(model_str, check_type, strict_mode, data_prop)\r\n     43         return onnx.load_from_string(inferred_model_str)\r\n     44     elif isinstance(model, string_types):\r\n\r\nInferenceError: [ShapeInferenceError] (op_type:ZipMap, node name: ZipMap): [ShapeInferenceError] type case unsupported for symbolic shape inference. inferred=5\r\n```\r\n\r\nI am actually trying to quantize the converted ONNX model and I am receiving the same error.\r\n\r\n```\r\nmodel_fp32 = '/content/rf_iris.onnx'\r\nmodel_quant = '/content/model.quant.onnx'\r\nquantized_model = quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8)\r\n```\r\n\r\nError:\r\n\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nInferenceError                            Traceback (most recent call last)\r\n<ipython-input-11-df73cba5202f> in <module>()\r\n      2 model_quant = '/content/model.quant.onnx'\r\n      3 #quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8)\r\n----> 4 quantized_model = quantize_qat(model_fp32, model_quant)\r\n\r\n2 frames\r\n/usr/local/lib/python3.7/dist-packages/onnxruntime/quantization/quantize.py in quantize_qat(model_input, model_output, op_types_to_quantize, per_channel, reduce_range, activation_type, weight_type, nodes_to_quantize, nodes_to_exclude, use_external_data_format)\r\n    376         nodes_to_quantize,\r\n    377         nodes_to_exclude,\r\n--> 378         op_types_to_quantize)\r\n    379 \r\n    380     quantizer.quantize_model()\r\n\r\n/usr/local/lib/python3.7/dist-packages/onnxruntime/quantization/onnx_quantizer.py in __init__(self, model, per_channel, reduce_range, mode, static, weight_qType, input_qType, tensors_range, nodes_to_quantize, nodes_to_exclude, op_types_to_quantize, extra_options)\r\n     31         self.extra_options = extra_options if extra_options is not None else {}\r\n     32         if not ('DisableShapeInference' in self.extra_options and self.extra_options['DisableShapeInference']):\r\n---> 33             model = onnx.shape_inference.infer_shapes(model)\r\n     34         self.value_infos = {vi.name: vi for vi in model.graph.value_info}\r\n     35         self.value_infos.update({ot.name: ot for ot in model.graph.output})\r\n\r\n/usr/local/lib/python3.7/dist-packages/onnx/shape_inference.py in infer_shapes(model, check_type, strict_mode, data_prop)\r\n     40     if isinstance(model, (ModelProto, binary_type)):\r\n     41         model_str = model if isinstance(model, binary_type) else model.SerializeToString()\r\n---> 42         inferred_model_str = C.infer_shapes(model_str, check_type, strict_mode, data_prop)\r\n     43         return onnx.load_from_string(inferred_model_str)\r\n     44     elif isinstance(model, string_types):\r\n\r\nInferenceError: [ShapeInferenceError] (op_type:ZipMap, node name: ZipMap): [ShapeInferenceError] type case unsupported for symbolic shape inference. inferred=5\r\n```\r\n\r\n\r\nExpected Output:\r\n\r\nNo error thrown and able to infer the shape of the model.\r\n","closed_by":{"login":"xadupre","id":22452781,"node_id":"MDQ6VXNlcjIyNDUyNzgx","avatar_url":"https://avatars.githubusercontent.com/u/22452781?v=4","gravatar_id":"","url":"https://api.github.com/users/xadupre","html_url":"https://github.com/xadupre","followers_url":"https://api.github.com/users/xadupre/followers","following_url":"https://api.github.com/users/xadupre/following{/other_user}","gists_url":"https://api.github.com/users/xadupre/gists{/gist_id}","starred_url":"https://api.github.com/users/xadupre/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xadupre/subscriptions","organizations_url":"https://api.github.com/users/xadupre/orgs","repos_url":"https://api.github.com/users/xadupre/repos","events_url":"https://api.github.com/users/xadupre/events{/privacy}","received_events_url":"https://api.github.com/users/xadupre/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/816/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/816/timeline","performed_via_github_app":null,"state_reason":"completed"}