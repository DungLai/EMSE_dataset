{"url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/932","repository_url":"https://api.github.com/repos/onnx/sklearn-onnx","labels_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/932/labels{/name}","comments_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/932/comments","events_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/932/events","html_url":"https://github.com/onnx/sklearn-onnx/issues/932","id":1433223105,"node_id":"I_kwDOCa0gS85VbT_B","number":932,"title":"Using argument final_types in skl2onnx.convert_sklearn produce invalid onnx model","user":{"login":"dmt-obd","id":7227265,"node_id":"MDQ6VXNlcjcyMjcyNjU=","avatar_url":"https://avatars.githubusercontent.com/u/7227265?v=4","gravatar_id":"","url":"https://api.github.com/users/dmt-obd","html_url":"https://github.com/dmt-obd","followers_url":"https://api.github.com/users/dmt-obd/followers","following_url":"https://api.github.com/users/dmt-obd/following{/other_user}","gists_url":"https://api.github.com/users/dmt-obd/gists{/gist_id}","starred_url":"https://api.github.com/users/dmt-obd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dmt-obd/subscriptions","organizations_url":"https://api.github.com/users/dmt-obd/orgs","repos_url":"https://api.github.com/users/dmt-obd/repos","events_url":"https://api.github.com/users/dmt-obd/events{/privacy}","received_events_url":"https://api.github.com/users/dmt-obd/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2022-11-02T14:16:43Z","updated_at":"2022-11-11T15:15:32Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Using argument `final_types` in [skl2onnx.convert_sklearn](http://onnx.ai/sklearn-onnx/api_summary.html?highlight=convert_sklearn#skl2onnx.convert_sklearn) causing invalid model output.\r\n\r\nRunning code:\r\n```python\r\nimport cloudpickle\r\nfrom skl2onnx import convert_sklearn, update_registered_converter\r\nfrom skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes  # noqa\r\nfrom onnxmltools.convert.lightgbm.operator_converters.LightGbm import convert_lightgbm  # noqa\r\nfrom skl2onnx.common.data_types import FloatTensorType, Int64TensorType, SequenceType, DictionaryType\r\nfrom lightgbm import LGBMClassifier\r\nimport onnxruntime as ort\r\n\r\n\r\nmodel_lightgbm = None\r\nwith open('model.pkl.cloud', mode='rb') as f:\r\n    model_lightgbm = cloudpickle.load(f)\r\n\r\nupdate_registered_converter(\r\n    LGBMClassifier, 'LightGbmLGBMClassifier',\r\n    calculate_linear_classifier_output_shapes, convert_lightgbm,\r\n    options={'zipmap': [True], 'nocl': [False]})\r\n\r\nmodel_onnx = convert_sklearn(\r\n    model_lightgbm, 'histogram_classifier',\r\n    [('input', FloatTensorType([1, 96]))])\r\n\r\nwith open(\"model.onnx\", \"wb\") as f:\r\n    f.write(model_onnx.SerializeToString())\r\n```\r\nProduce valid model - onnxruntime can load and infer model.\r\n![image](https://user-images.githubusercontent.com/7227265/199505286-56a4bcc8-a773-4fac-a18c-4412d91b5ffb.png)\r\n\r\nBut if I add `final_types` argument to rename or cast output, converter will produce invalid onnx model.\r\n ```python\r\nmodel_onnx = convert_sklearn(\r\n    model_lightgbm, 'histogram_classifier',\r\n    [('input', FloatTensorType([1, 96]))],\r\n    final_types=[('output', None), ('output_probability', None)])  # everything same except this line\r\n\r\n...\r\n\r\nnet_input = np.random.rand(1, 96).astype(np.float32)\r\nsession = ort.InferenceSession(\"model.onnx\", providers=['CPUExecutionProvider'])\r\nsession.run(None, {\"input\": net_input})\r\n```\r\n```bash\r\n---------------------------------------------------------------------------\r\nInvalidGraph                              Traceback (most recent call last)\r\nCell In [11], line 1\r\n----> 1 get_ipython().run_cell_magic('timeit', '', '\\nsess = rt.InferenceSession(onnx_model_path, providers=[\\'CPUExecutionProvider\\'])\\nsess.run(None, {\"input\": net_input})\\n')\r\n\r\nFile ~/Projects/lightgdm/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2417, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)\r\n   2415 with self.builtin_trap:\r\n   2416     args = (magic_arg_s, cell)\r\n-> 2417     result = fn(*args, **kwargs)\r\n   2418 return result\r\n\r\nFile ~/Projects/lightgdm/venv/lib/python3.8/site-packages/IPython/core/magics/execution.py:1162, in ExecutionMagics.timeit(self, line, cell, local_ns)\r\n   1160 for index in range(0, 10):\r\n   1161     number = 10 ** index\r\n-> 1162     time_number = timer.timeit(number)\r\n   1163     if time_number >= 0.2:\r\n   1164         break\r\n\r\nFile ~/Projects/lightgdm/venv/lib/python3.8/site-packages/IPython/core/magics/execution.py:156, in Timer.timeit(self, number)\r\n    154 gc.disable()\r\n    155 try:\r\n--> 156     timing = self.inner(it, self.timer)\r\n    157 finally:\r\n    158     if gcold:\r\n\r\nFile <magic-timeit>:1, in inner(_it, _timer)\r\n\r\nFile ~/Projects/lightgdm/venv/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:347, in InferenceSession.__init__(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\r\n    344 disabled_optimizers = kwargs[\"disabled_optimizers\"] if \"disabled_optimizers\" in kwargs else None\r\n    346 try:\r\n--> 347     self._create_inference_session(providers, provider_options, disabled_optimizers)\r\n    348 except ValueError:\r\n    349     if self._enable_fallback:\r\n\r\nFile ~/Projects/lightgdm/venv/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:384, in InferenceSession._create_inference_session(self, providers, provider_options, disabled_optimizers)\r\n    382 session_options = self._sess_options if self._sess_options else C.get_default_session_options()\r\n    383 if self._model_path:\r\n--> 384     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)\r\n    385 else:\r\n    386     sess = C.InferenceSession(session_options, self._model_bytes, False, self._read_config_from_model)\r\n\r\nInvalidGraph: [ONNXRuntimeError] : 10 : INVALID_GRAPH : Load model from /home/do-op/Projects/lightgdm/histogram_classifier_2.onnx failed:This is an invalid model. Type Error: Type 'seq(map(int64,tensor(float)))' of input parameter (output_probability1) of operator (Identity) in node (CIdentity1) is invalid.\r\n```\r\n![image](https://user-images.githubusercontent.com/7227265/199510146-36a47b2e-3b4c-4bd9-9f6d-79af28dcd52a.png)\r\n\r\nI suppose that exception occurs because _ZipMap_ output type is `sequence<map<int64,float32>>`, but _Identity_ or _Cast_ do not support such data types according [documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#Identity).\r\n\r\n## Artifacts\r\n\r\n[models.zip](https://github.com/onnx/sklearn-onnx/files/9921101/models.zip)\r\n\r\n## Required behavior\r\n\r\nProduce valid ONNX model or throw message by converter.\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/932/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/932/timeline","performed_via_github_app":null,"state_reason":null}