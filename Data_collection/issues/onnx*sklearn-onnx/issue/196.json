{"url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/196","repository_url":"https://api.github.com/repos/onnx/sklearn-onnx","labels_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/196/labels{/name}","comments_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/196/comments","events_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/196/events","html_url":"https://github.com/onnx/sklearn-onnx/issues/196","id":460072953,"node_id":"MDU6SXNzdWU0NjAwNzI5NTM=","number":196,"title":"TfidfVectoriser converter issues","user":{"login":"prabhat00155","id":7043157,"node_id":"MDQ6VXNlcjcwNDMxNTc=","avatar_url":"https://avatars.githubusercontent.com/u/7043157?v=4","gravatar_id":"","url":"https://api.github.com/users/prabhat00155","html_url":"https://github.com/prabhat00155","followers_url":"https://api.github.com/users/prabhat00155/followers","following_url":"https://api.github.com/users/prabhat00155/following{/other_user}","gists_url":"https://api.github.com/users/prabhat00155/gists{/gist_id}","starred_url":"https://api.github.com/users/prabhat00155/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prabhat00155/subscriptions","organizations_url":"https://api.github.com/users/prabhat00155/orgs","repos_url":"https://api.github.com/users/prabhat00155/repos","events_url":"https://api.github.com/users/prabhat00155/events{/privacy}","received_events_url":"https://api.github.com/users/prabhat00155/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2019-06-24T20:10:07Z","updated_at":"2019-06-24T22:05:07Z","closed_at":"2019-06-24T22:05:06Z","author_association":"COLLABORATOR","active_lock_reason":null,"body":"1) NaN values\r\n\r\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\r\nfrom sklearn.datasets import fetch_20newsgroups\r\n\r\ndata = fetch_20newsgroups()\r\nX, y = np.array(data.data)[:100], np.array(data.target)[:100]\r\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\r\n\r\nmodel = TfidfVectorizer().fit(X_train)\r\nonnx_model = convert_sklearn(model, 'cv', [('input', StringTensorType(X_test.shape))])\r\nsave_model(onnx_model, 'cv.onnx')\r\nsess = InferenceSession('cv.onnx')\r\nres = sess.run(None, input_feed={'input': X_test})\r\n\r\nprint(np.mean(np.isclose(model.transform(X_test).toarray(), res[0], atol=1e-5)))\r\n\r\n0.971024886272411 / 0.05691196146641691 (Number of NaN outputs vary a lot in different runs)\r\n\r\nmodel.transform(X_test).toarray()\r\n\r\narray([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\r\n        0.        ],\r\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\r\n        0.        ],\r\n       [0.        , 0.0390878 , 0.        , ..., 0.        , 0.02345268,\r\n        0.        ],\r\n       ...,\r\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\r\n        0.        ],\r\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\r\n        0.        ],\r\n       [0.        , 0.0268699 , 0.        , ..., 0.        , 0.        ,\r\n        0.        ]])\r\n\r\nres[0]\r\n\r\narray([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\r\n       [nan, nan, nan, ..., nan, nan, nan],\r\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\r\n       ...,\r\n       [nan, nan, nan, ..., nan, nan, nan],\r\n       [nan, nan, nan, ..., nan, nan, nan],\r\n       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)\r\n\r\n2) lowercase=False\r\n\r\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\r\nfrom sklearn.datasets import fetch_20newsgroups\r\n\r\ndata = fetch_20newsgroups()\r\nX, y = np.array(data.data)[:100], np.array(data.target)[:100]\r\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\r\n\r\nmodel = TfidfVectorizer(lowercase=False).fit(X_train)\r\nonnx_model = convert_sklearn(model, 'cv', [('input', StringTensorType(X_test.shape))])\r\nsave_model(onnx_model, 'cv.onnx')\r\nsess = InferenceSession('cv.onnx')\r\nres = sess.run(None, input_feed={'input': X_test})\r\n\r\nprint(np.mean(np.isclose(model.transform(X_test).toarray(), res[0], atol=1e-5)))\r\n\r\n0.19266698024459078\r\n\r\nmodel.transform(X_test).toarray()\r\n\r\narray([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\r\n        0.        ],\r\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\r\n        0.        ],\r\n       [0.        , 0.04067757, 0.        , ..., 0.        , 0.        ,\r\n        0.02440654],\r\n       ...,\r\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\r\n        0.        ],\r\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\r\n        0.        ],\r\n       [0.        , 0.03138701, 0.        , ..., 0.        , 0.        ,\r\n        0.        ]])\r\n\r\n\r\nres[0]\r\n\r\narray([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\r\n        0.        ],\r\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\r\n        0.        ],\r\n       [0.        , 0.03395877, 0.        , ..., 0.        , 0.        ,\r\n        0.        ],\r\n       ...,\r\n       [       nan,        nan,        nan, ...,        nan,        nan,\r\n               nan],\r\n       [       nan,        nan,        nan, ...,        nan,        nan,\r\n               nan],\r\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\r\n        0.        ]], dtype=float32)\r\n\r\n\r\n3) analyzer='char'\r\n\r\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\r\nfrom sklearn.datasets import fetch_20newsgroups\r\n\r\ndata = fetch_20newsgroups()\r\nX, y = np.array(data.data)[:100], np.array(data.target)[:100]\r\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\r\n\r\nmodel = TfidfVectorizer(analyzer='char').fit(X_train)\r\nonnx_model = convert_sklearn(model, 'cv', [('input', StringTensorType(X_test.shape))])\r\nsave_model(onnx_model, 'cv.onnx')\r\nsess = InferenceSession('cv.onnx')\r\nres = sess.run(None, input_feed={'input': X_test})\r\n\r\nprint(np.mean(np.isclose(model.transform(X_test).toarray(), res[0], atol=1e-5)))\r\n\r\n0.2504225352112676\r\n\r\nmodel.transform(X_test).toarray()\r\n\r\narray([[0.        , 0.04540119, 0.62653648, ..., 0.        , 0.        ,\r\n        0.        ],\r\n       [0.        , 0.07204533, 0.57293189, ..., 0.        , 0.        ,\r\n        0.        ],\r\n       [0.        , 0.01663145, 0.61892768, ..., 0.        , 0.        ,\r\n        0.        ],\r\n       ...,\r\n       [0.        , 0.03520802, 0.46474592, ..., 0.        , 0.        ,\r\n        0.        ],\r\n       [0.        , 0.03261331, 0.34787535, ..., 0.        , 0.        ,\r\n        0.        ],\r\n       [0.        , 0.02589324, 0.61991454, ..., 0.        , 0.00645606,\r\n        0.        ]])\r\n\r\nres[0]\r\n\r\narray([[0.16190134, 0.10120933, 0.74220175, ..., 0.        , 0.        ,\r\n        0.        ],\r\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\r\n        0.        ],\r\n       [0.        , 0.        ,        nan, ..., 0.        , 0.        ,\r\n        0.        ],\r\n       ...,\r\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\r\n        0.        ],\r\n       [       nan,        nan,        nan, ...,        nan,        nan,\r\n               nan],\r\n       [0.        ,        nan,        nan, ..., 0.        , 0.        ,\r\n        0.        ]], dtype=float32)\r\n\r\n4)\r\n","closed_by":{"login":"prabhat00155","id":7043157,"node_id":"MDQ6VXNlcjcwNDMxNTc=","avatar_url":"https://avatars.githubusercontent.com/u/7043157?v=4","gravatar_id":"","url":"https://api.github.com/users/prabhat00155","html_url":"https://github.com/prabhat00155","followers_url":"https://api.github.com/users/prabhat00155/followers","following_url":"https://api.github.com/users/prabhat00155/following{/other_user}","gists_url":"https://api.github.com/users/prabhat00155/gists{/gist_id}","starred_url":"https://api.github.com/users/prabhat00155/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prabhat00155/subscriptions","organizations_url":"https://api.github.com/users/prabhat00155/orgs","repos_url":"https://api.github.com/users/prabhat00155/repos","events_url":"https://api.github.com/users/prabhat00155/events{/privacy}","received_events_url":"https://api.github.com/users/prabhat00155/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/196/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/196/timeline","performed_via_github_app":null,"state_reason":"completed"}