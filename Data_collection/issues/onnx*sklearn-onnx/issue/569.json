{"url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/569","repository_url":"https://api.github.com/repos/onnx/sklearn-onnx","labels_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/569/labels{/name}","comments_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/569/comments","events_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/569/events","html_url":"https://github.com/onnx/sklearn-onnx/issues/569","id":759062599,"node_id":"MDU6SXNzdWU3NTkwNjI1OTk=","number":569,"title":"PipelineModel convert - sparkml","user":{"login":"GitOP","id":7380340,"node_id":"MDQ6VXNlcjczODAzNDA=","avatar_url":"https://avatars.githubusercontent.com/u/7380340?v=4","gravatar_id":"","url":"https://api.github.com/users/GitOP","html_url":"https://github.com/GitOP","followers_url":"https://api.github.com/users/GitOP/followers","following_url":"https://api.github.com/users/GitOP/following{/other_user}","gists_url":"https://api.github.com/users/GitOP/gists{/gist_id}","starred_url":"https://api.github.com/users/GitOP/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/GitOP/subscriptions","organizations_url":"https://api.github.com/users/GitOP/orgs","repos_url":"https://api.github.com/users/GitOP/repos","events_url":"https://api.github.com/users/GitOP/events{/privacy}","received_events_url":"https://api.github.com/users/GitOP/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-12-08T04:57:08Z","updated_at":"2020-12-08T13:43:07Z","closed_at":"2020-12-08T13:43:07Z","author_association":"NONE","active_lock_reason":null,"body":"Hello all, I've been trying to convert a sparkML pipeline model to onnx for a couple of days, have tried 2 different versions of spark:\r\n- 2.4.5 and,\r\n- 3.0.1\r\nBoth with the same results, here is my code:\r\n\r\n```\r\nfrom onnxmltools import convert_sparkml\r\nfrom onnxmltools.convert.sparkml.utils import buildInitialTypesSimple\r\n\r\nsample_input = test.drop('Time', 'Class', 'Amount') #Dropping unused columns for the model. Only retaining features\r\nprint(sample_input)\r\ninitial_types = buildInitialTypesSimple(sample_input) \r\nprint(initial_types)\r\nonnx_model = convert_sparkml(pipelineModel, name='Pyspark model', initial_types=initial_types, spark_session = spark )`\r\n\r\nAnd the output:\r\n`DataFrame[V1: double, V2: double, V3: double, V4: double, V5: double, V6: double, V7: double, V8: double, V9: double, V10: double, V11: double, V12: double, V13: double, V14: double, V15: double, V16: double, V17: double, V18: double, V19: double, V20: double, V21: double, V22: double, V23: double, V24: double, V25: double, V26: double, V27: double, V28: double]\r\n[('V1', FloatTensorType(shape=[1, 1])), ('V2', FloatTensorType(shape=[1, 1])), ('V3', FloatTensorType(shape=[1, 1])), ('V4', FloatTensorType(shape=[1, 1])), ('V5', FloatTensorType(shape=[1, 1])), ('V6', FloatTensorType(shape=[1, 1])), ('V7', FloatTensorType(shape=[1, 1])), ('V8', FloatTensorType(shape=[1, 1])), ('V9', FloatTensorType(shape=[1, 1])), ('V10', FloatTensorType(shape=[1, 1])), ('V11', FloatTensorType(shape=[1, 1])), ('V12', FloatTensorType(shape=[1, 1])), ('V13', FloatTensorType(shape=[1, 1])), ('V14', FloatTensorType(shape=[1, 1])), ('V15', FloatTensorType(shape=[1, 1])), ('V16', FloatTensorType(shape=[1, 1])), ('V17', FloatTensorType(shape=[1, 1])), ('V18', FloatTensorType(shape=[1, 1])), ('V19', FloatTensorType(shape=[1, 1])), ('V20', FloatTensorType(shape=[1, 1])), ('V21', FloatTensorType(shape=[1, 1])), ('V22', FloatTensorType(shape=[1, 1])), ('V23', FloatTensorType(shape=[1, 1])), ('V24', FloatTensorType(shape=[1, 1])), ('V25', FloatTensorType(shape=[1, 1])), ('V26', FloatTensorType(shape=[1, 1])), ('V27', FloatTensorType(shape=[1, 1])), ('V28', FloatTensorType(shape=[1, 1]))]\r\n```\r\n\r\nStack trace:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<command-2555591288018935> in <module>\r\n      6 initial_types = buildInitialTypesSimple(sample_input)\r\n      7 print(initial_types)\r\n----> 8 onnx_model = convert_sparkml(pipelineModel, name='Pyspark model', initial_types=initial_types, spark_session = spark )\r\n      9 print(onnx_model)\r\n\r\n/databricks/python/lib/python3.7/site-packages/onnxmltools/convert/main.py in convert_sparkml(model, name, initial_types, doc_string, target_opset, targeted_onnx, custom_conversion_functions, custom_shape_calculators, spark_session)\r\n     75     from .sparkml.convert import convert\r\n     76     return convert(model, name, initial_types, doc_string, target_opset, targeted_onnx,\r\n---> 77                    custom_conversion_functions, custom_shape_calculators, spark_session)\r\n     78 \r\n     79 \r\n\r\n/databricks/python/lib/python3.7/site-packages/onnxmltools/convert/sparkml/convert.py in convert(model, name, initial_types, doc_string, target_opset, targeted_onnx, custom_conversion_functions, custom_shape_calculators, spark_session)\r\n     73 \r\n     74     # Convert our Topology object into ONNX. The outcome is an ONNX model.\r\n---> 75     onnx_model = convert_topology(topology, name, doc_string, target_opset, targeted_onnx)\r\n     76 \r\n     77     return onnx_model\r\n\r\n/databricks/python/lib/python3.7/site-packages/onnxconverter_common/topology.py in convert_topology(topology, model_name, doc_string, target_opset, targeted_onnx, channel_first_inputs)\r\n    774         else:\r\n    775             # Convert the selected operator into some ONNX objects and save them into the container\r\n--> 776             get_converter(operator.type)(scope, operator, container)\r\n    777 \r\n    778     # When calling ModelComponentContainer's add_initializer(...), nothing is added into the input list.\r\n\r\n/databricks/python/lib/python3.7/site-packages/onnxmltools/convert/sparkml/operator_converters/gbt_classifier.py in convert_gbt_classifier(scope, operator, container)\r\n     27         regressor_output_names.append(regressor_output.full_name)\r\n     28         regressor_op.outputs.append(regressor_output)\r\n---> 29         convert_decision_tree_regressor(scope, regressor_op, container)\r\n     30         regressor_op.is_evaluated = True\r\n     31 \r\n\r\n/databricks/python/lib/python3.7/site-packages/onnxmltools/convert/sparkml/operator_converters/decision_tree_regressor.py in convert_decision_tree_regressor(scope, operator, container)\r\n     26 \r\n     27     container.add_node(op_type, operator.input_full_names, operator.output_full_names,\r\n---> 28                        op_domain='ai.onnx.ml', **attrs)\r\n     29 \r\n     30 \r\n\r\n/databricks/python/lib/python3.7/site-packages/onnxconverter_common/container.py in add_node(self, op_type, inputs, outputs, op_domain, op_version, **attrs)\r\n    169                 raise ValueError('Failed to create ONNX node. Undefined attribute pair (%s, %s) found' % (k, v))\r\n    170 \r\n--> 171         node = helper.make_node(op_type, inputs, outputs, **attrs)\r\n    172         node.domain = op_domain\r\n    173 \r\n\r\n/databricks/python/lib/python3.7/site-packages/onnx/helper.py in make_node(op_type, inputs, outputs, name, doc_string, domain, **kwargs)\r\n    108         node.attribute.extend(\r\n    109             make_attribute(key, value)\r\n--> 110             for key, value in sorted(kwargs.items()))\r\n    111     return node\r\n    112 \r\n\r\n/databricks/python/lib/python3.7/site-packages/onnx/helper.py in <genexpr>(.0)\r\n    108         node.attribute.extend(\r\n    109             make_attribute(key, value)\r\n--> 110             for key, value in sorted(kwargs.items()))\r\n    111     return node\r\n    112 \r\n\r\n/databricks/python/lib/python3.7/site-packages/onnx/helper.py in make_attribute(key, value, doc_string)\r\n    388         else:\r\n    389             raise ValueError(\r\n--> 390                 \"You passed in an iterable attribute but I cannot figure out \"\r\n    391                 \"its applicable type.\")\r\n    392     else:\r\n\r\nValueError: You passed in an iterable attribute but I cannot figure out its applicable type.\r\n```\r\n\r\nAny help/ideas are well appreciated","closed_by":{"login":"GitOP","id":7380340,"node_id":"MDQ6VXNlcjczODAzNDA=","avatar_url":"https://avatars.githubusercontent.com/u/7380340?v=4","gravatar_id":"","url":"https://api.github.com/users/GitOP","html_url":"https://github.com/GitOP","followers_url":"https://api.github.com/users/GitOP/followers","following_url":"https://api.github.com/users/GitOP/following{/other_user}","gists_url":"https://api.github.com/users/GitOP/gists{/gist_id}","starred_url":"https://api.github.com/users/GitOP/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/GitOP/subscriptions","organizations_url":"https://api.github.com/users/GitOP/orgs","repos_url":"https://api.github.com/users/GitOP/repos","events_url":"https://api.github.com/users/GitOP/events{/privacy}","received_events_url":"https://api.github.com/users/GitOP/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/569/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/569/timeline","performed_via_github_app":null,"state_reason":"completed"}