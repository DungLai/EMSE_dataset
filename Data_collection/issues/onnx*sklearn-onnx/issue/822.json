{"url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/822","repository_url":"https://api.github.com/repos/onnx/sklearn-onnx","labels_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/822/labels{/name}","comments_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/822/comments","events_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/822/events","html_url":"https://github.com/onnx/sklearn-onnx/issues/822","id":1128119864,"node_id":"I_kwDOCa0gS85DPb44","number":822,"title":"Converting TfIdfVectorizer to Onnx throws \"Unexpected type <class 'numpy.int32'>....\"","user":{"login":"eranamar","id":97590504,"node_id":"U_kgDOBdEc6A","avatar_url":"https://avatars.githubusercontent.com/u/97590504?v=4","gravatar_id":"","url":"https://api.github.com/users/eranamar","html_url":"https://github.com/eranamar","followers_url":"https://api.github.com/users/eranamar/followers","following_url":"https://api.github.com/users/eranamar/following{/other_user}","gists_url":"https://api.github.com/users/eranamar/gists{/gist_id}","starred_url":"https://api.github.com/users/eranamar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eranamar/subscriptions","organizations_url":"https://api.github.com/users/eranamar/orgs","repos_url":"https://api.github.com/users/eranamar/repos","events_url":"https://api.github.com/users/eranamar/events{/privacy}","received_events_url":"https://api.github.com/users/eranamar/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":{"login":"xiaowuhu","id":19218188,"node_id":"MDQ6VXNlcjE5MjE4MTg4","avatar_url":"https://avatars.githubusercontent.com/u/19218188?v=4","gravatar_id":"","url":"https://api.github.com/users/xiaowuhu","html_url":"https://github.com/xiaowuhu","followers_url":"https://api.github.com/users/xiaowuhu/followers","following_url":"https://api.github.com/users/xiaowuhu/following{/other_user}","gists_url":"https://api.github.com/users/xiaowuhu/gists{/gist_id}","starred_url":"https://api.github.com/users/xiaowuhu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xiaowuhu/subscriptions","organizations_url":"https://api.github.com/users/xiaowuhu/orgs","repos_url":"https://api.github.com/users/xiaowuhu/repos","events_url":"https://api.github.com/users/xiaowuhu/events{/privacy}","received_events_url":"https://api.github.com/users/xiaowuhu/received_events","type":"User","site_admin":false},"assignees":[{"login":"xiaowuhu","id":19218188,"node_id":"MDQ6VXNlcjE5MjE4MTg4","avatar_url":"https://avatars.githubusercontent.com/u/19218188?v=4","gravatar_id":"","url":"https://api.github.com/users/xiaowuhu","html_url":"https://github.com/xiaowuhu","followers_url":"https://api.github.com/users/xiaowuhu/followers","following_url":"https://api.github.com/users/xiaowuhu/following{/other_user}","gists_url":"https://api.github.com/users/xiaowuhu/gists{/gist_id}","starred_url":"https://api.github.com/users/xiaowuhu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xiaowuhu/subscriptions","organizations_url":"https://api.github.com/users/xiaowuhu/orgs","repos_url":"https://api.github.com/users/xiaowuhu/repos","events_url":"https://api.github.com/users/xiaowuhu/events{/privacy}","received_events_url":"https://api.github.com/users/xiaowuhu/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2022-02-09T06:48:15Z","updated_at":"2022-07-11T06:13:34Z","closed_at":"2022-07-11T06:13:34Z","author_association":"NONE","active_lock_reason":null,"body":"Hello,\r\nI've encountered an error when converting my sklearn pipeline to ONNX. The error originated from the tfidf converter when it tries to create a tensor of shape [None, `columns`] and the variable `columns` is of type np.int32 (but only allowed types are {int, np.int64, np.intc}\r\n\r\n**Here are some details I've noticed as well:**\r\nIt happened for TfIdfVectorizer and not CountVectorizer.\r\nIt happened when the TfIdv isn't alone, for example, there is a ColumnTransformer with multiple inner transformers where the TfIdfVectorizer is only one among them.\r\n\r\n**A way to reproduce:**\r\nFollow the example from your webpage: http://onnx.ai/sklearn-onnx/auto_examples/plot_tfidfvectorizer.html and add to the first TfIdfVectorizer `max_features=10` (I've tried various numbers here and the error appear on all)\r\nFor your convenience I put here the complete example:\r\n```python\r\nimport matplotlib.pyplot as plt\r\nimport os\r\nfrom onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\r\nimport numpy\r\nimport onnxruntime as rt\r\nfrom skl2onnx.common.data_types import StringTensorType\r\nfrom skl2onnx import convert_sklearn\r\nimport numpy as np\r\n\r\nfrom sklearn.base import BaseEstimator, TransformerMixin\r\nfrom sklearn.datasets import fetch_20newsgroups\r\ntry:\r\n    from sklearn.datasets._twenty_newsgroups import (\r\n        strip_newsgroup_footer, strip_newsgroup_quoting)\r\nexcept ImportError:\r\n    # scikit-learn < 0.24\r\n    from sklearn.datasets.twenty_newsgroups import (\r\n        strip_newsgroup_footer, strip_newsgroup_quoting)\r\nfrom sklearn.decomposition import TruncatedSVD\r\nfrom sklearn.feature_extraction.text import TfidfVectorizer\r\nfrom sklearn.pipeline import Pipeline\r\nfrom sklearn.compose import ColumnTransformer\r\nfrom sklearn.metrics import classification_report\r\nfrom sklearn.linear_model import LogisticRegression\r\n\r\n\r\n# limit the list of categories to make running this example faster.\r\ncategories = ['alt.atheism', 'talk.religion.misc']\r\ntrain = fetch_20newsgroups(random_state=1,\r\n                           subset='train',\r\n                           categories=categories,\r\n                           )\r\ntest = fetch_20newsgroups(random_state=1,\r\n                          subset='test',\r\n                          categories=categories,\r\n                          )\r\n\r\nclass SubjectBodyExtractor(BaseEstimator, TransformerMixin):\r\n    \"\"\"Extract the subject & body from a usenet post in a single pass.\r\n    Takes a sequence of strings and produces a dict of sequences. Keys are\r\n    `subject` and `body`.\r\n    \"\"\"\r\n\r\n    def fit(self, x, y=None):\r\n        return self\r\n\r\n    def transform(self, posts):\r\n        # construct object dtype array with two columns\r\n        # first column = 'subject' and second column = 'body'\r\n        features = np.empty(shape=(len(posts), 2), dtype=object)\r\n        for i, text in enumerate(posts):\r\n            headers, _, bod = text.partition('\\n\\n')\r\n            bod = strip_newsgroup_footer(bod)\r\n            bod = strip_newsgroup_quoting(bod)\r\n            features[i, 1] = bod\r\n\r\n            prefix = 'Subject:'\r\n            sub = ''\r\n            for line in headers.split('\\n'):\r\n                if line.startswith(prefix):\r\n                    sub = line[len(prefix):]\r\n                    break\r\n            features[i, 0] = sub\r\n\r\n        return features\r\n\r\n\r\ntrain_data = SubjectBodyExtractor().fit_transform(train.data)\r\ntest_data = SubjectBodyExtractor().fit_transform(test.data)\r\n\r\npipeline = Pipeline([\r\n    ('union', ColumnTransformer(\r\n        [\r\n            ('subject', TfidfVectorizer(min_df=50,max_features=500), 0),\r\n\r\n            ('body_bow', Pipeline([\r\n                ('tfidf', TfidfVectorizer()),\r\n                ('best', TruncatedSVD(n_components=50)),\r\n            ]), 1),\r\n\r\n            # Removed from the original example as\r\n            # it requires a custom converter.\r\n            # ('body_stats', Pipeline([\r\n            #   ('stats', TextStats()),  # returns a list of dicts\r\n            #   ('vect', DictVectorizer()),  # list of dicts -> feature matrix\r\n            # ]), 1),\r\n        ],\r\n\r\n        transformer_weights={\r\n            'subject': 0.8,\r\n            'body_bow': 0.5,\r\n            # 'body_stats': 1.0,\r\n        }\r\n    )),\r\n\r\n    # Use a LogisticRegression classifier on the combined features.\r\n    # Instead of LinearSVC (not fully ready in onnxruntime).\r\n    ('logreg', LogisticRegression()),\r\n])\r\n\r\npipeline.fit(train_data, train.target)\r\nprint(classification_report(pipeline.predict(test_data), test.target))\r\n\r\nseps = {\r\n    TfidfVectorizer: {\r\n        \"separators\": [\r\n            ' ', '.', '\\\\?', ',', ';', ':', '!',\r\n            '\\\\(', '\\\\)', '\\n', '\"', \"'\",\r\n            \"-\", \"\\\\[\", \"\\\\]\", \"@\"\r\n        ]\r\n    }\r\n}\r\nmodel_onnx = convert_sklearn(\r\n    pipeline, \"tfidf\",\r\n    initial_types=[(\"input\", StringTensorType([None, 2]))],\r\n    options=seps, \r\n    target_opset=12)\r\n```\r\n\r\n**The error trace**\r\n```\r\nFile ~\\Anaconda3\\envs\\research\\lib\\site-packages\\skl2onnx\\operator_converters\\tfidf_vectoriser.py:35, in convert_sklearn_tfidf_vectoriser(scope, operator, container)\r\n     31 else:\r\n     32     raise RuntimeError(\r\n     33         \"Unexpected dtype '{}'. Float or double expected.\".format(\r\n     34             proto_dtype))\r\n---> 35 cv_output_name = scope.declare_local_variable(\r\n     36     'count_vec_output', clr([None, columns]))\r\n     37 cv_operator.outputs.append(cv_output_name)\r\n     39 op_type = sklearn_operator_name_map[TfidfTransformer]\r\n\r\nFile ~\\Anaconda3\\envs\\research\\lib\\site-packages\\skl2onnx\\common\\_topology.py:720, in Scope.declare_local_variable(self, raw_name, type, prepend, missing_type, rename)\r\n    717 onnx_name = self.get_unique_variable_name(raw_name, rename=rename)\r\n    719 # Create the variable\r\n--> 720 variable = Variable(raw_name, onnx_name, self.name, type)\r\n    721 self.register_variable(variable, prepend=prepend)\r\n    722 return variable\r\n\r\nFile ~\\Anaconda3\\envs\\research\\lib\\site-packages\\skl2onnx\\common\\_topology.py:146, in Variable.__init__(self, raw_name, onnx_name, scope, type)\r\n    144 self.operators_outputs_ = []\r\n    145 self.operators_inputs_ = []\r\n--> 146 self._check()\r\n\r\nFile ~\\Anaconda3\\envs\\research\\lib\\site-packages\\skl2onnx\\common\\_topology.py:154, in Variable._check(self)\r\n    152     continue\r\n    153 if not isinstance(k, (int, np.int64, np.intc)):\r\n--> 154     raise ValueError(\r\n    155         \"Unexpected type %r for shape %r.\"\r\n    156         \"\" % (type(k), self))\r\n\r\nValueError: Unexpected type <class 'numpy.int32'> for shape Variable('count_vec_output', 'count_vec_output', type=FloatTensorType(shape=[None, 19])).\r\n```\r\n\r\n**Environment settings**\r\nRunning Anaconda Command line client (version 1.9.0) with Python 3.8.12 with packages:\r\nonnx==1.10.2\r\nonnxconverter-common==1.9.0\r\nonnxruntime==1.10.0\r\nskl2onnx==1.10.4\r\n\r\nThank you very much for working and contributing to sklean-onnx module!\r\n","closed_by":{"login":"xiaowuhu","id":19218188,"node_id":"MDQ6VXNlcjE5MjE4MTg4","avatar_url":"https://avatars.githubusercontent.com/u/19218188?v=4","gravatar_id":"","url":"https://api.github.com/users/xiaowuhu","html_url":"https://github.com/xiaowuhu","followers_url":"https://api.github.com/users/xiaowuhu/followers","following_url":"https://api.github.com/users/xiaowuhu/following{/other_user}","gists_url":"https://api.github.com/users/xiaowuhu/gists{/gist_id}","starred_url":"https://api.github.com/users/xiaowuhu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xiaowuhu/subscriptions","organizations_url":"https://api.github.com/users/xiaowuhu/orgs","repos_url":"https://api.github.com/users/xiaowuhu/repos","events_url":"https://api.github.com/users/xiaowuhu/events{/privacy}","received_events_url":"https://api.github.com/users/xiaowuhu/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/822/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/822/timeline","performed_via_github_app":null,"state_reason":"completed"}