{"url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/956","repository_url":"https://api.github.com/repos/onnx/sklearn-onnx","labels_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/956/labels{/name}","comments_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/956/comments","events_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/956/events","html_url":"https://github.com/onnx/sklearn-onnx/issues/956","id":1497604197,"node_id":"I_kwDOCa0gS85ZQ6Bl","number":956,"title":"ONNX conversion takes more time","user":{"login":"hanzigs","id":30790120,"node_id":"MDQ6VXNlcjMwNzkwMTIw","avatar_url":"https://avatars.githubusercontent.com/u/30790120?v=4","gravatar_id":"","url":"https://api.github.com/users/hanzigs","html_url":"https://github.com/hanzigs","followers_url":"https://api.github.com/users/hanzigs/followers","following_url":"https://api.github.com/users/hanzigs/following{/other_user}","gists_url":"https://api.github.com/users/hanzigs/gists{/gist_id}","starred_url":"https://api.github.com/users/hanzigs/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hanzigs/subscriptions","organizations_url":"https://api.github.com/users/hanzigs/orgs","repos_url":"https://api.github.com/users/hanzigs/repos","events_url":"https://api.github.com/users/hanzigs/events{/privacy}","received_events_url":"https://api.github.com/users/hanzigs/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-12-15T00:27:39Z","updated_at":"2023-01-05T22:29:07Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\nI'm using onnx converter for pyod Isolation forest\r\n```\r\nfrom onnxruntime import InferenceSession\r\nfrom sklearn.preprocessing import MinMaxScaler\r\nfrom skl2onnx.proto import onnx_proto\r\nfrom skl2onnx.common.data_types import (\r\n    FloatTensorType, Int64TensorType, guess_numpy_type)\r\nfrom skl2onnx import to_onnx, update_registered_converter, get_model_alias\r\nfrom skl2onnx.algebra.onnx_ops import (\r\n    OnnxIdentity, OnnxMul, OnnxLess, OnnxConcat, OnnxCast, OnnxAdd,\r\n    OnnxClip)\r\nfrom skl2onnx.algebra.onnx_operator import OnnxSubEstimator\r\nfrom pyod.models.iforest import IForest\r\n\r\ndef pyod_iforest_parser(scope, model, inputs, custom_parsers=None):\r\n    alias = get_model_alias(type(model))\r\n    this_operator = scope.declare_local_operator(alias, model)\r\n\r\n    # inputs\r\n    this_operator.inputs.append(inputs[0])\r\n\r\n    # outputs\r\n    cls_type = inputs[0].type.__class__\r\n    val_y1 = scope.declare_local_variable('label', Int64TensorType())\r\n    val_y2 = scope.declare_local_variable('probability', cls_type())\r\n    this_operator.outputs.append(val_y1)\r\n    this_operator.outputs.append(val_y2)\r\n\r\n    # end\r\n    return this_operator.outputs\r\n\r\ndef pyod_iforest_shape_calculator(operator):\r\n    N = operator.inputs[0].get_first_dimension()\r\n    operator.outputs[0].type.shape = [N, 1]\r\n    operator.outputs[1].type.shape = [N, 2]\r\n    \r\ndef pyod_iforest_converter(scope, operator, container):\r\n    op = operator.raw_operator\r\n    opv = container.target_opset\r\n    out = operator.outputs\r\n\r\n    # We retrieve the unique input.\r\n    X = operator.inputs[0]\r\n\r\n    # In most case, computation happen in floats.\r\n    # But it might be with double. ONNX is very strict\r\n    # about types, every constant should have the same\r\n    # type as the input.\r\n    dtype = guess_numpy_type(X.type)\r\n    detector = op.detector_  # Should be IForest from scikit-learn.\r\n    lab_pred = OnnxSubEstimator(detector, X, op_version=opv)\r\n    scores = OnnxIdentity(lab_pred[1], op_version=opv)\r\n\r\n    # labels\r\n    threshold = op.threshold_\r\n    above = OnnxLess(scores, np.array([threshold], dtype=dtype),\r\n                     op_version=opv)\r\n    labels = OnnxCast(above, op_version=opv, to=onnx_proto.TensorProto.INT64,\r\n                      output_names=out[:1])\r\n\r\n    # probabilities\r\n    train_scores = op.decision_scores_\r\n    scaler = MinMaxScaler().fit(train_scores.reshape(-1, 1))\r\n    scores_ = OnnxMul(scores, np.array([-1], dtype=dtype),\r\n                      op_version=opv)\r\n    # print(scaler.min_)\r\n    # print(scaler.scale_)\r\n    scaled = OnnxMul(scores_, scaler.scale_.astype(dtype), op_version=opv)\r\n    scaled_centered = OnnxAdd(scaled, scaler.min_.astype(dtype),\r\n                              op_version=opv)\r\n    clipped = OnnxClip(scaled_centered, np.array([0], dtype=dtype),\r\n                       np.array([1], dtype=dtype),\r\n                       op_version=opv)\r\n    clipped_ = OnnxAdd(\r\n        OnnxMul(clipped, np.array([-1], dtype=dtype),\r\n                op_version=opv),\r\n        np.array([1], dtype=dtype),\r\n        op_version=opv)\r\n    scores_2d = OnnxConcat(clipped_, clipped, axis=1, op_version=opv,\r\n                           output_names=out[1:])\r\n    labels.add_to(scope, container)\r\n    scores_2d.add_to(scope, container)\r\n\r\nupdate_registered_converter(\r\n    IForest, \"PyodIForest\",\r\n    pyod_iforest_shape_calculator,\r\n    pyod_iforest_converter,\r\n    parser=pyod_iforest_parser) \r\n```\r\nFor this small data\r\n```\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom pyod.models.iforest import IForest\r\nimport time\r\n\r\ndata = {'First':  [500, 500, 400, 100, 200, 300, 100],\r\n         'Second': ['a', 'b', 'a', 'b', 'a', 'b', 'c']}\r\ndf = pd.DataFrame(data,columns=['First','Second'])\r\ndumdf = pd.get_dummies(df) \r\nscaler = MinMaxScaler()\r\nscaler.partial_fit(dumdf)\r\nsc_data = scaler.transform(dumdf)\r\nmodel = IForest(n_estimators=10, bootstrap=True, behaviour='new',\r\n                 contamination=0.1, random_state=np.random.RandomState(42),\r\n                 verbose=1, n_jobs=-1)\r\nstarttime = time.time()\r\nmodelfit = model.fit(sc_data)\r\nendtime = time.time()\r\n\r\nprint('Model Time: ', endtime - starttime)\r\n\r\nfeature_names = dumdf.columns\r\ninitial_type = [('float_input', FloatTensorType([None, len(feature_names)]))]\r\n# Run Converters from above\r\nstarttime = time.time()\r\nonx = to_onnx(model, initial_types=initial_type)\r\nendtime = time.time()\r\n\r\nprint('ONNX Time: ', endtime - starttime)\r\n```\r\nComparing the Modelling time vs onnx conversion time, its taking 20 times more\r\n![image](https://user-images.githubusercontent.com/30790120/207744128-965d3c75-348a-46f4-8072-e23500d54d6e.png)\r\n\r\nIs there a possibility to reduce this? \r\nI'm using \r\npython 3.9.5\r\nonnxruntime==1.8.0\r\nskl2onnx==1.9.2\r\nscikit-learn==0.24.2\r\npyod==0.8.9\r\n\r\nThanks","closed_by":null,"reactions":{"url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/956/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/onnx/sklearn-onnx/issues/956/timeline","performed_via_github_app":null,"state_reason":null}