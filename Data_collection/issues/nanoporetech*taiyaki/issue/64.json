{"url":"https://api.github.com/repos/nanoporetech/taiyaki/issues/64","repository_url":"https://api.github.com/repos/nanoporetech/taiyaki","labels_url":"https://api.github.com/repos/nanoporetech/taiyaki/issues/64/labels{/name}","comments_url":"https://api.github.com/repos/nanoporetech/taiyaki/issues/64/comments","events_url":"https://api.github.com/repos/nanoporetech/taiyaki/issues/64/events","html_url":"https://github.com/nanoporetech/taiyaki/issues/64","id":534315731,"node_id":"MDU6SXNzdWU1MzQzMTU3MzE=","number":64,"title":"make multiGPU_test: AttributeError: 'DistributedDataParallel' object has no attribute 'sublayers'","user":{"login":"yao12310","id":35583526,"node_id":"MDQ6VXNlcjM1NTgzNTI2","avatar_url":"https://avatars.githubusercontent.com/u/35583526?v=4","gravatar_id":"","url":"https://api.github.com/users/yao12310","html_url":"https://github.com/yao12310","followers_url":"https://api.github.com/users/yao12310/followers","following_url":"https://api.github.com/users/yao12310/following{/other_user}","gists_url":"https://api.github.com/users/yao12310/gists{/gist_id}","starred_url":"https://api.github.com/users/yao12310/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yao12310/subscriptions","organizations_url":"https://api.github.com/users/yao12310/orgs","repos_url":"https://api.github.com/users/yao12310/repos","events_url":"https://api.github.com/users/yao12310/events{/privacy}","received_events_url":"https://api.github.com/users/yao12310/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":true,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2019-12-07T00:05:04Z","updated_at":"2020-11-13T14:35:23Z","closed_at":"2020-11-13T14:35:23Z","author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\n\r\nI'm trying to run ```bin/train_flipflop.py``` in multi-GPU mode, but whenever I run ```make multiGPU_test```, I encounter the above ```AttributeError```. All other tests are passing, and I believe all dependencies (CUDA, nvcc) are enabled. I've included the entire log from execution below, thank you in advance for your help!\r\n\r\n```\r\n+ echo 'Test of multi-GPU training with train_flipflop.py'\r\nTest of multi-GPU training with train_flipflop.py\r\n+ echo ''\r\n\r\n+ OPENBLAS_NUM_THREADS=1\r\n+ export OPENBLAS_NUM_THREADS\r\n+ OMP_NUM_THREADS=4\r\n+ export OMP_NUM_THREADS\r\n+ NGPU=2\r\n+ MAPPEDREADFILE=./test/data/mapped_signal_file/mapped_reads_1.hdf5\r\n+ MODEL=./models/mGru_flipflop.py\r\n+ RESULT_DIR=./workflow/multiGPU_test_results\r\n+ LR_MAX=0.003\r\n+ LR_MIN=0.00015\r\n+ LR_COSINE_ITERS=20000\r\n+ ITERATIONS=100\r\n+ WARMUP=10\r\n+ python -m torch.distributed.launch --nproc_per_node 2 --master_addr 127.0.0.2 --master_port 29501 ./bin/train_flipflop.py --overwrite --lr_cosine_iters 20000 --min_sub_batch_size 32 --warmup_batches 10 --niteration 100 --lr_max 0.003 --lr_min 0.00015 --outdir ./workflow/multiGPU_test_results ./models/mGru_flipflop.py ./test/data/mapped_signal_file/mapped_reads_1.hdf5\r\n* Taiyaki version 5.0.1\r\n* Platform is Linux-3.10.0-693.11.6.el7.x86_64-x86_64-with-redhat-7.4-Nitrogen\r\n* PyTorch version 1.0.0\r\n* CUDA version 9.0.176 on device Tesla K80\r\n* Command line:\r\n* \"./bin/train_flipflop.py --local_rank=0 --overwrite --lr_cosine_iters 20000 --min_sub_batch_size 32 --warmup_batches 10 --niteration 100 --lr_max 0.003 --lr_min 0.00015 --outdir ./workflow/multiGPU_test_results ./models/mGru_flipflop.py ./test/data/mapped_signal_file/mapped_reads_1.hdf5\r\n* Started on 2019-12-04 12:30:50.660884\r\n* Loading data from ./test/data/mapped_signal_file/mapped_reads_1.hdf5\r\n* Per read file MD5 79552fd2bbd6dffdf14c00ced021058d\r\n* Reads not filtered by id\r\n* Using alphabet definition: canonical alphabet ACGT and no modified bases\r\n* Loaded 5 reads.\r\n* Sampled 1000 chunks: median(mean_dwell)=9.84, mad(mean_dwell)=0.94\r\n* Reading network from ./models/mGru_flipflop.py\r\n* Network has 1989160 parameters.\r\n* Loaded standard (canonical bases-only) model.\r\n* Dumping initial model\r\n* Taiyaki version 5.0.1\r\n* Platform is Linux-3.10.0-693.11.6.el7.x86_64-x86_64-with-redhat-7.4-Nitrogen\r\n* PyTorch version 1.0.0\r\n* CUDA version 9.0.176 on device Tesla K80\r\n* Command line:\r\n* \"./bin/train_flipflop.py --local_rank=1 --overwrite --lr_cosine_iters 20000 --min_sub_batch_size 32 --warmup_batches 10 --niteration 100 --lr_max 0.003 --lr_min 0.00015 --outdir ./workflow/multiGPU_test_results ./models/mGru_flipflop.py ./test/data/mapped_signal_file/mapped_reads_1.hdf5\r\n* Started on 2019-12-04 12:30:51.614328\r\n* Loading data from ./test/data/mapped_signal_file/mapped_reads_1.hdf5\r\n* Per read file MD5 79552fd2bbd6dffdf14c00ced021058d\r\n* Reads not filtered by id\r\n* Using alphabet definition: canonical alphabet ACGT and no modified bases\r\n* Loaded 5 reads.\r\n* Sampled 1000 chunks: median(mean_dwell)=9.84, mad(mean_dwell)=0.97\r\n* Reading network from ./models/mGru_flipflop.py\r\n* MultiGPU process 0: loading initial model saved by process 0\r\n* MultiGPU process 1: loading initial model saved by process 0\r\n* Learning rate goes like cosine from lr_max to lr_min over 20000.0 iterations.\r\n* At start, train for 10 batches at warm-up learning rate 0.00015\r\nTraceback (most recent call last):\r\n  File \"./bin/train_flipflop.py\", line 530, in <module>\r\n* Learning rate goes like cosine from lr_max to lr_min over 20000.0 iterations.\r\n* At start, train for 10 batches at warm-up learning rate 0.00015\r\nTraceback (most recent call last):\r\n  File \"./bin/train_flipflop.py\", line 530, in <module>\r\n    main()\r\n  File \"./bin/train_flipflop.py\", line 379, in main\r\n    main()\r\n  File \"./bin/train_flipflop.py\", line 379, in main\r\n    network_is_catmod = is_cat_mod_model(network)\r\n  File \"./bin/train_flipflop.py\", line 106, in is_cat_mod_model\r\n    network_is_catmod = is_cat_mod_model(network)\r\n  File \"./bin/train_flipflop.py\", line 106, in is_cat_mod_model\r\n    return isinstance(network.sublayers[-1], layers.GlobalNormFlipFlopCatMod)\r\n  File \"/global/home/groups/consultsw/sl-7.x86_64/modules/pytorch/1.0.0-py36-cuda9.0/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 535, in __getattr__\r\n    type(self).__name__, name))\r\nAttributeError: 'DistributedDataParallel' object has no attribute 'sublayers'\r\n    return isinstance(network.sublayers[-1], layers.GlobalNormFlipFlopCatMod)\r\n  File \"/global/home/groups/consultsw/sl-7.x86_64/modules/pytorch/1.0.0-py36-cuda9.0/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 535, in __getattr__\r\n    type(self).__name__, name))\r\nAttributeError: 'DistributedDataParallel' object has no attribute 'sublayers'\r\n++ wc -l ./workflow/multiGPU_test_results/batch.log\r\n++ cut -f1 '-d '\r\n+ batchlog_lines=1\r\n+ echo 'Number of lines in training batch log should be 101: 1'\r\nNumber of lines in training batch log should be 101: 1\r\n+ '[' 1 -ne 101 ']'\r\n+ echo 'Training batch log has incorrect number of lines'\r\nTraining batch log has incorrect number of lines\r\n+ exit 1\r\nmake: *** [multiGPU_test] Error 1\r\n```","closed_by":{"login":"tmassingham-ont","id":19410440,"node_id":"MDQ6VXNlcjE5NDEwNDQw","avatar_url":"https://avatars.githubusercontent.com/u/19410440?v=4","gravatar_id":"","url":"https://api.github.com/users/tmassingham-ont","html_url":"https://github.com/tmassingham-ont","followers_url":"https://api.github.com/users/tmassingham-ont/followers","following_url":"https://api.github.com/users/tmassingham-ont/following{/other_user}","gists_url":"https://api.github.com/users/tmassingham-ont/gists{/gist_id}","starred_url":"https://api.github.com/users/tmassingham-ont/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tmassingham-ont/subscriptions","organizations_url":"https://api.github.com/users/tmassingham-ont/orgs","repos_url":"https://api.github.com/users/tmassingham-ont/repos","events_url":"https://api.github.com/users/tmassingham-ont/events{/privacy}","received_events_url":"https://api.github.com/users/tmassingham-ont/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/nanoporetech/taiyaki/issues/64/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/nanoporetech/taiyaki/issues/64/timeline","performed_via_github_app":null,"state_reason":"completed"}