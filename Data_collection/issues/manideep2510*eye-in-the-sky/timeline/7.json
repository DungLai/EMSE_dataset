[{"id":2447222591,"node_id":"MDE3OlJlbmFtZWRUaXRsZUV2ZW50MjQ0NzIyMjU5MQ==","url":"https://api.github.com/repos/manideep2510/eye-in-the-sky/issues/events/2447222591","actor":{"login":"mqray","id":43191048,"node_id":"MDQ6VXNlcjQzMTkxMDQ4","avatar_url":"https://avatars.githubusercontent.com/u/43191048?v=4","gravatar_id":"","url":"https://api.github.com/users/mqray","html_url":"https://github.com/mqray","followers_url":"https://api.github.com/users/mqray/followers","following_url":"https://api.github.com/users/mqray/following{/other_user}","gists_url":"https://api.github.com/users/mqray/gists{/gist_id}","starred_url":"https://api.github.com/users/mqray/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mqray/subscriptions","organizations_url":"https://api.github.com/users/mqray/orgs","repos_url":"https://api.github.com/users/mqray/repos","events_url":"https://api.github.com/users/mqray/events{/privacy}","received_events_url":"https://api.github.com/users/mqray/received_events","type":"User","site_admin":false},"event":"renamed","commit_id":null,"commit_url":null,"created_at":"2019-06-28T12:54:51Z","rename":{"from":"memoryerror","to":"MemoryError"},"performed_via_github_app":null},{"url":"https://api.github.com/repos/manideep2510/eye-in-the-sky/issues/comments/509637124","html_url":"https://github.com/manideep2510/eye-in-the-sky/issues/7#issuecomment-509637124","issue_url":"https://api.github.com/repos/manideep2510/eye-in-the-sky/issues/7","id":509637124,"node_id":"MDEyOklzc3VlQ29tbWVudDUwOTYzNzEyNA==","user":{"login":"manideep2510","id":25865501,"node_id":"MDQ6VXNlcjI1ODY1NTAx","avatar_url":"https://avatars.githubusercontent.com/u/25865501?v=4","gravatar_id":"","url":"https://api.github.com/users/manideep2510","html_url":"https://github.com/manideep2510","followers_url":"https://api.github.com/users/manideep2510/followers","following_url":"https://api.github.com/users/manideep2510/following{/other_user}","gists_url":"https://api.github.com/users/manideep2510/gists{/gist_id}","starred_url":"https://api.github.com/users/manideep2510/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/manideep2510/subscriptions","organizations_url":"https://api.github.com/users/manideep2510/orgs","repos_url":"https://api.github.com/users/manideep2510/repos","events_url":"https://api.github.com/users/manideep2510/events{/privacy}","received_events_url":"https://api.github.com/users/manideep2510/received_events","type":"User","site_admin":false},"created_at":"2019-07-09T13:15:01Z","updated_at":"2019-07-15T03:52:51Z","author_association":"OWNER","body":"The error should be because of these lines of code\r\n``` python\r\ntrainy  = trainy / np.max(trainy)\r\nvaly  = valy / np.max(valy)\r\n```\r\nor \r\n``` python\r\nx_datagen = ImageDataGenerator(**datagen_args)\r\ny_datagen = ImageDataGenerator(**datagen_args)\r\n```\r\nThe ```MemoryError``` happens because your machine doesn't have enough RAM to load the large arrays.\r\nPlease increase the RAM if you are using some kind of a virtual machine like AWS or GCP.\r\n\r\nOr you can use your own DataGenerator function to lead the images batch wise, as in this case you have a large image you can make crops of it like I did in [`main_unet.py`](https://github.com/manideep2510/eye-in-the-sky/blob/master/main_unet.py)","reactions":{"url":"https://api.github.com/repos/manideep2510/eye-in-the-sky/issues/comments/509637124/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"manideep2510","id":25865501,"node_id":"MDQ6VXNlcjI1ODY1NTAx","avatar_url":"https://avatars.githubusercontent.com/u/25865501?v=4","gravatar_id":"","url":"https://api.github.com/users/manideep2510","html_url":"https://github.com/manideep2510","followers_url":"https://api.github.com/users/manideep2510/followers","following_url":"https://api.github.com/users/manideep2510/following{/other_user}","gists_url":"https://api.github.com/users/manideep2510/gists{/gist_id}","starred_url":"https://api.github.com/users/manideep2510/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/manideep2510/subscriptions","organizations_url":"https://api.github.com/users/manideep2510/orgs","repos_url":"https://api.github.com/users/manideep2510/repos","events_url":"https://api.github.com/users/manideep2510/events{/privacy}","received_events_url":"https://api.github.com/users/manideep2510/received_events","type":"User","site_admin":false}},{"id":2481723564,"node_id":"MDExOkNsb3NlZEV2ZW50MjQ4MTcyMzU2NA==","url":"https://api.github.com/repos/manideep2510/eye-in-the-sky/issues/events/2481723564","actor":{"login":"manideep2510","id":25865501,"node_id":"MDQ6VXNlcjI1ODY1NTAx","avatar_url":"https://avatars.githubusercontent.com/u/25865501?v=4","gravatar_id":"","url":"https://api.github.com/users/manideep2510","html_url":"https://github.com/manideep2510","followers_url":"https://api.github.com/users/manideep2510/followers","following_url":"https://api.github.com/users/manideep2510/following{/other_user}","gists_url":"https://api.github.com/users/manideep2510/gists{/gist_id}","starred_url":"https://api.github.com/users/manideep2510/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/manideep2510/subscriptions","organizations_url":"https://api.github.com/users/manideep2510/orgs","repos_url":"https://api.github.com/users/manideep2510/repos","events_url":"https://api.github.com/users/manideep2510/events{/privacy}","received_events_url":"https://api.github.com/users/manideep2510/received_events","type":"User","site_admin":false},"event":"closed","commit_id":null,"commit_url":null,"created_at":"2019-07-15T03:52:56Z","state_reason":null,"performed_via_github_app":null},{"url":"https://api.github.com/repos/manideep2510/eye-in-the-sky/issues/comments/516959798","html_url":"https://github.com/manideep2510/eye-in-the-sky/issues/7#issuecomment-516959798","issue_url":"https://api.github.com/repos/manideep2510/eye-in-the-sky/issues/7","id":516959798,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNjk1OTc5OA==","user":{"login":"prativadas","id":35651955,"node_id":"MDQ6VXNlcjM1NjUxOTU1","avatar_url":"https://avatars.githubusercontent.com/u/35651955?v=4","gravatar_id":"","url":"https://api.github.com/users/prativadas","html_url":"https://github.com/prativadas","followers_url":"https://api.github.com/users/prativadas/followers","following_url":"https://api.github.com/users/prativadas/following{/other_user}","gists_url":"https://api.github.com/users/prativadas/gists{/gist_id}","starred_url":"https://api.github.com/users/prativadas/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prativadas/subscriptions","organizations_url":"https://api.github.com/users/prativadas/orgs","repos_url":"https://api.github.com/users/prativadas/repos","events_url":"https://api.github.com/users/prativadas/events{/privacy}","received_events_url":"https://api.github.com/users/prativadas/received_events","type":"User","site_admin":false},"created_at":"2019-07-31T18:09:59Z","updated_at":"2019-07-31T18:09:59Z","author_association":"NONE","body":"just to see what is happening you can\r\n\r\n> I got some trouble, that when I read all train_x images, I got a problem named MemoryError. The image size is 7200_6800_4 , I'm so confused, could you help me?\r\n> **the content of train.py is:**\r\n> \r\n> ```\r\n> #!usr/bin/env python\r\n> #-*- coding:utf-8 _*-\r\n> #@author:mqray\r\n> #@file: train.py\r\n> #@time: 2019/6/28 12:35\r\n> \r\n> import glob,os\r\n> from libtiff import TIFF\r\n> from funcs import *\r\n> from keras.preprocessing.image import ImageDataGenerator\r\n> \r\n> model = model.UNet(16)\r\n> \r\n> train_src_filelist = glob.glob(r'E:\\2019rscup_segamentation\\data\\main_train\\src\\*.tif')\r\n> train_label_filelist = glob.glob(r'E:\\2019rscup_segamentation\\data\\main_train\\label\\*.tif')\r\n> val_src_filelist = glob.glob(r'E:\\2019rscup_segamentation\\data\\main_val\\src\\*.tif')\r\n> val_label_filelist = glob.glob(r'E:\\2019rscup_segamentation\\data\\main_val\\label\\*.tif')\r\n> test_src_filelist =  glob.glob(r'E:\\2019rscup_segamentation\\data\\main_test\\*.tif')\r\n> print(train_src_filelist)\r\n> #训练集\r\n> train_x = []\r\n> for train_src in train_src_filelist:\r\n>     tif = TIFF.open(train_src)\r\n>     img = tif.read_image()\r\n>     crop_lists = crops(img)\r\n>     train_x = train_x + crop_lists\r\n>     # print(train_x.dtype)\r\n> # print(len(train_src_tmp))\r\n> \r\n> trainx = np.asarray(train_x)\r\n> \r\n> \r\n> train_y = []\r\n> for train_label in train_label_filelist[0]:\r\n>     tif = TIFF.open(train_label)\r\n>     img = tif.read_image()\r\n> \r\n>     crop_lists = crops(img)\r\n>     train_y = train_y + crop_lists\r\n> trainy = np.asarray(train_y)\r\n> \r\n> \r\n> #验证集\r\n> val_x = []\r\n> for val_src in val_src_filelist:\r\n>     tif = TIFF.open(val_src)\r\n>     img= tif.read_image()\r\n> \r\n>     crop_lists = crops(img)\r\n>     val_x = val_x + crop_lists\r\n> valx = np.asarray(val_x)\r\n> \r\n> val_y =[]\r\n> for val_label in val_label_filelist:\r\n>     tif = TIFF.open(val_label)\r\n>     img = tif.read_image()\r\n> \r\n>     crop_lists = crops(img)\r\n>     val_y = val_y + crop_lists\r\n> valy = np.asarray(val_y)\r\n> \r\n> color_dict = {0:(0,200,0),\r\n>               1:(150,250,0),\r\n>               2:(150,200,150),\r\n>               3:(200,0,200),\r\n>               4:(150,0,250),\r\n>               5:(150,150,250),\r\n>               6:(250,200,0),\r\n>               7:(200.200,0),\r\n>               8:(200,0,0),\r\n>               9:(250,0,150),\r\n>               10:(200,150,150),\r\n>               11:(250,150,150),\r\n>               12:(0,0,200),\r\n>               13:(0,150,200),\r\n>               14:(0,200,250),\r\n>               15:(0,0,0)}\r\n> \r\n> '''\r\n> 将标签值one-hot化\r\n> '''\r\n> trainy_hot = []\r\n> for i in range(trainy.shape[0]):\r\n>     hot_img = rgb_to_onehot(train_label_filelist[i], color_dict)\r\n>     trainy_hot.append(hot_img)\r\n> trainy_hot = np.asarray(trainy_hot)\r\n> \r\n> val_hot = []\r\n> for i in range(valy.shape[0]):\r\n>     hot_img = rgb_to_onehot(val_label_filelist[i], color_dict)\r\n>     val_hot.append(hot_img)\r\n> val_hot = np.asarray(val_hot)\r\n> \r\n> trainy  = trainy / np.max(trainy)\r\n> valy  = valy / np.max(valy)\r\n> \r\n> # data augmentation\r\n> \r\n> datagen_args = dict(rotation_range=45.,\r\n>                          width_shift_range=0.1,\r\n>                          height_shift_range=0.1,\r\n>                          shear_range=0.2,\r\n>                          zoom_range=0.2,\r\n>                          horizontal_flip=True,\r\n>                          vertical_flip=True,\r\n>                          fill_mode='reflect')\r\n> x_datagen = ImageDataGenerator(**datagen_args)\r\n> y_datagen = ImageDataGenerator(**datagen_args)\r\n> seed = 1\r\n> batch_size = 16\r\n> x_datagen.fit(train_x, augment=True, seed = seed)\r\n> y_datagen.fit(trainy, augment=True, seed = seed)\r\n> x_generator = x_datagen.flow(train_x, batch_size = 16, seed=seed)\r\n> y_generator = y_datagen.flow(trainy, batch_size = 16, seed=seed)\r\n> train_generator = zip(x_generator, y_generator)\r\n> X_datagen_val = ImageDataGenerator()\r\n> Y_datagen_val = ImageDataGenerator()\r\n> X_datagen_val.fit(valx, augment=True, seed=seed)\r\n> Y_datagen_val.fit(valy, augment=True, seed=seed)\r\n> X_test_augmented = X_datagen_val.flow(valx, batch_size=batch_size, seed=seed)\r\n> Y_test_augmented = Y_datagen_val.flow(valy, batch_size=batch_size, seed=seed)\r\n> test_generator = zip(X_test_augmented, Y_test_augmented)\r\n> history = model.fit_generator(train_generator, validation_data=test_generator, validation_steps=batch_size/2, epochs = 10, steps_per_epoch=len(x_generator))\r\n> model.save(\"model_augment.h5\")\r\n> \r\n> \r\n> \r\n> # history = model.fit(train_src_tmp,trainy_hot,epochs=1,validation_data=(val_src_x,val_hot),batch_size=1,verbose=1)\r\n> # model.save('model_onehot.h5')\r\n> \r\n> print(history.history.keys())\r\n> plt.plot(history.history['acc'])\r\n> plt.plot(history.history['val_acc'])\r\n> plt.title('model accuracy')\r\n> plt.ylabel('acc')\r\n> plt.xlabel('epoch')\r\n> plt.legend(['train','val'],'upper left')\r\n> plt.savefig('acc_plot.jpg')\r\n> plt.show()\r\n> plt.close()\r\n> \r\n> print(history.history.keys())\r\n> plt.plot(history.history['loss'])\r\n> plt.plot(history.history['val_loss'])\r\n> plt.title('model accuracy')\r\n> plt.ylabel('loss')\r\n> plt.xlabel('epoch')\r\n> plt.legend(['train','val'],'upper left')\r\n> plt.savefig('loss_plot.jpg')\r\n> plt.show()\r\n> plt.close()\r\n> ```\r\n> \r\n> **and the model file is :**\r\n> \r\n> ```\r\n> #!usr/bin/env python\r\n> #-*- coding:utf-8 _*-\r\n> #@author:mqray\r\n> #@file: uunet.py\r\n> #@time: 2019/6/24 10:48\r\n> \r\n> import PIL\r\n> from PIL import Image\r\n> import matplotlib.pyplot as plt\r\n> from libtiff import TIFF\r\n> from libtiff import TIFFfile, TIFFimage\r\n> from scipy.misc import imresize\r\n> import numpy as np\r\n> import glob\r\n> import cv2\r\n> import os\r\n> import math\r\n> import skimage.io as io\r\n> import skimage.transform as trans\r\n> from keras.models import *\r\n> from keras.layers import *\r\n> from keras.optimizers import *\r\n> from keras.callbacks import ModelCheckpoint, LearningRateScheduler\r\n> from keras.preprocessing.image import ImageDataGenerator\r\n> from keras import backend as K\r\n> \r\n> \r\n> # %matplotlib inline\r\n> \r\n> def UNet(num_class,shape=(512, 512, 4)):\r\n>     # Left side of the U-Net\r\n>     inputs = Input(shape)\r\n>     #    in_shape = inputs.shape\r\n>     #    print(in_shape)\r\n>     conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='random_normal')(inputs)\r\n>     conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv1)\r\n>     conv1 = BatchNormalization()(conv1)\r\n>     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\r\n>     conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='random_normal')(pool1)\r\n>     conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv2)\r\n>     conv2 = BatchNormalization()(conv2)\r\n>     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\r\n>     conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='random_normal')(pool2)\r\n>     conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv3)\r\n>     conv3 = BatchNormalization()(conv3)\r\n>     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\r\n>     conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='random_normal')(pool3)\r\n>     conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv4)\r\n>     conv4 = BatchNormalization()(conv4)\r\n>     drop4 = Dropout(0.5)(conv4)\r\n>     pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\r\n> \r\n>     # Bottom of the U-Net\r\n>     conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='random_normal')(pool4)\r\n>     conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv5)\r\n>     conv5 = BatchNormalization()(conv5)\r\n>     drop5 = Dropout(0.5)(conv5)\r\n> \r\n>     # Upsampling Starts, right side of the U-Net\r\n>     up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='random_normal')(\r\n>         UpSampling2D(size=(2, 2))(drop5))\r\n>     merge6 = concatenate([drop4, up6], axis=3)\r\n>     conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='random_normal')(merge6)\r\n>     conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv6)\r\n>     conv6 = BatchNormalization()(conv6)\r\n> \r\n>     up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='random_normal')(\r\n>         UpSampling2D(size=(2, 2))(conv6))\r\n>     merge7 = concatenate([conv3, up7], axis=3)\r\n>     conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='random_normal')(merge7)\r\n>     conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv7)\r\n>     conv7 = BatchNormalization()(conv7)\r\n> \r\n>     up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='random_normal')(\r\n>         UpSampling2D(size=(2, 2))(conv7))\r\n>     merge8 = concatenate([conv2, up8], axis=3)\r\n>     conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='random_normal')(merge8)\r\n>     conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv8)\r\n>     conv8 = BatchNormalization()(conv8)\r\n> \r\n>     up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='random_normal')(\r\n>         UpSampling2D(size=(2, 2))(conv8))\r\n>     merge9 = concatenate([conv1, up9], axis=3)\r\n>     conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='random_normal')(merge9)\r\n>     conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv9)\r\n>     conv9 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv9)\r\n>     conv9 = BatchNormalization()(conv9)\r\n> \r\n>     # Output layer of the U-Net with a softmax activation\r\n>     conv10 = Conv2D(num_class, 1, activation='softmax')(conv9)\r\n> \r\n>     model = Model(input=inputs, output=conv10)\r\n> \r\n>     model.compile(optimizer=Adam(lr=0.000001), loss='categorical_crossentropy', metrics=['accuracy'])\r\n> \r\n>     model.summary()\r\n> \r\n>     # filelist_modelweights = sorted(glob.glob('*.h5'), key=numericalSort)\r\n> \r\n>     # if 'model_nocropping.h5' in filelist_modelweights:\r\n>     #   model.load_weights('model_nocropping.h5')\r\n>     return model\r\n> ```\r\n\r\njust to see what is happening you can decrease the number of epochs and also batch size if you are running the code on a local  machine with no GPU","reactions":{"url":"https://api.github.com/repos/manideep2510/eye-in-the-sky/issues/comments/516959798/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"prativadas","id":35651955,"node_id":"MDQ6VXNlcjM1NjUxOTU1","avatar_url":"https://avatars.githubusercontent.com/u/35651955?v=4","gravatar_id":"","url":"https://api.github.com/users/prativadas","html_url":"https://github.com/prativadas","followers_url":"https://api.github.com/users/prativadas/followers","following_url":"https://api.github.com/users/prativadas/following{/other_user}","gists_url":"https://api.github.com/users/prativadas/gists{/gist_id}","starred_url":"https://api.github.com/users/prativadas/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/prativadas/subscriptions","organizations_url":"https://api.github.com/users/prativadas/orgs","repos_url":"https://api.github.com/users/prativadas/repos","events_url":"https://api.github.com/users/prativadas/events{/privacy}","received_events_url":"https://api.github.com/users/prativadas/received_events","type":"User","site_admin":false}}]