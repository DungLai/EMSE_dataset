{"url":"https://api.github.com/repos/manideep2510/eye-in-the-sky/issues/7","repository_url":"https://api.github.com/repos/manideep2510/eye-in-the-sky","labels_url":"https://api.github.com/repos/manideep2510/eye-in-the-sky/issues/7/labels{/name}","comments_url":"https://api.github.com/repos/manideep2510/eye-in-the-sky/issues/7/comments","events_url":"https://api.github.com/repos/manideep2510/eye-in-the-sky/issues/7/events","html_url":"https://github.com/manideep2510/eye-in-the-sky/issues/7","id":462021088,"node_id":"MDU6SXNzdWU0NjIwMjEwODg=","number":7,"title":"MemoryError","user":{"login":"mqray","id":43191048,"node_id":"MDQ6VXNlcjQzMTkxMDQ4","avatar_url":"https://avatars.githubusercontent.com/u/43191048?v=4","gravatar_id":"","url":"https://api.github.com/users/mqray","html_url":"https://github.com/mqray","followers_url":"https://api.github.com/users/mqray/followers","following_url":"https://api.github.com/users/mqray/following{/other_user}","gists_url":"https://api.github.com/users/mqray/gists{/gist_id}","starred_url":"https://api.github.com/users/mqray/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mqray/subscriptions","organizations_url":"https://api.github.com/users/mqray/orgs","repos_url":"https://api.github.com/users/mqray/repos","events_url":"https://api.github.com/users/mqray/events{/privacy}","received_events_url":"https://api.github.com/users/mqray/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2019-06-28T12:54:25Z","updated_at":"2019-07-31T18:09:59Z","closed_at":"2019-07-15T03:52:56Z","author_association":"NONE","active_lock_reason":null,"body":"I got some trouble, that when I read all train_x images, I got a problem named  MemoryError. The image size is 7200*6800*4 , I'm so confused, could you help me?\r\n**the content of train.py  is:**\r\n```\r\n#!usr/bin/env python\r\n#-*- coding:utf-8 _*-\r\n#@author:mqray\r\n#@file: train.py\r\n#@time: 2019/6/28 12:35\r\n\r\nimport glob,os\r\nfrom libtiff import TIFF\r\nfrom funcs import *\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\n\r\nmodel = model.UNet(16)\r\n\r\ntrain_src_filelist = glob.glob(r'E:\\2019rscup_segamentation\\data\\main_train\\src\\*.tif')\r\ntrain_label_filelist = glob.glob(r'E:\\2019rscup_segamentation\\data\\main_train\\label\\*.tif')\r\nval_src_filelist = glob.glob(r'E:\\2019rscup_segamentation\\data\\main_val\\src\\*.tif')\r\nval_label_filelist = glob.glob(r'E:\\2019rscup_segamentation\\data\\main_val\\label\\*.tif')\r\ntest_src_filelist =  glob.glob(r'E:\\2019rscup_segamentation\\data\\main_test\\*.tif')\r\nprint(train_src_filelist)\r\n#训练集\r\ntrain_x = []\r\nfor train_src in train_src_filelist:\r\n    tif = TIFF.open(train_src)\r\n    img = tif.read_image()\r\n    crop_lists = crops(img)\r\n    train_x = train_x + crop_lists\r\n    # print(train_x.dtype)\r\n# print(len(train_src_tmp))\r\n\r\ntrainx = np.asarray(train_x)\r\n\r\n\r\ntrain_y = []\r\nfor train_label in train_label_filelist[0]:\r\n    tif = TIFF.open(train_label)\r\n    img = tif.read_image()\r\n\r\n    crop_lists = crops(img)\r\n    train_y = train_y + crop_lists\r\ntrainy = np.asarray(train_y)\r\n\r\n\r\n#验证集\r\nval_x = []\r\nfor val_src in val_src_filelist:\r\n    tif = TIFF.open(val_src)\r\n    img= tif.read_image()\r\n\r\n    crop_lists = crops(img)\r\n    val_x = val_x + crop_lists\r\nvalx = np.asarray(val_x)\r\n\r\nval_y =[]\r\nfor val_label in val_label_filelist:\r\n    tif = TIFF.open(val_label)\r\n    img = tif.read_image()\r\n\r\n    crop_lists = crops(img)\r\n    val_y = val_y + crop_lists\r\nvaly = np.asarray(val_y)\r\n\r\ncolor_dict = {0:(0,200,0),\r\n              1:(150,250,0),\r\n              2:(150,200,150),\r\n              3:(200,0,200),\r\n              4:(150,0,250),\r\n              5:(150,150,250),\r\n              6:(250,200,0),\r\n              7:(200.200,0),\r\n              8:(200,0,0),\r\n              9:(250,0,150),\r\n              10:(200,150,150),\r\n              11:(250,150,150),\r\n              12:(0,0,200),\r\n              13:(0,150,200),\r\n              14:(0,200,250),\r\n              15:(0,0,0)}\r\n\r\n'''\r\n将标签值one-hot化\r\n'''\r\ntrainy_hot = []\r\nfor i in range(trainy.shape[0]):\r\n    hot_img = rgb_to_onehot(train_label_filelist[i], color_dict)\r\n    trainy_hot.append(hot_img)\r\ntrainy_hot = np.asarray(trainy_hot)\r\n\r\nval_hot = []\r\nfor i in range(valy.shape[0]):\r\n    hot_img = rgb_to_onehot(val_label_filelist[i], color_dict)\r\n    val_hot.append(hot_img)\r\nval_hot = np.asarray(val_hot)\r\n\r\ntrainy  = trainy / np.max(trainy)\r\nvaly  = valy / np.max(valy)\r\n\r\n# data augmentation\r\n\r\ndatagen_args = dict(rotation_range=45.,\r\n                         width_shift_range=0.1,\r\n                         height_shift_range=0.1,\r\n                         shear_range=0.2,\r\n                         zoom_range=0.2,\r\n                         horizontal_flip=True,\r\n                         vertical_flip=True,\r\n                         fill_mode='reflect')\r\nx_datagen = ImageDataGenerator(**datagen_args)\r\ny_datagen = ImageDataGenerator(**datagen_args)\r\nseed = 1\r\nbatch_size = 16\r\nx_datagen.fit(train_x, augment=True, seed = seed)\r\ny_datagen.fit(trainy, augment=True, seed = seed)\r\nx_generator = x_datagen.flow(train_x, batch_size = 16, seed=seed)\r\ny_generator = y_datagen.flow(trainy, batch_size = 16, seed=seed)\r\ntrain_generator = zip(x_generator, y_generator)\r\nX_datagen_val = ImageDataGenerator()\r\nY_datagen_val = ImageDataGenerator()\r\nX_datagen_val.fit(valx, augment=True, seed=seed)\r\nY_datagen_val.fit(valy, augment=True, seed=seed)\r\nX_test_augmented = X_datagen_val.flow(valx, batch_size=batch_size, seed=seed)\r\nY_test_augmented = Y_datagen_val.flow(valy, batch_size=batch_size, seed=seed)\r\ntest_generator = zip(X_test_augmented, Y_test_augmented)\r\nhistory = model.fit_generator(train_generator, validation_data=test_generator, validation_steps=batch_size/2, epochs = 10, steps_per_epoch=len(x_generator))\r\nmodel.save(\"model_augment.h5\")\r\n\r\n\r\n\r\n# history = model.fit(train_src_tmp,trainy_hot,epochs=1,validation_data=(val_src_x,val_hot),batch_size=1,verbose=1)\r\n# model.save('model_onehot.h5')\r\n\r\nprint(history.history.keys())\r\nplt.plot(history.history['acc'])\r\nplt.plot(history.history['val_acc'])\r\nplt.title('model accuracy')\r\nplt.ylabel('acc')\r\nplt.xlabel('epoch')\r\nplt.legend(['train','val'],'upper left')\r\nplt.savefig('acc_plot.jpg')\r\nplt.show()\r\nplt.close()\r\n\r\nprint(history.history.keys())\r\nplt.plot(history.history['loss'])\r\nplt.plot(history.history['val_loss'])\r\nplt.title('model accuracy')\r\nplt.ylabel('loss')\r\nplt.xlabel('epoch')\r\nplt.legend(['train','val'],'upper left')\r\nplt.savefig('loss_plot.jpg')\r\nplt.show()\r\nplt.close()\r\n```\r\n\r\n**and the model file is :**\r\n```\r\n#!usr/bin/env python\r\n#-*- coding:utf-8 _*-\r\n#@author:mqray\r\n#@file: uunet.py\r\n#@time: 2019/6/24 10:48\r\n\r\nimport PIL\r\nfrom PIL import Image\r\nimport matplotlib.pyplot as plt\r\nfrom libtiff import TIFF\r\nfrom libtiff import TIFFfile, TIFFimage\r\nfrom scipy.misc import imresize\r\nimport numpy as np\r\nimport glob\r\nimport cv2\r\nimport os\r\nimport math\r\nimport skimage.io as io\r\nimport skimage.transform as trans\r\nfrom keras.models import *\r\nfrom keras.layers import *\r\nfrom keras.optimizers import *\r\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\nfrom keras import backend as K\r\n\r\n\r\n# %matplotlib inline\r\n\r\ndef UNet(num_class,shape=(512, 512, 4)):\r\n    # Left side of the U-Net\r\n    inputs = Input(shape)\r\n    #    in_shape = inputs.shape\r\n    #    print(in_shape)\r\n    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='random_normal')(inputs)\r\n    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv1)\r\n    conv1 = BatchNormalization()(conv1)\r\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\r\n    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='random_normal')(pool1)\r\n    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv2)\r\n    conv2 = BatchNormalization()(conv2)\r\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\r\n    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='random_normal')(pool2)\r\n    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv3)\r\n    conv3 = BatchNormalization()(conv3)\r\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\r\n    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='random_normal')(pool3)\r\n    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv4)\r\n    conv4 = BatchNormalization()(conv4)\r\n    drop4 = Dropout(0.5)(conv4)\r\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\r\n\r\n    # Bottom of the U-Net\r\n    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='random_normal')(pool4)\r\n    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv5)\r\n    conv5 = BatchNormalization()(conv5)\r\n    drop5 = Dropout(0.5)(conv5)\r\n\r\n    # Upsampling Starts, right side of the U-Net\r\n    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='random_normal')(\r\n        UpSampling2D(size=(2, 2))(drop5))\r\n    merge6 = concatenate([drop4, up6], axis=3)\r\n    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='random_normal')(merge6)\r\n    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv6)\r\n    conv6 = BatchNormalization()(conv6)\r\n\r\n    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='random_normal')(\r\n        UpSampling2D(size=(2, 2))(conv6))\r\n    merge7 = concatenate([conv3, up7], axis=3)\r\n    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='random_normal')(merge7)\r\n    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv7)\r\n    conv7 = BatchNormalization()(conv7)\r\n\r\n    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='random_normal')(\r\n        UpSampling2D(size=(2, 2))(conv7))\r\n    merge8 = concatenate([conv2, up8], axis=3)\r\n    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='random_normal')(merge8)\r\n    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv8)\r\n    conv8 = BatchNormalization()(conv8)\r\n\r\n    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='random_normal')(\r\n        UpSampling2D(size=(2, 2))(conv8))\r\n    merge9 = concatenate([conv1, up9], axis=3)\r\n    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='random_normal')(merge9)\r\n    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv9)\r\n    conv9 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='random_normal')(conv9)\r\n    conv9 = BatchNormalization()(conv9)\r\n\r\n    # Output layer of the U-Net with a softmax activation\r\n    conv10 = Conv2D(num_class, 1, activation='softmax')(conv9)\r\n\r\n    model = Model(input=inputs, output=conv10)\r\n\r\n    model.compile(optimizer=Adam(lr=0.000001), loss='categorical_crossentropy', metrics=['accuracy'])\r\n\r\n    model.summary()\r\n\r\n    # filelist_modelweights = sorted(glob.glob('*.h5'), key=numericalSort)\r\n\r\n    # if 'model_nocropping.h5' in filelist_modelweights:\r\n    #   model.load_weights('model_nocropping.h5')\r\n    return model\r\n\r\n```\r\n\r\n","closed_by":{"login":"manideep2510","id":25865501,"node_id":"MDQ6VXNlcjI1ODY1NTAx","avatar_url":"https://avatars.githubusercontent.com/u/25865501?v=4","gravatar_id":"","url":"https://api.github.com/users/manideep2510","html_url":"https://github.com/manideep2510","followers_url":"https://api.github.com/users/manideep2510/followers","following_url":"https://api.github.com/users/manideep2510/following{/other_user}","gists_url":"https://api.github.com/users/manideep2510/gists{/gist_id}","starred_url":"https://api.github.com/users/manideep2510/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/manideep2510/subscriptions","organizations_url":"https://api.github.com/users/manideep2510/orgs","repos_url":"https://api.github.com/users/manideep2510/repos","events_url":"https://api.github.com/users/manideep2510/events{/privacy}","received_events_url":"https://api.github.com/users/manideep2510/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/manideep2510/eye-in-the-sky/issues/7/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/manideep2510/eye-in-the-sky/issues/7/timeline","performed_via_github_app":null,"state_reason":"completed"}