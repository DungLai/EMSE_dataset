{"url":"https://api.github.com/repos/nikitakit/self-attentive-parser/issues/5","repository_url":"https://api.github.com/repos/nikitakit/self-attentive-parser","labels_url":"https://api.github.com/repos/nikitakit/self-attentive-parser/issues/5/labels{/name}","comments_url":"https://api.github.com/repos/nikitakit/self-attentive-parser/issues/5/comments","events_url":"https://api.github.com/repos/nikitakit/self-attentive-parser/issues/5/events","html_url":"https://github.com/nikitakit/self-attentive-parser/issues/5","id":349144279,"node_id":"MDU6SXNzdWUzNDkxNDQyNzk=","number":5,"title":"Error when parsing the American Constitution with spacy","user":{"login":"shlomihod","id":6306135,"node_id":"MDQ6VXNlcjYzMDYxMzU=","avatar_url":"https://avatars.githubusercontent.com/u/6306135?v=4","gravatar_id":"","url":"https://api.github.com/users/shlomihod","html_url":"https://github.com/shlomihod","followers_url":"https://api.github.com/users/shlomihod/followers","following_url":"https://api.github.com/users/shlomihod/following{/other_user}","gists_url":"https://api.github.com/users/shlomihod/gists{/gist_id}","starred_url":"https://api.github.com/users/shlomihod/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shlomihod/subscriptions","organizations_url":"https://api.github.com/users/shlomihod/orgs","repos_url":"https://api.github.com/users/shlomihod/repos","events_url":"https://api.github.com/users/shlomihod/events{/privacy}","received_events_url":"https://api.github.com/users/shlomihod/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2018-08-09T14:08:32Z","updated_at":"2019-07-31T13:42:36Z","closed_at":"2019-01-06T04:56:19Z","author_association":"NONE","active_lock_reason":null,"body":"I'm trying to run the parse using spacy on the American Constitution (https://pastebin.com/Ss2MWFVr) with this code:\r\n\r\n```python\r\nimport spacy\r\nfrom benepar.spacy_plugin import BeneparComponent\r\n\r\nnlp = spacy.load('en')\r\nnlp.add_pipe(BeneparComponent(\"benepar_en\"))\r\n\r\nnlp(american_constitution_text)\r\n```\r\nI'm getting an error - the error is different for using CPU or GPU. I've also tried longer text, and there is no problem. If I remove `nlp.add_pipe(BeneparComponent(\"benepar_en\"))`, it works.\r\n\r\n### CPU Error\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1321     try:\r\n-> 1322       return fn(*args)\r\n   1323     except errors.OpError as e:\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1306       return self._call_tf_sessionrun(\r\n-> 1307           options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1308 \r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1408           self._session, options, feed_dict, fetch_list, target_list,\r\n-> 1409           run_metadata)\r\n   1410     else:\r\n\r\nInvalidArgumentError: indices[2590] = 29134 is not in [0, 19200)\r\n\t [[Node: GatherV2_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Tile, ToInt32, GatherV2_8/axis)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-10-aeb678c45aba> in <module>()\r\n----> 1 nlp_only_parsing(PROBLEMATIC_TEXT)\r\n\r\n~/.local/lib/python3.5/site-packages/spacy/language.py in __call__(self, text, disable)\r\n    350             if not hasattr(proc, '__call__'):\r\n    351                 raise ValueError(Errors.E003.format(component=type(proc), name=name))\r\n--> 352             doc = proc(doc)\r\n    353             if doc is None:\r\n    354                 raise ValueError(Errors.E005.format(name=name))\r\n\r\n~/.local/lib/python3.5/site-packages/benepar/spacy_plugin.py in __call__(self, doc)\r\n     75     def __call__(self, doc):\r\n     76         constituent_data = PartialConstituentData()\r\n---> 77         for parse_raw, sent in self._batched_parsed_raw(self._process_doc(doc)):\r\n     78             # The optimized cython decoder implementation doesn't actually\r\n     79             # generate trees, only scores and span indices. Indices follow a\r\n\r\n~/.local/lib/python3.5/site-packages/benepar/base_parser.py in _batched_parsed_raw(self, sentence_data_pairs)\r\n    220             batch_data.append(datum)\r\n    221             if len(batch_sentences) >= self.batch_size:\r\n--> 222                 for chart_np, datum in zip(self._make_charts(batch_sentences), batch_data):\r\n    223                     yield chart_decoder.decode(chart_np), datum\r\n    224                 batch_sentences = []\r\n\r\n~/.local/lib/python3.5/site-packages/benepar/base_parser.py in _make_charts(self, sentences)\r\n    203     def _make_charts(self, sentences):\r\n    204         inp_val = self._charify(sentences)\r\n--> 205         out_val = self._sess.run(self._charts, {self._chars: inp_val})\r\n    206         for snum, sentence in enumerate(sentences):\r\n    207             chart_size = len(sentence) + 1\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    898     try:\r\n    899       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 900                          run_metadata_ptr)\r\n    901       if run_metadata:\r\n    902         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1133     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1134       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1135                              feed_dict_tensor, options, run_metadata)\r\n   1136     else:\r\n   1137       results = []\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1314     if handle is None:\r\n   1315       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1316                            run_metadata)\r\n   1317     else:\r\n   1318       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1333         except KeyError:\r\n   1334           pass\r\n-> 1335       raise type(e)(node_def, op, message)\r\n   1336 \r\n   1337   def _extend_graph(self):\r\n\r\nInvalidArgumentError: indices[2590] = 29134 is not in [0, 19200)\r\n\t [[Node: GatherV2_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Tile, ToInt32, GatherV2_8/axis)]]\r\n\r\nCaused by op 'GatherV2_1', defined at:\r\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\r\n    self.io_loop.start()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 127, in start\r\n    self.asyncio_loop.run_forever()\r\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\r\n    self._run_once()\r\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\r\n    handle._run()\r\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\r\n    self._callback(*self._args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 759, in _run_callback\r\n    ret = callback()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\r\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\r\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\r\n    self._handle_recv()\r\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\r\n    raw_cell, store_history, silent, shell_futures)\r\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-9-6f0432446d27>\", line 6, in <module>\r\n    nlp_only_parsing.add_pipe(BeneparComponent(\"benepar_en\"))\r\n  File \"/home/users/shlohod/.local/lib/python3.5/site-packages/benepar/spacy_plugin.py\", line 73, in __init__\r\n    super(BeneparComponent, self).__init__(filename, batch_size)\r\n  File \"/home/users/shlohod/.local/lib/python3.5/site-packages/benepar/base_parser.py\", line 163, in __init__\r\n    tf.import_graph_def(graph_def, name='')\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/importer.py\", line 513, in import_graph_def\r\n    _ProcessNewOps(graph)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/importer.py\", line 303, in _ProcessNewOps\r\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3540, in _add_new_tf_operations\r\n    for c_op in c_api_util.new_tf_operations(self)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3540, in <listcomp>\r\n    for c_op in c_api_util.new_tf_operations(self)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3428, in _create_op_from_tf_operation\r\n    ret = Operation(c_op, self)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): indices[2590] = 29134 is not in [0, 19200)\r\n\t [[Node: GatherV2_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Tile, ToInt32, GatherV2_8/axis)]]\r\n```\r\n\r\n### GPU Error\r\n```\r\n---------------------------------------------------------------------------\r\nResourceExhaustedError                    Traceback (most recent call last)\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1321     try:\r\n-> 1322       return fn(*args)\r\n   1323     except errors.OpError as e:\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1306       return self._call_tf_sessionrun(\r\n-> 1307           options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1308 \r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1408           self._session, options, feed_dict, fetch_list, target_list,\r\n-> 1409           run_metadata)\r\n   1410     else:\r\n\r\nResourceExhaustedError: OOM when allocating tensor of shape [1024,16384] and type float\r\n\t [[Node: ConstantFolding/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel_enter = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [1024,16384] values: [0.0838829875 0.0388401747 0.173968613]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](^bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/while/lstm_cell/MatMul/Enter)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nResourceExhaustedError                    Traceback (most recent call last)\r\n<ipython-input-3-8f26748b155f> in <module>()\r\n      5 nlp.add_pipe(BeneparComponent(\"benepar_en\"))\r\n      6 \r\n----> 7 nlp(american)\r\n\r\n~/.local/lib/python3.5/site-packages/spacy/language.py in __call__(self, text, disable)\r\n    350             if not hasattr(proc, '__call__'):\r\n    351                 raise ValueError(Errors.E003.format(component=type(proc), name=name))\r\n--> 352             doc = proc(doc)\r\n    353             if doc is None:\r\n    354                 raise ValueError(Errors.E005.format(name=name))\r\n\r\n~/.local/lib/python3.5/site-packages/benepar/spacy_plugin.py in __call__(self, doc)\r\n     75     def __call__(self, doc):\r\n     76         constituent_data = PartialConstituentData()\r\n---> 77         for parse_raw, sent in self._batched_parsed_raw(self._process_doc(doc)):\r\n     78             # The optimized cython decoder implementation doesn't actually\r\n     79             # generate trees, only scores and span indices. Indices follow a\r\n\r\n~/.local/lib/python3.5/site-packages/benepar/base_parser.py in _batched_parsed_raw(self, sentence_data_pairs)\r\n    220             batch_data.append(datum)\r\n    221             if len(batch_sentences) >= self.batch_size:\r\n--> 222                 for chart_np, datum in zip(self._make_charts(batch_sentences), batch_data):\r\n    223                     yield chart_decoder.decode(chart_np), datum\r\n    224                 batch_sentences = []\r\n\r\n~/.local/lib/python3.5/site-packages/benepar/base_parser.py in _make_charts(self, sentences)\r\n    203     def _make_charts(self, sentences):\r\n    204         inp_val = self._charify(sentences)\r\n--> 205         out_val = self._sess.run(self._charts, {self._chars: inp_val})\r\n    206         for snum, sentence in enumerate(sentences):\r\n    207             chart_size = len(sentence) + 1\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    898     try:\r\n    899       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 900                          run_metadata_ptr)\r\n    901       if run_metadata:\r\n    902         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1133     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1134       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1135                              feed_dict_tensor, options, run_metadata)\r\n   1136     else:\r\n   1137       results = []\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1314     if handle is None:\r\n   1315       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1316                            run_metadata)\r\n   1317     else:\r\n   1318       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1333         except KeyError:\r\n   1334           pass\r\n-> 1335       raise type(e)(node_def, op, message)\r\n   1336 \r\n   1337   def _extend_graph(self):\r\n\r\nResourceExhaustedError: OOM when allocating tensor of shape [1024,16384] and type float\r\n\t [[Node: ConstantFolding/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel_enter = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [1024,16384] values: [0.0838829875 0.0388401747 0.173968613]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](^bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/while/lstm_cell/MatMul/Enter)]]\r\n```","closed_by":{"login":"nikitakit","id":252225,"node_id":"MDQ6VXNlcjI1MjIyNQ==","avatar_url":"https://avatars.githubusercontent.com/u/252225?v=4","gravatar_id":"","url":"https://api.github.com/users/nikitakit","html_url":"https://github.com/nikitakit","followers_url":"https://api.github.com/users/nikitakit/followers","following_url":"https://api.github.com/users/nikitakit/following{/other_user}","gists_url":"https://api.github.com/users/nikitakit/gists{/gist_id}","starred_url":"https://api.github.com/users/nikitakit/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nikitakit/subscriptions","organizations_url":"https://api.github.com/users/nikitakit/orgs","repos_url":"https://api.github.com/users/nikitakit/repos","events_url":"https://api.github.com/users/nikitakit/events{/privacy}","received_events_url":"https://api.github.com/users/nikitakit/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/nikitakit/self-attentive-parser/issues/5/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/nikitakit/self-attentive-parser/issues/5/timeline","performed_via_github_app":null,"state_reason":"completed"}