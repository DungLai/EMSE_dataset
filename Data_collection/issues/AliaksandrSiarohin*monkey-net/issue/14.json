{"url":"https://api.github.com/repos/AliaksandrSiarohin/monkey-net/issues/14","repository_url":"https://api.github.com/repos/AliaksandrSiarohin/monkey-net","labels_url":"https://api.github.com/repos/AliaksandrSiarohin/monkey-net/issues/14/labels{/name}","comments_url":"https://api.github.com/repos/AliaksandrSiarohin/monkey-net/issues/14/comments","events_url":"https://api.github.com/repos/AliaksandrSiarohin/monkey-net/issues/14/events","html_url":"https://github.com/AliaksandrSiarohin/monkey-net/issues/14","id":479996345,"node_id":"MDU6SXNzdWU0Nzk5OTYzNDU=","number":14,"title":"Error running code on 2 GPUs","user":{"login":"TsainGra","id":24549065,"node_id":"MDQ6VXNlcjI0NTQ5MDY1","avatar_url":"https://avatars.githubusercontent.com/u/24549065?v=4","gravatar_id":"","url":"https://api.github.com/users/TsainGra","html_url":"https://github.com/TsainGra","followers_url":"https://api.github.com/users/TsainGra/followers","following_url":"https://api.github.com/users/TsainGra/following{/other_user}","gists_url":"https://api.github.com/users/TsainGra/gists{/gist_id}","starred_url":"https://api.github.com/users/TsainGra/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/TsainGra/subscriptions","organizations_url":"https://api.github.com/users/TsainGra/orgs","repos_url":"https://api.github.com/users/TsainGra/repos","events_url":"https://api.github.com/users/TsainGra/events{/privacy}","received_events_url":"https://api.github.com/users/TsainGra/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2019-08-13T07:15:13Z","updated_at":"2019-08-16T09:04:02Z","closed_at":"2019-08-16T09:03:40Z","author_association":"NONE","active_lock_reason":null,"body":"Use predefined train-test split.\r\nTransfer...\r\n/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\r\n  return f(*args, **kwds)\r\n\r\n0it [00:00, ?it/s]\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 80, in <module>\r\n    transfer(config, generator, kp_detector, opt.checkpoint, log_dir, dataset)\r\n  File \"/home/kushagra/monkey-net/transfer.py\", line 112, in transfer\r\n    out = transfer_one(generator, kp_detector, source_image, driving_video, transfer_params)\r\n  File \"/home/kushagra/monkey-net/transfer.py\", line 68, in transfer_one\r\n    kp_driving = cat_dict([kp_detector(driving_video[:, :, i:(i + 1)]) for i in range(d)], dim=1)\r\n  File \"/home/kushagra/monkey-net/transfer.py\", line 68, in <listcomp>\r\n    kp_driving = cat_dict([kp_detector(driving_video[:, :, i:(i + 1)]) for i in range(d)], dim=1)\r\n  File \"/home/kushagra/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/kushagra/.local/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 122, in forward\r\n    replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\r\n  File \"/home/kushagra/monkey-net/sync_batchnorm/replicate.py\", line 65, in replicate\r\n    modules = super(DataParallelWithCallback, self).replicate(module, device_ids)\r\n  File \"/home/kushagra/.local/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 127, in replicate\r\n    return replicate(module, device_ids)\r\n  File \"/home/kushagra/.local/lib/python3.6/site-packages/torch/nn/parallel/replicate.py\", line 12, in replicate\r\n    param_copies = Broadcast.apply(devices, *params)\r\n  File \"/home/kushagra/.local/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\", line 19, in forward\r\n    outputs = comm.broadcast_coalesced(inputs, ctx.target_gpus)\r\n  File \"/home/kushagra/.local/lib/python3.6/site-packages/torch/cuda/comm.py\", line 40, in broadcast_coalesced\r\n    return torch._C._broadcast_coalesced(tensors, devices, buffer_size)\r\nRuntimeError: all tensors must be on devices[0]\r\n\r\nI understand that I need to put all the input tensors on the 0 device. But not sure exactly how to do that, I tried some ways from\r\nhttps://discuss.pytorch.org/t/how-to-solve-the-problem-of-runtimeerror-all-tensors-must-be-on-devices-0/15198/5\r\nhowever that did not work.\r\n\r\nI also put all the models to device 1 [For eg. generator.to(opt.device_ids[1])], in the hope that it will free up space for tensors in device 0 (otherwise I would get a CUDA out of memory error).\r\n\r\nRunning the model on 2 RTX 2080 with CUDA 10","closed_by":{"login":"TsainGra","id":24549065,"node_id":"MDQ6VXNlcjI0NTQ5MDY1","avatar_url":"https://avatars.githubusercontent.com/u/24549065?v=4","gravatar_id":"","url":"https://api.github.com/users/TsainGra","html_url":"https://github.com/TsainGra","followers_url":"https://api.github.com/users/TsainGra/followers","following_url":"https://api.github.com/users/TsainGra/following{/other_user}","gists_url":"https://api.github.com/users/TsainGra/gists{/gist_id}","starred_url":"https://api.github.com/users/TsainGra/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/TsainGra/subscriptions","organizations_url":"https://api.github.com/users/TsainGra/orgs","repos_url":"https://api.github.com/users/TsainGra/repos","events_url":"https://api.github.com/users/TsainGra/events{/privacy}","received_events_url":"https://api.github.com/users/TsainGra/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/AliaksandrSiarohin/monkey-net/issues/14/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/AliaksandrSiarohin/monkey-net/issues/14/timeline","performed_via_github_app":null,"state_reason":"completed"}