{"url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/27","repository_url":"https://api.github.com/repos/Neuraxio/Neuraxle","labels_url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/27/labels{/name}","comments_url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/27/comments","events_url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/27/events","html_url":"https://github.com/Neuraxio/Neuraxle/issues/27","id":476506884,"node_id":"MDU6SXNzdWU0NzY1MDY4ODQ=","number":27,"title":"Pipeline checkpoints needs to hash data and hyperparams","user":{"login":"guillaume-chevalier","id":11862328,"node_id":"MDQ6VXNlcjExODYyMzI4","avatar_url":"https://avatars.githubusercontent.com/u/11862328?v=4","gravatar_id":"","url":"https://api.github.com/users/guillaume-chevalier","html_url":"https://github.com/guillaume-chevalier","followers_url":"https://api.github.com/users/guillaume-chevalier/followers","following_url":"https://api.github.com/users/guillaume-chevalier/following{/other_user}","gists_url":"https://api.github.com/users/guillaume-chevalier/gists{/gist_id}","starred_url":"https://api.github.com/users/guillaume-chevalier/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/guillaume-chevalier/subscriptions","organizations_url":"https://api.github.com/users/guillaume-chevalier/orgs","repos_url":"https://api.github.com/users/guillaume-chevalier/repos","events_url":"https://api.github.com/users/guillaume-chevalier/events{/privacy}","received_events_url":"https://api.github.com/users/guillaume-chevalier/received_events","type":"User","site_admin":false},"labels":[{"id":1290971222,"node_id":"MDU6TGFiZWwxMjkwOTcxMjIy","url":"https://api.github.com/repos/Neuraxio/Neuraxle/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"}],"state":"closed","locked":false,"assignee":{"login":"alexbrillant","id":19400226,"node_id":"MDQ6VXNlcjE5NDAwMjI2","avatar_url":"https://avatars.githubusercontent.com/u/19400226?v=4","gravatar_id":"","url":"https://api.github.com/users/alexbrillant","html_url":"https://github.com/alexbrillant","followers_url":"https://api.github.com/users/alexbrillant/followers","following_url":"https://api.github.com/users/alexbrillant/following{/other_user}","gists_url":"https://api.github.com/users/alexbrillant/gists{/gist_id}","starred_url":"https://api.github.com/users/alexbrillant/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexbrillant/subscriptions","organizations_url":"https://api.github.com/users/alexbrillant/orgs","repos_url":"https://api.github.com/users/alexbrillant/repos","events_url":"https://api.github.com/users/alexbrillant/events{/privacy}","received_events_url":"https://api.github.com/users/alexbrillant/received_events","type":"User","site_admin":false},"assignees":[{"login":"alexbrillant","id":19400226,"node_id":"MDQ6VXNlcjE5NDAwMjI2","avatar_url":"https://avatars.githubusercontent.com/u/19400226?v=4","gravatar_id":"","url":"https://api.github.com/users/alexbrillant","html_url":"https://github.com/alexbrillant","followers_url":"https://api.github.com/users/alexbrillant/followers","following_url":"https://api.github.com/users/alexbrillant/following{/other_user}","gists_url":"https://api.github.com/users/alexbrillant/gists{/gist_id}","starred_url":"https://api.github.com/users/alexbrillant/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexbrillant/subscriptions","organizations_url":"https://api.github.com/users/alexbrillant/orgs","repos_url":"https://api.github.com/users/alexbrillant/repos","events_url":"https://api.github.com/users/alexbrillant/events{/privacy}","received_events_url":"https://api.github.com/users/alexbrillant/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2019-08-04T02:16:47Z","updated_at":"2019-09-17T20:09:03Z","closed_at":"2019-09-17T20:09:03Z","author_association":"MEMBER","active_lock_reason":null,"body":"A pipeline can be run on many datasets and it can be re-trained with many different hyperparameters on all of those datasets. Thus, we need a way to make the difference between each checkpoint. This will allow hyperparameter tuning when the hyperparameters of the steps change, and this will allow not reusing the same checkpoints between train data and test data (and other data) if checkpoints are enabled. \r\n\r\nDynamically create subfolders of pipeline cache according to: \r\n- `data_hash`: The hash of the input data to the pipeline. We don't want to load checkpoints for new data by mistake. \r\n- `hyperparams_hash`: The hyperparameter samples of the pipeline, e.g.: `hash(p.get_hyperparams())`. \r\n\r\nThis means that for each pipeline, the subfolders tree could look like that for example: \r\n```\r\n./cache\r\n    {data_hash}/\r\n        step_a_{hyperparams_hash for step_a}.pickle\r\n        step_b_{hyperparams_hash for step_b}.pickle\r\n        step_b_{another hyperparams_hash for step_b}.pickle\r\n        subpipeline_c_{hyperparams_hash for subpipeline_c}/\r\n            step_d_{hyperparams_hash for step_d}.pickle\r\n            step_e_{hyperparams_hash for step_e}.pickle\r\n            step_f_{hyperparams_hash for step_f}.pickle\r\n        subpipeline_c_{another hyperparams_hash for subpipeline_c}/\r\n            step_d_{hyperparams_hash for step_d}.pickle\r\n            step_e_{hyperparams_hash for step_e}.pickle\r\n            step_f_{hyperparams_hash for step_f}.pickle\r\n        subpipeline_c_{also another hyperparams_hash for subpipeline_c}/\r\n            step_d_{hyperparams_hash for step_d}.pickle\r\n            step_e_{hyperparams_hash for step_e}.pickle\r\n            step_f_{hyperparams_hash for step_f}.pickle\r\n    {data_hash for another dataset}/\r\n        step_a_{hyperparams_hash for step_a}.pickle\r\n        step_b_{hyperparams_hash for step_b}.pickle\r\n        step_b_{another hyperparams_hash for step_b}.pickle\r\n        ...\r\n    {data_hash for still another dataset}/\r\n        step_a_{hyperparams_hash for step_a}.pickle\r\n        step_b_{hyperparams_hash for step_b}.pickle\r\n        step_b_{another hyperparams_hash for step_b}.pickle\r\n        ...\r\n```\r\n\r\nInteresting facts and discussion points, assuming each step or most step is checkpointed : \r\n- Sometimes, the hyperparameters of a few pipeline steps will be the same, and only the final pipeline step will change. This means it's possible to reuse the same checkpoints for each first steps given a dataset, and only the last step will need two different checkpoints. \r\n- If a pipeline step has hyperparameter that changes, but that is executed on the same data, the checkpoint name (suffix past a final underscore delimiter \"__\") will be different. (or if hash is fast to compute, check if the new checkpoint is the same than the old one, and if so it's possible to avoid re-writing to disks?)\r\n- Hashing huge numpy arrays can be a lengthy process, so perhaps we could add hashers such as just taking the shape of the input array to hash it when the input is an np array, and so forth.\r\n- The hasher could be sent as an argument of the PipelineRunner or Pipeline, and could be deactivated by sending a hasher that always returns the same value such that every checkpoint just always trigger (?). In fact, there should also be a way to deactivate checkpoints completely (e.g.: for sending models in production). \r\n- For AutoML, we need to reuse the same checkpoints if the hyperparameters of the previous steps AND the current step are unchanged (hashes needs to take ranges of steps before the checkpoint, not just the hyperparams of the checkpoint itself). ","closed_by":{"login":"alexbrillant","id":19400226,"node_id":"MDQ6VXNlcjE5NDAwMjI2","avatar_url":"https://avatars.githubusercontent.com/u/19400226?v=4","gravatar_id":"","url":"https://api.github.com/users/alexbrillant","html_url":"https://github.com/alexbrillant","followers_url":"https://api.github.com/users/alexbrillant/followers","following_url":"https://api.github.com/users/alexbrillant/following{/other_user}","gists_url":"https://api.github.com/users/alexbrillant/gists{/gist_id}","starred_url":"https://api.github.com/users/alexbrillant/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexbrillant/subscriptions","organizations_url":"https://api.github.com/users/alexbrillant/orgs","repos_url":"https://api.github.com/users/alexbrillant/repos","events_url":"https://api.github.com/users/alexbrillant/events{/privacy}","received_events_url":"https://api.github.com/users/alexbrillant/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/27/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/27/timeline","performed_via_github_app":null,"state_reason":"completed"}