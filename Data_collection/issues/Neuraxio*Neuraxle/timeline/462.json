[{"id":4515397665,"node_id":"MDEyOkxhYmVsZWRFdmVudDQ1MTUzOTc2NjU=","url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/events/4515397665","actor":{"login":"brucelightyear","id":2175223,"node_id":"MDQ6VXNlcjIxNzUyMjM=","avatar_url":"https://avatars.githubusercontent.com/u/2175223?v=4","gravatar_id":"","url":"https://api.github.com/users/brucelightyear","html_url":"https://github.com/brucelightyear","followers_url":"https://api.github.com/users/brucelightyear/followers","following_url":"https://api.github.com/users/brucelightyear/following{/other_user}","gists_url":"https://api.github.com/users/brucelightyear/gists{/gist_id}","starred_url":"https://api.github.com/users/brucelightyear/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/brucelightyear/subscriptions","organizations_url":"https://api.github.com/users/brucelightyear/orgs","repos_url":"https://api.github.com/users/brucelightyear/repos","events_url":"https://api.github.com/users/brucelightyear/events{/privacy}","received_events_url":"https://api.github.com/users/brucelightyear/received_events","type":"User","site_admin":false},"event":"labeled","commit_id":null,"commit_url":null,"created_at":"2021-03-26T18:12:02Z","label":{"name":"bug","color":"d73a4a"},"performed_via_github_app":null},{"id":4515397667,"node_id":"MDEyOkxhYmVsZWRFdmVudDQ1MTUzOTc2Njc=","url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/events/4515397667","actor":{"login":"brucelightyear","id":2175223,"node_id":"MDQ6VXNlcjIxNzUyMjM=","avatar_url":"https://avatars.githubusercontent.com/u/2175223?v=4","gravatar_id":"","url":"https://api.github.com/users/brucelightyear","html_url":"https://github.com/brucelightyear","followers_url":"https://api.github.com/users/brucelightyear/followers","following_url":"https://api.github.com/users/brucelightyear/following{/other_user}","gists_url":"https://api.github.com/users/brucelightyear/gists{/gist_id}","starred_url":"https://api.github.com/users/brucelightyear/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/brucelightyear/subscriptions","organizations_url":"https://api.github.com/users/brucelightyear/orgs","repos_url":"https://api.github.com/users/brucelightyear/repos","events_url":"https://api.github.com/users/brucelightyear/events{/privacy}","received_events_url":"https://api.github.com/users/brucelightyear/received_events","type":"User","site_admin":false},"event":"labeled","commit_id":null,"commit_url":null,"created_at":"2021-03-26T18:12:02Z","label":{"name":"invalid","color":"e4e669"},"performed_via_github_app":null},{"id":4515400758,"node_id":"MDE3OlJlbmFtZWRUaXRsZUV2ZW50NDUxNTQwMDc1OA==","url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/events/4515400758","actor":{"login":"brucelightyear","id":2175223,"node_id":"MDQ6VXNlcjIxNzUyMjM=","avatar_url":"https://avatars.githubusercontent.com/u/2175223?v=4","gravatar_id":"","url":"https://api.github.com/users/brucelightyear","html_url":"https://github.com/brucelightyear","followers_url":"https://api.github.com/users/brucelightyear/followers","following_url":"https://api.github.com/users/brucelightyear/following{/other_user}","gists_url":"https://api.github.com/users/brucelightyear/gists{/gist_id}","starred_url":"https://api.github.com/users/brucelightyear/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/brucelightyear/subscriptions","organizations_url":"https://api.github.com/users/brucelightyear/orgs","repos_url":"https://api.github.com/users/brucelightyear/repos","events_url":"https://api.github.com/users/brucelightyear/events{/privacy}","received_events_url":"https://api.github.com/users/brucelightyear/received_events","type":"User","site_admin":false},"event":"renamed","commit_id":null,"commit_url":null,"created_at":"2021-03-26T18:12:49Z","rename":{"from":"Bug: FileNotFoundError while long path in Windows10","to":"Bug: FileNotFoundError with long folder path in Windows10"},"performed_via_github_app":null},{"url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/comments/808507529","html_url":"https://github.com/Neuraxio/Neuraxle/issues/462#issuecomment-808507529","issue_url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/462","id":808507529,"node_id":"MDEyOklzc3VlQ29tbWVudDgwODUwNzUyOQ==","user":{"login":"guillaume-chevalier","id":11862328,"node_id":"MDQ6VXNlcjExODYyMzI4","avatar_url":"https://avatars.githubusercontent.com/u/11862328?v=4","gravatar_id":"","url":"https://api.github.com/users/guillaume-chevalier","html_url":"https://github.com/guillaume-chevalier","followers_url":"https://api.github.com/users/guillaume-chevalier/followers","following_url":"https://api.github.com/users/guillaume-chevalier/following{/other_user}","gists_url":"https://api.github.com/users/guillaume-chevalier/gists{/gist_id}","starred_url":"https://api.github.com/users/guillaume-chevalier/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/guillaume-chevalier/subscriptions","organizations_url":"https://api.github.com/users/guillaume-chevalier/orgs","repos_url":"https://api.github.com/users/guillaume-chevalier/repos","events_url":"https://api.github.com/users/guillaume-chevalier/events{/privacy}","received_events_url":"https://api.github.com/users/guillaume-chevalier/received_events","type":"User","site_admin":false},"created_at":"2021-03-26T21:04:55Z","updated_at":"2021-03-26T21:04:55Z","author_association":"MEMBER","body":"@brucelightyear we have never tested the framework on Windows. We expect the integration in windows to take some time and effort as we've never tried it. Right now the framework may have unexpected behavior on a Windows system regarding disk writes. Thanks for logging the issue! ","reactions":{"url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/comments/808507529/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"guillaume-chevalier","id":11862328,"node_id":"MDQ6VXNlcjExODYyMzI4","avatar_url":"https://avatars.githubusercontent.com/u/11862328?v=4","gravatar_id":"","url":"https://api.github.com/users/guillaume-chevalier","html_url":"https://github.com/guillaume-chevalier","followers_url":"https://api.github.com/users/guillaume-chevalier/followers","following_url":"https://api.github.com/users/guillaume-chevalier/following{/other_user}","gists_url":"https://api.github.com/users/guillaume-chevalier/gists{/gist_id}","starred_url":"https://api.github.com/users/guillaume-chevalier/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/guillaume-chevalier/subscriptions","organizations_url":"https://api.github.com/users/guillaume-chevalier/orgs","repos_url":"https://api.github.com/users/guillaume-chevalier/repos","events_url":"https://api.github.com/users/guillaume-chevalier/events{/privacy}","received_events_url":"https://api.github.com/users/guillaume-chevalier/received_events","type":"User","site_admin":false}},{"id":4516006646,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50NDUxNjAwNjY0Ng==","url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/events/4516006646","actor":{"login":"brucelightyear","id":2175223,"node_id":"MDQ6VXNlcjIxNzUyMjM=","avatar_url":"https://avatars.githubusercontent.com/u/2175223?v=4","gravatar_id":"","url":"https://api.github.com/users/brucelightyear","html_url":"https://github.com/brucelightyear","followers_url":"https://api.github.com/users/brucelightyear/followers","following_url":"https://api.github.com/users/brucelightyear/following{/other_user}","gists_url":"https://api.github.com/users/brucelightyear/gists{/gist_id}","starred_url":"https://api.github.com/users/brucelightyear/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/brucelightyear/subscriptions","organizations_url":"https://api.github.com/users/brucelightyear/orgs","repos_url":"https://api.github.com/users/brucelightyear/repos","events_url":"https://api.github.com/users/brucelightyear/events{/privacy}","received_events_url":"https://api.github.com/users/brucelightyear/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2021-03-26T21:04:55Z","performed_via_github_app":null},{"id":4516006649,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDQ1MTYwMDY2NDk=","url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/events/4516006649","actor":{"login":"brucelightyear","id":2175223,"node_id":"MDQ6VXNlcjIxNzUyMjM=","avatar_url":"https://avatars.githubusercontent.com/u/2175223?v=4","gravatar_id":"","url":"https://api.github.com/users/brucelightyear","html_url":"https://github.com/brucelightyear","followers_url":"https://api.github.com/users/brucelightyear/followers","following_url":"https://api.github.com/users/brucelightyear/following{/other_user}","gists_url":"https://api.github.com/users/brucelightyear/gists{/gist_id}","starred_url":"https://api.github.com/users/brucelightyear/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/brucelightyear/subscriptions","organizations_url":"https://api.github.com/users/brucelightyear/orgs","repos_url":"https://api.github.com/users/brucelightyear/repos","events_url":"https://api.github.com/users/brucelightyear/events{/privacy}","received_events_url":"https://api.github.com/users/brucelightyear/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2021-03-26T21:04:55Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/comments/943930982","html_url":"https://github.com/Neuraxio/Neuraxle/issues/462#issuecomment-943930982","issue_url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/462","id":943930982,"node_id":"IC_kwDOCpoNY844Qz5m","user":{"login":"guillaume-chevalier","id":11862328,"node_id":"MDQ6VXNlcjExODYyMzI4","avatar_url":"https://avatars.githubusercontent.com/u/11862328?v=4","gravatar_id":"","url":"https://api.github.com/users/guillaume-chevalier","html_url":"https://github.com/guillaume-chevalier","followers_url":"https://api.github.com/users/guillaume-chevalier/followers","following_url":"https://api.github.com/users/guillaume-chevalier/following{/other_user}","gists_url":"https://api.github.com/users/guillaume-chevalier/gists{/gist_id}","starred_url":"https://api.github.com/users/guillaume-chevalier/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/guillaume-chevalier/subscriptions","organizations_url":"https://api.github.com/users/guillaume-chevalier/orgs","repos_url":"https://api.github.com/users/guillaume-chevalier/repos","events_url":"https://api.github.com/users/guillaume-chevalier/events{/privacy}","received_events_url":"https://api.github.com/users/guillaume-chevalier/received_events","type":"User","site_admin":false},"created_at":"2021-10-15T02:19:39Z","updated_at":"2021-10-15T02:19:39Z","author_association":"MEMBER","body":"Full quick tests dump for windows: \r\n\r\n```\r\nC:\\Users\\Guillaume\\neuraxle\\Neuraxle>pytest testing/ --ignore=testing/metaopt/test_tpe.py --ignore=testing/examples/test_examples.py\r\n=============================================== test session starts ================================================\r\nplatform win32 -- Python 3.9.7, pytest-4.3.1, py-1.10.0, pluggy-1.0.0\r\nrootdir: C:\\Users\\Guillaume\\neuraxle\\Neuraxle, inifile:\r\nplugins: cov-2.6.1\r\ncollected 492 items\r\n\r\ntesting\\test_apply.py ........                                                                                [  1%]\r\ntesting\\test_basestep.py ......                                                                               [  2%]\r\ntesting\\test_checkpoints.py ...........                                                                       [  5%]\r\ntesting\\test_context_logger.py F.E                                                                            [  5%]\r\ntesting\\test_data_container.py .....                                                                          [  6%]\r\ntesting\\test_data_container_batching.py ....                                                                  [  7%]\r\ntesting\\test_forcehandle_mixin.py ..                                                                          [  7%]\r\ntesting\\test_full_pipeline_dump.py ..                                                                         [  8%]\r\ntesting\\test_hashlib_md5_value_hashing.py ....                                                                [  8%]\r\ntesting\\test_joblib_checkpoint_step.py ......                                                                 [ 10%]\r\ntesting\\test_metastep_mixin.py ...                                                                            [ 10%]\r\ntesting\\test_minibatch_sequential_pipeline.py ...                                                             [ 11%]\r\ntesting\\test_optional.py ..                                                                                   [ 11%]\r\ntesting\\test_output_transformer_wrapper.py .........                                                          [ 13%]\r\ntesting\\test_pipeline.py ....................                                                                 [ 17%]\r\ntesting\\test_pipeline_hashing.py ...........................                                                  [ 23%]\r\ntesting\\test_pipeline_setup_teardown.py ...                                                                   [ 23%]\r\ntesting\\test_recursive_arguments.py ...                                                                       [ 24%]\r\ntesting\\test_recursive_dict.py .............                                                                  [ 27%]\r\ntesting\\test_resumable_pipeline.py .................................                                          [ 33%]\r\ntesting\\test_service_assertions.py .........                                                                  [ 35%]\r\ntesting\\test_step_saving.py ......                                                                            [ 36%]\r\ntesting\\test_streaming.py ............................                                                        [ 42%]\r\ntesting\\test_truncable_steps.py .....                                                                         [ 43%]\r\ntesting\\test_union.py .........                                                                               [ 45%]\r\ntesting\\test_zip_data_container.py ....                                                                       [ 46%]\r\ntesting\\api\\test_flask.py .                                                                                   [ 46%]\r\ntesting\\hyperparams\\test_distributions.py ........................                                            [ 51%]\r\ntesting\\hyperparams\\test_get_set_hyperparams.py ........................                                      [ 56%]\r\ntesting\\hyperparams\\test_scipy_distributions.py ..........FFFFFFFF.....                                       [ 60%]\r\ntesting\\hyperparams\\test_space.py .......                                                                     [ 62%]\r\ntesting\\metaopt\\test_automl.py .s......                                                                       [ 63%]\r\ntesting\\metaopt\\test_automl_sequential_wrapper.py ..                                                          [ 64%]\r\ntesting\\metaopt\\test_hyperparams_repository.py ....                                                           [ 65%]\r\ntesting\\metaopt\\test_observable_hyperparams_repository.py ...                                                 [ 65%]\r\ntesting\\metaopt\\test_random.py ............                                                                   [ 68%]\r\ntesting\\metaopt\\test_trial.py F...........                                                                    [ 70%]\r\ntesting\\metaopt\\test_validation_split_wrapper.py s.                                                           [ 70%]\r\ntesting\\steps\\test_assertion_steps.py ..                                                                      [ 71%]\r\ntesting\\steps\\test_choose_one_or_many_steps_of.py .............                                               [ 73%]\r\ntesting\\steps\\test_column_selector_2d.py ...........                                                          [ 76%]\r\ntesting\\steps\\test_column_transformer.py .............................................                        [ 85%]\r\ntesting\\steps\\test_concatenate_data_container.py .....                                                        [ 86%]\r\ntesting\\steps\\test_data_shuffling.py .                                                                        [ 86%]\r\ntesting\\steps\\test_epochs_repeater.py ....                                                                    [ 87%]\r\ntesting\\steps\\test_expand_dim.py ...                                                                          [ 88%]\r\ntesting\\steps\\test_features.py .......                                                                        [ 89%]\r\ntesting\\steps\\test_flatten_for_each.py ..                                                                     [ 89%]\r\ntesting\\steps\\test_for_each.py ...                                                                            [ 90%]\r\ntesting\\steps\\test_if_execution_phase_is_then_do.py ....                                                      [ 91%]\r\ntesting\\steps\\test_numpy_steps.py ....                                                                        [ 92%]\r\ntesting\\steps\\test_one_hot.py ...                                                                             [ 92%]\r\ntesting\\steps\\test_output_transformer_wrapper.py .                                                            [ 92%]\r\ntesting\\steps\\test_reversible_preprocessing_wrapper.py ...                                                    [ 93%]\r\ntesting\\steps\\test_sklearn_wrapper.py ..........                                                              [ 95%]\r\ntesting\\steps\\test_step_cloner_for_each_data_input.py ......                                                  [ 96%]\r\ntesting\\steps\\test_train_only_wrapper.py .............                                                        [ 99%]\r\ntesting\\steps\\test_value_caching_wrapper.py ...                                                               [100%]\r\n\r\n====================================================== ERRORS ======================================================\r\n_____________________________ ERROR at teardown of TestTrialLogger.test_logger_automl ______________________________\r\n\r\nself = <testing.test_context_logger.TestTrialLogger object at 0x000001868F6302B0>\r\n\r\n    def teardown(self):\r\n>       shutil.rmtree(self.tmpdir)\r\n\r\ntesting\\test_context_logger.py:123:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\nC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.2032.0_x64__qbz5n2kfra8p0\\lib\\shutil.py:748: in rmtree\r\n    return _rmtree_unsafe(path, onerror)\r\nC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.2032.0_x64__qbz5n2kfra8p0\\lib\\shutil.py:626: in _rmtree_unsafe\r\n    onerror(os.unlink, fullname, sys.exc_info())\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\npath = 'C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_logger_automl0'\r\nonerror = <function rmtree.<locals>.onerror at 0x000001868E7383A0>\r\n\r\n    def _rmtree_unsafe(path, onerror):\r\n        try:\r\n            with os.scandir(path) as scandir_it:\r\n                entries = list(scandir_it)\r\n        except OSError:\r\n            onerror(os.scandir, path, sys.exc_info())\r\n            entries = []\r\n        for entry in entries:\r\n            fullname = entry.path\r\n            if _rmtree_isdir(entry):\r\n                try:\r\n                    if entry.is_symlink():\r\n                        # This can only happen if someone replaces\r\n                        # a directory with a symlink after the call to\r\n                        # os.scandir or entry.is_dir above.\r\n                        raise OSError(\"Cannot call rmtree on a symbolic link\")\r\n                except OSError:\r\n                    onerror(os.path.islink, fullname, sys.exc_info())\r\n                    continue\r\n                _rmtree_unsafe(fullname, onerror)\r\n            else:\r\n                try:\r\n>                   os.unlink(fullname)\r\nE                   PermissionError: [WinError 32] Le processus ne peut pas accéder au fichier car ce fichier est utilisé par un autre processus: 'C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_logger_automl0\\\\trial_0.log'\r\n\r\nC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.2032.0_x64__qbz5n2kfra8p0\\lib\\shutil.py:624: PermissionError\r\n----------------------------------------------- Captured stderr call -----------------------------------------------\r\n[22:10:26][INFO][auto_ml][168]:\r\nnew trial: {\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    }\r\n}\r\n[22:10:26][INFO][auto_ml][865]: trial 1/4\r\n[22:10:26][INFO][auto_ml][583]: fitting trial 1/4 split 1/1\r\nhyperparams: {\r\n    \"LoggingStep\": {},\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    },\r\n    \"NumpyReshape\": {}\r\n}\r\n[22:10:26][INFO][auto_ml][624]: epoch 1/2\r\n[22:10:26][WARNING][test_context_logger][37]: fit call - logging call # 0\r\n[22:10:26][WARNING][test_context_logger][37]: transform call - logging call # 1\r\n[22:10:26][WARNING][test_context_logger][37]: transform call - logging call # 2\r\n[22:10:26][INFO][trial][450]: main train: 47.5\r\n[22:10:26][INFO][trial][471]: main validation: 295.0\r\n[22:10:26][INFO][auto_ml][624]: epoch 2/2\r\n[22:10:26][WARNING][test_context_logger][37]: fit call - logging call # 3\r\n[22:10:26][WARNING][test_context_logger][37]: transform call - logging call # 4\r\n[22:10:26][WARNING][test_context_logger][37]: transform call - logging call # 5\r\n[22:10:26][INFO][trial][450]: main train: 47.5\r\n[22:10:26][INFO][trial][471]: main validation: 295.0\r\n[22:10:27][INFO][auto_ml][596]: success trial 1/4 split 1/1\r\nhyperparams: {\r\n    \"LoggingStep\": {},\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    },\r\n    \"NumpyReshape\": {}\r\n}\r\nbest score: 295.0 at epoch 0\r\n[22:10:27][INFO][auto_ml][168]:\r\nnew trial: {\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    }\r\n}\r\n[22:10:27][INFO][auto_ml][865]: trial 2/4\r\n[22:10:27][INFO][auto_ml][583]: fitting trial 2/4 split 1/1\r\nhyperparams: {\r\n    \"LoggingStep\": {},\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    },\r\n    \"NumpyReshape\": {}\r\n}\r\n[22:10:27][INFO][auto_ml][624]: epoch 1/2\r\n[22:10:27][WARNING][test_context_logger][37]: fit call - logging call # 0\r\n[22:10:27][WARNING][test_context_logger][37]: transform call - logging call # 1\r\n[22:10:27][WARNING][test_context_logger][37]: transform call - logging call # 2\r\n[22:10:27][INFO][trial][450]: main train: 47.5\r\n[22:10:27][INFO][trial][471]: main validation: 295.0\r\n[22:10:27][INFO][auto_ml][624]: epoch 2/2\r\n[22:10:27][WARNING][test_context_logger][37]: fit call - logging call # 3\r\n[22:10:27][WARNING][test_context_logger][37]: transform call - logging call # 4\r\n[22:10:27][WARNING][test_context_logger][37]: transform call - logging call # 5\r\n[22:10:27][INFO][trial][450]: main train: 47.5\r\n[22:10:27][INFO][trial][471]: main validation: 295.0\r\n[22:10:28][INFO][auto_ml][596]: success trial 2/4 split 1/1\r\nhyperparams: {\r\n    \"LoggingStep\": {},\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    },\r\n    \"NumpyReshape\": {}\r\n}\r\nbest score: 295.0 at epoch 0\r\n[22:10:28][INFO][auto_ml][168]:\r\nnew trial: {\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    }\r\n}\r\n[22:10:28][INFO][auto_ml][865]: trial 3/4\r\n[22:10:28][INFO][auto_ml][583]: fitting trial 3/4 split 1/1\r\nhyperparams: {\r\n    \"LoggingStep\": {},\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    },\r\n    \"NumpyReshape\": {}\r\n}\r\n[22:10:28][INFO][auto_ml][624]: epoch 1/2\r\n[22:10:28][WARNING][test_context_logger][37]: fit call - logging call # 0\r\n[22:10:28][WARNING][test_context_logger][37]: transform call - logging call # 1\r\n[22:10:28][WARNING][test_context_logger][37]: transform call - logging call # 2\r\n[22:10:28][INFO][trial][450]: main train: 47.5\r\n[22:10:28][INFO][trial][471]: main validation: 295.0\r\n[22:10:29][INFO][auto_ml][624]: epoch 2/2\r\n[22:10:29][WARNING][test_context_logger][37]: fit call - logging call # 3\r\n[22:10:29][WARNING][test_context_logger][37]: transform call - logging call # 4\r\n[22:10:29][WARNING][test_context_logger][37]: transform call - logging call # 5\r\n[22:10:29][INFO][trial][450]: main train: 47.5\r\n[22:10:29][INFO][trial][471]: main validation: 295.0\r\n[22:10:29][INFO][auto_ml][596]: success trial 3/4 split 1/1\r\nhyperparams: {\r\n    \"LoggingStep\": {},\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    },\r\n    \"NumpyReshape\": {}\r\n}\r\nbest score: 295.0 at epoch 0\r\n[22:10:29][INFO][auto_ml][168]:\r\nnew trial: {\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    }\r\n}\r\n[22:10:29][INFO][auto_ml][865]: trial 4/4\r\n[22:10:29][INFO][auto_ml][583]: fitting trial 4/4 split 1/1\r\nhyperparams: {\r\n    \"LoggingStep\": {},\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    },\r\n    \"NumpyReshape\": {}\r\n}\r\n[22:10:29][INFO][auto_ml][624]: epoch 1/2\r\n[22:10:29][WARNING][test_context_logger][37]: fit call - logging call # 0\r\n[22:10:29][WARNING][test_context_logger][37]: transform call - logging call # 1\r\n[22:10:30][WARNING][test_context_logger][37]: transform call - logging call # 2\r\n[22:10:30][INFO][trial][450]: main train: 47.5\r\n[22:10:30][INFO][trial][471]: main validation: 295.0\r\n[22:10:30][INFO][auto_ml][624]: epoch 2/2\r\n[22:10:30][WARNING][test_context_logger][37]: fit call - logging call # 3\r\n[22:10:30][WARNING][test_context_logger][37]: transform call - logging call # 4\r\n[22:10:30][WARNING][test_context_logger][37]: transform call - logging call # 5\r\n[22:10:30][INFO][trial][450]: main train: 47.5\r\n[22:10:30][INFO][trial][471]: main validation: 295.0\r\n[22:10:30][INFO][auto_ml][596]: success trial 4/4 split 1/1\r\nhyperparams: {\r\n    \"LoggingStep\": {},\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    },\r\n    \"NumpyReshape\": {}\r\n}\r\nbest score: 295.0 at epoch 0\r\n[22:10:30][INFO][auto_ml][834]:\r\nbest hyperparams: {\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    }\r\n}\r\n[22:10:30][WARNING][test_context_logger][37]: fit call - logging call # 0\r\n[22:10:30][WARNING][test_context_logger][37]: fit call - logging call # 1\r\n------------------------------------------------ Captured log call -------------------------------------------------\r\nauto_ml.py                 168 INFO\r\nnew trial: {\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    }\r\n}\r\nauto_ml.py                 865 INFO     trial 1/4\r\nauto_ml.py                 583 INFO     fitting trial 1/4 split 1/1\r\nhyperparams: {\r\n    \"LoggingStep\": {},\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    },\r\n    \"NumpyReshape\": {}\r\n}\r\nauto_ml.py                 624 INFO     epoch 1/2\r\ntest_context_logger.py      37 WARNING  fit call - logging call # 0\r\ntest_context_logger.py      37 WARNING  transform call - logging call # 1\r\ntest_context_logger.py      37 WARNING  transform call - logging call # 2\r\ntrial.py                   450 INFO     main train: 47.5\r\ntrial.py                   471 INFO     main validation: 295.0\r\nauto_ml.py                 624 INFO     epoch 2/2\r\ntest_context_logger.py      37 WARNING  fit call - logging call # 3\r\ntest_context_logger.py      37 WARNING  transform call - logging call # 4\r\ntest_context_logger.py      37 WARNING  transform call - logging call # 5\r\ntrial.py                   450 INFO     main train: 47.5\r\ntrial.py                   471 INFO     main validation: 295.0\r\nauto_ml.py                 596 INFO     success trial 1/4 split 1/1\r\nhyperparams: {\r\n    \"LoggingStep\": {},\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    },\r\n    \"NumpyReshape\": {}\r\n}\r\nbest score: 295.0 at epoch 0\r\nauto_ml.py                 168 INFO\r\nnew trial: {\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    }\r\n}\r\nauto_ml.py                 865 INFO     trial 2/4\r\nauto_ml.py                 583 INFO     fitting trial 2/4 split 1/1\r\nhyperparams: {\r\n    \"LoggingStep\": {},\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    },\r\n    \"NumpyReshape\": {}\r\n}\r\nauto_ml.py                 624 INFO     epoch 1/2\r\ntest_context_logger.py      37 WARNING  fit call - logging call # 0\r\ntest_context_logger.py      37 WARNING  transform call - logging call # 1\r\ntest_context_logger.py      37 WARNING  transform call - logging call # 2\r\ntrial.py                   450 INFO     main train: 47.5\r\ntrial.py                   471 INFO     main validation: 295.0\r\nauto_ml.py                 624 INFO     epoch 2/2\r\ntest_context_logger.py      37 WARNING  fit call - logging call # 3\r\ntest_context_logger.py      37 WARNING  transform call - logging call # 4\r\ntest_context_logger.py      37 WARNING  transform call - logging call # 5\r\ntrial.py                   450 INFO     main train: 47.5\r\ntrial.py                   471 INFO     main validation: 295.0\r\nauto_ml.py                 596 INFO     success trial 2/4 split 1/1\r\nhyperparams: {\r\n    \"LoggingStep\": {},\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    },\r\n    \"NumpyReshape\": {}\r\n}\r\nbest score: 295.0 at epoch 0\r\nauto_ml.py                 168 INFO\r\nnew trial: {\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    }\r\n}\r\nauto_ml.py                 865 INFO     trial 3/4\r\nauto_ml.py                 583 INFO     fitting trial 3/4 split 1/1\r\nhyperparams: {\r\n    \"LoggingStep\": {},\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    },\r\n    \"NumpyReshape\": {}\r\n}\r\nauto_ml.py                 624 INFO     epoch 1/2\r\ntest_context_logger.py      37 WARNING  fit call - logging call # 0\r\ntest_context_logger.py      37 WARNING  transform call - logging call # 1\r\ntest_context_logger.py      37 WARNING  transform call - logging call # 2\r\ntrial.py                   450 INFO     main train: 47.5\r\ntrial.py                   471 INFO     main validation: 295.0\r\nauto_ml.py                 624 INFO     epoch 2/2\r\ntest_context_logger.py      37 WARNING  fit call - logging call # 3\r\ntest_context_logger.py      37 WARNING  transform call - logging call # 4\r\ntest_context_logger.py      37 WARNING  transform call - logging call # 5\r\ntrial.py                   450 INFO     main train: 47.5\r\ntrial.py                   471 INFO     main validation: 295.0\r\nauto_ml.py                 596 INFO     success trial 3/4 split 1/1\r\nhyperparams: {\r\n    \"LoggingStep\": {},\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    },\r\n    \"NumpyReshape\": {}\r\n}\r\nbest score: 295.0 at epoch 0\r\nauto_ml.py                 168 INFO\r\nnew trial: {\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    }\r\n}\r\nauto_ml.py                 865 INFO     trial 4/4\r\nauto_ml.py                 583 INFO     fitting trial 4/4 split 1/1\r\nhyperparams: {\r\n    \"LoggingStep\": {},\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    },\r\n    \"NumpyReshape\": {}\r\n}\r\nauto_ml.py                 624 INFO     epoch 1/2\r\ntest_context_logger.py      37 WARNING  fit call - logging call # 0\r\ntest_context_logger.py      37 WARNING  transform call - logging call # 1\r\ntest_context_logger.py      37 WARNING  transform call - logging call # 2\r\ntrial.py                   450 INFO     main train: 47.5\r\ntrial.py                   471 INFO     main validation: 295.0\r\nauto_ml.py                 624 INFO     epoch 2/2\r\ntest_context_logger.py      37 WARNING  fit call - logging call # 3\r\ntest_context_logger.py      37 WARNING  transform call - logging call # 4\r\ntest_context_logger.py      37 WARNING  transform call - logging call # 5\r\ntrial.py                   450 INFO     main train: 47.5\r\ntrial.py                   471 INFO     main validation: 295.0\r\nauto_ml.py                 596 INFO     success trial 4/4 split 1/1\r\nhyperparams: {\r\n    \"LoggingStep\": {},\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    },\r\n    \"NumpyReshape\": {}\r\n}\r\nbest score: 295.0 at epoch 0\r\nauto_ml.py                 834 INFO\r\nbest hyperparams: {\r\n    \"MultiplyByN\": {\r\n        \"multiply_by\": 2\r\n    }\r\n}\r\ntest_context_logger.py      37 WARNING  fit call - logging call # 0\r\ntest_context_logger.py      37 WARNING  fit call - logging call # 1\r\n===================================================== FAILURES =====================================================\r\n___________________________________________________ test_logger ____________________________________________________\r\n\r\n    def test_logger():\r\n        file_path = \"test.log\"\r\n\r\n        if os.path.exists(file_path):\r\n            os.remove(file_path)\r\n\r\n        # Given\r\n        logger = logging.getLogger('test')\r\n        file_handler = logging.FileHandler(file_path)\r\n        file_handler.setLevel('DEBUG')\r\n        logger.addHandler(file_handler)\r\n        logger.setLevel('DEBUG')\r\n        context = ExecutionContext(logger=logger)\r\n        pipeline = Pipeline([\r\n            MultiplyByN(2).set_hyperparams_space(HyperparameterSpace({\r\n                'multiply_by': FixedHyperparameter(2)\r\n            })),\r\n            NumpyReshape(new_shape=(-1, 1)),\r\n            LoggingStep()\r\n        ])\r\n\r\n        # When\r\n        data_container = DataContainer(\r\n            data_inputs=np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\r\n        )\r\n        pipeline.handle_fit(data_container, context)\r\n\r\n        # Then\r\n        assert os.path.exists(file_path)\r\n        with open(file_path) as f:\r\n            l = f.read()\r\n\r\n        # Teardown\r\n>       os.remove(file_path)\r\nE       PermissionError: [WinError 32] Le processus ne peut pas accéder au fichier car ce fichier est utilisé par un autre processus: 'test.log'\r\n\r\ntesting\\test_context_logger.py:74: PermissionError\r\n----------------------------------------------- Captured stderr call -----------------------------------------------\r\n[22:10:25][WARNING][test_context_logger][37]: fit call - logging call # 0\r\n------------------------------------------------ Captured log call -------------------------------------------------\r\ntest_context_logger.py      37 WARNING  fit call - logging call # 0\r\n___________________________________ test_after_serialization[hd0-_test_randint] ____________________________________\r\n\r\nhd = <neuraxle.hyperparams.scipy_distributions.RandInt object at 0x000001868F447EE0>\r\ntest_method = <function _test_randint at 0x000001868EFE3670>\r\ntmpdir = local('C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd0__0')\r\n\r\n    @pytest.mark.parametrize(\"hd, test_method\", [\r\n        (RandInt(min_included=-10, max_included=10, null_default_value=0), _test_randint),\r\n        (LogNormal(hard_clip_min=-5, hard_clip_max=5, log2_space_mean=0.0, log2_space_std=2.0, null_default_value=-1.0), _test_lognormal),\r\n        (Normal(hard_clip_min=0.0, hard_clip_max=1.0, mean=0.5, std=0.2, null_default_value=0.0), _test_normal),\r\n        (LogUniform(min_included=0.001, max_included=10), _test_loguniform),\r\n        (Uniform(min_included=-10, max_included=10), _test_uniform),\r\n        (Poisson(min_included=0.0, max_included=10.0, null_default_value=0.0, mu=5.0), _test_discrete_poisson),\r\n        (Gaussian(min_included=0, max_included=10, null_default_value=0.0), _test_gaussian),\r\n        (Histogram(histogram=np.histogram(norm.rvs(size=10000, loc=0, scale=1.5, random_state=123), bins=100), null_default_value=0.0), _test_histogram)\r\n    ])\r\n    def test_after_serialization(hd, test_method, tmpdir):\r\n>       joblib.dump(hd, os.path.join(str(tmpdir), '{}.joblib'.format(hd.__class__)))\r\n\r\ntesting\\hyperparams\\test_scipy_distributions.py:286:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nvalue = <neuraxle.hyperparams.scipy_distributions.RandInt object at 0x000001868F447EE0>\r\nfilename = \"C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd0__0\\\\<class 'neuraxle.hyperparams.scipy_distributions.RandInt'>.joblib\"\r\ncompress = 0, protocol = None, cache_size = None\r\n\r\n    def dump(value, filename, compress=0, protocol=None, cache_size=None):\r\n        \"\"\"Persist an arbitrary Python object into one file.\r\n\r\n        Read more in the :ref:`User Guide <persistence>`.\r\n\r\n        Parameters\r\n        -----------\r\n        value: any Python object\r\n            The object to store to disk.\r\n        filename: str, pathlib.Path, or file object.\r\n            The file object or path of the file in which it is to be stored.\r\n            The compression method corresponding to one of the supported filename\r\n            extensions ('.z', '.gz', '.bz2', '.xz' or '.lzma') will be used\r\n            automatically.\r\n        compress: int from 0 to 9 or bool or 2-tuple, optional\r\n            Optional compression level for the data. 0 or False is no compression.\r\n            Higher value means more compression, but also slower read and\r\n            write times. Using a value of 3 is often a good compromise.\r\n            See the notes for more details.\r\n            If compress is True, the compression level used is 3.\r\n            If compress is a 2-tuple, the first element must correspond to a string\r\n            between supported compressors (e.g 'zlib', 'gzip', 'bz2', 'lzma'\r\n            'xz'), the second element must be an integer from 0 to 9, corresponding\r\n            to the compression level.\r\n        protocol: int, optional\r\n            Pickle protocol, see pickle.dump documentation for more details.\r\n        cache_size: positive int, optional\r\n            This option is deprecated in 0.10 and has no effect.\r\n\r\n        Returns\r\n        -------\r\n        filenames: list of strings\r\n            The list of file names in which the data is stored. If\r\n            compress is false, each array is stored in a different file.\r\n\r\n        See Also\r\n        --------\r\n        joblib.load : corresponding loader\r\n\r\n        Notes\r\n        -----\r\n        Memmapping on load cannot be used for compressed files. Thus\r\n        using compression can significantly slow down loading. In\r\n        addition, compressed files take extra extra memory during\r\n        dump and load.\r\n\r\n        \"\"\"\r\n\r\n        if Path is not None and isinstance(filename, Path):\r\n            filename = str(filename)\r\n\r\n        is_filename = isinstance(filename, str)\r\n        is_fileobj = hasattr(filename, \"write\")\r\n\r\n        compress_method = 'zlib'  # zlib is the default compression method.\r\n        if compress is True:\r\n            # By default, if compress is enabled, we want the default compress\r\n            # level of the compressor.\r\n            compress_level = None\r\n        elif isinstance(compress, tuple):\r\n            # a 2-tuple was set in compress\r\n            if len(compress) != 2:\r\n                raise ValueError(\r\n                    'Compress argument tuple should contain exactly 2 elements: '\r\n                    '(compress method, compress level), you passed {}'\r\n                    .format(compress))\r\n            compress_method, compress_level = compress\r\n        elif isinstance(compress, str):\r\n            compress_method = compress\r\n            compress_level = None  # Use default compress level\r\n            compress = (compress_method, compress_level)\r\n        else:\r\n            compress_level = compress\r\n\r\n        if compress_method == 'lz4' and lz4 is None:\r\n            raise ValueError(LZ4_NOT_INSTALLED_ERROR)\r\n\r\n        if (compress_level is not None and\r\n                compress_level is not False and\r\n                compress_level not in range(10)):\r\n            # Raising an error if a non valid compress level is given.\r\n            raise ValueError(\r\n                'Non valid compress level given: \"{}\". Possible values are '\r\n                '{}.'.format(compress_level, list(range(10))))\r\n\r\n        if compress_method not in _COMPRESSORS:\r\n            # Raising an error if an unsupported compression method is given.\r\n            raise ValueError(\r\n                'Non valid compression method given: \"{}\". Possible values are '\r\n                '{}.'.format(compress_method, _COMPRESSORS))\r\n\r\n        if not is_filename and not is_fileobj:\r\n            # People keep inverting arguments, and the resulting error is\r\n            # incomprehensible\r\n            raise ValueError(\r\n                'Second argument should be a filename or a file-like object, '\r\n                '%s (type %s) was given.'\r\n                % (filename, type(filename))\r\n            )\r\n\r\n        if is_filename and not isinstance(compress, tuple):\r\n            # In case no explicit compression was requested using both compression\r\n            # method and level in a tuple and the filename has an explicit\r\n            # extension, we select the corresponding compressor.\r\n\r\n            # unset the variable to be sure no compression level is set afterwards.\r\n            compress_method = None\r\n            for name, compressor in _COMPRESSORS.items():\r\n                if filename.endswith(compressor.extension):\r\n                    compress_method = name\r\n\r\n            if compress_method in _COMPRESSORS and compress_level == 0:\r\n                # we choose the default compress_level in case it was not given\r\n                # as an argument (using compress).\r\n                compress_level = None\r\n\r\n        if cache_size is not None:\r\n            # Cache size is deprecated starting from version 0.10\r\n            warnings.warn(\"Please do not set 'cache_size' in joblib.dump, \"\r\n                          \"this parameter has no effect and will be removed. \"\r\n                          \"You used 'cache_size={}'\".format(cache_size),\r\n                          DeprecationWarning, stacklevel=2)\r\n\r\n        if compress_level != 0:\r\n            with _write_fileobject(filename, compress=(compress_method,\r\n                                                       compress_level)) as f:\r\n                NumpyPickler(f, protocol=protocol).dump(value)\r\n        elif is_filename:\r\n>           with open(filename, 'wb') as f:\r\nE           OSError: [Errno 22] Invalid argument: \"C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd0__0\\\\<class 'neuraxle.hyperparams.scipy_distributions.RandInt'>.joblib\"\r\n\r\n..\\..\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\numpy_pickle.py:481: OSError\r\n__________________________________ test_after_serialization[hd1-_test_lognormal] ___________________________________\r\n\r\nhd = <neuraxle.hyperparams.scipy_distributions.LogNormal object at 0x000001868F447E80>\r\ntest_method = <function _test_lognormal at 0x000001868EFE3310>\r\ntmpdir = local('C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd1__0')\r\n\r\n    @pytest.mark.parametrize(\"hd, test_method\", [\r\n        (RandInt(min_included=-10, max_included=10, null_default_value=0), _test_randint),\r\n        (LogNormal(hard_clip_min=-5, hard_clip_max=5, log2_space_mean=0.0, log2_space_std=2.0, null_default_value=-1.0), _test_lognormal),\r\n        (Normal(hard_clip_min=0.0, hard_clip_max=1.0, mean=0.5, std=0.2, null_default_value=0.0), _test_normal),\r\n        (LogUniform(min_included=0.001, max_included=10), _test_loguniform),\r\n        (Uniform(min_included=-10, max_included=10), _test_uniform),\r\n        (Poisson(min_included=0.0, max_included=10.0, null_default_value=0.0, mu=5.0), _test_discrete_poisson),\r\n        (Gaussian(min_included=0, max_included=10, null_default_value=0.0), _test_gaussian),\r\n        (Histogram(histogram=np.histogram(norm.rvs(size=10000, loc=0, scale=1.5, random_state=123), bins=100), null_default_value=0.0), _test_histogram)\r\n    ])\r\n    def test_after_serialization(hd, test_method, tmpdir):\r\n>       joblib.dump(hd, os.path.join(str(tmpdir), '{}.joblib'.format(hd.__class__)))\r\n\r\ntesting\\hyperparams\\test_scipy_distributions.py:286:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nvalue = <neuraxle.hyperparams.scipy_distributions.LogNormal object at 0x000001868F447E80>\r\nfilename = \"C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd1__0\\\\<class 'neuraxle.hyperparams.scipy_distributions.LogNormal'>.joblib\"\r\ncompress = 0, protocol = None, cache_size = None\r\n\r\n    def dump(value, filename, compress=0, protocol=None, cache_size=None):\r\n        \"\"\"Persist an arbitrary Python object into one file.\r\n\r\n        Read more in the :ref:`User Guide <persistence>`.\r\n\r\n        Parameters\r\n        -----------\r\n        value: any Python object\r\n            The object to store to disk.\r\n        filename: str, pathlib.Path, or file object.\r\n            The file object or path of the file in which it is to be stored.\r\n            The compression method corresponding to one of the supported filename\r\n            extensions ('.z', '.gz', '.bz2', '.xz' or '.lzma') will be used\r\n            automatically.\r\n        compress: int from 0 to 9 or bool or 2-tuple, optional\r\n            Optional compression level for the data. 0 or False is no compression.\r\n            Higher value means more compression, but also slower read and\r\n            write times. Using a value of 3 is often a good compromise.\r\n            See the notes for more details.\r\n            If compress is True, the compression level used is 3.\r\n            If compress is a 2-tuple, the first element must correspond to a string\r\n            between supported compressors (e.g 'zlib', 'gzip', 'bz2', 'lzma'\r\n            'xz'), the second element must be an integer from 0 to 9, corresponding\r\n            to the compression level.\r\n        protocol: int, optional\r\n            Pickle protocol, see pickle.dump documentation for more details.\r\n        cache_size: positive int, optional\r\n            This option is deprecated in 0.10 and has no effect.\r\n\r\n        Returns\r\n        -------\r\n        filenames: list of strings\r\n            The list of file names in which the data is stored. If\r\n            compress is false, each array is stored in a different file.\r\n\r\n        See Also\r\n        --------\r\n        joblib.load : corresponding loader\r\n\r\n        Notes\r\n        -----\r\n        Memmapping on load cannot be used for compressed files. Thus\r\n        using compression can significantly slow down loading. In\r\n        addition, compressed files take extra extra memory during\r\n        dump and load.\r\n\r\n        \"\"\"\r\n\r\n        if Path is not None and isinstance(filename, Path):\r\n            filename = str(filename)\r\n\r\n        is_filename = isinstance(filename, str)\r\n        is_fileobj = hasattr(filename, \"write\")\r\n\r\n        compress_method = 'zlib'  # zlib is the default compression method.\r\n        if compress is True:\r\n            # By default, if compress is enabled, we want the default compress\r\n            # level of the compressor.\r\n            compress_level = None\r\n        elif isinstance(compress, tuple):\r\n            # a 2-tuple was set in compress\r\n            if len(compress) != 2:\r\n                raise ValueError(\r\n                    'Compress argument tuple should contain exactly 2 elements: '\r\n                    '(compress method, compress level), you passed {}'\r\n                    .format(compress))\r\n            compress_method, compress_level = compress\r\n        elif isinstance(compress, str):\r\n            compress_method = compress\r\n            compress_level = None  # Use default compress level\r\n            compress = (compress_method, compress_level)\r\n        else:\r\n            compress_level = compress\r\n\r\n        if compress_method == 'lz4' and lz4 is None:\r\n            raise ValueError(LZ4_NOT_INSTALLED_ERROR)\r\n\r\n        if (compress_level is not None and\r\n                compress_level is not False and\r\n                compress_level not in range(10)):\r\n            # Raising an error if a non valid compress level is given.\r\n            raise ValueError(\r\n                'Non valid compress level given: \"{}\". Possible values are '\r\n                '{}.'.format(compress_level, list(range(10))))\r\n\r\n        if compress_method not in _COMPRESSORS:\r\n            # Raising an error if an unsupported compression method is given.\r\n            raise ValueError(\r\n                'Non valid compression method given: \"{}\". Possible values are '\r\n                '{}.'.format(compress_method, _COMPRESSORS))\r\n\r\n        if not is_filename and not is_fileobj:\r\n            # People keep inverting arguments, and the resulting error is\r\n            # incomprehensible\r\n            raise ValueError(\r\n                'Second argument should be a filename or a file-like object, '\r\n                '%s (type %s) was given.'\r\n                % (filename, type(filename))\r\n            )\r\n\r\n        if is_filename and not isinstance(compress, tuple):\r\n            # In case no explicit compression was requested using both compression\r\n            # method and level in a tuple and the filename has an explicit\r\n            # extension, we select the corresponding compressor.\r\n\r\n            # unset the variable to be sure no compression level is set afterwards.\r\n            compress_method = None\r\n            for name, compressor in _COMPRESSORS.items():\r\n                if filename.endswith(compressor.extension):\r\n                    compress_method = name\r\n\r\n            if compress_method in _COMPRESSORS and compress_level == 0:\r\n                # we choose the default compress_level in case it was not given\r\n                # as an argument (using compress).\r\n                compress_level = None\r\n\r\n        if cache_size is not None:\r\n            # Cache size is deprecated starting from version 0.10\r\n            warnings.warn(\"Please do not set 'cache_size' in joblib.dump, \"\r\n                          \"this parameter has no effect and will be removed. \"\r\n                          \"You used 'cache_size={}'\".format(cache_size),\r\n                          DeprecationWarning, stacklevel=2)\r\n\r\n        if compress_level != 0:\r\n            with _write_fileobject(filename, compress=(compress_method,\r\n                                                       compress_level)) as f:\r\n                NumpyPickler(f, protocol=protocol).dump(value)\r\n        elif is_filename:\r\n>           with open(filename, 'wb') as f:\r\nE           OSError: [Errno 22] Invalid argument: \"C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd1__0\\\\<class 'neuraxle.hyperparams.scipy_distributions.LogNormal'>.joblib\"\r\n\r\n..\\..\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\numpy_pickle.py:481: OSError\r\n____________________________________ test_after_serialization[hd2-_test_normal] ____________________________________\r\n\r\nhd = <neuraxle.hyperparams.scipy_distributions.Normal object at 0x000001868F272AF0>\r\ntest_method = <function _test_normal at 0x000001868EFE30D0>\r\ntmpdir = local('C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd2__0')\r\n\r\n    @pytest.mark.parametrize(\"hd, test_method\", [\r\n        (RandInt(min_included=-10, max_included=10, null_default_value=0), _test_randint),\r\n        (LogNormal(hard_clip_min=-5, hard_clip_max=5, log2_space_mean=0.0, log2_space_std=2.0, null_default_value=-1.0), _test_lognormal),\r\n        (Normal(hard_clip_min=0.0, hard_clip_max=1.0, mean=0.5, std=0.2, null_default_value=0.0), _test_normal),\r\n        (LogUniform(min_included=0.001, max_included=10), _test_loguniform),\r\n        (Uniform(min_included=-10, max_included=10), _test_uniform),\r\n        (Poisson(min_included=0.0, max_included=10.0, null_default_value=0.0, mu=5.0), _test_discrete_poisson),\r\n        (Gaussian(min_included=0, max_included=10, null_default_value=0.0), _test_gaussian),\r\n        (Histogram(histogram=np.histogram(norm.rvs(size=10000, loc=0, scale=1.5, random_state=123), bins=100), null_default_value=0.0), _test_histogram)\r\n    ])\r\n    def test_after_serialization(hd, test_method, tmpdir):\r\n>       joblib.dump(hd, os.path.join(str(tmpdir), '{}.joblib'.format(hd.__class__)))\r\n\r\ntesting\\hyperparams\\test_scipy_distributions.py:286:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nvalue = <neuraxle.hyperparams.scipy_distributions.Normal object at 0x000001868F272AF0>\r\nfilename = \"C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd2__0\\\\<class 'neuraxle.hyperparams.scipy_distributions.Normal'>.joblib\"\r\ncompress = 0, protocol = None, cache_size = None\r\n\r\n    def dump(value, filename, compress=0, protocol=None, cache_size=None):\r\n        \"\"\"Persist an arbitrary Python object into one file.\r\n\r\n        Read more in the :ref:`User Guide <persistence>`.\r\n\r\n        Parameters\r\n        -----------\r\n        value: any Python object\r\n            The object to store to disk.\r\n        filename: str, pathlib.Path, or file object.\r\n            The file object or path of the file in which it is to be stored.\r\n            The compression method corresponding to one of the supported filename\r\n            extensions ('.z', '.gz', '.bz2', '.xz' or '.lzma') will be used\r\n            automatically.\r\n        compress: int from 0 to 9 or bool or 2-tuple, optional\r\n            Optional compression level for the data. 0 or False is no compression.\r\n            Higher value means more compression, but also slower read and\r\n            write times. Using a value of 3 is often a good compromise.\r\n            See the notes for more details.\r\n            If compress is True, the compression level used is 3.\r\n            If compress is a 2-tuple, the first element must correspond to a string\r\n            between supported compressors (e.g 'zlib', 'gzip', 'bz2', 'lzma'\r\n            'xz'), the second element must be an integer from 0 to 9, corresponding\r\n            to the compression level.\r\n        protocol: int, optional\r\n            Pickle protocol, see pickle.dump documentation for more details.\r\n        cache_size: positive int, optional\r\n            This option is deprecated in 0.10 and has no effect.\r\n\r\n        Returns\r\n        -------\r\n        filenames: list of strings\r\n            The list of file names in which the data is stored. If\r\n            compress is false, each array is stored in a different file.\r\n\r\n        See Also\r\n        --------\r\n        joblib.load : corresponding loader\r\n\r\n        Notes\r\n        -----\r\n        Memmapping on load cannot be used for compressed files. Thus\r\n        using compression can significantly slow down loading. In\r\n        addition, compressed files take extra extra memory during\r\n        dump and load.\r\n\r\n        \"\"\"\r\n\r\n        if Path is not None and isinstance(filename, Path):\r\n            filename = str(filename)\r\n\r\n        is_filename = isinstance(filename, str)\r\n        is_fileobj = hasattr(filename, \"write\")\r\n\r\n        compress_method = 'zlib'  # zlib is the default compression method.\r\n        if compress is True:\r\n            # By default, if compress is enabled, we want the default compress\r\n            # level of the compressor.\r\n            compress_level = None\r\n        elif isinstance(compress, tuple):\r\n            # a 2-tuple was set in compress\r\n            if len(compress) != 2:\r\n                raise ValueError(\r\n                    'Compress argument tuple should contain exactly 2 elements: '\r\n                    '(compress method, compress level), you passed {}'\r\n                    .format(compress))\r\n            compress_method, compress_level = compress\r\n        elif isinstance(compress, str):\r\n            compress_method = compress\r\n            compress_level = None  # Use default compress level\r\n            compress = (compress_method, compress_level)\r\n        else:\r\n            compress_level = compress\r\n\r\n        if compress_method == 'lz4' and lz4 is None:\r\n            raise ValueError(LZ4_NOT_INSTALLED_ERROR)\r\n\r\n        if (compress_level is not None and\r\n                compress_level is not False and\r\n                compress_level not in range(10)):\r\n            # Raising an error if a non valid compress level is given.\r\n            raise ValueError(\r\n                'Non valid compress level given: \"{}\". Possible values are '\r\n                '{}.'.format(compress_level, list(range(10))))\r\n\r\n        if compress_method not in _COMPRESSORS:\r\n            # Raising an error if an unsupported compression method is given.\r\n            raise ValueError(\r\n                'Non valid compression method given: \"{}\". Possible values are '\r\n                '{}.'.format(compress_method, _COMPRESSORS))\r\n\r\n        if not is_filename and not is_fileobj:\r\n            # People keep inverting arguments, and the resulting error is\r\n            # incomprehensible\r\n            raise ValueError(\r\n                'Second argument should be a filename or a file-like object, '\r\n                '%s (type %s) was given.'\r\n                % (filename, type(filename))\r\n            )\r\n\r\n        if is_filename and not isinstance(compress, tuple):\r\n            # In case no explicit compression was requested using both compression\r\n            # method and level in a tuple and the filename has an explicit\r\n            # extension, we select the corresponding compressor.\r\n\r\n            # unset the variable to be sure no compression level is set afterwards.\r\n            compress_method = None\r\n            for name, compressor in _COMPRESSORS.items():\r\n                if filename.endswith(compressor.extension):\r\n                    compress_method = name\r\n\r\n            if compress_method in _COMPRESSORS and compress_level == 0:\r\n                # we choose the default compress_level in case it was not given\r\n                # as an argument (using compress).\r\n                compress_level = None\r\n\r\n        if cache_size is not None:\r\n            # Cache size is deprecated starting from version 0.10\r\n            warnings.warn(\"Please do not set 'cache_size' in joblib.dump, \"\r\n                          \"this parameter has no effect and will be removed. \"\r\n                          \"You used 'cache_size={}'\".format(cache_size),\r\n                          DeprecationWarning, stacklevel=2)\r\n\r\n        if compress_level != 0:\r\n            with _write_fileobject(filename, compress=(compress_method,\r\n                                                       compress_level)) as f:\r\n                NumpyPickler(f, protocol=protocol).dump(value)\r\n        elif is_filename:\r\n>           with open(filename, 'wb') as f:\r\nE           OSError: [Errno 22] Invalid argument: \"C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd2__0\\\\<class 'neuraxle.hyperparams.scipy_distributions.Normal'>.joblib\"\r\n\r\n..\\..\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\numpy_pickle.py:481: OSError\r\n__________________________________ test_after_serialization[hd3-_test_loguniform] __________________________________\r\n\r\nhd = <neuraxle.hyperparams.scipy_distributions.LogUniform object at 0x000001868F447370>\r\ntest_method = <function _test_loguniform at 0x000001868EFE34C0>\r\ntmpdir = local('C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd3__0')\r\n\r\n    @pytest.mark.parametrize(\"hd, test_method\", [\r\n        (RandInt(min_included=-10, max_included=10, null_default_value=0), _test_randint),\r\n        (LogNormal(hard_clip_min=-5, hard_clip_max=5, log2_space_mean=0.0, log2_space_std=2.0, null_default_value=-1.0), _test_lognormal),\r\n        (Normal(hard_clip_min=0.0, hard_clip_max=1.0, mean=0.5, std=0.2, null_default_value=0.0), _test_normal),\r\n        (LogUniform(min_included=0.001, max_included=10), _test_loguniform),\r\n        (Uniform(min_included=-10, max_included=10), _test_uniform),\r\n        (Poisson(min_included=0.0, max_included=10.0, null_default_value=0.0, mu=5.0), _test_discrete_poisson),\r\n        (Gaussian(min_included=0, max_included=10, null_default_value=0.0), _test_gaussian),\r\n        (Histogram(histogram=np.histogram(norm.rvs(size=10000, loc=0, scale=1.5, random_state=123), bins=100), null_default_value=0.0), _test_histogram)\r\n    ])\r\n    def test_after_serialization(hd, test_method, tmpdir):\r\n>       joblib.dump(hd, os.path.join(str(tmpdir), '{}.joblib'.format(hd.__class__)))\r\n\r\ntesting\\hyperparams\\test_scipy_distributions.py:286:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nvalue = <neuraxle.hyperparams.scipy_distributions.LogUniform object at 0x000001868F447370>\r\nfilename = \"C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd3__0\\\\<class 'neuraxle.hyperparams.scipy_distributions.LogUniform'>.joblib\"\r\ncompress = 0, protocol = None, cache_size = None\r\n\r\n    def dump(value, filename, compress=0, protocol=None, cache_size=None):\r\n        \"\"\"Persist an arbitrary Python object into one file.\r\n\r\n        Read more in the :ref:`User Guide <persistence>`.\r\n\r\n        Parameters\r\n        -----------\r\n        value: any Python object\r\n            The object to store to disk.\r\n        filename: str, pathlib.Path, or file object.\r\n            The file object or path of the file in which it is to be stored.\r\n            The compression method corresponding to one of the supported filename\r\n            extensions ('.z', '.gz', '.bz2', '.xz' or '.lzma') will be used\r\n            automatically.\r\n        compress: int from 0 to 9 or bool or 2-tuple, optional\r\n            Optional compression level for the data. 0 or False is no compression.\r\n            Higher value means more compression, but also slower read and\r\n            write times. Using a value of 3 is often a good compromise.\r\n            See the notes for more details.\r\n            If compress is True, the compression level used is 3.\r\n            If compress is a 2-tuple, the first element must correspond to a string\r\n            between supported compressors (e.g 'zlib', 'gzip', 'bz2', 'lzma'\r\n            'xz'), the second element must be an integer from 0 to 9, corresponding\r\n            to the compression level.\r\n        protocol: int, optional\r\n            Pickle protocol, see pickle.dump documentation for more details.\r\n        cache_size: positive int, optional\r\n            This option is deprecated in 0.10 and has no effect.\r\n\r\n        Returns\r\n        -------\r\n        filenames: list of strings\r\n            The list of file names in which the data is stored. If\r\n            compress is false, each array is stored in a different file.\r\n\r\n        See Also\r\n        --------\r\n        joblib.load : corresponding loader\r\n\r\n        Notes\r\n        -----\r\n        Memmapping on load cannot be used for compressed files. Thus\r\n        using compression can significantly slow down loading. In\r\n        addition, compressed files take extra extra memory during\r\n        dump and load.\r\n\r\n        \"\"\"\r\n\r\n        if Path is not None and isinstance(filename, Path):\r\n            filename = str(filename)\r\n\r\n        is_filename = isinstance(filename, str)\r\n        is_fileobj = hasattr(filename, \"write\")\r\n\r\n        compress_method = 'zlib'  # zlib is the default compression method.\r\n        if compress is True:\r\n            # By default, if compress is enabled, we want the default compress\r\n            # level of the compressor.\r\n            compress_level = None\r\n        elif isinstance(compress, tuple):\r\n            # a 2-tuple was set in compress\r\n            if len(compress) != 2:\r\n                raise ValueError(\r\n                    'Compress argument tuple should contain exactly 2 elements: '\r\n                    '(compress method, compress level), you passed {}'\r\n                    .format(compress))\r\n            compress_method, compress_level = compress\r\n        elif isinstance(compress, str):\r\n            compress_method = compress\r\n            compress_level = None  # Use default compress level\r\n            compress = (compress_method, compress_level)\r\n        else:\r\n            compress_level = compress\r\n\r\n        if compress_method == 'lz4' and lz4 is None:\r\n            raise ValueError(LZ4_NOT_INSTALLED_ERROR)\r\n\r\n        if (compress_level is not None and\r\n                compress_level is not False and\r\n                compress_level not in range(10)):\r\n            # Raising an error if a non valid compress level is given.\r\n            raise ValueError(\r\n                'Non valid compress level given: \"{}\". Possible values are '\r\n                '{}.'.format(compress_level, list(range(10))))\r\n\r\n        if compress_method not in _COMPRESSORS:\r\n            # Raising an error if an unsupported compression method is given.\r\n            raise ValueError(\r\n                'Non valid compression method given: \"{}\". Possible values are '\r\n                '{}.'.format(compress_method, _COMPRESSORS))\r\n\r\n        if not is_filename and not is_fileobj:\r\n            # People keep inverting arguments, and the resulting error is\r\n            # incomprehensible\r\n            raise ValueError(\r\n                'Second argument should be a filename or a file-like object, '\r\n                '%s (type %s) was given.'\r\n                % (filename, type(filename))\r\n            )\r\n\r\n        if is_filename and not isinstance(compress, tuple):\r\n            # In case no explicit compression was requested using both compression\r\n            # method and level in a tuple and the filename has an explicit\r\n            # extension, we select the corresponding compressor.\r\n\r\n            # unset the variable to be sure no compression level is set afterwards.\r\n            compress_method = None\r\n            for name, compressor in _COMPRESSORS.items():\r\n                if filename.endswith(compressor.extension):\r\n                    compress_method = name\r\n\r\n            if compress_method in _COMPRESSORS and compress_level == 0:\r\n                # we choose the default compress_level in case it was not given\r\n                # as an argument (using compress).\r\n                compress_level = None\r\n\r\n        if cache_size is not None:\r\n            # Cache size is deprecated starting from version 0.10\r\n            warnings.warn(\"Please do not set 'cache_size' in joblib.dump, \"\r\n                          \"this parameter has no effect and will be removed. \"\r\n                          \"You used 'cache_size={}'\".format(cache_size),\r\n                          DeprecationWarning, stacklevel=2)\r\n\r\n        if compress_level != 0:\r\n            with _write_fileobject(filename, compress=(compress_method,\r\n                                                       compress_level)) as f:\r\n                NumpyPickler(f, protocol=protocol).dump(value)\r\n        elif is_filename:\r\n>           with open(filename, 'wb') as f:\r\nE           OSError: [Errno 22] Invalid argument: \"C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd3__0\\\\<class 'neuraxle.hyperparams.scipy_distributions.LogUniform'>.joblib\"\r\n\r\n..\\..\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\numpy_pickle.py:481: OSError\r\n___________________________________ test_after_serialization[hd4-_test_uniform] ____________________________________\r\n\r\nhd = <neuraxle.hyperparams.scipy_distributions.Uniform object at 0x000001868F272640>\r\ntest_method = <function _test_uniform at 0x000001868EFE3820>\r\ntmpdir = local('C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd4__0')\r\n\r\n    @pytest.mark.parametrize(\"hd, test_method\", [\r\n        (RandInt(min_included=-10, max_included=10, null_default_value=0), _test_randint),\r\n        (LogNormal(hard_clip_min=-5, hard_clip_max=5, log2_space_mean=0.0, log2_space_std=2.0, null_default_value=-1.0), _test_lognormal),\r\n        (Normal(hard_clip_min=0.0, hard_clip_max=1.0, mean=0.5, std=0.2, null_default_value=0.0), _test_normal),\r\n        (LogUniform(min_included=0.001, max_included=10), _test_loguniform),\r\n        (Uniform(min_included=-10, max_included=10), _test_uniform),\r\n        (Poisson(min_included=0.0, max_included=10.0, null_default_value=0.0, mu=5.0), _test_discrete_poisson),\r\n        (Gaussian(min_included=0, max_included=10, null_default_value=0.0), _test_gaussian),\r\n        (Histogram(histogram=np.histogram(norm.rvs(size=10000, loc=0, scale=1.5, random_state=123), bins=100), null_default_value=0.0), _test_histogram)\r\n    ])\r\n    def test_after_serialization(hd, test_method, tmpdir):\r\n>       joblib.dump(hd, os.path.join(str(tmpdir), '{}.joblib'.format(hd.__class__)))\r\n\r\ntesting\\hyperparams\\test_scipy_distributions.py:286:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nvalue = <neuraxle.hyperparams.scipy_distributions.Uniform object at 0x000001868F272640>\r\nfilename = \"C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd4__0\\\\<class 'neuraxle.hyperparams.scipy_distributions.Uniform'>.joblib\"\r\ncompress = 0, protocol = None, cache_size = None\r\n\r\n    def dump(value, filename, compress=0, protocol=None, cache_size=None):\r\n        \"\"\"Persist an arbitrary Python object into one file.\r\n\r\n        Read more in the :ref:`User Guide <persistence>`.\r\n\r\n        Parameters\r\n        -----------\r\n        value: any Python object\r\n            The object to store to disk.\r\n        filename: str, pathlib.Path, or file object.\r\n            The file object or path of the file in which it is to be stored.\r\n            The compression method corresponding to one of the supported filename\r\n            extensions ('.z', '.gz', '.bz2', '.xz' or '.lzma') will be used\r\n            automatically.\r\n        compress: int from 0 to 9 or bool or 2-tuple, optional\r\n            Optional compression level for the data. 0 or False is no compression.\r\n            Higher value means more compression, but also slower read and\r\n            write times. Using a value of 3 is often a good compromise.\r\n            See the notes for more details.\r\n            If compress is True, the compression level used is 3.\r\n            If compress is a 2-tuple, the first element must correspond to a string\r\n            between supported compressors (e.g 'zlib', 'gzip', 'bz2', 'lzma'\r\n            'xz'), the second element must be an integer from 0 to 9, corresponding\r\n            to the compression level.\r\n        protocol: int, optional\r\n            Pickle protocol, see pickle.dump documentation for more details.\r\n        cache_size: positive int, optional\r\n            This option is deprecated in 0.10 and has no effect.\r\n\r\n        Returns\r\n        -------\r\n        filenames: list of strings\r\n            The list of file names in which the data is stored. If\r\n            compress is false, each array is stored in a different file.\r\n\r\n        See Also\r\n        --------\r\n        joblib.load : corresponding loader\r\n\r\n        Notes\r\n        -----\r\n        Memmapping on load cannot be used for compressed files. Thus\r\n        using compression can significantly slow down loading. In\r\n        addition, compressed files take extra extra memory during\r\n        dump and load.\r\n\r\n        \"\"\"\r\n\r\n        if Path is not None and isinstance(filename, Path):\r\n            filename = str(filename)\r\n\r\n        is_filename = isinstance(filename, str)\r\n        is_fileobj = hasattr(filename, \"write\")\r\n\r\n        compress_method = 'zlib'  # zlib is the default compression method.\r\n        if compress is True:\r\n            # By default, if compress is enabled, we want the default compress\r\n            # level of the compressor.\r\n            compress_level = None\r\n        elif isinstance(compress, tuple):\r\n            # a 2-tuple was set in compress\r\n            if len(compress) != 2:\r\n                raise ValueError(\r\n                    'Compress argument tuple should contain exactly 2 elements: '\r\n                    '(compress method, compress level), you passed {}'\r\n                    .format(compress))\r\n            compress_method, compress_level = compress\r\n        elif isinstance(compress, str):\r\n            compress_method = compress\r\n            compress_level = None  # Use default compress level\r\n            compress = (compress_method, compress_level)\r\n        else:\r\n            compress_level = compress\r\n\r\n        if compress_method == 'lz4' and lz4 is None:\r\n            raise ValueError(LZ4_NOT_INSTALLED_ERROR)\r\n\r\n        if (compress_level is not None and\r\n                compress_level is not False and\r\n                compress_level not in range(10)):\r\n            # Raising an error if a non valid compress level is given.\r\n            raise ValueError(\r\n                'Non valid compress level given: \"{}\". Possible values are '\r\n                '{}.'.format(compress_level, list(range(10))))\r\n\r\n        if compress_method not in _COMPRESSORS:\r\n            # Raising an error if an unsupported compression method is given.\r\n            raise ValueError(\r\n                'Non valid compression method given: \"{}\". Possible values are '\r\n                '{}.'.format(compress_method, _COMPRESSORS))\r\n\r\n        if not is_filename and not is_fileobj:\r\n            # People keep inverting arguments, and the resulting error is\r\n            # incomprehensible\r\n            raise ValueError(\r\n                'Second argument should be a filename or a file-like object, '\r\n                '%s (type %s) was given.'\r\n                % (filename, type(filename))\r\n            )\r\n\r\n        if is_filename and not isinstance(compress, tuple):\r\n            # In case no explicit compression was requested using both compression\r\n            # method and level in a tuple and the filename has an explicit\r\n            # extension, we select the corresponding compressor.\r\n\r\n            # unset the variable to be sure no compression level is set afterwards.\r\n            compress_method = None\r\n            for name, compressor in _COMPRESSORS.items():\r\n                if filename.endswith(compressor.extension):\r\n                    compress_method = name\r\n\r\n            if compress_method in _COMPRESSORS and compress_level == 0:\r\n                # we choose the default compress_level in case it was not given\r\n                # as an argument (using compress).\r\n                compress_level = None\r\n\r\n        if cache_size is not None:\r\n            # Cache size is deprecated starting from version 0.10\r\n            warnings.warn(\"Please do not set 'cache_size' in joblib.dump, \"\r\n                          \"this parameter has no effect and will be removed. \"\r\n                          \"You used 'cache_size={}'\".format(cache_size),\r\n                          DeprecationWarning, stacklevel=2)\r\n\r\n        if compress_level != 0:\r\n            with _write_fileobject(filename, compress=(compress_method,\r\n                                                       compress_level)) as f:\r\n                NumpyPickler(f, protocol=protocol).dump(value)\r\n        elif is_filename:\r\n>           with open(filename, 'wb') as f:\r\nE           OSError: [Errno 22] Invalid argument: \"C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd4__0\\\\<class 'neuraxle.hyperparams.scipy_distributions.Uniform'>.joblib\"\r\n\r\n..\\..\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\numpy_pickle.py:481: OSError\r\n_______________________________ test_after_serialization[hd5-_test_discrete_poisson] _______________________________\r\n\r\nhd = <neuraxle.hyperparams.scipy_distributions.Poisson object at 0x000001868F447460>\r\ntest_method = <function _test_discrete_poisson at 0x000001868EFE3C10>\r\ntmpdir = local('C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd5__0')\r\n\r\n    @pytest.mark.parametrize(\"hd, test_method\", [\r\n        (RandInt(min_included=-10, max_included=10, null_default_value=0), _test_randint),\r\n        (LogNormal(hard_clip_min=-5, hard_clip_max=5, log2_space_mean=0.0, log2_space_std=2.0, null_default_value=-1.0), _test_lognormal),\r\n        (Normal(hard_clip_min=0.0, hard_clip_max=1.0, mean=0.5, std=0.2, null_default_value=0.0), _test_normal),\r\n        (LogUniform(min_included=0.001, max_included=10), _test_loguniform),\r\n        (Uniform(min_included=-10, max_included=10), _test_uniform),\r\n        (Poisson(min_included=0.0, max_included=10.0, null_default_value=0.0, mu=5.0), _test_discrete_poisson),\r\n        (Gaussian(min_included=0, max_included=10, null_default_value=0.0), _test_gaussian),\r\n        (Histogram(histogram=np.histogram(norm.rvs(size=10000, loc=0, scale=1.5, random_state=123), bins=100), null_default_value=0.0), _test_histogram)\r\n    ])\r\n    def test_after_serialization(hd, test_method, tmpdir):\r\n>       joblib.dump(hd, os.path.join(str(tmpdir), '{}.joblib'.format(hd.__class__)))\r\n\r\ntesting\\hyperparams\\test_scipy_distributions.py:286:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nvalue = <neuraxle.hyperparams.scipy_distributions.Poisson object at 0x000001868F447460>\r\nfilename = \"C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd5__0\\\\<class 'neuraxle.hyperparams.scipy_distributions.Poisson'>.joblib\"\r\ncompress = 0, protocol = None, cache_size = None\r\n\r\n    def dump(value, filename, compress=0, protocol=None, cache_size=None):\r\n        \"\"\"Persist an arbitrary Python object into one file.\r\n\r\n        Read more in the :ref:`User Guide <persistence>`.\r\n\r\n        Parameters\r\n        -----------\r\n        value: any Python object\r\n            The object to store to disk.\r\n        filename: str, pathlib.Path, or file object.\r\n            The file object or path of the file in which it is to be stored.\r\n            The compression method corresponding to one of the supported filename\r\n            extensions ('.z', '.gz', '.bz2', '.xz' or '.lzma') will be used\r\n            automatically.\r\n        compress: int from 0 to 9 or bool or 2-tuple, optional\r\n            Optional compression level for the data. 0 or False is no compression.\r\n            Higher value means more compression, but also slower read and\r\n            write times. Using a value of 3 is often a good compromise.\r\n            See the notes for more details.\r\n            If compress is True, the compression level used is 3.\r\n            If compress is a 2-tuple, the first element must correspond to a string\r\n            between supported compressors (e.g 'zlib', 'gzip', 'bz2', 'lzma'\r\n            'xz'), the second element must be an integer from 0 to 9, corresponding\r\n            to the compression level.\r\n        protocol: int, optional\r\n            Pickle protocol, see pickle.dump documentation for more details.\r\n        cache_size: positive int, optional\r\n            This option is deprecated in 0.10 and has no effect.\r\n\r\n        Returns\r\n        -------\r\n        filenames: list of strings\r\n            The list of file names in which the data is stored. If\r\n            compress is false, each array is stored in a different file.\r\n\r\n        See Also\r\n        --------\r\n        joblib.load : corresponding loader\r\n\r\n        Notes\r\n        -----\r\n        Memmapping on load cannot be used for compressed files. Thus\r\n        using compression can significantly slow down loading. In\r\n        addition, compressed files take extra extra memory during\r\n        dump and load.\r\n\r\n        \"\"\"\r\n\r\n        if Path is not None and isinstance(filename, Path):\r\n            filename = str(filename)\r\n\r\n        is_filename = isinstance(filename, str)\r\n        is_fileobj = hasattr(filename, \"write\")\r\n\r\n        compress_method = 'zlib'  # zlib is the default compression method.\r\n        if compress is True:\r\n            # By default, if compress is enabled, we want the default compress\r\n            # level of the compressor.\r\n            compress_level = None\r\n        elif isinstance(compress, tuple):\r\n            # a 2-tuple was set in compress\r\n            if len(compress) != 2:\r\n                raise ValueError(\r\n                    'Compress argument tuple should contain exactly 2 elements: '\r\n                    '(compress method, compress level), you passed {}'\r\n                    .format(compress))\r\n            compress_method, compress_level = compress\r\n        elif isinstance(compress, str):\r\n            compress_method = compress\r\n            compress_level = None  # Use default compress level\r\n            compress = (compress_method, compress_level)\r\n        else:\r\n            compress_level = compress\r\n\r\n        if compress_method == 'lz4' and lz4 is None:\r\n            raise ValueError(LZ4_NOT_INSTALLED_ERROR)\r\n\r\n        if (compress_level is not None and\r\n                compress_level is not False and\r\n                compress_level not in range(10)):\r\n            # Raising an error if a non valid compress level is given.\r\n            raise ValueError(\r\n                'Non valid compress level given: \"{}\". Possible values are '\r\n                '{}.'.format(compress_level, list(range(10))))\r\n\r\n        if compress_method not in _COMPRESSORS:\r\n            # Raising an error if an unsupported compression method is given.\r\n            raise ValueError(\r\n                'Non valid compression method given: \"{}\". Possible values are '\r\n                '{}.'.format(compress_method, _COMPRESSORS))\r\n\r\n        if not is_filename and not is_fileobj:\r\n            # People keep inverting arguments, and the resulting error is\r\n            # incomprehensible\r\n            raise ValueError(\r\n                'Second argument should be a filename or a file-like object, '\r\n                '%s (type %s) was given.'\r\n                % (filename, type(filename))\r\n            )\r\n\r\n        if is_filename and not isinstance(compress, tuple):\r\n            # In case no explicit compression was requested using both compression\r\n            # method and level in a tuple and the filename has an explicit\r\n            # extension, we select the corresponding compressor.\r\n\r\n            # unset the variable to be sure no compression level is set afterwards.\r\n            compress_method = None\r\n            for name, compressor in _COMPRESSORS.items():\r\n                if filename.endswith(compressor.extension):\r\n                    compress_method = name\r\n\r\n            if compress_method in _COMPRESSORS and compress_level == 0:\r\n                # we choose the default compress_level in case it was not given\r\n                # as an argument (using compress).\r\n                compress_level = None\r\n\r\n        if cache_size is not None:\r\n            # Cache size is deprecated starting from version 0.10\r\n            warnings.warn(\"Please do not set 'cache_size' in joblib.dump, \"\r\n                          \"this parameter has no effect and will be removed. \"\r\n                          \"You used 'cache_size={}'\".format(cache_size),\r\n                          DeprecationWarning, stacklevel=2)\r\n\r\n        if compress_level != 0:\r\n            with _write_fileobject(filename, compress=(compress_method,\r\n                                                       compress_level)) as f:\r\n                NumpyPickler(f, protocol=protocol).dump(value)\r\n        elif is_filename:\r\n>           with open(filename, 'wb') as f:\r\nE           OSError: [Errno 22] Invalid argument: \"C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd5__0\\\\<class 'neuraxle.hyperparams.scipy_distributions.Poisson'>.joblib\"\r\n\r\n..\\..\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\numpy_pickle.py:481: OSError\r\n___________________________________ test_after_serialization[hd6-_test_gaussian] ___________________________________\r\n\r\nhd = <neuraxle.hyperparams.scipy_distributions.Gaussian object at 0x000001868F264E80>\r\ntest_method = <function _test_gaussian at 0x000001868EFE38B0>\r\ntmpdir = local('C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd6__0')\r\n\r\n    @pytest.mark.parametrize(\"hd, test_method\", [\r\n        (RandInt(min_included=-10, max_included=10, null_default_value=0), _test_randint),\r\n        (LogNormal(hard_clip_min=-5, hard_clip_max=5, log2_space_mean=0.0, log2_space_std=2.0, null_default_value=-1.0), _test_lognormal),\r\n        (Normal(hard_clip_min=0.0, hard_clip_max=1.0, mean=0.5, std=0.2, null_default_value=0.0), _test_normal),\r\n        (LogUniform(min_included=0.001, max_included=10), _test_loguniform),\r\n        (Uniform(min_included=-10, max_included=10), _test_uniform),\r\n        (Poisson(min_included=0.0, max_included=10.0, null_default_value=0.0, mu=5.0), _test_discrete_poisson),\r\n        (Gaussian(min_included=0, max_included=10, null_default_value=0.0), _test_gaussian),\r\n        (Histogram(histogram=np.histogram(norm.rvs(size=10000, loc=0, scale=1.5, random_state=123), bins=100), null_default_value=0.0), _test_histogram)\r\n    ])\r\n    def test_after_serialization(hd, test_method, tmpdir):\r\n>       joblib.dump(hd, os.path.join(str(tmpdir), '{}.joblib'.format(hd.__class__)))\r\n\r\ntesting\\hyperparams\\test_scipy_distributions.py:286:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nvalue = <neuraxle.hyperparams.scipy_distributions.Gaussian object at 0x000001868F264E80>\r\nfilename = \"C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd6__0\\\\<class 'neuraxle.hyperparams.scipy_distributions.Gaussian'>.joblib\"\r\ncompress = 0, protocol = None, cache_size = None\r\n\r\n    def dump(value, filename, compress=0, protocol=None, cache_size=None):\r\n        \"\"\"Persist an arbitrary Python object into one file.\r\n\r\n        Read more in the :ref:`User Guide <persistence>`.\r\n\r\n        Parameters\r\n        -----------\r\n        value: any Python object\r\n            The object to store to disk.\r\n        filename: str, pathlib.Path, or file object.\r\n            The file object or path of the file in which it is to be stored.\r\n            The compression method corresponding to one of the supported filename\r\n            extensions ('.z', '.gz', '.bz2', '.xz' or '.lzma') will be used\r\n            automatically.\r\n        compress: int from 0 to 9 or bool or 2-tuple, optional\r\n            Optional compression level for the data. 0 or False is no compression.\r\n            Higher value means more compression, but also slower read and\r\n            write times. Using a value of 3 is often a good compromise.\r\n            See the notes for more details.\r\n            If compress is True, the compression level used is 3.\r\n            If compress is a 2-tuple, the first element must correspond to a string\r\n            between supported compressors (e.g 'zlib', 'gzip', 'bz2', 'lzma'\r\n            'xz'), the second element must be an integer from 0 to 9, corresponding\r\n            to the compression level.\r\n        protocol: int, optional\r\n            Pickle protocol, see pickle.dump documentation for more details.\r\n        cache_size: positive int, optional\r\n            This option is deprecated in 0.10 and has no effect.\r\n\r\n        Returns\r\n        -------\r\n        filenames: list of strings\r\n            The list of file names in which the data is stored. If\r\n            compress is false, each array is stored in a different file.\r\n\r\n        See Also\r\n        --------\r\n        joblib.load : corresponding loader\r\n\r\n        Notes\r\n        -----\r\n        Memmapping on load cannot be used for compressed files. Thus\r\n        using compression can significantly slow down loading. In\r\n        addition, compressed files take extra extra memory during\r\n        dump and load.\r\n\r\n        \"\"\"\r\n\r\n        if Path is not None and isinstance(filename, Path):\r\n            filename = str(filename)\r\n\r\n        is_filename = isinstance(filename, str)\r\n        is_fileobj = hasattr(filename, \"write\")\r\n\r\n        compress_method = 'zlib'  # zlib is the default compression method.\r\n        if compress is True:\r\n            # By default, if compress is enabled, we want the default compress\r\n            # level of the compressor.\r\n            compress_level = None\r\n        elif isinstance(compress, tuple):\r\n            # a 2-tuple was set in compress\r\n            if len(compress) != 2:\r\n                raise ValueError(\r\n                    'Compress argument tuple should contain exactly 2 elements: '\r\n                    '(compress method, compress level), you passed {}'\r\n                    .format(compress))\r\n            compress_method, compress_level = compress\r\n        elif isinstance(compress, str):\r\n            compress_method = compress\r\n            compress_level = None  # Use default compress level\r\n            compress = (compress_method, compress_level)\r\n        else:\r\n            compress_level = compress\r\n\r\n        if compress_method == 'lz4' and lz4 is None:\r\n            raise ValueError(LZ4_NOT_INSTALLED_ERROR)\r\n\r\n        if (compress_level is not None and\r\n                compress_level is not False and\r\n                compress_level not in range(10)):\r\n            # Raising an error if a non valid compress level is given.\r\n            raise ValueError(\r\n                'Non valid compress level given: \"{}\". Possible values are '\r\n                '{}.'.format(compress_level, list(range(10))))\r\n\r\n        if compress_method not in _COMPRESSORS:\r\n            # Raising an error if an unsupported compression method is given.\r\n            raise ValueError(\r\n                'Non valid compression method given: \"{}\". Possible values are '\r\n                '{}.'.format(compress_method, _COMPRESSORS))\r\n\r\n        if not is_filename and not is_fileobj:\r\n            # People keep inverting arguments, and the resulting error is\r\n            # incomprehensible\r\n            raise ValueError(\r\n                'Second argument should be a filename or a file-like object, '\r\n                '%s (type %s) was given.'\r\n                % (filename, type(filename))\r\n            )\r\n\r\n        if is_filename and not isinstance(compress, tuple):\r\n            # In case no explicit compression was requested using both compression\r\n            # method and level in a tuple and the filename has an explicit\r\n            # extension, we select the corresponding compressor.\r\n\r\n            # unset the variable to be sure no compression level is set afterwards.\r\n            compress_method = None\r\n            for name, compressor in _COMPRESSORS.items():\r\n                if filename.endswith(compressor.extension):\r\n                    compress_method = name\r\n\r\n            if compress_method in _COMPRESSORS and compress_level == 0:\r\n                # we choose the default compress_level in case it was not given\r\n                # as an argument (using compress).\r\n                compress_level = None\r\n\r\n        if cache_size is not None:\r\n            # Cache size is deprecated starting from version 0.10\r\n            warnings.warn(\"Please do not set 'cache_size' in joblib.dump, \"\r\n                          \"this parameter has no effect and will be removed. \"\r\n                          \"You used 'cache_size={}'\".format(cache_size),\r\n                          DeprecationWarning, stacklevel=2)\r\n\r\n        if compress_level != 0:\r\n            with _write_fileobject(filename, compress=(compress_method,\r\n                                                       compress_level)) as f:\r\n                NumpyPickler(f, protocol=protocol).dump(value)\r\n        elif is_filename:\r\n>           with open(filename, 'wb') as f:\r\nE           OSError: [Errno 22] Invalid argument: \"C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd6__0\\\\<class 'neuraxle.hyperparams.scipy_distributions.Gaussian'>.joblib\"\r\n\r\n..\\..\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\numpy_pickle.py:481: OSError\r\n__________________________________ test_after_serialization[hd7-_test_histogram] ___________________________________\r\n\r\nhd = <neuraxle.hyperparams.scipy_distributions.Histogram object at 0x000001868F4479A0>\r\ntest_method = <function _test_histogram at 0x000001868EFE3940>\r\ntmpdir = local('C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd7__0')\r\n\r\n    @pytest.mark.parametrize(\"hd, test_method\", [\r\n        (RandInt(min_included=-10, max_included=10, null_default_value=0), _test_randint),\r\n        (LogNormal(hard_clip_min=-5, hard_clip_max=5, log2_space_mean=0.0, log2_space_std=2.0, null_default_value=-1.0), _test_lognormal),\r\n        (Normal(hard_clip_min=0.0, hard_clip_max=1.0, mean=0.5, std=0.2, null_default_value=0.0), _test_normal),\r\n        (LogUniform(min_included=0.001, max_included=10), _test_loguniform),\r\n        (Uniform(min_included=-10, max_included=10), _test_uniform),\r\n        (Poisson(min_included=0.0, max_included=10.0, null_default_value=0.0, mu=5.0), _test_discrete_poisson),\r\n        (Gaussian(min_included=0, max_included=10, null_default_value=0.0), _test_gaussian),\r\n        (Histogram(histogram=np.histogram(norm.rvs(size=10000, loc=0, scale=1.5, random_state=123), bins=100), null_default_value=0.0), _test_histogram)\r\n    ])\r\n    def test_after_serialization(hd, test_method, tmpdir):\r\n>       joblib.dump(hd, os.path.join(str(tmpdir), '{}.joblib'.format(hd.__class__)))\r\n\r\ntesting\\hyperparams\\test_scipy_distributions.py:286:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nvalue = <neuraxle.hyperparams.scipy_distributions.Histogram object at 0x000001868F4479A0>\r\nfilename = \"C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd7__0\\\\<class 'neuraxle.hyperparams.scipy_distributions.Histogram'>.joblib\"\r\ncompress = 0, protocol = None, cache_size = None\r\n\r\n    def dump(value, filename, compress=0, protocol=None, cache_size=None):\r\n        \"\"\"Persist an arbitrary Python object into one file.\r\n\r\n        Read more in the :ref:`User Guide <persistence>`.\r\n\r\n        Parameters\r\n        -----------\r\n        value: any Python object\r\n            The object to store to disk.\r\n        filename: str, pathlib.Path, or file object.\r\n            The file object or path of the file in which it is to be stored.\r\n            The compression method corresponding to one of the supported filename\r\n            extensions ('.z', '.gz', '.bz2', '.xz' or '.lzma') will be used\r\n            automatically.\r\n        compress: int from 0 to 9 or bool or 2-tuple, optional\r\n            Optional compression level for the data. 0 or False is no compression.\r\n            Higher value means more compression, but also slower read and\r\n            write times. Using a value of 3 is often a good compromise.\r\n            See the notes for more details.\r\n            If compress is True, the compression level used is 3.\r\n            If compress is a 2-tuple, the first element must correspond to a string\r\n            between supported compressors (e.g 'zlib', 'gzip', 'bz2', 'lzma'\r\n            'xz'), the second element must be an integer from 0 to 9, corresponding\r\n            to the compression level.\r\n        protocol: int, optional\r\n            Pickle protocol, see pickle.dump documentation for more details.\r\n        cache_size: positive int, optional\r\n            This option is deprecated in 0.10 and has no effect.\r\n\r\n        Returns\r\n        -------\r\n        filenames: list of strings\r\n            The list of file names in which the data is stored. If\r\n            compress is false, each array is stored in a different file.\r\n\r\n        See Also\r\n        --------\r\n        joblib.load : corresponding loader\r\n\r\n        Notes\r\n        -----\r\n        Memmapping on load cannot be used for compressed files. Thus\r\n        using compression can significantly slow down loading. In\r\n        addition, compressed files take extra extra memory during\r\n        dump and load.\r\n\r\n        \"\"\"\r\n\r\n        if Path is not None and isinstance(filename, Path):\r\n            filename = str(filename)\r\n\r\n        is_filename = isinstance(filename, str)\r\n        is_fileobj = hasattr(filename, \"write\")\r\n\r\n        compress_method = 'zlib'  # zlib is the default compression method.\r\n        if compress is True:\r\n            # By default, if compress is enabled, we want the default compress\r\n            # level of the compressor.\r\n            compress_level = None\r\n        elif isinstance(compress, tuple):\r\n            # a 2-tuple was set in compress\r\n            if len(compress) != 2:\r\n                raise ValueError(\r\n                    'Compress argument tuple should contain exactly 2 elements: '\r\n                    '(compress method, compress level), you passed {}'\r\n                    .format(compress))\r\n            compress_method, compress_level = compress\r\n        elif isinstance(compress, str):\r\n            compress_method = compress\r\n            compress_level = None  # Use default compress level\r\n            compress = (compress_method, compress_level)\r\n        else:\r\n            compress_level = compress\r\n\r\n        if compress_method == 'lz4' and lz4 is None:\r\n            raise ValueError(LZ4_NOT_INSTALLED_ERROR)\r\n\r\n        if (compress_level is not None and\r\n                compress_level is not False and\r\n                compress_level not in range(10)):\r\n            # Raising an error if a non valid compress level is given.\r\n            raise ValueError(\r\n                'Non valid compress level given: \"{}\". Possible values are '\r\n                '{}.'.format(compress_level, list(range(10))))\r\n\r\n        if compress_method not in _COMPRESSORS:\r\n            # Raising an error if an unsupported compression method is given.\r\n            raise ValueError(\r\n                'Non valid compression method given: \"{}\". Possible values are '\r\n                '{}.'.format(compress_method, _COMPRESSORS))\r\n\r\n        if not is_filename and not is_fileobj:\r\n            # People keep inverting arguments, and the resulting error is\r\n            # incomprehensible\r\n            raise ValueError(\r\n                'Second argument should be a filename or a file-like object, '\r\n                '%s (type %s) was given.'\r\n                % (filename, type(filename))\r\n            )\r\n\r\n        if is_filename and not isinstance(compress, tuple):\r\n            # In case no explicit compression was requested using both compression\r\n            # method and level in a tuple and the filename has an explicit\r\n            # extension, we select the corresponding compressor.\r\n\r\n            # unset the variable to be sure no compression level is set afterwards.\r\n            compress_method = None\r\n            for name, compressor in _COMPRESSORS.items():\r\n                if filename.endswith(compressor.extension):\r\n                    compress_method = name\r\n\r\n            if compress_method in _COMPRESSORS and compress_level == 0:\r\n                # we choose the default compress_level in case it was not given\r\n                # as an argument (using compress).\r\n                compress_level = None\r\n\r\n        if cache_size is not None:\r\n            # Cache size is deprecated starting from version 0.10\r\n            warnings.warn(\"Please do not set 'cache_size' in joblib.dump, \"\r\n                          \"this parameter has no effect and will be removed. \"\r\n                          \"You used 'cache_size={}'\".format(cache_size),\r\n                          DeprecationWarning, stacklevel=2)\r\n\r\n        if compress_level != 0:\r\n            with _write_fileobject(filename, compress=(compress_method,\r\n                                                       compress_level)) as f:\r\n                NumpyPickler(f, protocol=protocol).dump(value)\r\n        elif is_filename:\r\n>           with open(filename, 'wb') as f:\r\nE           OSError: [Errno 22] Invalid argument: \"C:\\\\Users\\\\Guillaume\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Guillaume\\\\pytest-1\\\\test_after_serialization_hd7__0\\\\<class 'neuraxle.hyperparams.scipy_distributions.Histogram'>.joblib\"\r\n\r\n..\\..\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\numpy_pickle.py:481: OSError\r\n________________________________________ test_trial_should_create_new_split ________________________________________\r\n\r\n    def test_trial_should_create_new_split():\r\n        hp = HyperparameterSamples({'a': 2})\r\n        repo = InMemoryHyperparamsRepository()\r\n        trial = Trial(\r\n            save_trial_function=repo.save_trial,\r\n            hyperparams=hp,\r\n            main_metric_name=MAIN_METRIC_NAME\r\n        )\r\n\r\n        with trial.new_validation_split(Identity()) as trial_split:\r\n            trial_split.set_success()\r\n\r\n        assert isinstance(trial_split.start_time, datetime.datetime)\r\n        assert isinstance(trial_split.end_time, datetime.datetime)\r\n>       assert trial_split.start_time < trial_split.end_time\r\nE       AssertionError: assert datetime.datetime(2021, 10, 14, 22, 12, 53, 931650) < datetime.datetime(2021, 10, 14, 22, 12, 53, 931650)\r\nE        +  where datetime.datetime(2021, 10, 14, 22, 12, 53, 931650) = Trial.from_json({'status': 'success', 'error': None, 'metric_results': {}, 'error_traceback': None, 'start_time': '10/14/2021, 22:12:53', 'end_time': '10/14/2021, 22:12:53', 'split_number': 0, 'main_metric_name': 'mse'}).start_time\r\nE        +  and   datetime.datetime(2021, 10, 14, 22, 12, 53, 931650) = Trial.from_json({'status': 'success', 'error': None, 'metric_results': {}, 'error_traceback': None, 'start_time': '10/14/2021, 22:12:53', 'end_time': '10/14/2021, 22:12:53', 'split_number': 0, 'main_metric_name': 'mse'}).end_time\r\n\r\ntesting\\metaopt\\test_trial.py:36: AssertionError\r\n================================================= warnings summary =================================================\r\nneuraxle\\steps\\flow.py:132\r\nneuraxle\\steps\\flow.py:132\r\n  C:\\Users\\Guillaume\\neuraxle\\Neuraxle\\neuraxle\\steps\\flow.py:132: PytestWarning: cannot collect test class 'TestOnlyWrapper' because it has a __init__ constructor\r\n    class TestOnlyWrapper(TrainOrTestOnlyWrapper):\r\n\r\ntesting/test_data_container.py::test_list_data_container_concat\r\n  C:\\Users\\Guillaume\\neuraxle\\Neuraxle\\testing\\test_data_container.py:63: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\r\n  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n    assert np.array_equal(np.array(data_container.current_ids), np.array(list(range(0, 200))).astype(np.str))\r\n\r\ntesting/test_data_container.py::test_list_data_container_concat\r\n  C:\\Users\\Guillaume\\neuraxle\\Neuraxle\\testing\\test_data_container.py:65: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\n  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n    expected_data_inputs = np.array(list(range(0, 200))).astype(np.int)\r\n\r\ntesting/test_data_container.py::test_list_data_container_concat\r\n  C:\\Users\\Guillaume\\neuraxle\\Neuraxle\\testing\\test_data_container.py:66: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\n  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n    actual_data_inputs = np.array(data_container.data_inputs).astype(np.int)\r\n\r\ntesting/test_data_container.py::test_list_data_container_concat\r\n  C:\\Users\\Guillaume\\neuraxle\\Neuraxle\\testing\\test_data_container.py:69: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\n  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n    expected_expected_outputs = np.array(list(range(100, 300))).astype(np.int)\r\n\r\ntesting/test_data_container.py::test_list_data_container_concat\r\n  C:\\Users\\Guillaume\\neuraxle\\Neuraxle\\testing\\test_data_container.py:70: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\n  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n    assert np.array_equal(np.array(data_container.expected_outputs).astype(np.int), expected_expected_outputs)\r\n\r\ntesting/test_data_container_batching.py::test_data_container_batching[3-False-None-expected_data_containers0]\r\ntesting/test_data_container_batching.py::test_data_container_batching[3-True-0-expected_data_containers1]\r\ntesting/test_data_container_batching.py::test_data_container_batching[3-True-default_value2-expected_data_containers2]\r\n  C:\\Users\\Guillaume\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\r\n    return bool(asarray(a1 == a2).all())\r\n\r\ntesting/test_service_assertions.py::TestServiceAssertion::test_step_with_context_saver\r\n  C:\\Users\\Guillaume\\neuraxle\\Neuraxle\\neuraxle\\base.py:3891: UserWarning: Warning! the loading of a StepWithContext instance overrides the context attribute with the one provided at loading.\r\n    warnings.warn(\r\n\r\ntesting/test_union.py::test_model_stacking_fit_transform\r\ntesting/test_union.py::test_model_stacking_transform\r\n  C:\\Users\\Guillaume\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\r\n    y = column_or_1d(y, warn=True)\r\n\r\ntesting/steps/test_data_shuffling.py::test_data_shuffling_should_shuffle_data_inputs_and_expected_outputs\r\n  C:\\Users\\Guillaume\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\numeric.py:2440: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\r\n    a1, a2 = asarray(a1), asarray(a2)\r\n\r\n-- Docs: https://docs.pytest.org/en/latest/warnings.html\r\n===================== 10 failed, 480 passed, 2 skipped, 14 warnings, 1 error in 181.20 seconds =====================\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/comments/943930982/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"guillaume-chevalier","id":11862328,"node_id":"MDQ6VXNlcjExODYyMzI4","avatar_url":"https://avatars.githubusercontent.com/u/11862328?v=4","gravatar_id":"","url":"https://api.github.com/users/guillaume-chevalier","html_url":"https://github.com/guillaume-chevalier","followers_url":"https://api.github.com/users/guillaume-chevalier/followers","following_url":"https://api.github.com/users/guillaume-chevalier/following{/other_user}","gists_url":"https://api.github.com/users/guillaume-chevalier/gists{/gist_id}","starred_url":"https://api.github.com/users/guillaume-chevalier/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/guillaume-chevalier/subscriptions","organizations_url":"https://api.github.com/users/guillaume-chevalier/orgs","repos_url":"https://api.github.com/users/guillaume-chevalier/repos","events_url":"https://api.github.com/users/guillaume-chevalier/events{/privacy}","received_events_url":"https://api.github.com/users/guillaume-chevalier/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/comments/944046483","html_url":"https://github.com/Neuraxio/Neuraxle/issues/462#issuecomment-944046483","issue_url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/462","id":944046483,"node_id":"IC_kwDOCpoNY844RQGT","user":{"login":"guillaume-chevalier","id":11862328,"node_id":"MDQ6VXNlcjExODYyMzI4","avatar_url":"https://avatars.githubusercontent.com/u/11862328?v=4","gravatar_id":"","url":"https://api.github.com/users/guillaume-chevalier","html_url":"https://github.com/guillaume-chevalier","followers_url":"https://api.github.com/users/guillaume-chevalier/followers","following_url":"https://api.github.com/users/guillaume-chevalier/following{/other_user}","gists_url":"https://api.github.com/users/guillaume-chevalier/gists{/gist_id}","starred_url":"https://api.github.com/users/guillaume-chevalier/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/guillaume-chevalier/subscriptions","organizations_url":"https://api.github.com/users/guillaume-chevalier/orgs","repos_url":"https://api.github.com/users/guillaume-chevalier/repos","events_url":"https://api.github.com/users/guillaume-chevalier/events{/privacy}","received_events_url":"https://api.github.com/users/guillaume-chevalier/received_events","type":"User","site_admin":false},"created_at":"2021-10-15T06:53:22Z","updated_at":"2021-10-15T06:53:22Z","author_association":"MEMBER","body":"Added in #512 that got merged. ","reactions":{"url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/comments/944046483/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"guillaume-chevalier","id":11862328,"node_id":"MDQ6VXNlcjExODYyMzI4","avatar_url":"https://avatars.githubusercontent.com/u/11862328?v=4","gravatar_id":"","url":"https://api.github.com/users/guillaume-chevalier","html_url":"https://github.com/guillaume-chevalier","followers_url":"https://api.github.com/users/guillaume-chevalier/followers","following_url":"https://api.github.com/users/guillaume-chevalier/following{/other_user}","gists_url":"https://api.github.com/users/guillaume-chevalier/gists{/gist_id}","starred_url":"https://api.github.com/users/guillaume-chevalier/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/guillaume-chevalier/subscriptions","organizations_url":"https://api.github.com/users/guillaume-chevalier/orgs","repos_url":"https://api.github.com/users/guillaume-chevalier/repos","events_url":"https://api.github.com/users/guillaume-chevalier/events{/privacy}","received_events_url":"https://api.github.com/users/guillaume-chevalier/received_events","type":"User","site_admin":false}},{"id":5468021188,"node_id":"CE_lADOCpoNY84yMuT7zwAAAAFF62HE","url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/events/5468021188","actor":{"login":"guillaume-chevalier","id":11862328,"node_id":"MDQ6VXNlcjExODYyMzI4","avatar_url":"https://avatars.githubusercontent.com/u/11862328?v=4","gravatar_id":"","url":"https://api.github.com/users/guillaume-chevalier","html_url":"https://github.com/guillaume-chevalier","followers_url":"https://api.github.com/users/guillaume-chevalier/followers","following_url":"https://api.github.com/users/guillaume-chevalier/following{/other_user}","gists_url":"https://api.github.com/users/guillaume-chevalier/gists{/gist_id}","starred_url":"https://api.github.com/users/guillaume-chevalier/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/guillaume-chevalier/subscriptions","organizations_url":"https://api.github.com/users/guillaume-chevalier/orgs","repos_url":"https://api.github.com/users/guillaume-chevalier/repos","events_url":"https://api.github.com/users/guillaume-chevalier/events{/privacy}","received_events_url":"https://api.github.com/users/guillaume-chevalier/received_events","type":"User","site_admin":false},"event":"closed","commit_id":null,"commit_url":null,"created_at":"2021-10-15T06:53:22Z","state_reason":null,"performed_via_github_app":null},{"id":5474715140,"node_id":"MIE_lADOCpoNY84yMuT7zwAAAAFGUYYE","url":"https://api.github.com/repos/Neuraxio/Neuraxle/issues/events/5474715140","actor":{"login":"guillaume-chevalier","id":11862328,"node_id":"MDQ6VXNlcjExODYyMzI4","avatar_url":"https://avatars.githubusercontent.com/u/11862328?v=4","gravatar_id":"","url":"https://api.github.com/users/guillaume-chevalier","html_url":"https://github.com/guillaume-chevalier","followers_url":"https://api.github.com/users/guillaume-chevalier/followers","following_url":"https://api.github.com/users/guillaume-chevalier/following{/other_user}","gists_url":"https://api.github.com/users/guillaume-chevalier/gists{/gist_id}","starred_url":"https://api.github.com/users/guillaume-chevalier/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/guillaume-chevalier/subscriptions","organizations_url":"https://api.github.com/users/guillaume-chevalier/orgs","repos_url":"https://api.github.com/users/guillaume-chevalier/repos","events_url":"https://api.github.com/users/guillaume-chevalier/events{/privacy}","received_events_url":"https://api.github.com/users/guillaume-chevalier/received_events","type":"User","site_admin":false},"event":"milestoned","commit_id":null,"commit_url":null,"created_at":"2021-10-17T20:53:04Z","milestone":{"title":"0.6.1"},"performed_via_github_app":null}]