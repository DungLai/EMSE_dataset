{"url":"https://api.github.com/repos/hackingmaterials/automatminer/issues/331","repository_url":"https://api.github.com/repos/hackingmaterials/automatminer","labels_url":"https://api.github.com/repos/hackingmaterials/automatminer/issues/331/labels{/name}","comments_url":"https://api.github.com/repos/hackingmaterials/automatminer/issues/331/comments","events_url":"https://api.github.com/repos/hackingmaterials/automatminer/issues/331/events","html_url":"https://github.com/hackingmaterials/automatminer/issues/331","id":690333119,"node_id":"MDU6SXNzdWU2OTAzMzMxMTk=","number":331,"title":"Error: Found array with 0 feature(s) & tpot unsupported set of arguments","user":{"login":"krkaufma","id":38843564,"node_id":"MDQ6VXNlcjM4ODQzNTY0","avatar_url":"https://avatars.githubusercontent.com/u/38843564?v=4","gravatar_id":"","url":"https://api.github.com/users/krkaufma","html_url":"https://github.com/krkaufma","followers_url":"https://api.github.com/users/krkaufma/followers","following_url":"https://api.github.com/users/krkaufma/following{/other_user}","gists_url":"https://api.github.com/users/krkaufma/gists{/gist_id}","starred_url":"https://api.github.com/users/krkaufma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/krkaufma/subscriptions","organizations_url":"https://api.github.com/users/krkaufma/orgs","repos_url":"https://api.github.com/users/krkaufma/repos","events_url":"https://api.github.com/users/krkaufma/events{/privacy}","received_events_url":"https://api.github.com/users/krkaufma/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2020-09-01T17:51:01Z","updated_at":"2021-09-11T07:46:23Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I am running the following software in a conda virtual env:\r\nUbuntu 18.04\r\nPython 3.6.8\r\nautomatminer 1.0.3.20200727 (installed with pip, not from conda)\r\n\r\nBoth errors are encountered when fitting a MatPipe pipe in express or debug mode. \r\n\r\n**First, the array with 0 features issue:**\r\n\r\nValueError: Found array with 0 feature(s) (shape=(25, 0)) while a minimum of 1 is required by RobustScaler.\r\n\r\nThe stack trace:\r\n\r\n```\r\nValueError Traceback (most recent call last)\r\nin\r\n1 # Create Matpipe in ‘express’ mode for recommended settings\r\n2 pipe = MatPipe.from_preset(preset=“express”, n_jobs=22)\r\n----> 3 pipe.fit(df=train_df, target=target_name)\r\n\r\n~/.local/lib/python3.6/site-packages/automatminer/utils/pkg.py in wrapper(*args, **kwargs)\r\n102 def wrapper(*args, **kwargs):\r\n103 args[0].is_fit = False\r\n–> 104 result = func(*args, **kwargs)\r\n105 args[0].is_fit = True\r\n106 return result\r\n\r\n~/.local/lib/python3.6/site-packages/automatminer/pipeline.py in fit(self, df, target)\r\n182 df = self.cleaner.fit_transform(df, target)\r\n183 df = self.reducer.fit_transform(df, target)\r\n–> 184 self.learner.fit(df, target)\r\n185 logger.info(“MatPipe successfully fit.”)\r\n186 self.post_fit_df = df\r\n\r\n~/.local/lib/python3.6/site-packages/automatminer/utils/log.py in wrapper(*args, **kwargs)\r\n94 self = args[0]\r\n95 logger.info(\"{}Starting {}.\".format(self._log_prefix, operation))\r\n—> 96 result = meth(*args, **kwargs)\r\n97 logger.info(\"{}Finished {}.\".format(self._log_prefix, operation))\r\n98 return result\r\n\r\n~/.local/lib/python3.6/site-packages/automatminer/utils/pkg.py in wrapper(*args, **kwargs)\r\n102 def wrapper(*args, **kwargs):\r\n103 args[0].is_fit = False\r\n–> 104 result = func(*args, **kwargs)\r\n105 args[0].is_fit = True\r\n106 return result\r\n\r\n~/.local/lib/python3.6/site-packages/automatminer/automl/adaptors.py in fit(self, df, target, **fit_kwargs)\r\n135 self._features = df.drop(columns=target).columns.tolist()\r\n136 self._fitted_target = target\r\n–> 137 self._backend = self._backend.fit(X, y, **fit_kwargs)\r\n138 return self\r\n139\r\n\r\n~/.local/lib/python3.6/site-packages/tpot/base.py in fit(self, features, target, sample_weight, groups)\r\n744 # raise the exception if it’s our last attempt\r\n745 if attempt == (attempts - 1):\r\n–> 746 raise e\r\n747 return self\r\n748\r\n\r\n~/.local/lib/python3.6/site-packages/tpot/base.py in fit(self, features, target, sample_weight, groups)\r\n736\r\n737 self._update_top_pipeline()\r\n–> 738 self._summary_of_best_pipeline(features, target)\r\n739 # Delete the temporary cache before exiting\r\n740 self._cleanup_memory()\r\n\r\n~/.local/lib/python3.6/site-packages/tpot/base.py in summary_of_best_pipeline(self, features, target)\r\n860 with warnings.catch_warnings():\r\n861 warnings.simplefilter(‘ignore’)\r\n–> 862 self.pareto_front_fitted_pipelines[str(pipeline)].fit(features, target)\r\n863\r\n864 def predict(self, features):\r\n\r\n~/.local/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self, X, y, **fit_params)\r\n348 This estimator\r\n349 “”\"\r\n–> 350 Xt, fit_params = self._fit(X, y, **fit_params)\r\n351 with _print_elapsed_time(‘Pipeline’,\r\n352 self._log_message(len(self.steps) - 1)):\r\n\r\n~/.local/lib/python3.6/site-packages/sklearn/pipeline.py in _fit(self, X, y, **fit_params)\r\n313 message_clsname=‘Pipeline’,\r\n314 message=self._log_message(step_idx),\r\n–> 315 **fit_params_steps[name])\r\n316 # Replace the transformer of the step with the fitted\r\n317 # transformer. This is necessary when loading the transformer\r\n\r\n~/.local/lib/python3.6/site-packages/joblib/memory.py in call(self, *args, **kwargs)\r\n563\r\n564 def call(self, *args, **kwargs):\r\n–> 565 return self._cached_call(args, kwargs)[0]\r\n566\r\n567 def getstate(self):\r\n\r\n~/.local/lib/python3.6/site-packages/joblib/memory.py in _cached_call(self, args, kwargs, shelving)\r\n529\r\n530 if must_call:\r\n–> 531 out, metadata = self.call(*args, **kwargs)\r\n532 if self.mmap_mode is not None:\r\n533 # Memmap the output at the first call to be consistent with\r\n\r\n~/.local/lib/python3.6/site-packages/joblib/memory.py in call(self, *args, **kwargs)\r\n725 if self._verbose > 0:\r\n726 print(format_call(self.func, args, kwargs))\r\n–> 727 output = self.func(*args, **kwargs)\r\n728 self.store_backend.dump_item(\r\n729 [func_id, args_id], output, verbose=self._verbose)\r\n\r\n~/.local/lib/python3.6/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer, X, y, weight, message_clsname, message, **fit_params)\r\n726 with _print_elapsed_time(message_clsname, message):\r\n727 if hasattr(transformer, ‘fit_transform’):\r\n–> 728 res = transformer.fit_transform(X, y, **fit_params)\r\n729 else:\r\n730 res = transformer.fit(X, y, **fit_params).transform(X)\r\n\r\n~/.local/lib/python3.6/site-packages/sklearn/base.py in fit_transform(self, X, y, **fit_params)\r\n572 else:\r\n573 # fit method of arity 2 (supervised transformation)\r\n–> 574 return self.fit(X, y, **fit_params).transform(X)\r\n575\r\n576\r\n\r\n~/.local/lib/python3.6/site-packages/sklearn/preprocessing/_data.py in fit(self, X, y)\r\n1198 # the quantiles\r\n1199 X = check_array(X, accept_sparse=‘csc’, estimator=self,\r\n-> 1200 dtype=FLOAT_DTYPES, force_all_finite=‘allow-nan’)\r\n1201\r\n1202 q_min, q_max = self.quantile_range\r\n\r\n~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\r\n592 \" a minimum of %d is required%s.\"\r\n593 % (n_features, array.shape, ensure_min_features,\r\n–> 594 context))\r\n595\r\n596 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:\r\n\r\nValueError: Found array with 0 feature(s) (shape=(25, 0)) while a minimum of 1 is required by RobustScaler.\r\n```\r\n\r\n\r\n**Second, the tpot unsupported set of arguments:**\r\nIt appears to me that the genetic algorithm is attempting to pass invalid combinations of arguments to sklearn models. This occurs in ‘debug’ and ‘express’ presets.\r\n\r\nValueError: Unsupported set of arguments: The combination of penalty=‘l2’ and loss=‘epsilon_insensitive’ are not supported when dual=False, Parameters: penalty=‘l2’, loss=‘epsilon_insensitive’, dual=False\r\n\r\nThe stack trace:\r\n```\r\n_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(22, 0)) while a minimum of 1 is required by MaxAbsScaler…\r\n_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(22, 0)) while a minimum of 1 is required by MaxAbsScaler…\r\n_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(22, 0)) while a minimum of 1 is required by MaxAbsScaler…\r\n_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(22, 0)) while a minimum of 1 is required by MaxAbsScaler…\r\n_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(22, 0)) while a minimum of 1 is required by MaxAbsScaler…\r\nPipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\r\n\r\nValueError Traceback (most recent call last)\r\nin\r\n1 # Create Matpipe in ‘debug’ mode for quick test\r\n2 dummy_pipe = MatPipe.from_preset(preset=“debug”, n_jobs=20)\r\n----> 3 dummy_pipe.fit(df=train_df, target=target_name)\r\n\r\n~/.local/lib/python3.6/site-packages/automatminer/utils/pkg.py in wrapper(*args, **kwargs)\r\n102 def wrapper(*args, **kwargs):\r\n103 args[0].is_fit = False\r\n–> 104 result = func(*args, **kwargs)\r\n105 args[0].is_fit = True\r\n106 return result\r\n\r\n~/.local/lib/python3.6/site-packages/automatminer/pipeline.py in fit(self, df, target)\r\n182 df = self.cleaner.fit_transform(df, target)\r\n183 df = self.reducer.fit_transform(df, target)\r\n–> 184 self.learner.fit(df, target)\r\n185 logger.info(“MatPipe successfully fit.”)\r\n186 self.post_fit_df = df\r\n\r\n~/.local/lib/python3.6/site-packages/automatminer/utils/log.py in wrapper(*args, **kwargs)\r\n94 self = args[0]\r\n95 logger.info(\"{}Starting {}.\".format(self._log_prefix, operation))\r\n—> 96 result = meth(*args, **kwargs)\r\n97 logger.info(\"{}Finished {}.\".format(self._log_prefix, operation))\r\n98 return result\r\n\r\n~/.local/lib/python3.6/site-packages/automatminer/utils/pkg.py in wrapper(*args, **kwargs)\r\n102 def wrapper(*args, **kwargs):\r\n103 args[0].is_fit = False\r\n–> 104 result = func(*args, **kwargs)\r\n105 args[0].is_fit = True\r\n106 return result\r\n\r\n~/.local/lib/python3.6/site-packages/automatminer/automl/adaptors.py in fit(self, df, target, **fit_kwargs)\r\n135 self._features = df.drop(columns=target).columns.tolist()\r\n136 self._fitted_target = target\r\n–> 137 self._backend = self._backend.fit(X, y, **fit_kwargs)\r\n138 return self\r\n139\r\n\r\n~/.local/lib/python3.6/site-packages/tpot/base.py in fit(self, features, target, sample_weight, groups)\r\n744 # raise the exception if it’s our last attempt\r\n745 if attempt == (attempts - 1):\r\n–> 746 raise e\r\n747 return self\r\n748\r\n\r\n~/.local/lib/python3.6/site-packages/tpot/base.py in fit(self, features, target, sample_weight, groups)\r\n736\r\n737 self._update_top_pipeline()\r\n–> 738 self._summary_of_best_pipeline(features, target)\r\n739 # Delete the temporary cache before exiting\r\n740 self._cleanup_memory()\r\n\r\n~/.local/lib/python3.6/site-packages/tpot/base.py in summary_of_best_pipeline(self, features, target)\r\n860 with warnings.catch_warnings():\r\n861 warnings.simplefilter(‘ignore’)\r\n–> 862 self.pareto_front_fitted_pipelines[str(pipeline)].fit(features, target)\r\n863\r\n864 def predict(self, features):\r\n\r\n~/.local/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self, X, y, **fit_params)\r\n352 self._log_message(len(self.steps) - 1)):\r\n353 if self._final_estimator != ‘passthrough’:\r\n–> 354 self._final_estimator.fit(Xt, y, **fit_params)\r\n355 return self\r\n356\r\n\r\n~/.local/lib/python3.6/site-packages/sklearn/svm/classes.py in fit(self, X, y, sample_weight)\r\n430 None, penalty, self.dual, self.verbose,\r\n431 self.max_iter, self.tol, self.random_state, loss=self.loss,\r\n–> 432 epsilon=self.epsilon, sample_weight=sample_weight)\r\n433 self.coef = self.coef_.ravel()\r\n434\r\n\r\n~/.local/lib/python3.6/site-packages/sklearn/svm/_base.py in fit_liblinear(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\r\n933 dtype=np.float64)\r\n934\r\n–> 935 solver_type = get_liblinear_solver_type(multi_class, penalty, loss, dual)\r\n936 raw_coef, n_iter = liblinear.train_wrap(\r\n937 X, y_ind, sp.isspmatrix(X), solver_type, tol, bias, C,\r\n\r\n~/.local/lib/python3.6/site-packages/sklearn/svm/_base.py in _get_liblinear_solver_type(multi_class, penalty, loss, dual)\r\n791 raise ValueError('Unsupported set of arguments: %s, ’\r\n792 'Parameters: penalty=%r, loss=%r, dual=\r\nr\r\n'\r\n−\r\n→\r\n793\r\n(error_string, penalty, loss, dual))\r\n794\r\n795\r\n```\r\n\r\n\r\nOriginal reports on matsci.org can be found [here](https://matsci.org/t/error-found-array-with-0-feature-s/4848) and [here](https://matsci.org/t/tpot-unsupported-set-of-arguments/4845).","closed_by":null,"reactions":{"url":"https://api.github.com/repos/hackingmaterials/automatminer/issues/331/reactions","total_count":2,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":2},"timeline_url":"https://api.github.com/repos/hackingmaterials/automatminer/issues/331/timeline","performed_via_github_app":null,"state_reason":null}