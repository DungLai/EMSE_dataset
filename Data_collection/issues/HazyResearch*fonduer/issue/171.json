{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/171","repository_url":"https://api.github.com/repos/HazyResearch/fonduer","labels_url":"https://api.github.com/repos/HazyResearch/fonduer/issues/171/labels{/name}","comments_url":"https://api.github.com/repos/HazyResearch/fonduer/issues/171/comments","events_url":"https://api.github.com/repos/HazyResearch/fonduer/issues/171/events","html_url":"https://github.com/HazyResearch/fonduer/issues/171","id":375411408,"node_id":"MDU6SXNzdWUzNzU0MTE0MDg=","number":171,"title":"LogisticRegression MemoryError","user":{"login":"wanted68","id":7629790,"node_id":"MDQ6VXNlcjc2Mjk3OTA=","avatar_url":"https://avatars.githubusercontent.com/u/7629790?v=4","gravatar_id":"","url":"https://api.github.com/users/wanted68","html_url":"https://github.com/wanted68","followers_url":"https://api.github.com/users/wanted68/followers","following_url":"https://api.github.com/users/wanted68/following{/other_user}","gists_url":"https://api.github.com/users/wanted68/gists{/gist_id}","starred_url":"https://api.github.com/users/wanted68/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wanted68/subscriptions","organizations_url":"https://api.github.com/users/wanted68/orgs","repos_url":"https://api.github.com/users/wanted68/repos","events_url":"https://api.github.com/users/wanted68/events{/privacy}","received_events_url":"https://api.github.com/users/wanted68/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2018-10-30T10:13:31Z","updated_at":"2018-10-30T18:43:31Z","closed_at":"2018-10-30T18:43:31Z","author_association":"NONE","active_lock_reason":null,"body":"I am using fonduer Logistic Regression to train a model on some textual data in order to extract relations. Here is the code I use:\r\n```\r\nfrom fonduer.learning import LogisticRegression\r\ndisc_model = LogisticRegression()\r\n%time disc_model.train((train_cands[0], F_train[0]), train_marginals, n_epochs=50, lr=0.001)\r\n\r\n```\r\nThe code doesn't have any problem when I run it on 20 Docs but when I increase the number of Docs to 40 I get this error:\r\n```\r\n\r\n[INFO] fonduer.learning.disc_learning - Load defalut parameters for Logistic Regression\r\n\r\n---------------------------------------------------------------------------\r\nMemoryError                               Traceback (most recent call last)\r\n<timed eval> in <module>\r\n\r\n~/.venv/lib/python3.6/site-packages/fonduer/learning/disc_learning.py in train(self, X_train, Y_train, n_epochs, lr, batch_size, rebalance, X_dev, Y_dev, print_freq, dev_ckpt, dev_ckpt_delay, save_dir, seed, host_device)\r\n    169 \r\n    170         _X_train, _Y_train = self._preprocess_data(\r\n--> 171             X_train, Y_train, idxs=train_idxs, train=True\r\n    172         )\r\n    173         if X_dev is not None:\r\n\r\n~/.venv/lib/python3.6/site-packages/fonduer/learning/disc_models/logistic_regression.py in _preprocess_data(self, X, Y, idxs, train)\r\n     59         C, F = X\r\n     60         if issparse(F):\r\n---> 61             F = F.todense()\r\n     62 \r\n     63         if idxs is None:\r\n\r\n~/.venv/lib/python3.6/site-packages/scipy/sparse/base.py in todense(self, order, out)\r\n    844             `numpy.matrix` object that shares the same memory.\r\n    845         \"\"\"\r\n--> 846         return np.asmatrix(self.toarray(order=order, out=out))\r\n    847 \r\n    848     def toarray(self, order=None, out=None):\r\n\r\n~/.venv/lib/python3.6/site-packages/scipy/sparse/compressed.py in toarray(self, order, out)\r\n    945         if out is None and order is None:\r\n    946             order = self._swap('cf')[0]\r\n--> 947         out = self._process_toarray_args(order, out)\r\n    948         if not (out.flags.c_contiguous or out.flags.f_contiguous):\r\n    949             raise ValueError('Output array must be C or F contiguous')\r\n\r\n~/.venv/lib/python3.6/site-packages/scipy/sparse/base.py in _process_toarray_args(self, order, out)\r\n   1182             return out\r\n   1183         else:\r\n-> 1184             return np.zeros(self.shape, dtype=self.dtype, order=order)\r\n   1185 \r\n   1186 \r\n\r\nMemoryError: \r\n```\r\nI have 16,0 GB Total Physical Memory.  F_size = 6347423 and F_type = float64","closed_by":{"login":"senwu","id":5580008,"node_id":"MDQ6VXNlcjU1ODAwMDg=","avatar_url":"https://avatars.githubusercontent.com/u/5580008?v=4","gravatar_id":"","url":"https://api.github.com/users/senwu","html_url":"https://github.com/senwu","followers_url":"https://api.github.com/users/senwu/followers","following_url":"https://api.github.com/users/senwu/following{/other_user}","gists_url":"https://api.github.com/users/senwu/gists{/gist_id}","starred_url":"https://api.github.com/users/senwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/senwu/subscriptions","organizations_url":"https://api.github.com/users/senwu/orgs","repos_url":"https://api.github.com/users/senwu/repos","events_url":"https://api.github.com/users/senwu/events{/privacy}","received_events_url":"https://api.github.com/users/senwu/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/171/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/HazyResearch/fonduer/issues/171/timeline","performed_via_github_app":null,"state_reason":"completed"}