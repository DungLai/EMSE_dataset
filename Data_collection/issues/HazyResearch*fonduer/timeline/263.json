[{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/493145331","html_url":"https://github.com/HazyResearch/fonduer/issues/263#issuecomment-493145331","issue_url":"https://api.github.com/repos/HazyResearch/fonduer/issues/263","id":493145331,"node_id":"MDEyOklzc3VlQ29tbWVudDQ5MzE0NTMzMQ==","user":{"login":"HiromuHota","id":20668349,"node_id":"MDQ6VXNlcjIwNjY4MzQ5","avatar_url":"https://avatars.githubusercontent.com/u/20668349?v=4","gravatar_id":"","url":"https://api.github.com/users/HiromuHota","html_url":"https://github.com/HiromuHota","followers_url":"https://api.github.com/users/HiromuHota/followers","following_url":"https://api.github.com/users/HiromuHota/following{/other_user}","gists_url":"https://api.github.com/users/HiromuHota/gists{/gist_id}","starred_url":"https://api.github.com/users/HiromuHota/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HiromuHota/subscriptions","organizations_url":"https://api.github.com/users/HiromuHota/orgs","repos_url":"https://api.github.com/users/HiromuHota/repos","events_url":"https://api.github.com/users/HiromuHota/events{/privacy}","received_events_url":"https://api.github.com/users/HiromuHota/received_events","type":"User","site_admin":false},"created_at":"2019-05-16T16:46:53Z","updated_at":"2019-05-16T16:46:53Z","author_association":"CONTRIBUTOR","body":"I'd leave the 1st question to @SenWu or @lukehsiao .\r\n\r\nFor the 2nd question, technically yes. We can separate the training and test pipeline, but it is not straight-forward to do so as of today as I described in #259.\r\n\r\n> The entire corpus will have to be parsed to extract the mentions and candidates and store the feature keys.\r\n\r\nNo, you don't have to parse the entire corpus again in the test phase, assuming the entire corpus includes train, dev, and test.\r\nTo do so, use the latest commit (not released yet) version of Fonduer, which has #258, and follow the instructions below.\r\n\r\nIn the training phase, save the feature keys in a file like below:\r\n```\r\nfeaturizer = Featurizer(session, candidate_classes)\r\nfeaturizer.apply(split=0, train=True, parallelism=PARALLEL)\r\nkey_names = [key.name for key in featurizer.get_keys()]\r\nwith open('feature_keys.pkl', 'wb') as f:\r\n    pickle.dump(key_names, f)\r\n```\r\n\r\nIn the test phase, load the feature keys from the file to the database as below:\r\n```\r\nfeaturizer = Featurizer(session, candidate_classes)\r\nwith open('feature_keys.pkl', 'rb') as f:\r\n    key_names = pickle.load(f)\r\nfeaturizer.drop_keys(key_names)\r\nfeaturizer.upsert_keys(key_names)\r\n```\r\n\r\nYou may have more questions about 2nd question. I'm happy to help you as much as I can.","reactions":{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/493145331/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"HiromuHota","id":20668349,"node_id":"MDQ6VXNlcjIwNjY4MzQ5","avatar_url":"https://avatars.githubusercontent.com/u/20668349?v=4","gravatar_id":"","url":"https://api.github.com/users/HiromuHota","html_url":"https://github.com/HiromuHota","followers_url":"https://api.github.com/users/HiromuHota/followers","following_url":"https://api.github.com/users/HiromuHota/following{/other_user}","gists_url":"https://api.github.com/users/HiromuHota/gists{/gist_id}","starred_url":"https://api.github.com/users/HiromuHota/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HiromuHota/subscriptions","organizations_url":"https://api.github.com/users/HiromuHota/orgs","repos_url":"https://api.github.com/users/HiromuHota/repos","events_url":"https://api.github.com/users/HiromuHota/events{/privacy}","received_events_url":"https://api.github.com/users/HiromuHota/received_events","type":"User","site_admin":false}},{"id":2347072374,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MjM0NzA3MjM3NA==","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2347072374","actor":{"login":"senwu","id":5580008,"node_id":"MDQ6VXNlcjU1ODAwMDg=","avatar_url":"https://avatars.githubusercontent.com/u/5580008?v=4","gravatar_id":"","url":"https://api.github.com/users/senwu","html_url":"https://github.com/senwu","followers_url":"https://api.github.com/users/senwu/followers","following_url":"https://api.github.com/users/senwu/following{/other_user}","gists_url":"https://api.github.com/users/senwu/gists{/gist_id}","starred_url":"https://api.github.com/users/senwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/senwu/subscriptions","organizations_url":"https://api.github.com/users/senwu/orgs","repos_url":"https://api.github.com/users/senwu/repos","events_url":"https://api.github.com/users/senwu/events{/privacy}","received_events_url":"https://api.github.com/users/senwu/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2019-05-16T16:46:53Z","performed_via_github_app":null},{"id":2347072376,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDIzNDcwNzIzNzY=","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2347072376","actor":{"login":"senwu","id":5580008,"node_id":"MDQ6VXNlcjU1ODAwMDg=","avatar_url":"https://avatars.githubusercontent.com/u/5580008?v=4","gravatar_id":"","url":"https://api.github.com/users/senwu","html_url":"https://github.com/senwu","followers_url":"https://api.github.com/users/senwu/followers","following_url":"https://api.github.com/users/senwu/following{/other_user}","gists_url":"https://api.github.com/users/senwu/gists{/gist_id}","starred_url":"https://api.github.com/users/senwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/senwu/subscriptions","organizations_url":"https://api.github.com/users/senwu/orgs","repos_url":"https://api.github.com/users/senwu/repos","events_url":"https://api.github.com/users/senwu/events{/privacy}","received_events_url":"https://api.github.com/users/senwu/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2019-05-16T16:46:53Z","performed_via_github_app":null},{"id":2347072381,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MjM0NzA3MjM4MQ==","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2347072381","actor":{"login":"lukehsiao","id":7573542,"node_id":"MDQ6VXNlcjc1NzM1NDI=","avatar_url":"https://avatars.githubusercontent.com/u/7573542?v=4","gravatar_id":"","url":"https://api.github.com/users/lukehsiao","html_url":"https://github.com/lukehsiao","followers_url":"https://api.github.com/users/lukehsiao/followers","following_url":"https://api.github.com/users/lukehsiao/following{/other_user}","gists_url":"https://api.github.com/users/lukehsiao/gists{/gist_id}","starred_url":"https://api.github.com/users/lukehsiao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lukehsiao/subscriptions","organizations_url":"https://api.github.com/users/lukehsiao/orgs","repos_url":"https://api.github.com/users/lukehsiao/repos","events_url":"https://api.github.com/users/lukehsiao/events{/privacy}","received_events_url":"https://api.github.com/users/lukehsiao/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2019-05-16T16:46:53Z","performed_via_github_app":null},{"id":2347072382,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDIzNDcwNzIzODI=","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2347072382","actor":{"login":"lukehsiao","id":7573542,"node_id":"MDQ6VXNlcjc1NzM1NDI=","avatar_url":"https://avatars.githubusercontent.com/u/7573542?v=4","gravatar_id":"","url":"https://api.github.com/users/lukehsiao","html_url":"https://github.com/lukehsiao","followers_url":"https://api.github.com/users/lukehsiao/followers","following_url":"https://api.github.com/users/lukehsiao/following{/other_user}","gists_url":"https://api.github.com/users/lukehsiao/gists{/gist_id}","starred_url":"https://api.github.com/users/lukehsiao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lukehsiao/subscriptions","organizations_url":"https://api.github.com/users/lukehsiao/orgs","repos_url":"https://api.github.com/users/lukehsiao/repos","events_url":"https://api.github.com/users/lukehsiao/events{/privacy}","received_events_url":"https://api.github.com/users/lukehsiao/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2019-05-16T16:46:53Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/493329347","html_url":"https://github.com/HazyResearch/fonduer/issues/263#issuecomment-493329347","issue_url":"https://api.github.com/repos/HazyResearch/fonduer/issues/263","id":493329347,"node_id":"MDEyOklzc3VlQ29tbWVudDQ5MzMyOTM0Nw==","user":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false},"created_at":"2019-05-17T05:52:24Z","updated_at":"2019-05-17T05:52:24Z","author_association":"NONE","body":"Thanks @HiromuHota . I will definitely try this out. I do have more queries on the prediction capabilities of fonduer. Please help me get some clarity on these.\r\n\r\n1. How well does fonduer fair when we have documents that differ structurally? \r\n\r\n2. Is the main role of the model to predict whether the candidate is a true candidate or not ?\r\n\r\n3. How can we scale this to multiple candidates, does that mean creating separate models for each of those?","reactions":{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/493329347/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false}},{"id":2348366447,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MjM0ODM2NjQ0Nw==","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2348366447","actor":{"login":"HiromuHota","id":20668349,"node_id":"MDQ6VXNlcjIwNjY4MzQ5","avatar_url":"https://avatars.githubusercontent.com/u/20668349?v=4","gravatar_id":"","url":"https://api.github.com/users/HiromuHota","html_url":"https://github.com/HiromuHota","followers_url":"https://api.github.com/users/HiromuHota/followers","following_url":"https://api.github.com/users/HiromuHota/following{/other_user}","gists_url":"https://api.github.com/users/HiromuHota/gists{/gist_id}","starred_url":"https://api.github.com/users/HiromuHota/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HiromuHota/subscriptions","organizations_url":"https://api.github.com/users/HiromuHota/orgs","repos_url":"https://api.github.com/users/HiromuHota/repos","events_url":"https://api.github.com/users/HiromuHota/events{/privacy}","received_events_url":"https://api.github.com/users/HiromuHota/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2019-05-17T05:52:24Z","performed_via_github_app":null},{"id":2348366449,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDIzNDgzNjY0NDk=","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2348366449","actor":{"login":"HiromuHota","id":20668349,"node_id":"MDQ6VXNlcjIwNjY4MzQ5","avatar_url":"https://avatars.githubusercontent.com/u/20668349?v=4","gravatar_id":"","url":"https://api.github.com/users/HiromuHota","html_url":"https://github.com/HiromuHota","followers_url":"https://api.github.com/users/HiromuHota/followers","following_url":"https://api.github.com/users/HiromuHota/following{/other_user}","gists_url":"https://api.github.com/users/HiromuHota/gists{/gist_id}","starred_url":"https://api.github.com/users/HiromuHota/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HiromuHota/subscriptions","organizations_url":"https://api.github.com/users/HiromuHota/orgs","repos_url":"https://api.github.com/users/HiromuHota/repos","events_url":"https://api.github.com/users/HiromuHota/events{/privacy}","received_events_url":"https://api.github.com/users/HiromuHota/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2019-05-17T05:52:24Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/493339526","html_url":"https://github.com/HazyResearch/fonduer/issues/263#issuecomment-493339526","issue_url":"https://api.github.com/repos/HazyResearch/fonduer/issues/263","id":493339526,"node_id":"MDEyOklzc3VlQ29tbWVudDQ5MzMzOTUyNg==","user":{"login":"senwu","id":5580008,"node_id":"MDQ6VXNlcjU1ODAwMDg=","avatar_url":"https://avatars.githubusercontent.com/u/5580008?v=4","gravatar_id":"","url":"https://api.github.com/users/senwu","html_url":"https://github.com/senwu","followers_url":"https://api.github.com/users/senwu/followers","following_url":"https://api.github.com/users/senwu/following{/other_user}","gists_url":"https://api.github.com/users/senwu/gists{/gist_id}","starred_url":"https://api.github.com/users/senwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/senwu/subscriptions","organizations_url":"https://api.github.com/users/senwu/orgs","repos_url":"https://api.github.com/users/senwu/repos","events_url":"https://api.github.com/users/senwu/events{/privacy}","received_events_url":"https://api.github.com/users/senwu/received_events","type":"User","site_admin":false},"created_at":"2019-05-17T06:39:22Z","updated_at":"2019-05-17T06:39:52Z","author_association":"COLLABORATOR","body":"Hi @atulgupta9,\r\n\r\nThanks for your interests in our research!\r\n\r\nLet me try to answer your questions, and hope it can help to understand more about Fonduer.\r\n\r\n> Is the fonduer prediction pipeline production ready? How can we fine tune it to achieve better accuracy? Should the main focus be on the quality of the extracted mentions?\r\n\r\nWe currently provide two prediction model in Fonduer (Logistic regression, LSTM). You can tune those two models pretty easily and we provide a simple interface for that (see [here](https://github.com/HazyResearch/fonduer/blob/master/src/fonduer/learning/classifier.py#L106)). Of course you can also customize your own prediction model based on your needs (for example if you want to use BERT to extract features, here are some [references](https://github.com/HazyResearch/fonduer/tree/master/src/fonduer/learning/disc_models)).\r\n\r\nIn order to achieve better quality, there are many factors you might want to consider:\r\n(1) do you have good candidates? e.g., the candidate can cover most of the ground truth (or in other words good recall)\r\n(2) do you have good labels for candidates to train? (do those labels have a good correlation with the ground truth?) High-quality label data is very important for a machine learning model to learn a good prediction model.\r\n(3) does the class balance is good? Usually, we expect the data has good class balance. e.g., 50% positive data and 50% negative data.\r\n(4) does the model good for your data? It highly depends on your problem. Our current model tries to incorporate the multi-modality features into the learning model to learn more signals. From our experience and feedback from our collaboration, those signals are pretty useful in extracting information from richly formatted data.\r\n\r\nWe recently published another paper which shares some best practices, you can find it [here](https://sing.stanford.edu/site/publications/hack-lctes19.pdf).\r\n\r\n> How well does fonduer fair when we have documents that differ structurally?\r\n\r\nOne of the design goals of Fonduer is to address the data variety in richly formatted data. In order to address that, we propose to use a unified data model to unify the data with a different structure (like HTML). We are keep improving our data model to handle more cases (we now support plain text, CSV, TSV, HTML, PDF, and etc..).\r\nPlease let us know if you have any suggestion or cases that it doesn't work.\r\n\r\n> Is the main role of the model to predict whether the candidate is a true candidate or not?\r\n\r\nYes, the prediction model is trying to predict the true candidate based on your label data and the useful signal of data.\r\n\r\n> How can we scale this to multiple candidates, does that mean creating separate models for each of those?\r\n\r\nI assume you mean multiple relations (correct me if I am wrong). Right now, Fonduer supports multiple relation candidates extraction, but the learning part only supports a single relation. We will release a new machine learning to support learning multiple relations simultaneously soon.","reactions":{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/493339526/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"senwu","id":5580008,"node_id":"MDQ6VXNlcjU1ODAwMDg=","avatar_url":"https://avatars.githubusercontent.com/u/5580008?v=4","gravatar_id":"","url":"https://api.github.com/users/senwu","html_url":"https://github.com/senwu","followers_url":"https://api.github.com/users/senwu/followers","following_url":"https://api.github.com/users/senwu/following{/other_user}","gists_url":"https://api.github.com/users/senwu/gists{/gist_id}","starred_url":"https://api.github.com/users/senwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/senwu/subscriptions","organizations_url":"https://api.github.com/users/senwu/orgs","repos_url":"https://api.github.com/users/senwu/repos","events_url":"https://api.github.com/users/senwu/events{/privacy}","received_events_url":"https://api.github.com/users/senwu/received_events","type":"User","site_admin":false}},{"id":2348437424,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MjM0ODQzNzQyNA==","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2348437424","actor":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2019-05-17T06:39:22Z","performed_via_github_app":null},{"id":2348437427,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDIzNDg0Mzc0Mjc=","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2348437427","actor":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2019-05-17T06:39:22Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/493348211","html_url":"https://github.com/HazyResearch/fonduer/issues/263#issuecomment-493348211","issue_url":"https://api.github.com/repos/HazyResearch/fonduer/issues/263","id":493348211,"node_id":"MDEyOklzc3VlQ29tbWVudDQ5MzM0ODIxMQ==","user":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false},"created_at":"2019-05-17T07:14:14Z","updated_at":"2019-05-17T07:14:14Z","author_association":"NONE","body":"Thanks @SenWu for a speedy response. It will surely help me proceed forward.\r\n\r\nPlease can we keep this thread open. I will try to post some snippets to let you guys understand the use case we are trying to tackle with fonduer and get your inputs on our approach. ","reactions":{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/493348211/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false}},{"id":2348500238,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MjM0ODUwMDIzOA==","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2348500238","actor":{"login":"senwu","id":5580008,"node_id":"MDQ6VXNlcjU1ODAwMDg=","avatar_url":"https://avatars.githubusercontent.com/u/5580008?v=4","gravatar_id":"","url":"https://api.github.com/users/senwu","html_url":"https://github.com/senwu","followers_url":"https://api.github.com/users/senwu/followers","following_url":"https://api.github.com/users/senwu/following{/other_user}","gists_url":"https://api.github.com/users/senwu/gists{/gist_id}","starred_url":"https://api.github.com/users/senwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/senwu/subscriptions","organizations_url":"https://api.github.com/users/senwu/orgs","repos_url":"https://api.github.com/users/senwu/repos","events_url":"https://api.github.com/users/senwu/events{/privacy}","received_events_url":"https://api.github.com/users/senwu/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2019-05-17T07:14:14Z","performed_via_github_app":null},{"id":2348500241,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDIzNDg1MDAyNDE=","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2348500241","actor":{"login":"senwu","id":5580008,"node_id":"MDQ6VXNlcjU1ODAwMDg=","avatar_url":"https://avatars.githubusercontent.com/u/5580008?v=4","gravatar_id":"","url":"https://api.github.com/users/senwu","html_url":"https://github.com/senwu","followers_url":"https://api.github.com/users/senwu/followers","following_url":"https://api.github.com/users/senwu/following{/other_user}","gists_url":"https://api.github.com/users/senwu/gists{/gist_id}","starred_url":"https://api.github.com/users/senwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/senwu/subscriptions","organizations_url":"https://api.github.com/users/senwu/orgs","repos_url":"https://api.github.com/users/senwu/repos","events_url":"https://api.github.com/users/senwu/events{/privacy}","received_events_url":"https://api.github.com/users/senwu/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2019-05-17T07:14:14Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/493875032","html_url":"https://github.com/HazyResearch/fonduer/issues/263#issuecomment-493875032","issue_url":"https://api.github.com/repos/HazyResearch/fonduer/issues/263","id":493875032,"node_id":"MDEyOklzc3VlQ29tbWVudDQ5Mzg3NTAzMg==","user":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false},"created_at":"2019-05-20T07:46:34Z","updated_at":"2019-05-20T07:46:34Z","author_association":"NONE","body":"### Use Case Discussion\r\nWe have sourced financial documents from the internet, these documents have no definite structure or a repeating pattern. \r\nThe basic need is to extract and build details about the organization (CEO, Board of Directors, Revenue Generated, Net Income/Loss etc..). \r\nThe required information may be spread across the document or may be confined to a few pages which we cannot pinpoint. \r\n\r\nWe will be confining this discussion to the extraction and prediction of revenue terms. Below are some snaps of the documents we are handling. Each snap is of a different document.\r\n![image](https://user-images.githubusercontent.com/16721762/58001429-0f152480-7af9-11e9-87d2-db956aa477d5.png)\r\n![image](https://user-images.githubusercontent.com/16721762/58001432-10dee800-7af9-11e9-9505-eaa72303186b.png)\r\n![image](https://user-images.githubusercontent.com/16721762/58001433-12a8ab80-7af9-11e9-9639-511be533d820.png)\r\n![image](https://user-images.githubusercontent.com/16721762/58001441-150b0580-7af9-11e9-8981-bc8e98770450.png)\r\n\r\nAlthough, the above images reflect a specific structure being followed but we have about 299 documents with many of them containing information in images/running text rather than tables.\r\n\r\nThe entire set is divided as follows:\r\nTrain Set : 180 docs\r\nDev Set :  60 docs\r\nTest Set : 59 docs\r\n\r\n### Code\r\n#### Extracting the mentions\r\nFor extracting the revenue mentions we have captured revenue related tags in a csv and are using it\r\n```\r\nrevenue_mention = mention_subclass(\"revenue_mention\")\r\n\r\nrevenue_tags = set(df['revenue tag'].str.lower().tolist())\r\n\r\ndef filter_revenue_with_tags(mention):    \r\n    for tag in revenue_tags:\r\n        if str(tag).lower().strip() in str(mention.sentence.text).lower():\r\n            return True\r\n    return False   \r\n\r\nfilter1 = LambdaFunctionMatcher(func = filter_revenue_with_tags,longest_match_only=True)\r\nsentence_mentions = MentionSentences()\r\nmention_extractor = MentionExtractor(session, [revenue_mention],[sentence_mentions],[filter1])\r\n```\r\nAfter extraction we got:\r\n`Mentions: 293205`\r\n\r\n#### Getting the candidates\r\nFor candidate extraction , we have further refined those tags and limited it using throttlers.\r\n```\r\nrevenue_cand = candidate_subclass(\"revenue_cand\",[revenue_mention])\r\n\r\ndef filter_revenue_with_keyword(c):\r\n    keywords = ['revenues for the fiscal year','revenue for the fiscal year','revenue for the year','revenues for the year','net earning','net loss','revenue of','revenues of','operating revenue','net sale','record revenue','gross revenue','net revenue','revenue increased','revenues increased','service revenue','present value','sale revenue','sales revenue','total oil and gas sale','consolidated revenue','operating revenue','cost of revenue','sale']\r\n    for keyword in keywords:\r\n        if keyword in str(c[0][0].get_span()).lower():\r\n            if '$' in str(c[0][0].get_span()).lower():\r\n                return True\r\n    return False\r\n\r\ncandidate_extractor_revenue = CandidateExtractor(session, [revenue_cand],throttlers=[filter_revenue_with_keyword])\r\n\r\n\r\nfor i, docs in enumerate([train_docs, dev_docs, test_docs]):\r\n    \r\n    candidate_extractor_revenue.apply(docs, split=i, parallelism=PARALLEL)\r\n    print(\"Number of Candidates in split={}: {}\".format(i, session.query(revenue_cand).filter(revenue_cand.split == i).count()))\r\n\r\ntrain_cands_rev = candidate_extractor_revenue.get_candidates(split = 0)\r\ndev_cands_rev = candidate_extractor_revenue.get_candidates(split = 1)\r\ntest_cands_rev = candidate_extractor_revenue.get_candidates(split = 2)    \r\n```\r\nSo basically we are looking for sentences that contain those keywords, and the $ amount.\r\nThe number of candidates obtained were as follows:\r\n```\r\nTrain Candidates : 2887\r\nDev Candidates: 974\r\nTest Candidates: 1005\r\n```\r\n\r\n#### Featurizer phase\r\n```\r\nfeaturizer_rev = Featurizer(session, [revenue_cand])\r\n\r\n%time featurizer_rev.apply(split=0, train=True,parallelism=PARALLEL)\r\n%time F_train_cands_rev = featurizer_rev.get_feature_matrices(train_cands_rev)\r\nprint(\"Train Candidates shape: {}\".format(F_train_cands_rev[0].shape))\r\n\r\n%time featurizer_rev.apply(split=1, parallelism=PARALLEL)\r\n%time F_dev_cands_rev = featurizer_rev.get_feature_matrices(dev_cands_rev)\r\nprint(\"Dev Candidates shape: {}\".format(F_dev_cands_rev[0].shape))\r\n\r\n%time featurizer_rev.apply(split=2, parallelism=PARALLEL)\r\n%time F_test_cands_rev = featurizer_rev.get_feature_matrices(test_cands_rev)\r\nprint(\"Test Candidates shape: {}\".format(F_test_cands_rev[0].shape))\r\n```\r\nWe got `58531` features for these candidates.\r\n\r\n#### Gold labels generation\r\nCreated our own function to load and store the labels as directed in the hardware tutorial.\r\n**Does this really have any significance in the entire pipeline?**\r\n`load_section_heading_gold_labels(session, [revenue_cand], gold_file, annotator_name='gold')`\r\n\r\n#### Candidate Labelling\r\nIn order to label such varied data, we thought of doing this process manually. So the candidate sentences were taken out and manually labelled.\r\nAt the end of this we had a dictionary of sentences and we used it to mark the true and false candidates.\r\n\r\n```\r\ndef is_revenue(c):\r\n    if c.get_mentions()[0][0].get_span() in labelling_dict:\r\n        if labelling_dict.get(c.get_mentions()[0][0].get_span()):\r\n            return TRUE\r\n        else:\r\n            return FALSE\r\n    return ABSTAIN\r\n```\r\n**We noticed most of the files contained two or three true candidates and most were false candidates. There is a huge disparity in their no. Should this pose a problem? Is abstaining from voting a solution as per 'Automating the Generation of Hardware Component Knowledge Bases' research paper ? What criteria could be used for abstaining from voting (All are manually labelled here) ?**\r\n\r\nThen we ran the generative model to get the train marginals. **Though, I doubt if this is required here as we never abstained from voting.  I am really unclear why this is needed. But since the learning model needed it we used it** \r\n```\r\nlabeler_rev = Labeler(session, [revenue_cand])\r\n\r\n%time labeler_rev.apply(split=0, lfs=[[is_revenue]], train=True, parallelism=PARALLEL)\r\n%time L_train_rev = labeler_rev.get_label_matrices(train_cands_rev)\r\n\r\nL_gold_train_rev = labeler_rev.get_gold_labels(train_cands_rev, annotator = 'gold')\r\nanalysis.lf_summary(L_train_rev[0], lf_names=labeler_rev.get_keys(), Y=L_gold_train_rev[0].todense().reshape(-1,).tolist()[0])\r\n\r\ngen_model = LabelModel(k=2)\r\n%time gen_model.train_model(L_train_rev[0], n_epochs=300, print_every=100)\r\ntrain_marginals_rev = gen_model.predict_proba(L_train_rev[0])\r\n```\r\n\r\n#### Learning Phase\r\nThe model used was Sparse Logistic Regression.\r\n```\r\ndisc_model = SparseLogisticRegression()\r\n# disc_model = LSTM()\r\n%time disc_model.train((train_cands_rev[0], F_train_cands_rev[0]), train_marginals_rev, n_epochs=100, lr=0.001)\r\n```\r\nThe results were not very impressive.\r\nIn our first attempt, with very few candidates\r\n[revenue_pred_299_docs.pdf](https://github.com/HazyResearch/fonduer/files/3196729/revenue_pred_299_docs.pdf)\r\n- Two candidates were identified as true. One TP, One FP.\r\n\r\nIn our second attempt,\r\n- We have improved the keyword list as in this post and are currently working on manually labelling the data.\r\n\r\n### Expectations & Queries\r\n\r\n1.  Can such a use case be handled through fonduer?\r\n2. What could be the bottleneck? Is the number of documents sufficient to cater to what we want?\r\n3. Please suggest, if there is anything you would like us to change in our approach.\r\n4. Please answer the queries raised within each phase.\r\n\r\nSorry for such a long write-up. Please take your time to go through this and help me. Thanks.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/493875032/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/495071155","html_url":"https://github.com/HazyResearch/fonduer/issues/263#issuecomment-495071155","issue_url":"https://api.github.com/repos/HazyResearch/fonduer/issues/263","id":495071155,"node_id":"MDEyOklzc3VlQ29tbWVudDQ5NTA3MTE1NQ==","user":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false},"created_at":"2019-05-23T05:20:17Z","updated_at":"2019-05-23T05:20:17Z","author_association":"NONE","body":"@SenWu @HiromuHota , Can we use the generated feature size as an estimate to predict how the model would  behave? If so, what is an appropriate range within which we can state that the predictions will be good?","reactions":{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/495071155/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false}},{"id":2361274199,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MjM2MTI3NDE5OQ==","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2361274199","actor":{"login":"senwu","id":5580008,"node_id":"MDQ6VXNlcjU1ODAwMDg=","avatar_url":"https://avatars.githubusercontent.com/u/5580008?v=4","gravatar_id":"","url":"https://api.github.com/users/senwu","html_url":"https://github.com/senwu","followers_url":"https://api.github.com/users/senwu/followers","following_url":"https://api.github.com/users/senwu/following{/other_user}","gists_url":"https://api.github.com/users/senwu/gists{/gist_id}","starred_url":"https://api.github.com/users/senwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/senwu/subscriptions","organizations_url":"https://api.github.com/users/senwu/orgs","repos_url":"https://api.github.com/users/senwu/repos","events_url":"https://api.github.com/users/senwu/events{/privacy}","received_events_url":"https://api.github.com/users/senwu/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2019-05-23T05:20:17Z","performed_via_github_app":null},{"id":2361274200,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDIzNjEyNzQyMDA=","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2361274200","actor":{"login":"senwu","id":5580008,"node_id":"MDQ6VXNlcjU1ODAwMDg=","avatar_url":"https://avatars.githubusercontent.com/u/5580008?v=4","gravatar_id":"","url":"https://api.github.com/users/senwu","html_url":"https://github.com/senwu","followers_url":"https://api.github.com/users/senwu/followers","following_url":"https://api.github.com/users/senwu/following{/other_user}","gists_url":"https://api.github.com/users/senwu/gists{/gist_id}","starred_url":"https://api.github.com/users/senwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/senwu/subscriptions","organizations_url":"https://api.github.com/users/senwu/orgs","repos_url":"https://api.github.com/users/senwu/repos","events_url":"https://api.github.com/users/senwu/events{/privacy}","received_events_url":"https://api.github.com/users/senwu/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2019-05-23T05:20:17Z","performed_via_github_app":null},{"id":2361274203,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MjM2MTI3NDIwMw==","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2361274203","actor":{"login":"HiromuHota","id":20668349,"node_id":"MDQ6VXNlcjIwNjY4MzQ5","avatar_url":"https://avatars.githubusercontent.com/u/20668349?v=4","gravatar_id":"","url":"https://api.github.com/users/HiromuHota","html_url":"https://github.com/HiromuHota","followers_url":"https://api.github.com/users/HiromuHota/followers","following_url":"https://api.github.com/users/HiromuHota/following{/other_user}","gists_url":"https://api.github.com/users/HiromuHota/gists{/gist_id}","starred_url":"https://api.github.com/users/HiromuHota/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HiromuHota/subscriptions","organizations_url":"https://api.github.com/users/HiromuHota/orgs","repos_url":"https://api.github.com/users/HiromuHota/repos","events_url":"https://api.github.com/users/HiromuHota/events{/privacy}","received_events_url":"https://api.github.com/users/HiromuHota/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2019-05-23T05:20:17Z","performed_via_github_app":null},{"id":2361274204,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDIzNjEyNzQyMDQ=","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2361274204","actor":{"login":"HiromuHota","id":20668349,"node_id":"MDQ6VXNlcjIwNjY4MzQ5","avatar_url":"https://avatars.githubusercontent.com/u/20668349?v=4","gravatar_id":"","url":"https://api.github.com/users/HiromuHota","html_url":"https://github.com/HiromuHota","followers_url":"https://api.github.com/users/HiromuHota/followers","following_url":"https://api.github.com/users/HiromuHota/following{/other_user}","gists_url":"https://api.github.com/users/HiromuHota/gists{/gist_id}","starred_url":"https://api.github.com/users/HiromuHota/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HiromuHota/subscriptions","organizations_url":"https://api.github.com/users/HiromuHota/orgs","repos_url":"https://api.github.com/users/HiromuHota/repos","events_url":"https://api.github.com/users/HiromuHota/events{/privacy}","received_events_url":"https://api.github.com/users/HiromuHota/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2019-05-23T05:20:17Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/495802804","html_url":"https://github.com/HazyResearch/fonduer/issues/263#issuecomment-495802804","issue_url":"https://api.github.com/repos/HazyResearch/fonduer/issues/263","id":495802804,"node_id":"MDEyOklzc3VlQ29tbWVudDQ5NTgwMjgwNA==","user":{"login":"senwu","id":5580008,"node_id":"MDQ6VXNlcjU1ODAwMDg=","avatar_url":"https://avatars.githubusercontent.com/u/5580008?v=4","gravatar_id":"","url":"https://api.github.com/users/senwu","html_url":"https://github.com/senwu","followers_url":"https://api.github.com/users/senwu/followers","following_url":"https://api.github.com/users/senwu/following{/other_user}","gists_url":"https://api.github.com/users/senwu/gists{/gist_id}","starred_url":"https://api.github.com/users/senwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/senwu/subscriptions","organizations_url":"https://api.github.com/users/senwu/orgs","repos_url":"https://api.github.com/users/senwu/repos","events_url":"https://api.github.com/users/senwu/events{/privacy}","received_events_url":"https://api.github.com/users/senwu/received_events","type":"User","site_admin":false},"created_at":"2019-05-24T22:19:03Z","updated_at":"2019-05-24T22:19:03Z","author_association":"COLLABORATOR","body":"Hi @atulgupta9,\r\n\r\nThanks for the description of your use case and I am sorry for the late response (a lot of dues this week).\r\n\r\nYour problem is a very good example/use case for Fonduer. Let me try to To answer your question here:\r\n\r\n> We noticed most of the files contained two or three true candidates and most were false candidates. There is a huge disparity in their no. Should this pose a problem?\r\n\r\nNo, this is no problem and actually a very common case in extracting knowledge from richly formatted data. One general question you might care is how to generate your candidates since it's super easy to generate many negative candidates and miss positive candidates.\r\n \r\n> Is abstaining from voting a solution as per 'Automating the Generation of Hardware Component Knowledge Bases' research paper? What criteria could be used for abstaining from voting (All are manually labeled here)?\r\n\r\nThis is a good question and very important for the user who wants to provide weak supervisions in our framework. The `abstain` means this rule/pattern is applicable which is saying it's not an indicator for this specific candidate and you don't want to vote it (the system will ignore this candidate when evaluating this rule/pattern). \r\n\r\n> Can such a use case be handled through fonduer?\r\n\r\nYour problem is a very good example/use case for Fonduer.\r\n\r\n> What could be the bottleneck? \r\n\r\nAs I mentioned before, there are several parts you want to consider:\r\n(1) how you generate the mentions/candidates?\r\nYour first attempt to mention/candidate extraction is good, and I think your second attempt can improve them a lot by adding missing ones and filtering mistakes.\r\n(2) how to label them?\r\nBy checking your weak labels, you will have an estimation about the quality of your labels.\r\n(3) does the model can capture the signals?\r\nIn our applications, we think the model incorporates a lot of signals from different modalities and it's a good baseline to have. You might want to add more features for your applications to improve it and Fonduer supports that as well. \r\n\r\n> Is the number of documents sufficient to cater to what we want?\r\n\r\nYes, this is a pretty good example and start point. I will be more powerful if you can add more documents in and let the model learn more.\r\n\r\n> Please suggest, if there is anything you would like us to change in our approach.\r\n\r\nI think for each phrase, you can do a sanity check to make sure it matches your expectation.\r\n\r\n> Can we use the generated feature size as an estimate to predict how the model would behave? If so, what is an appropriate range within which we can state that the predictions will be good?\r\n\r\nThis is a good question, but I don't have the good answer for that. Fonduer generates all multi-modality features based on the feature library from the documents. One thing you can check is that whether the generated features can be a good indicator not.\r\n\r\nSen","reactions":{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/495802804/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"senwu","id":5580008,"node_id":"MDQ6VXNlcjU1ODAwMDg=","avatar_url":"https://avatars.githubusercontent.com/u/5580008?v=4","gravatar_id":"","url":"https://api.github.com/users/senwu","html_url":"https://github.com/senwu","followers_url":"https://api.github.com/users/senwu/followers","following_url":"https://api.github.com/users/senwu/following{/other_user}","gists_url":"https://api.github.com/users/senwu/gists{/gist_id}","starred_url":"https://api.github.com/users/senwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/senwu/subscriptions","organizations_url":"https://api.github.com/users/senwu/orgs","repos_url":"https://api.github.com/users/senwu/repos","events_url":"https://api.github.com/users/senwu/events{/privacy}","received_events_url":"https://api.github.com/users/senwu/received_events","type":"User","site_admin":false}},{"id":2366799594,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MjM2Njc5OTU5NA==","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2366799594","actor":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2019-05-24T22:19:03Z","performed_via_github_app":null},{"id":2366799595,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDIzNjY3OTk1OTU=","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2366799595","actor":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2019-05-24T22:19:03Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/497316184","html_url":"https://github.com/HazyResearch/fonduer/issues/263#issuecomment-497316184","issue_url":"https://api.github.com/repos/HazyResearch/fonduer/issues/263","id":497316184,"node_id":"MDEyOklzc3VlQ29tbWVudDQ5NzMxNjE4NA==","user":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false},"created_at":"2019-05-30T12:43:04Z","updated_at":"2019-05-30T12:43:04Z","author_association":"NONE","body":"Hi @SenWu \r\n\r\nThanks for all the help.  Just want to have your quick thought on this.\r\n\r\nI am using two sessions (Initialized using Fonduer Meta): one for training; other for predictions\r\nAll the processes in the training session happen really quick but while using the other session for prediction it takes a considerable amount of time even to process one file. Can this be resolved?\r\n\r\nShould the previous sessions be terminated before initiating a new one? I guess its something to do with SQLAlchemy.","reactions":{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/497316184/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false}},{"id":2377991185,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MjM3Nzk5MTE4NQ==","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2377991185","actor":{"login":"senwu","id":5580008,"node_id":"MDQ6VXNlcjU1ODAwMDg=","avatar_url":"https://avatars.githubusercontent.com/u/5580008?v=4","gravatar_id":"","url":"https://api.github.com/users/senwu","html_url":"https://github.com/senwu","followers_url":"https://api.github.com/users/senwu/followers","following_url":"https://api.github.com/users/senwu/following{/other_user}","gists_url":"https://api.github.com/users/senwu/gists{/gist_id}","starred_url":"https://api.github.com/users/senwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/senwu/subscriptions","organizations_url":"https://api.github.com/users/senwu/orgs","repos_url":"https://api.github.com/users/senwu/repos","events_url":"https://api.github.com/users/senwu/events{/privacy}","received_events_url":"https://api.github.com/users/senwu/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2019-05-30T12:43:04Z","performed_via_github_app":null},{"id":2377991187,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDIzNzc5OTExODc=","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2377991187","actor":{"login":"senwu","id":5580008,"node_id":"MDQ6VXNlcjU1ODAwMDg=","avatar_url":"https://avatars.githubusercontent.com/u/5580008?v=4","gravatar_id":"","url":"https://api.github.com/users/senwu","html_url":"https://github.com/senwu","followers_url":"https://api.github.com/users/senwu/followers","following_url":"https://api.github.com/users/senwu/following{/other_user}","gists_url":"https://api.github.com/users/senwu/gists{/gist_id}","starred_url":"https://api.github.com/users/senwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/senwu/subscriptions","organizations_url":"https://api.github.com/users/senwu/orgs","repos_url":"https://api.github.com/users/senwu/repos","events_url":"https://api.github.com/users/senwu/events{/privacy}","received_events_url":"https://api.github.com/users/senwu/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2019-05-30T12:43:04Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/505643910","html_url":"https://github.com/HazyResearch/fonduer/issues/263#issuecomment-505643910","issue_url":"https://api.github.com/repos/HazyResearch/fonduer/issues/263","id":505643910,"node_id":"MDEyOklzc3VlQ29tbWVudDUwNTY0MzkxMA==","user":{"login":"senwu","id":5580008,"node_id":"MDQ6VXNlcjU1ODAwMDg=","avatar_url":"https://avatars.githubusercontent.com/u/5580008?v=4","gravatar_id":"","url":"https://api.github.com/users/senwu","html_url":"https://github.com/senwu","followers_url":"https://api.github.com/users/senwu/followers","following_url":"https://api.github.com/users/senwu/following{/other_user}","gists_url":"https://api.github.com/users/senwu/gists{/gist_id}","starred_url":"https://api.github.com/users/senwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/senwu/subscriptions","organizations_url":"https://api.github.com/users/senwu/orgs","repos_url":"https://api.github.com/users/senwu/repos","events_url":"https://api.github.com/users/senwu/events{/privacy}","received_events_url":"https://api.github.com/users/senwu/received_events","type":"User","site_admin":false},"created_at":"2019-06-25T22:18:12Z","updated_at":"2019-06-25T22:18:12Z","author_association":"COLLABORATOR","body":"Hi @atulgupta9,\r\n\r\nSorry for the late response! I think that might be a SQLAlchemy issue about inserting info into database. One potential solution is to reduce the parallelism.\r\n\r\nSen","reactions":{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/505643910/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"senwu","id":5580008,"node_id":"MDQ6VXNlcjU1ODAwMDg=","avatar_url":"https://avatars.githubusercontent.com/u/5580008?v=4","gravatar_id":"","url":"https://api.github.com/users/senwu","html_url":"https://github.com/senwu","followers_url":"https://api.github.com/users/senwu/followers","following_url":"https://api.github.com/users/senwu/following{/other_user}","gists_url":"https://api.github.com/users/senwu/gists{/gist_id}","starred_url":"https://api.github.com/users/senwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/senwu/subscriptions","organizations_url":"https://api.github.com/users/senwu/orgs","repos_url":"https://api.github.com/users/senwu/repos","events_url":"https://api.github.com/users/senwu/events{/privacy}","received_events_url":"https://api.github.com/users/senwu/received_events","type":"User","site_admin":false}},{"id":2439099218,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MjQzOTA5OTIxOA==","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2439099218","actor":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2019-06-25T22:18:12Z","performed_via_github_app":null},{"id":2439099220,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDI0MzkwOTkyMjA=","url":"https://api.github.com/repos/HazyResearch/fonduer/issues/events/2439099220","actor":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2019-06-25T22:18:12Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/515344558","html_url":"https://github.com/HazyResearch/fonduer/issues/263#issuecomment-515344558","issue_url":"https://api.github.com/repos/HazyResearch/fonduer/issues/263","id":515344558,"node_id":"MDEyOklzc3VlQ29tbWVudDUxNTM0NDU1OA==","user":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false},"created_at":"2019-07-26T07:37:23Z","updated_at":"2019-07-26T07:37:23Z","author_association":"NONE","body":"Hi @SenWu @HiromuHota \r\n\r\nGuys, I am trying to build api endpoints for automatically calling the fonduer built in functions.\r\n\r\nI have two separate api endpoints : for mention/candidate extraction and for training.\r\n\r\nThese routes may be called any number of times under different projects. So you can assume that every time the api is called the mentions/candidates and the db we are referring to would be different.\r\n\r\nNow, I have these variables\r\n`candidate_<candidate_name> = candidate_subclass(\"candidate_<candidate_name>\", [mention_<mention_name>])`\r\n\r\nDepending on the number of candidates user has specified. We will have that many variables.\r\n\r\nNow for training the model, I would need these candidates for featurization and labelling.\r\nMy initial thought was that a simple query to the underlying table **candidate_<candidate_name>** would work.\r\n\r\nBut then I realized, that I will have to store either the **candidate_<candidate_name>** variable defined above or the **candiate_extractor** that was defined to get the candidates.\r\n\r\nI tried pickling the **candidate_<candidate_name>** variable but ended up with an error like this\r\n[https://stackoverflow.com/questions/4677012/python-cant-pickle-type-x-attribute-lookup-failed](https://stackoverflow.com/questions/4677012/python-cant-pickle-type-x-attribute-lookup-failed)\r\n\r\nCan you guys help me find a way to do this?\r\nAn easy solution that I thought of was to keep a dictionary in memory. But we will lose it if we restart the application. \r\n\r\nAny help would be appreciated.\r\n\r\nThanks\r\nAtul","reactions":{"url":"https://api.github.com/repos/HazyResearch/fonduer/issues/comments/515344558/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"atulgupta9","id":16721762,"node_id":"MDQ6VXNlcjE2NzIxNzYy","avatar_url":"https://avatars.githubusercontent.com/u/16721762?v=4","gravatar_id":"","url":"https://api.github.com/users/atulgupta9","html_url":"https://github.com/atulgupta9","followers_url":"https://api.github.com/users/atulgupta9/followers","following_url":"https://api.github.com/users/atulgupta9/following{/other_user}","gists_url":"https://api.github.com/users/atulgupta9/gists{/gist_id}","starred_url":"https://api.github.com/users/atulgupta9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atulgupta9/subscriptions","organizations_url":"https://api.github.com/users/atulgupta9/orgs","repos_url":"https://api.github.com/users/atulgupta9/repos","events_url":"https://api.github.com/users/atulgupta9/events{/privacy}","received_events_url":"https://api.github.com/users/atulgupta9/received_events","type":"User","site_admin":false}}]