{"url":"https://api.github.com/repos/dbiir/UER-py/issues/300","repository_url":"https://api.github.com/repos/dbiir/UER-py","labels_url":"https://api.github.com/repos/dbiir/UER-py/issues/300/labels{/name}","comments_url":"https://api.github.com/repos/dbiir/UER-py/issues/300/comments","events_url":"https://api.github.com/repos/dbiir/UER-py/issues/300/events","html_url":"https://github.com/dbiir/UER-py/issues/300","id":1190469331,"node_id":"I_kwDOCsNQKM5G9R7T","number":300,"title":"支持从checkpoint断点训练","user":{"login":"rookiebird","id":17564726,"node_id":"MDQ6VXNlcjE3NTY0NzI2","avatar_url":"https://avatars.githubusercontent.com/u/17564726?v=4","gravatar_id":"","url":"https://api.github.com/users/rookiebird","html_url":"https://github.com/rookiebird","followers_url":"https://api.github.com/users/rookiebird/followers","following_url":"https://api.github.com/users/rookiebird/following{/other_user}","gists_url":"https://api.github.com/users/rookiebird/gists{/gist_id}","starred_url":"https://api.github.com/users/rookiebird/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rookiebird/subscriptions","organizations_url":"https://api.github.com/users/rookiebird/orgs","repos_url":"https://api.github.com/users/rookiebird/repos","events_url":"https://api.github.com/users/rookiebird/events{/privacy}","received_events_url":"https://api.github.com/users/rookiebird/received_events","type":"User","site_admin":false},"labels":[{"id":1312752221,"node_id":"MDU6TGFiZWwxMzEyNzUyMjIx","url":"https://api.github.com/repos/dbiir/UER-py/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2022-04-02T02:35:02Z","updated_at":"2022-06-06T02:23:19Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"想问下UER支持从断点加载模型重新训练吗？ 我设置50w个step的训练， 因为服务器不稳定的原因训练有时会中断，所以我设置了断点保存，然后每次从新训练的时候，都是将pretrain.sh 中的 pretrained_model_path 路径重新设置为断点路径，然后再修改下要训练的step数目。 我的数据大概200w+，使用的是 bert-wwm, 进行mlm训练， batch_size 为 128 ， 现在大概训练了30w个step ，但是准确率只有0.5左右，不知道是不是我哪里操作有问题？， 这个是我pretrain.sh的配置\r\n\r\npython3 pretrain.py --dataset_path dataset.pt \\\r\n                    --vocab_path /data/notebooks/jupyter-notebook/berts/chinese-roberta-wwm-ext/vocab.txt \\\r\n                    --pretrained_model_path save_model/output_model_2.bin-100000 \\\r\n                    --config_path models/bert/base_config.json \\\r\n                    --output_model_path save_model/output_model_2.bin \\\r\n                    --world_size 4 --gpu_ranks 0 1 2 3 --learning_rate 1e-4 \\\r\n                    --whole_word_masking \\\r\n                    --total_steps 200000 --save_checkpoint_steps 50000 \\\r\n                    --data_processor mlm \\\r\n                    --embedding word_pos_seg --encoder transformer --mask fully_visible --target mlm --tie_weights","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dbiir/UER-py/issues/300/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dbiir/UER-py/issues/300/timeline","performed_via_github_app":null,"state_reason":null}