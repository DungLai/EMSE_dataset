{"url":"https://api.github.com/repos/dbiir/UER-py/issues/220","repository_url":"https://api.github.com/repos/dbiir/UER-py","labels_url":"https://api.github.com/repos/dbiir/UER-py/issues/220/labels{/name}","comments_url":"https://api.github.com/repos/dbiir/UER-py/issues/220/comments","events_url":"https://api.github.com/repos/dbiir/UER-py/issues/220/events","html_url":"https://github.com/dbiir/UER-py/issues/220","id":1046644905,"node_id":"I_kwDOCsNQKM4-Yoip","number":220,"title":"关于预训练BART的问题","user":{"login":"caijie12138","id":18359811,"node_id":"MDQ6VXNlcjE4MzU5ODEx","avatar_url":"https://avatars.githubusercontent.com/u/18359811?v=4","gravatar_id":"","url":"https://api.github.com/users/caijie12138","html_url":"https://github.com/caijie12138","followers_url":"https://api.github.com/users/caijie12138/followers","following_url":"https://api.github.com/users/caijie12138/following{/other_user}","gists_url":"https://api.github.com/users/caijie12138/gists{/gist_id}","starred_url":"https://api.github.com/users/caijie12138/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/caijie12138/subscriptions","organizations_url":"https://api.github.com/users/caijie12138/orgs","repos_url":"https://api.github.com/users/caijie12138/repos","events_url":"https://api.github.com/users/caijie12138/events{/privacy}","received_events_url":"https://api.github.com/users/caijie12138/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-11-07T02:40:42Z","updated_at":"2021-12-06T07:46:03Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"您好\r\n我尝试在您发布在huggingface的BART base chinese checkpoint上继续预训练，但是发现训练之后的效果反而更差了。\r\n\r\n\r\n预训练之前：\r\n[{'generated_text': '作 为 电 子 支 付 的 平 台 ， 京 东 绝 对 是 领 先 者 而 如 今 的 刘 强 东 已 经 是 身 价 过 亿 的 老 板 。'}]\r\n\r\n预训练之后：\r\n[{'generated_text': '作 为 电 子 。 电 子 的 平 台 ， 京 东 绝 对 是 领 先 者 。 如 今 的 刘 强 ， 已 经 是 身 价 过 去 的 老 板 。'}]\r\n\r\n但是loss看起来是正常的：\r\n|    15000/  300000 steps| 45762.33 tokens/s| loss    3.85| acc: 0.405\r\n|    20000/  300000 steps| 45768.57 tokens/s| loss    1.86| acc: 0.660\r\n|    25000/  300000 steps| 45703.98 tokens/s| loss    0.86| acc: 0.857\r\n|    30000/  300000 steps| 45733.30 tokens/s| loss    0.62| acc: 0.901\r\n|    35000/  300000 steps| 45730.72 tokens/s| loss    0.53| acc: 0.915\r\n|    40000/  300000 steps| 45734.99 tokens/s| loss    0.46| acc: 0.924\r\n|    45000/  300000 steps| 45734.17 tokens/s| loss    0.42| acc: 0.930\r\n\r\n以下是我的预训练命令：\r\npython3 pretrain.py --dataset_path cluecorpussmall_bart_seq512_dataset.pt \\\r\n\t\t   --pretrained_model_path pytorch_model.bin \\\r\n                    --vocab_path models/google_zh_vocab.txt \\\r\n                    --config_path models/bart/base_config.json \\\r\n                    --output_model_path models/cluecorpussmall_bart_seq512_dataset.bin \\\r\n                    --world_size 4 --gpu_ranks 0 1 2 3 \\\r\n                    --total_steps 30000000 --save_checkpoint_steps 100000 --report_steps 5000 \\\r\n                    --learning_rate 1e-4 --batch_size  \\\r\n                    --span_masking --span_max_length 3 \\\r\n                    --embedding word_pos --tgt_embedding word_pos \\\r\n                    --encoder transformer --mask fully_visible --decoder transformer \\\r\n                    --target bart --tie_weights \\\r\n\t\t   --has_lmtarget_bias\r\n\r\n如果有问题的话，希望您能指出，感激不尽！","closed_by":null,"reactions":{"url":"https://api.github.com/repos/dbiir/UER-py/issues/220/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/dbiir/UER-py/issues/220/timeline","performed_via_github_app":null,"state_reason":null}