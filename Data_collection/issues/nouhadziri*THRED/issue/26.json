{"url":"https://api.github.com/repos/nouhadziri/THRED/issues/26","repository_url":"https://api.github.com/repos/nouhadziri/THRED","labels_url":"https://api.github.com/repos/nouhadziri/THRED/issues/26/labels{/name}","comments_url":"https://api.github.com/repos/nouhadziri/THRED/issues/26/comments","events_url":"https://api.github.com/repos/nouhadziri/THRED/issues/26/events","html_url":"https://github.com/nouhadziri/THRED/issues/26","id":617263642,"node_id":"MDU6SXNzdWU2MTcyNjM2NDI=","number":26,"title":"GPU-Util is low When use multi-GPUs","user":{"login":"LTlitong","id":38782066,"node_id":"MDQ6VXNlcjM4NzgyMDY2","avatar_url":"https://avatars.githubusercontent.com/u/38782066?v=4","gravatar_id":"","url":"https://api.github.com/users/LTlitong","html_url":"https://github.com/LTlitong","followers_url":"https://api.github.com/users/LTlitong/followers","following_url":"https://api.github.com/users/LTlitong/following{/other_user}","gists_url":"https://api.github.com/users/LTlitong/gists{/gist_id}","starred_url":"https://api.github.com/users/LTlitong/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/LTlitong/subscriptions","organizations_url":"https://api.github.com/users/LTlitong/orgs","repos_url":"https://api.github.com/users/LTlitong/repos","events_url":"https://api.github.com/users/LTlitong/events{/privacy}","received_events_url":"https://api.github.com/users/LTlitong/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-05-13T08:46:44Z","updated_at":"2020-05-21T16:49:07Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hello,\r\n\r\nI want to train on multi-GPUs,  and I try 8, 4 and 2 gpus. But the GPU-Util of some gpus are low, almost 0%.  An epoch training time on 8 gpus is almost 20 minutes longer than on a single gpu. \r\n \r\nYour code sets the GPU default num as 4.  But when I try 4 cards, there is also one card's  GPU-Util  always 0%.  There is no 0% GPU-Util on the two cards, but the GPU-Util of one of the cards is still 20%.\r\nThis is GPU Usage when training on 4 cards:\r\n![gpu-util](https://user-images.githubusercontent.com/38782066/81789471-9e032400-9536-11ea-9d44-2a624415a6bc.PNG)\r\n![image](https://user-images.githubusercontent.com/38782066/81789917-3d281b80-9537-11ea-8616-57fd2f9981d8.png)\r\n\r\nI am not very clear about shard.  I want to ask whether need to modify the code to train on multi-GPUs and accelerate the training ?\r\n\r\nLooking forward to your replyÔºÅ\r\n\r\n\r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/nouhadziri/THRED/issues/26/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/nouhadziri/THRED/issues/26/timeline","performed_via_github_app":null,"state_reason":null}