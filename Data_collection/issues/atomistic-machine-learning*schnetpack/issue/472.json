{"url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/472","repository_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack","labels_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/472/labels{/name}","comments_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/472/comments","events_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/472/events","html_url":"https://github.com/atomistic-machine-learning/schnetpack/issues/472","id":1495497883,"node_id":"I_kwDOCMZ5Ls5ZI3yb","number":472,"title":"Error during model fitting: <input> file not found?","user":{"login":"EnoshI","id":44939569,"node_id":"MDQ6VXNlcjQ0OTM5NTY5","avatar_url":"https://avatars.githubusercontent.com/u/44939569?v=4","gravatar_id":"","url":"https://api.github.com/users/EnoshI","html_url":"https://github.com/EnoshI","followers_url":"https://api.github.com/users/EnoshI/followers","following_url":"https://api.github.com/users/EnoshI/following{/other_user}","gists_url":"https://api.github.com/users/EnoshI/gists{/gist_id}","starred_url":"https://api.github.com/users/EnoshI/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/EnoshI/subscriptions","organizations_url":"https://api.github.com/users/EnoshI/orgs","repos_url":"https://api.github.com/users/EnoshI/repos","events_url":"https://api.github.com/users/EnoshI/events{/privacy}","received_events_url":"https://api.github.com/users/EnoshI/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":8,"created_at":"2022-12-14T02:26:00Z","updated_at":"2022-12-21T15:48:41Z","closed_at":"2022-12-21T15:48:41Z","author_association":"NONE","active_lock_reason":null,"body":"So I am working with a custom dataset created with:\r\n```\r\nimport os\r\nimport torch\r\nimport pymatgen\r\nimport numpy as np\r\nimport schnetpack as spk\r\nimport schnetpack.transform as trn\r\nfrom scipy import interpolate\r\nimport matplotlib.pyplot as plt\r\nfrom ase import Atoms\r\nimport numpy as np\r\nfrom schnetpack.datasets import ASEAtomsData\r\nfrom pymatgen.ext.matproj import MPRester\r\n#from mp-api import MPRester\r\nfrom pymatgen.core import Structure\r\n\r\nwith MPRester('Bp0Q8XcNOhuFD2HK') as mpr:\r\n    data = mpr.query(criteria={'has_bandstructure':True,'nelements': 2}, properties = ['task_id',\"structure\",'efermi'])\r\n    dos = {data[0]['task_id']: mpr.get_dos_by_material_id(data[0]['task_id'])}\r\n    new_eleDOS = {data[0]['task_id']:1}\r\n    elemental_dos = {data[0]['task_id']:1}\r\n    #eleDOS_unshifted = {data[0]['task_id']:1}\r\n    for i in range(3): # len(data)\r\n        dos[data[i]['task_id']] = mpr.get_dos_by_material_id(data[i]['task_id'])\r\n        elemental_dos[data[i]['task_id']] = dos[data[i]['task_id']].get_element_dos()\r\n        #eleDOS_unshifted[data[i]['task_id']] = dos[data[i]['task_id']].get_element_dos()\r\n        for elem in elemental_dos[data[i]['task_id']]:\r\n            elemental_dos[data[i]['task_id']][elem].energies = elemental_dos[data[i]['task_id']][elem].energies - data[i]['efermi']\r\n\r\n        xnew = np.arange(-10.2, 0.2, 0.1)\r\n        for elem in elemental_dos[data[i]['task_id']]:\r\n            total = []\r\n            spin1 = []\r\n            spin2 = []\r\n            for spin in elemental_dos[data[i]['task_id']][elem].densities:\r\n                if spin.value == 1:\r\n                    for density in elemental_dos[data[i]['task_id']][elem].densities[spin]:\r\n                        spin1.append(density)\r\n                else:\r\n                    for density in elemental_dos[data[i]['task_id']][elem].densities[spin]:\r\n                        spin2.append(density)\r\n            if len(spin2) == 0:\r\n                total = np.array(spin1)\r\n            else:\r\n                total = np.array(spin1) + np.array(spin2)\r\n            elemental_dos[data[i]['task_id']][elem].densities['total'] = total\r\n            y = elemental_dos[data[i]['task_id']][elem].densities['total']\r\n            tck = interpolate.splrep(elemental_dos[data[i]['task_id']][elem].energies, y, s=0)\r\n            elemental_dos[data[i]['task_id']][elem].densities['SplInterpE'] = xnew\r\n            elemental_dos[data[i]['task_id']][elem].densities['SplInterpDOS'] = interpolate.splev(xnew, tck, der=0)\r\n\r\n        tally = 0\r\n        for j in elemental_dos[data[i]['task_id']]:\r\n            if tally == 0:\r\n                temp = {j.symbol: elemental_dos[data[i]['task_id']][j]}\r\n                tally = 1\r\n            else:\r\n                temp[j.symbol] = elemental_dos[data[i]['task_id']][j]\r\n        new_eleDOS[data[i]['task_id']] = temp\r\n\r\n    #for spin in elemental_dos[data[i]['task_id']][elem].densities:\r\n    #    spins.append(spin)\r\n    #x = elemental_dos[data[i]['task_id']][elem].energies\r\n    #y = elemental_dos[data[i]['task_id']][elem].densities[spins[0]]\r\n    #tck = interpolate.splrep(x, y, s=0)\r\n    #xnew = np.arange(-11,1,0.1)\r\n    #ynew = interpolate.splev(xnew, tck, der=0)\r\n\r\n    #plt.figure()\r\n    #plt.plot(x, y, 'x', xnew, ynew, x, y, 'b')\r\n    #plt.legend(['Linear', 'Cubic Spline', 'True'])\r\n    #plt.axis([-0.05, 6.33, -1.05, 1.05])\r\n    #plt.title('Cubic-spline interpolation of DOS')\r\n    #plt.show()\r\n\r\n    atms = {data[0]['task_id']:1}\r\n    for i in range(3): # len(data)\r\n        s = data[i]['structure']\r\n        atms[data[i]['task_id']] = Atoms(numbers=s.atomic_numbers, positions=s.cart_coords, cell=s.lattice.matrix, pbc=True,)\r\n\r\n    del temp\r\n    del i\r\n    del j\r\n    del tally\r\natoms_list,properties_list = [],[]\r\nfor at in atms:\r\n    atoms_list.append(atms[at])\r\n\r\nfor m in elemental_dos:\r\n    properties = {}\r\n    properties['atom_numbers'] = []\r\n    properties['DOS'] = []\r\n    #properties['pDOS'] = []\r\n    track = 1\r\n    for elem in elemental_dos[m]:\r\n        if track == 1:\r\n            properties['energy_levels'] = np.array(elemental_dos[m][elem].densities['SplInterpE'])\r\n            properties['DOS'].append(elemental_dos[m][elem].densities['SplInterpDOS'])\r\n            #for n in new_eleDOS[m][elem].densities:\r\n                #properties['pDOS'].append(np.array(new_eleDOS[m][elem].densities[n]))\r\n            track = 0\r\n        else:\r\n            properties['DOS'].append(elemental_dos[m][elem].densities['SplInterpDOS'])\r\n            #for n in new_eleDOS[m][elem].densities:\r\n                #properties['pDOS'].append(np.array(new_eleDOS[m][elem].densities[n]))\r\n        properties['atom_numbers'].append(elem.number)\r\n    properties['atom_numbers'] = np.array(properties['atom_numbers'])\r\n    properties['DOS'] = np.matrix(properties['DOS'])\r\n    #properties['pDOS'] = np.array(properties['pDOS'])\r\n    properties_list.append(properties)\r\ndataset = ASEAtomsData.create('./testn1.db',distance_unit='Ang',transforms = [\r\n        trn.ASENeighborList(cutoff=5.),trn.CastTo32(),trn.AddOffsets(dataset, add_mean=True, add_atomrefs=True)\r\n                                        ], property_unit_dict={'energy_levels':'eV',\r\n                                                             'DOS':'states/eV/atom',\r\n                                                             'atom_numbers':'number'})\r\ndataset.add_systems(properties_list,atoms_list)\r\n```\r\n\r\n\r\nI am also using a custom loss function module that is required for the way I'm handling my data outputs:\r\n```\r\nfrom torch.nn.modules.loss import _Loss\r\nfrom torch import Tensor\r\nclass dos_loss(_Loss):\r\n    def __init__(self, size_average=None, reduce=None) -> None:\r\n        super(dos_loss, self).__init__(size_average, reduce)\r\n\r\n    def forward(self, input: Tensor, target: Tensor) -> Tensor:\r\n        return loss_fn(input, target)\r\n\r\n    def loss_fn(output, true):\r\n        def mse(actual, pred):\r\n            return torch.square(torch.subtract(actual, pred)).mean()\r\n\r\n        loss = 0\r\n        try:\r\n            for i in range(len(true)):\r\n                for elem in range(len(true[i]['atom_numbers'])):\r\n                    pred_dos = output[i]['scalar_representation'][\r\n                        true[i]['_atomic_numbers'] == true[i]['atom_numbers'][elem]].sum(axis=0)\r\n                    loss += mse(true[i]['DOS'][elem], pred_dos)\r\n        except:\r\n            for elem in range(len(true['atom_numbers'])):\r\n                pred_dos = output['scalar_representation'][true['_atomic_numbers'] == true['atom_numbers'][elem]].sum(\r\n                    axis=0)\r\n                loss += mse(true['DOS'][elem], pred_dos)\r\n        # except:\r\n        # loss= 10\r\n        return loss\r\n```\r\n\r\nand finally, I am getting an error during the model training where it is searching for some <input> file during the last line:\r\n```\r\nimport os\r\nimport torch\r\nimport torchmetrics\r\nimport schnetpack as spk\r\nimport schnetpack.transform as trn\r\nimport pytorch_lightning as pl\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nfrom schnetpack.data.datamodule import AtomsDataModule\r\nfrom Test import dos_loss as customLoss\r\n\r\nresults = dataset\r\n\r\npDOSdata = './pDOSdata'\r\n#qm9tut = './qm9tut'\r\nif not os.path.exists(pDOSdata):\r\n    os.makedirs(pDOSdata)\r\n\r\npDOS_data = AtomsDataModule(\r\n    './testn1.db',\r\n    batch_size= 1,\r\n    num_train=1,\r\n    num_val=1,\r\n    transforms=[\r\n        trn.ASENeighborList(cutoff=5.),\r\n        trn.CastTo32()\r\n    ],\r\n    split_file=os.path.join(pDOSdata, \"split.npz\")\r\n)\r\npDOS_data.prepare_data()\r\npDOS_data.setup()\r\n\r\n#test_data = dict([(a,b.float()) if b.dtype==torch.float64 else (a,b) for a,b in dataset[0].items()])\r\n\r\ncutoff = 5.0\r\nn_atom_basis = 104\r\n\r\npairwise_distance = spk.atomistic.PairwiseDistances() # calculates pairwise distances between atoms\r\nradial_basis = spk.nn.GaussianRBF(n_rbf=20, cutoff=cutoff)\r\nschnet = spk.representation.SchNet(\r\n    n_atom_basis=n_atom_basis, n_interactions=3,\r\n    radial_basis=radial_basis,\r\n    cutoff_fn=spk.nn.CosineCutoff(cutoff)\r\n)\r\n\r\npred_DOS = spk.atomistic.Atomwise(n_in=n_atom_basis, output_key=results)\r\n\r\nnnpot = spk.model.NeuralNetworkPotential(\r\n    representation=schnet,\r\n    input_modules=[pairwise_distance],\r\n    output_modules=[pred_DOS],\r\n    postprocessors=[trn.CastTo64()]\r\n)\r\n\r\noutput_DOS = spk.task.ModelOutput(\r\n    name=results,\r\n    loss_fn=customLoss(),\r\n    loss_weight=1.,\r\n    metrics={\r\n        \"MAE\": torchmetrics.MeanAbsoluteError()\r\n    }\r\n)\r\n\r\ntask = spk.task.AtomisticTask(\r\n    model=nnpot,\r\n    outputs=[output_DOS],\r\n    optimizer_cls=torch.optim.AdamW,\r\n    optimizer_args={\"lr\": 1e-4}\r\n)\r\n\r\nlogger = pl.loggers.TensorBoardLogger(save_dir=pDOSdata)\r\ncallbacks = [\r\n    spk.train.ModelCheckpoint(\r\n        model_path=os.path.join(pdostut, \"best_inference_model\"),\r\n        save_top_k=1,\r\n        monitor=\"val_loss\"\r\n    )\r\n]\r\n\r\ntrainer = pl.Trainer(\r\n    callbacks=callbacks,\r\n    logger=None,\r\n    default_root_dir=pDOSdata,\r\n    max_epochs=3, # for testing, we restrict the number of epochs\r\n)\r\ntrainer.fit(task, datamodule=pDOS_data)\r\n```\r\n\r\nI'm getting an error that says: \r\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/enosh/PycharmProjects/DOS_model/<input>'\r\n","closed_by":{"login":"Stefaanhess","id":23171261,"node_id":"MDQ6VXNlcjIzMTcxMjYx","avatar_url":"https://avatars.githubusercontent.com/u/23171261?v=4","gravatar_id":"","url":"https://api.github.com/users/Stefaanhess","html_url":"https://github.com/Stefaanhess","followers_url":"https://api.github.com/users/Stefaanhess/followers","following_url":"https://api.github.com/users/Stefaanhess/following{/other_user}","gists_url":"https://api.github.com/users/Stefaanhess/gists{/gist_id}","starred_url":"https://api.github.com/users/Stefaanhess/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Stefaanhess/subscriptions","organizations_url":"https://api.github.com/users/Stefaanhess/orgs","repos_url":"https://api.github.com/users/Stefaanhess/repos","events_url":"https://api.github.com/users/Stefaanhess/events{/privacy}","received_events_url":"https://api.github.com/users/Stefaanhess/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/472/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/472/timeline","performed_via_github_app":null,"state_reason":"completed"}