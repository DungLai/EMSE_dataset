{"url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/155","repository_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack","labels_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/155/labels{/name}","comments_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/155/comments","events_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/155/events","html_url":"https://github.com/atomistic-machine-learning/schnetpack/issues/155","id":479194599,"node_id":"MDU6SXNzdWU0NzkxOTQ1OTk=","number":155,"title":"Slow Training","user":{"login":"jwz-ecust","id":16930052,"node_id":"MDQ6VXNlcjE2OTMwMDUy","avatar_url":"https://avatars.githubusercontent.com/u/16930052?v=4","gravatar_id":"","url":"https://api.github.com/users/jwz-ecust","html_url":"https://github.com/jwz-ecust","followers_url":"https://api.github.com/users/jwz-ecust/followers","following_url":"https://api.github.com/users/jwz-ecust/following{/other_user}","gists_url":"https://api.github.com/users/jwz-ecust/gists{/gist_id}","starred_url":"https://api.github.com/users/jwz-ecust/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jwz-ecust/subscriptions","organizations_url":"https://api.github.com/users/jwz-ecust/orgs","repos_url":"https://api.github.com/users/jwz-ecust/repos","events_url":"https://api.github.com/users/jwz-ecust/events{/privacy}","received_events_url":"https://api.github.com/users/jwz-ecust/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2019-08-09T22:57:48Z","updated_at":"2019-08-12T10:31:01Z","closed_at":"2019-08-12T10:31:01Z","author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\nI am appreciated for the NN framework. I have used SchNet in my dataset (clusters, 20-100 atoms). I found the training process is too slow (training: 100,000, almost three days' training) and the most time is spent on data loader. Is there any methods to accelerate the data loader? I have tried the [prefetcher](https://github.com/NVIDIA/apex/issues/304) but there is no obvious promotion. \r\n\r\nConfiguration list\r\n- platform: ubuntu 16.04\r\n- gtx 1080ti\r\n- i5 8400\r\n\r\nHere is the [prefetcher code](https://github.com/jwz-ecust/schnetpack/blob/dev/src/schnetpack/datasets/cluster.py)\r\n\r\nThanks!\r\n\r\nJiawei Zhang","closed_by":{"login":"ktschuett","id":6585114,"node_id":"MDQ6VXNlcjY1ODUxMTQ=","avatar_url":"https://avatars.githubusercontent.com/u/6585114?v=4","gravatar_id":"","url":"https://api.github.com/users/ktschuett","html_url":"https://github.com/ktschuett","followers_url":"https://api.github.com/users/ktschuett/followers","following_url":"https://api.github.com/users/ktschuett/following{/other_user}","gists_url":"https://api.github.com/users/ktschuett/gists{/gist_id}","starred_url":"https://api.github.com/users/ktschuett/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ktschuett/subscriptions","organizations_url":"https://api.github.com/users/ktschuett/orgs","repos_url":"https://api.github.com/users/ktschuett/repos","events_url":"https://api.github.com/users/ktschuett/events{/privacy}","received_events_url":"https://api.github.com/users/ktschuett/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/155/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/155/timeline","performed_via_github_app":null,"state_reason":"completed"}