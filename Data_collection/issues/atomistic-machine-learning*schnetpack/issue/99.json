{"url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/99","repository_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack","labels_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/99/labels{/name}","comments_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/99/comments","events_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/99/events","html_url":"https://github.com/atomistic-machine-learning/schnetpack/issues/99","id":435928422,"node_id":"MDU6SXNzdWU0MzU5Mjg0MjI=","number":99,"title":"CUDA memory issue during optimization","user":{"login":"xiaowei-xie","id":44622421,"node_id":"MDQ6VXNlcjQ0NjIyNDIx","avatar_url":"https://avatars.githubusercontent.com/u/44622421?v=4","gravatar_id":"","url":"https://api.github.com/users/xiaowei-xie","html_url":"https://github.com/xiaowei-xie","followers_url":"https://api.github.com/users/xiaowei-xie/followers","following_url":"https://api.github.com/users/xiaowei-xie/following{/other_user}","gists_url":"https://api.github.com/users/xiaowei-xie/gists{/gist_id}","starred_url":"https://api.github.com/users/xiaowei-xie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xiaowei-xie/subscriptions","organizations_url":"https://api.github.com/users/xiaowei-xie/orgs","repos_url":"https://api.github.com/users/xiaowei-xie/repos","events_url":"https://api.github.com/users/xiaowei-xie/events{/privacy}","received_events_url":"https://api.github.com/users/xiaowei-xie/received_events","type":"User","site_admin":false},"labels":[{"id":1044272344,"node_id":"MDU6TGFiZWwxMDQ0MjcyMzQ0","url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/labels/question","name":"question","color":"d876e3","default":true,"description":"Not a bug report, but a question or other problem"}],"state":"closed","locked":false,"assignee":{"login":"Stefaanhess","id":23171261,"node_id":"MDQ6VXNlcjIzMTcxMjYx","avatar_url":"https://avatars.githubusercontent.com/u/23171261?v=4","gravatar_id":"","url":"https://api.github.com/users/Stefaanhess","html_url":"https://github.com/Stefaanhess","followers_url":"https://api.github.com/users/Stefaanhess/followers","following_url":"https://api.github.com/users/Stefaanhess/following{/other_user}","gists_url":"https://api.github.com/users/Stefaanhess/gists{/gist_id}","starred_url":"https://api.github.com/users/Stefaanhess/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Stefaanhess/subscriptions","organizations_url":"https://api.github.com/users/Stefaanhess/orgs","repos_url":"https://api.github.com/users/Stefaanhess/repos","events_url":"https://api.github.com/users/Stefaanhess/events{/privacy}","received_events_url":"https://api.github.com/users/Stefaanhess/received_events","type":"User","site_admin":false},"assignees":[{"login":"Stefaanhess","id":23171261,"node_id":"MDQ6VXNlcjIzMTcxMjYx","avatar_url":"https://avatars.githubusercontent.com/u/23171261?v=4","gravatar_id":"","url":"https://api.github.com/users/Stefaanhess","html_url":"https://github.com/Stefaanhess","followers_url":"https://api.github.com/users/Stefaanhess/followers","following_url":"https://api.github.com/users/Stefaanhess/following{/other_user}","gists_url":"https://api.github.com/users/Stefaanhess/gists{/gist_id}","starred_url":"https://api.github.com/users/Stefaanhess/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Stefaanhess/subscriptions","organizations_url":"https://api.github.com/users/Stefaanhess/orgs","repos_url":"https://api.github.com/users/Stefaanhess/repos","events_url":"https://api.github.com/users/Stefaanhess/events{/privacy}","received_events_url":"https://api.github.com/users/Stefaanhess/received_events","type":"User","site_admin":false}],"milestone":null,"comments":6,"created_at":"2019-04-22T23:05:40Z","updated_at":"2019-04-25T08:32:24Z","closed_at":"2019-04-24T13:11:50Z","author_association":"NONE","active_lock_reason":null,"body":"I have been training on various size water clusters and trying to optimize a water 256 using the trained model. The training process worked fine, but when I try to optimize, I always get the following CUDA memory error. When I run on CPU, the optimization is pretty slow(5min per step). I would like to ask, is the requirement of this much memory a legitimate thing and what is causing it so memory intensive? Or do you have any idea what might went wrong?\r\nThank you in advance for any help your could possibly provide!\r\n\r\nTraceback (most recent call last):\r\n  File \"optimize_water_256_wacsf.py\", line 15, in <module>\r\n    print(\"forces:\", atoms.get_forces())\r\n  File \"/home/xiaowei/.local/lib/python3.6/site-packages/ase/atoms.py\", line 714, in get_forces\r\n    forces = self._calc.get_forces(self)\r\n  File \"/home/xiaowei/.local/lib/python3.6/site-packages/ase/calculators/calculator.py\", line 519, in get_forces\r\n    return self.get_property('forces', atoms)\r\n  File \"/home/xiaowei/.local/lib/python3.6/site-packages/ase/calculators/calculator.py\", line 552, in get_property\r\n    self.calculate(atoms, [name], system_changes)\r\n  File \"/home/xiaowei/miniconda3/lib/python3.6/site-packages/schnetpack-0.2.1-py3.6.egg/schnetpack/ase_interface.py\", line 92, in calculate\r\n  File \"/home/xiaowei/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 494, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/xiaowei/miniconda3/lib/python3.6/site-packages/schnetpack-0.2.1-py3.6.egg/schnetpack/atomistic.py\", line 61, in forward\r\n  File \"/home/xiaowei/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 494, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/xiaowei/miniconda3/lib/python3.6/site-packages/schnetpack-0.2.1-py3.6.egg/schnetpack/representation/hdnn.py\", line 366, in forward\r\n  File \"/home/xiaowei/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 494, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/xiaowei/miniconda3/lib/python3.6/site-packages/schnetpack-0.2.1-py3.6.egg/schnetpack/representation/hdnn.py\", line 238, in forward\r\n  File \"/home/xiaowei/miniconda3/lib/python3.6/site-packages/schnetpack-0.2.1-py3.6.egg/schnetpack/nn/neighbors.py\", line 204, in neighbor_elements\r\nRuntimeError: CUDA out of memory. Tried to allocate 1.68 GiB (GPU 0; 7.77 GiB total capacity; 6.02 GiB already allocated; 648.62 MiB free; 17.94 MiB cached)\r\n\r\nThe following is the code I have been using to run optimization.\r\n\r\nimport torch\r\nfrom schnetpack.ase_interface import SpkCalculator\r\nfrom ase import Atoms\r\nfrom ase.io import read\r\nfrom ase.optimize import BFGS\r\n\r\npath_to_model = \"XX_water_wacsf/best_model\"\r\nmodel = torch.load(path_to_model)\r\n\r\natoms = read('water_256.xyz')\r\ncalc = SpkCalculator(model, device=\"cuda\")\r\natoms.set_calculator(calc)\r\nprint(\"forces:\", atoms.get_forces())\r\nprint(\"total_energy\", atoms.get_potential_energy())\r\ndyn = BFGS(atoms,trajectory='water_256_opt_BFGS_wacsf.traj',restart='water_256_opt_BFGS_wacsf.pckl')\r\ndyn.run(fmax=0.05)\r\n\r\n\r\n\r\n","closed_by":{"login":"ktschuett","id":6585114,"node_id":"MDQ6VXNlcjY1ODUxMTQ=","avatar_url":"https://avatars.githubusercontent.com/u/6585114?v=4","gravatar_id":"","url":"https://api.github.com/users/ktschuett","html_url":"https://github.com/ktschuett","followers_url":"https://api.github.com/users/ktschuett/followers","following_url":"https://api.github.com/users/ktschuett/following{/other_user}","gists_url":"https://api.github.com/users/ktschuett/gists{/gist_id}","starred_url":"https://api.github.com/users/ktschuett/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ktschuett/subscriptions","organizations_url":"https://api.github.com/users/ktschuett/orgs","repos_url":"https://api.github.com/users/ktschuett/repos","events_url":"https://api.github.com/users/ktschuett/events{/privacy}","received_events_url":"https://api.github.com/users/ktschuett/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/99/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/99/timeline","performed_via_github_app":null,"state_reason":"completed"}