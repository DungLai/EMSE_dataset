{"url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/95","repository_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack","labels_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/95/labels{/name}","comments_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/95/comments","events_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/95/events","html_url":"https://github.com/atomistic-machine-learning/schnetpack/issues/95","id":429363348,"node_id":"MDU6SXNzdWU0MjkzNjMzNDg=","number":95,"title":"Scalability of SchNet","user":{"login":"Dom1L","id":20482947,"node_id":"MDQ6VXNlcjIwNDgyOTQ3","avatar_url":"https://avatars.githubusercontent.com/u/20482947?v=4","gravatar_id":"","url":"https://api.github.com/users/Dom1L","html_url":"https://github.com/Dom1L","followers_url":"https://api.github.com/users/Dom1L/followers","following_url":"https://api.github.com/users/Dom1L/following{/other_user}","gists_url":"https://api.github.com/users/Dom1L/gists{/gist_id}","starred_url":"https://api.github.com/users/Dom1L/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Dom1L/subscriptions","organizations_url":"https://api.github.com/users/Dom1L/orgs","repos_url":"https://api.github.com/users/Dom1L/repos","events_url":"https://api.github.com/users/Dom1L/events{/privacy}","received_events_url":"https://api.github.com/users/Dom1L/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2019-04-04T16:06:10Z","updated_at":"2019-04-04T16:19:02Z","closed_at":"2019-04-04T16:19:02Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Hi guys,\r\n\r\nI was playing around with the package and wanted to know what the limits of SchNet are. So I tried to feed a protein (trypsin, 1700 atoms) into the network using the default settings and ran into some Cuda out of memory errors (TitanV 12GB).\r\nI tried to scale the features, number of interactions blocks etc. down while using a batch size of 1 and still did not get it to work. \r\nSo what is your experience with the scalability of this network? Do you think it is due to the model itself (including distance matrices, features, rbf etc.), the implementation (optimizing it a bit more) or did I approach it wrong?\r\n\r\nIn case you want to reproduce it, I made a small script and a  .db file including 100x trypsin with a dummy energy value.\r\n\r\nThanks for your help and this nice package.\r\n\r\n```python\r\nimport torch\r\nimport torch.nn.functional as F\r\nfrom torch.optim import Adam\r\n\r\nimport schnetpack as spk\r\nfrom schnetpack.data import AtomsData\r\nimport schnetpack.atomistic as atm\r\nimport schnetpack.representation as rep\r\n\r\ndata = AtomsData('3ptb.db', properties=['energy'])\r\n\r\n# split in train and val\r\ntrain, val, test = data.create_splits(80, 20)\r\nloader = spk.data.AtomsLoader(train, batch_size=1, num_workers=1)\r\nval_loader = spk.data.AtomsLoader(val)\r\n\r\n# create model\r\nreps = rep.SchNet(\r\n    n_atom_basis=32,\r\n    n_filters=128,\r\n    n_interactions=1,\r\n    cutoff=5.0,\r\n    n_gaussians=25,\r\n    normalize_filter=False,\r\n    coupled_interactions=True,\r\n    return_intermediate=False,\r\n    max_z=100,\r\n    trainable_gaussians=False,\r\n    distance_expansion=None)\r\noutput = atm.Atomwise()\r\nmodel = atm.AtomisticModel(reps, output).cuda()\r\n\r\nopt = Adam(model.parameters(), lr=1e-4)\r\nloss = lambda b, p: F.mse_loss(p[\"y\"], b['energy'])\r\ntrainer = spk.train.Trainer(\"output/\", model, loss, opt, loader, val_loader)\r\n\r\ntrainer.train(torch.device(\"cuda\"))\r\n```\r\n[3ptbdb.zip](https://github.com/atomistic-machine-learning/schnetpack/files/3044397/3ptbdb.zip)\r\n\r\n","closed_by":{"login":"ktschuett","id":6585114,"node_id":"MDQ6VXNlcjY1ODUxMTQ=","avatar_url":"https://avatars.githubusercontent.com/u/6585114?v=4","gravatar_id":"","url":"https://api.github.com/users/ktschuett","html_url":"https://github.com/ktschuett","followers_url":"https://api.github.com/users/ktschuett/followers","following_url":"https://api.github.com/users/ktschuett/following{/other_user}","gists_url":"https://api.github.com/users/ktschuett/gists{/gist_id}","starred_url":"https://api.github.com/users/ktschuett/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ktschuett/subscriptions","organizations_url":"https://api.github.com/users/ktschuett/orgs","repos_url":"https://api.github.com/users/ktschuett/repos","events_url":"https://api.github.com/users/ktschuett/events{/privacy}","received_events_url":"https://api.github.com/users/ktschuett/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/95/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/atomistic-machine-learning/schnetpack/issues/95/timeline","performed_via_github_app":null,"state_reason":"completed"}