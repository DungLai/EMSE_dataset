{"url":"https://api.github.com/repos/Stick-To/CenterNet-tensorflow/issues/18","repository_url":"https://api.github.com/repos/Stick-To/CenterNet-tensorflow","labels_url":"https://api.github.com/repos/Stick-To/CenterNet-tensorflow/issues/18/labels{/name}","comments_url":"https://api.github.com/repos/Stick-To/CenterNet-tensorflow/issues/18/comments","events_url":"https://api.github.com/repos/Stick-To/CenterNet-tensorflow/issues/18/events","html_url":"https://github.com/Stick-To/CenterNet-tensorflow/issues/18","id":494383844,"node_id":"MDU6SXNzdWU0OTQzODM4NDQ=","number":18,"title":"When I was using estimator with your model,  Global step not increased,always was 0.","user":{"login":"YangYangGirl","id":32426369,"node_id":"MDQ6VXNlcjMyNDI2MzY5","avatar_url":"https://avatars.githubusercontent.com/u/32426369?v=4","gravatar_id":"","url":"https://api.github.com/users/YangYangGirl","html_url":"https://github.com/YangYangGirl","followers_url":"https://api.github.com/users/YangYangGirl/followers","following_url":"https://api.github.com/users/YangYangGirl/following{/other_user}","gists_url":"https://api.github.com/users/YangYangGirl/gists{/gist_id}","starred_url":"https://api.github.com/users/YangYangGirl/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/YangYangGirl/subscriptions","organizations_url":"https://api.github.com/users/YangYangGirl/orgs","repos_url":"https://api.github.com/users/YangYangGirl/repos","events_url":"https://api.github.com/users/YangYangGirl/events{/privacy}","received_events_url":"https://api.github.com/users/YangYangGirl/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":12,"created_at":"2019-09-17T03:42:50Z","updated_at":"2019-09-18T10:51:51Z","closed_at":"2019-09-18T10:51:51Z","author_association":"NONE","active_lock_reason":null,"body":"![image](https://user-images.githubusercontent.com/32426369/65009652-0cf49280-d940-11e9-8d44-470c98d5b530.png)\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport sys\r\nimport os\r\n\r\ndef estimator_model_fn(features, labels, mode, params):\r\n    img = features['img']\r\n    model = CenterNet(params['config'], params['is_train'])\r\n    if mode == tf.estimator.ModeKeys.EVAL:\r\n        model.build_whole_network(img, labels)\r\n        print(\"======== loss =========\")\r\n        print(loss)\r\n        loss = model.loss\r\n        return tf.estimator.EstimatorSpec(mode, loss=loss)\r\n\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        model.build_whole_network(img, labels)\r\n        loss = model.loss\r\n        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\r\n\r\n        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n        if update_ops:\r\n            with tf.control_dependencies(update_ops):\r\n                train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\r\n                return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        final_bbox, final_scores, final_category = model.build_whole_network(img, None)\r\n        predictions = {\r\n            'predict_boxes': model.detection_pred[1],\r\n            'predict_scores': model.detection_pred[0],\r\n            'predict_category': model.detection_pred[2]\r\n        }\r\n        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\r\n\r\nclass CenterNet:\r\n    def __init__(self, config = {}, is_training=True):\r\n        self.is_training = is_training  # 是否训练\r\n        self.config = config\r\n        assert config['mode'] in ['train', 'test']\r\n        assert config['data_format'] in ['channels_first', 'channels_last']\r\n        self.config = config\r\n        self.input_size = config['input_size']\r\n        if config['data_format'] == 'channels_last':\r\n            self.data_shape = [self.input_size, self.input_size, 3]\r\n        else:\r\n            self.data_shape = [3, self.input_size, self.input_size]\r\n        self.num_classes = config['num_classes']\r\n        self.weight_decay = config['weight_decay']\r\n        self.prob = 1. - config['keep_prob']\r\n        self.data_format = config['data_format']\r\n        self.mode = config['mode']\r\n        self.batch_size = config['batch_size'] if config['mode'] == 'train' else 1\r\n\r\n        if self.mode != 'train':\r\n            self.score_threshold = config['score_threshold']\r\n            self.top_k_results_output = config['top_k_results_output']\r\n\r\n        #self.global_step = tf.get_variable(name='global_step', initializer=tf.constant(0), trainable=False)\r\n        #self.is_training = True\r\n\r\n    def build_whole_network(self, input_image_batch, gtboxes_batch=None):\r\n        #print(\"input_image_batch\", input_image_batch)\r\n        if self.is_training:\r\n            print(\"=====is_training======\")\r\n            print(gtboxes_batch)\r\n            gtboxes_batch = tf.reshape(gtboxes_batch, [1, -1, 5])  # 最后一个维度为类别\r\n            gtboxes_batch = tf.cast(gtboxes_batch, tf.float32)\r\n\r\n        img_shape = tf.shape(input_image_batch)\r\n\r\n        with tf.variable_scope('backone'):\r\n            conv = self._conv_bn_activation(\r\n                bottom=input_image_batch,\r\n                filters=16,\r\n                kernel_size=7,\r\n                strides=1,\r\n            )\r\n            conv = self._conv_bn_activation(\r\n                bottom=conv,\r\n                filters=16,\r\n                kernel_size=3,\r\n                strides=1,\r\n            )\r\n            conv = self._conv_bn_activation(\r\n                bottom=conv,\r\n                filters=32,\r\n                kernel_size=3,\r\n                strides=2,\r\n            )\r\n            dla_stage3 = self._dla_generator(conv, 64, 1, self._basic_block)\r\n            dla_stage3 = self._max_pooling(dla_stage3, 2, 2)\r\n\r\n            dla_stage4 = self._dla_generator(dla_stage3, 128, 2, self._basic_block)\r\n            residual = self._conv_bn_activation(dla_stage3, 128, 1, 1)\r\n            residual = self._avg_pooling(residual, 2, 2)\r\n            dla_stage4 = self._max_pooling(dla_stage4, 2, 2)\r\n            dla_stage4 = dla_stage4 + residual\r\n\r\n            dla_stage5 = self._dla_generator(dla_stage4, 256, 2, self._basic_block)\r\n            residual = self._conv_bn_activation(dla_stage4, 256, 1, 1)\r\n            residual = self._avg_pooling(residual, 2, 2)\r\n            dla_stage5 = self._max_pooling(dla_stage5, 2, 2)\r\n            dla_stage5 = dla_stage5 + residual\r\n\r\n            dla_stage6 = self._dla_generator(dla_stage5, 512, 1, self._basic_block)\r\n            residual = self._conv_bn_activation(dla_stage5, 512, 1, 1)\r\n            residual = self._avg_pooling(residual, 2, 2)\r\n            dla_stage6 = self._max_pooling(dla_stage6, 2, 2)\r\n            dla_stage6 = dla_stage6 + residual\r\n        with tf.variable_scope('upsampling'):\r\n            dla_stage6 = self._conv_bn_activation(dla_stage6, 256, 1, 1)\r\n            dla_stage6_5 = self._dconv_bn_activation(dla_stage6, 256, 4, 2)\r\n            dla_stage6_4 = self._dconv_bn_activation(dla_stage6_5, 256, 4, 2)\r\n            dla_stage6_3 = self._dconv_bn_activation(dla_stage6_4, 256, 4, 2)\r\n\r\n            dla_stage5 = self._conv_bn_activation(dla_stage5, 256, 1, 1)\r\n            #print(\"--- dla_stage5, dla_stage6_5 ---\")\r\n            #print(dla_stage5, dla_stage6_5)\r\n            dla_stage5_4 = self._conv_bn_activation(dla_stage5 + dla_stage6_5, 256, 3, 1)\r\n            dla_stage5_4 = self._dconv_bn_activation(dla_stage5_4, 256, 4, 2)\r\n            dla_stage5_3 = self._dconv_bn_activation(dla_stage5_4, 256, 4, 2)\r\n\r\n            dla_stage4 = self._conv_bn_activation(dla_stage4, 256, 1, 1)\r\n            dla_stage4_3 = self._conv_bn_activation(dla_stage4 + dla_stage5_4 + dla_stage6_4, 256, 3, 1)\r\n            dla_stage4_3 = self._dconv_bn_activation(dla_stage4_3, 256, 4, 2)\r\n\r\n            features = self._conv_bn_activation(dla_stage6_3 + dla_stage5_3 + dla_stage4_3, 256, 3, 1)\r\n            features = self._conv_bn_activation(features, 256, 1, 1)\r\n            stride = 4.0\r\n\r\n        with tf.variable_scope('center_detector'):\r\n            keypoints = self._conv_bn_activation(features, self.num_classes, 3, 1, None)\r\n            offset = self._conv_bn_activation(features, 2, 3, 1, None)\r\n            size = self._conv_bn_activation(features, 2, 3, 1, None)\r\n            if self.data_format == 'channels_first':\r\n                keypoints = tf.transpose(keypoints, [0, 2, 3, 1])\r\n                offset = tf.transpose(offset, [0, 2, 3, 1])\r\n                size = tf.transpose(size, [0, 2, 3, 1])\r\n            pshape = [tf.shape(offset)[1], tf.shape(offset)[2]]\r\n\r\n            h = tf.range(0., tf.cast(pshape[0], tf.float32), dtype=tf.float32)\r\n            w = tf.range(0., tf.cast(pshape[1], tf.float32), dtype=tf.float32)\r\n            [meshgrid_x, meshgrid_y] = tf.meshgrid(w, h)\r\n            if self.mode == 'train':\r\n                total_loss = []\r\n                print(\"---------------------\")\r\n                print(\"keypoints\", keypoints)\r\n                print(\"gtboxes_batch\", gtboxes_batch)\r\n                for i in range(self.batch_size):\r\n                    loss = self._compute_one_image_loss(keypoints[i, ...], offset[i, ...], size[i, ...],\r\n                                                        gtboxes_batch[i], meshgrid_y, meshgrid_x,\r\n                                                        stride, pshape)\r\n                    total_loss.append(loss)\r\n\r\n                #self.loss = total_loss[0]# +\r\n                self.loss = self.weight_decay * tf.add_n([tf.nn.l2_loss(var) for var in tf.trainable_variables()])\r\n                #self.loss = tf.ones([2], dtype=tf.float32)[0]\r\n            else:\r\n                keypoints = tf.sigmoid(keypoints)\r\n                meshgrid_y = tf.expand_dims(meshgrid_y, axis=-1)\r\n                meshgrid_x = tf.expand_dims(meshgrid_x, axis=-1)\r\n                center = tf.concat([meshgrid_y, meshgrid_x], axis=-1)\r\n                category = tf.expand_dims(tf.squeeze(tf.argmax(keypoints, axis=-1, output_type=tf.int32)), axis=-1)\r\n                meshgrid_xyz = tf.concat([tf.zeros_like(category), tf.cast(center, tf.int32), category], axis=-1)\r\n                keypoints = tf.gather_nd(keypoints, meshgrid_xyz)\r\n                keypoints = tf.expand_dims(keypoints, axis=0)\r\n                keypoints = tf.expand_dims(keypoints, axis=-1)\r\n                keypoints_peak = self._max_pooling(keypoints, 3, 1)\r\n                keypoints_mask = tf.cast(tf.equal(keypoints, keypoints_peak), tf.float32)\r\n                keypoints = keypoints * keypoints_mask\r\n                scores = tf.reshape(keypoints, [-1])\r\n                class_id = tf.reshape(category, [-1])\r\n                bbox_yx = tf.reshape(center + offset, [-1, 2])\r\n                bbox_hw = tf.reshape(size, [-1, 2])\r\n                score_mask = scores > self.score_threshold\r\n                scores = tf.boolean_mask(scores, score_mask)\r\n                class_id = tf.boolean_mask(class_id, score_mask)\r\n                bbox_yx = tf.boolean_mask(bbox_yx, score_mask)\r\n                bbox_hw = tf.boolean_mask(bbox_hw, score_mask)\r\n                bbox = tf.concat([bbox_yx - bbox_hw / 2., bbox_yx + bbox_hw / 2.], axis=-1) * stride\r\n                num_select = tf.cond(tf.shape(scores)[0] > self.top_k_results_output, lambda: self.top_k_results_output,\r\n                                     lambda: tf.shape(scores)[0])\r\n                select_scores, select_indices = tf.nn.top_k(scores, num_select)\r\n                select_class_id = tf.gather(class_id, select_indices)\r\n                select_bbox = tf.gather(bbox, select_indices)\r\n                self.detection_pred = [select_scores, select_bbox, select_class_id]\r\n\r\n\r\n    def _define_inputs(self):\r\n        shape = [self.batch_size]\r\n        shape.extend(self.data_shape)\r\n        mean = tf.convert_to_tensor([0.485, 0.456, 0.406], dtype=tf.float32)\r\n        std = tf.convert_to_tensor([0.229, 0.224, 0.225], dtype=tf.float32)\r\n        if self.data_format == 'channels_last':\r\n            mean = tf.reshape(mean, [1, 1, 1, 3])\r\n            std = tf.reshape(std, [1, 1, 1, 3])\r\n        else:\r\n            mean = tf.reshape(mean, [1, 3, 1, 1])\r\n            std = tf.reshape(std, [1, 3, 1, 1])\r\n        if self.mode == 'train':\r\n            self.images, self.ground_truth = self.train_iterator.get_next()\r\n            print(\"load ground_truth.shape\", self.ground_truth)\r\n            self.images.set_shape(shape)\r\n            self.images = (self.images / 255. - mean) / std\r\n        else:\r\n            self.images = tf.placeholder(tf.float32, shape, name='images')\r\n            self.images = (self.images / 255. - mean) / std\r\n            self.ground_truth = tf.placeholder(tf.float32, [self.batch_size, None, 5], name='labels')\r\n        self.lr = tf.placeholder(dtype=tf.float32, shape=[], name='lr')\r\n\r\n    def _compute_one_image_loss(self, keypoints, offset, size, ground_truth, meshgrid_y, meshgrid_x,\r\n                                stride, pshape):\r\n        #ground_truth = tf.reshape(ground_truth, [-1, 5])\r\n        print(\"reshape to [1, 5] ground_truth\", ground_truth)\r\n        #slice_index = tf.argmin(ground_truth, axis=0)[0]\r\n        #ground_truth = tf.gather(ground_truth, tf.range(0, slice_index, dtype=tf.int64))\r\n        ngbbox_y = ground_truth[..., 0] / stride\r\n        ngbbox_x = ground_truth[..., 1] / stride\r\n        ngbbox_h = ground_truth[..., 2] / stride\r\n        ngbbox_w = ground_truth[..., 3] / stride\r\n        class_id = tf.cast(ground_truth[..., 4], dtype=tf.int32)\r\n        ngbbox_yx = ground_truth[..., 0:2] / stride\r\n        ngbbox_yx_round = tf.floor(ngbbox_yx)\r\n        offset_gt = ngbbox_yx - ngbbox_yx_round\r\n        size_gt = ground_truth[..., 2:4] / stride\r\n        ngbbox_yx_round_int = tf.cast(ngbbox_yx_round, tf.int64)\r\n        keypoints_loss = self._keypoints_loss(keypoints, ngbbox_yx_round_int, ngbbox_y, ngbbox_x, ngbbox_h,\r\n                                              ngbbox_w, class_id, meshgrid_y, meshgrid_x, pshape)\r\n\r\n        offset = tf.gather_nd(offset, ngbbox_yx_round_int)\r\n        size = tf.gather_nd(size, ngbbox_yx_round_int)\r\n        offset_loss = tf.reduce_mean(tf.abs(offset_gt - offset))\r\n        size_loss = tf.reduce_mean(tf.abs(size_gt - size))\r\n        total_loss = keypoints_loss + 0.1*size_loss + offset_loss\r\n        print(\"=================================\")\r\n        print(\"total_loss\", total_loss)\r\n        return total_loss\r\n        #return 0.1\r\n\r\n    def _keypoints_loss(self, keypoints, gbbox_yx, gbbox_y, gbbox_x, gbbox_h, gbbox_w,\r\n                        classid, meshgrid_y, meshgrid_x, pshape):\r\n        sigma = self._gaussian_radius(gbbox_h, gbbox_w, 0.7)\r\n        gbbox_y = tf.reshape(gbbox_y, [-1, 1, 1])\r\n        gbbox_x = tf.reshape(gbbox_x, [-1, 1, 1])\r\n        sigma = tf.reshape(sigma, [-1, 1, 1])\r\n\r\n        num_g = tf.shape(gbbox_y)[0]\r\n        meshgrid_y = tf.expand_dims(meshgrid_y, 0)\r\n        meshgrid_y = tf.tile(meshgrid_y, [num_g, 1, 1])\r\n        meshgrid_x = tf.expand_dims(meshgrid_x, 0)\r\n        meshgrid_x = tf.tile(meshgrid_x, [num_g, 1, 1])\r\n\r\n        keyp_penalty_reduce = tf.exp(-((gbbox_y-meshgrid_y)**2 + (gbbox_x-meshgrid_x)**2)/(2*sigma**2))\r\n        zero_like_keyp = tf.expand_dims(tf.zeros(pshape, dtype=tf.float32), axis=-1)\r\n        reduction = []\r\n        gt_keypoints = []\r\n        for i in range(self.num_classes):\r\n            exist_i = tf.equal(classid, i)\r\n            reduce_i = tf.boolean_mask(keyp_penalty_reduce, exist_i, axis=0)\r\n            reduce_i = tf.cond(\r\n                tf.equal(tf.shape(reduce_i)[0], 0),\r\n                lambda: zero_like_keyp,\r\n                lambda: tf.expand_dims(tf.reduce_max(reduce_i, axis=0), axis=-1)\r\n            )\r\n            reduction.append(reduce_i)\r\n\r\n            gbbox_yx_i = tf.boolean_mask(gbbox_yx, exist_i)\r\n            gt_keypoints_i = tf.cond(\r\n                tf.equal(tf.shape(gbbox_yx_i)[0], 0),\r\n                lambda: zero_like_keyp,\r\n                lambda: tf.expand_dims(tf.sparse.to_dense(tf.sparse.SparseTensor(gbbox_yx_i, tf.ones_like(gbbox_yx_i[..., 0], tf.float32), dense_shape=pshape), validate_indices=False),\r\n                                       axis=-1)\r\n            )\r\n            gt_keypoints.append(gt_keypoints_i)\r\n        reduction = tf.concat(reduction, axis=-1)\r\n        gt_keypoints = tf.concat(gt_keypoints, axis=-1)\r\n        keypoints_pos_loss = -tf.pow(1.-tf.sigmoid(keypoints), 2.) * tf.log_sigmoid(keypoints) * gt_keypoints\r\n        keypoints_neg_loss = -tf.pow(1.-reduction, 4) * tf.pow(tf.sigmoid(keypoints), 2.) * (-keypoints+tf.log_sigmoid(keypoints)) * (1.-gt_keypoints)\r\n        keypoints_loss = tf.reduce_sum(keypoints_pos_loss) / tf.cast(num_g, tf.float32) + tf.reduce_sum(keypoints_neg_loss) / tf.cast(num_g, tf.float32)\r\n        return keypoints_loss\r\n\r\n    # from cornernet\r\n    def _gaussian_radius(self, height, width, min_overlap=0.7):\r\n        a1 = 1.\r\n        b1 = (height + width)\r\n        c1 = width * height * (1. - min_overlap) / (1. + min_overlap)\r\n        sq1 = tf.sqrt(b1 ** 2. - 4. * a1 * c1)\r\n        r1 = (b1 + sq1) / 2.\r\n        a2 = 4.\r\n        b2 = 2. * (height + width)\r\n        c2 = (1. - min_overlap) * width * height\r\n        sq2 = tf.sqrt(b2 ** 2. - 4. * a2 * c2)\r\n        r2 = (b2 + sq2) / 2.\r\n        a3 = 4. * min_overlap\r\n        b3 = -2. * min_overlap * (height + width)\r\n        c3 = (min_overlap - 1.) * width * height\r\n        sq3 = tf.sqrt(b3 ** 2. - 4. * a3 * c3)\r\n        r3 = (b3 + sq3) / 2.\r\n        return tf.reduce_min([r1, r2, r3])\r\n\r\n    def _create_summary(self):\r\n        with tf.variable_scope('summaries'):\r\n            tf.summary.scalar('loss', self.loss)\r\n            self.summary_op = tf.summary.merge_all()\r\n\r\n    '''def load_weight(self, path):\r\n        self.saver.restore(self.sess, path)\r\n        print('load weight', path, 'successfully')\r\n\r\n    def load_pretrained_weight(self, path):\r\n        self.pretrained_saver.restore(self.sess, path)\r\n        print('load pretrained weight', path, 'successfully')\r\n    '''\r\n\r\n    def _bn(self, bottom):\r\n        bn = tf.layers.batch_normalization(\r\n            inputs=bottom,\r\n            axis=3 if self.data_format == 'channels_last' else 1,\r\n            training=self.is_training\r\n        )\r\n        return bn\r\n\r\n    def _conv_bn_activation(self, bottom, filters, kernel_size, strides, activation=tf.nn.relu):\r\n        conv = tf.layers.conv2d(\r\n            inputs=bottom,\r\n            filters=filters,\r\n            kernel_size=kernel_size,\r\n            strides=strides,\r\n            padding='same',\r\n            data_format=self.data_format\r\n        )\r\n        bn = self._bn(conv)\r\n        if activation is not None:\r\n            return activation(bn)\r\n        else:\r\n            return bn\r\n\r\n    def _dconv_bn_activation(self, bottom, filters, kernel_size, strides, activation=tf.nn.relu):\r\n        conv = tf.layers.conv2d_transpose(\r\n            inputs=bottom,\r\n            filters=filters,\r\n            kernel_size=kernel_size,\r\n            strides=strides,\r\n            padding='same',\r\n            data_format=self.data_format,\r\n        )\r\n        bn = self._bn(conv)\r\n        if activation is not None:\r\n            bn = activation(bn)\r\n        return bn\r\n\r\n    def _separable_conv_layer(self, bottom, filters, kernel_size, strides, activation=tf.nn.relu):\r\n        conv = tf.layers.separable_conv2d(\r\n            inputs=bottom,\r\n            filters=filters,\r\n            kernel_size=kernel_size,\r\n            strides=strides,\r\n            padding='same',\r\n            data_format=self.data_format,\r\n            use_bias=False,\r\n        )\r\n        bn = self._bn(conv)\r\n        if activation is not None:\r\n            bn = activation(bn)\r\n        return bn\r\n\r\n    def _basic_block(self, bottom, filters):\r\n        conv = self._conv_bn_activation(bottom, filters, 3, 1)\r\n        conv = self._conv_bn_activation(conv, filters, 3, 1)\r\n        axis = 3 if self.data_format == 'channels_last' else 1\r\n        input_channels = tf.shape(bottom)[axis]\r\n        shutcut = tf.cond(\r\n            tf.equal(input_channels, filters),\r\n            lambda: bottom,\r\n            lambda: self._conv_bn_activation(bottom, filters, 1, 1)\r\n        )\r\n        return conv + shutcut\r\n\r\n    def _dla_generator(self, bottom, filters, levels, stack_block_fn):\r\n        if levels == 1:\r\n            block1 = stack_block_fn(bottom, filters)\r\n            block2 = stack_block_fn(block1, filters)\r\n            aggregation = block1 + block2\r\n            aggregation = self._conv_bn_activation(aggregation, filters, 3, 1)\r\n        else:\r\n            block1 = self._dla_generator(bottom, filters, levels-1, stack_block_fn)\r\n            block2 = self._dla_generator(block1, filters, levels-1, stack_block_fn)\r\n            aggregation = block1 + block2\r\n            aggregation = self._conv_bn_activation(aggregation, filters, 3, 1)\r\n        return aggregation\r\n\r\n    def _max_pooling(self, bottom, pool_size, strides, name=None):\r\n        return tf.layers.max_pooling2d(\r\n            inputs=bottom,\r\n            pool_size=pool_size,\r\n            strides=strides,\r\n            padding='same',\r\n            data_format=self.data_format,\r\n            name=name\r\n        )\r\n\r\n    def _avg_pooling(self, bottom, pool_size, strides, name=None):\r\n        return tf.layers.average_pooling2d(\r\n            inputs=bottom,\r\n            pool_size=pool_size,\r\n            strides=strides,\r\n            padding='same',\r\n            data_format=self.data_format,\r\n            name=name\r\n        )\r\n\r\n    def _dropout(self, bottom, name):\r\n        return tf.layers.dropout(\r\n            inputs=bottom,\r\n            rate=self.prob,\r\n            training=self.is_training,\r\n            name=name\r\n        )\r\n```","closed_by":{"login":"Stick-To","id":34546552,"node_id":"MDQ6VXNlcjM0NTQ2NTUy","avatar_url":"https://avatars.githubusercontent.com/u/34546552?v=4","gravatar_id":"","url":"https://api.github.com/users/Stick-To","html_url":"https://github.com/Stick-To","followers_url":"https://api.github.com/users/Stick-To/followers","following_url":"https://api.github.com/users/Stick-To/following{/other_user}","gists_url":"https://api.github.com/users/Stick-To/gists{/gist_id}","starred_url":"https://api.github.com/users/Stick-To/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Stick-To/subscriptions","organizations_url":"https://api.github.com/users/Stick-To/orgs","repos_url":"https://api.github.com/users/Stick-To/repos","events_url":"https://api.github.com/users/Stick-To/events{/privacy}","received_events_url":"https://api.github.com/users/Stick-To/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/Stick-To/CenterNet-tensorflow/issues/18/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/Stick-To/CenterNet-tensorflow/issues/18/timeline","performed_via_github_app":null,"state_reason":"completed"}