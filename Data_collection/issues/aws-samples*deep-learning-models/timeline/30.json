[{"url":"https://api.github.com/repos/aws-samples/deep-learning-models/issues/comments/670022195","html_url":"https://github.com/aws-samples/deep-learning-models/issues/30#issuecomment-670022195","issue_url":"https://api.github.com/repos/aws-samples/deep-learning-models/issues/30","id":670022195,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MDAyMjE5NQ==","user":{"login":"jarednielsen","id":4564897,"node_id":"MDQ6VXNlcjQ1NjQ4OTc=","avatar_url":"https://avatars.githubusercontent.com/u/4564897?v=4","gravatar_id":"","url":"https://api.github.com/users/jarednielsen","html_url":"https://github.com/jarednielsen","followers_url":"https://api.github.com/users/jarednielsen/followers","following_url":"https://api.github.com/users/jarednielsen/following{/other_user}","gists_url":"https://api.github.com/users/jarednielsen/gists{/gist_id}","starred_url":"https://api.github.com/users/jarednielsen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jarednielsen/subscriptions","organizations_url":"https://api.github.com/users/jarednielsen/orgs","repos_url":"https://api.github.com/users/jarednielsen/repos","events_url":"https://api.github.com/users/jarednielsen/events{/privacy}","received_events_url":"https://api.github.com/users/jarednielsen/received_events","type":"User","site_admin":false},"created_at":"2020-08-06T16:05:37Z","updated_at":"2020-08-06T16:05:37Z","author_association":"CONTRIBUTOR","body":"What is your tokenizers version?","reactions":{"url":"https://api.github.com/repos/aws-samples/deep-learning-models/issues/comments/670022195/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"jarednielsen","id":4564897,"node_id":"MDQ6VXNlcjQ1NjQ4OTc=","avatar_url":"https://avatars.githubusercontent.com/u/4564897?v=4","gravatar_id":"","url":"https://api.github.com/users/jarednielsen","html_url":"https://github.com/jarednielsen","followers_url":"https://api.github.com/users/jarednielsen/followers","following_url":"https://api.github.com/users/jarednielsen/following{/other_user}","gists_url":"https://api.github.com/users/jarednielsen/gists{/gist_id}","starred_url":"https://api.github.com/users/jarednielsen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jarednielsen/subscriptions","organizations_url":"https://api.github.com/users/jarednielsen/orgs","repos_url":"https://api.github.com/users/jarednielsen/repos","events_url":"https://api.github.com/users/jarednielsen/events{/privacy}","received_events_url":"https://api.github.com/users/jarednielsen/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/aws-samples/deep-learning-models/issues/comments/670839330","html_url":"https://github.com/aws-samples/deep-learning-models/issues/30#issuecomment-670839330","issue_url":"https://api.github.com/repos/aws-samples/deep-learning-models/issues/30","id":670839330,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MDgzOTMzMA==","user":{"login":"yunzhongOvO","id":37217083,"node_id":"MDQ6VXNlcjM3MjE3MDgz","avatar_url":"https://avatars.githubusercontent.com/u/37217083?v=4","gravatar_id":"","url":"https://api.github.com/users/yunzhongOvO","html_url":"https://github.com/yunzhongOvO","followers_url":"https://api.github.com/users/yunzhongOvO/followers","following_url":"https://api.github.com/users/yunzhongOvO/following{/other_user}","gists_url":"https://api.github.com/users/yunzhongOvO/gists{/gist_id}","starred_url":"https://api.github.com/users/yunzhongOvO/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yunzhongOvO/subscriptions","organizations_url":"https://api.github.com/users/yunzhongOvO/orgs","repos_url":"https://api.github.com/users/yunzhongOvO/repos","events_url":"https://api.github.com/users/yunzhongOvO/events{/privacy}","received_events_url":"https://api.github.com/users/yunzhongOvO/received_events","type":"User","site_admin":false},"created_at":"2020-08-08T07:35:48Z","updated_at":"2020-08-08T07:35:48Z","author_association":"NONE","body":"> What is your tokenizers version?\r\n\r\nwhat does \"tokenizers\" mean？Do I need to install it specifically？\r\n\r\nwhat‘s more， I also got errors when transforming wikibooks and wikipedia  to tfrecords:\r\n```\r\n$python3 -m preprocess --dataset=wikibooks --shards=2048 --processes=64 --cache_dir=/data/bert_train/wikibooks --tfrecords_dir=/data/bert_train/wikibooks_512seq/\r\n\r\n2020-08-08 15:21:29.765348: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\nLoading dataset: wikibooks\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/huzhongzhe/deep-learning-models/models/nlp/common/preprocess.py\", line 113, in <module>\r\n    dset_wikipedia._data = dset_wikipedia.data.cast(dset_books.schema)\r\nAttributeError: 'Dataset' object has no attribute 'schema'\r\n```\r\n```\r\n$ python3 -m preprocess --dataset=wikipedia --shards=2048 --processes=64 --cache_dir=/data/bert_train/wikipedia --tfrecords_dir=/data/bert_train/wikipedia_512seq/\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/huzhongzhe/deep-learning-models/models/nlp/common/preprocess.py\", line 127, in <module>\r\n    load_from_cache_file=load_from_cache_file,\r\n  File \"/home/huzhongzhe/.local/lib/python3.6/site-packages/nlp/arrow_dataset.py\", line 1064, in filter\r\n    verbose=verbose,\r\n  File \"/home/huzhongzhe/.local/lib/python3.6/site-packages/nlp/arrow_dataset.py\", line 960, in map\r\n    writer.write_batch(batch)\r\n  File \"/home/huzhongzhe/.local/lib/python3.6/site-packages/nlp/arrow_writer.py\", line 190, in write_batch\r\n    pa_table: pa.Table = pa.Table.from_pydict(batch_examples, schema=self._schema)\r\n  File \"pyarrow/types.pxi\", line 933, in __iter__\r\nKeyError: \"The passed mapping doesn't contain the following field(s) of the schema: title\"\r\n```\r\n ","reactions":{"url":"https://api.github.com/repos/aws-samples/deep-learning-models/issues/comments/670839330/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"yunzhongOvO","id":37217083,"node_id":"MDQ6VXNlcjM3MjE3MDgz","avatar_url":"https://avatars.githubusercontent.com/u/37217083?v=4","gravatar_id":"","url":"https://api.github.com/users/yunzhongOvO","html_url":"https://github.com/yunzhongOvO","followers_url":"https://api.github.com/users/yunzhongOvO/followers","following_url":"https://api.github.com/users/yunzhongOvO/following{/other_user}","gists_url":"https://api.github.com/users/yunzhongOvO/gists{/gist_id}","starred_url":"https://api.github.com/users/yunzhongOvO/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yunzhongOvO/subscriptions","organizations_url":"https://api.github.com/users/yunzhongOvO/orgs","repos_url":"https://api.github.com/users/yunzhongOvO/repos","events_url":"https://api.github.com/users/yunzhongOvO/events{/privacy}","received_events_url":"https://api.github.com/users/yunzhongOvO/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/aws-samples/deep-learning-models/issues/comments/670937831","html_url":"https://github.com/aws-samples/deep-learning-models/issues/30#issuecomment-670937831","issue_url":"https://api.github.com/repos/aws-samples/deep-learning-models/issues/30","id":670937831,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MDkzNzgzMQ==","user":{"login":"yunzhongOvO","id":37217083,"node_id":"MDQ6VXNlcjM3MjE3MDgz","avatar_url":"https://avatars.githubusercontent.com/u/37217083?v=4","gravatar_id":"","url":"https://api.github.com/users/yunzhongOvO","html_url":"https://github.com/yunzhongOvO","followers_url":"https://api.github.com/users/yunzhongOvO/followers","following_url":"https://api.github.com/users/yunzhongOvO/following{/other_user}","gists_url":"https://api.github.com/users/yunzhongOvO/gists{/gist_id}","starred_url":"https://api.github.com/users/yunzhongOvO/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yunzhongOvO/subscriptions","organizations_url":"https://api.github.com/users/yunzhongOvO/orgs","repos_url":"https://api.github.com/users/yunzhongOvO/repos","events_url":"https://api.github.com/users/yunzhongOvO/events{/privacy}","received_events_url":"https://api.github.com/users/yunzhongOvO/received_events","type":"User","site_admin":false},"created_at":"2020-08-08T14:51:37Z","updated_at":"2020-08-08T14:51:37Z","author_association":"NONE","body":"> > What is your tokenizers version?\r\n> \r\n> what does \"tokenizers\" mean？Do I need to install it specifically？\r\n> \r\n> what‘s more， I also got errors when transforming wikibooks and wikipedia to tfrecords:\r\n> \r\n> ```\r\n> $python3 -m preprocess --dataset=wikibooks --shards=2048 --processes=64 --cache_dir=/data/bert_train/wikibooks --tfrecords_dir=/data/bert_train/wikibooks_512seq/\r\n> \r\n> 2020-08-08 15:21:29.765348: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n> Loading dataset: wikibooks\r\n> Traceback (most recent call last):\r\n>   File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n>     \"__main__\", mod_spec)\r\n>   File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n>     exec(code, run_globals)\r\n>   File \"/home/huzhongzhe/deep-learning-models/models/nlp/common/preprocess.py\", line 113, in <module>\r\n>     dset_wikipedia._data = dset_wikipedia.data.cast(dset_books.schema)\r\n> AttributeError: 'Dataset' object has no attribute 'schema'\r\n> ```\r\n> \r\n> ```\r\n> $ python3 -m preprocess --dataset=wikipedia --shards=2048 --processes=64 --cache_dir=/data/bert_train/wikipedia --tfrecords_dir=/data/bert_train/wikipedia_512seq/\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n>     \"__main__\", mod_spec)\r\n>   File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n>     exec(code, run_globals)\r\n>   File \"/home/huzhongzhe/deep-learning-models/models/nlp/common/preprocess.py\", line 127, in <module>\r\n>     load_from_cache_file=load_from_cache_file,\r\n>   File \"/home/huzhongzhe/.local/lib/python3.6/site-packages/nlp/arrow_dataset.py\", line 1064, in filter\r\n>     verbose=verbose,\r\n>   File \"/home/huzhongzhe/.local/lib/python3.6/site-packages/nlp/arrow_dataset.py\", line 960, in map\r\n>     writer.write_batch(batch)\r\n>   File \"/home/huzhongzhe/.local/lib/python3.6/site-packages/nlp/arrow_writer.py\", line 190, in write_batch\r\n>     pa_table: pa.Table = pa.Table.from_pydict(batch_examples, schema=self._schema)\r\n>   File \"pyarrow/types.pxi\", line 933, in __iter__\r\n> KeyError: \"The passed mapping doesn't contain the following field(s) of the schema: title\"\r\n> ```\r\n\r\nI figured out the tokenizers  version is  0.8.1rc1","reactions":{"url":"https://api.github.com/repos/aws-samples/deep-learning-models/issues/comments/670937831/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"yunzhongOvO","id":37217083,"node_id":"MDQ6VXNlcjM3MjE3MDgz","avatar_url":"https://avatars.githubusercontent.com/u/37217083?v=4","gravatar_id":"","url":"https://api.github.com/users/yunzhongOvO","html_url":"https://github.com/yunzhongOvO","followers_url":"https://api.github.com/users/yunzhongOvO/followers","following_url":"https://api.github.com/users/yunzhongOvO/following{/other_user}","gists_url":"https://api.github.com/users/yunzhongOvO/gists{/gist_id}","starred_url":"https://api.github.com/users/yunzhongOvO/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yunzhongOvO/subscriptions","organizations_url":"https://api.github.com/users/yunzhongOvO/orgs","repos_url":"https://api.github.com/users/yunzhongOvO/repos","events_url":"https://api.github.com/users/yunzhongOvO/events{/privacy}","received_events_url":"https://api.github.com/users/yunzhongOvO/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/aws-samples/deep-learning-models/issues/comments/671661534","html_url":"https://github.com/aws-samples/deep-learning-models/issues/30#issuecomment-671661534","issue_url":"https://api.github.com/repos/aws-samples/deep-learning-models/issues/30","id":671661534,"node_id":"MDEyOklzc3VlQ29tbWVudDY3MTY2MTUzNA==","user":{"login":"jarednielsen","id":4564897,"node_id":"MDQ6VXNlcjQ1NjQ4OTc=","avatar_url":"https://avatars.githubusercontent.com/u/4564897?v=4","gravatar_id":"","url":"https://api.github.com/users/jarednielsen","html_url":"https://github.com/jarednielsen","followers_url":"https://api.github.com/users/jarednielsen/followers","following_url":"https://api.github.com/users/jarednielsen/following{/other_user}","gists_url":"https://api.github.com/users/jarednielsen/gists{/gist_id}","starred_url":"https://api.github.com/users/jarednielsen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jarednielsen/subscriptions","organizations_url":"https://api.github.com/users/jarednielsen/orgs","repos_url":"https://api.github.com/users/jarednielsen/repos","events_url":"https://api.github.com/users/jarednielsen/events{/privacy}","received_events_url":"https://api.github.com/users/jarednielsen/received_events","type":"User","site_admin":false},"created_at":"2020-08-11T00:51:20Z","updated_at":"2020-08-11T00:51:20Z","author_association":"CONTRIBUTOR","body":"Related to your first issue, there's an unreleased fix in the master branch of tokenizers. Running these commands to install tokenizers from source will fix that.\r\n\r\nhttps://github.com/aws-samples/deep-learning-models/blob/5b1194a862c026a30d5dfff46979cb7e80869e81/models/nlp/Dockerfile#L122-L128\r\n\r\nThe `schema` attribute was recently removed in `nlp==0.4.0` via https://github.com/huggingface/nlp/pull/423, so I've updated the script to reflect that.","reactions":{"url":"https://api.github.com/repos/aws-samples/deep-learning-models/issues/comments/671661534/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"jarednielsen","id":4564897,"node_id":"MDQ6VXNlcjQ1NjQ4OTc=","avatar_url":"https://avatars.githubusercontent.com/u/4564897?v=4","gravatar_id":"","url":"https://api.github.com/users/jarednielsen","html_url":"https://github.com/jarednielsen","followers_url":"https://api.github.com/users/jarednielsen/followers","following_url":"https://api.github.com/users/jarednielsen/following{/other_user}","gists_url":"https://api.github.com/users/jarednielsen/gists{/gist_id}","starred_url":"https://api.github.com/users/jarednielsen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jarednielsen/subscriptions","organizations_url":"https://api.github.com/users/jarednielsen/orgs","repos_url":"https://api.github.com/users/jarednielsen/repos","events_url":"https://api.github.com/users/jarednielsen/events{/privacy}","received_events_url":"https://api.github.com/users/jarednielsen/received_events","type":"User","site_admin":false}},{"id":3922839370,"node_id":"MDExOkNsb3NlZEV2ZW50MzkyMjgzOTM3MA==","url":"https://api.github.com/repos/aws-samples/deep-learning-models/issues/events/3922839370","actor":{"login":"jarednielsen","id":4564897,"node_id":"MDQ6VXNlcjQ1NjQ4OTc=","avatar_url":"https://avatars.githubusercontent.com/u/4564897?v=4","gravatar_id":"","url":"https://api.github.com/users/jarednielsen","html_url":"https://github.com/jarednielsen","followers_url":"https://api.github.com/users/jarednielsen/followers","following_url":"https://api.github.com/users/jarednielsen/following{/other_user}","gists_url":"https://api.github.com/users/jarednielsen/gists{/gist_id}","starred_url":"https://api.github.com/users/jarednielsen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jarednielsen/subscriptions","organizations_url":"https://api.github.com/users/jarednielsen/orgs","repos_url":"https://api.github.com/users/jarednielsen/repos","events_url":"https://api.github.com/users/jarednielsen/events{/privacy}","received_events_url":"https://api.github.com/users/jarednielsen/received_events","type":"User","site_admin":false},"event":"closed","commit_id":null,"commit_url":null,"created_at":"2020-10-26T21:10:57Z","state_reason":null,"performed_via_github_app":null}]