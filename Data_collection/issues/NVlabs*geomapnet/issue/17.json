{"url":"https://api.github.com/repos/NVlabs/geomapnet/issues/17","repository_url":"https://api.github.com/repos/NVlabs/geomapnet","labels_url":"https://api.github.com/repos/NVlabs/geomapnet/issues/17/labels{/name}","comments_url":"https://api.github.com/repos/NVlabs/geomapnet/issues/17/comments","events_url":"https://api.github.com/repos/NVlabs/geomapnet/issues/17/events","html_url":"https://github.com/NVlabs/geomapnet/issues/17","id":442651301,"node_id":"MDU6SXNzdWU0NDI2NTEzMDE=","number":17,"title":"How to get the  DSO: Direct sparse odometry for our own dataset","user":{"login":"DRAhmadFaraz","id":38114191,"node_id":"MDQ6VXNlcjM4MTE0MTkx","avatar_url":"https://avatars.githubusercontent.com/u/38114191?v=4","gravatar_id":"","url":"https://api.github.com/users/DRAhmadFaraz","html_url":"https://github.com/DRAhmadFaraz","followers_url":"https://api.github.com/users/DRAhmadFaraz/followers","following_url":"https://api.github.com/users/DRAhmadFaraz/following{/other_user}","gists_url":"https://api.github.com/users/DRAhmadFaraz/gists{/gist_id}","starred_url":"https://api.github.com/users/DRAhmadFaraz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DRAhmadFaraz/subscriptions","organizations_url":"https://api.github.com/users/DRAhmadFaraz/orgs","repos_url":"https://api.github.com/users/DRAhmadFaraz/repos","events_url":"https://api.github.com/users/DRAhmadFaraz/events{/privacy}","received_events_url":"https://api.github.com/users/DRAhmadFaraz/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2019-05-10T10:31:55Z","updated_at":"2019-07-25T12:16:35Z","closed_at":"2019-06-22T23:40:29Z","author_association":"NONE","active_lock_reason":null,"body":"@samarth-robo, \r\nRespected Sir, I have successfully installed your code and it works fine on 7-Scenes dataset, \r\n\r\nNow I want to run your code on my own Images, I have extracted the `frame00xxx-pose.txt` for every corresponding images by using Visual-SFM, but here your code also needs the **DSO: Direct sparse odometry** of 12 values for the comparison, so can you please guide me how to extract the DSO from monocular images having 4x4 poses for each frame too..??\r\n\r\nOr can you please guide me format of **DSO** file values, \r\n\r\nIs these values are also Rotation and Translation.?\r\nand what is the format of these files in that text file named `\"dso_poses/seq-xx.txt\".??` like 12 values shows what.? which values are for which parameters for camera.?\r\n\r\nwaiting for your kind response,\r\nBest regards.","closed_by":{"login":"samarth-robo","id":2848070,"node_id":"MDQ6VXNlcjI4NDgwNzA=","avatar_url":"https://avatars.githubusercontent.com/u/2848070?v=4","gravatar_id":"","url":"https://api.github.com/users/samarth-robo","html_url":"https://github.com/samarth-robo","followers_url":"https://api.github.com/users/samarth-robo/followers","following_url":"https://api.github.com/users/samarth-robo/following{/other_user}","gists_url":"https://api.github.com/users/samarth-robo/gists{/gist_id}","starred_url":"https://api.github.com/users/samarth-robo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/samarth-robo/subscriptions","organizations_url":"https://api.github.com/users/samarth-robo/orgs","repos_url":"https://api.github.com/users/samarth-robo/repos","events_url":"https://api.github.com/users/samarth-robo/events{/privacy}","received_events_url":"https://api.github.com/users/samarth-robo/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/NVlabs/geomapnet/issues/17/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/NVlabs/geomapnet/issues/17/timeline","performed_via_github_app":null,"state_reason":"completed"}