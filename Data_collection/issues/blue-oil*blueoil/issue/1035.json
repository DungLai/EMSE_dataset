{"url":"https://api.github.com/repos/blue-oil/blueoil/issues/1035","repository_url":"https://api.github.com/repos/blue-oil/blueoil","labels_url":"https://api.github.com/repos/blue-oil/blueoil/issues/1035/labels{/name}","comments_url":"https://api.github.com/repos/blue-oil/blueoil/issues/1035/comments","events_url":"https://api.github.com/repos/blue-oil/blueoil/issues/1035/events","html_url":"https://github.com/blue-oil/blueoil/issues/1035","id":619005541,"node_id":"MDU6SXNzdWU2MTkwMDU1NDE=","number":1035,"title":"lm_fpga.elf of LMBiSeNetQuantize doesn't work","user":{"login":"tk26eng","id":35796618,"node_id":"MDQ6VXNlcjM1Nzk2NjE4","avatar_url":"https://avatars.githubusercontent.com/u/35796618?v=4","gravatar_id":"","url":"https://api.github.com/users/tk26eng","html_url":"https://github.com/tk26eng","followers_url":"https://api.github.com/users/tk26eng/followers","following_url":"https://api.github.com/users/tk26eng/following{/other_user}","gists_url":"https://api.github.com/users/tk26eng/gists{/gist_id}","starred_url":"https://api.github.com/users/tk26eng/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tk26eng/subscriptions","organizations_url":"https://api.github.com/users/tk26eng/orgs","repos_url":"https://api.github.com/users/tk26eng/repos","events_url":"https://api.github.com/users/tk26eng/events{/privacy}","received_events_url":"https://api.github.com/users/tk26eng/received_events","type":"User","site_admin":false},"labels":[{"id":1095590109,"node_id":"MDU6TGFiZWwxMDk1NTkwMTA5","url":"https://api.github.com/repos/blue-oil/blueoil/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"open","locked":true,"assignee":{"login":"tk26eng","id":35796618,"node_id":"MDQ6VXNlcjM1Nzk2NjE4","avatar_url":"https://avatars.githubusercontent.com/u/35796618?v=4","gravatar_id":"","url":"https://api.github.com/users/tk26eng","html_url":"https://github.com/tk26eng","followers_url":"https://api.github.com/users/tk26eng/followers","following_url":"https://api.github.com/users/tk26eng/following{/other_user}","gists_url":"https://api.github.com/users/tk26eng/gists{/gist_id}","starred_url":"https://api.github.com/users/tk26eng/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tk26eng/subscriptions","organizations_url":"https://api.github.com/users/tk26eng/orgs","repos_url":"https://api.github.com/users/tk26eng/repos","events_url":"https://api.github.com/users/tk26eng/events{/privacy}","received_events_url":"https://api.github.com/users/tk26eng/received_events","type":"User","site_admin":false},"assignees":[{"login":"tk26eng","id":35796618,"node_id":"MDQ6VXNlcjM1Nzk2NjE4","avatar_url":"https://avatars.githubusercontent.com/u/35796618?v=4","gravatar_id":"","url":"https://api.github.com/users/tk26eng","html_url":"https://github.com/tk26eng","followers_url":"https://api.github.com/users/tk26eng/followers","following_url":"https://api.github.com/users/tk26eng/following{/other_user}","gists_url":"https://api.github.com/users/tk26eng/gists{/gist_id}","starred_url":"https://api.github.com/users/tk26eng/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tk26eng/subscriptions","organizations_url":"https://api.github.com/users/tk26eng/orgs","repos_url":"https://api.github.com/users/tk26eng/repos","events_url":"https://api.github.com/users/tk26eng/events{/privacy}","received_events_url":"https://api.github.com/users/tk26eng/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2020-05-15T14:26:02Z","updated_at":"2020-05-15T14:29:13Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"lm_fpga.elf doesn't work well with LMBiSeNetQuantize.\r\nThe program gets stucked (freezed) when we run it on FPGA.\r\n\r\nThe error point is:\r\n\r\n```\r\n  Conv2D_struct.input_height = 1;\r\n  Conv2D_struct.input_width = 1;\r\n  Conv2D_struct.kernel_height = 1;\r\n  Conv2D_struct.kernel_width = 1;\r\n  Conv2D_struct.kernel_depth = 512;\r\n  Conv2D_struct.kernel_elements = 512;\r\n  Conv2D_struct.output_channels = 512;\r\n  Conv2D_struct.output_height = 1;\r\n  Conv2D_struct.output_width = 1;\r\n  Conv2D_struct.padding = 0;\r\n  Conv2D_struct.stride_along_height = 1;\r\n  Conv2D_struct.stride_along_width = 1;\r\n  Conv2D_struct.temporary_buf = qconv_tmp_buffer.get();\r\n  binConv2D_struct.normal_conv_params = Conv2D_struct;\r\n  binConv2D_struct.bin_input_extra_bits = 0;\r\n  binConv2D_struct.bin_input_bitwidth = 2;\r\n  binConv2D_struct.bin_kernel_ndata = 8192;\r\n  binConv2D_struct.bin_input_nwords = 8192;\r\n  binConv2D_struct.bin_input_ndata = 8192*2;\r\n  binConv2D_struct.device_input_buf = device_input_buf;\r\n  binConv2D_struct.device_output_buf = device_output_buf;\r\n  binConv2D_struct.thresholds = nullptr;\r\n  binConv2D_struct.n_bit = 2;\r\n  binConv2D_struct.max_value = 2.0;\r\n  binConv2D_struct.debug_name = \"context_merge_attention_32_conv_conv2d_Conv2D\";\r\n#ifdef RUN_ON_FPGA\r\n  binConv2D_struct.device_kernel_phys_addr = KERNEL_ADDR + context_merge_attention_32_conv_conv2d_Conv2D_kernel_offset;\r\n  binConv2D_struct.device_thresholds_phys_addr = 0;\r\n#endif\r\n  func_QuantizedConv2D(context_merge_attention_32_QTZ_linear_mid_tread_half_output, context_merge_attention_32_conv_conv2d_kernel_1_BinaryMeanScalingQuantizer_new_output, context_merge_attention_32_conv_conv2d_Conv2D_Y, scaling_factors::context_merge_attention_32_conv_conv2d_Conv2D, binConv2D_struct);\r\n```\r\n\r\nSo we can find out the error occurs at attention block of LMBiSeNet.\r\nThe error has disappeared if the `NETWORK.USE_ATTENTION_REFINEMENT = False` is set in configuration as option.\r\n\r\nShould we improve this ?","closed_by":null,"reactions":{"url":"https://api.github.com/repos/blue-oil/blueoil/issues/1035/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/blue-oil/blueoil/issues/1035/timeline","performed_via_github_app":null,"state_reason":null}