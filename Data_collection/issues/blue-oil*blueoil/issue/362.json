{"url":"https://api.github.com/repos/blue-oil/blueoil/issues/362","repository_url":"https://api.github.com/repos/blue-oil/blueoil","labels_url":"https://api.github.com/repos/blue-oil/blueoil/issues/362/labels{/name}","comments_url":"https://api.github.com/repos/blue-oil/blueoil/issues/362/comments","events_url":"https://api.github.com/repos/blue-oil/blueoil/issues/362/events","html_url":"https://github.com/blue-oil/blueoil/issues/362","id":466619716,"node_id":"MDU6SXNzdWU0NjY2MTk3MTY=","number":362,"title":"Kernel Initializer is not passed into conv2D","user":{"login":"ananno","id":3903030,"node_id":"MDQ6VXNlcjM5MDMwMzA=","avatar_url":"https://avatars.githubusercontent.com/u/3903030?v=4","gravatar_id":"","url":"https://api.github.com/users/ananno","html_url":"https://github.com/ananno","followers_url":"https://api.github.com/users/ananno/followers","following_url":"https://api.github.com/users/ananno/following{/other_user}","gists_url":"https://api.github.com/users/ananno/gists{/gist_id}","starred_url":"https://api.github.com/users/ananno/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ananno/subscriptions","organizations_url":"https://api.github.com/users/ananno/orgs","repos_url":"https://api.github.com/users/ananno/repos","events_url":"https://api.github.com/users/ananno/events{/privacy}","received_events_url":"https://api.github.com/users/ananno/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":true,"assignee":null,"assignees":[],"milestone":null,"comments":8,"created_at":"2019-07-11T02:11:36Z","updated_at":"2020-11-02T02:31:31Z","closed_at":"2020-11-02T02:31:31Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"# Background\r\nI've been working with the new blueoil/lmnet code and found out that the `kernel_initializer` is not passed in `conv2D` wrapper function defined in `lmnet/lmnet/layers/layers.py`. The `kernel_initializer` argument in `darknet` block function in `lmnet/lmnet/blocks.py` provided but it is not passed into the actual `tf.layers.conv2d` function inside the wrapper function `conv2D`.\r\n\r\n* `lmnet/lmnet/blocks.py`\r\n```\r\n# TODO(wakisaka): should be replace to conv_bn_act().\r\ndef darknet(name, inputs, filters, kernel_size,\r\n            is_training=tf.constant(False), activation=None, data_format=\"NHWC\", *args, **kwargs):\r\n    \"\"\"Darknet19 block.\r\n\r\n    Do convolution, batch_norm, bias, leaky_relu activation.\r\n    Ref: https://arxiv.org/pdf/1612.08242.pdf\r\n         https://github.com/pjreddie/darknet/blob/3bf2f342c03b0ad22efd799d5be9990c9d792354/cfg/darknet19.cfg\r\n         https://github.com/pjreddie/darknet/blob/8215a8864d4ad07e058acafd75b2c6ff6600b9e8/cfg/yolo.2.0.cfg\r\n    \"\"\"\r\n    if data_format == \"NCHW\":\r\n        channel_data_format = \"channels_first\"\r\n    elif data_format == \"NHWC\":\r\n        channel_data_format = \"channels_last\"\r\n    else:\r\n        raise ValueError(\"data format must be 'NCHW' or 'NHWC'. got {}.\".format(data_format))\r\n\r\n    with tf.variable_scope(name):\r\n        if activation is None:\r\n            def activation(x): return tf.nn.leaky_relu(x, alpha=0.1, name=\"leaky_relu\")\r\n\r\n        conv = conv2d(\"conv\", inputs, filters=filters, kernel_size=kernel_size,\r\n                      activation=None, use_bias=False, data_format=channel_data_format,\r\n                      kernel_initializer=tf.contrib.layers.variance_scaling_initializer(),\r\n                      *args, **kwargs)  # he initializer\r\n\r\n        # TODO(wakisaka): Should be the same as darknet batrch norm.\r\n        # https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/contrib/layers/python/layers/layers.py\r\n        # https://github.com/pjreddie/darknet/blob/8215a8864d4ad07e058acafd75b2c6ff6600b9e8/src/batchnorm_layer.c#L135\r\n        batch_normed = batch_norm(\"bn\", conv, is_training=is_training, decay=0.99, scale=True, center=True,\r\n                                  data_format=data_format)\r\n        tf.summary.histogram(\"batch_normed\", batch_normed)\r\n\r\n        output = activation(batch_normed)\r\n        tf.summary.histogram(\"output\", output)\r\n\r\n        return output\r\n```\r\n* `lmnet/lmnet/layers/layers.py`\r\n```\r\ndef conv2d(\r\n    name,\r\n    inputs,\r\n    filters,\r\n    kernel_size,\r\n    strides=1,\r\n    padding=\"SAME\",\r\n    activation=tf.nn.relu,\r\n    kernel_initializer=tf.contrib.layers.xavier_initializer(),\r\n    is_debug=False,\r\n    *args,\r\n    **kwargs\r\n):\r\n\r\n    output = tf.layers.conv2d(\r\n        name=name,\r\n        inputs=inputs,\r\n        filters=filters,\r\n        kernel_size=kernel_size,\r\n        strides=strides,\r\n        padding=padding,\r\n        activation=activation,\r\n        *args,\r\n        **kwargs,\r\n    )\r\n\r\n    if is_debug:\r\n        tf.summary.histogram(name + \"/output\", output)\r\n\r\n    return output\r\n\r\n```\r\nIn my opinion, `kernel_regularizer` argument in `conv2D` function should not be defined explicitly. If defined in the calling function it will be automatically passed via `*args, **kwargs` argument extension. i.e. \r\n* Solution\r\n```\r\ndef conv2d(\r\n    name,\r\n    inputs,\r\n    filters,\r\n    kernel_size,\r\n    strides=1,\r\n    padding=\"SAME\",\r\n    activation=tf.nn.relu,\r\n    is_debug=False,\r\n    *args,\r\n    **kwargs\r\n):\r\n\r\n    output = tf.layers.conv2d(\r\n        name=name,\r\n        inputs=inputs,\r\n        filters=filters,\r\n        kernel_size=kernel_size,\r\n        strides=strides,\r\n        padding=padding,\r\n        activation=activation,\r\n        *args,\r\n        **kwargs,\r\n    )\r\n\r\n    if is_debug:\r\n        tf.summary.histogram(name + \"/output\", output)\r\n\r\n    return output\r\n```\r\n","closed_by":{"login":"ananno","id":3903030,"node_id":"MDQ6VXNlcjM5MDMwMzA=","avatar_url":"https://avatars.githubusercontent.com/u/3903030?v=4","gravatar_id":"","url":"https://api.github.com/users/ananno","html_url":"https://github.com/ananno","followers_url":"https://api.github.com/users/ananno/followers","following_url":"https://api.github.com/users/ananno/following{/other_user}","gists_url":"https://api.github.com/users/ananno/gists{/gist_id}","starred_url":"https://api.github.com/users/ananno/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ananno/subscriptions","organizations_url":"https://api.github.com/users/ananno/orgs","repos_url":"https://api.github.com/users/ananno/repos","events_url":"https://api.github.com/users/ananno/events{/privacy}","received_events_url":"https://api.github.com/users/ananno/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/blue-oil/blueoil/issues/362/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/blue-oil/blueoil/issues/362/timeline","performed_via_github_app":null,"state_reason":"completed"}