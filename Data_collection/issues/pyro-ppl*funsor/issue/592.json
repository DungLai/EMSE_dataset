{"url":"https://api.github.com/repos/pyro-ppl/funsor/issues/592","repository_url":"https://api.github.com/repos/pyro-ppl/funsor","labels_url":"https://api.github.com/repos/pyro-ppl/funsor/issues/592/labels{/name}","comments_url":"https://api.github.com/repos/pyro-ppl/funsor/issues/592/comments","events_url":"https://api.github.com/repos/pyro-ppl/funsor/issues/592/events","html_url":"https://github.com/pyro-ppl/funsor/issues/592","id":1198633400,"node_id":"I_kwDOCgoJts5HcbG4","number":592,"title":"FR Thompson sampling example","user":{"login":"fritzo","id":648532,"node_id":"MDQ6VXNlcjY0ODUzMg==","avatar_url":"https://avatars.githubusercontent.com/u/648532?v=4","gravatar_id":"","url":"https://api.github.com/users/fritzo","html_url":"https://github.com/fritzo","followers_url":"https://api.github.com/users/fritzo/followers","following_url":"https://api.github.com/users/fritzo/following{/other_user}","gists_url":"https://api.github.com/users/fritzo/gists{/gist_id}","starred_url":"https://api.github.com/users/fritzo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fritzo/subscriptions","organizations_url":"https://api.github.com/users/fritzo/orgs","repos_url":"https://api.github.com/users/fritzo/repos","events_url":"https://api.github.com/users/fritzo/events{/privacy}","received_events_url":"https://api.github.com/users/fritzo/received_events","type":"User","site_admin":false},"labels":[{"id":1235911323,"node_id":"MDU6TGFiZWwxMjM1OTExMzIz","url":"https://api.github.com/repos/pyro-ppl/funsor/labels/examples","name":"examples","color":"0052cc","default":false,"description":"Examples and tutorials"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-04-09T14:24:44Z","updated_at":"2022-04-09T15:09:04Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"I came across this cute example of nested semiring dynamic programming in the context of Bayesian optimization. [Thompson sampling](https://en.wikipedia.org/wiki/Thompson_sampling) first performs Bayesian regression, fitting a posterior `p(θ|Xs,ys)` over parameters `θ` given a fully-supervised dataset of `(X,y)` pairs, then repeatedly samples parameters `θ` and optimizes expected reward `E[y|X,θ]` over `X`. That is, at each step\r\n```\r\nX_optimal <- arg max_X int_y int_θ y p(y|θ,X)  p(θ) prod_i p(yi|θ,Xi)\r\n# new choice                       --reward-- prior ---likelihood---\r\n```\r\nFor example in [Pyroed](https://github.com/pyro-ppl/pyroed) `p(θ) prod_i p(yi|θ,Xi)` is approximated variationally, and `E[y|θ,X]` is  just a tensor contraction (although there it is optimized via annealed Gibbs sampling rather than via dynamic programming, as an aside we could add an annealed Gibbs sampling interpretation to Funsor for sum-product contractions).\r\n\r\nWhat would be a good example here, where we might leverage Funsor's dynamic programming to implement both the integral and argmax operators?","closed_by":null,"reactions":{"url":"https://api.github.com/repos/pyro-ppl/funsor/issues/592/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/pyro-ppl/funsor/issues/592/timeline","performed_via_github_app":null,"state_reason":null}