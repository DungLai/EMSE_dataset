{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/224","repository_url":"https://api.github.com/repos/BindsNET/bindsnet","labels_url":"https://api.github.com/repos/BindsNET/bindsnet/issues/224/labels{/name}","comments_url":"https://api.github.com/repos/BindsNET/bindsnet/issues/224/comments","events_url":"https://api.github.com/repos/BindsNET/bindsnet/issues/224/events","html_url":"https://github.com/BindsNET/bindsnet/issues/224","id":428606740,"node_id":"MDU6SXNzdWU0Mjg2MDY3NDA=","number":224,"title":"Reward prediction error instead of reward","user":{"login":"Huizerd","id":15855769,"node_id":"MDQ6VXNlcjE1ODU1NzY5","avatar_url":"https://avatars.githubusercontent.com/u/15855769?v=4","gravatar_id":"","url":"https://api.github.com/users/Huizerd","html_url":"https://github.com/Huizerd","followers_url":"https://api.github.com/users/Huizerd/followers","following_url":"https://api.github.com/users/Huizerd/following{/other_user}","gists_url":"https://api.github.com/users/Huizerd/gists{/gist_id}","starred_url":"https://api.github.com/users/Huizerd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Huizerd/subscriptions","organizations_url":"https://api.github.com/users/Huizerd/orgs","repos_url":"https://api.github.com/users/Huizerd/repos","events_url":"https://api.github.com/users/Huizerd/events{/privacy}","received_events_url":"https://api.github.com/users/Huizerd/received_events","type":"User","site_admin":false},"labels":[{"id":832665087,"node_id":"MDU6TGFiZWw4MzI2NjUwODc=","url":"https://api.github.com/repos/BindsNET/bindsnet/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":8,"created_at":"2019-04-03T07:29:10Z","updated_at":"2019-04-22T13:53:17Z","closed_at":"2019-04-22T13:53:17Z","author_association":"COLLABORATOR","active_lock_reason":null,"body":"As suggested by [Fremaux et al. (2010)](http://www.jneurosci.org/content/30/40/13326.short), learning performance of reward-modulated STDP can be greatly enhanced by using 'reward prediction error' instead of actual reward in the computation of the new weights (`w += gamma * dt * reward * e_trace`). I tested this for a simple 1D navigation task, with the following result for non-RPE:\r\n\r\n![final_reward_plot](https://user-images.githubusercontent.com/15855769/55460188-99f59a80-55f1-11e9-93bf-5bec467e331c.png)\r\n\r\nAnd for RPE:\r\n\r\n![final_reward_plot](https://user-images.githubusercontent.com/15855769/55460206-a679f300-55f1-11e9-8609-c07095bd3657.png)\r\n\r\nWhere blue is the predicted reward for an episode, and red the actual obtained one. The maximum reward that could've been achieved in one episode is 10000, so the RPE-variant got very close.\r\n\r\nI implemented the predicted reward as a simple moving average of past episodes (per step, so `episode_reward / steps`), and fed this to the `Network.run`. I used `Pipeline`, which I had to modify in order to be able to modify reward between getting it back from the `Gym` environment and feeding it to `Network.run`.\r\n\r\nI would like to implement this in BindsNET as well, so my questions are: have you heard of this? Has anyone tried to implement it yet, and how? Do you have a preferred way of implementing?\r\n\r\nI think it would be cool if someone can decide for their own how they want to implement the predicted reward. So we might need the ability to pass a function to `Pipeline` / `Network`. This might also cover the reward features discussed in #217.","closed_by":{"login":"djsaunde","id":1245942,"node_id":"MDQ6VXNlcjEyNDU5NDI=","avatar_url":"https://avatars.githubusercontent.com/u/1245942?v=4","gravatar_id":"","url":"https://api.github.com/users/djsaunde","html_url":"https://github.com/djsaunde","followers_url":"https://api.github.com/users/djsaunde/followers","following_url":"https://api.github.com/users/djsaunde/following{/other_user}","gists_url":"https://api.github.com/users/djsaunde/gists{/gist_id}","starred_url":"https://api.github.com/users/djsaunde/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/djsaunde/subscriptions","organizations_url":"https://api.github.com/users/djsaunde/orgs","repos_url":"https://api.github.com/users/djsaunde/repos","events_url":"https://api.github.com/users/djsaunde/events{/privacy}","received_events_url":"https://api.github.com/users/djsaunde/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/224/reactions","total_count":3,"+1":3,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/BindsNET/bindsnet/issues/224/timeline","performed_via_github_app":null,"state_reason":"completed"}