[{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/770091017","html_url":"https://github.com/BindsNET/bindsnet/issues/453#issuecomment-770091017","issue_url":"https://api.github.com/repos/BindsNET/bindsnet/issues/453","id":770091017,"node_id":"MDEyOklzc3VlQ29tbWVudDc3MDA5MTAxNw==","user":{"login":"Hananel-Hazan","id":3954715,"node_id":"MDQ6VXNlcjM5NTQ3MTU=","avatar_url":"https://avatars.githubusercontent.com/u/3954715?v=4","gravatar_id":"","url":"https://api.github.com/users/Hananel-Hazan","html_url":"https://github.com/Hananel-Hazan","followers_url":"https://api.github.com/users/Hananel-Hazan/followers","following_url":"https://api.github.com/users/Hananel-Hazan/following{/other_user}","gists_url":"https://api.github.com/users/Hananel-Hazan/gists{/gist_id}","starred_url":"https://api.github.com/users/Hananel-Hazan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Hananel-Hazan/subscriptions","organizations_url":"https://api.github.com/users/Hananel-Hazan/orgs","repos_url":"https://api.github.com/users/Hananel-Hazan/repos","events_url":"https://api.github.com/users/Hananel-Hazan/events{/privacy}","received_events_url":"https://api.github.com/users/Hananel-Hazan/received_events","type":"User","site_admin":false},"created_at":"2021-01-29T22:49:13Z","updated_at":"2021-01-29T22:49:13Z","author_association":"COLLABORATOR","body":"It should be possible, using Quantization and normalization of the data, then encode it with spikes. \r\n\r\nThe discussion area is more suitable to this questions, since this is not a bug or unexpected behavioral.","reactions":{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/770091017/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"Hananel-Hazan","id":3954715,"node_id":"MDQ6VXNlcjM5NTQ3MTU=","avatar_url":"https://avatars.githubusercontent.com/u/3954715?v=4","gravatar_id":"","url":"https://api.github.com/users/Hananel-Hazan","html_url":"https://github.com/Hananel-Hazan","followers_url":"https://api.github.com/users/Hananel-Hazan/followers","following_url":"https://api.github.com/users/Hananel-Hazan/following{/other_user}","gists_url":"https://api.github.com/users/Hananel-Hazan/gists{/gist_id}","starred_url":"https://api.github.com/users/Hananel-Hazan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Hananel-Hazan/subscriptions","organizations_url":"https://api.github.com/users/Hananel-Hazan/orgs","repos_url":"https://api.github.com/users/Hananel-Hazan/repos","events_url":"https://api.github.com/users/Hananel-Hazan/events{/privacy}","received_events_url":"https://api.github.com/users/Hananel-Hazan/received_events","type":"User","site_admin":false}},{"id":4268340792,"node_id":"MDExOkNsb3NlZEV2ZW50NDI2ODM0MDc5Mg==","url":"https://api.github.com/repos/BindsNET/bindsnet/issues/events/4268340792","actor":{"login":"Hananel-Hazan","id":3954715,"node_id":"MDQ6VXNlcjM5NTQ3MTU=","avatar_url":"https://avatars.githubusercontent.com/u/3954715?v=4","gravatar_id":"","url":"https://api.github.com/users/Hananel-Hazan","html_url":"https://github.com/Hananel-Hazan","followers_url":"https://api.github.com/users/Hananel-Hazan/followers","following_url":"https://api.github.com/users/Hananel-Hazan/following{/other_user}","gists_url":"https://api.github.com/users/Hananel-Hazan/gists{/gist_id}","starred_url":"https://api.github.com/users/Hananel-Hazan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Hananel-Hazan/subscriptions","organizations_url":"https://api.github.com/users/Hananel-Hazan/orgs","repos_url":"https://api.github.com/users/Hananel-Hazan/repos","events_url":"https://api.github.com/users/Hananel-Hazan/events{/privacy}","received_events_url":"https://api.github.com/users/Hananel-Hazan/received_events","type":"User","site_admin":false},"event":"closed","commit_id":null,"commit_url":null,"created_at":"2021-01-29T22:49:13Z","state_reason":null,"performed_via_github_app":null},{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/1236374595","html_url":"https://github.com/BindsNET/bindsnet/issues/453#issuecomment-1236374595","issue_url":"https://api.github.com/repos/BindsNET/bindsnet/issues/453","id":1236374595,"node_id":"IC_kwDOBzWFSM5JsZRD","user":{"login":"w5688414","id":12107462,"node_id":"MDQ6VXNlcjEyMTA3NDYy","avatar_url":"https://avatars.githubusercontent.com/u/12107462?v=4","gravatar_id":"","url":"https://api.github.com/users/w5688414","html_url":"https://github.com/w5688414","followers_url":"https://api.github.com/users/w5688414/followers","following_url":"https://api.github.com/users/w5688414/following{/other_user}","gists_url":"https://api.github.com/users/w5688414/gists{/gist_id}","starred_url":"https://api.github.com/users/w5688414/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/w5688414/subscriptions","organizations_url":"https://api.github.com/users/w5688414/orgs","repos_url":"https://api.github.com/users/w5688414/repos","events_url":"https://api.github.com/users/w5688414/events{/privacy}","received_events_url":"https://api.github.com/users/w5688414/received_events","type":"User","site_admin":false},"created_at":"2022-09-04T16:28:10Z","updated_at":"2022-09-04T16:28:10Z","author_association":"NONE","body":"Is there any examples for STDP training with iris dataset","reactions":{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/1236374595/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"w5688414","id":12107462,"node_id":"MDQ6VXNlcjEyMTA3NDYy","avatar_url":"https://avatars.githubusercontent.com/u/12107462?v=4","gravatar_id":"","url":"https://api.github.com/users/w5688414","html_url":"https://github.com/w5688414","followers_url":"https://api.github.com/users/w5688414/followers","following_url":"https://api.github.com/users/w5688414/following{/other_user}","gists_url":"https://api.github.com/users/w5688414/gists{/gist_id}","starred_url":"https://api.github.com/users/w5688414/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/w5688414/subscriptions","organizations_url":"https://api.github.com/users/w5688414/orgs","repos_url":"https://api.github.com/users/w5688414/repos","events_url":"https://api.github.com/users/w5688414/events{/privacy}","received_events_url":"https://api.github.com/users/w5688414/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/1236411136","html_url":"https://github.com/BindsNET/bindsnet/issues/453#issuecomment-1236411136","issue_url":"https://api.github.com/repos/BindsNET/bindsnet/issues/453","id":1236411136,"node_id":"IC_kwDOBzWFSM5JsiMA","user":{"login":"SimonInParis","id":45327416,"node_id":"MDQ6VXNlcjQ1MzI3NDE2","avatar_url":"https://avatars.githubusercontent.com/u/45327416?v=4","gravatar_id":"","url":"https://api.github.com/users/SimonInParis","html_url":"https://github.com/SimonInParis","followers_url":"https://api.github.com/users/SimonInParis/followers","following_url":"https://api.github.com/users/SimonInParis/following{/other_user}","gists_url":"https://api.github.com/users/SimonInParis/gists{/gist_id}","starred_url":"https://api.github.com/users/SimonInParis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SimonInParis/subscriptions","organizations_url":"https://api.github.com/users/SimonInParis/orgs","repos_url":"https://api.github.com/users/SimonInParis/repos","events_url":"https://api.github.com/users/SimonInParis/events{/privacy}","received_events_url":"https://api.github.com/users/SimonInParis/received_events","type":"User","site_admin":false},"created_at":"2022-09-04T20:36:48Z","updated_at":"2022-09-04T20:37:24Z","author_association":"COLLABORATOR","body":"Not yet, but I think this is feasible:\r\n\r\nThe first thing I'm thinking of is to use the unsupervised Self Organizing Map (SOM) model: https://github.com/BindsNET/bindsnet/blob/61fda794534bf3c85307f8f71a6124ff5c7c4b52/examples/mnist/SOM_LM-SNNs.py\r\n\r\n-the input layer size is 4\r\n-encode the 4 decimal inputs into spikes using Poisson (just like in the SOM source)\r\n-let the unsupervised STDP choose and arrange the most relevant neurons, given the input patterns\r\n-try with an output layer of size 400, it should be fast and accurate\r\n-let the supervised linear readout mechanism (from the SOM source) assign the output neurons (or neurons regions) to each of the 3 classes\r\n-use about 100 time steps (ms) for each run\r\n\r\nThe current script has a lot of monitoring tools for you to understand what's going on.\r\n\r\nThe biggest work is to switch from a 2D image (MNIST) to 4 parameters.\r\n\r\nYou should get a decent result with a very small model!","reactions":{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/1236411136/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"SimonInParis","id":45327416,"node_id":"MDQ6VXNlcjQ1MzI3NDE2","avatar_url":"https://avatars.githubusercontent.com/u/45327416?v=4","gravatar_id":"","url":"https://api.github.com/users/SimonInParis","html_url":"https://github.com/SimonInParis","followers_url":"https://api.github.com/users/SimonInParis/followers","following_url":"https://api.github.com/users/SimonInParis/following{/other_user}","gists_url":"https://api.github.com/users/SimonInParis/gists{/gist_id}","starred_url":"https://api.github.com/users/SimonInParis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SimonInParis/subscriptions","organizations_url":"https://api.github.com/users/SimonInParis/orgs","repos_url":"https://api.github.com/users/SimonInParis/repos","events_url":"https://api.github.com/users/SimonInParis/events{/privacy}","received_events_url":"https://api.github.com/users/SimonInParis/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/1237559301","html_url":"https://github.com/BindsNET/bindsnet/issues/453#issuecomment-1237559301","issue_url":"https://api.github.com/repos/BindsNET/bindsnet/issues/453","id":1237559301,"node_id":"IC_kwDOBzWFSM5Jw6gF","user":{"login":"w5688414","id":12107462,"node_id":"MDQ6VXNlcjEyMTA3NDYy","avatar_url":"https://avatars.githubusercontent.com/u/12107462?v=4","gravatar_id":"","url":"https://api.github.com/users/w5688414","html_url":"https://github.com/w5688414","followers_url":"https://api.github.com/users/w5688414/followers","following_url":"https://api.github.com/users/w5688414/following{/other_user}","gists_url":"https://api.github.com/users/w5688414/gists{/gist_id}","starred_url":"https://api.github.com/users/w5688414/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/w5688414/subscriptions","organizations_url":"https://api.github.com/users/w5688414/orgs","repos_url":"https://api.github.com/users/w5688414/repos","events_url":"https://api.github.com/users/w5688414/events{/privacy}","received_events_url":"https://api.github.com/users/w5688414/received_events","type":"User","site_admin":false},"created_at":"2022-09-06T01:10:06Z","updated_at":"2022-09-06T01:10:06Z","author_association":"NONE","body":"[SOM_LM-SNNs_v1.zip](https://github.com/BindsNET/bindsnet/files/9492566/SOM_LM-SNNs_v1.zip)\r\n\r\nI try to modify the SOM_LM-SNNs.py, but I got 0 accuracy. Can you help me to find the error? here is my code\r\n\r\n```\r\nimport argparse\r\nimport os\r\nfrom time import time as t\r\n\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport torch\r\nfrom torchvision import transforms\r\nfrom tqdm import tqdm\r\n\r\nfrom bindsnet.analysis.plotting import (\r\n    plot_assignments,\r\n    plot_input,\r\n    plot_performance,\r\n    plot_spikes,\r\n    plot_voltages,\r\n    plot_weights,\r\n)\r\nfrom bindsnet.datasets import MNIST\r\nfrom bindsnet.encoding import PoissonEncoder, poisson\r\nfrom bindsnet.evaluation import all_activity, assign_labels, proportion_weighting\r\nfrom bindsnet.models import IncreasingInhibitionNetwork\r\nfrom bindsnet.network.monitors import Monitor\r\nfrom bindsnet.utils import get_square_assignments, get_square_weights\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument(\"--seed\", type=int, default=0)\r\nparser.add_argument(\"--n_neurons\", type=int, default=400)\r\nparser.add_argument(\"--n_epochs\", type=int, default=1)\r\nparser.add_argument(\"--n_test\", type=int, default=10000)\r\nparser.add_argument(\"--n_train\", type=int, default=60000)\r\nparser.add_argument(\"--n_workers\", type=int, default=-1)\r\nparser.add_argument(\"--theta_plus\", type=float, default=0.05)\r\nparser.add_argument(\"--time\", type=int, default=100)\r\nparser.add_argument(\"--dt\", type=int, default=1.0)\r\nparser.add_argument(\"--intensity\", type=float, default=64)\r\nparser.add_argument(\"--progress_interval\", type=int, default=10)\r\nparser.add_argument(\"--update_interval\", type=int, default=250)\r\nparser.add_argument(\"--update_inhibation_weights\", type=int, default=500)\r\nparser.add_argument(\"--plot_interval\", type=int, default=250)\r\nparser.add_argument(\"--plot\", dest=\"plot\", action=\"store_true\")\r\nparser.add_argument(\"--gpu\", dest=\"gpu\", action=\"store_true\")\r\nparser.set_defaults(plot=True, gpu=True)\r\n\r\nargs = parser.parse_args()\r\n\r\nseed = args.seed\r\nn_neurons = args.n_neurons\r\nn_epochs = args.n_epochs\r\nn_test = args.n_test\r\nn_train = args.n_train\r\nn_workers = args.n_workers\r\ntheta_plus = args.theta_plus\r\ntime = args.time\r\ndt = args.dt\r\nintensity = args.intensity\r\nprogress_interval = args.progress_interval\r\nplot_interval = args.plot_interval\r\nupdate_interval = args.update_interval\r\nplot = args.plot\r\ngpu = args.gpu\r\nupdate_inhibation_weights = args.update_inhibation_weights\r\n\r\n# Sets up Gpu use\r\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\nif gpu and torch.cuda.is_available():\r\n    torch.cuda.manual_seed_all(seed)\r\nelse:\r\n    torch.manual_seed(seed)\r\n    device = \"cpu\"\r\n    if gpu:\r\n        gpu = False\r\n\r\ntorch.set_num_threads(os.cpu_count() - 1)\r\nprint(\"Running on Device = \", device)\r\n\r\n# Determines number of workers to use\r\nif n_workers == -1:\r\n    n_workers = 0  # torch.cuda.is_available() * 4 * torch.cuda.device_count()\r\n\r\nn_sqrt = int(np.ceil(np.sqrt(n_neurons)))\r\nstart_intensity = intensity\r\n\r\n# Build network.\r\nnetwork = IncreasingInhibitionNetwork(\r\n    n_input=4,\r\n    n_neurons=n_neurons,\r\n    start_inhib=10,\r\n    max_inhib=-40.0,\r\n    theta_plus=0.05,\r\n    tc_theta_decay=1e7,\r\n    inpt_shape=(1, 4),\r\n    nu=(1e-4, 1e-2),\r\n)\r\n\r\nnetwork.to(device)\r\n\r\n# Load MNIST data.\r\n# dataset = MNIST(\r\n#     PoissonEncoder(time=time, dt=dt),\r\n#     None,\r\n#     root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\r\n#     download=True,\r\n#     transform=transforms.Compose(\r\n#         [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\r\n#     ),\r\n# )\r\n\r\nfrom sklearn.datasets import load_iris\r\nfrom sklearn.model_selection import train_test_split\r\nfrom bindsnet.encoding import Encoder, NullEncoder\r\nfrom torch.utils.data import Dataset\r\n\r\niris = load_iris()\r\nX = iris['data']*10\r\ny = iris['target']\r\nnames = iris['target_names']\r\nfeature_names = iris['feature_names']\r\n\r\n# Split the data set into training and testing\r\nX_train, X_test, y_train, y_test = train_test_split(\r\n    X, y, test_size=0.2, random_state=2)\r\n\r\nclass CustomDataset(Dataset):\r\n    def __init__(self,images,labels,image_encoder=None,label_encoder=None) -> None:\r\n        super().__init__()\r\n            # Allow the passthrough of None, but change to NullEncoder\r\n        if image_encoder is None:\r\n            image_encoder = NullEncoder()\r\n\r\n        if label_encoder is None:\r\n            label_encoder = NullEncoder()\r\n        self.images = images\r\n        self.labels = labels\r\n        self.image_encoder = image_encoder\r\n        self.label_encoder = label_encoder\r\n\r\n    def __getitem__(self, ind: int):\r\n        image, label = self.images[ind],self.labels[ind]\r\n        # print(image)\r\n        # print(label)\r\n        image = torch.tensor(image).unsqueeze(0).to(torch.float32)\r\n        label = torch.tensor(label)\r\n        # print(image.shape)\r\n        output = {\r\n                \"image\": image,\r\n                \"label\": label,\r\n                \"encoded_image\": self.image_encoder(image),\r\n                \"encoded_label\": self.label_encoder(label),\r\n            }\r\n\r\n        return output\r\n\r\n    def __len__(self) -> int:\r\n        return self.images.shape[0]\r\n\r\ndataset = CustomDataset(images=X_train,labels=y_train,image_encoder=PoissonEncoder(time=time, dt=dt))\r\n\r\n# Record spikes during the simulation.\r\nspike_record = torch.zeros((update_interval, int(time / dt), n_neurons), device=device)\r\n\r\n# Neuron assignments and spike proportions.\r\nn_classes = 3\r\nassignments = -torch.ones(n_neurons, device=device)\r\nproportions = torch.zeros((n_neurons, n_classes), device=device)\r\nrates = torch.zeros((n_neurons, n_classes), device=device)\r\n\r\n# Sequence of accuracy estimates.\r\naccuracy = {\"all\": [], \"proportion\": []}\r\n\r\n# Voltage recording for excitatory and inhibitory layers.\r\nsom_voltage_monitor = Monitor(\r\n    network.layers[\"Y\"], [\"v\"], time=int(time / dt), device=device\r\n)\r\nnetwork.add_monitor(som_voltage_monitor, name=\"som_voltage\")\r\n\r\n# Set up monitors for spikes and voltages\r\nspikes = {}\r\nfor layer in set(network.layers):\r\n    spikes[layer] = Monitor(\r\n        network.layers[layer], state_vars=[\"s\"], time=int(time / dt), device=device\r\n    )\r\n    network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\r\n\r\nvoltages = {}\r\nfor layer in set(network.layers) - {\"X\"}:\r\n    voltages[layer] = Monitor(\r\n        network.layers[layer], state_vars=[\"v\"], time=int(time / dt), device=device\r\n    )\r\n    network.add_monitor(voltages[layer], name=\"%s_voltages\" % layer)\r\n\r\ninpt_ims, inpt_axes = None, None\r\nspike_ims, spike_axes = None, None\r\nweights_im = None\r\nassigns_im = None\r\nperf_ax = None\r\nvoltage_axes, voltage_ims = None, None\r\nsave_weights_fn = \"plots/weights/weights.png\"\r\nsave_performance_fn = \"plots/performance/performance.png\"\r\nsave_assaiments_fn = \"plots/assaiments/assaiments.png\"\r\n\r\ndirectorys = [\"plots\", \"plots/weights\", \"plots/performance\", \"plots/assaiments\"]\r\nfor directory in directorys:\r\n    if not os.path.exists(directory):\r\n        os.makedirs(directory)\r\n\r\n# diagonal weights for increassing the inhibitiosn\r\nweights_mask = (1 - torch.diag(torch.ones(n_neurons))).to(device)\r\n\r\n# Train the network.\r\nprint(\"\\nBegin training.\\n\")\r\nstart = t()\r\n\r\nfor epoch in range(n_epochs):\r\n    labels = []\r\n\r\n    if epoch % progress_interval == 0:\r\n        print(\"Progress: %d / %d (%.4f seconds)\" % (epoch, n_epochs, t() - start))\r\n        start = t()\r\n\r\n    # Create a dataloader to iterate and batch data\r\n    dataloader = torch.utils.data.DataLoader(\r\n        dataset, batch_size=1, shuffle=True, num_workers=n_workers, pin_memory=gpu\r\n    )\r\n\r\n    pbar = tqdm(total=n_train)\r\n    for step, batch in enumerate(dataloader):\r\n        if step == n_train:\r\n            break\r\n\r\n        # Get next input sample.\r\n        inputs = {\r\n            \"X\": batch[\"encoded_image\"].view(int(time / dt), 1, 4).to(device)\r\n        }\r\n\r\n        if step > 0:\r\n            if step % update_inhibation_weights == 0:\r\n                if step % (update_inhibation_weights * 10) == 0:\r\n                    network.Y_to_Y.w -= weights_mask * 50\r\n                else:\r\n                    # Inhibit the connection even more\r\n                    # network.Y_to_Y.w -= weights_mask * network.Y_to_Y.w.abs()*0.2\r\n                    network.Y_to_Y.w -= weights_mask * 0.5\r\n\r\n            if step % update_interval == 0:\r\n                # Convert the array of labels into a tensor\r\n                label_tensor = torch.tensor(labels, device=device)\r\n\r\n                # Get network predictions.\r\n                all_activity_pred = all_activity(\r\n                    spikes=spike_record, assignments=assignments, n_labels=n_classes\r\n                )\r\n                proportion_pred = proportion_weighting(\r\n                    spikes=spike_record,\r\n                    assignments=assignments,\r\n                    proportions=proportions,\r\n                    n_labels=n_classes,\r\n                )\r\n\r\n                # Compute network accuracy according to available classification strategies.\r\n                accuracy[\"all\"].append(\r\n                    100\r\n                    * torch.sum(label_tensor.long() == all_activity_pred).item()\r\n                    / len(label_tensor)\r\n                )\r\n                accuracy[\"proportion\"].append(\r\n                    100\r\n                    * torch.sum(label_tensor.long() == proportion_pred).item()\r\n                    / len(label_tensor)\r\n                )\r\n\r\n                tqdm.write(\r\n                    \"\\nAll activity accuracy: %.2f (last), %.2f (average), %.2f (best)\"\r\n                    % (\r\n                        accuracy[\"all\"][-1],\r\n                        np.mean(accuracy[\"all\"]),\r\n                        np.max(accuracy[\"all\"]),\r\n                    )\r\n                )\r\n                tqdm.write(\r\n                    \"Proportion weighting accuracy: %.2f (last), %.2f (average), %.2f\"\r\n                    \" (best)\\n\"\r\n                    % (\r\n                        accuracy[\"proportion\"][-1],\r\n                        np.mean(accuracy[\"proportion\"]),\r\n                        np.max(accuracy[\"proportion\"]),\r\n                    )\r\n                )\r\n\r\n                # Assign labels to excitatory layer neurons.\r\n                assignments, proportions, rates = assign_labels(\r\n                    spikes=spike_record,\r\n                    labels=label_tensor,\r\n                    n_labels=n_classes,\r\n                    rates=rates,\r\n                )\r\n\r\n                labels = []\r\n\r\n        labels.append(batch[\"label\"])\r\n\r\n        temp_spikes = 0\r\n        factor = 1.2\r\n        for retry in range(5):\r\n            # Run the network on the input.\r\n            network.run(inputs=inputs, time=time, input_time_dim=1)\r\n\r\n            # Get spikes from the network\r\n            temp_spikes = spikes[\"Y\"].get(\"s\").squeeze()\r\n\r\n            if temp_spikes.sum().sum() < 2:\r\n                inputs[\"X\"] *= (\r\n                    poisson(\r\n                        datum=factor * batch[\"image\"].clamp(min=0),\r\n                        dt=dt,\r\n                        time=int(time / dt),\r\n                    )\r\n                    .to(device)\r\n                    .view(int(time / dt), 1, 4)\r\n                )\r\n                factor *= factor\r\n            else:\r\n                break\r\n\r\n        # Get voltage recording.\r\n        exc_voltages = som_voltage_monitor.get(\"v\")\r\n\r\n        # Add to spikes recording.\r\n        # spike_record[step % update_interval] = temp_spikes.detach().clone().cpu()\r\n        spike_record[step % update_interval].copy_(temp_spikes, non_blocking=True)\r\n\r\n        # Optionally plot various simulation information.\r\n        if plot and step % plot_interval == 0:\r\n            image = batch[\"image\"].view(4)\r\n            inpt = inputs[\"X\"].view(time, 4).sum(0).view(4)\r\n            input_exc_weights = network.connections[(\"X\", \"Y\")].w\r\n            square_weights = get_square_weights(\r\n                input_exc_weights.view(4, n_neurons), n_sqrt, 2\r\n            )\r\n            square_assignments = get_square_assignments(assignments, n_sqrt)\r\n            spikes_ = {layer: spikes[layer].get(\"s\") for layer in spikes}\r\n            voltages = {\"Y\": exc_voltages}\r\n            # inpt_axes, inpt_ims = plot_input(\r\n            #     image, inpt, label=batch[\"label\"], axes=inpt_axes, ims=inpt_ims\r\n            # )\r\n            spike_ims, spike_axes = plot_spikes(spikes_, ims=spike_ims, axes=spike_axes)\r\n            [weights_im, save_weights_fn] = plot_weights(\r\n                square_weights, im=weights_im, save=save_weights_fn\r\n            )\r\n            assigns_im = plot_assignments(\r\n                square_assignments, im=assigns_im, save=save_assaiments_fn\r\n            )\r\n            perf_ax = plot_performance(accuracy, ax=perf_ax, save=save_performance_fn)\r\n            voltage_ims, voltage_axes = plot_voltages(\r\n                voltages, ims=voltage_ims, axes=voltage_axes, plot_type=\"line\"\r\n            )\r\n            #\r\n            plt.pause(1e-8)\r\n\r\n        network.reset_state_variables()  # Reset state variables.\r\n        pbar.set_description_str(\"Train progress: \")\r\n        pbar.update()\r\n\r\nprint(\"Progress: %d / %d (%.4f seconds)\" % (epoch + 1, n_epochs, t() - start))\r\nprint(\"Training complete.\\n\")\r\n\r\n\r\n# Load MNIST data.\r\n# test_dataset = MNIST(\r\n#     PoissonEncoder(time=time, dt=dt),\r\n#     None,\r\n#     root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\r\n#     download=True,\r\n#     train=False,\r\n#     transform=transforms.Compose(\r\n#         [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\r\n#     ),\r\n# )\r\ntest_dataset = CustomDataset(images=X_test,labels=y_test,image_encoder=PoissonEncoder(time=time, dt=dt))\r\n\r\n\r\n# Sequence of accuracy estimates.\r\naccuracy = {\"all\": 0, \"proportion\": 0}\r\n\r\n# Record spikes during the simulation.\r\nspike_record = torch.zeros(1, int(time / dt), n_neurons, device=device)\r\n\r\n# Train the network.\r\nprint(\"\\nBegin testing\\n\")\r\nnetwork.train(mode=False)\r\nstart = t()\r\n\r\npbar = tqdm(total=n_test)\r\nfor step, batch in enumerate(test_dataset):\r\n    if step >= n_test:\r\n        break\r\n    # Get next input sample.\r\n    inputs = {\"X\": batch[\"encoded_image\"].view(int(time / dt), 1, 4)}\r\n    if gpu:\r\n        inputs = {k: v.cuda() for k, v in inputs.items()}\r\n\r\n    # Run the network on the input.\r\n    network.run(inputs=inputs, time=time, input_time_dim=1)\r\n\r\n    # Add to spikes recording.\r\n    spike_record[0] = spikes[\"Y\"].get(\"s\").squeeze()\r\n\r\n    # Convert the array of labels into a tensor\r\n    label_tensor = torch.tensor(batch[\"label\"], device=device)\r\n\r\n    # Get network predictions.\r\n    all_activity_pred = all_activity(\r\n        spikes=spike_record, assignments=assignments, n_labels=n_classes\r\n    )\r\n    proportion_pred = proportion_weighting(\r\n        spikes=spike_record,\r\n        assignments=assignments,\r\n        proportions=proportions,\r\n        n_labels=n_classes,\r\n    )\r\n\r\n    # Compute network accuracy according to available classification strategies.\r\n    accuracy[\"all\"] += float(torch.sum(label_tensor.long() == all_activity_pred).item())\r\n    accuracy[\"proportion\"] += float(\r\n        torch.sum(label_tensor.long() == proportion_pred).item()\r\n    )\r\n\r\n    network.reset_state_variables()  # Reset state variables.\r\n    pbar.set_description_str(\"Test progress: \")\r\n    pbar.update()\r\n\r\n\r\nprint(\"\\nAll activity accuracy: %.2f\" % (accuracy[\"all\"] / n_test))\r\nprint(\"Proportion weighting accuracy: %.2f \\n\" % (accuracy[\"proportion\"] / n_test))\r\n\r\n\r\nprint(\"Progress: %d / %d (%.4f seconds)\" % (epoch + 1, n_epochs, t() - start))\r\nprint(\"Testing complete.\\n\")\r\n\r\n```","reactions":{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/1237559301/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"w5688414","id":12107462,"node_id":"MDQ6VXNlcjEyMTA3NDYy","avatar_url":"https://avatars.githubusercontent.com/u/12107462?v=4","gravatar_id":"","url":"https://api.github.com/users/w5688414","html_url":"https://github.com/w5688414","followers_url":"https://api.github.com/users/w5688414/followers","following_url":"https://api.github.com/users/w5688414/following{/other_user}","gists_url":"https://api.github.com/users/w5688414/gists{/gist_id}","starred_url":"https://api.github.com/users/w5688414/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/w5688414/subscriptions","organizations_url":"https://api.github.com/users/w5688414/orgs","repos_url":"https://api.github.com/users/w5688414/repos","events_url":"https://api.github.com/users/w5688414/events{/privacy}","received_events_url":"https://api.github.com/users/w5688414/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/1237859444","html_url":"https://github.com/BindsNET/bindsnet/issues/453#issuecomment-1237859444","issue_url":"https://api.github.com/repos/BindsNET/bindsnet/issues/453","id":1237859444,"node_id":"IC_kwDOBzWFSM5JyDx0","user":{"login":"SimonInParis","id":45327416,"node_id":"MDQ6VXNlcjQ1MzI3NDE2","avatar_url":"https://avatars.githubusercontent.com/u/45327416?v=4","gravatar_id":"","url":"https://api.github.com/users/SimonInParis","html_url":"https://github.com/SimonInParis","followers_url":"https://api.github.com/users/SimonInParis/followers","following_url":"https://api.github.com/users/SimonInParis/following{/other_user}","gists_url":"https://api.github.com/users/SimonInParis/gists{/gist_id}","starred_url":"https://api.github.com/users/SimonInParis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SimonInParis/subscriptions","organizations_url":"https://api.github.com/users/SimonInParis/orgs","repos_url":"https://api.github.com/users/SimonInParis/repos","events_url":"https://api.github.com/users/SimonInParis/events{/privacy}","received_events_url":"https://api.github.com/users/SimonInParis/received_events","type":"User","site_admin":false},"created_at":"2022-09-06T08:56:07Z","updated_at":"2022-09-06T08:56:07Z","author_association":"COLLABORATOR","body":"`X = iris['data']*10`\r\nis not enough to generate spikes, as reported by the neurons threshold graph.\r\n\r\nI found that:\r\n`X = iris['data']*args.intensity` is better, especially when intensity is about 100.0\r\n\r\nThen, the Iris dataset is very short (120 training samples). Therefore you have to adjust these:\r\n```\r\nparser.add_argument(\"--progress_interval\", type=int, default=10)\r\nparser.add_argument(\"--update_interval\", type=int, default=250)\r\nparser.add_argument(\"--update_inhibation_weights\", type=int, default=500)\r\n```\r\n\r\nto account for the length of the dataset.\r\n\r\nI'd suggest to try to set all of them to 120-1=119 for example, so that at every epoch, you adjust the SOM mechanism (increasing output neurons lateral inhibition), and report the best average accuracy from the last epoch.\r\n\r\nIf you don't succeed, with these ideas, try to monitor the 2D assignment map of the output neurons, and see if it is diverse enough. After some training, it should look like some smooth 2D map of the input labels (0, 1 or 2).\r\n\r\nAlso, don't hesitate to use many epochs, like 10 or more... because the dataset is so short.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/1237859444/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"SimonInParis","id":45327416,"node_id":"MDQ6VXNlcjQ1MzI3NDE2","avatar_url":"https://avatars.githubusercontent.com/u/45327416?v=4","gravatar_id":"","url":"https://api.github.com/users/SimonInParis","html_url":"https://github.com/SimonInParis","followers_url":"https://api.github.com/users/SimonInParis/followers","following_url":"https://api.github.com/users/SimonInParis/following{/other_user}","gists_url":"https://api.github.com/users/SimonInParis/gists{/gist_id}","starred_url":"https://api.github.com/users/SimonInParis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SimonInParis/subscriptions","organizations_url":"https://api.github.com/users/SimonInParis/orgs","repos_url":"https://api.github.com/users/SimonInParis/repos","events_url":"https://api.github.com/users/SimonInParis/events{/privacy}","received_events_url":"https://api.github.com/users/SimonInParis/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/1239542794","html_url":"https://github.com/BindsNET/bindsnet/issues/453#issuecomment-1239542794","issue_url":"https://api.github.com/repos/BindsNET/bindsnet/issues/453","id":1239542794,"node_id":"IC_kwDOBzWFSM5J4ewK","user":{"login":"w5688414","id":12107462,"node_id":"MDQ6VXNlcjEyMTA3NDYy","avatar_url":"https://avatars.githubusercontent.com/u/12107462?v=4","gravatar_id":"","url":"https://api.github.com/users/w5688414","html_url":"https://github.com/w5688414","followers_url":"https://api.github.com/users/w5688414/followers","following_url":"https://api.github.com/users/w5688414/following{/other_user}","gists_url":"https://api.github.com/users/w5688414/gists{/gist_id}","starred_url":"https://api.github.com/users/w5688414/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/w5688414/subscriptions","organizations_url":"https://api.github.com/users/w5688414/orgs","repos_url":"https://api.github.com/users/w5688414/repos","events_url":"https://api.github.com/users/w5688414/events{/privacy}","received_events_url":"https://api.github.com/users/w5688414/received_events","type":"User","site_admin":false},"created_at":"2022-09-07T15:29:05Z","updated_at":"2022-09-07T15:29:05Z","author_association":"NONE","body":"I tried the parameters that you suggested, but I got very low accuracy, about 37%, can you give more suggestions, I am new to the SNN.\r\n\r\n```\r\nimport argparse\r\nimport os\r\nfrom time import time as t\r\n\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport torch\r\nfrom torchvision import transforms\r\nfrom tqdm import tqdm\r\n\r\nfrom bindsnet.analysis.plotting import (\r\n    plot_assignments,\r\n    plot_input,\r\n    plot_performance,\r\n    plot_spikes,\r\n    plot_voltages,\r\n    plot_weights,\r\n)\r\nfrom bindsnet.datasets import MNIST\r\nfrom bindsnet.encoding import PoissonEncoder, poisson\r\nfrom bindsnet.evaluation import all_activity, assign_labels, proportion_weighting\r\nfrom bindsnet.models import IncreasingInhibitionNetwork\r\nfrom bindsnet.network.monitors import Monitor\r\nfrom bindsnet.utils import get_square_assignments, get_square_weights\r\nfrom sklearn.datasets import load_iris\r\nfrom sklearn.model_selection import train_test_split\r\nfrom bindsnet.encoding import Encoder, NullEncoder\r\nfrom torch.utils.data import Dataset\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument(\"--seed\", type=int, default=0)\r\nparser.add_argument(\"--n_neurons\", type=int, default=13)\r\nparser.add_argument(\"--n_epochs\", type=int, default=20)\r\nparser.add_argument(\"--n_test\", type=int, default=30)\r\nparser.add_argument(\"--n_train\", type=int, default=120)\r\nparser.add_argument(\"--n_workers\", type=int, default=-1)\r\nparser.add_argument(\"--theta_plus\", type=float, default=0.05)\r\nparser.add_argument(\"--time\", type=int, default=100)\r\nparser.add_argument(\"--dt\", type=int, default=1.0)\r\nparser.add_argument(\"--intensity\", type=float, default=50)\r\nparser.add_argument(\"--progress_interval\", type=int, default=10)\r\nparser.add_argument(\"--update_interval\", type=int, default=10)\r\nparser.add_argument(\"--update_inhibation_weights\", type=int, default=10)\r\nparser.add_argument(\"--plot_interval\", type=int, default=500)\r\nparser.add_argument(\"--plot\", dest=\"plot\", action=\"store_true\")\r\nparser.add_argument(\"--gpu\", dest=\"gpu\", action=\"store_true\")\r\nparser.set_defaults(plot=True, gpu=True)\r\n\r\nargs = parser.parse_args()\r\n\r\nseed = args.seed\r\nn_neurons = args.n_neurons\r\nn_epochs = args.n_epochs\r\nn_test = args.n_test\r\nn_train = args.n_train\r\nn_workers = args.n_workers\r\ntheta_plus = args.theta_plus\r\ntime = args.time\r\ndt = args.dt\r\nintensity = args.intensity\r\nprogress_interval = args.progress_interval\r\nplot_interval = args.plot_interval\r\nupdate_interval = args.update_interval\r\nplot = args.plot\r\ngpu = args.gpu\r\nupdate_inhibation_weights = args.update_inhibation_weights\r\n\r\n# Sets up Gpu use\r\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\nif gpu and torch.cuda.is_available():\r\n    torch.cuda.manual_seed_all(seed)\r\nelse:\r\n    torch.manual_seed(seed)\r\n    device = \"cpu\"\r\n    if gpu:\r\n        gpu = False\r\n\r\ntorch.set_num_threads(os.cpu_count() - 1)\r\nprint(\"Running on Device = \", device)\r\n\r\n# Determines number of workers to use\r\nif n_workers == -1:\r\n    n_workers = 0  # torch.cuda.is_available() * 4 * torch.cuda.device_count()\r\n\r\nn_sqrt = int(np.ceil(np.sqrt(n_neurons)))\r\nstart_intensity = intensity\r\n\r\n# Build network.\r\nnetwork = IncreasingInhibitionNetwork(\r\n    n_input=4,\r\n    n_neurons=n_neurons,\r\n    start_inhib=10,\r\n    max_inhib=-40.0,\r\n    theta_plus=0.05,\r\n    tc_theta_decay=1e7,\r\n    inpt_shape=(1, 4),\r\n    nu=(1e-4, 1e-2),\r\n)\r\n\r\nnetwork.to(device)\r\n\r\niris = load_iris()\r\nX = iris['data']*args.intensity\r\ny = iris['target']\r\nnames = iris['target_names']\r\nfeature_names = iris['feature_names']\r\n\r\n# Split the data set into training and testing\r\nX_train, X_test, y_train, y_test = train_test_split(\r\n    X, y, test_size=0.2, random_state=2)\r\n\r\nclass CustomDataset(Dataset):\r\n    def __init__(self,images,labels,image_encoder=None,label_encoder=None) -> None:\r\n        super().__init__()\r\n            # Allow the passthrough of None, but change to NullEncoder\r\n        if image_encoder is None:\r\n            image_encoder = NullEncoder()\r\n\r\n        if label_encoder is None:\r\n            label_encoder = NullEncoder()\r\n        self.images = images\r\n        self.labels = labels\r\n        self.image_encoder = image_encoder\r\n        self.label_encoder = label_encoder\r\n\r\n    def __getitem__(self, ind: int):\r\n        image, label = self.images[ind],self.labels[ind]\r\n        image = torch.tensor(image).unsqueeze(0).to(torch.float32)\r\n        label = torch.tensor(label)\r\n        output = {\r\n                \"image\": image,\r\n                \"label\": label,\r\n                \"encoded_image\": self.image_encoder(image),\r\n                \"encoded_label\": self.label_encoder(label),\r\n            }\r\n\r\n        return output\r\n\r\n    def __len__(self) -> int:\r\n        return self.images.shape[0]\r\n\r\ndataset = CustomDataset(images=X_train,labels=y_train,image_encoder=PoissonEncoder(time=time, dt=dt))\r\n\r\n# Record spikes during the simulation.\r\nspike_record = torch.zeros((update_interval, int(time / dt), n_neurons), device=device)\r\n\r\n# Neuron assignments and spike proportions.\r\nn_classes = 3\r\nassignments = -torch.ones(n_neurons, device=device)\r\nproportions = torch.zeros((n_neurons, n_classes), device=device)\r\nrates = torch.zeros((n_neurons, n_classes), device=device)\r\n\r\n# Sequence of accuracy estimates.\r\naccuracy = {\"all\": [], \"proportion\": []}\r\n\r\n# Voltage recording for excitatory and inhibitory layers.\r\nsom_voltage_monitor = Monitor(\r\n    network.layers[\"Y\"], [\"v\"], time=int(time / dt), device=device\r\n)\r\nnetwork.add_monitor(som_voltage_monitor, name=\"som_voltage\")\r\n\r\n# Set up monitors for spikes and voltages\r\nspikes = {}\r\nfor layer in set(network.layers):\r\n    spikes[layer] = Monitor(\r\n        network.layers[layer], state_vars=[\"s\"], time=int(time / dt), device=device\r\n    )\r\n    network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\r\n\r\nvoltages = {}\r\nfor layer in set(network.layers) - {\"X\"}:\r\n    voltages[layer] = Monitor(\r\n        network.layers[layer], state_vars=[\"v\"], time=int(time / dt), device=device\r\n    )\r\n    network.add_monitor(voltages[layer], name=\"%s_voltages\" % layer)\r\n\r\ninpt_ims, inpt_axes = None, None\r\nspike_ims, spike_axes = None, None\r\nweights_im = None\r\nassigns_im = None\r\nperf_ax = None\r\nvoltage_axes, voltage_ims = None, None\r\nsave_weights_fn = \"plots/weights/weights.png\"\r\nsave_performance_fn = \"plots/performance/performance.png\"\r\nsave_assaiments_fn = \"plots/assaiments/assaiments.png\"\r\n\r\ndirectorys = [\"plots\", \"plots/weights\", \"plots/performance\", \"plots/assaiments\"]\r\nfor directory in directorys:\r\n    if not os.path.exists(directory):\r\n        os.makedirs(directory)\r\n\r\n# diagonal weights for increassing the inhibitiosn\r\nweights_mask = (1 - torch.diag(torch.ones(n_neurons))).to(device)\r\n\r\n# Train the network.\r\nprint(\"\\nBegin training.\\n\")\r\nstart = t()\r\n\r\nfor epoch in range(n_epochs):\r\n    labels = []\r\n\r\n    if epoch % progress_interval == 0:\r\n        print(\"Progress: %d / %d (%.4f seconds)\" % (epoch, n_epochs, t() - start))\r\n        start = t()\r\n\r\n    # Create a dataloader to iterate and batch data\r\n    dataloader = torch.utils.data.DataLoader(\r\n        dataset, batch_size=1, shuffle=True, num_workers=n_workers, pin_memory=gpu\r\n    )\r\n\r\n    pbar = tqdm(total=n_train)\r\n    for step, batch in enumerate(dataloader):\r\n        if step == n_train:\r\n            break\r\n\r\n        # Get next input sample.\r\n        inputs = {\r\n            \"X\": batch[\"encoded_image\"].view(int(time / dt), 1, 4).to(device)\r\n        }\r\n\r\n        if step > 0:\r\n            if step % update_inhibation_weights == 0:\r\n                if step % (update_inhibation_weights * 10) == 0:\r\n                    network.Y_to_Y.w -= weights_mask * 50\r\n                else:\r\n                    # Inhibit the connection even more\r\n                    # network.Y_to_Y.w -= weights_mask * network.Y_to_Y.w.abs()*0.2\r\n                    network.Y_to_Y.w -= weights_mask * 0.5\r\n\r\n            if step % update_interval == 0:\r\n                # Convert the array of labels into a tensor\r\n                label_tensor = torch.tensor(labels, device=device)\r\n\r\n                # Get network predictions.\r\n                all_activity_pred = all_activity(\r\n                    spikes=spike_record, assignments=assignments, n_labels=n_classes\r\n                )\r\n                proportion_pred = proportion_weighting(\r\n                    spikes=spike_record,\r\n                    assignments=assignments,\r\n                    proportions=proportions,\r\n                    n_labels=n_classes,\r\n                )\r\n\r\n                # Compute network accuracy according to available classification strategies.\r\n                accuracy[\"all\"].append(\r\n                    100\r\n                    * torch.sum(label_tensor.long() == all_activity_pred).item()\r\n                    / len(label_tensor)\r\n                )\r\n                accuracy[\"proportion\"].append(\r\n                    100\r\n                    * torch.sum(label_tensor.long() == proportion_pred).item()\r\n                    / len(label_tensor)\r\n                )\r\n\r\n                tqdm.write(\r\n                    \"\\nAll activity accuracy: %.2f (last), %.2f (average), %.2f (best)\"\r\n                    % (\r\n                        accuracy[\"all\"][-1],\r\n                        np.mean(accuracy[\"all\"]),\r\n                        np.max(accuracy[\"all\"]),\r\n                    )\r\n                )\r\n                tqdm.write(\r\n                    \"Proportion weighting accuracy: %.2f (last), %.2f (average), %.2f\"\r\n                    \" (best)\\n\"\r\n                    % (\r\n                        accuracy[\"proportion\"][-1],\r\n                        np.mean(accuracy[\"proportion\"]),\r\n                        np.max(accuracy[\"proportion\"]),\r\n                    )\r\n                )\r\n\r\n                # Assign labels to excitatory layer neurons.\r\n                assignments, proportions, rates = assign_labels(\r\n                    spikes=spike_record,\r\n                    labels=label_tensor,\r\n                    n_labels=n_classes,\r\n                    rates=rates,\r\n                )\r\n\r\n                labels = []\r\n\r\n        labels.append(batch[\"label\"])\r\n\r\n        temp_spikes = 0\r\n        factor = 1.2\r\n        for retry in range(5):\r\n            # Run the network on the input.\r\n            network.run(inputs=inputs, time=time, input_time_dim=1)\r\n\r\n            # Get spikes from the network\r\n            temp_spikes = spikes[\"Y\"].get(\"s\").squeeze()\r\n\r\n            if temp_spikes.sum().sum() < 2:\r\n                inputs[\"X\"] *= (\r\n                    poisson(\r\n                        datum=factor * batch[\"image\"].clamp(min=0),\r\n                        dt=dt,\r\n                        time=int(time / dt),\r\n                    )\r\n                    .to(device)\r\n                    .view(int(time / dt), 1, 4)\r\n                )\r\n                factor *= factor\r\n            else:\r\n                break\r\n\r\n        # Get voltage recording.\r\n        exc_voltages = som_voltage_monitor.get(\"v\")\r\n\r\n        # Add to spikes recording.\r\n        # spike_record[step % update_interval] = temp_spikes.detach().clone().cpu()\r\n        spike_record[step % update_interval].copy_(temp_spikes, non_blocking=True)\r\n\r\n        # Optionally plot various simulation information.\r\n        if plot and step % plot_interval == 0:\r\n            image = batch[\"image\"].view(4)\r\n            inpt = inputs[\"X\"].view(time, 4).sum(0).view(4)\r\n            input_exc_weights = network.connections[(\"X\", \"Y\")].w\r\n            square_weights = get_square_weights(\r\n                input_exc_weights.view(4, n_neurons), n_sqrt, 2\r\n            )\r\n            square_assignments = get_square_assignments(assignments, n_sqrt)\r\n            spikes_ = {layer: spikes[layer].get(\"s\") for layer in spikes}\r\n            voltages = {\"Y\": exc_voltages}\r\n            inpt_axes, inpt_ims = plot_input(\r\n                image, inpt, label=batch[\"label\"], axes=inpt_axes, ims=inpt_ims\r\n            )\r\n            spike_ims, spike_axes = plot_spikes(spikes_, ims=spike_ims, axes=spike_axes)\r\n            [weights_im, save_weights_fn] = plot_weights(\r\n                square_weights, im=weights_im, save=save_weights_fn\r\n            )\r\n            assigns_im = plot_assignments(\r\n                square_assignments, im=assigns_im, save=save_assaiments_fn\r\n            )\r\n            perf_ax = plot_performance(accuracy, ax=perf_ax, save=save_performance_fn)\r\n            voltage_ims, voltage_axes = plot_voltages(\r\n                voltages, ims=voltage_ims, axes=voltage_axes, plot_type=\"line\"\r\n            )\r\n            #\r\n            plt.pause(1e-8)\r\n\r\n        network.reset_state_variables()  # Reset state variables.\r\n        pbar.set_description_str(\"Train progress: \")\r\n        pbar.update()\r\n\r\nprint(\"Progress: %d / %d (%.4f seconds)\" % (epoch + 1, n_epochs, t() - start))\r\nprint(\"Training complete.\\n\")\r\n\r\ntest_dataset = CustomDataset(images=X_test,labels=y_test,image_encoder=PoissonEncoder(time=time, dt=dt))\r\n\r\n# Sequence of accuracy estimates.\r\naccuracy = {\"all\": 0, \"proportion\": 0}\r\n\r\n# Record spikes during the simulation.\r\nspike_record = torch.zeros(1, int(time / dt), n_neurons, device=device)\r\n\r\n# Train the network.\r\nprint(\"\\nBegin testing\\n\")\r\nnetwork.train(mode=False)\r\nstart = t()\r\n\r\npbar = tqdm(total=n_test)\r\nfor step, batch in enumerate(test_dataset):\r\n    if step >= n_test:\r\n        break\r\n    # Get next input sample.\r\n    inputs = {\"X\": batch[\"encoded_image\"].view(int(time / dt), 1, 4)}\r\n    if gpu:\r\n        inputs = {k: v.cuda() for k, v in inputs.items()}\r\n\r\n    # Run the network on the input.\r\n    network.run(inputs=inputs, time=time, input_time_dim=1)\r\n\r\n    # Add to spikes recording.\r\n    spike_record[0] = spikes[\"Y\"].get(\"s\").squeeze()\r\n\r\n    # Convert the array of labels into a tensor\r\n    label_tensor = torch.tensor(batch[\"label\"], device=device)\r\n\r\n    # Get network predictions.\r\n    all_activity_pred = all_activity(\r\n        spikes=spike_record, assignments=assignments, n_labels=n_classes\r\n    )\r\n    proportion_pred = proportion_weighting(\r\n        spikes=spike_record,\r\n        assignments=assignments,\r\n        proportions=proportions,\r\n        n_labels=n_classes,\r\n    )\r\n\r\n    # Compute network accuracy according to available classification strategies.\r\n    accuracy[\"all\"] += float(torch.sum(label_tensor.long() == all_activity_pred).item())\r\n    accuracy[\"proportion\"] += float(\r\n        torch.sum(label_tensor.long() == proportion_pred).item()\r\n    )\r\n\r\n    network.reset_state_variables()  # Reset state variables.\r\n    pbar.set_description_str(\"Test progress: \")\r\n    pbar.update()\r\n\r\n\r\nprint(\"\\nAll activity accuracy: %.2f\" % (accuracy[\"all\"] / n_test))\r\nprint(\"Proportion weighting accuracy: %.2f \\n\" % (accuracy[\"proportion\"] / n_test))\r\n\r\nprint(\"Progress: %d / %d (%.4f seconds)\" % (epoch + 1, n_epochs, t() - start))\r\nprint(\"Testing complete.\\n\")\r\n\r\n```","reactions":{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/1239542794/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"w5688414","id":12107462,"node_id":"MDQ6VXNlcjEyMTA3NDYy","avatar_url":"https://avatars.githubusercontent.com/u/12107462?v=4","gravatar_id":"","url":"https://api.github.com/users/w5688414","html_url":"https://github.com/w5688414","followers_url":"https://api.github.com/users/w5688414/followers","following_url":"https://api.github.com/users/w5688414/following{/other_user}","gists_url":"https://api.github.com/users/w5688414/gists{/gist_id}","starred_url":"https://api.github.com/users/w5688414/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/w5688414/subscriptions","organizations_url":"https://api.github.com/users/w5688414/orgs","repos_url":"https://api.github.com/users/w5688414/repos","events_url":"https://api.github.com/users/w5688414/events{/privacy}","received_events_url":"https://api.github.com/users/w5688414/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/1239803371","html_url":"https://github.com/BindsNET/bindsnet/issues/453#issuecomment-1239803371","issue_url":"https://api.github.com/repos/BindsNET/bindsnet/issues/453","id":1239803371,"node_id":"IC_kwDOBzWFSM5J5eXr","user":{"login":"Hananel-Hazan","id":3954715,"node_id":"MDQ6VXNlcjM5NTQ3MTU=","avatar_url":"https://avatars.githubusercontent.com/u/3954715?v=4","gravatar_id":"","url":"https://api.github.com/users/Hananel-Hazan","html_url":"https://github.com/Hananel-Hazan","followers_url":"https://api.github.com/users/Hananel-Hazan/followers","following_url":"https://api.github.com/users/Hananel-Hazan/following{/other_user}","gists_url":"https://api.github.com/users/Hananel-Hazan/gists{/gist_id}","starred_url":"https://api.github.com/users/Hananel-Hazan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Hananel-Hazan/subscriptions","organizations_url":"https://api.github.com/users/Hananel-Hazan/orgs","repos_url":"https://api.github.com/users/Hananel-Hazan/repos","events_url":"https://api.github.com/users/Hananel-Hazan/events{/privacy}","received_events_url":"https://api.github.com/users/Hananel-Hazan/received_events","type":"User","site_admin":false},"created_at":"2022-09-07T19:46:48Z","updated_at":"2022-09-07T19:46:48Z","author_association":"COLLABORATOR","body":"Can you post the assignment map of the output neurons, and the spikes raster plots of the network? That will give us indication on how the the activity in network. ","reactions":{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/1239803371/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"Hananel-Hazan","id":3954715,"node_id":"MDQ6VXNlcjM5NTQ3MTU=","avatar_url":"https://avatars.githubusercontent.com/u/3954715?v=4","gravatar_id":"","url":"https://api.github.com/users/Hananel-Hazan","html_url":"https://github.com/Hananel-Hazan","followers_url":"https://api.github.com/users/Hananel-Hazan/followers","following_url":"https://api.github.com/users/Hananel-Hazan/following{/other_user}","gists_url":"https://api.github.com/users/Hananel-Hazan/gists{/gist_id}","starred_url":"https://api.github.com/users/Hananel-Hazan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Hananel-Hazan/subscriptions","organizations_url":"https://api.github.com/users/Hananel-Hazan/orgs","repos_url":"https://api.github.com/users/Hananel-Hazan/repos","events_url":"https://api.github.com/users/Hananel-Hazan/events{/privacy}","received_events_url":"https://api.github.com/users/Hananel-Hazan/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/1242053602","html_url":"https://github.com/BindsNET/bindsnet/issues/453#issuecomment-1242053602","issue_url":"https://api.github.com/repos/BindsNET/bindsnet/issues/453","id":1242053602,"node_id":"IC_kwDOBzWFSM5KCDvi","user":{"login":"w5688414","id":12107462,"node_id":"MDQ6VXNlcjEyMTA3NDYy","avatar_url":"https://avatars.githubusercontent.com/u/12107462?v=4","gravatar_id":"","url":"https://api.github.com/users/w5688414","html_url":"https://github.com/w5688414","followers_url":"https://api.github.com/users/w5688414/followers","following_url":"https://api.github.com/users/w5688414/following{/other_user}","gists_url":"https://api.github.com/users/w5688414/gists{/gist_id}","starred_url":"https://api.github.com/users/w5688414/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/w5688414/subscriptions","organizations_url":"https://api.github.com/users/w5688414/orgs","repos_url":"https://api.github.com/users/w5688414/repos","events_url":"https://api.github.com/users/w5688414/events{/privacy}","received_events_url":"https://api.github.com/users/w5688414/received_events","type":"User","site_admin":false},"created_at":"2022-09-09T14:35:03Z","updated_at":"2022-09-09T14:35:03Z","author_association":"NONE","body":"\r\nhere is my results, can you give more advice, thanks!\r\n![performance](https://user-images.githubusercontent.com/12107462/189374843-945643ce-0e25-4aa7-959f-42518e9aacc4.png)\r\n![weights 20](https://user-images.githubusercontent.com/12107462/189374911-bf51b356-9c4f-4970-b7f0-e37fc069c5c5.png)\r\n![assaiments 1](https://user-images.githubusercontent.com/12107462/189374942-15e9d005-4a6f-42b8-8cdc-5b7785277cca.png)\r\n\r\n","reactions":{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/1242053602/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"w5688414","id":12107462,"node_id":"MDQ6VXNlcjEyMTA3NDYy","avatar_url":"https://avatars.githubusercontent.com/u/12107462?v=4","gravatar_id":"","url":"https://api.github.com/users/w5688414","html_url":"https://github.com/w5688414","followers_url":"https://api.github.com/users/w5688414/followers","following_url":"https://api.github.com/users/w5688414/following{/other_user}","gists_url":"https://api.github.com/users/w5688414/gists{/gist_id}","starred_url":"https://api.github.com/users/w5688414/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/w5688414/subscriptions","organizations_url":"https://api.github.com/users/w5688414/orgs","repos_url":"https://api.github.com/users/w5688414/repos","events_url":"https://api.github.com/users/w5688414/events{/privacy}","received_events_url":"https://api.github.com/users/w5688414/received_events","type":"User","site_admin":false}},{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/1242160838","html_url":"https://github.com/BindsNET/bindsnet/issues/453#issuecomment-1242160838","issue_url":"https://api.github.com/repos/BindsNET/bindsnet/issues/453","id":1242160838,"node_id":"IC_kwDOBzWFSM5KCd7G","user":{"login":"Hananel-Hazan","id":3954715,"node_id":"MDQ6VXNlcjM5NTQ3MTU=","avatar_url":"https://avatars.githubusercontent.com/u/3954715?v=4","gravatar_id":"","url":"https://api.github.com/users/Hananel-Hazan","html_url":"https://github.com/Hananel-Hazan","followers_url":"https://api.github.com/users/Hananel-Hazan/followers","following_url":"https://api.github.com/users/Hananel-Hazan/following{/other_user}","gists_url":"https://api.github.com/users/Hananel-Hazan/gists{/gist_id}","starred_url":"https://api.github.com/users/Hananel-Hazan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Hananel-Hazan/subscriptions","organizations_url":"https://api.github.com/users/Hananel-Hazan/orgs","repos_url":"https://api.github.com/users/Hananel-Hazan/repos","events_url":"https://api.github.com/users/Hananel-Hazan/events{/privacy}","received_events_url":"https://api.github.com/users/Hananel-Hazan/received_events","type":"User","site_admin":false},"created_at":"2022-09-09T16:00:33Z","updated_at":"2022-09-09T16:00:33Z","author_association":"COLLABORATOR","body":"From the weights matrix values, second image, its seems that the weights are saturated. To solve this, adjust the normalization value in the `IncreasingInhibitionNetwork` object from the default `norm = 78.4` to something lower.","reactions":{"url":"https://api.github.com/repos/BindsNET/bindsnet/issues/comments/1242160838/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"Hananel-Hazan","id":3954715,"node_id":"MDQ6VXNlcjM5NTQ3MTU=","avatar_url":"https://avatars.githubusercontent.com/u/3954715?v=4","gravatar_id":"","url":"https://api.github.com/users/Hananel-Hazan","html_url":"https://github.com/Hananel-Hazan","followers_url":"https://api.github.com/users/Hananel-Hazan/followers","following_url":"https://api.github.com/users/Hananel-Hazan/following{/other_user}","gists_url":"https://api.github.com/users/Hananel-Hazan/gists{/gist_id}","starred_url":"https://api.github.com/users/Hananel-Hazan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Hananel-Hazan/subscriptions","organizations_url":"https://api.github.com/users/Hananel-Hazan/orgs","repos_url":"https://api.github.com/users/Hananel-Hazan/repos","events_url":"https://api.github.com/users/Hananel-Hazan/events{/privacy}","received_events_url":"https://api.github.com/users/Hananel-Hazan/received_events","type":"User","site_admin":false}}]