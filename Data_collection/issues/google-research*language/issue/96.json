{"url":"https://api.github.com/repos/google-research/language/issues/96","repository_url":"https://api.github.com/repos/google-research/language","labels_url":"https://api.github.com/repos/google-research/language/issues/96/labels{/name}","comments_url":"https://api.github.com/repos/google-research/language/issues/96/comments","events_url":"https://api.github.com/repos/google-research/language/issues/96/events","html_url":"https://github.com/google-research/language/issues/96","id":781876165,"node_id":"MDU6SXNzdWU3ODE4NzYxNjU=","number":96,"title":"REALM Training on TPU","user":{"login":"ogis-uno","id":1725331,"node_id":"MDQ6VXNlcjE3MjUzMzE=","avatar_url":"https://avatars.githubusercontent.com/u/1725331?v=4","gravatar_id":"","url":"https://api.github.com/users/ogis-uno","html_url":"https://github.com/ogis-uno","followers_url":"https://api.github.com/users/ogis-uno/followers","following_url":"https://api.github.com/users/ogis-uno/following{/other_user}","gists_url":"https://api.github.com/users/ogis-uno/gists{/gist_id}","starred_url":"https://api.github.com/users/ogis-uno/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ogis-uno/subscriptions","organizations_url":"https://api.github.com/users/ogis-uno/orgs","repos_url":"https://api.github.com/users/ogis-uno/repos","events_url":"https://api.github.com/users/ogis-uno/events{/privacy}","received_events_url":"https://api.github.com/users/ogis-uno/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-08T06:15:09Z","updated_at":"2021-01-08T06:35:56Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi, I'm trying to train REALM on Colab Free TPU with my own dataset, pre-trained model and modified code.\r\n\r\nMy question is : Can I train REALM on TPU (with GRPC call for dynamic dataset).\r\n\r\nI deployed GRPC server on Compute Engine VM, and confirmed I can make a GRPC call with following code.\r\n\"aaa.aaa.aaa.aaa\" is VM's external IP, \"bbbb\" is the port of GRPC server. \r\n```\r\nimport sys\r\nsys.path.append(\"./language\")\r\nfrom tensorflow.compat import v1 as tf\r\nfrom language.realm.preprocessing import _make_rpc_op\r\n\r\ntf.enable_eager_execution()\r\n\r\nwith tf.Session() as sess:\r\n  result = sess.run([_make_rpc_op(\"aaa.aaa.aaa.aaa:bbbb\", 1000)])\r\n  print(result[0].response)\r\n\r\n# b'\\n\\xbb\\x94\\x01\\n\\x8c\\x18\\n\\x016....\r\n```\r\nI was able to parse the received serialized example to the features. so my GRPC server seems working well. \r\n\r\nBut when I invoked my training loop with `estimator.train(input_fn=train_input_fn, max_steps=FLAGS.num_train_steps)`, training seems get stuck after following log messages.(I removed some duplicate messages manually.)\r\n```\r\n...\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:TPU job name worker\r\nINFO:tensorflow:Graph was finalized.\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Saving checkpoints for 0 into gs://somewhere/realm/model/model.ckpt.\r\nWARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPrefer Variable.assign which has equivalent behavior in 2.X.\r\nINFO:tensorflow:Initialized dataset iterators in 1 seconds\r\nINFO:tensorflow:Installing graceful shutdown hook.\r\nINFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\r\nINFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\r\nINFO:tensorflow:Init TPU system\r\nINFO:tensorflow:Initialized TPU in 5 seconds\r\nINFO:tensorflow:Starting infeed thread controller.\r\nINFO:tensorflow:Starting outfeed thread controller.\r\nINFO:tensorflow:Enqueue next (10) batch(es) of data to infeed.\r\nINFO:tensorflow:Dequeue next (10) batch(es) of data from outfeed.\r\n```\r\nTraining seems running,  but no log output and checkpoints show up after that.\r\nCurrently, I used Colab Free TPU for now, and `train_preprocessing_servers` was specified as follows. \r\n```\r\nFLAGS.train_preprocessing_servers\r\n# [\"aaa.aaa.aaa.aaa:bbbb\"]\r\n```\r\nI also tried with VM's internal ip address, but got no luck.\r\n\r\nAfter that, I wrote serialized examples to TFRecord format file. and replaced `get_dynamic_dataset()` with following code.\r\n```\r\ndef get_dynamic_dataset(preprocessing_servers,\r\n                        featurizer,\r\n                        num_input_threads):\r\n\r\n  def _parse_example(serialized_example):\r\n    return nest_utils.tf_example_to_structure(\r\n        serialized_example, featurizer.query_and_docs_feature_structure)\r\n\r\n  realm_examples = \"gs://somewhere/realm_examples.tfr\"\r\n  dataset = tf.data.TFRecordDataset([realm_examples], compression_type=\"GZIP\")\r\n  return dataset.map(_parse_example, num_parallel_calls=num_input_threads)\r\n\r\nfrom language.realm import model\r\nmodel.get_dynamic_dataset = get_dynamic_dataset\r\n```\r\n\r\nWith only this modification, training works well, so there seems to be a problem with GRPC call. \r\nI want to train with dynamic dataset, is there a way to achieve that with TPU?","closed_by":null,"reactions":{"url":"https://api.github.com/repos/google-research/language/issues/96/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/google-research/language/issues/96/timeline","performed_via_github_app":null,"state_reason":null}