{"url":"https://api.github.com/repos/richzhang/PerceptualSimilarity/issues/57","repository_url":"https://api.github.com/repos/richzhang/PerceptualSimilarity","labels_url":"https://api.github.com/repos/richzhang/PerceptualSimilarity/issues/57/labels{/name}","comments_url":"https://api.github.com/repos/richzhang/PerceptualSimilarity/issues/57/comments","events_url":"https://api.github.com/repos/richzhang/PerceptualSimilarity/issues/57/events","html_url":"https://github.com/richzhang/PerceptualSimilarity/issues/57","id":762419251,"node_id":"MDU6SXNzdWU3NjI0MTkyNTE=","number":57,"title":"RuntimeError: Function 'CudnnConvolutionBackward' returned nan values in its 1th output.","user":{"login":"fede-vaccaro","id":33399189,"node_id":"MDQ6VXNlcjMzMzk5MTg5","avatar_url":"https://avatars.githubusercontent.com/u/33399189?v=4","gravatar_id":"","url":"https://api.github.com/users/fede-vaccaro","html_url":"https://github.com/fede-vaccaro","followers_url":"https://api.github.com/users/fede-vaccaro/followers","following_url":"https://api.github.com/users/fede-vaccaro/following{/other_user}","gists_url":"https://api.github.com/users/fede-vaccaro/gists{/gist_id}","starred_url":"https://api.github.com/users/fede-vaccaro/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fede-vaccaro/subscriptions","organizations_url":"https://api.github.com/users/fede-vaccaro/orgs","repos_url":"https://api.github.com/users/fede-vaccaro/repos","events_url":"https://api.github.com/users/fede-vaccaro/events{/privacy}","received_events_url":"https://api.github.com/users/fede-vaccaro/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-12-11T14:47:56Z","updated_at":"2020-12-11T14:48:50Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi there, i'm currently training an Artifact Removal/Super Resolution model, a multilayer ESPCN, but i'm having this issue after few iterations of training:\r\n\r\nThis is the code how i instantiate the loss:\r\n\r\n`lpips = lpips.LPIPS(net='vgg')`\r\n\r\nThis is the code about the model:\r\n\r\n```\r\nclass ESPCNResBlock(nn.Module):\r\n    def __init__(self, nf=64):\r\n        super(ESPCNResBlock, self).__init__()\r\n        self.conv1 = nn.Conv2d(nf, nf, kernel_size=3, padding=3 // 2)\r\n        self.conv2 = nn.Conv2d(nf, nf, kernel_size=3, padding=3 // 2)\r\n\r\n    def forward(self, input):\r\n        x = self.conv1(input)\r\n        x = F.hardtanh(x, min_val=-1, max_val=1.0)\r\n        x = self.conv2(x)\r\n        x = F.hardtanh(x, min_val=-1, max_val=1.0)\r\n        return x + input\r\n\r\nclass ESPCN(nn.Module):\r\n    def __init__(self, scale_factor=2, n_blocks=4, nf=64, in_channels=3, out_channels=3):\r\n        super(ESPCN, self).__init__()\r\n        self.scale_factor = scale_factor\r\n        layers = [nn.Conv2d(in_channels, nf, kernel_size=5, padding=5 // 2),\r\n                  nn.Hardtanh()]\r\n        for _ in range(n_blocks//2):\r\n            layers += [ESPCNResBlock(),\r\n                       ]\r\n\r\n        layers += [\r\n            nn.Conv2d(nf, 32, kernel_size=3, padding=3 // 2),\r\n            nn.Hardtanh(),\r\n        ]\r\n        self.first_part = nn.Sequential(*layers)\r\n        self.last_part = nn.Sequential(\r\n            nn.Conv2d(32, out_channels * (scale_factor ** 2), kernel_size=3, padding=3 // 2),\r\n            nn.PixelShuffle(scale_factor) if scale_factor > 1 else nn.Identity(),\r\n            nn.Tanh()\r\n        )\r\n\r\n        self._initialize_weights()\r\n\r\n    def _initialize_weights(self):\r\n        for m in self.modules():\r\n            if isinstance(m, nn.Conv2d):\r\n                if m.in_channels == 32:\r\n                    nn.init.normal_(m.weight.data, mean=0.0, std=0.001)\r\n                    nn.init.zeros_(m.bias.data)\r\n                else:\r\n                    nn.init.normal_(m.weight.data, mean=0.0,\r\n                                    std=math.sqrt(2 / (m.out_channels * m.weight.data[0][0].numel())))\r\n                    nn.init.zeros_(m.bias.data)\r\n\r\n    def forward(self, input):\r\n        x = self.first_part(input)\r\n        x = self.last_part(x)\r\n\r\n        x = x + F.interpolate(input,\r\n                              scale_factor=self.scale_factor,\r\n                              mode='bilinear')\r\n\r\n        x = torch.clamp(x, min=-1, max=1)\r\n        return x\r\n\r\n```\r\n\r\nI've localized the error in the normalize function, however i'm still looking for a fix.\r\nThe model is trained with Adam on batch of 64x64 images. ","closed_by":null,"reactions":{"url":"https://api.github.com/repos/richzhang/PerceptualSimilarity/issues/57/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/richzhang/PerceptualSimilarity/issues/57/timeline","performed_via_github_app":null,"state_reason":null}