{"url":"https://api.github.com/repos/richzhang/PerceptualSimilarity/issues/4","repository_url":"https://api.github.com/repos/richzhang/PerceptualSimilarity","labels_url":"https://api.github.com/repos/richzhang/PerceptualSimilarity/issues/4/labels{/name}","comments_url":"https://api.github.com/repos/richzhang/PerceptualSimilarity/issues/4/comments","events_url":"https://api.github.com/repos/richzhang/PerceptualSimilarity/issues/4/events","html_url":"https://github.com/richzhang/PerceptualSimilarity/issues/4","id":297978358,"node_id":"MDU6SXNzdWUyOTc5NzgzNTg=","number":4,"title":"small input size","user":{"login":"dribnet","id":945979,"node_id":"MDQ6VXNlcjk0NTk3OQ==","avatar_url":"https://avatars.githubusercontent.com/u/945979?v=4","gravatar_id":"","url":"https://api.github.com/users/dribnet","html_url":"https://github.com/dribnet","followers_url":"https://api.github.com/users/dribnet/followers","following_url":"https://api.github.com/users/dribnet/following{/other_user}","gists_url":"https://api.github.com/users/dribnet/gists{/gist_id}","starred_url":"https://api.github.com/users/dribnet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dribnet/subscriptions","organizations_url":"https://api.github.com/users/dribnet/orgs","repos_url":"https://api.github.com/users/dribnet/repos","events_url":"https://api.github.com/users/dribnet/events{/privacy}","received_events_url":"https://api.github.com/users/dribnet/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2018-02-17T04:30:55Z","updated_at":"2018-02-25T21:12:53Z","closed_at":"2018-02-25T21:12:53Z","author_association":"NONE","active_lock_reason":null,"body":"I am trying to independently replicate the LPIPS metric in Keras, initially focusing on uncalibrated VGG. Following the `README` I was getting the `test_network.py` working, but am a little confused by the three example images `ex_ref.png`, `ex_p0.png`, and `ex_p1.png` and how they are processed.\r\n\r\nEach of these images are 64x64, and in `test_network.py` they are passed to the vgg network without scaling. But the native input size of VGG is 224x224 and the [pytorch models documentation](http://pytorch.org/docs/master/torchvision/models.html#id2) clearly states that input sizes are expected to that size (or larger):\r\n\r\n> All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224.\r\n\r\nNotably, when provided with 224x224 inputs, the layer sizes are:\r\n\r\n * (64, 224, 224)\r\n * (128, 112, 112)\r\n * (256, 56, 56)\r\n * (512, 28, 28)\r\n * (512, 14, 14)\r\n\r\nHowever when they left at 64x64 without scaling, the layer sizes are smaller at each stage:\r\n\r\n * (64, 64, 64)\r\n * (128, 32, 32)\r\n * (256, 16, 16)\r\n * (512, 8, 8)\r\n * (512, 4, 4)\r\n\r\nI'm not familiar with pytorch internals and so it's not clear to me how to interpret this behaviour in porting this to Keras. So my questions are:\r\n\r\n * Are these smaller inputs in fact valid ways of using these pre-trained VGG weights?\r\n * Could the LPIPS metric alternatively be implemented by always scaling inputs to the expected WxH sizes?\r\n\r\n\r\n","closed_by":{"login":"dribnet","id":945979,"node_id":"MDQ6VXNlcjk0NTk3OQ==","avatar_url":"https://avatars.githubusercontent.com/u/945979?v=4","gravatar_id":"","url":"https://api.github.com/users/dribnet","html_url":"https://github.com/dribnet","followers_url":"https://api.github.com/users/dribnet/followers","following_url":"https://api.github.com/users/dribnet/following{/other_user}","gists_url":"https://api.github.com/users/dribnet/gists{/gist_id}","starred_url":"https://api.github.com/users/dribnet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dribnet/subscriptions","organizations_url":"https://api.github.com/users/dribnet/orgs","repos_url":"https://api.github.com/users/dribnet/repos","events_url":"https://api.github.com/users/dribnet/events{/privacy}","received_events_url":"https://api.github.com/users/dribnet/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/richzhang/PerceptualSimilarity/issues/4/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/richzhang/PerceptualSimilarity/issues/4/timeline","performed_via_github_app":null,"state_reason":"completed"}