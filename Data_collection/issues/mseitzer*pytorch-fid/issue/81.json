{"url":"https://api.github.com/repos/mseitzer/pytorch-fid/issues/81","repository_url":"https://api.github.com/repos/mseitzer/pytorch-fid","labels_url":"https://api.github.com/repos/mseitzer/pytorch-fid/issues/81/labels{/name}","comments_url":"https://api.github.com/repos/mseitzer/pytorch-fid/issues/81/comments","events_url":"https://api.github.com/repos/mseitzer/pytorch-fid/issues/81/events","html_url":"https://github.com/mseitzer/pytorch-fid/issues/81","id":1155730664,"node_id":"I_kwDOBzaGKs5E4wzo","number":81,"title":"RuntimeError: stack expects each tensor to be equal size","user":{"login":"smittal10","id":12741907,"node_id":"MDQ6VXNlcjEyNzQxOTA3","avatar_url":"https://avatars.githubusercontent.com/u/12741907?v=4","gravatar_id":"","url":"https://api.github.com/users/smittal10","html_url":"https://github.com/smittal10","followers_url":"https://api.github.com/users/smittal10/followers","following_url":"https://api.github.com/users/smittal10/following{/other_user}","gists_url":"https://api.github.com/users/smittal10/gists{/gist_id}","starred_url":"https://api.github.com/users/smittal10/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/smittal10/subscriptions","organizations_url":"https://api.github.com/users/smittal10/orgs","repos_url":"https://api.github.com/users/smittal10/repos","events_url":"https://api.github.com/users/smittal10/events{/privacy}","received_events_url":"https://api.github.com/users/smittal10/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2022-03-01T19:33:21Z","updated_at":"2022-03-20T10:22:46Z","closed_at":"2022-03-20T10:22:46Z","author_association":"NONE","active_lock_reason":null,"body":"I'm using the pip package for pytorch-fid. I get this error when I run the following command. The two folders contain variable image sizes, but wouldn't the dataset util handle this?\r\npython -m pytorch_fid path/to/dataset1 path/to/dataset2\r\n\r\nError Log: \r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/mindalle/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"/opt/conda/envs/mindalle/lib/python3.8/runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/opt/conda/envs/mindalle/lib/python3.8/site-packages/pytorch_fid/__main__.py\", line 3, in <module>\r\n    pytorch_fid.fid_score.main()\r\n  File \"/opt/conda/envs/mindalle/lib/python3.8/site-packages/pytorch_fid/fid_score.py\", line 279, in main\r\n    fid_value = calculate_fid_given_paths(args.path,\r\n  File \"/opt/conda/envs/mindalle/lib/python3.8/site-packages/pytorch_fid/fid_score.py\", line 256, in calculate_fid_given_paths\r\n    m1, s1 = compute_statistics_of_path(paths[0], model, batch_size,\r\n  File \"/opt/conda/envs/mindalle/lib/python3.8/site-packages/pytorch_fid/fid_score.py\", line 240, in compute_statistics_of_path\r\n    m, s = calculate_activation_statistics(files, model, batch_size,\r\n  File \"/opt/conda/envs/mindalle/lib/python3.8/site-packages/pytorch_fid/fid_score.py\", line 225, in calculate_activation_statistics\r\n    act = get_activations(files, model, batch_size, dims, device, num_workers)\r\n  File \"/opt/conda/envs/mindalle/lib/python3.8/site-packages/pytorch_fid/fid_score.py\", line 129, in get_activations\r\n    for batch in tqdm(dataloader):\r\n  File \"/opt/conda/envs/mindalle/lib/python3.8/site-packages/tqdm/std.py\", line 1180, in __iter__\r\n    for obj in iterable:\r\n  File \"/opt/conda/envs/mindalle/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 517, in __next__\r\n    data = self._next_data()\r\n  File \"/opt/conda/envs/mindalle/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1199, in _next_data\r\n    return self._process_data(data)\r\n  File \"/opt/conda/envs/mindalle/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1225, in _process_data\r\n    data.reraise()\r\n  File \"/opt/conda/envs/mindalle/lib/python3.8/site-packages/torch/_utils.py\", line 429, in reraise\r\n    raise self.exc_type(msg)\r\nRuntimeError: Caught RuntimeError in DataLoader worker process 0.\r\nOriginal Traceback (most recent call last):\r\n  File \"/opt/conda/envs/mindalle/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\r\n    data = fetcher.fetch(index)\r\n  File \"/opt/conda/envs/mindalle/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\r\n    return self.collate_fn(data)\r\n  File \"/opt/conda/envs/mindalle/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\r\n    return torch.stack(batch, 0, out=out)\r\nRuntimeError: stack expects each tensor to be equal size, but got [3, 480, 640] at entry 0 and [3, 640, 480] at entry 1","closed_by":{"login":"mseitzer","id":16725193,"node_id":"MDQ6VXNlcjE2NzI1MTkz","avatar_url":"https://avatars.githubusercontent.com/u/16725193?v=4","gravatar_id":"","url":"https://api.github.com/users/mseitzer","html_url":"https://github.com/mseitzer","followers_url":"https://api.github.com/users/mseitzer/followers","following_url":"https://api.github.com/users/mseitzer/following{/other_user}","gists_url":"https://api.github.com/users/mseitzer/gists{/gist_id}","starred_url":"https://api.github.com/users/mseitzer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mseitzer/subscriptions","organizations_url":"https://api.github.com/users/mseitzer/orgs","repos_url":"https://api.github.com/users/mseitzer/repos","events_url":"https://api.github.com/users/mseitzer/events{/privacy}","received_events_url":"https://api.github.com/users/mseitzer/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/mseitzer/pytorch-fid/issues/81/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/mseitzer/pytorch-fid/issues/81/timeline","performed_via_github_app":null,"state_reason":"completed"}