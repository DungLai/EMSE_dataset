{"url":"https://api.github.com/repos/namisan/mt-dnn/issues/156","repository_url":"https://api.github.com/repos/namisan/mt-dnn","labels_url":"https://api.github.com/repos/namisan/mt-dnn/issues/156/labels{/name}","comments_url":"https://api.github.com/repos/namisan/mt-dnn/issues/156/comments","events_url":"https://api.github.com/repos/namisan/mt-dnn/issues/156/events","html_url":"https://github.com/namisan/mt-dnn/issues/156","id":584739586,"node_id":"MDU6SXNzdWU1ODQ3Mzk1ODY=","number":156,"title":"evaluation of a model","user":{"login":"antgr","id":2175768,"node_id":"MDQ6VXNlcjIxNzU3Njg=","avatar_url":"https://avatars.githubusercontent.com/u/2175768?v=4","gravatar_id":"","url":"https://api.github.com/users/antgr","html_url":"https://github.com/antgr","followers_url":"https://api.github.com/users/antgr/followers","following_url":"https://api.github.com/users/antgr/following{/other_user}","gists_url":"https://api.github.com/users/antgr/gists{/gist_id}","starred_url":"https://api.github.com/users/antgr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antgr/subscriptions","organizations_url":"https://api.github.com/users/antgr/orgs","repos_url":"https://api.github.com/users/antgr/repos","events_url":"https://api.github.com/users/antgr/events{/privacy}","received_events_url":"https://api.github.com/users/antgr/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-03-19T22:36:07Z","updated_at":"2020-04-01T07:09:54Z","closed_at":"2020-04-01T07:09:54Z","author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\nif we run for example for four epochs training, how should I evaluate the performance of the model? I have the predictions of the model at the end of each epoch, for validation and for test set. What should I report as *the* performance of the model? Should I report the best  performance of the four epochs? Should I report the test set performance for the epoch where the model has the best performance on validation test? Does the framework reports automatically the performance of the model? ","closed_by":{"login":"namisan","id":3060273,"node_id":"MDQ6VXNlcjMwNjAyNzM=","avatar_url":"https://avatars.githubusercontent.com/u/3060273?v=4","gravatar_id":"","url":"https://api.github.com/users/namisan","html_url":"https://github.com/namisan","followers_url":"https://api.github.com/users/namisan/followers","following_url":"https://api.github.com/users/namisan/following{/other_user}","gists_url":"https://api.github.com/users/namisan/gists{/gist_id}","starred_url":"https://api.github.com/users/namisan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/namisan/subscriptions","organizations_url":"https://api.github.com/users/namisan/orgs","repos_url":"https://api.github.com/users/namisan/repos","events_url":"https://api.github.com/users/namisan/events{/privacy}","received_events_url":"https://api.github.com/users/namisan/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/namisan/mt-dnn/issues/156/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/namisan/mt-dnn/issues/156/timeline","performed_via_github_app":null,"state_reason":"completed"}