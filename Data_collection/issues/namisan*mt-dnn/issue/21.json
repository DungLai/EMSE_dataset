{"url":"https://api.github.com/repos/namisan/mt-dnn/issues/21","repository_url":"https://api.github.com/repos/namisan/mt-dnn","labels_url":"https://api.github.com/repos/namisan/mt-dnn/issues/21/labels{/name}","comments_url":"https://api.github.com/repos/namisan/mt-dnn/issues/21/comments","events_url":"https://api.github.com/repos/namisan/mt-dnn/issues/21/events","html_url":"https://github.com/namisan/mt-dnn/issues/21","id":433829317,"node_id":"MDU6SXNzdWU0MzM4MjkzMTc=","number":21,"title":"Running fine_tuning and domain_adaption scripts using my trained model instead of mt_dnn_base.pt","user":{"login":"ns-moosavi","id":19606435,"node_id":"MDQ6VXNlcjE5NjA2NDM1","avatar_url":"https://avatars.githubusercontent.com/u/19606435?v=4","gravatar_id":"","url":"https://api.github.com/users/ns-moosavi","html_url":"https://github.com/ns-moosavi","followers_url":"https://api.github.com/users/ns-moosavi/followers","following_url":"https://api.github.com/users/ns-moosavi/following{/other_user}","gists_url":"https://api.github.com/users/ns-moosavi/gists{/gist_id}","starred_url":"https://api.github.com/users/ns-moosavi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ns-moosavi/subscriptions","organizations_url":"https://api.github.com/users/ns-moosavi/orgs","repos_url":"https://api.github.com/users/ns-moosavi/repos","events_url":"https://api.github.com/users/ns-moosavi/events{/privacy}","received_events_url":"https://api.github.com/users/ns-moosavi/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2019-04-16T14:59:12Z","updated_at":"2019-04-16T17:49:18Z","closed_at":"2019-04-16T17:28:22Z","author_association":"NONE","active_lock_reason":null,"body":"Hello,\r\n\r\nI have trained the mt-dnn, initialized with mt_dnn_large.pt, with some new input and with the following parameters \r\n\r\n> `{'log_file': 'checkpoints/mt-dnn-NL-labels_adamax_answer_opt1_gc0_ggc1_2019-04-15T2138/log.log', 'init_checkpoint': '../mt_dnn_models/mt_dnn_large.pt', 'data_dir': '../data/mt_dnn', 'data_sort_on': False, 'name': 'farmer', 'train_datasets': ['mnli', 'rte', 'qnli'], 'test_datasets': ['mnli_matched', 'mnli_mismatched', 'rte'], 'pw_tasks': ['qnnli'], 'update_bert_opt': 0, 'multi_gpu_on': True, 'mem_cum_type': 'simple', 'answer_num_turn': 5, 'answer_mem_drop_p': 0.1, 'answer_att_hidden_size': 128, 'answer_att_type': 'bilinear', 'answer_rnn_type': 'gru', 'answer_sum_att_type': 'bilinear', 'answer_merge_opt': 1, 'answer_mem_type': 1, 'answer_dropout_p': 0.1, 'answer_weight_norm_on': False, 'dump_state_on': False, 'answer_opt': [1, 1, 1], 'label_size': '3,2,2', 'mtl_opt': 0, 'ratio': 0, 'mix_opt': 0, 'max_seq_len': 512, 'init_ratio': 1, 'cuda': True, 'log_per_updates': 500, 'epochs': 5, 'batch_size': 16, 'batch_size_eval': 8, 'optimizer': 'adamax', 'grad_clipping': 0.0, 'global_grad_clipping': 1.0, 'weight_decay': 0, 'learning_rate': 5e-05, 'momentum': 0, 'warmup': 0.1, 'warmup_schedule': 'warmup_linear', 'vb_dropout': True, 'dropout_p': 0.1, 'dropout_w': 0.0, 'bert_dropout_p': 0.1, 'ema_opt': 0, 'ema_gamma': 0.995, 'have_lr_scheduler': True, 'multi_step_lr': '10,20,30', 'freeze_layers': -1, 'embedding_opt': 0, 'lr_gamma': 0.5, 'bert_l2norm': 0.0, 'scheduler_type': 'ms', 'output_dir': 'checkpoints/mt-dnn-NL-labels_adamax_answer_opt1_gc0_ggc1_2019-04-15T2138', 'seed': 2018, 'task_config_path': 'configs/tasks_config.json', 'tasks_dropout_p': [0.1, 0.1, 0.1]}``\r\n\r\nI train this model for e.g., 4 epochs and I want to perform the fine tuning and domain adaptation experiments based on the resulting model, \"checkpoint/model_4.pt\". Therefore, in run_rte.sh or snli_domain_adaptation_bash.sh I replace the initial checkpoint from ../mt_dnn_models/mt_dnn_base.pt to checkpoint/model_4.pt.\r\n\r\nDoing so, I get the following error\r\n\r\n \r\n\r\n> export CUDA_VISIBLE_DEVICES=4,5\r\nBetter speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\r\nNamespace(answer_att_hidden_size=128, answer_att_type='bilinear', answer_dropout_p=0.1, answer_mem_drop_p=0.1, answer_mem_type=1, answer_merge_opt=1, answer_num_turn=5, answer_opt=0, answer_rnn_type='gru', answer_sum_att_type='bilinear', answer_weight_norm_on=False, batch_size=32, batch_size_eval=8, bert_dropout_p=0.1, bert_l2norm=0.0, cuda=True, data_dir='../data/mt_dnn/', data_sort_on=False, dropout_p=0.1, dropout_w=0.0, dump_state_on=False, ema_gamma=0.995, ema_opt=0, embedding_opt=0, epochs=5, freeze_layers=-1, global_grad_clipping=1.0, grad_clipping=0.0, have_lr_scheduler=True, init_checkpoint='checkpoints/mt-dnn-NL-labels_adamax_answer_opt1_gc0_ggc1_2019-04-15T2138/model_4.pt', init_ratio=1, label_size='3', learning_rate=2e-05, log_file='checkpoints/mt-dnn-rte_adamax_answer_opt0_gc0_ggc1_2019-04-16T1636/log.log', log_per_updates=500, lr_gamma=0.5, max_seq_len=512, mem_cum_type='simple', mix_opt=0, momentum=0, mtl_opt=0, multi_gpu_on=False, multi_step_lr='10,20,30', name='farmer', optimizer='adamax', output_dir='checkpoints/mt-dnn-rte_adamax_answer_opt0_gc0_ggc1_2019-04-16T1636', pw_tasks=['qnnli'], ratio=0, scheduler_type='ms', seed=2018, task_config_path='configs/tasks_config.json', test_datasets=['rte'], train_datasets=['rte'], update_bert_opt=0, vb_dropout=True, warmup=0.1, warmup_schedule='warmup_linear', weight_decay=0)\r\n04/16/2019 04:36:15 0\r\n04/16/2019 04:36:15 Launching the MT-DNN training\r\n04/16/2019 04:36:15 Loading ../data/mt_dnn/rte_train.json as task 0\r\nLoaded 2490 samples out of 2490\r\n04/16/2019 04:36:15 2\r\nLoaded 277 samples out of 277\r\nLoaded 3000 samples out of 3000\r\n04/16/2019 04:36:15 ####################\r\n04/16/2019 04:36:15 {'log_file': 'checkpoints/mt-dnn-rte_adamax_answer_opt0_gc0_ggc1_2019-04-16T1636/log.log', 'init_checkpoint': 'checkpoints/mt-dnn-NL-labels_adamax_answer_opt1_gc0_ggc1_2019-04-15T2138/model_4.pt', 'data_dir': '../data/mt_dnn/', 'data_sort_on': False, 'name': 'farmer', 'train_datasets': ['rte'], 'test_datasets': ['rte'], 'pw_tasks': ['qnnli'], 'update_bert_opt': 0, 'multi_gpu_on': False, 'mem_cum_type': 'simple', 'answer_num_turn': 5, 'answer_mem_drop_p': 0.1, 'answer_att_hidden_size': 128, 'answer_att_type': 'bilinear', 'answer_rnn_type': 'gru', 'answer_sum_att_type': 'bilinear', 'answer_merge_opt': 1, 'answer_mem_type': 1, 'answer_dropout_p': 0.1, 'answer_weight_norm_on': False, 'dump_state_on': False, 'answer_opt': [0], 'label_size': '2', 'mtl_opt': 0, 'ratio': 0, 'mix_opt': 0, 'max_seq_len': 512, 'init_ratio': 1, 'cuda': True, 'log_per_updates': 500, 'epochs': 5, 'batch_size': 32, 'batch_size_eval': 8, 'optimizer': 'adamax', 'grad_clipping': 0.0, 'global_grad_clipping': 1.0, 'weight_decay': 0, 'learning_rate': 2e-05, 'momentum': 0, 'warmup': 0.1, 'warmup_schedule': 'warmup_linear', 'vb_dropout': True, 'dropout_p': 0.1, 'dropout_w': 0.0, 'bert_dropout_p': 0.1, 'ema_opt': 0, 'ema_gamma': 0.995, 'have_lr_scheduler': True, 'multi_step_lr': '10,20,30', 'freeze_layers': -1, 'embedding_opt': 0, 'lr_gamma': 0.5, 'bert_l2norm': 0.0, 'scheduler_type': 'ms', 'output_dir': 'checkpoints/mt-dnn-rte_adamax_answer_opt0_gc0_ggc1_2019-04-16T1636', 'seed': 2018, 'task_config_path': 'configs/tasks_config.json', 'tasks_dropout_p': [0.1]}\r\n04/16/2019 04:36:15 ####################\r\n04/16/2019 04:36:35 \r\n############# Model Arch of MT-DNN #############\r\nSANBertNetwork(\r\n  (bert): BertModel(\r\n    (embeddings): BertEmbeddings(\r\n      (word_embeddings): Embedding(30522, 1024)\r\n      (position_embeddings): Embedding(512, 1024)\r\n      (token_type_embeddings): Embedding(2, 1024)\r\n      (LayerNorm): BertLayerNorm()\r\n      (dropout): Dropout(p=0.1)\r\n    )\r\n    (encoder): BertEncoder(\r\n      (layer): ModuleList(\r\n        (0): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (1): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (2): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (3): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (4): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (5): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (6): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (7): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (8): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (9): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (10): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (11): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (12): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (13): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (14): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (15): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (16): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (17): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (18): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (19): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (20): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (21): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (22): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n        (23): BertLayer(\r\n          (attention): BertAttention(\r\n            (self): BertSelfAttention(\r\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n            (output): BertSelfOutput(\r\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n              (LayerNorm): BertLayerNorm()\r\n              (dropout): Dropout(p=0.1)\r\n            )\r\n          )\r\n          (intermediate): BertIntermediate(\r\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\r\n          )\r\n          (output): BertOutput(\r\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\r\n            (LayerNorm): BertLayerNorm()\r\n            (dropout): Dropout(p=0.1)\r\n          )\r\n        )\r\n      )\r\n    )\r\n    (pooler): BertPooler(\r\n      (dense): Linear(in_features=1024, out_features=1024, bias=True)\r\n      (activation): Tanh()\r\n    )\r\n  )\r\n  (scoring_list): ModuleList(\r\n    (0): SANClassifier(\r\n      (dropout): DropoutWrapper()\r\n      (query_wsum): SelfAttnWrapper(\r\n        (att): LinearSelfAttn(\r\n          (linear): Linear(in_features=1024, out_features=1, bias=True)\r\n          (dropout): DropoutWrapper()\r\n        )\r\n      )\r\n      (attn): FlatSimilarityWrapper(\r\n        (att_dropout): DropoutWrapper()\r\n        (score_func): BilinearFlatSim(\r\n          (linear): Linear(in_features=1024, out_features=1024, bias=True)\r\n          (dropout): DropoutWrapper()\r\n        )\r\n      )\r\n      (rnn): GRUCell(1024, 1024)\r\n      (classifier): Classifier(\r\n        (dropout): DropoutWrapper()\r\n        (proj): Linear(in_features=4096, out_features=3, bias=True)\r\n      )\r\n    )\r\n    (1): SANClassifier(\r\n      (dropout): DropoutWrapper()\r\n      (query_wsum): SelfAttnWrapper(\r\n        (att): LinearSelfAttn(\r\n          (linear): Linear(in_features=1024, out_features=1, bias=True)\r\n          (dropout): DropoutWrapper()\r\n        )\r\n      )\r\n      (attn): FlatSimilarityWrapper(\r\n        (att_dropout): DropoutWrapper()\r\n        (score_func): BilinearFlatSim(\r\n          (linear): Linear(in_features=1024, out_features=1024, bias=True)\r\n          (dropout): DropoutWrapper()\r\n        )\r\n      )\r\n      (rnn): GRUCell(1024, 1024)\r\n      (classifier): Classifier(\r\n        (dropout): DropoutWrapper()\r\n        (proj): Linear(in_features=4096, out_features=2, bias=True)\r\n      )\r\n    )\r\n    (2): SANClassifier(\r\n      (dropout): DropoutWrapper()\r\n      (query_wsum): SelfAttnWrapper(\r\n        (att): LinearSelfAttn(\r\n          (linear): Linear(in_features=1024, out_features=1, bias=True)\r\n          (dropout): DropoutWrapper()\r\n        )\r\n      )\r\n      (attn): FlatSimilarityWrapper(\r\n        (att_dropout): DropoutWrapper()\r\n        (score_func): BilinearFlatSim(\r\n          (linear): Linear(in_features=1024, out_features=1024, bias=True)\r\n          (dropout): DropoutWrapper()\r\n        )\r\n      )\r\n      (rnn): GRUCell(1024, 1024)\r\n      (classifier): Classifier(\r\n        (dropout): DropoutWrapper()\r\n        (proj): Linear(in_features=4096, out_features=2, bias=True)\r\n      )\r\n    )\r\n  )\r\n)\r\n\r\n04/16/2019 04:36:35 Total number of params: 357215242\r\n\r\n04/16/2019 04:36:36 At epoch 0\r\nTraceback (most recent call last):\r\n  File \"../train.py\", line 354, in <module>\r\n    main()\r\n  File \"../train.py\", line 316, in main\r\n    model.update(batch_meta, batch_data)\r\n  File \"../mt_dnn/model.py\", line 151, in update\r\n    self.optimizer.step()\r\n  File \"../module/bert_optim.py\", line 119, in step\r\n    exp_avg.mul_(beta1).add_(1 - beta1, grad)\r\nRuntimeError: expected type torch.FloatTensor but got torch.cuda.FloatTensor\r\n\r\n\r\nMay I ask you what is the problem?\r\nI can run either of these scripts using ../mt_dnn_models/mt_dnn_large.pt but not using the model that  trained myself, i.e., model_4.pt\r\n","closed_by":{"login":"namisan","id":3060273,"node_id":"MDQ6VXNlcjMwNjAyNzM=","avatar_url":"https://avatars.githubusercontent.com/u/3060273?v=4","gravatar_id":"","url":"https://api.github.com/users/namisan","html_url":"https://github.com/namisan","followers_url":"https://api.github.com/users/namisan/followers","following_url":"https://api.github.com/users/namisan/following{/other_user}","gists_url":"https://api.github.com/users/namisan/gists{/gist_id}","starred_url":"https://api.github.com/users/namisan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/namisan/subscriptions","organizations_url":"https://api.github.com/users/namisan/orgs","repos_url":"https://api.github.com/users/namisan/repos","events_url":"https://api.github.com/users/namisan/events{/privacy}","received_events_url":"https://api.github.com/users/namisan/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/namisan/mt-dnn/issues/21/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/namisan/mt-dnn/issues/21/timeline","performed_via_github_app":null,"state_reason":"completed"}