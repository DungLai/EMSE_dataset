{"url":"https://api.github.com/repos/namisan/mt-dnn/issues/163","repository_url":"https://api.github.com/repos/namisan/mt-dnn","labels_url":"https://api.github.com/repos/namisan/mt-dnn/issues/163/labels{/name}","comments_url":"https://api.github.com/repos/namisan/mt-dnn/issues/163/comments","events_url":"https://api.github.com/repos/namisan/mt-dnn/issues/163/events","html_url":"https://github.com/namisan/mt-dnn/issues/163","id":600537700,"node_id":"MDU6SXNzdWU2MDA1Mzc3MDA=","number":163,"title":"Is there a way to extract all layers and all head's embedding using mt_dnn_base_uncased in extractor.py?","user":{"login":"Jess0-0","id":29790071,"node_id":"MDQ6VXNlcjI5NzkwMDcx","avatar_url":"https://avatars.githubusercontent.com/u/29790071?v=4","gravatar_id":"","url":"https://api.github.com/users/Jess0-0","html_url":"https://github.com/Jess0-0","followers_url":"https://api.github.com/users/Jess0-0/followers","following_url":"https://api.github.com/users/Jess0-0/following{/other_user}","gists_url":"https://api.github.com/users/Jess0-0/gists{/gist_id}","starred_url":"https://api.github.com/users/Jess0-0/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Jess0-0/subscriptions","organizations_url":"https://api.github.com/users/Jess0-0/orgs","repos_url":"https://api.github.com/users/Jess0-0/repos","events_url":"https://api.github.com/users/Jess0-0/events{/privacy}","received_events_url":"https://api.github.com/users/Jess0-0/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-04-15T19:32:03Z","updated_at":"2020-04-18T19:20:45Z","closed_at":"2020-04-18T19:20:45Z","author_association":"NONE","active_lock_reason":null,"body":"When using the extractor.py and set the --layers to \"0,1,2,3,4,5,6,7,8,9,10,11\", the script is able to extract the embedding for all 12 layers for each token. I'm wondering if there is a way to extract the embedding for all 12 layers for all 12 heads in the model for each token. If not, I'm wondering if the current 768 dimension array for each layer is taking an average of all 12 head's embedding or using other forms of aggregation.\r\n\r\nAlso, I'm wondering if there is a script to extract the attention matrices for each input sample.","closed_by":{"login":"Jess0-0","id":29790071,"node_id":"MDQ6VXNlcjI5NzkwMDcx","avatar_url":"https://avatars.githubusercontent.com/u/29790071?v=4","gravatar_id":"","url":"https://api.github.com/users/Jess0-0","html_url":"https://github.com/Jess0-0","followers_url":"https://api.github.com/users/Jess0-0/followers","following_url":"https://api.github.com/users/Jess0-0/following{/other_user}","gists_url":"https://api.github.com/users/Jess0-0/gists{/gist_id}","starred_url":"https://api.github.com/users/Jess0-0/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Jess0-0/subscriptions","organizations_url":"https://api.github.com/users/Jess0-0/orgs","repos_url":"https://api.github.com/users/Jess0-0/repos","events_url":"https://api.github.com/users/Jess0-0/events{/privacy}","received_events_url":"https://api.github.com/users/Jess0-0/received_events","type":"User","site_admin":false},"reactions":{"url":"https://api.github.com/repos/namisan/mt-dnn/issues/163/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/namisan/mt-dnn/issues/163/timeline","performed_via_github_app":null,"state_reason":"completed"}